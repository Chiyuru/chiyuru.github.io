<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"chiyuru.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="我自己一个人能完成一个学期的 scribing，所以能不能多给点 bonus（确信 茶园老师和教务手都太快了，俩小时速通特殊原因选课，下次还来。">
<meta property="og:type" content="article">
<meta property="og:title" content="年轻人的第一门 optimization 是茶园课">
<meta property="og:url" content="https://chiyuru.github.io/2023/09/25/Introduction-to-Optimization-Theory/index.html">
<meta property="og:site_name" content="『姑妄言之姑妄听之』">
<meta property="og:description" content="我自己一个人能完成一个学期的 scribing，所以能不能多给点 bonus（确信 茶园老师和教务手都太快了，俩小时速通特殊原因选课，下次还来。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/09/26/PEzuQl2MOW37Jr1.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/26/Q9FIPLlzdce5aux.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/10/21/AzN5LGkDotKBbFh.png">
<meta property="og:image" content="https://s2.loli.net/2023/09/26/PEzuQl2MOW37Jr1.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/10/21/Y79yhqJDgElijmI.png">
<meta property="og:image" content="https://s2.loli.net/2023/09/26/PEzuQl2MOW37Jr1.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/26/PEzuQl2MOW37Jr1.jpg">
<meta property="article:published_time" content="2023-09-25T02:28:52.000Z">
<meta property="article:modified_time" content="2023-10-27T10:58:50.585Z">
<meta property="article:author" content="驰雨Chiyuru">
<meta property="article:tag" content="数学">
<meta property="article:tag" content="统计">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/09/26/PEzuQl2MOW37Jr1.jpg">

<link rel="canonical" href="https://chiyuru.github.io/2023/09/25/Introduction-to-Optimization-Theory/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>年轻人的第一门 optimization 是茶园课 | 『姑妄言之姑妄听之』</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="『姑妄言之姑妄听之』" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">『姑妄言之姑妄听之』</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-link">

    <a href="/links/" rel="section"><i class="fa fa-link fa-fw"></i>链接</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chiyuru.github.io/2023/09/25/Introduction-to-Optimization-Theory/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="驰雨Chiyuru">
      <meta itemprop="description" content="おはよう、朝だよ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="『姑妄言之姑妄听之』">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          年轻人的第一门 optimization 是茶园课
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-09-25 10:28:52" itemprop="dateCreated datePublished" datetime="2023-09-25T10:28:52+08:00">2023-09-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-10-27 18:58:50" itemprop="dateModified" datetime="2023-10-27T18:58:50+08:00">2023-10-27</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>我自己一个人能完成一个学期的 scribing，<del>所以能不能多给点
bonus</del>（确信</p>
<p>茶园老师和教务手都太快了，俩小时速通特殊原因选课，下次还来。</p>
<span id="more"></span>
<h1 id="lecture-1">Lecture 1</h1>
<p>打开 Introduction to Linear Optimization，看到第一章标题是 linear
programming，差点 PTSD 到当场退课（</p>
<p>实际上就是线性规划，和（我害怕的那个）programming 没什么关系（</p>
<h2 id="standardized-linear-programming">Standardized Linear
Programming</h2>
<h3 id="reduce-to-standardized-format">Reduce to Standardized
Format</h3>
<ul>
<li><p>线性优化众所周知应该是线性的（草），最朴素的想法下它可以转换为以下形式：</p>
<p><span class="math display">\[\text{minimize} \quad c^Tx\]</span></p>
<p><span class="math display">\[\text{subject to} \quad \begin{aligned}
&amp; a_i^Tx \geq b_i \quad i \in M_1 \\ &amp; a_i^Tx \leq b_i \quad i
\in M_2 \\ &amp; a_i^Tx = b_i \quad i \in M_3 \\ &amp; x_j \geq 0 \quad
\quad j \in N_1 \\ &amp; x_j \leq 0 \quad \quad j \in N_2
\end{aligned}\]</span></p>
<p>主要是通过取 <span class="math inline">\(-c\)</span> 把 maximize
问题变为 minimize，以及将不同的 constraints 分类。</p></li>
<li><p>想要改成更为统一、方便处理的形式，可以通过取负将所有的
constraints 改为 <span class="math inline">\(a_i ^T x \geq
b_i\)</span>，但还是全取等最好。</p>
<p><span class="math display">\[\text{minimize} \quad c^Tx\]</span></p>
<p><span class="math display">\[\text{subject to} \quad \begin{aligned}
&amp; A^Tx =b  \\ &amp; x_j \geq 0  \end{aligned}\]</span></p>
<p>具体来说只需要再经历以下两步化简：</p>
<ul>
<li>将不受限制的 free variable 拆解为 <span class="math inline">\(x_i =
x_i ^+ - x_i ^-\)</span>，则有 <span class="math inline">\(x_i^+ \geq 0,
x_i ^- \geq 0\)</span>；</li>
<li>将 <span class="math inline">\(\sum_{j=1} ^n a_{ij} x_j \leq
b_i\)</span> 改为 <span class="math inline">\(\sum_{j=1} ^n a_{ij} x_j +
y_i = b_i, \text{with} \; y_i \geq 0\)</span></li>
</ul>
<p>注意到 <span class="math inline">\(x_j \geq 0\)</span>
是对所有变量成立的，我还是第二次看才发现这个问题。</p></li>
</ul>
<h3 id="other-optimization-problems">Other Optimization Problems</h3>
<p>也会遇到一些其他形式的优化问题，在 cost function
之类的地方有些许改动，处理思想仍然是一样的。</p>
<ul>
<li><p><span class="math display">\[\text{minimize} \quad
\max_{i=1,2,...,m} (c_i^Tx+d_i)\]</span></p>
<p><span class="math display">\[\text{subject to} \quad Ax \geq
b\]</span></p>
<p>只需要把 cost function 变成 <span class="math inline">\(m\)</span> 个
constraints 就可以了：</p>
<p><span class="math display">\[\text{minimize} \quad z\]</span></p>
<p><span class="math display">\[\text{subject to} \begin{aligned} \quad
&amp; Ax \geq b \\ &amp; z \geq c_i^Tx + d_i  \quad \text{for} \; i =
1,2,...,m\end{aligned}\]</span></p></li>
<li><p><span class="math display">\[\text{minimize} \quad \sum_{i=1}^n
c_i | x_i|\]</span></p>
<p><span class="math display">\[\text{subject to} \quad Ax \geq
b\]</span></p>
<p>这个在日记里吐槽过了，我个人认为更符合直觉的是拆正负部，只是需要保证二者之一是
<span class="math inline">\(0\)</span>，还是不方便，学实分析学得。也可以改成：</p>
<p><span class="math display">\[\text{minimize} \quad \sum_{i=1}^n c_i
y_i\]</span></p>
<p><span class="math display">\[\text{subject to} \begin{aligned} \quad
&amp; Ax \geq b \\ &amp; x_i \leq y_i, -x_i \leq y_i \quad \text{for} \;
i=1,2,...,n \\ &amp; y_i \geq 0 \quad \quad \quad \ \ \ \qquad
\text{for} \; i =1,2,...,n  \end{aligned}\]</span></p></li>
</ul>
<p>都很 trivial，初等变换一下就好了。</p>
<h2 id="solutions-to-lp-problems">Solutions to LP Problems</h2>
<p>首先 LP problem 有四种可能性，学着学着都要忘了。</p>
<ul>
<li>There exists a unique optimal solution.</li>
<li>There exist multiple optimal solutions; in that case, the set of
optimal solutions can be either bounded or unbounded.</li>
<li>The optimal cost is <span class="math inline">\(-\infty\)</span>,
and no feasible solution is optimal.</li>
<li>The feasible set is empty. (The LP problem is infeasible.)</li>
</ul>
<h3 id="notations">Notations</h3>
<p>一些拼不对的单词了属于是。</p>
<p>突然发现其实可以在笔记里多放点迷言迷语：</p>
<p><img src="https://s2.loli.net/2023/09/26/PEzuQl2MOW37Jr1.jpg" alt="mi1.jpg"></p>
<ul>
<li><p>A <strong>polyhedron</strong> is a set that can be described as
<span class="math inline">\(\{x \in \mathbb R^n | Ax \geq b \}\)</span>,
where <span class="math inline">\(A\)</span> is an <span class="math inline">\(m\times n\)</span> matrix and <span class="math inline">\(b \in \mathbb R^m\)</span>.</p></li>
<li><p>A set <span class="math inline">\(S \subset \mathbb R^n\)</span>
is <strong>bounded</strong> if there exists a constant <span class="math inline">\(K\)</span> such that the absolute value of every
component of every element of <span class="math inline">\(S\)</span> is
less than or equal to <span class="math inline">\(K\)</span>.</p></li>
<li><p>Let <span class="math inline">\(a\)</span> be a non-zero vector
on <span class="math inline">\(\mathbb R^n\)</span> and let <span class="math inline">\(b\)</span> be a scalar, thus:</p>
<ul>
<li>The set <span class="math inline">\(\{x \in \mathbb R^n | a^Tx =b
\}\)</span> is called a <strong>hyperplane</strong>.</li>
<li>The set <span class="math inline">\(\{x \in \mathbb R^n | a^Tx \geq
b \}\)</span> is called a <strong>half-space</strong>.</li>
</ul></li>
<li><p>A set <span class="math inline">\(S \subset \mathbb R^n\)</span>
is <strong>convex</strong> if for any <span class="math inline">\(x , y
\in S\)</span> and any <span class="math inline">\(\lambda \in
[0,1]\)</span>, we have <span class="math inline">\(\lambda x +
(1-\lambda) y \in S\)</span>.</p></li>
<li><p>Let <span class="math inline">\(x_1 ,x_2,...,x_n\)</span> be
vectors in <span class="math inline">\(\mathbb R^k\)</span> and let
<span class="math inline">\(\lambda_1, \lambda_2,...,\lambda_n\)</span>
be non-negative scalars whose sum is unity.</p>
<p>The convex hull of <span class="math inline">\(x_1,
x_2,...,x_n\)</span> is the set of all convex combinations of these
vectors, i.e.,</p>
<p><span class="math display">\[\{\sum_{i=1}^n \lambda_i x_i |
\sum_{i=1}^n \lambda_i =1 \;  \text{and} \; \lambda_i \in [0,1]
\}\]</span></p></li>
</ul>
<p>有一些很 trivial 的结论，看起来既重要又不重要的，希望有脑子就行。</p>
<p><img src="https://s2.loli.net/2023/09/26/Q9FIPLlzdce5aux.jpg" alt="mi2.jpg"></p>
<ul>
<li>One writes <span class="math inline">\(f(x) = O(g(x))\)</span> if
there exists a positive real number <span class="math inline">\(M\)</span> and a real number <span class="math inline">\(x_0\)</span> s.t. <span class="math inline">\(f(x)
\leq Mg(x)\)</span> for any <span class="math inline">\(x \geq
x_0\)</span>.</li>
<li>One writes <span class="math inline">\(f(x) = \Omega (g(x))\)</span>
if there exists a positive real number <span class="math inline">\(M\)</span> and a real number <span class="math inline">\(x_0\)</span> s.t. <span class="math inline">\(f(x)
\geq M g(x)\)</span> for any <span class="math inline">\(x\geq
x_0\)</span>.</li>
<li>One writes <span class="math inline">\(f(x) = \Theta (g(x))\)</span>
if <span class="math inline">\(f(x)= O(g(x))\)</span> and <span class="math inline">\(f(x) = \Omega(g(x))\)</span>.</li>
</ul>
<p>这门课上为什么有人没学过算法不知道这些是什么啊.jpg</p>
<h3 id="how-to-describe-optimal-solutions">How to Describe Optimal
Solutions</h3>
<p>有三种刻画 corner point 的方法，我们稍后证明它们在 polyhedron
里是等价的。</p>
<ul>
<li><p>Let <span class="math inline">\(P\)</span> be a polyhedron. A
vector <span class="math inline">\(x\in P\)</span> is an <strong>extreme
point</strong> of <span class="math inline">\(P\)</span> if we cannot
find two vectors <span class="math inline">\(y,z \in P\)</span>, both
different from <span class="math inline">\(x\)</span>, and a scalar
<span class="math inline">\(\lambda \in [0,1]\)</span> such that <span class="math inline">\(x = \lambda y + (1-\lambda) z\)</span>.</p></li>
<li><p>Let <span class="math inline">\(P\)</span> be a polyhedron. A
vector <span class="math inline">\(x\in P\)</span> is an
<strong>vertex</strong> of <span class="math inline">\(P\)</span> if
there exists a vector <span class="math inline">\(c \in \mathbb
R^n\)</span> such that <span class="math inline">\(c^T x &lt; c^T
y\)</span> for all <span class="math inline">\(y \in P\)</span> and
<span class="math inline">\(y\neq x\)</span>. (Also holds for &gt; by
taking <span class="math inline">\(-c\)</span>)</p></li>
<li><p>Let <span class="math inline">\(P\)</span> be a polyhedron. A
vector <span class="math inline">\(x\in P\)</span> is an <strong>basic
solution</strong> of <span class="math inline">\(P\)</span> if:</p>
<ul>
<li>All equality constraints holds.</li>
<li>Out of the constraints that are active at <span class="math inline">\(x\)</span>, there are <span class="math inline">\(n\)</span> of them that are linearly
independent.</li>
</ul>
<p>Moreover, if <span class="math inline">\(x\)</span> is a basic
solution that satisfies all the constraints, we say it's a <strong>basic
feasible solution</strong>.</p></li>
</ul>
<p>所以说只要 constraints 的个数是有限的，那么其中选择 <span class="math inline">\(n\)</span> 个 linearly independent
的方法是有限的，basic (feasible) solution 的个数就是有限的。</p>
<p>注意到定义 basic solution 的时候事实上 equality constraints 和
inequality constraints
的地位不等，然而作为一个线性优化问题是可以在这方面有很多等价形式的，事实上
basic solution 会受到 polyhedron 定义形式的影响，具体的例子详见 P49
的平面规划问题。另外，basic feasible solution 不会受到 polyhedron
形式的影响。</p>
<p>最后是有关这三个定义等价性的定理：</p>
<p>Let <span class="math inline">\(P\)</span> be a nonempty polyhedron
and let <span class="math inline">\(x \in P\)</span>, then the following
are equivalent:</p>
<ul>
<li><span class="math inline">\(x\)</span> is an extreme point.</li>
<li><span class="math inline">\(x\)</span> is a vertex.</li>
<li><span class="math inline">\(x\)</span> is a basic feasible
solution.</li>
</ul>
<p><del>证明太长了，这里写不下（</del> 但说实话从 extreme point 推 basic
feasible solution 还不是很显然，要用一点点分析智慧（</p>
<h3 id="algebraic-approach-to-optimal-solutions">Algebraic Approach to
Optimal Solutions</h3>
<p>说了这么多，也把 basic feasible solution
用三种方式刻画出来了，但是对于具体例子的计算还是借助矩阵工具。</p>
<p>有一个 applicable procedure：</p>
<p>For constructing basic solutions for a polyhedron <span class="math inline">\(P= \{x \in \mathbb R^n | Ax = b , x \geq 0
\}\)</span>, use the three-step procedures below:</p>
<ul>
<li><p>Choose <span class="math inline">\(m\)</span> linearly
independent columns <span class="math inline">\(A_{B(1)}, A_{B(2)},
\cdots , A_{B(m)}\)</span> and solve</p>
<p><span class="math display">\[\begin{bmatrix} | &amp; | &amp; \cdots
&amp;| \\ A_{B(1)} &amp; A_{B(2)} &amp; \cdots &amp; A_{B(m)} \\ \cdots
&amp; \cdots &amp;\cdots  &amp; \cdots \\ | &amp; | &amp; \cdots &amp; |
\end{bmatrix} \begin{bmatrix} x_{B(1)} \\ x_{B(2)} \\ \cdots \\
x_{B(m)}  \end{bmatrix} = \begin{bmatrix}b_1 \\ b_2 \\ \cdots \\ b_m
\end{bmatrix}\]</span></p></li>
<li><p>Take <span class="math inline">\(x_i =0\)</span> for <span class="math inline">\(i \neq B(1),B(2), \cdots, B(m)\)</span></p></li>
<li><p>Combine all the components of <span class="math inline">\(x\)</span> and get the basic solution of the base
<span class="math inline">\((A_{B(1)}, A_{B(2)}, \cdots ,
A_{B(m)})\)</span>.</p></li>
</ul>
<p>不同的 base 可以得到不同的 basic solution，也可能会得到相同的。</p>
<p>在解 basic solution 的时候本质上只用到了 <span class="math inline">\(m\)</span> 个 constraint equalities 作为
base，以及 <span class="math inline">\(n-m\)</span> 个 non-negative
constraints，实际上 <span class="math inline">\(x\)</span> 可能不仅在这
<span class="math inline">\(n\)</span> 个 constraints 处
active，如果有多于 <span class="math inline">\(n\)</span> 个 constraints
在 <span class="math inline">\(x\)</span> 处 active 则称它是一个
degenerate basic solution。</p>
<p>很明显的一点是在 polyhedron 里如果一个 basic solution 有多于 <span class="math inline">\(n-m\)</span> 个分量是 <span class="math inline">\(0\)</span>，那么它一定
degenerate。由矩阵解的唯一性，这也是 degenerate basic solution
的唯一情形。</p>
<h3 id="existence-of-vertex">Existence of Vertex</h3>
<p>非常口胡地说，要有 basic feasible solution
至少区域的边界上要先有个角吧（比划</p>
<ul>
<li>A polyhedron <span class="math inline">\(P \subset \Re^n\)</span>
<span class="math inline">\(\textbf{contains a line}\)</span> if there
exists a vector <span class="math inline">\(x \in P\)</span> and a
nonzero vector <span class="math inline">\(d \in \Re^n\)</span> such
that <span class="math inline">\(x + \lambda d \in P\)</span> holds for
all scalar <span class="math inline">\(\lambda\)</span>.</li>
</ul>
<p>也就是说范围里面不能有直线才能有 vertex。</p>
<ul>
<li><p>Suppose that the polyhedron <span class="math inline">\(P = \{x
\in \Re^n \mid \textbf{a}_i^T x \geqslant b_i , i=1,2, \cdots, m
\}\)</span> is nonempty. Then the following is equivalent:</p>
<ul>
<li><p>The polyhedron <span class="math inline">\(P\)</span> has at
least one extreme point.</p></li>
<li><p>The polyhedron does not contain a line.</p></li>
<li><p>There exist <span class="math inline">\(n\)</span> vectors out of
the family <span class="math inline">\(\textbf{a}_1, \textbf{a}_2,
\cdots, \textbf{a}_m\)</span>, which are linearly independent.</p></li>
</ul></li>
</ul>
<p>一个更重要的定理是关于 bounded polyhedron 和 standardized problem
的：</p>
<ul>
<li>Every nonempty bounded polyhedron and every nonempty polyhedron in
standard form has at least one basic feasible solution.</li>
</ul>
<p>这是因为前者显然不含直线，后者定义在 <span class="math inline">\(\{x
\geq 0\}\)</span> 的区域里也不含直线。注意到所有的 LP problem
其实都可以转化为后者的形式，所以说实际上都是有 basic feasible solution
的。这话比较模糊，意思是对于新的 standardized problem 一定会有 basic
feasible solution，然而把这个解限制到原来问题的维度中得到的解未必会是
basic feasible solution。</p>
<p>不过没有关系，我们会在后面看到实际上这已经够用了，因为目的不是解
basic feasible solution，而是找出 optimal cost。在 standardized problem
下的 optimal cost 可以用 basic feasible solution 得到，而它和原问题的
optimal cost 一致。</p>
<h3 id="why-is-vertex-important">Why is Vertex Important?</h3>
<p>说了这么多，为啥要解 basic feasible solution，对做 optimal cost
有什么好处吗？事实上，optimal cost 要么 unbounded，要么是在 basic
feasible solution 处取到，所以说只要 optimal cost 不是 <span class="math inline">\(-\infty\)</span> 就就把所有的 basic feasible
solution 找出来溜一遍就好了。</p>
<p>严肃一点用定理来说明的话是以下几条，对应书上 Section 2.6：</p>
<ul>
<li>Suppose the linear programming problem <span class="math inline">\(P\)</span> has at least one extreme point, and
there exists at least one optimal solution. Then there exist one optimal
solution and is the extreme point of <span class="math inline">\(P\)</span>.</li>
<li>Suppose the linear programming problem <span class="math inline">\(P\)</span> has at least one extreme point. Then,
either the optimal cost is <span class="math inline">\(-\infty\)</span>
or there exist one extreme point, and it's also one of the optimal
solution.</li>
</ul>
<p>注意到任意一个 LP problem 都可以转化为标准形式并保持 cost
不变，每个标准形式都有 extreme point，所以说上一条定理实际上是对任意 LP
problem 成立的。</p>
<p>另外，第一个定理并不能推出第二个，因为并非 optimal cost 不是 <span class="math inline">\(-\infty\)</span> 就能推出有 optimal
solution，比如说在 <span class="math inline">\(x &gt;0\)</span> 上找
<span class="math inline">\(\frac 1x\)</span> 的最小值，既不是 <span class="math inline">\(-\infty\)</span> 也不存在 optimal solution。zjz 的
PPT 还有 yy 讲课的时候都说
trivial，实际上是不能这么推的。但可以通过沿特定方向移动到下一个 basic
feasible solution 的方法证明这种情况在 LP problem
里不会出现，这也就是第二个定理的证明。</p>
<h1 id="lecture-2">Lecture 2</h1>
<p>这节课和 Ruizhe Shi 合作的 scribing 见
https://www.overleaf.com/read/hwpxppmfnjbk。</p>
<p>说实话我觉得 scribing 是写给队友和老师看的罢了，所以当然还要有个
<del>从里面复制然后暴论的</del> 废话版本写给自己看。</p>
<h2 id="simplex-method">Simplex Method</h2>
<p>简单来说 simplex method 是从一个 basic feasible solution
出发，用最简单的计算方法寻找下一个 basic feasible solution
的方法。从几何的角度来说从多边形的一个顶点出发到另一个顶点，当然是沿着中间连接的边走过去最方便，所以也就是在寻找
adjacent basic feasible solution。</p>
<blockquote>
<p>Recap: Two basic solutions are said <strong>adjacent</strong> iff
there are <span class="math inline">\(n-1\)</span> linearly independent
constraints that are active at both of them. We also say that two bases
are adjacent if they share all but one column.</p>
</blockquote>
<p>也就是说，修改 solution vector 中的一对 component 即可。</p>
<h3 id="find-the-initial-solution">Find the Initial Solution</h3>
<p>想开始一个循环的算法得先有个 initial solution
才能开始罢（，为了计算复杂性不如选个最简单的。</p>
<p>在 LP 问题的标准化中经常会有加入一些 artificial variable
来把不等号改成等号的行为，比如说 <span class="math inline">\(a^T x \geq
b\)</span> 完全可以写成 <span class="math inline">\(a_1 x_1 + \cdots +
a_n x_n + y_1 = b\)</span>，里面这个 <span class="math inline">\(y_1\)</span> 就是一个 artificial
variable。它的系数是 <span class="math inline">\(1\)</span>，放在整个矩阵里其实可以作为最简单的
linearly independent column 选出来计算 basic feasible solution。</p>
<p>即使是在标准形式下也可以用这个思路来找一个简单的 initial
solution，考虑：</p>
<p><span class="math display">\[\begin{aligned}
    \text{minimize} \quad &amp; \textbf{c}^T x  \\
    \text{subject to} \quad &amp; \textbf{Ax} = \textbf{b} \\
                     &amp; \textbf{x} \geqslant \textbf{0}
\end{aligned}\]</span></p>
<p>By multiplying some rows of <span class="math inline">\(\textbf{A}\)</span> by <span class="math inline">\(-1\)</span>, we can assume without loss of
generality that <span class="math inline">\(\textbf{b} \geqslant
\textbf{0}\)</span>. We now introduce a vector of artificial variables
<span class="math inline">\(\textbf{y}\)</span> and consider the
auxiliary problem:</p>
<p><span class="math display">\[\begin{aligned}
    \text{minimize} \quad &amp; y_1 + y_2 + \cdots  + y_m \\
    \text{subject to} \quad &amp; \textbf{Ax} + \textbf{y} = b \\
                            &amp; \textbf{x} \geqslant 0 \\
                            &amp; \textbf{y} \geqslant 0
\end{aligned}\]</span></p>
<p>这个 auxiliary problem 的初始化很容易，让 <span class="math inline">\(\textbf {x} =0\)</span> 且 <span class="math inline">\(\textbf {y} = b\)</span> 就是 basic feasible
solution，对应 basis 为 <span class="math inline">\(\textbf {I}_{m
\times m}\)</span>。 某种程度上 auxiliary problem 等同于 original
problem。首先，如果 <span class="math inline">\(\textbf {x}\)</span> 是
original problem 的 basic feasible solution，则将 <span class="math inline">\(\textbf {x}\)</span> 和 <span class="math inline">\(\textbf {y} =0\)</span> 结合起来会产生 auxiliary
problem 的 optimal solution。另一方面，如果能获得 auxiliary problem 的
optimal solution，则根据约束 <span class="math inline">\(\textbf {y}
\geqslant 0\)</span>，它必须满足 <span class="math inline">\(\textbf
{y}=0\)</span>。于是 <span class="math inline">\(\textbf {x}\)</span> 是
original problem 的 basic feasible solution。</p>
<p>另外如果auxiliary problem 的 optimal cost 不是零，那么 original
problem 是 infeasible 的。所以我们可以直接考虑下面的 auxiliary problem
来解 original problem 的 optimal solution，用它简单形式下的 initial
solution 开始 simplex method。</p>
<h3 id="develop-feasible-direction">Develop Feasible Direction</h3>
<p>所谓的 feasible direction 其实就是我们希望“沿着边来移动 solution
point”的那个边。当然移动的时候未必会沿着边来移动，可能就直接按照两个顶点的连线移动，但是怎么说呢，就是个形象点的说法（</p>
<ul>
<li>Let <span class="math inline">\(\textbf{x}\)</span> be an element of
a polyhedron <span class="math inline">\(P\)</span>. A vector <span class="math inline">\(\textbf{d} \in \Re^n\)</span> is said to be a
<strong>feasible direction</strong> at <span class="math inline">\(x\)</span>, if there exists a positive scalar
<span class="math inline">\(\theta\)</span> for which <span class="math inline">\(\textbf{x}+\theta  \textbf{d} \in P\)</span>.</li>
</ul>
<p>在上一次得到的 basic feasible solution 里假设 basis <span class="math inline">\(B\)</span> 的下标是 <span class="math inline">\(B(1),B(2),\cdots, B(m)\)</span>，记 <span class="math inline">\(I = \{B(1) , B(2), \cdots ,
B(m)\}\)</span>。本质上每一次希望的移动就是在 <span class="math inline">\(I^c\)</span> 里面挑选一个新的下标 <span class="math inline">\(j\)</span> 然后将 <span class="math inline">\(x_j\)</span> 变为 <span class="math inline">\(1\)</span>，为了保证 basic feasible solution 的
<span class="math inline">\(n\)</span> 个 active constraints
的条件，还需要再在 <span class="math inline">\(I\)</span>
里面挑选一个下标 <span class="math inline">\(B(i)\)</span> 然后将 <span class="math inline">\(x_{B(i)}\)</span> 变为 <span class="math inline">\(0\)</span>。</p>
<p>从 applicable 的角度来说，具体的计算步骤是：</p>
<ul>
<li>选择一个 <span class="math inline">\(I^c\)</span> 中的 <span class="math inline">\(j\)</span> 作为新的下标，计算 <span class="math inline">\(B^{-1}A_j\)</span> 作为 <span class="math inline">\(d_{B(1)}, d_{B(2)}, \cdots, d_{B(m)}\)</span>
的值，记 <span class="math inline">\(d_j=1\)</span>，其余的分量保持
<span class="math inline">\(0\)</span>。</li>
<li>寻找一个合适的 <span class="math inline">\(\theta\)</span> 使得
<span class="math inline">\(x +\theta d\)</span> 是一个最合适的 basic
feasible solution</li>
</ul>
<p>实际上如果确定了 <span class="math inline">\(j\)</span>，这里的 <span class="math inline">\(\theta\)</span>
的选择范围就是有限的了，只有对于小于 <span class="math inline">\(0\)</span> 的 <span class="math inline">\(d_{B(i)}\)</span> 才能作为移动到 <span class="math inline">\(0\)</span> 的方向。</p>
<p><span class="math display">\[\begin{aligned}
      \theta =\left(-\frac{x_{B(i)}}{d_{B(i)}}\right), \;
\{i=1,\ldots,m,d_{B(i)}&lt;0\}
  \end{aligned}\]</span></p>
<p>然而其实连 <span class="math inline">\(j\)</span>
都没确定呢，一开始是随便取的，嘿嘿。所以下面要考虑怎么选择 <span class="math inline">\(j\)</span>，其后怎么选择 <span class="math inline">\(\theta\)</span>，或者两个其实也可以一起选就是了，但是计算复杂度可能又会提高。</p>
<h3 id="choice-of-adjacent-basic-feasible-solution">Choice of Adjacent
Basic Feasible Solution</h3>
<p>Feasible direction
确认了之后就要考虑到底按照哪个下标来移动，最朴素的想法是突然想起来这是个优化问题（，然后按照单次移动的
cost 相关的问题来考虑。</p>
<ul>
<li><p>Let <span class="math inline">\(\textbf{x}\)</span> be a basic
solution, let <span class="math inline">\(\textbf{B}\)</span> be an
associated basis matrix, and let <span class="math inline">\(\textbf{c}_B\)</span> be the vector of costs of
the basic variables. For each <span class="math inline">\(j\)</span>, we
define the <strong>reduced cost</strong> <span class="math inline">\(\bar c_j\)</span> of the variables <span class="math inline">\(x_j\)</span> according to the formula</p>
<p><span class="math display">\[\begin{aligned}
    \bar c_j=c_j-\textbf{c}_B \textbf{B}^{-1}\textbf{A}_j.
  \end{aligned}\]</span></p></li>
</ul>
<p>这样定义了一个关于各个 <span class="math inline">\(j\)</span>
对应的单位 reduced cost，也就是 <span class="math inline">\(x_j\)</span>
每增加 <span class="math inline">\(1\)</span> 会导致 cost
减少的量，当然是减得越多越好。另外 <span class="math inline">\(\bar
c_j\)</span> 在 <span class="math inline">\(j\)</span> 取 <span class="math inline">\(I\)</span> 中的下标时等于 <span class="math inline">\(0\)</span>，这其实很能 make sense，毕竟不能再按照
<span class="math inline">\(B(i)\)</span> 来作为加入 basis
的下标了，会导致的 cost 变化也只能是 <span class="math inline">\(0\)</span>。所以 reduced cost 是一个 general
definition，可以再用它们来定义一个向量 <span class="math inline">\(\bar
c\)</span>，其各个分量就是 reduced cost。</p>
<p>寻找下一个 basic feasible solution
的最好的选择就是找一个绝对值最大（实际上最小）的 <span class="math inline">\(\bar c_j\)</span>，沿着这个方向移动最大的一个
<span class="math inline">\(\theta^*&gt;0\)</span>，然后 cost 就减少了
<span class="math inline">\(\theta^* \bar c_j\)</span>。这样选择 <span class="math inline">\(\bar c_j\)</span> 和对应的下标 <span class="math inline">\(j\)</span> 从直觉上来说可以经历更少的步数到达
optimal solution，降低算法复杂度。</p>
<p>另外，也可以从某个点处的 reduced cost vector <span class="math inline">\(\bar c\)</span>
看出一些东西，主要有关这个点有没有达到 optimal cost，等等。</p>
<ul>
<li>Consider a basic feasible solution <span class="math inline">\(x\)</span> associated with a basis matrix <span class="math inline">\(B\)</span>, and let <span class="math inline">\(\bar c\)</span> be the corresponding vector of
reduced costs.
<ul>
<li>If <span class="math inline">\(\bar c \geq 0\)</span>, then <span class="math inline">\(x\)</span> is optimal.</li>
<li>If <span class="math inline">\(x\)</span> is optimal and
nondegenerate, then <span class="math inline">\(\bar c \geq
0\)</span>.</li>
</ul></li>
<li>A basis matrix <span class="math inline">\(B\)</span> is optimal iff
<ul>
<li><span class="math inline">\(B^{-1}b \geq 0\)</span></li>
<li><span class="math inline">\(\bar c^T = c^T - c^T _B B^{-1} A \geq
0^T\)</span></li>
</ul></li>
</ul>
<h3 id="termination">Termination</h3>
<p>最后两个问题是：算法会不会进入循环？会不会找不到 optimal solution
就停下来？答案是都不会。</p>
<p>因为只有有限个 basic feasible
solution，所以只要不经过同一个点两遍，就可以遍历所有的可能性。不经过同一个点两遍这件事通过
lexicographic pivoting rule
来决定，保证从字典序上来说所有的解是递增的，就不会出现循环。</p>
<p>另外既然 optimal solution 要么是 <span class="math inline">\(-\infty\)</span> 要么是在某个 basic feasible
solution 处取到，那么既然遍历（注意并不是真正的遍历，并不会走到 cost
比较大的一些 basic feasible solution，比如说比 initial solution 的 cost
更大的解就不可能取到，这能提高效率且不遗漏）了 basic feasible solution
就一定能找到 optimal solution，所以说 simplex method
是个非常完满的算法。</p>
<h3 id="summary">Summary</h3>
<p>最后总结一下 simplex method 的步骤。</p>
<ul>
<li>通过解 auxiliary problem 找到一个本质 trivial 的 initial
solution；它可能不存在，此时原问题 infeasible；</li>
<li>通过做 <span class="math inline">\(\bar c^T = c^T - c^T_B
B^{-1}A\)</span> 得到在此处的 reduced cost vector，
<ul>
<li>如果 <span class="math inline">\(\bar c \geq
0\)</span>，说明目前的解就是 optimal solution</li>
<li>否则找出绝对值最大的 <span class="math inline">\(\bar
c_j\)</span>，确定下标 <span class="math inline">\(j\)</span>，再找出对应的 feasible direction 是
<span class="math inline">\(d_B = -B^{-1}A, d_j=1\)</span>.</li>
</ul></li>
<li>通过找 <span class="math inline">\(\theta^* = \max \{\theta \geq 0
\mid x +\theta d \in P \}\)</span> 来更新 basic feasible solution 为
<span class="math inline">\(y = x+\theta d\)</span>，可能遇到：
<ul>
<li>如果 <span class="math inline">\(\theta\)</span> unbounded，则
optimal cost 也是 <span class="math inline">\(-\infty\)</span>；</li>
<li>否则可以更新 optimal cost 和对应的 basic feasible
solution，然后重复以上步骤直到找到 optimal solution。</li>
</ul></li>
</ul>
<h2 id="introduction-to-duality">Introduction to Duality</h2>
<p>把 LP problem 变成它的 dual problem 的 motivation
其实来自拉格朗日乘子法，本质上是对 cost function 的形式 penalize
一个条件，如果不满足条件的话 cost function
就会变大，从而找到最小值。</p>
<p><del>想必这个过程推起来很简单吧我就不写了</del></p>
<p>简单来说，primal problem 和 dual problem 的对应关系是这样的：</p>
<p><span class="math display">\[\begin{aligned} \text{minimize}
\quad  &amp; c^T x \\ \text{subject to} \quad &amp; a_i ^T x \geq b
\quad  i \in M_1 \\ &amp; a_i ^T x \leq b_i \quad  i \in M_2  \\ &amp;
a_i ^T x = b_i \quad  i \in M_3  \\ &amp; x_j  \geq 0 \quad  j \in
N_1  \\ &amp; x_j  \leq 0 \quad  j \in N_2  \\ &amp; x_j \; \text{free}
\quad  j \in N_3   \end{aligned} \quad \quad \quad \begin{aligned}
\text{maximize} \quad  &amp; p^T b \\ \text{subject to} \quad &amp;
p_i  \geq 0 \quad  i \in M_1 \\ &amp; p_i \leq 0 \quad  i \in M_2  \\
&amp; p_i \; \text{free} \quad  i \in M_3  \\ &amp; p^TA_j \leq c_j
\quad  j \in N_1  \\ &amp; p^TA_j  \geq c_j \quad  j \in N_2  \\ &amp;
p^TA_j = c_j \quad  j \in N_3   \end{aligned}\]</span></p>
<p>可以看出来 dual 的 dual 就是 primal。</p>
<p>除此之外还需要一些定理来说明 dual 和 primal 的 cost 之间的关系。</p>
<h3 id="duality-theorems">Duality Theorems</h3>
<ul>
<li><p>(Weak Duality) If <span class="math inline">\(x\)</span> is a
feasible solution to the primal problem and <span class="math inline">\(p\)</span> is a feasible solution to the dual
problem, then <span class="math inline">\(p^Tb\leqslant
c^Tx\)</span>.</p>
<p><strong>Proof</strong>: Set <span class="math inline">\(u_i = p_i
(a_i^Tx - b_i), v_j = (c_j - p^TA_j) x_j\)</span>, then by feasibility
<span class="math inline">\(u_i \geq 0, v_i \geq 0\)</span>.</p>
<p>Therefore <span class="math inline">\(\sum_{i,j}u_i +v_j = p^T(Ax-b)
+ (c^T- p^TA)x = c^Tx - p^Tb \geq 0\)</span>.</p>
<ul>
<li>If the optimal cost in the primal is <span class="math inline">\(-\infty\)</span>, then the dual one must be
infeasible.</li>
<li>If the optimal cost in the dual is <span class="math inline">\(+\infty\)</span>, then the primal one must be
infeasible.</li>
<li>Let <span class="math inline">\(x\)</span> and <span class="math inline">\(p\)</span> be feasible solutions to the primal and
the dual problem respectively, and suppose that <span class="math inline">\(p^T b = c^Tx\)</span> holds. Then <span class="math inline">\(x\)</span> and <span class="math inline">\(p\)</span> are optimal solutions to the primal and
the dual respectively.</li>
</ul></li>
</ul>
<p>Weak duality 引出的第三条最重要，如果 <span class="math inline">\(x\)</span> 不是 optimal solution 则对任意的
feasible solution <span class="math inline">\(x&#39;\)</span> 都有 <span class="math inline">\(c^Tx&#39; \geq p^Tb =
c^Tx\)</span>，导致矛盾，<span class="math inline">\(p\)</span> 的
optimality 同理。这说明了 <span class="math inline">\(c^Tx =
p^Tb\)</span> 可以导出二者分别在此处取到 optimal
cost，这引出了更重要的一条 strong duality，保证其一有 optimal solution
的时候另一个也有。</p>
<ul>
<li><p>(Strong Duality) If a linear programming problem has an optimal
solution, so does its dual, and the respective optimal costs are
equal.</p>
<p><strong>Proof</strong>: Consider the problem in standard form. The
simplex method (with lexicographic pivoting rule) terminates with an
optimal solution <span class="math inline">\(x^*\)</span> and an optimal
basis <span class="math inline">\(B\)</span>, then <span class="math display">\[\begin{aligned}
    \bar c^T=c^T-c_B^TB^{-1}A\geqslant0.
\end{aligned}\]</span></p>
<p>Let <span class="math inline">\(p^*=(c_B^T B^{-1})^T\)</span> as the
corresponding optimal solution <span class="math inline">\(p\)</span>,
then <span class="math display">\[\begin{aligned}
    (p^*)^TA=c_B^T B^{-1}A\leqslant c^T,
\end{aligned}\]</span> and <span class="math display">\[\begin{aligned}
(p^*)^Tb=c_B^TB^{-1}b=c_B^Tx_B=c^Tx^*.
\end{aligned}\]</span> So the strong duality holds.</p></li>
</ul>
<p>最后来个 Farka's lemma，把 constraints
作为一个矩阵从原来的优化问题里面抽出来看：</p>
<ul>
<li>(Farka's lemma) Let <span class="math inline">\(A\)</span> be a
matrix of dimensions <span class="math inline">\(m\times n\)</span> and
let <span class="math inline">\(b\)</span> be a vector in <span class="math inline">\(\Re ^m\)</span>. Then exactly one of the following
two alternative holds:
<ul>
<li>There exists some <span class="math inline">\(x\geqslant 0\)</span>
such that <span class="math inline">\(Ax=b\)</span>.</li>
<li>There exists some vector <span class="math inline">\(p\)</span> such
that <span class="math inline">\(p^TA\geqslant 0\)</span> and <span class="math inline">\(p^Tb&lt;0\)</span>.</li>
</ul></li>
<li>(Farka's corollary) Let <span class="math inline">\(A_1,\ldots,A_n\)</span> and <span class="math inline">\(b\)</span> be given vectors and suppose that any
vector <span class="math inline">\(p\)</span> that satisfies <span class="math inline">\(p^TA_i\geqslant 0\)</span>, <span class="math inline">\(i=1,\ldots,n\)</span>, must also satisfy <span class="math inline">\(p^Tb\geqslant 0\)</span>. Then <span class="math inline">\(b\)</span> can be expressed as a nonnegative
linear combination of the vectors <span class="math inline">\(A_1,\ldots, A_n\)</span>.</li>
</ul>
<p>就变成了很普通但是又看着有点奇怪的矩阵变换问题，谁知道背后还有个优化问题.jpg。事实上对于不同形式的
primal 和 dual problem
我们都可以写出来一对相反的条件，让它们二者成立其一。</p>
<h1 id="lecture-3">Lecture 3</h1>
<p>在上这节课之前我把 HW2 写完了，相应地其实就把 Nash equilibrium
那道题做了。是周二晚上吃饭之前写完的，吃饭之前多花了五分钟写成 LaTeX
然后超级开心地离开四教，吃完回来又读了一遍感觉证得很好，真的很喜欢这个方法还有这整个问题。</p>
<p>所以我还是忍不住在 acknowledge 里面写了 MashPlant 日记里那段话：</p>
<blockquote>
<p>All exercises but Ex 4.29 are finished on my own. Among them I
appreciate the solution of Ex 4.10 most (though trivial), as this is
actually quite a triumph, even if it's hard to explain to your friends
or family members.</p>
</blockquote>
<p><del>好了现在大家都知道我不会做 Ex 4.29 了</del></p>
<p>然后 Lecture 3
上又把这个问题拿出来讲了，顺便把这个作业题也证明了，有点不爽（（x</p>
<h2 id="nash-equilibrium">Nash Equilibrium</h2>
<p>先把 theorem 丢出来，然后写一个我的证明：</p>
<h3 id="theory">Theory</h3>
<p><strong>Ex 4.10</strong></p>
<p>Consider the standard form problem of minimizing <span class="math inline">\(c^Tx\)</span> subject to <span class="math inline">\(Ax = b, x \geq 0\)</span>. We define the
Lagrangean by</p>
<p><span class="math display">\[L(x,p) = c^Tx + p^T(b-Ax)\]</span></p>
<p>Consider the following game: player 1 chooses some <span class="math inline">\(x \geq 0\)</span>, and player 2 chooses some <span class="math inline">\(p\)</span>; then, player 1 pays to player 2 the
amount <span class="math inline">\(L(x,p)\)</span>. Player 1 would like
to minimize <span class="math inline">\(L(x,p)\)</span>, while player 2
would like to maximize it.</p>
<p>A pair <span class="math inline">\((x^*,p^*)\)</span> with <span class="math inline">\(x^* \geq 0\)</span>, is called an equilibrium
point if <span class="math inline">\(L(x^*,p) \leq L(x^*,p^*) \leq
L(x,p^*), \; \forall x \geq 0, \forall p\)</span>.</p>
<p>(Thus, we have an equilibrium if no player is able to prove her
performance by unilaterally modifying her choice.)</p>
<p>Show that a pair (<span class="math inline">\(x^*,p^*\)</span>) is an
equilibrium if and only if <span class="math inline">\(x^*\)</span> and
<span class="math inline">\(p^*\)</span> are optimal solutions to the
standard form problem under consideration and its dual respectively.</p>
<p><strong>Proof</strong>:</p>
<p>Consider the primal problem and the dual problem in the following
form:</p>
<p><span class="math display">\[\begin{aligned}
    \textbf{minimize} \quad &amp; c^Tx \\
    \textbf{subject to} \quad &amp; Ax = b \\
    &amp; x \geq 0
\end{aligned} \quad \quad \quad
\begin{aligned}
    \textbf{maximize} \quad &amp; p^Tb \\
    \textbf{subject to} \quad &amp; A^T b \leq c \\
    \\
\end{aligned}\]</span></p>
<ol type="1">
<li>If <span class="math inline">\(x^*\)</span> and <span class="math inline">\(p^*\)</span> are optimal solutions to the primal
problem and the dual problem respectively, then there is:</li>
</ol>
<p><span class="math display">\[L(x^*, p) = c^Tx^* + p^T(b -Ax^*) =
c^Tx^* = L(x^*, p^*)\]</span></p>
<p><span class="math display">\[L(x,p^*) = c^Tx + p^{*T} (b-Ax) = (c^T -
p^{*T} A)x + p^{*T} b \geq p^{*T} b = c^Tx^*\]</span></p>
<p>according to the strong duality theorem.</p>
<p>Therefore <span class="math inline">\(L(x^*,p) \leq L(x^*,p^*) \leq
L(x,p^*)\)</span> holds, and <span class="math inline">\((x^*,p^*)\)</span> is an equilibrium.</p>
<ol start="2" type="1">
<li>If <span class="math inline">\((x^*,p^*)\)</span> is an equilibrium,
first to prove that <span class="math inline">\(x^*\)</span> is a
feasible solution to the primal problem. Consider the first inequality
<span class="math inline">\(L(x^*, p ) \leq L(x^*, p^*)\)</span> which
holds for any <span class="math inline">\(p\)</span>. If <span class="math inline">\(b - Ax^* \neq 0\)</span>, by taking <span class="math inline">\(p = b - Ax^* +p^*\)</span>, we can obtain</li>
</ol>
<p><span class="math display">\[L(x^*,p) - L(x^*, p^*) = (p-
p^*)^T(b-Ax^*) = (b-Ax^*)(b-Ax^*) &gt;0,\]</span></p>
<p>which leads to contradiction. Therefore <span class="math inline">\(Ax^* = b\)</span> holds, <span class="math inline">\(x^*\)</span> is a feasible solution to the primal
problem and <span class="math inline">\(L(x^*, p^*) = c^T
x^*\)</span>.</p>
<p>Next step we prove that <span class="math inline">\(p^*\)</span> is a
feasible solution to the dual problem. Consider the second inequality
<span class="math inline">\(c^T x^* = L(x^*,p^*) \leq L(x, p^*)\)</span>
which holds for any <span class="math inline">\(x \geq 0\)</span>. By
taking <span class="math inline">\(x =0\)</span> we can obtain that
<span class="math inline">\(c^T x^* \leq L(0,p^*) = p^{*T}b\)</span>
holds.</p>
<p>Moreover, if there exists <span class="math inline">\(i\)</span> s.t.
<span class="math inline">\(c_i - p^T A_i &lt;0\)</span>, we can take
<span class="math inline">\(x_i = -\frac{p^{*T}b - c^Tx^*}{c_i - p^{*T}
A_i} +1\)</span> and <span class="math inline">\(x_j =0\)</span> for all
<span class="math inline">\(j \neq i\)</span>, then <span class="math inline">\(x \geq 0\)</span>. Take such <span class="math inline">\(x\)</span> to the inequality and there is:</p>
<p><span class="math display">\[c^Tx^* = L(x^*,p^*) \leq L(x,p^*) =
p^{*T} b + (c_i - p^{*T} A_i) x_i &lt;  p^{*T} b  - (p^{*T}b - c^Tx^*) =
c^Tx^* ,\]</span></p>
<p>which leads to contradiction. Thus <span class="math inline">\(c_i -
p^{*T} A_i \geq 0\)</span> holds for any subscript <span class="math inline">\(i\)</span>, i.e. <span class="math inline">\(c -
p^{*T}A \geq 0\)</span>. Therefore <span class="math inline">\(p^*\)</span> is a feasible solution to the dual
problem.</p>
<p>According to the inequality <span class="math inline">\(c^T x^* \leq
p^{*T}b\)</span> we obtained before and the weak duality theorem, there
is <span class="math inline">\(c^T x^* = p^{*T} b\)</span>, and
therefore <span class="math inline">\(x^*, p^*\)</span> are optimal
solutions to the primal problem and the dual problem respectively.</p>
<h3 id="application">Application</h3>
<p>其实已经挺清楚的了，就是说 <span class="math inline">\(\max_p \min_x
L(x,p) = \min_x \max_p L(x,p)\)</span> 这样子，所以说 dual 和 primal
得到的结果是一致的。</p>
<h3 id="application-of-farkas-lemma">Application of Farka's Lemma</h3>
<p>先回顾下 Farka's lemma：</p>
<p>(Farka's lemma) Let <span class="math inline">\(A\)</span> be a
matrix of dimensions <span class="math inline">\(m\times n\)</span> and
let <span class="math inline">\(b\)</span> be a vector in <span class="math inline">\(\Re ^m\)</span>. Then exactly one of the following
two alternative holds:</p>
<ul>
<li>There exists some <span class="math inline">\(x\geqslant 0\)</span>
such that <span class="math inline">\(Ax=b\)</span>.</li>
<li>There exists some vector <span class="math inline">\(p\)</span> such
that <span class="math inline">\(p^TA\geqslant 0\)</span> and <span class="math inline">\(p^Tb&lt;0\)</span>.</li>
</ul>
<p>除了用一对 primal problem 和 dual problem
记这个结论之外，还可以用一个图来直观地理解：</p>
<p><img src="https://s2.loli.net/2023/10/21/AzN5LGkDotKBbFh.png" alt="farka.png"></p>
<p>当 <span class="math inline">\(b\)</span> 不落在 <span class="math inline">\(A_i\)</span> 和 <span class="math inline">\(x \geq
0\)</span>
构造出的阴影范围内，也就是说第一个条件不满足的时候，就一定存在 <span class="math inline">\(p\)</span> 使得 <span class="math inline">\(p\)</span> 和 <span class="math inline">\(b\)</span> 的夹角是“钝角”，而且 <span class="math inline">\(p\)</span> 和每个 <span class="math inline">\(A_i\)</span> 的夹角是“锐角”。</p>
<p>考虑一个有 <span class="math inline">\(n\)</span>
种商品的贸易过程，每次购买的份额是一个 asset vector <span class="math inline">\(x =
(x_1,x_2,...,x_n)\)</span>，初始状态下的价格是一个 price vector <span class="math inline">\(p =
(p_1,p_2,...,p_n)\)</span>，因此初始状态下投入的资金是 <span class="math inline">\(p^Tx\)</span>。一段时间后会呈现出 <span class="math inline">\(m\)</span> 种状态之一，第 <span class="math inline">\(i\)</span> 种状态下这 <span class="math inline">\(n\)</span> 种商品的售价是一个 payoff vector <span class="math inline">\((r_{i1},r_{i2},...,r_{in})\)</span>。由此构造一个
payoff matrix：</p>
<p><span class="math display">\[R= \begin{bmatrix} r_{11} &amp; r_{12}
&amp; \cdots &amp; r_{1n} \\ \cdots &amp; \cdots &amp; \cdots &amp;
\cdots \\\cdots &amp; \cdots &amp; \cdots &amp; \cdots \\ r_{m1} &amp;
r_{m2} &amp; \cdots &amp;  r_{mn} \end{bmatrix}\]</span></p>
<p>取 <span class="math inline">\(w = Rx = (w_1,w_2,\cdots,w_m)\)</span>
作为购买份额为 <span class="math inline">\(x\)</span> 时，最终在 <span class="math inline">\(m\)</span> 个状态下分别得到的收入。有一个 absence
of arbitrage
condition，大概就是说不可能在负投资的状态下得到正收益，也就是说 <span class="math inline">\(Rx \geq 0\)</span> 可以推出 <span class="math inline">\(p^Tx \geq 0\)</span>。</p>
<p>由 Farka's lemma 可知此时第二条不成立，一定存在 <span class="math inline">\(q \geq 0\)</span> 使得 <span class="math inline">\(R ^T q = p\)</span>。</p>
<h2 id="the-center-of-gravity-method">The Center of Gravity Method</h2>
<p>实际上就是一个不断切割已有的 polyhedron 来找到 optimal solution
的过程。简单来说从初始状态开始，每个状态下手里有一个多边形 <span class="math inline">\(S_t\)</span>（feasible set 的 subset）和它的质心
<span class="math inline">\(x_t\)</span>，然后把使得取值大于 <span class="math inline">\(c^Tx_t\)</span> 的部分切掉，也就是取 <span class="math inline">\(S_t\)</span> 和 hyperapce <span class="math inline">\(\{x \in \mathbb R^n \mid c^T(x-x^T) &gt; 0
\}\)</span> 的交这一部分作为不可能取到 optimal cost
的区域，余下的部分是下一状态的多边形 <span class="math inline">\(S_{t+1}\)</span> 和相应的质心 <span class="math inline">\(x_{t+1}\)</span>，由此按照所需的精度来逼近 optimal
cost。</p>
<p>写成算法的步骤来说也非常简单，实际上每次就操作两步。先取整个 feasible
set 作为 <span class="math inline">\(S_1\)</span>，然后：</p>
<ol type="1">
<li>Take <span class="math inline">\(x_t = \frac{1}{Vol(S_t)} \int_{x
\in S_t} x \; dx\)</span> as the center of gravity of the polyhedron
<span class="math inline">\(S_t\)</span>;</li>
<li>Take <span class="math inline">\(S_{t+1} = S_t \cap \{x \mid
c^T(x-x_t) \leq 0 \}\)</span> as the new polyhedron.</li>
</ol>
<p>一直重复直到 <span class="math inline">\(S_t\)</span> 足够小，此时
<span class="math inline">\(c^T x_t\)</span> 和 optimal cost <span class="math inline">\(c^Tx^*\)</span>
的误差也会足够小。这由一些定理保证。</p>
<ul>
<li><p>Let <span class="math inline">\(K\)</span> be a centered convex
set (i.e. <span class="math inline">\(\int_{x \in K} xdx=0\)</span>),
then for any <span class="math inline">\(w \in \mathbb R^n\)</span>,
<span class="math inline">\(w \neq 0\)</span>, one has</p>
<p><span class="math display">\[Vol(\mathcal K \cap \{x \in \mathbb R^n
: x^T w \geq 0\}) \geq \frac 1 e Vol(\mathcal K)\]</span></p></li>
</ul>
<p>这告诉我们每个新的多边形和原多边形之间有一个体积关系是 <span class="math inline">\(Vol(S_{t+1}) \leq (1-\frac 1 e) Vol(S_t) \leq
\cdots \leq (1-\frac 1 e)^t Vol(S_1)\)</span>，再对于 <span class="math inline">\(\varepsilon = (1-\frac 1 e)^{t/n}\)</span> 取
<span class="math inline">\(\mathcal S_\varepsilon = \{(1-\varepsilon
)x^* + \varepsilon x, \forall x \in S_1\}\)</span>，实际上是对 <span class="math inline">\(S_1\)</span> 做了一个仿射变换。此时有 <span class="math inline">\(Vol(S_\varepsilon)=\varepsilon^n Vol(S_1) =
(1-\frac 1 e)^tVol(S_1) \geq Vol(S_{t+1})\)</span>，于是可以找到一个
<span class="math inline">\(x_\varepsilon \in S_\varepsilon\)</span>
使其在 <span class="math inline">\(t\)</span> 时刻时仍在 <span class="math inline">\(S_t\)</span> 中，而 <span class="math inline">\(t+1\)</span> 时刻就被“裁剪”了出去。</p>
<p>所以有</p>
<p><span class="math display">\[c^Tx_{t+1} &lt; c^Tx_\varepsilon =
c^T((1-\varepsilon)x^*+ \varepsilon x) \leq c^Tx^* + 2B\varepsilon
=c^Tx^*+2B(1-\frac 1 e)^{t/n}\]</span></p>
<p>也就是说 <span class="math inline">\(c^Tx_{t+1} - c^Tx^* &lt;
2B(1-\frac 1 e)^{t/n}\)</span> 作为 <span class="math inline">\(t+1\)</span> 时刻下取值距离 optimal cost
的误差可以被控制，并且我们可以在 <span class="math inline">\(O(n
\log(\frac{1}{\varepsilon}))\)</span> 时间下得到误差为 <span class="math inline">\(\varepsilon\)</span> 的 cost 和 solution。这比
simplex method 误差大一些，但是 polynomial time algorithm。</p>
<h2 id="the-ellipsoid-method">The Ellipsoid Method</h2>
<p><del>讲这个的时候我太困了，上楼找了个教室睡觉，没听。我估计我困成那样听也听不懂，他这个手稿太抽象了也看不大懂，貌似书上也没这一部分，哥们有点子崩溃（。等
scribing 了。</del></p>
<p>我都学会了 scribing 还没出来，自己写一个吧。</p>
<h3 id="notations-1">Notations</h3>
<p>首先是一些记号：</p>
<p><img src="https://s2.loli.net/2023/09/26/PEzuQl2MOW37Jr1.jpg" alt="mi1.jpg"></p>
<ul>
<li><p>A set <span class="math inline">\(E\)</span> of vectors in <span class="math inline">\(\mathbb R^N\)</span> of the form <span class="math inline">\(E = E(z,D) = \{x \in \mathbb R^n \mid (x- z)^T
D^{-1} (x-z) \leq1 \}\)</span>, where <span class="math inline">\(D\)</span> is an <span class="math inline">\(n
\times n\)</span> positive definite symmetric matrix, is called an
ellipsoid with center <span class="math inline">\(z \in \mathbb
R^n\)</span>.</p></li>
<li><p>If <span class="math inline">\(D\)</span> is a <span class="math inline">\(n \times n\)</span> nonsingular matrix and <span class="math inline">\(b \in \mathbb R^n\)</span>, then the mapping <span class="math inline">\(S: \mathbb R^n \to \mathbb R^n\)</span> defined by
<span class="math inline">\(S(x) = Dx + b\)</span>, is called an affine
transformation.</p></li>
</ul>
<p>注意到仿射变换都是可逆的，所以可以把仿射变换的像定义成</p>
<ul>
<li><span class="math inline">\(S(L) = \{y \in \mathbb R^n \mid y = Dx
+b, \text{for some } x\in L \}\)</span></li>
<li>The volume of a set <span class="math inline">\(L \in \mathbb
R^n\)</span>, which is denoted by <span class="math inline">\(Vol(L)\)</span>, is defined as <span class="math inline">\(Vol(L) = \int_{x \in L}dx\)</span></li>
</ul>
<p>然后就可以得到仿射变换后的体积是</p>
<ul>
<li><p>If <span class="math inline">\(S(x) = Dx + b\)</span> then <span class="math inline">\(Vol(S(L)) = |det(D)| Vol(L)\)</span></p>
<p><strong>Proof</strong>: <span class="math inline">\(Vol(S(L)) =
\int_{y \in S(L)} dy = \int_{x \in L} |det(D)| dx = |det(D)|
Vol(L)\)</span></p></li>
</ul>
<h3 id="algorithm">Algorithm</h3>
<p>目标是考虑一个 <span class="math inline">\(Ax \geq b\)</span>
形式的优化问题的 feasible set，也就是一个 polyhedron <span class="math inline">\(P\)</span> 是否是空集的问题，可以用一个 Ellipsoid
Algorithm
来解决。既然是用迭代算法解决，其实就不能太苛求精细程度，我们约定最后得到的覆盖椭圆的面积小于
<span class="math inline">\(\varepsilon\)</span> 时就认为 <span class="math inline">\(P\)</span> 是一个空集。</p>
<p>首先考虑一个覆盖所求 polyhedron <span class="math inline">\(P\)</span> 的椭圆 <span class="math inline">\(E_t\)</span>，如果其中心 <span class="math inline">\(x_t \in P\)</span> 则找到了一个 <span class="math inline">\(P\)</span> 中的解，可以得出 <span class="math inline">\(P\)</span> 是非空的；如果 <span class="math inline">\(x_t \notin P\)</span> 那么 <span class="math inline">\(x_t\)</span> 一定违反了其中的某个 constraint <span class="math inline">\(a_i ^Tx \geq b_i\)</span>，<span class="math inline">\(P\)</span> 一定在 halfspace <span class="math inline">\(\{x \in \mathbb R^n \mid a_i^T x \geq a_i^Tx_t
\}\)</span> 和 <span class="math inline">\(E_t\)</span>
的交集里，这样我们再做一个新的更小的椭圆 <span class="math inline">\(E_{t+1}\)</span>
来覆盖这一部分，就可以继续这一算法。</p>
<p>来个我非常喜欢的图！</p>
<p><img src="https://s2.loli.net/2023/10/21/Y79yhqJDgElijmI.png" alt="ellipsoid_method.png"></p>
<p>现在需要解决的问题仍然是 termination 问题，也就是是否 <span class="math inline">\(E_{t+1}\)</span> 的体积一定比 <span class="math inline">\(E_t\)</span>
更小。以下定理保证了它们的体积之间一定有一个指数级的减少：</p>
<ul>
<li><p>Let <span class="math inline">\(E = E(z,D)\)</span> be an
ellipsoid in <span class="math inline">\(\mathbb R^n\)</span>, and let
<span class="math inline">\(a\)</span> be a nonzero vector. Consider the
halfspace <span class="math inline">\(H = \{x \in \mathbb R ^n \mid a^Tx
\geq a^T z \}\)</span> and let</p>
<p><span class="math display">\[\bar z = z +
\frac{1}{n+1}  \frac{Da}{\sqrt{a^TDa}}\]</span></p>
<p><span class="math display">\[\bar D = \frac{n^2}{n^2-1} (D -
\frac{2}{n+1} \frac{Daa^TD}{a^TDa})\]</span></p>
<p>Then <span class="math inline">\(\bar D\)</span> is positive definite
and the new ellipsoid <span class="math inline">\(\bar E = E(\bar z,
\bar D)\)</span> satisfies the following properties:</p>
<ul>
<li><span class="math inline">\(E \cap H \subset \bar E\)</span></li>
<li><span class="math inline">\(Vol(\bar E) &lt; e^{-1/(2(n+1))}
Vol(E)\)</span></li>
</ul>
<p><strong>Proof</strong>: First consider <span class="math inline">\(a
= e_1. D = I_{n \times n}\)</span> and the center of <span class="math inline">\(E_0\)</span> as <span class="math inline">\(z =
0\)</span>. It's trivial to see that the first property holds. In this
case the positive definite matrix of <span class="math inline">\(\bar
E_0\)</span> is <span class="math inline">\(D = diag((\frac{n}{n+1})^2,
\frac{n^2}{n^2-1}, \cdots,\frac{n^2}{n^2-1})\)</span>, and the center is
<span class="math inline">\(a =
(\frac{1}{n+1},0,\cdots,0)^T\)</span>.</p>
<p>Now by constructing an affine transformation we can consider the
general case. The transformation T should let <span class="math inline">\(T(E) = E_0, T(H) = H_0\)</span> and <span class="math inline">\(T(\bar E) = \bar E_0\)</span>. By some elementary
observations we can obtain that affine transformations preserve set
inclusion, i.e. if <span class="math inline">\(E_0 \cap H_0 \subset \bar
E_0\)</span>, then there is <span class="math inline">\(T(E_0) \cap
T(H_0) \subset T(\bar E_0)\)</span>, therefore the first property holds
naturally.</p>
<p>Let <span class="math inline">\(R\)</span> be the rotation matrix
corresponding to the vector <span class="math inline">\(u = D^{\frac 1
2} a\)</span>, i.e.,</p>
<p><span class="math display">\[R^TR = I, \quad RD^{\frac 1 2}a_i =
\|D^{\frac 1 2} a_i \| e_1\]</span></p>
<p>Consider the following affine transformation:</p>
<p><span class="math display">\[T(x) = R(D^{-\frac 1
2}(x-z))\]</span></p>
<p>Therefore,</p>
<p><span class="math inline">\(\begin{aligned} x \in E &amp; \iff
(x-z)^TD^{-1}(x-z)\leq 1 \\ &amp; \iff (x-z)^TD^{-\frac 1
2}R^TRD^{-\frac 1 2}(x-z)\leq 1 \\ &amp; \iff T(x)^T T(x) \leq 1 \\
&amp; \iff T(x) \in E_0, \end{aligned}\)</span></p>
<p>which implies that <span class="math inline">\(T(E) =
E_0\)</span>.</p>
<p>Similarly,</p>
<p><span class="math display">\[\begin{aligned} x \in H &amp; \iff
a_i^T(x-z )\geq 0 \\ &amp; \iff \|D^{-\frac 1 2}a_i \| e_1 ^T RD^{-\frac
1 2} (x-z) \geq 0 \\ &amp; \iff e_1 ^T T(x) \geq 0 \\ &amp; \iff T(x)
\in H_0,  \end{aligned}\]</span></p>
<p>which implies <span class="math inline">\(T(H) = H_0\)</span>.</p>
<p>Moreover there is also <span class="math inline">\(T(\bar E) = \bar
E_0\)</span> and we omit the complicated algebraic manipulations.
Therefore <span class="math inline">\(E \cap H \subset \bar E\)</span>
holds according to the properties of affine transformation. Next we
prove the conclusion about the volume.</p>
<p><span class="math inline">\(\frac{Vol(\bar E)}{Vol(E)} =
\frac{Vol(T(\bar E))}{Vol(T(E))} = \frac{Vol(\bar E_0)}{Vol(E_0)} =
det(D_0 ^{\frac 1 2}) =
(\frac{n}{\sqrt{n^2-1}})^{n-1}(\frac{n}{n+1})\)</span></p>
<p>Consider</p>
<p><span class="math display">\[(\frac{n^2}{n^2-1})^{\frac{n-1}{2}}(\frac{n}{n+1})
= (1+\frac{1}{n^2-1})^{\frac{n-1}{2}}(1-\frac{1}{n+1}) \leq
(e^{\frac{1}{n^2-1}})^{\frac{n-1}{2}} e^{-\frac{1}{n+1}}
=  e^{-\frac{1}{2(n+1)}},\]</span></p>
<p>and the desired result follows.</p></li>
</ul>
<p>另外如果估计得再精细一点的话下界其实是 <span class="math inline">\(\exp(-\frac{1}{2n})\)</span>（详见
Bubeck），可以对函数求导做。</p>
<p>所以只要初始状态的 ellipsoid
体积有限，算法一定会在有限时间内终止，可以用来解决 feasiblility
的问题，这是一个可以在 <span class="math inline">\(O(n \log
\varepsilon)\)</span> 时间内结束的算法，实际上对于找 feasible solution
来说还是很快的。但 feasible solution
一个单点对于优化问题来说其实没什么用，我们的目标仍然是寻找 optimal
cost，为此需要一些类似于 center of gravity method 的方法。</p>
<p>另外 ellipsoid method 也可以用来解决 optimal cost
的逼近，有这样一个体积关系了之后原理和 center of gravity method
类似：</p>
<p><del>每个新的 ellipsoid 和上一时刻 ellipsoid 之间有一个体积关系是
<span class="math inline">\(Vol(S_{t+1}) \leq \exp(-\frac{1}{2n})
Vol(S_t) \leq \cdots \leq \exp(-\frac{t}{2n}) Vol(S_1)\)</span>，再对于
<span class="math inline">\(\varepsilon = \exp(-\frac{t}{2n^2})\)</span>
取 <span class="math inline">\(\mathcal S_\varepsilon = \{(1-\varepsilon
)x^* + \varepsilon x, \forall x \in S_1\}\)</span>，实际上是对 <span class="math inline">\(S_1\)</span> 做了一个仿射变换。此时有 <span class="math inline">\(Vol(S_\varepsilon)=\varepsilon^n Vol(S_1) =
\exp(-\frac{t}{2n}) Vol(S_1) \geq
Vol(S_{t+1})\)</span>，于是可以找到一个 <span class="math inline">\(x_\varepsilon \in S_\varepsilon\)</span> 使其在
<span class="math inline">\(t\)</span> 时刻时仍在 <span class="math inline">\(S_t\)</span> 中，而 <span class="math inline">\(t+1\)</span> 时刻就被“裁剪”了出去。</del></p>
<p><del>所以有：</del></p>
<p><del><span class="math display">\[c^Tx_{t+1} &lt; c^Tx_\varepsilon =
c^T((1-\varepsilon)x^*+ \varepsilon x) \leq c^Tx^* + 2B\varepsilon
=c^Tx^*+2B \exp(-\frac{t}{2n^2}),\]</span></del></p>
<p><del>也就是说 <span class="math inline">\(c^Tx_{t+1} - c^Tx^* &lt; 2B
\exp(-\frac{t}{2n^2})\)</span> 作为 <span class="math inline">\(t+1\)</span> 时刻下取值距离 optimal cost
的误差可以被控制，并且我们可以在 <span class="math inline">\(O(n^2
\log(\frac{1}{\varepsilon}))\)</span> 时间下得到误差为 <span class="math inline">\(\varepsilon\)</span> 的 cost 和
solution。同样是得到的 cost 比 simplex method 误差大一些并非精确值，但是
polynomial time algorithm，虽然比起 center of gravity method
来说消耗更大，但也有它的优势。</del></p>
<p>之前的想法一直有大问题，我当时也没怎么看懂 Bubeck
那本书的内容，更是完全不理解为什么 time usage 里面还有 <span class="math inline">\(R/r\)</span>
的项。今晚做出来优化作业第一题之后醍醐灌顶，直接复制到这里来就很清楚了。</p>
<p><strong>Problem</strong>: Consider the following convex optimization
problem (<span class="math inline">\(f,g_i\)</span> are convex):</p>
<p><span class="math display">\[\text{minimize} \quad f(x)\]</span></p>
<p><span class="math display">\[\text{subject to} \quad g_i(x) \leq 0,
i=1,2,\cdots,m.\]</span></p>
<p>Let <span class="math inline">\(\mathcal K = \{x \mid g_i(x) \leq 0,
i=1,2,\cdots,m\}\)</span>. Assume that there exists <span class="math inline">\(x_,x_0^\prime\)</span> s.t. <span class="math inline">\(\mathcal K\)</span> is between balls of radius
<span class="math inline">\(r,R\)</span>,</p>
<p><span class="math display">\[B(x_0,r) \subseteq \mathcal K \subseteq
B(x_0^\prime,R)\]</span></p>
<p>Further assume that <span class="math inline">\(\sup_{x \in \mathcal
K} |f(x)| \leq B\)</span>. Given any <span class="math inline">\(x \in
\mathbb R^n\)</span> one can evaluate <span class="math inline">\(f(x),g_i(x), \nabla f(x) , \nabla g_i(x)\)</span>.
Propose an efficient implementation of the Ellipsoid's method. Prove
that the algorithm converges in <span class="math inline">\(\mathcal
O(n^2 \log(\frac{BR}{r \varepsilon}))\)</span> iterations to find an
<span class="math inline">\(\varepsilon\)</span> optimal solution.</p>
<p><strong>Solution</strong>: To begin the algorithm, we set <span class="math inline">\(\mathcal E_0 = B(x_0^\prime, R)\)</span> and <span class="math inline">\(c_0 = x_0^\prime\)</span> as its center. At time
<span class="math inline">\(t\)</span> we divide the possible results
into two situations as follows.</p>
<ul>
<li><p>If <span class="math inline">\(c_t \notin \mathcal K\)</span>,
then there is some constraints <span class="math inline">\(g_i(x) \leq
0\)</span> violated so that <span class="math inline">\(c_t\)</span>
does not lie in the feasible set. We find the violated constraints by
calling the zeroth order oracle <span class="math inline">\(g_i(c_t)\)</span> and compare their value with
<span class="math inline">\(0\)</span>. To save the computational source
we just pick the violated constraint <span class="math inline">\(g_i(c_t) &gt;0\)</span> with the smallest
subscript, and number it as <span class="math inline">\(g_i^{(t)}\)</span>.</p>
<p>Thus the feasible set <span class="math inline">\(\mathcal K\)</span>
lies in <span class="math inline">\(\mathcal E _t \cap \{x \mid g_i
^{(t)} (x) \leq g_i ^{(t)} (c_t)\} \subseteq \mathcal E _t \cap \{x \mid
\nabla g_i^{(t)}(c_t)^T (x-c_t) \leq 0\}\)</span> according to the
definition of subgradient. And the exact value of subgradient <span class="math inline">\(\nabla g_i^{(t)}(c_t)\)</span> can be obtained by
calling the first order oracle <span class="math inline">\(\nabla
g_i^{(t)}\)</span>.</p>
<p>Then we can just construct the <span class="math inline">\((t+1)\)</span>-th ellipsoid by covering the set
shown above, i.e. <span class="math inline">\(\mathcal E_{t+1} \supseteq
\mathcal E _t \cap \{x \mid \nabla g_i^{(t)}(c_t)^T (x-c_t) \leq
0\}\)</span>.</p></li>
<li><p>The second case is much easier. If we found <span class="math inline">\(c_t \in \mathcal K\)</span>, by considering the
subset <span class="math inline">\(\mathcal E_t \cap \{ x \mid f(x) &lt;
f(c_t)\} \subseteq \mathcal E_t\)</span>, we can either find <span class="math inline">\(c_t\)</span> is optimal by observing that the set
is empty or found a better solution through iteration.</p>
<p>According to the definition of subgradient, there is <span class="math inline">\(\mathcal E_t \cap \{x \mid f(x) &lt; f(c_t)\}
\subseteq \mathcal E_t \cap \{ x \mid \nabla f(c_t)^T (x-c_t) \leq
0\}\)</span>. Then we can just construct the <span class="math inline">\((t+1)\)</span>-th ellipsoid by covering the set
shown above, i.e. <span class="math inline">\(\mathcal E_{t+1} \supseteq
\mathcal E _t \cap \{ x \mid \nabla f(c_t)^T (x-c_t) \leq 0\}\)</span>,
in which the value of subgradient <span class="math inline">\(\nabla
f(c_t)\)</span> can be obtained by calling the first order oracle <span class="math inline">\(\nabla f\)</span>.</p></li>
</ul>
<p>For both situations, we can obtain <span class="math inline">\(\mathcal E_{t+1}\)</span> with the least volume
such that <span class="math inline">\(Vol(\mathcal E_{t+1} ) \leq
\exp(-\frac{1}{2n}) Vol(\mathcal E_t)\)</span> according to the theorem
we proved in class (and we can construct the exact form of <span class="math inline">\(\mathcal E_{t+1}\)</span> through the complex
equation, which won't be shown again in this solution).</p>
<p>Therefore, if <span class="math inline">\(t \geq 2n^2
\log(\frac{R}{r})\)</span> there is <span class="math inline">\(Vol(\mathcal E_t) \leq Vol(B(x_0,r))\)</span> and
<span class="math inline">\(\{c_1,c_2,\cdots,c_t\} \cap \mathcal K \neq
\varnothing\)</span>. From now on we only consider the time that ensures
<span class="math inline">\(\{c_1,c_2,\cdots,c_t\} \cap \mathcal K \neq
\varnothing\)</span>.</p>
<p>For fixed <span class="math inline">\(\varepsilon &gt;0\)</span>, we
take <span class="math inline">\(\mathcal K_\varepsilon =
\{(1-\varepsilon)x^* + \varepsilon x \mid \forall x \in
B(x_0,r)\}\)</span> as an affine transformation, in which <span class="math inline">\(x^*\)</span> is the optimal solution of this
problem. Moreover we denote <span class="math inline">\(x_t \triangleq
\arg \min_{c_s \in \{c_0,c_1,\cdots, c_t\} \cap \mathcal K}
f(c_s)\)</span>.</p>
<p>When we take <span class="math inline">\(\varepsilon = \frac{R}{r}
\exp(-\frac{t}{2n^2})\)</span> there is <span class="math display">\[Vol(\mathcal K_\varepsilon ) = \varepsilon^n
Vol(B(x_0,r)) = \varepsilon^n (\frac{r}{R})^n Vol(B(x_0^\prime ,R)) =
\exp(-\frac{t}{2n^2}) Vol(B(x_0^\prime, R)) &gt; Vol(\mathcal
E_t)\]</span></p>
<p>This inequality implies that there exists one time <span class="math inline">\(r \in \{1,2,\cdots,t\}\)</span> s.t. there exists
<span class="math inline">\(x_\varepsilon \in \mathcal
K_\varepsilon\)</span>, <span class="math inline">\(x_\varepsilon \in
\mathcal E_{r-1}\)</span>, but <span class="math inline">\(x_\varepsilon
\notin \mathcal E_r\)</span>, therefore <span class="math inline">\(x_\varepsilon\)</span> is not optimal. According
to the convexity of <span class="math inline">\(f(x)\)</span>, there is
<span class="math display">\[f(x_t) &lt; f(c_r)
\leq  f(x_\varepsilon)  = f((1-\varepsilon)x^* + \varepsilon x_r) \leq
(1-\varepsilon) f(x^*) + \varepsilon f(x_r) \leq f(x^*) +
2B\varepsilon,\]</span> which implies that <span class="math display">\[f(x_t) - f(x^*) \leq 2B\varepsilon =
\frac{2BR}{r} \exp(-\frac{t}{2n^2}).\]</span></p>
<p>Then we can conclude that the algorithm converges in <span class="math inline">\(\mathcal O(n^2 \log(\frac{BR}{\varepsilon
r}))\)</span> iterations to find an <span class="math inline">\(\varepsilon\)</span> optimal solution, and the
desired result follows.</p>
<h1 id="lecture-4">Lecture 4</h1>
<p>睡了（，等个笔记（（</p>
<p>10.23 UPD：今天布置了个优化 HW3
但又迅速删掉了，我也不知道为什么要同时把讲义也删掉，当时正好在贴所以也没来得及下（。这助教是否也是一个优化算法控制的，要传就把所有的东西都传上来要删就全部删掉，来保证要么所有人都满意要么所有人都不满意（。</p>
<h2 id="convex-optimization">Convex Optimization</h2>
<h3 id="notations-2">Notations</h3>
<p>#每日迷神</p>
<p><img src="https://s2.loli.net/2023/09/26/PEzuQl2MOW37Jr1.jpg" alt="mi1.jpg"></p>
<ul>
<li>A set <span class="math inline">\(C \in \mathbb R^n\)</span> is
affine iff for any <span class="math inline">\(x,y \in C\)</span> and
any <span class="math inline">\(\theta \in \mathbb R\)</span>, there is
<span class="math inline">\(\theta x + (1-\theta) y \in C\)</span>,
therefore the whole line lies in <span class="math inline">\(C\)</span>.
<ul>
<li>Therefore, if <span class="math inline">\(C\)</span> is an affine
set and <span class="math inline">\(x_0 \in C\)</span>, then the set
<span class="math inline">\(V = \{x-x_0 \mid \forall x \in C\}\)</span>
is a subspace.</li>
</ul></li>
<li>An affine hull of <span class="math inline">\(C\)</span> is denoted
as <span class="math inline">\(aff(C) = \{\theta_1 x_1+ \theta_2
x_2+\cdots+ \theta_k x_k \mid \forall k \in \mathbb Z_+, x_i \in C,
\theta_i \in \mathbb R \}\)</span></li>
<li>The relative interior <span class="math inline">\(relint(C) = \{x\in
C \mid \exist r &gt;0 , \text{s.t. } B(x,r) \cap aff(C) \subseteq C
\}\)</span></li>
</ul>
<p>简单来说，affine set/affine hull 和 convex
版本的唯一区别就是参数不需要取在 <span class="math inline">\([0,1]\)</span> 之间，所以它一般是个平面。</p>
<ul>
<li><p>A set <span class="math inline">\(C\)</span> is called a cone iff
<span class="math inline">\(\forall x \in C\)</span> and for any <span class="math inline">\(\theta &gt; 0\)</span>, there is <span class="math inline">\(\theta x \in C\)</span>.</p></li>
<li><p>(Extended convex function) A function <span class="math inline">\(f : \mathbb R^n \to \mathbb R\)</span> is convex,
we can extend its domain <span class="math inline">\(dom(f)\)</span> to
<span class="math inline">\(\mathbb R^n\)</span> by taking <span class="math inline">\(f(x) = \infty\)</span> for any <span class="math inline">\(x \notin dom(f)\)</span>.</p></li>
<li><p>(Epigraph of a function) <span class="math inline">\(epi(f) =
\{(x,t) \mid t \geq f(x)\}\)</span></p>
<p>Therefore <span class="math inline">\(f\)</span> is a convex function
if and only if <span class="math inline">\(epi(f)\)</span> is a convex
set.</p></li>
</ul>
<h3 id="basic-theorems">Basic Theorems</h3>
<ul>
<li><p>(Seperating Hyperplane Theorem) Suppose <span class="math inline">\(C,D\)</span> are nonempty disjoint convex sets,
then there exists <span class="math inline">\(a \neq 0\)</span>, <span class="math inline">\(a,b \in \mathbb R^n\)</span> s.t. <span class="math inline">\(C \subseteq \{x \in \mathbb R^n \mid a^Tx \leq
b\}\)</span> and <span class="math inline">\(D \subseteq \{x \in \mathbb
R^n \mid a^Tx \geq b\}\)</span>.</p>
<p><strong>Proof</strong>: We only consider the case when <span class="math inline">\(C,D\)</span> are both closed and bounded.</p>
<p>Define <span class="math inline">\(dist(C,D) = \inf\{\|u-v\|_2 \mid u
\in C,v \in D \}\)</span> as the distance between <span class="math inline">\(C,D\)</span>, then by closed and boundness we can
find <span class="math inline">\(c \in C, d \in D\)</span> s.t. <span class="math inline">\(dist(C,D) = \|c-d\|_2\)</span>. Take <span class="math inline">\(a = d-c\)</span>, <span class="math inline">\(b =
\frac 1 2 (\|d\|_2^2 - \|c\|_2^2)\)</span>.</p>
<p>Then the affine transformation <span class="math inline">\(f(x) =
a^Tx - b\)</span> will let <span class="math inline">\(f(x)
&lt;0\)</span> for any <span class="math inline">\(x \in D\)</span>, and
<span class="math inline">\(f(x) &gt;0\)</span> for any <span class="math inline">\(x \in C\)</span>.</p></li>
<li><p>(Supporting Hyperplane Theorem) Suppose <span class="math inline">\(C\)</span> is convex, then for any <span class="math inline">\(x \in bd(C)\)</span> here exists a supporting
vector <span class="math inline">\(a \neq 0, a \in \mathbb R^n\)</span>,
s.t. <span class="math inline">\(\forall x \in C\)</span>, <span class="math inline">\(a^Tx_0 \leq a^Tx\)</span>. (<span class="math inline">\(bd(C)\)</span> is the boundary of <span class="math inline">\(C\)</span>)</p></li>
</ul>
<p>别的没什么了，convex function
的性质什么的真没必要再写一遍了，他又不讲 subgradient。</p>
<h1 id="lecture-5">Lecture 5</h1>
<p>才隔了两周，今天怎么又是哥们在做 scribing 啊（。read-only 的链接在<a target="_blank" rel="noopener" href="https://www.overleaf.com/read/tvswmtjkgtsp#b147f8">这里</a>。</p>
<p>今天讲一些 convex optimization 里的例子，给哥们整的一愣一愣的。</p>
<h2 id="examples-in-convex-optimization">Examples in Convex
Optimization</h2>
<h3 id="notations-3">Notations</h3>
<p>#每日迷神</p>
<p><img src="https://s2.loli.net/2023/09/26/PEzuQl2MOW37Jr1.jpg" alt="mi1.jpg"></p>
<p>你还别说现在还真不一定书上都有了，那个 max cut 给哥们整不会了，Boyd
上面没写，Bubeck 就写了一点而且还把课上的内容跳过去了。而且 Bubeck
本来就简略，看了个寂寞。</p>
<ul>
<li><p>The following optimization problem is called a convex
optimization problem if <span class="math inline">\(x_0, f_i\)</span>
are convex, and <span class="math inline">\(h_i\)</span> are linear:</p>
<p><span class="math display">\[\begin{aligned}
\textbf{minimize}  \quad &amp; f_0(x) \\
\textbf{subject to} \quad &amp; f_i(x) \leq 0 \\
&amp; h_i (x) =0
\end{aligned}\]</span></p></li>
<li><p><span class="math inline">\(x\)</span> is a <span class="math inline">\(\varepsilon\)</span>-suboptimal if <span class="math inline">\(f_0(x) \leq p^* + \varepsilon\)</span>, in which
<span class="math inline">\(p^*\)</span> is the optimal value of the
convex optimization problem.</p></li>
<li><p><span class="math inline">\(x_0\)</span> is locally optimal if
there exists <span class="math inline">\(R &gt;0\)</span> s.t. <span class="math inline">\(x_0\)</span> is the optimal solution to:</p></li>
</ul>
<p>​ <span class="math display">\[\begin{aligned}
   \textbf{minimize}  \quad &amp; f_0(x) \\
   \textbf{subject to} \quad &amp; f_i(x) \leq 0 \\
   &amp; h_i (x) =0 \\
   &amp; \|x-x_0\| \leq R \end{aligned}\]</span></p>
<h3 id="why-convex-optimization">Why Convex Optimization?</h3>
<p>为什么研究凸优化？一个是 linear programming problem
有它的局限性，许多问题只能往凸优化的方向转化。另外凸性质实际上是非常美妙的。下面是一个很
trivial 的例子，我们对 convex optimization
的转化问题的探究远不止于此。</p>
<p>Why is convex optimization important? That's because some non-convex
problems have underlying convexity. For example, we consider the
following optimization problem:</p>
<p><span class="math display">\[\begin{aligned}
\textbf{minimize}  \quad &amp; f_0(x)=x_1^2+x_2^2 \\
\textbf{subject to} \quad &amp; f_1(x) = \frac{x_1}{1+x_2^2} \leq 0 \\
&amp; h_i (x) = (x_1+x_2)^2 =0
\end{aligned}\]</span></p>
<p>which can easily be transformed into a standard convex optimization
problem.</p>
<h2 id="example-max-cut-problem">Example: Max Cut Problem</h2>
<p>别 TCS 了求你了求你了求你了（</p>
<p>通过一个 max cut problem 来体现从 nonconvex optimization 向 convex
optimization 的转化，从方法论的层面上来说是两步。</p>
<p>Why are convex optimization problems important? That's because many
non-convex optimization problems can be transformed into convex ones,
and we can solve convex optimization problems through mature
technologies. Generally speaking, the process contains two steps:</p>
<ol type="1">
<li>First, transform the non-convex problem into convex ones through
relaxation.</li>
<li>Next recover a solution from the convex problem to the non-convex
one through random rounding.</li>
</ol>
<h3 id="notations-4">Notations</h3>
<ul>
<li>A cut in an undirected graph <span class="math inline">\(G = (V,
\mathcal E)\)</span> is defined as <span class="math inline">\(A
\subseteq V\)</span>.The capacity of a cut <span class="math inline">\(A\)</span> is defined as <span class="math inline">\(c(A) = | \{(u,v)\in \mathcal E \mid u \in A, u \in
A^c\}|\)</span>.</li>
</ul>
<p>而 max cut 问题就是寻找最大的 <span class="math inline">\(c(A)\)</span>，尽管我不知道这样做有什么意义，但它是
NP-hard 的。所以我们只需要找到一个 polynomial time
的算法就可以证明...（逃</p>
<ul>
<li>​ An <span class="math inline">\(\alpha\)</span>-approximate max cut
is a cut <span class="math inline">\(A\)</span> s.t. <span class="math inline">\(c(A) \geq \alpha \max_{U \subseteq V}
c(U)\)</span>.</li>
</ul>
<h3 id="frac-1-2-approximate-approach"><span class="math inline">\(\frac
1 2\)</span>-Approximate Approach</h3>
<p>怎么是概率做法，真稀奇。</p>
<p>To be more specific, we can give a <span class="math inline">\(\frac{1}{2}\)</span>-approximate max cut by
randomly adding each point <span class="math inline">\(v\)</span> in
<span class="math inline">\(V\)</span> to the cut <span class="math inline">\(A\)</span> with probability <span class="math inline">\(\frac{1}{2}\)</span>. Consider the expectation of
<span class="math inline">\(c(A)\)</span> here and we can get:</p>
<p><span class="math display">\[\mathbb E_A(c(A)) = \mathbb E_A
\sum_{(u,v)\in \mathcal E} 1_{(u \in A,v \in A^c)} = \sum_{(u,v) \in
\mathcal E} P(u \in A, v \in A^c) = \sum_{(u,v) \in \mathcal E}
\frac{1}{2} = \frac{|\mathcal E|}{2}.\]</span></p>
<p>然而这还是很粗糙。</p>
<h3 id="linear-approach">Linear Approach</h3>
<p>如果没有 convex optimization 的话就是考虑一些 linear programming
的近似，举两个失败的 approach 说明这很困难：</p>
<ul>
<li><p>Consider the following formulation of the problem:</p>
<p><span class="math display">\[\begin{aligned}
    \textbf{maximize}_{x\in \mathbb R^n} \quad &amp; \sum_{(u,v)\in
\mathcal E} \frac{1}{2}(1-x_ux_v) \\
    \textbf{subject to} \quad &amp; x_v \in \{-1,1\}
\end{aligned}\]</span></p></li>
<li><p>This is not a linear programming problem, and we can transform it
by denoting <span class="math inline">\(z_e = x_ux_v, e=(u,v) \in
\mathcal{E}\)</span>:</p>
<p><span class="math display">\[\begin{aligned}
    \textbf{maximize}_{x,z} \quad &amp; \sum_{e \in E} \frac{1}{2 }
(1-z_e) \\
    \textbf{subject to} \quad &amp; z_{(u,v)} \geq -x_u -x_v -1 \\
     &amp; z_{(u,v)} \geq x_u +x_v -1 \\
     &amp; x_v \in [-1,1]
\end{aligned}\]</span></p></li>
</ul>
<p>However, this still fails for we can choose <span class="math inline">\(x_v =x_u=0\)</span> and <span class="math inline">\(z_{(u,v)} =-1\)</span> in the feasible set, which
means the approach will only give a randomized choice of <span class="math inline">\(A\)</span>. Now turn to convex optimization for
help.</p>
<h3 id="convex-transformation">Convex Transformation</h3>
<ul>
<li><p>The basic idea is to replace <span class="math inline">\(x_u.x_v\)</span> with <span class="math inline">\(n-1\)</span> dimensional vectors and construct an
auxiliary problem, which is called semi-definite relaxation:</p>
<p><span class="math display">\[\begin{aligned}
    \textbf{maximize} \quad &amp; \sum_{(u,v) \in \mathcal E}
\frac{1}{2} (1-x_u^Tx_v) \\
    \textbf{subject to} \quad &amp; x_u \in S^{n-1} \text{ for any
}u=1,2,\cdots,n
\end{aligned}\]</span></p>
<p>in which <span class="math inline">\(S^{n-1}\)</span> is the unit
sphere in <span class="math inline">\(\mathbb R^{n-1}\)</span>. Observe
that <span class="math inline">\(\frac{1}{4}\|x_u-x_v\|^2 =\frac{1}{4}
(x_u -x_v)^T(x_u-x_v) = \frac{1}{2} (1-x_ux_v)\)</span>, and <span class="math inline">\(\frac{1}{2} \sum_{e \in \mathcal E} (1-z_e) =
\frac{1}{4} \sum_{(u,v)\in \mathcal E} \|x_u - x_v\|^2\)</span>.</p>
<p>Now we take <span class="math inline">\(\text{Maxcut}^\circ
(C)\)</span> as the optimal cost of the auxiliary problem and denote
<span class="math inline">\(\text{Maxcut} (C)\)</span> as the optimal
cost of the original problem. Then there is <span class="math inline">\(\text{Maxcut} (C) \leq \text{Maxcut}^\circ
(C)\)</span> because any optimal solution of the original problem can be
transformed into a feasible solution in the auxiliary one.</p>
<p>To be more precise, if <span class="math inline">\(\{x_u\}\)</span>
is an optimal solution to the original problem, then for any <span class="math inline">\(x_u = 1\)</span> there is <span class="math inline">\(x_v = -1\)</span> for each <span class="math inline">\(v \in \{v \mid (u,v) \in \mathcal E\}\)</span>.
Therefore we can take <span class="math inline">\(x_u = e_1\)</span>,
<span class="math inline">\(x_v = -e_1\)</span> for any <span class="math inline">\(v \in \{v \mid (u,v) \in \mathcal E\}\)</span> as
a feasible solution to the auxiliary problem, and the cost is equal to
the optimal cost of the original one.</p></li>
<li><p>However the auxiliary problem is still non-convex, we'd like to
consider another optimization problem as follows:</p>
<p><span class="math display">\[\begin{aligned}
    \textbf{minimize} \quad &amp; X \cdot A = \sum_{i,j \in V} X_{ij}
A_{ij} \\
    \textbf{subject to} \quad &amp; X \geq 0 \;  \\
     &amp; X_{ii}=1
\end{aligned}\]</span></p>
<p>in which <span class="math inline">\(X \geq 0\)</span> means <span class="math inline">\(X\)</span> is semi-definite, i.e. <span class="math inline">\(X \in S_+^n, X \in \mathbb R^{n \times
n}\)</span>.</p>
<p>We set <span class="math inline">\(A_{ij}=1\)</span> if <span class="math inline">\((i,j) \in \mathcal E\)</span>, else <span class="math inline">\(A_{ij}=0\)</span>. Now we prove that the two
problems above are equivalent.</p></li>
<li><p>The following two max-cut optimization problems are
equivalent:</p></li>
</ul>
<p>​ <span class="math display">\[\begin{aligned}
  ​            \textbf{maximize} \quad &amp; \sum_{(u,v) \in \mathcal E}
\frac{1}{2} (1-x_u^Tx_v) \\
  ​    \textbf{subject to} \quad &amp; x_u \in S^{n-1} \\
  ​    \\
  ​    \end{aligned} \quad \quad \quad
  ​    \begin{aligned}
  ​        \textbf{minimize} \quad &amp; X \cdot A = \sum_{i,j \in V}
X_{ij} A_{ij} \\
  ​    \textbf{subject to} \quad &amp; X \geq 0 \;  \\
  ​     &amp; X_{ii}=1
  ​    \end{aligned}\]</span></p>
<p><strong>Proof</strong>: Note that <span class="math inline">\(X_{ij}
= x_i^T x_j\)</span> (and sometimes <span class="math inline">\(X\)</span> is called the gram matrix),
therefore</p>
<p><span class="math display">\[\begin{aligned}
          X \in S_+^n \text{ is feasible } &amp; \iff X_{ij}=1 \text{
for any } i \in V \\
          &amp; \iff \|x_u \|=1 \text{ for any } u \in V \\
          &amp; \iff x_u \in S^{n-1} \text{ for any } u \in V
      \end{aligned}\]</span></p>
<p>and the desired result follows.</p>

    </div>

    
    
    
        <div class="reward-container">
  <div>我很可爱 请给我钱（？）</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.jpg" alt="驰雨Chiyuru 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.jpg" alt="驰雨Chiyuru 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>驰雨Chiyuru
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://chiyuru.github.io/2023/09/25/Introduction-to-Optimization-Theory/" title="年轻人的第一门 optimization 是茶园课">https://chiyuru.github.io/2023/09/25/Introduction-to-Optimization-Theory/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%95%B0%E5%AD%A6/" rel="tag"># 数学</a>
              <a href="/tags/%E7%BB%9F%E8%AE%A1/" rel="tag"># 统计</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/09/20/Advanced-Mathematical-Statistics-I/" rel="prev" title="高等数理统计 I 比统计推断多了啥">
      <i class="fa fa-chevron-left"></i> 高等数理统计 I 比统计推断多了啥
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/09/29/tea/" rel="next" title="三点几了，饮茶先啦">
      三点几了，饮茶先啦 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  
  <div class="comments">
  <script src="https://utteranc.es/client.js" repo="Chiyuru/chiyuru.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async></script>
  </div>
  
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-1"><span class="nav-text">Lecture 1</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#standardized-linear-programming"><span class="nav-text">Standardized Linear
Programming</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#reduce-to-standardized-format"><span class="nav-text">Reduce to Standardized
Format</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#other-optimization-problems"><span class="nav-text">Other Optimization Problems</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#solutions-to-lp-problems"><span class="nav-text">Solutions to LP Problems</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#notations"><span class="nav-text">Notations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#how-to-describe-optimal-solutions"><span class="nav-text">How to Describe Optimal
Solutions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#algebraic-approach-to-optimal-solutions"><span class="nav-text">Algebraic Approach to
Optimal Solutions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#existence-of-vertex"><span class="nav-text">Existence of Vertex</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#why-is-vertex-important"><span class="nav-text">Why is Vertex Important?</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-2"><span class="nav-text">Lecture 2</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#simplex-method"><span class="nav-text">Simplex Method</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#find-the-initial-solution"><span class="nav-text">Find the Initial Solution</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#develop-feasible-direction"><span class="nav-text">Develop Feasible Direction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#choice-of-adjacent-basic-feasible-solution"><span class="nav-text">Choice of Adjacent
Basic Feasible Solution</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#termination"><span class="nav-text">Termination</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#summary"><span class="nav-text">Summary</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#introduction-to-duality"><span class="nav-text">Introduction to Duality</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#duality-theorems"><span class="nav-text">Duality Theorems</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-3"><span class="nav-text">Lecture 3</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#nash-equilibrium"><span class="nav-text">Nash Equilibrium</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#theory"><span class="nav-text">Theory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#application"><span class="nav-text">Application</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#application-of-farkas-lemma"><span class="nav-text">Application of Farka&#39;s Lemma</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#the-center-of-gravity-method"><span class="nav-text">The Center of Gravity Method</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#the-ellipsoid-method"><span class="nav-text">The Ellipsoid Method</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#notations-1"><span class="nav-text">Notations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#algorithm"><span class="nav-text">Algorithm</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-4"><span class="nav-text">Lecture 4</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#convex-optimization"><span class="nav-text">Convex Optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#notations-2"><span class="nav-text">Notations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#basic-theorems"><span class="nav-text">Basic Theorems</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-5"><span class="nav-text">Lecture 5</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#examples-in-convex-optimization"><span class="nav-text">Examples in Convex
Optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#notations-3"><span class="nav-text">Notations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#why-convex-optimization"><span class="nav-text">Why Convex Optimization?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#example-max-cut-problem"><span class="nav-text">Example: Max Cut Problem</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#notations-4"><span class="nav-text">Notations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#frac-1-2-approximate-approach"><span class="nav-text">\(\frac
1 2\)-Approximate Approach</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#linear-approach"><span class="nav-text">Linear Approach</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#convex-transformation"><span class="nav-text">Convex Transformation</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="驰雨Chiyuru"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">驰雨Chiyuru</p>
  <div class="site-description" itemprop="description">おはよう、朝だよ</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">76</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Chiyuru" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Chiyuru" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:chiyuruu@gmail.com" title="E-Mail → mailto:chiyuruu@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/Chiyuru_0417" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;Chiyuru_0417" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/chiyuruu" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;chiyuruu" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>知乎</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright">
  
  &copy; 2022 – 
  <span itemprop="copyrightYear">2026</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">驰雨Chiyuru</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv1">
  本站总访客数：<span id="busuanzi_value_site_uv"></span>
</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":-15,"vOffset":-15},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
