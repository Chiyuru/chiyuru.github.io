<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"chiyuru.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="本来真没打算连载这个，结果这课居然把课程笔记算成百分制里面的 10 分（，那就写罢。 有参考 Vica Yang 的统辅笔记，JhZhang 的课堂笔记和 V1ncent19 的统辅笔记，如有引用均会在文中注明，在此向前辈表示感谢。">
<meta property="og:type" content="article">
<meta property="og:title" content="还就那个线性回归分析">
<meta property="og:url" content="https://chiyuru.github.io/2023/02/21/Linear-Regression-Analysis/index.html">
<meta property="og:site_name" content="『姑妄言之姑妄听之』">
<meta property="og:description" content="本来真没打算连载这个，结果这课居然把课程笔记算成百分制里面的 10 分（，那就写罢。 有参考 Vica Yang 的统辅笔记，JhZhang 的课堂笔记和 V1ncent19 的统辅笔记，如有引用均会在文中注明，在此向前辈表示感谢。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/02/26/AHxRkaSBD87fW3V.png">
<meta property="og:image" content="https://s2.loli.net/2023/02/26/iRyejXI6TuSvroJ.png">
<meta property="article:published_time" content="2023-02-21T11:12:18.000Z">
<meta property="article:modified_time" content="2023-03-03T04:05:27.619Z">
<meta property="article:author" content="驰雨Chiyuru">
<meta property="article:tag" content="课程实录">
<meta property="article:tag" content="数学">
<meta property="article:tag" content="统计">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/02/26/AHxRkaSBD87fW3V.png">

<link rel="canonical" href="https://chiyuru.github.io/2023/02/21/Linear-Regression-Analysis/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>还就那个线性回归分析 | 『姑妄言之姑妄听之』</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="『姑妄言之姑妄听之』" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">『姑妄言之姑妄听之』</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chiyuru.github.io/2023/02/21/Linear-Regression-Analysis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="驰雨Chiyuru">
      <meta itemprop="description" content="おはよう、朝だよ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="『姑妄言之姑妄听之』">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          还就那个线性回归分析
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-02-21 19:12:18" itemprop="dateCreated datePublished" datetime="2023-02-21T19:12:18+08:00">2023-02-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-03-03 12:05:27" itemprop="dateModified" datetime="2023-03-03T12:05:27+08:00">2023-03-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>本来真没打算连载这个，结果这课居然把课程笔记算成百分制里面的 10
分（，那就写罢。</p>
<p>有参考 <a target="_blank" rel="noopener" href="https://blog.vicayang.cc/tags/statistics/">Vica Yang
的统辅笔记</a>，<a target="_blank" rel="noopener" href="https://www.zhihu.com/column/c_1332050772843511808">JhZhang
的课堂笔记</a>和 <a target="_blank" rel="noopener" href="https://v1ncent19.github.io/SummaryNotes/">V1ncent19
的统辅笔记</a>，如有引用均会在文中注明，在此向前辈表示感谢。</p>
<span id="more"></span>
<h1 id="lecture-1">Lecture 1</h1>
<p>主要是在吹水，开玩笑以及活跃气氛。正经的内容大概就一个古老的回归现象，我还没有听得很懂，麻了。</p>
<h2 id="galtons-experiment">Galton's Experiment</h2>
<p>以下全是胡说八道，不能保证完全对。</p>
<p>介绍正态分布的时候会有一个很经典的小球过钉板的演示实验，最后落在底部的球似乎呈现出一个正态分布。但实际上球和钉子的每次碰撞都是一个
Bernoulli 过程，过了 n 层钉板就是 n 次 Bernoulli
过程加和，可以近似为正态分布。实际上只要 n
够大，由中心极限定理任何分布的加和都可以被近似为正态分布。</p>
<p>但我觉得实际上小球的情况并不是独立的，毕竟过程中会有相互的碰撞，真的没问题吗（</p>
<p>回归现象的起源是 Galton
对于父代和子代的身高做了一个统计，发现身高远离均值的父母的后代往往身高会比他们更接近平均水平，也就是某一身高水平的父母的孩子的身高中位数作为因变量，父母身高作为自变量时，拟合出的直线的斜率小于
<span class="math inline">\(1\)</span>。</p>
<p>假设不发生回归现象，则和钉板现象一样，后代的性状会逐渐分散，这被认为是一个种群稳定性状的方式。听起来很玄学，似乎也有一个稍微合理的生物学解释了，但我们希望从统计学的角度分析这件事，背后是存在数学规律的。</p>
<p><img src="https://s2.loli.net/2023/02/26/AHxRkaSBD87fW3V.png" alt="Galton.png"></p>
<p>上图是课程中反复出现的一张图，对此做了很多解释。最上面的正态分布是父代的身高情况（实际上是父母身高的加权和），通过一个“倾斜槽”之后的第二个正态分布展示了子代的身高情况，比父代更加靠近中心。下方也有一个类似于钉板的装置，n
层钉板指的就是 n
代繁衍的过程，或者也可以指代一代繁衍中的其他影响身高的非基因因素，它们被视作独立同分布的，因此加和由中心极限定理可以被近似为正态分布。</p>
<p>图中还呈现出了父代中的一个小组“过钉板”后的结果，是一个小的正态分布。实际上子代的数据就是由一个一个小的正态分布叠加起来的，而正态分布可以线性相加，所以最后呈现出的还是正态分布。</p>
<p>好玄学，我也不知道我在说什么，甚至不是很确定自己理解对了没有。</p>
<p>Anyway，还是 think mathematically，记 <span class="math inline">\(X_i\)</span> 为第 <span class="math inline">\(i\)</span> 代的种群身高变化量，<span class="math inline">\(\lbrace X_i \rbrace\)</span>
是独立同分布的。则记父代种群的随机变量为 <span class="math inline">\(F=
\Sigma _{i=1} ^n X_i\)</span>，子代种群的随机变量为 <span class="math inline">\(S=
\Sigma_{i=1}^nX_i\)</span>，考虑二者的相关系数：</p>
<p><span class="math inline">\(\rho(F,S) =
\frac{cov(F,S)}{\sqrt{Var(F)Var(S)} } = \frac{Var(F) + Cov
(F,X_n)}{\sqrt{Var(F)Var(S)} }
=1+\frac{cov(F,X_n)}{Var(F)}&lt;1\)</span>，因此 <span class="math inline">\(\rho(F,X_n)&lt;0\)</span> 也即二者呈负相关。</p>
<h2 id="一些术语">一些术语</h2>
<ul>
<li><p>一般来说，我们把 <span class="math inline">\(X\)</span> 作为
predictor/input/explanatory variable，把 <span class="math inline">\(Y\)</span> 作为 response/output/dependent
variable。</p></li>
<li><p><span class="math inline">\(Y \sim X\)</span> 被称为 simple
regression，一元总归是简单的。</p>
<p><span class="math inline">\(Y \sim X_1,X_2,...,X_p\)</span> 称为
multiple/multivariate regression，实际上这两者是不一样的。</p>
<p>如果每个回归式中有超过一个 <span class="math inline">\(X\)</span>
就称为 multiple regression，如果有多个 <span class="math inline">\(Y\)</span> 就称为 multivariate
regression，并且每个式子里只能有一个不同的 dependent variable。</p>
<p>还有叫做 multivariate multiple regression 的回归方法，也就是用多个
<span class="math inline">\(X\)</span> 来预测多个 <span class="math inline">\(Y\)</span> 的情况，每个 <span class="math inline">\(Y\)</span> 出现在不同的式子里。</p></li>
<li><p>一般来说 <span class="math inline">\(Y\)</span>
是连续型随机变量，<span class="math inline">\(X\)</span>
可以是连续型、离散型或者分类型随机变量。有一些名词，不抄了，简单列一下：</p>
<p><img src="https://s2.loli.net/2023/02/26/iRyejXI6TuSvroJ.png" alt="regression.png"></p></li>
</ul>
<h1 id="lecture-2">Lecture 2</h1>
<h2 id="simple-linear-regression">Simple Linear Regression</h2>
<h3 id="数据的组织和表示">数据的组织和表示</h3>
<p>Simple linear regression 的数据一般是二元数据对 <span class="math inline">\((X_i , Y_i)\)</span>，每一对数据称为一个
case。数据集记作 <span class="math inline">\((X_1,Y_1),...,(X_n,Y_n)\)</span>，其中 <span class="math inline">\(X_i\)</span> 是 i-th observed explanatory
variable，<span class="math inline">\(Y_i\)</span> 是 i-th observed
response variable。</p>
<h3 id="模型的表示">模型的表示</h3>
<p><span class="math inline">\(Y_i = \beta_0 + \beta_1 X_i + \varepsilon
_i\)</span>，<span class="math inline">\(\varepsilon _i\)</span> 被称为
random error term，其中 <span class="math inline">\(\beta_0,\beta_1\)</span>
是参数。为了简化模型便于操作，需要对 random error term 做一些假设：</p>
<ul>
<li>均值为 <span class="math inline">\(E(\varepsilon_i) =
0\)</span>，方差为 <span class="math inline">\(Var(\varepsilon _i) =
\sigma ^2\)</span>，注意 <span class="math inline">\(\sigma\)</span>
是一个未知常数，也视作参数；</li>
<li>不同的 <span class="math inline">\(\varepsilon _i\)</span> 和 <span class="math inline">\(\varepsilon _j\)</span>
是不相关的。注意此处不需要不独立。</li>
</ul>
<p>对于更强的模型，例如 simple linear regression model with normal
error，我们直接要求 <span class="math inline">\(\varepsilon_1,...,\varepsilon_n i.i.d. \sim
N(0,\sigma^2)\)</span>（因为正态分布的不相关性和独立性等价）。这是一个很广泛的假设，但有时正态假设是明显有问题的，需要修正。</p>
<p>事实上，在 linear regression model 中，<span class="math inline">\(X_i\)</span> 和 <span class="math inline">\(Y_i\)</span> 的地位是不对等的。<span class="math inline">\(X_i\)</span> 被视为不带随机性的常数，而 <span class="math inline">\(Y_i\)</span> 因为 <span class="math inline">\(\varepsilon_i\)</span> 的存在是一个随机变量，有
<span class="math inline">\(E(Y_i) = \beta_0 + \beta_1
X_i\)</span>，<span class="math inline">\(Var(Y_i)=Var(\varepsilon_i) =
\sigma^2\)</span>。因此，回归线可以视作 <span class="math inline">\((X_i, E(Y_i))\)</span> 连成的直线，而数据点 <span class="math inline">\((X_i,Y_i)\)</span> 分布在回归线附近。</p>
<p>特别地，在正态假设下， 有 <span class="math inline">\(Y_i \sim
N(\beta_0 + \beta_1 X_i,\sigma^2)\)</span>，<span class="math inline">\(i=1,2,...,n\)</span>。</p>
<h3 id="参数的意义和求算">参数的意义和求算</h3>
<p>斜率 <span class="math inline">\(\beta_1\)</span> 的意义为 <span class="math inline">\(X_i\)</span> 增加 1 单位时 <span class="math inline">\(Y_i\)</span> 的变化量；截距 <span class="math inline">\(\beta_0\)</span> 的意义分两种情况解释，当 <span class="math inline">\(X_i\)</span> 取值范围中有 <span class="math inline">\(0\)</span> 时即为 <span class="math inline">\(X_i=0\)</span> 时的平均响应 <span class="math inline">\(E(Y_i)\)</span>，否则截距没有意义。</p>
<h4 id="least-sum-of-square-方法">Least Sum of Square 方法</h4>
<p>求算最佳参数实际上就是求使得 sum of squared diff 最小的 <span class="math inline">\(\hat{\beta_0},\hat{\beta_1}\)</span>，从而得到
<span class="math inline">\(Y_i\)</span> 的估计值 $= + X_i $。于是有
<span class="math inline">\(\hat{\beta_0},\hat{\beta_1} = \arg \min
_{\beta_0,\beta_1} \Sigma(Y_i - \beta_0 - \beta_1X_i)^2=\arg \min
_{\beta_0,\beta_1} \Sigma_{i=1 } ^n e_i
^2\)</span>。求导即可简单地得出：</p>
<p><span class="math display">\[b_1 = \hat{\beta_1} = \frac{\Sigma_i
(X_i - \bar{X})(Y_i - \bar{Y})}{\Sigma _i (X_i-\bar{X})^2}\]</span></p>
<p><span class="math display">\[b_0 = \hat{\beta_0} = \bar{Y} - b_1
\bar{X}\]</span></p>
<p>记残差为 <span class="math inline">\(e_i = Y_i - \hat{Y_i}= Y_i -
\hat{\beta_0} - \hat{\beta_1} X_i=\beta_0 + \beta_1X_i +\varepsilon _i -
\hat{\beta_0} - \hat{\beta_1}X_i \approx \varepsilon _i\)</span> ，也即
<span class="math inline">\(e_i\)</span> 为某一组 observed data <span class="math inline">\(Y_1,Y_2,...,Y_n\)</span> 之下得到的残差，但绝非
<span class="math inline">\(\varepsilon _i\)</span>
本身。残差是观测到的确定值，而 <span class="math inline">\(\varepsilon
_i\)</span> 是随机变量。</p>
<p>事实上求导的过程蕴含以下结论：</p>
<p><span class="math display">\[\Sigma _{i=1} ^n e_i=0\]</span></p>
<p><span class="math display">\[\Sigma _{i=1} ^{n} X_i e_i =
0\]</span></p>
<p>以上二式可以看做对 <span class="math inline">\(e_i\)</span>
的线性约束，<span class="math inline">\(\lbrace e_i \rbrace\)</span>
的自由度是 <span class="math inline">\(n-2\)</span>，互相之间不是独立的，这也是和 <span class="math inline">\(\lbrace \varepsilon _i \rbrace\)</span>
的差别之一。由此还可以得到一些其他性质，例如回归线必过 <span class="math inline">\((\bar{X},\bar{Y})\)</span>，不在此一一列举。</p>
<p>以上即为参数 <span class="math inline">\(\beta_0,\beta_1\)</span>
的估计方法。下面再考虑参数 <span class="math inline">\(\sigma\)</span>
的估计，使用残差 <span class="math inline">\(e_1,...,e_n\)</span>
来考虑。</p>
<p>取 <span class="math inline">\(\hat{\sigma ^2} = \frac{\Sigma _{i=1}
^n e_i ^2}{n-2}\)</span>。这是因为 <span class="math inline">\(e_1,e_2,...,e_n\)</span> 的 degree of
freedom（自由度） 记为 <span class="math inline">\(df_E =
n-2\)</span>，由此考虑 sum of square <span class="math inline">\(SSE=
\Sigma_{i=1} ^n (Y_i - \hat{Y_i})^2=\Sigma _{i=1} ^n e_i
^2\)</span>，定义 mean of squared errors <span class="math inline">\(MSE= \frac{SSE}{df_E} = \frac{\Sigma_{i=1}^n e_i
^2}{n-2}\)</span> 为 <span class="math inline">\(\hat{\sigma
^2}\)</span>。</p>
<h4 id="mle-方法">MLE 方法</h4>
<p>也可以用推断课上的 MLE 方法。实际上，我们想找到一个 <span class="math inline">\(\beta_0,\beta_1\)</span> 的最佳估计，还可以使用
MLE 方法进行估计。</p>
<p>在正态假设下，我们可以将 <span class="math inline">\(n\)</span>
组数据视作 <span class="math inline">\(n\)</span>
个互相独立的随机变量，取使得其likelihood function 最大的一组 <span class="math inline">\(\beta_-,\beta_1,\sigma^2\)</span>
作为估计量。likelihood function 即为 <span class="math inline">\(f(y_1,y_2,...,y_n) =
f_1(y_1)...f_n(y_n)\)</span>，得到的 estimator 中 <span class="math inline">\(\hat{\beta_0},\hat{\beta_1}\)</span> 与 least sum
of square 中得出的估计量相同，但 <span class="math inline">\(\hat{\sigma
^2} = \frac{\Sigma _{i=1} ^n e_i
^2}{n}\)</span>。注意这是一个有偏的估计量，而 least sum of square
得到的估计量是无偏的。</p>
<h2 id="推断复习">推断复习</h2>
<p>咕了。什么嘛，我推断学得还是可以的嘛（x</p>
<h1 id="附录">附录</h1>
<h2 id="常见重要分布">常见重要分布</h2>
<p>From <a target="_blank" rel="noopener" href="https://v1ncent19.github.io/SummaryNotes/">Statistic
Note</a> P10, by V1ncent19</p>
<table style="width:100%;">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(X\)</span></th>
<th><span class="math inline">\(p_X(k)\big/f_X(x)\)</span></th>
<th><span class="math inline">\(\mathbb{E}\)</span></th>
<th><span class="math inline">\(var\)</span></th>
<th>PGF</th>
<th>MGF</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\mathrm{Bern} (p)\)</span></td>
<td></td>
<td><span class="math inline">\(p\)</span></td>
<td><span class="math inline">\(pq\)</span></td>
<td></td>
<td><span class="math inline">\(q+pe^s\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(B (n,p)\)</span></td>
<td><span class="math inline">\(C_n^k p^k(1-p)^{n-k}\)</span></td>
<td><span class="math inline">\(np\)</span></td>
<td><span class="math inline">\(npq\)</span></td>
<td><span class="math inline">\((q+ps)^n\)</span></td>
<td><span class="math inline">\((q+pe^s)^n\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mathrm{Geo} (p)\)</span></td>
<td><span class="math inline">\((1-p)^{k-1}p\)</span></td>
<td><span class="math inline">\(\dfrac{1}{p}\)</span></td>
<td><span class="math inline">\(\dfrac{q}{p^2}\)</span></td>
<td><span class="math inline">\(\dfrac{ps}{1-qs}\)</span></td>
<td><span class="math inline">\(\dfrac{pe^s}{1-qe^s}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(H(n,M,N)\)</span></td>
<td><span class="math inline">\(\dfrac{C_M^kC_{N-M}^{n-k}}{C_N^n}\)</span></td>
<td><span class="math inline">\(n\dfrac{M}{N}\)</span></td>
<td><span class="math inline">\(\dfrac{nM(N-n)(N-M)}{N^2(n-1)}\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(P(\lambda)\)</span></td>
<td><span class="math inline">\(\dfrac{\lambda^k}{k!}e^{-\lambda}\)</span></td>
<td><span class="math inline">\(\lambda\)</span></td>
<td><span class="math inline">\(\lambda\)</span></td>
<td><span class="math inline">\(e^{\lambda(s-1)}\)</span></td>
<td><span class="math inline">\(e^{\lambda(e^s-1)}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(U(a,b)\)</span></td>
<td><span class="math inline">\(\dfrac{1}{b-a}\)</span></td>
<td><span class="math inline">\(\dfrac{a+b}{2}\)</span></td>
<td><span class="math inline">\(\dfrac{(b-a)^2}{12}\)</span></td>
<td></td>
<td><span class="math inline">\(\dfrac{e^{sb}-e^{sa}}{(b-a)^s}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(N(\mu,\sigma^2)\)</span></td>
<td><span class="math inline">\(\dfrac{1}{\sigma
\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\)</span></td>
<td><span class="math inline">\(\mu\)</span></td>
<td><span class="math inline">\(\sigma^2\)</span></td>
<td></td>
<td><span class="math inline">\(e^{\frac{\sigma^2s^2}{2}+\mu
s}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\epsilon(\lambda)\)</span></td>
<td><span class="math inline">\(\lambda e^{-\lambda x}\)</span></td>
<td><span class="math inline">\(\dfrac{1}{\lambda}\)</span></td>
<td><span class="math inline">\(\dfrac{1}{\lambda^2}\)</span></td>
<td></td>
<td><span class="math inline">\(\frac{\lambda}{\lambda-s}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\Gamma(\alpha,\lambda)\)</span></td>
<td><span class="math inline">\(\dfrac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda
x}\)</span></td>
<td><span class="math inline">\(\dfrac{\alpha}{\lambda}\)</span></td>
<td><span class="math inline">\(\dfrac{\alpha}{\lambda^2}\)</span></td>
<td></td>
<td>$()^<span class="math inline">\(| |\)</span>B(,)$</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\chi^2_n\)</span></td>
<td><span class="math inline">\(\dfrac{1}{2^{\frac{n}{2}}\Gamma(\frac{n}{2})}x^{\frac{n}{2}-1}e^{-\frac{x}{2}}\)</span></td>
<td><span class="math inline">\(n\)</span></td>
<td><span class="math inline">\(2n\)</span></td>
<td></td>
<td>$ (1-2s)^{-n/2} $</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(t_\nu\)</span></td>
<td><span class="math inline">\(\dfrac{\Gamma(\frac{\nu+1}{2})}{\sqrt{\nu\pi}\Gamma(\frac{\nu}{2})}(1+\frac{x^2}{\nu})^{-\frac{\nu+1}{2}}\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(\dfrac{\nu}{\nu-2}\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(F_{m,n}\)</span></td>
<td><span class="math inline">\(\dfrac{\Gamma(\frac{m+n}{2})}{\Gamma(\frac{m}{2})\Gamma(\frac{n}{2})}\dfrac{m^\frac{m}{2}n^\frac{n}{2}x^{\frac{m}{2}-1}}{(mx+n)^{\frac{m+n}{2}}}\)</span></td>
<td><span class="math inline">\(\dfrac{n}{n-2}\)</span></td>
<td><span class="math inline">\(\dfrac{2n^2(m+n-2)}{m(n-2)^2(n-4)}\)</span></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Consider <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>
i.i.d. <span class="math inline">\(\sim N(0,1)\)</span>; <span class="math inline">\(Y,Y_1,Y_2,\ldots,Y_m\)</span> i.i.d. <span class="math inline">\(\sim N(0,1)\)</span> - <span class="math inline">\(\chi^2\)</span> Distribution：</p>
<p><span class="math inline">\(\chi^2\)</span> distribution with degree
of freedom <span class="math inline">\(n\)</span>：$ =_{i=1}^n
X_i<sup>2</sup>2_n$。 For independent <span class="math inline">\(\xi_i\sim\chi^2_{n_i},\,
i=1,2,\ldots,k\)</span>：<span class="math inline">\(x_{i_0}=\sum_{i=1}^k\xi_i\sim\chi^2_{n_1+\ldots+n_k}\)</span></p>
<ul>
<li><p><span class="math inline">\(t\)</span> Distribution：</p>
<p><span class="math inline">\(t\)</span> distribution with degree of
freedom <span class="math inline">\(n\)</span>：$ T==t_n$</p>
<p>Upper <span class="math inline">\(\alpha\)</span>-fractile of <span class="math inline">\(t_\nu\)</span>, satisfies <span class="math inline">\(\mathbb{P}(T\geq
c)=\alpha\)</span>，$t_{,}=<em>{c}(Tc)=,Tt</em>$</p></li>
<li><p><span class="math inline">\(F\)</span> Distribution：</p>
<p><span class="math inline">\(F\)</span> distribution with degree of
freedom <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span>：$ F=F_{m,n}$</p>
<ul>
<li>If <span class="math inline">\(Z\sim F_{m,n}\)</span>, then <span class="math inline">\(\dfrac{1}{Z}\sim F_{n,m}\)</span>；</li>
<li>If <span class="math inline">\(T\sim t_n\)</span>, then <span class="math inline">\(T^2\sim F_{1,n}\)</span>；</li>
<li><span class="math inline">\(F_{m,n,1-\alpha}=\dfrac{1}{F_{n,m,\alpha}}\)</span>
。</li>
</ul></li>
</ul>
<p>Some useful lemmas in statistical inference：</p>
<ul>
<li><p>For <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>
independent with <span class="math inline">\(X_i\sim
N(\mu_i,\sigma^2_i)\)</span>, then <span class="math inline">\(\sum_{i=1}^n\left(\frac{X_i-\mu_i}{\sigma_i}\right)^2\sim
\chi^2_n\)</span></p></li>
<li><p>For <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>
i.i.d.<span class="math inline">\(\sim N(\mu,\sigma^2)\)</span>, then $
T=t_{n-1} $</p></li>
<li><p>For <span class="math inline">\(X_1,X_2,\ldots,X_m\)</span>
i.i.d.<span class="math inline">\(\sim N(\mu_1,\sigma^2)\)</span>, <span class="math inline">\(Y_1,Y_2,\ldots,Y_n\)</span> i.i.d.<span class="math inline">\(\sim N(\mu_2,\sigma^2)\)</span>,d enote sample
pooled variance <span class="math inline">\(S_{\omega}^2=\dfrac{(m-1)S^2_1+(n-1)S^2_2}{m+n-2}\)</span>,
then <span class="math inline">\(T=\frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}{S_{\omega}}\cdot
\sqrt{\frac{mn}{m+n}}\sim t_{m+n-2}\)</span></p></li>
<li><p>For <span class="math inline">\(X_1,X_2,\ldots,X_m\)</span>
i.i.d.<span class="math inline">\(\sim N(\mu,\sigma^2)\)</span>, <span class="math inline">\(Y_1,Y_2,\ldots,Y_n\)</span> i.i.d.<span class="math inline">\(\sim N(\mu_2,\sigma^2)\)</span>, then
$T=F_{m-1,n-1} $</p></li>
<li><p>For <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>
i.i.d. <span class="math inline">\(\sim \varepsilon(\lambda)\)</span>,
then $ 2n{X}=2<em>{i=1}^nX_i ^2</em>{2n} $</p>
<p>Remark：for <span class="math inline">\(X_i\sim\varepsilon(\lambda)=\Gamma(1,\lambda)\)</span>，<span class="math inline">\(2\lambda\sum_{i=1}^nX_i\sim\Gamma(n,1/2)=\chi^2_{2n}\)</span>.</p></li>
</ul>
<h2 id="分位数速查">分位数速查</h2>
<p>用 R 怎么算还没研究完，先放个分位数图算了。</p>

    </div>

    
    
    
        <div class="reward-container">
  <div>我很可爱 请给我钱（？）</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.jpg" alt="驰雨Chiyuru 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.jpg" alt="驰雨Chiyuru 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>驰雨Chiyuru
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://chiyuru.github.io/2023/02/21/Linear-Regression-Analysis/" title="还就那个线性回归分析">https://chiyuru.github.io/2023/02/21/Linear-Regression-Analysis/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E8%AF%BE%E7%A8%8B%E5%AE%9E%E5%BD%95/" rel="tag"># 课程实录</a>
              <a href="/tags/%E6%95%B0%E5%AD%A6/" rel="tag"># 数学</a>
              <a href="/tags/%E7%BB%9F%E8%AE%A1/" rel="tag"># 统计</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/02/01/Learn-Mathematical-Analysis-or-Die-2/" rel="prev" title="数学分析 I 速通日志（下）">
      <i class="fa fa-chevron-left"></i> 数学分析 I 速通日志（下）
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/02/25/Multivariate-Statistical-Analysis/" rel="next" title="多元问题对我来说太难了，但是多元统计分析">
      多元问题对我来说太难了，但是多元统计分析 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  
  <div class="comments">
  <script src="https://utteranc.es/client.js" repo="Chiyuru/chiyuru.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async></script>
  </div>
  
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-1"><span class="nav-text">Lecture 1</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#galtons-experiment"><span class="nav-text">Galton&#39;s Experiment</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E6%9C%AF%E8%AF%AD"><span class="nav-text">一些术语</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-2"><span class="nav-text">Lecture 2</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#simple-linear-regression"><span class="nav-text">Simple Linear Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E7%BB%84%E7%BB%87%E5%92%8C%E8%A1%A8%E7%A4%BA"><span class="nav-text">数据的组织和表示</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%A4%BA"><span class="nav-text">模型的表示</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E7%9A%84%E6%84%8F%E4%B9%89%E5%92%8C%E6%B1%82%E7%AE%97"><span class="nav-text">参数的意义和求算</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#least-sum-of-square-%E6%96%B9%E6%B3%95"><span class="nav-text">Least Sum of Square 方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mle-%E6%96%B9%E6%B3%95"><span class="nav-text">MLE 方法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8E%A8%E6%96%AD%E5%A4%8D%E4%B9%A0"><span class="nav-text">推断复习</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%99%84%E5%BD%95"><span class="nav-text">附录</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E9%87%8D%E8%A6%81%E5%88%86%E5%B8%83"><span class="nav-text">常见重要分布</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E4%BD%8D%E6%95%B0%E9%80%9F%E6%9F%A5"><span class="nav-text">分位数速查</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="驰雨Chiyuru"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">驰雨Chiyuru</p>
  <div class="site-description" itemprop="description">おはよう、朝だよ</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">26</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Chiyuru" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Chiyuru" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:mafy21@mails.tsinghua.edu.cn" title="E-Mail → mailto:mafy21@mails.tsinghua.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/Chiyuru_0417" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;Chiyuru_0417" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/ma-fei-yan-33" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;ma-fei-yan-33" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>知乎</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright">
  
  &copy; 2022 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">驰雨Chiyuru</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv1">
  本站总访客数：<span id="busuanzi_value_site_uv"></span>
</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":-15,"vOffset":-15},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
