<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"chiyuru.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="本来真没打算连载这个，结果这课居然把课程笔记算成百分制里面的 10 分（，那就写罢。 有参考 Vica Yang 的统辅笔记，JhZhang 的课堂笔记和 V1ncent19 的统辅笔记，如有引用均会在文中注明，在此向前辈表示感谢。">
<meta property="og:type" content="article">
<meta property="og:title" content="还就那个线性回归分析">
<meta property="og:url" content="https://chiyuru.github.io/2023/02/21/Linear-Regression-Analysis/index.html">
<meta property="og:site_name" content="『姑妄言之姑妄听之』">
<meta property="og:description" content="本来真没打算连载这个，结果这课居然把课程笔记算成百分制里面的 10 分（，那就写罢。 有参考 Vica Yang 的统辅笔记，JhZhang 的课堂笔记和 V1ncent19 的统辅笔记，如有引用均会在文中注明，在此向前辈表示感谢。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/02/26/AHxRkaSBD87fW3V.png">
<meta property="og:image" content="https://s2.loli.net/2023/02/26/iRyejXI6TuSvroJ.png">
<meta property="og:image" content="https://s2.loli.net/2023/03/16/XO3Bt8FehprNz5q.png">
<meta property="og:image" content="https://s2.loli.net/2023/03/16/3tpYiuFSd7Xw2vK.png">
<meta property="article:published_time" content="2023-02-21T11:12:18.000Z">
<meta property="article:modified_time" content="2023-03-23T14:20:32.175Z">
<meta property="article:author" content="驰雨Chiyuru">
<meta property="article:tag" content="课程实录">
<meta property="article:tag" content="统计">
<meta property="article:tag" content="数学">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/02/26/AHxRkaSBD87fW3V.png">

<link rel="canonical" href="https://chiyuru.github.io/2023/02/21/Linear-Regression-Analysis/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>还就那个线性回归分析 | 『姑妄言之姑妄听之』</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="『姑妄言之姑妄听之』" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">『姑妄言之姑妄听之』</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chiyuru.github.io/2023/02/21/Linear-Regression-Analysis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="驰雨Chiyuru">
      <meta itemprop="description" content="おはよう、朝だよ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="『姑妄言之姑妄听之』">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          还就那个线性回归分析
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-02-21 19:12:18" itemprop="dateCreated datePublished" datetime="2023-02-21T19:12:18+08:00">2023-02-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-03-23 22:20:32" itemprop="dateModified" datetime="2023-03-23T22:20:32+08:00">2023-03-23</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>本来真没打算连载这个，结果这课居然把课程笔记算成百分制里面的 10
分（，那就写罢。</p>
<p>有参考 <a target="_blank" rel="noopener" href="https://blog.vicayang.cc/tags/statistics/">Vica Yang
的统辅笔记</a>，<a target="_blank" rel="noopener" href="https://www.zhihu.com/column/c_1332050772843511808">JhZhang
的课堂笔记</a>和 <a target="_blank" rel="noopener" href="https://v1ncent19.github.io/SummaryNotes/">V1ncent19
的统辅笔记</a>，如有引用均会在文中注明，在此向前辈表示感谢。</p>
<span id="more"></span>
<h1 id="lecture-1">Lecture 1</h1>
<p>主要是在吹水，开玩笑以及活跃气氛。正经的内容大概就一个古老的回归现象，我还没有听得很懂，麻了。</p>
<h2 id="galtons-experiment">Galton's Experiment</h2>
<p>以下全是胡说八道，不能保证完全对。</p>
<p>介绍正态分布的时候会有一个很经典的小球过钉板的演示实验，最后落在底部的球似乎呈现出一个正态分布。但实际上球和钉子的每次碰撞都是一个
Bernoulli 过程，过了 n 层钉板就是 n 次 Bernoulli
过程加和，可以近似为正态分布。实际上只要 n
够大，由中心极限定理任何分布的加和都可以被近似为正态分布。</p>
<p>但我觉得实际上小球的情况并不是独立的，毕竟过程中会有相互的碰撞，真的没问题吗（</p>
<p>回归现象的起源是 Galton
对于父代和子代的身高做了一个统计，发现身高远离均值的父母的后代往往身高会比他们更接近平均水平，也就是某一身高水平的父母的孩子的身高中位数作为因变量，父母身高作为自变量时，拟合出的直线的斜率小于
<span class="math inline">\(1\)</span>。</p>
<p>假设不发生回归现象，则和钉板现象一样，后代的性状会逐渐分散，这被认为是一个种群稳定性状的方式。听起来很玄学，似乎也有一个稍微合理的生物学解释了，但我们希望从统计学的角度分析这件事，背后是存在数学规律的。</p>
<p><img src="https://s2.loli.net/2023/02/26/AHxRkaSBD87fW3V.png" alt="Galton.png"></p>
<p>上图是课程中反复出现的一张图，对此做了很多解释。最上面的正态分布是父代的身高情况（实际上是父母身高的加权和），通过一个“倾斜槽”之后的第二个正态分布展示了子代的身高情况，比父代更加靠近中心。下方也有一个类似于钉板的装置，n
层钉板指的就是 n
代繁衍的过程，或者也可以指代一代繁衍中的其他影响身高的非基因因素，它们被视作独立同分布的，因此加和由中心极限定理可以被近似为正态分布。</p>
<p>图中还呈现出了父代中的一个小组“过钉板”后的结果，是一个小的正态分布。实际上子代的数据就是由一个一个小的正态分布叠加起来的，而正态分布可以线性相加，所以最后呈现出的还是正态分布。</p>
<p>好玄学，我也不知道我在说什么，甚至不是很确定自己理解对了没有。</p>
<p>Anyway，还是 think mathematically，记 <span class="math inline">\(X_i\)</span> 为第 <span class="math inline">\(i\)</span> 代的种群身高变化量，<span class="math inline">\(\lbrace X_i \rbrace\)</span>
是独立同分布的。则记父代种群的随机变量为 <span class="math inline">\(F=
\Sigma _{i=1} ^n X_i\)</span>，子代种群的随机变量为 <span class="math inline">\(S=
\Sigma_{i=1}^nX_i\)</span>，考虑二者的相关系数：</p>
<p><span class="math inline">\(\rho(F,S) =
\frac{cov(F,S)}{\sqrt{Var(F)Var(S)} } = \frac{Var(F) + Cov
(F,X_n)}{\sqrt{Var(F)Var(S)} }
=1+\frac{cov(F,X_n)}{Var(F)}&lt;1\)</span>，因此 <span class="math inline">\(\rho(F,X_n)&lt;0\)</span> 也即二者呈负相关。</p>
<h2 id="一些术语">一些术语</h2>
<ul>
<li><p>一般来说，我们把 <span class="math inline">\(X\)</span> 作为
predictor/input/explanatory variable，把 <span class="math inline">\(Y\)</span> 作为 response/output/dependent
variable。</p></li>
<li><p><span class="math inline">\(Y \sim X\)</span> 被称为 simple
regression，一元总归是简单的。</p>
<p><span class="math inline">\(Y \sim X_1,X_2,...,X_p\)</span> 称为
multiple/multivariate regression，实际上这两者是不一样的。</p>
<p>如果每个回归式中有超过一个 <span class="math inline">\(X\)</span>
就称为 multiple regression，如果有多个 <span class="math inline">\(Y\)</span> 就称为 multivariate
regression，并且每个式子里只能有一个不同的 dependent variable。</p>
<p>还有叫做 multivariate multiple regression 的回归方法，也就是用多个
<span class="math inline">\(X\)</span> 来预测多个 <span class="math inline">\(Y\)</span> 的情况，每个 <span class="math inline">\(Y\)</span> 出现在不同的式子里。</p></li>
<li><p>一般来说 <span class="math inline">\(Y\)</span>
是连续型随机变量，<span class="math inline">\(X\)</span>
可以是连续型、离散型或者分类型随机变量。有一些名词，不抄了，简单列一下：</p>
<p><img src="https://s2.loli.net/2023/02/26/iRyejXI6TuSvroJ.png" alt="regression.png"></p></li>
</ul>
<h1 id="lecture-2">Lecture 2</h1>
<h2 id="simple-linear-regression">Simple Linear Regression</h2>
<h3 id="数据的组织和表示">数据的组织和表示</h3>
<p>Simple linear regression 的数据一般是二元数据对 <span class="math inline">\((X_i , Y_i)\)</span>，每一对数据称为一个
case。数据集记作 <span class="math inline">\((X_1,Y_1),...,(X_n,Y_n)\)</span>，其中 <span class="math inline">\(X_i\)</span> 是 i-th observed explanatory
variable，<span class="math inline">\(Y_i\)</span> 是 i-th observed
response variable。</p>
<h3 id="模型的表示">模型的表示</h3>
<p><span class="math inline">\(Y_i = \beta_0 + \beta_1 X_i + \varepsilon
_i\)</span>，<span class="math inline">\(\varepsilon _i\)</span> 被称为
random error term，其中 <span class="math inline">\(\beta_0,\beta_1\)</span>
是参数。为了简化模型便于操作，需要对 random error term 做一些假设：</p>
<ul>
<li>均值为 <span class="math inline">\(E(\varepsilon_i) =
0\)</span>，方差为 <span class="math inline">\(Var(\varepsilon _i) =
\sigma ^2\)</span>，注意 <span class="math inline">\(\sigma\)</span>
是一个未知常数，也视作参数；</li>
<li>不同的 <span class="math inline">\(\varepsilon _i\)</span> 和 <span class="math inline">\(\varepsilon _j\)</span>
是不相关的。注意此处不需要不独立。</li>
</ul>
<p>对于更强的模型，例如 simple linear regression model with normal
error，我们直接要求 <span class="math inline">\(\varepsilon_1,...,\varepsilon_n i.i.d. \sim
N(0,\sigma^2)\)</span>（因为正态分布的不相关性和独立性等价）。这是一个很广泛的假设，但有时正态假设是明显有问题的，需要修正。</p>
<p>事实上，在 linear regression model 中，<span class="math inline">\(X_i\)</span> 和 <span class="math inline">\(Y_i\)</span> 的地位是不对等的。<span class="math inline">\(X_i\)</span> 被视为不带随机性的常数，而 <span class="math inline">\(Y_i\)</span> 因为 <span class="math inline">\(\varepsilon_i\)</span> 的存在是一个随机变量，有
<span class="math inline">\(E(Y_i) = \beta_0 + \beta_1
X_i\)</span>，<span class="math inline">\(Var(Y_i)=Var(\varepsilon_i) =
\sigma^2\)</span>。因此，回归线可以视作 <span class="math inline">\((X_i, E(Y_i))\)</span> 连成的直线，而数据点 <span class="math inline">\((X_i,Y_i)\)</span> 分布在回归线附近。</p>
<p>特别地，在正态假设下， 有 <span class="math inline">\(Y_i \sim
N(\beta_0 + \beta_1 X_i,\sigma^2)\)</span>，<span class="math inline">\(i=1,2,...,n\)</span>。</p>
<h3 id="参数的意义和求算">参数的意义和求算</h3>
<p>斜率 <span class="math inline">\(\beta_1\)</span> 的意义为 <span class="math inline">\(X_i\)</span> 增加 1 单位时 <span class="math inline">\(Y_i\)</span> 的变化量；截距 <span class="math inline">\(\beta_0\)</span> 的意义分两种情况解释，当 <span class="math inline">\(X_i\)</span> 取值范围中有 <span class="math inline">\(0\)</span> 时即为 <span class="math inline">\(X_i=0\)</span> 时的平均响应 <span class="math inline">\(E(Y_i)\)</span>，否则截距没有意义。</p>
<h4 id="least-sum-of-square-方法">Least Sum of Square 方法</h4>
<p>求算最佳参数实际上就是求使得 sum of squared diff 最小的 <span class="math inline">\(\hat{\beta_0},\hat{\beta_1}\)</span>，从而得到
<span class="math inline">\(Y_i\)</span> 的估计值 $= + X_i $。于是有
<span class="math inline">\(\hat{\beta_0},\hat{\beta_1} = \arg \min
_{\beta_0,\beta_1} \Sigma(Y_i - \beta_0 - \beta_1X_i)^2=\arg \min
_{\beta_0,\beta_1} \Sigma_{i=1 } ^n e_i
^2\)</span>。求导即可简单地得出：</p>
<p><span class="math display">\[b_1 = \hat{\beta_1} = \frac{\Sigma_i
(X_i - \bar{X})(Y_i - \bar{Y})}{\Sigma _i (X_i-\bar{X})^2}\]</span></p>
<p><span class="math display">\[b_0 = \hat{\beta_0} = \bar{Y} - b_1
\bar{X}\]</span></p>
<p>记残差为 <span class="math inline">\(e_i = Y_i - \hat{Y_i}= Y_i -
\hat{\beta_0} - \hat{\beta_1} X_i=\beta_0 + \beta_1X_i +\varepsilon _i -
\hat{\beta_0} - \hat{\beta_1}X_i \approx \varepsilon _i\)</span> ，也即
<span class="math inline">\(e_i\)</span> 为某一组 observed data <span class="math inline">\(Y_1,Y_2,...,Y_n\)</span> 之下得到的残差，但绝非
<span class="math inline">\(\varepsilon _i\)</span>
本身。残差是观测到的确定值，而 <span class="math inline">\(\varepsilon
_i\)</span> 是随机变量。</p>
<p>事实上求导的过程蕴含以下结论：</p>
<p><span class="math display">\[\Sigma _{i=1} ^n e_i=0\]</span></p>
<p><span class="math display">\[\Sigma _{i=1} ^{n} X_i e_i =
0\]</span></p>
<p>以上二式可以看做对 <span class="math inline">\(e_i\)</span>
的线性约束，<span class="math inline">\(\lbrace e_i \rbrace\)</span>
的自由度是 <span class="math inline">\(n-2\)</span>，互相之间不是独立的，这也是和 <span class="math inline">\(\lbrace \varepsilon _i \rbrace\)</span>
的差别之一。由此还可以得到一些其他性质，例如回归线必过 <span class="math inline">\((\bar{X},\bar{Y})\)</span>，不在此一一列举。</p>
<p>以上即为参数 <span class="math inline">\(\beta_0,\beta_1\)</span>
的估计方法。下面再考虑参数 <span class="math inline">\(\sigma\)</span>
的估计，使用残差 <span class="math inline">\(e_1,...,e_n\)</span>
来考虑。</p>
<p>取 <span class="math inline">\(\hat{\sigma ^2} = \frac{\Sigma _{i=1}
^n e_i ^2}{n-2}\)</span>。这是因为 <span class="math inline">\(e_1,e_2,...,e_n\)</span> 的 degree of
freedom（自由度） 记为 <span class="math inline">\(df_E =
n-2\)</span>，由此考虑 sum of square <span class="math inline">\(SSE=
\Sigma_{i=1} ^n (Y_i - \hat{Y_i})^2=\Sigma _{i=1} ^n e_i
^2\)</span>，定义 mean of squared errors <span class="math inline">\(MSE= \frac{SSE}{df_E} = \frac{\Sigma_{i=1}^n e_i
^2}{n-2}\)</span> 为 <span class="math inline">\(\hat{\sigma
^2}\)</span>。</p>
<h4 id="mle-方法">MLE 方法</h4>
<p>也可以用推断课上的 MLE 方法。实际上，我们想找到一个 <span class="math inline">\(\beta_0,\beta_1\)</span> 的最佳估计，还可以使用
MLE 方法进行估计。</p>
<p>在正态假设下，我们可以将 <span class="math inline">\(n\)</span>
组数据视作 <span class="math inline">\(n\)</span>
个互相独立的随机变量，取使得其likelihood function 最大的一组 <span class="math inline">\(\beta_-,\beta_1,\sigma^2\)</span>
作为估计量。likelihood function 即为 <span class="math inline">\(f(y_1,y_2,...,y_n) =
f_1(y_1)...f_n(y_n)\)</span>，得到的 estimator 中 <span class="math inline">\(\hat{\beta_0},\hat{\beta_1}\)</span> 与 least sum
of square 中得出的估计量相同，但 <span class="math inline">\(\hat{\sigma
^2} = \frac{\Sigma _{i=1} ^n e_i
^2}{n}\)</span>。注意这是一个有偏的估计量，而 least sum of square
得到的估计量是无偏的。</p>
<h2 id="推断复习">推断复习</h2>
<p>咕了。什么嘛，我推断学得还是可以的嘛（x</p>
<h1 id="lecture-3">Lecture 3</h1>
<h2 id="线性回归中的推断">线性回归中的推断</h2>
<p>回顾一下，无论是 OLS 方法还是 MLE 方法，我们得到的参数估计 <span class="math inline">\(b_0\)</span>,<span class="math inline">\(b_1\)</span> 都是相同的：</p>
<p><span class="math display">\[b_1 = \hat{\beta_1} = \frac{\Sigma_i
(X_i - \bar{X})(Y_i - \bar{Y})}{\Sigma _i (X_i-\bar{X})^2}\]</span></p>
<p><span class="math display">\[b_0 = \hat{\beta_0} = \bar{Y} - b_1
\bar{X}\]</span></p>
<p>通过简单的计算可以知道：</p>
<p><span class="math display">\[E(b_1) = \beta_1,Var(b_1) ={\sigma^2
\over S_{XX}},s^2(b_1) = \frac{s^2}{S_{XX}}\]</span>，</p>
<p>其中 <span class="math inline">\(S_{XX} = \Sigma_{i=1} ^n (X_i -
\bar{X})^2\)</span>, <span class="math inline">\(s^2 = \hat{\sigma}^2 =
\frac{\Sigma_{i=1}^n e_i^2}{n-2}\)</span>。</p>
<h3 id="参数推断">参数推断</h3>
<ul>
<li><p>对 <span class="math inline">\(\beta_1\)</span> 进行推断：null
hypothesis 为 <span class="math inline">\(H_0: \beta_1
=0\)</span>，这样设置是因为关心两个变量之间是否存在线性关系。</p>
<p>在假设 <span class="math inline">\(H_0\)</span> 下可以考虑 test
statistic 为 <span class="math inline">\(T= \frac{b_1 -0}{s(b_1)} \sim
t_{n-2}\)</span>，这是因为 <span class="math inline">\(H_0\)</span>
假设下 <span class="math inline">\(b_1-0 \sim
N(0,\frac{\sigma}{\sqrt{Sxx}})\)</span>，我们一般用 <span class="math inline">\(\sigma\)</span> 的无偏估计 <span class="math inline">\(\hat{\sigma} = \sqrt{\frac{\Sigma_{i=1}^n e_i
^2}{n-2}}\)</span> 来处理。</p>
<p>level of significance 为 <span class="math inline">\(\alpha\)</span>，于是当 observed data <span class="math inline">\(t_0\)</span> 满足 <span class="math inline">\(|t_0| &gt; t_{n-2,1-\alpha /2}\)</span> 时 reject
<span class="math inline">\(H_0\)</span>。</p>
<p>如果没有拒绝 <span class="math inline">\(H_0\)</span>，通常的可能有以下三种：</p>
<ul>
<li>发生了 Type II Error，没有成功拒绝掉 <span class="math inline">\(H_0\)</span> 而事实相反；</li>
<li><span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span> 之间确实没有什么线性关系；</li>
<li><span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span> 之间有关系，但是非线性。（这句话原来的
typo 是“有线性关系，但是非线性”，绷不住了，中午被 Photon
指出来了，非常感谢他）</li>
</ul></li>
<li><p>对 <span class="math inline">\(\beta_1\)</span> 做 confidence
interval：由于在 <span class="math inline">\(\beta_1\)</span>
代表斜率的情况下，有 <span class="math inline">\(\frac{b_1 -
\beta_1}{s(b_1)} \sim^{H_0} t_{n-2}\)</span>。</p>
<p>于是 <span class="math inline">\(P(\frac{|b_1-\beta_1|}{s(b_1)} &lt;
t_{n-2,1-\alpha /2}) = 1-\alpha\)</span>，<span class="math inline">\(\beta_1\)</span> 的 100%<span class="math inline">\((1-\alpha)\)</span> confidence interval 是</p>
<p><span class="math display">\[(b_1 - t_{n-2,1-\alpha /2} s(b_1),b_1 +
t_{n-2,1-\alpha /2} s(b_1))\]</span></p></li>
<li><p>类似地可以对 <span class="math inline">\(\beta_0\)</span>
做推断，有 <span class="math inline">\(\frac{b_0 -\beta_0}{s(b_0)} \sim
t_{n-2}\)</span>，因此如果 null hypothesis 为 <span class="math inline">\(H_0: \beta_0 =0\)</span>，rejection region
即为满足条件 $ &gt; t_{n-2,1-/2} $ 的数据。对于偏移的 null hypothesis
<span class="math inline">\(H_0 : \beta_0 =c\)</span>，也只要相应地移动
rejection region 即可。</p>
<p>100%<span class="math inline">\((1-\alpha)\)</span> confidence
interval 为 <span class="math inline">\((b_0 - t_{n-2,1-\alpha /2}
s(b_0),b_0 + t_{n-2,1-\alpha /2} s(b_0))\)</span>。</p>
<p>实际上我们一般对 <span class="math inline">\(\beta_0\)</span>
的推断不感兴趣，因为这个参数未必有意义，依赖于 <span class="math inline">\(X\)</span> 的取值范围。</p></li>
<li><p>以上都是对单个参数进行推断，实际上我们也可以进行 joint
inference：</p>
<p>同时推断两个参数 <span class="math inline">\((\beta_0,\beta_1)\)</span>，这时候得到的就是
confidence region，使得 <span class="math inline">\(P((\beta_0,\beta_1)
\in S \subset \mathbb R^2) = 100(1-\alpha) \%\)</span>。实际上因为 <span class="math inline">\((b_0 , b_1) ^T \sim N((\beta_0,\beta_1)^T ,
\sigma^2 \Sigma_{2\times 2})\)</span>，所以最小的 confidence region
是一个椭圆。</p>
<p>实际上我们也可以考虑做一个矩形的 confidence
region，也即对两个参数分别作 confidence interval，confidence coefficient
分别为 <span class="math inline">\(\sqrt{1-\alpha} \approx
1-\frac{\alpha}{2}\)</span>。因此 confidence region 为：</p>
<p><span class="math display">\[ (b_1 - t_{n-2,1-\alpha /4} s(b_1),b_1 +
t_{n-2,1-\alpha /4} s(b_1)) \times (b_0 - t_{n-2,1-\alpha /4} s(b_0),b_0
+ t_{n-2,1-\alpha /4} s(b_0))\]</span></p></li>
</ul>
<h3 id="power-function">Power Function</h3>
<p>一个 significance test 的 power 指的是 reject <span class="math inline">\(H_0\)</span> 时 <span class="math inline">\(H_1\)</span> 是正确的的概率，也就是 <span class="math inline">\(1-P(\)</span>Type II Error<span class="math inline">\()\)</span>。实际上一个推断是好的的情况下需要既不
over-powered 也不 under powered，这和 Type I Error 与 Type II Error
此消彼长的性质有关。</p>
<p>Power function 一般是一个关于参数的函数。以推断 <span class="math inline">\(\beta_1\)</span> 的过程为例，计算这一推断的 power
function。</p>
<ul>
<li><p>我们在线性回归参数推断里会用到一种非中心化 t-分布。普通的
t-分布是关于 <span class="math inline">\(x=0\)</span> 对称的，非中心化
t-分布有一定的偏差。注意并不是整体在坐标轴方向上的移动，其形状也发生了变化。表达式为
<span class="math inline">\(t(df, \delta ) = \frac{N(0,1) +
\delta}{\sqrt{\chi_{df} / df}}\)</span>。</p></li>
<li><p>对 <span class="math inline">\(\beta_1\)</span> 进行推断：null
hypothesis 为 <span class="math inline">\(H_0: \beta_1
=0\)</span>，这样设置是因为关心两个变量之间是否存在线性关系。</p>
<p>在假设 <span class="math inline">\(H_0\)</span> 下可以考虑 test
statistic 为 <span class="math inline">\(T= \frac{b_1 -0}{s(b_1)} \sim
t_{n-2}\)</span>，然而在 <span class="math inline">\(H_1\)</span>
下,</p>
<p><span class="math display">\[T=\frac{b_1}{s(b_1)} = \frac{b_1 -
\beta_1 + \beta_1}{s(b_1)} = \frac{b_1-\beta_1}{s(b_1)} + \frac{\beta_1
/ \sigma(b_1)}{s(b_1)/\sigma(b_1)} =  \frac{N(0,1) +
\delta}{\sqrt{\chi_{df} / df}} \sim
t(n-2,\beta_1/\sigma(b_1))\]</span></p>
<p>于是 <span class="math inline">\(Power(\beta_1) = P(Reject H_0 | H_1
holds) = P(|T| &gt; t_{n-2,1-\alpha /2} | \beta_1 \neq 0) =
P(T&lt;t_{n-2,\alpha /2}) +1-P(T&lt;t_{n-2,1-\alpha
/2})\)</span>，其中在 <span class="math inline">\(\beta_1 \neq
0\)</span> 的条件下，<span class="math inline">\(T\sim t(n-2,\beta_1 /
\sigma(b_1))\)</span>。</p></li>
<li><p>Remark：上述形式更方便代码实现，因为 <code>pt</code>
函数里可以直接给出非中心化参数来计算函数值。上个学期推断课上使用 power
function 时对上式的计算采用以下的方式：</p>
<p><span class="math display">\[\begin{aligned} Power(\beta_1) &amp;=
P(\frac{b_1-\beta_1}{s(b_1)}&gt; t_{n-2,1-\alpha /2}-\frac{\beta_1 /
\sigma(b_1)}{s(b_1)/\sigma(b_1)})+P(\frac{b_1-\beta_1}{s(b_1)}&lt;
t_{n-2,\alpha /2}-\frac{\beta_1 / \sigma(b_1)}{s(b_1)/\sigma(b_1)}) \\
&amp;=1-P(\frac{b_1-\beta_1}{s(b_1)}&lt; t_{n-2,1-\alpha
/2}-\frac{\beta_1 /
\sigma(b_1)}{s(b_1)/\sigma(b_1)})+P(\frac{b_1-\beta_1}{s(b_1)}&lt;
t_{n-2,\alpha /2}-\frac{\beta_1 / \sigma(b_1)}{s(b_1)/\sigma(b_1)})
\\&amp;=1-F(t_{n-2,1-\alpha /2}-\frac{\beta_1 /
\sigma(b_1)}{s(b_1)/\sigma(b_1)}) + F( t_{n-2,\alpha /2}-\frac{\beta_1 /
\sigma(b_1)}{s(b_1)/\sigma(b_1)})  \end{aligned}\]</span></p>
<p>其中，<span class="math inline">\(\frac{b_1-\beta_1 }{s(b_1)} \sim
t_{n-2}\)</span>，<span class="math inline">\(F\)</span> 是 <span class="math inline">\(t_{n-2}\)</span> 的 CDF 函数。</p>
<p>这个形式太过复杂了。</p></li>
</ul>
<h2 id="blue">BLUE</h2>
<p><a target="_blank" rel="noopener" href="https://record.umich.edu/articles/origins-go-blue/">Go Blue
!</a>（</p>
<p>简单来说，OLS Estimators 是 the best linear unbiased estimator，简称
OLS estimators 是 BLUE。best 的意思是方差最小，这是不难证明的。</p>
<p>BLUE 是非常好的性质，也希望我以后能 go blue（逃</p>
<h1 id="lecture-4">Lecture 4</h1>
<p>Prediction &amp; ANOVA，感谢 zzy 救我的生统概论（</p>
<h2 id="estimation-prediction">Estimation &amp; Prediction</h2>
<h3 id="平均响应的推断">平均响应的推断</h3>
<p>有了线性回归模型之后当然是要用来做预测，通过已有数据拟合出一个线性模型，再用来估计未知点的值。对于需要估计的点
<span class="math inline">\(X_h\)</span>，一般来说估计值都是考虑平均响应
(mean response) <span class="math inline">\(\mu_h = E(Y_h) = \beta_0
+\beta_1 X_h\)</span>，把 <span class="math inline">\(\hat{\mu_h} = b_0
+ b_1 X_h\)</span> 作为 <span class="math inline">\(\mu_h\)</span>
的估计。这是一个
estimator，既然如此就要考虑它的性质，也要先考虑平均响应的置信区间。</p>
<ul>
<li><p><span class="math inline">\(E(\hat{\mu_h}) = E(b_0) + E(b_1)X_h =
\beta_0 + \beta_1 X_h = \mu_h\)</span> ，是 unbiased estimator</p></li>
<li><p><span class="math inline">\(Var(\hat{\mu_h}) = Var(\bar{Y}+
b_1(X_h - \bar{X})) = \sigma^2 [\frac{1}{n} + \frac{(X_h -
\bar{X})^2}{\Sigma (X_i -\bar{X})^2}]\)</span> ，是 minimum
variance</p></li>
<li><p><span class="math inline">\(\hat{\mu_h} = \bar{Y} + (X_h -
\bar{X}) b_1\)</span>，由于 <span class="math inline">\(\bar{Y}\)</span>
和 <span class="math inline">\(b_1\)</span> 都有正态假设，因此 <span class="math inline">\(\hat{\mu_h}\)</span> 也服从正态分布，<span class="math inline">\(\hat{\mu_h} \sim N(\mu_h ,
Var(\hat{\mu_h}))\)</span>。</p></li>
<li><p><span class="math inline">\(Var(\hat{\mu_h})\)</span> 的估计量是
<span class="math inline">\(s^2(\hat{\mu_h}) = s^2[\frac 1 n +
\frac{(X_h-\bar{X})^2}{\Sigma(X_i - \bar{X})^2}]\)</span>，于是有 <span class="math inline">\(\frac{\hat{\mu_h} - \mu_h}{s(\hat{\mu_h})} \sim
t_{n-2}\)</span>。</p>
<p>因此，<span class="math inline">\(\mu_h\)</span> 的 <span class="math inline">\(100 \% (1-\alpha)\)</span> confidence interval 是
<span class="math inline">\((\hat{\mu_h} - t_{n-2, 1-\alpha /2}
s(\hat{\mu_h}),\hat{\mu_h} + t_{n-2, 1-\alpha /2}
s(\hat{\mu_h}))\)</span>。confidence interval 的长度为 $2t_{n-2, 1-/2}
s() = 2t_{n-2, 1-/2} s $，其中 <span class="math inline">\(s =
\sqrt{[\frac{\Sigma_{i=1}^n
e_i^2}{n-2}]}\)</span>。因此置信区间的长度是近似于随 <span class="math inline">\(X_h - \bar{X}\)</span>
递增而递增的。也就是说，<span class="math inline">\(X_h\)</span> 距离
<span class="math inline">\(\bar{X}\)</span>
越远，置信区间的长度越大，准确性越难保证。</p>
<p>综上，我们成功找到了这个对于 <span class="math inline">\(\mu_h\)</span> 的估计的置信区间。</p></li>
</ul>
<h3 id="预测值的推断">预测值的推断</h3>
<p>把平均响应 <span class="math inline">\(E(Y_h | X_h = x_h)\)</span>
作为 <span class="math inline">\(Y_h\)</span>
的预测值不够精准，我们希望做一个改进：<span class="math inline">\(Y_{h(new)} = \beta_0 + \beta_1 X_h
+\varepsilon\)</span> 且有 <span class="math inline">\(E(\varepsilon) =
0,Var(\varepsilon) = \sigma^2\)</span>。注意这里 <span class="math inline">\(\varepsilon\)</span> 是随机变量，<span class="math inline">\(\beta_0,\beta_1\)</span> 是未知值的参数，<span class="math inline">\(X_h\)</span> 是已知的常数。</p>
<p>对它做估计 <span class="math inline">\(\hat{Y}_{h(new)} = \hat{\mu_h}
= b_0+b_1 X_h\)</span>，考虑这个估计的性质。</p>
<ul>
<li><p><span class="math inline">\(E(\hat{Y}_{h(new)}) = E(b_0 + b_1
X_h) = \beta_0 + \beta_1 X_h\)</span></p></li>
<li><p>从简单的情形开始，如果 <span class="math inline">\(\beta_0,\beta_1,\sigma\)</span>
都是已知的参数，则在正态假设下 <span class="math inline">\(\frac{Y_{h(new)} -E(Y_h)}{\sigma}\sim
N(0,1)\)</span>（非正态假设情况下服从未知分布），<span class="math inline">\(Y_{h(new)}\)</span> 的 confidence interval 是
<span class="math inline">\((E(Y_h) - z_{1-\alpha /2} \sigma,E(Y_h) +
z_{1-\alpha /2} \sigma)\)</span>。</p></li>
<li><p>一般情况下，设 <span class="math inline">\(d_h = Y_{h(new)} -
\hat{Y}_{h(new)} = Y_{h(new)} - \hat{\mu_h}\)</span>，于是有 <span class="math inline">\(E(d_h) = 0\)</span>。</p>
<p>计算可知方差 <span class="math inline">\(Var(d_h) = Var(Y_{h(new)} -
\hat{\mu} _h) = Var(Y_{h(new)})+Var(\hat{\mu_h}) = \sigma^2[1+\frac 1 n
+\frac{(X_h - \bar{X})^2}{\Sigma(X_i - \bar{X})^2}]\)</span>；</p>
<p>standard error 为 <span class="math inline">\(s^2(d_h) = s^2 [1+\frac
1 n +\frac{(X_h - \bar{X})^2}{\Sigma(X_i - \bar{X})^2}]\)</span>；</p>
<p>于是有 <span class="math inline">\(\frac{d_h - E(d_h)}{s(d_h)} =
\frac{d_h}{s(d_h)} = \frac{Y_{h(new)} - \hat{\mu}_h}{s(d_h)} \sim
t_{n-2}\)</span>，<span class="math inline">\(Y_{h(new)}\)</span>
的置信区间是 <span class="math inline">\((\hat{\mu}_h - s(d_h)
t_{n-2,1-\alpha/2},\hat{\mu}_h + s(d_h)
t_{n-2,1-\alpha/2})\)</span>。可以看到置信区间的长度是 <span class="math inline">\(2 t_{n-2,1-\alpha/2} s(d_h)\)</span>，其中 <span class="math inline">\(s^2(d_h) = s^2 + s^2(\hat{\mu}_h
^2)\)</span>，因此<strong>预测区间比平均响应的置信区间略宽</strong>。</p></li>
</ul>
<h3 id="预测值的平均的推断">预测值的平均的推断</h3>
<p>考虑在 <span class="math inline">\(X_h\)</span> 处的 <span class="math inline">\(m\)</span> 个预测值的平均响应，为 ${Y_h} = m
<em>{i=1} ^m Y</em>{h(new) i} = _0 +<em>1 X_h+ 1m </em>{i=1}^m _i
$，预测值的平均仍然是 <span class="math inline">\(\hat{Y_h}=b_0 + b_1
X_h\)</span>。有 <span class="math inline">\(\varepsilon _i \sim
N(0,\sigma^2)\)</span> 为正态假设。于是 <span class="math inline">\(Var(\bar{Y}_h - \hat{Y_h}) = \sigma^2 [\frac 1m +
\frac 1 n + \frac{(X_h - \bar{X})^2}{\Sigma(X_i - \bar{X})^2}] \leq
Var(d_h)\)</span>。</p>
<h3 id="confidence-band-for-entire-regression-line">Confidence Band for
Entire Regression Line</h3>
<p>怎么翻译都没那味，就写原文吧。</p>
<p>希望找到一个 confidence band：<span class="math inline">\(\lbrace
(x,y): L(x)&lt;y&lt;U(x), x\in \mathbb R \rbrace\)</span>，对于任意点
<span class="math inline">\(x\)</span> 有 <span class="math inline">\(P[l(x) &lt; \beta_0 +\beta_1 x &lt;u(x)] =
1-\alpha\)</span>。对于固定的点 <span class="math inline">\(x\)</span>，<span class="math inline">\(100 \%
(1-\alpha)\)</span> 置信区间为 <span class="math inline">\((\hat{\mu_x}
- t_{n-2, 1-\alpha /2} s(\hat{\mu_x}),\hat{\mu_x} + t_{n-2, 1-\alpha /2}
s(\hat{\mu_x}))\)</span>。</p>
<p>所以只要取 <span class="math inline">\(W=max\{(\hat{\mu}_x -
\mu_x)/s(\hat{\mu}_x) \}\)</span>，即有置信区间为 <span class="math inline">\((\hat{\mu}_x - W s(\hat{\mu_x}),\hat{\mu}_x + W
s(\hat{\mu_x}))\)</span>，其中 <span class="math inline">\(W =
\sqrt{2F_{1-\alpha,2,n-2}}\)</span>。实际上 <span class="math inline">\(W &gt; t_{n-2,1-\alpha /2}\)</span>，也就是说
confidence band 处处比 confidence interval 更宽，level of confidence
<span class="math inline">\(\alpha&#39;\)</span> 也更小。</p>
<h3 id="summary">Summary</h3>
<p>一个显示 confidence interval of mean response，prediction interval 和
confidence band 宽度关系的图：</p>
<p><img src="https://s2.loli.net/2023/03/16/XO3Bt8FehprNz5q.png" alt="bands.png"></p>
<h2 id="analysis-of-variance-anova">Analysis of Variance (ANOVA)</h2>
<h3 id="variance-estimator">Variance Estimator</h3>
<p>先上点概念：</p>
<ul>
<li><p>Total Sum of Squares: <span class="math inline">\(SST= \Sigma(Y_i
- \bar{Y})^2\)</span>，<span class="math inline">\(df_{SST} =
n-1\)</span></p>
<p>Sample Variance: <span class="math inline">\(S_n ^2 =
\frac{SST}{n-1}\)</span>，是非常熟悉的统计量。</p></li>
<li><p>Variation due to Error: <span class="math inline">\(SSE =
\Sigma(Y_i -\hat{Y}_i)^2= \Sigma e_i ^2\)</span>, <span class="math inline">\(df_{SSE} = n-2\)</span></p>
<p>Mean Square Error: <span class="math inline">\(MSE = \frac{SSE}{df} =
\frac{\Sigma_{i=1} ^n e_i ^2}{n-2}\)</span>，可以作为 <span class="math inline">\(\sigma^2 = Var(\varepsilon)\)</span>
的一个估计。</p>
<p><span class="math inline">\(E(MSE) = \sigma^2\)</span></p></li>
<li><p>Variation due to Regression: <span class="math inline">\(SSR =
\Sigma(\hat{Y}_i - \bar{Y})^2 = b_1 ^2 \Sigma (X_i-\bar{X})^2\)</span>,
<span class="math inline">\(df_{SSR} = 1\)</span></p>
<p>Mean Squares of Regression: <span class="math inline">\(MSR =
\frac{SSR}{df} = SSR\)</span></p>
<p>$E(MSR) = E(SSR) = E(b_1 ^2) ((X_i - {X})^2)= ^2 + _1^2 (X_i - {X})^2
$;</p></li>
</ul>
<p>可以计算得到 <span class="math inline">\(SST=SSE+SSR\)</span>，自由度方面也是 <span class="math inline">\(df_{SST} = df_{SSE}+df_{SSR}\)</span>。</p>
<p>事实上在 Lecture 2 中我们考虑过是选取 sample variance 还是选取 MSE
作为 <span class="math inline">\(\hat{\sigma}^2\)</span>，这里的定义给出了更清晰的答案：<span class="math inline">\(SSE\)</span> 更加注重原值和模型之间的联系，把
<span class="math inline">\(\hat{Y_i}\)</span> 作为 <span class="math inline">\(Y_i\)</span> 的估计值，在 sample variance 中是把
<span class="math inline">\(\bar{Y}\)</span> 作为 <span class="math inline">\(Y_i\)</span> 的估计值，前者更好地体现了 <span class="math inline">\(\varepsilon\)</span> 的场景。</p>
<h3 id="f-检验">F-检验</h3>
<p>我们希望通过以上统计量检验 <span class="math inline">\(X,Y\)</span>
之间是否存在线性关系。考虑假设 <span class="math inline">\(H_0: \beta_1
= 0 ; H_1 : \beta_1 \neq 0\)</span>。</p>
<p>在正态假设和 <span class="math inline">\(H_0\)</span> 成立条件下，取
test statistic 为 <span class="math inline">\(F= \frac{MSR}{MSE} =
\frac{SSR / df_R}{SSE / df_E} = \frac{\chi_{dfR}/df_R}{\chi_{dfE}/df_E}
\sim F_{df_R,df_E} = F_{1,n-2}\)</span>。考虑拒绝 <span class="math inline">\(H_0\)</span> 的情况，我们要求 <span class="math inline">\(F_0 &gt; F_{1-\alpha,df_R,df_E} = F_{1-\alpha,
1,n-2}\)</span>，满足此条件的 <span class="math inline">\((X,Y)\)</span>
构成 rejection region。或者从 P-value 的角度来看，满足不等式 <span class="math inline">\(P(F&gt;F_0 | F_{1,n-2}) &lt; \alpha\)</span>
的全体 <span class="math inline">\((X,Y)\)</span> 落在 rejection region
中。</p>
<p>考虑检验的 power function。在 <span class="math inline">\(H_1:
\beta_1 \neq 0\)</span> 条件下，Power(<span class="math inline">\(\beta_1\)</span>) = <span class="math inline">\(P(F&gt; F_{1-\alpha , 1,n-2} | non-central
F)\)</span>。</p>
<h3 id="general-linear-test">General Linear Test</h3>
<p>另一种检验上述假设的方式。考虑假设 <span class="math inline">\(H_0:
\beta_1 = 0 ; H_1 : \beta_1 \neq
0\)</span>，我们来比较两种不同的模型：</p>
<p>full model: <span class="math inline">\(Y_i = \beta_0+\beta_1 X_i
+\varepsilon _i\)</span>，reduced model: <span class="math inline">\(Y_i
= \beta_0 + \varepsilon_i\)</span>，在 <span class="math inline">\(H_0\)</span>
假设成立时两个模型是等价的。考虑方差统计量：</p>
<ul>
<li><span class="math inline">\(SSE(F) = SSE\)</span> for full model
with <span class="math inline">\(df_{EF}\)</span>，在 simple linear
regression 下 <span class="math inline">\(df_{EF}=n-2\)</span>，<span class="math inline">\(SSE(F) = SSE\)</span></li>
<li><span class="math inline">\(SSE(R) = SSE\)</span> for reduced model
with <span class="math inline">\(df_{ER}\)</span>，在 simple linear
regression 下 <span class="math inline">\(df_{ER}=n-1\)</span>，<span class="math inline">\(SSE(R) = SST\)</span></li>
</ul>
<p>在 <span class="math inline">\(H_0\)</span> 假设下，$F =
F_{(df_{ER}-df_{EF}),df_{EF}} $。实际上，在 simple linear regression
下和 F-检验是一致的。但是 general linear test
是一个更广泛的方法，可以用于任何形式的线性检验。</p>
<h3 id="pearson-correlation-r">Pearson Correlation r</h3>
<p><span class="math inline">\(r = \frac{\Sigma (X_i - \bar{X})(Y_i -
\bar{Y})}{\sqrt{\Sigma(X_i - \bar{X})^2} \sqrt{\Sigma(Y_i -
\bar{Y})^2}}\)</span> 被称为相关系数，反映了一组数据 <span class="math inline">\((X,Y)\)</span> 之间的线性关系程度。</p>
<p><span class="math inline">\(R^2 = \frac{SSR}{SST}\)</span>
被称为决定系数，事实上在 simple linear regression 下有 <span class="math inline">\(r^2=R^2\)</span>，因为 <span class="math inline">\(r = b_1 \frac{\sigma_X}{\sigma_Y}\)</span>。</p>
<p><img src="https://s2.loli.net/2023/03/16/3tpYiuFSd7Xw2vK.png" alt="2dimtest.png"></p>
<h1 id="lecture-5">Lecture 5</h1>
<p>模型假设与诊断。</p>
<h2 id="模型假设">模型假设</h2>
<p>回顾一下简单线性回归的模型假设：<span class="math inline">\(Y_i =
\beta_1 X_i + \beta_0 +\varepsilon _i\)</span></p>
<ul>
<li><span class="math inline">\(\varepsilon _1, \varepsilon _2 ,...,
\varepsilon_n\)</span> 相互独立</li>
<li><span class="math inline">\(\varepsilon_i\)</span> 服从正态分布</li>
<li><span class="math inline">\(\mathbb E(\varepsilon _i) =
0\)</span>，<span class="math inline">\(Var(\varepsilon_i) =
\sigma^2\)</span></li>
</ul>
<p>可以总结成 LINE: linearity, independence, normality, equal
variance</p>
<h2 id="diagnostics-and-remedies">Diagnostics and Remedies</h2>
<p>诊断的方式粗暴一点来说就是肉眼诊断，用一些可视化工具（主要是画图）和其他方式来检验模型的假设是否符合。如果违反了模型假设，结果很有可能不可靠。此时需要用一些弥补的方式来处理。</p>
<h3 id="diagnostics-of-x">Diagnostics of X</h3>
<p>诊断过程需要关注的是 <span class="math inline">\(X\)</span> 而非
<span class="math inline">\(Y\)</span>，因为 <span class="math inline">\(Y\)</span> 之间是独立异分布的。<span class="math inline">\(Y_i \sim N(\beta_0 +\beta_1 X_i ,
\sigma^2)\)</span>。有一些可以关心的统计量：</p>
<ul>
<li>sample mean 展现了 <span class="math inline">\(X\)</span>
的主要位置</li>
<li>standard deviation 展现了数据的分散程度</li>
<li>偏度 skewness <span class="math inline">\(g_1 = \frac{m_3}{m_2
^\frac 3 2} = \frac{\frac 1 n \Sigma_{i=1}^n (x_i - \bar x)^3}{(\frac 1
n \Sigma_{i=1}^n (x_i -\bar x)^2)^\frac 3 2}\)</span>
展现了数据的对称性</li>
<li>峰度 kurtosis <span class="math inline">\(g_2 = \frac{m_4}{m_2 ^2}
-3 = \frac{\frac 1 n \Sigma_{i=1}^n (x_i - \bar x )^4}{(\frac 1 n
\Sigma_{i=1} ^n (x_i -\bar x)^2)^2} - 3\)</span>
展现了数据相对于正态分布的尾迹</li>
<li>range 展现了 <span class="math inline">\(X\)</span> 的分布范围</li>
</ul>
<p>其中值得关注的是偏度和峰度两个统计量，<del>因为之前没有提过</del></p>
<p>关于偏度：</p>
<ul>
<li><span class="math inline">\(g_1 &lt;0\)</span> 时称为 negatively
skewed，左尾比较长，所以也会称为 skewed left</li>
<li><span class="math inline">\(g_1 &gt;0\)</span> 时称为 positively
skewed，右尾比较长，所以也会称为 skewed right</li>
</ul>
<p>由图可见偏度是能够体现数据的对称程度的。实际上对称程度是相对正态分布而言的。</p>
<p>这里有个图.jpg</p>
<p>关于峰度：</p>
<p>咕咕咕咕咕咕，下午腰痛得要裂开索性睡了一觉，没写完（</p>
<h1 id="附录">附录</h1>
<h2 id="常见重要分布">常见重要分布</h2>
<p>From <a target="_blank" rel="noopener" href="https://v1ncent19.github.io/SummaryNotes/">Statistic
Note</a> P10, by V1ncent19</p>
<table style="width:100%;">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(X\)</span></th>
<th><span class="math inline">\(p_X(k)\big/f_X(x)\)</span></th>
<th><span class="math inline">\(\mathbb{E}\)</span></th>
<th><span class="math inline">\(var\)</span></th>
<th>PGF</th>
<th>MGF</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\mathrm{Bern} (p)\)</span></td>
<td></td>
<td><span class="math inline">\(p\)</span></td>
<td><span class="math inline">\(pq\)</span></td>
<td></td>
<td><span class="math inline">\(q+pe^s\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(B (n,p)\)</span></td>
<td><span class="math inline">\(C_n^k p^k(1-p)^{n-k}\)</span></td>
<td><span class="math inline">\(np\)</span></td>
<td><span class="math inline">\(npq\)</span></td>
<td><span class="math inline">\((q+ps)^n\)</span></td>
<td><span class="math inline">\((q+pe^s)^n\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mathrm{Geo} (p)\)</span></td>
<td><span class="math inline">\((1-p)^{k-1}p\)</span></td>
<td><span class="math inline">\(\dfrac{1}{p}\)</span></td>
<td><span class="math inline">\(\dfrac{q}{p^2}\)</span></td>
<td><span class="math inline">\(\dfrac{ps}{1-qs}\)</span></td>
<td><span class="math inline">\(\dfrac{pe^s}{1-qe^s}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(H(n,M,N)\)</span></td>
<td><span class="math inline">\(\dfrac{C_M^kC_{N-M}^{n-k}}{C_N^n}\)</span></td>
<td><span class="math inline">\(n\dfrac{M}{N}\)</span></td>
<td><span class="math inline">\(\dfrac{nM(N-n)(N-M)}{N^2(n-1)}\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(P(\lambda)\)</span></td>
<td><span class="math inline">\(\dfrac{\lambda^k}{k!}e^{-\lambda}\)</span></td>
<td><span class="math inline">\(\lambda\)</span></td>
<td><span class="math inline">\(\lambda\)</span></td>
<td><span class="math inline">\(e^{\lambda(s-1)}\)</span></td>
<td><span class="math inline">\(e^{\lambda(e^s-1)}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(U(a,b)\)</span></td>
<td><span class="math inline">\(\dfrac{1}{b-a}\)</span></td>
<td><span class="math inline">\(\dfrac{a+b}{2}\)</span></td>
<td><span class="math inline">\(\dfrac{(b-a)^2}{12}\)</span></td>
<td></td>
<td><span class="math inline">\(\dfrac{e^{sb}-e^{sa}}{(b-a)^s}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(N(\mu,\sigma^2)\)</span></td>
<td><span class="math inline">\(\dfrac{1}{\sigma
\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\)</span></td>
<td><span class="math inline">\(\mu\)</span></td>
<td><span class="math inline">\(\sigma^2\)</span></td>
<td></td>
<td><span class="math inline">\(e^{\frac{\sigma^2s^2}{2}+\mu
s}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\epsilon(\lambda)\)</span></td>
<td><span class="math inline">\(\lambda e^{-\lambda x}\)</span></td>
<td><span class="math inline">\(\dfrac{1}{\lambda}\)</span></td>
<td><span class="math inline">\(\dfrac{1}{\lambda^2}\)</span></td>
<td></td>
<td><span class="math inline">\(\frac{\lambda}{\lambda-s}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\Gamma(\alpha,\lambda)\)</span></td>
<td><span class="math inline">\(\dfrac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda
x}\)</span></td>
<td><span class="math inline">\(\dfrac{\alpha}{\lambda}\)</span></td>
<td><span class="math inline">\(\dfrac{\alpha}{\lambda^2}\)</span></td>
<td></td>
<td>$()^<span class="math inline">\(| |\)</span>B(,)$</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\chi^2_n\)</span></td>
<td><span class="math inline">\(\dfrac{1}{2^{\frac{n}{2}}\Gamma(\frac{n}{2})}x^{\frac{n}{2}-1}e^{-\frac{x}{2}}\)</span></td>
<td><span class="math inline">\(n\)</span></td>
<td><span class="math inline">\(2n\)</span></td>
<td></td>
<td>$ (1-2s)^{-n/2} $</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(t_\nu\)</span></td>
<td><span class="math inline">\(\dfrac{\Gamma(\frac{\nu+1}{2})}{\sqrt{\nu\pi}\Gamma(\frac{\nu}{2})}(1+\frac{x^2}{\nu})^{-\frac{\nu+1}{2}}\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(\dfrac{\nu}{\nu-2}\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(F_{m,n}\)</span></td>
<td><span class="math inline">\(\dfrac{\Gamma(\frac{m+n}{2})}{\Gamma(\frac{m}{2})\Gamma(\frac{n}{2})}\dfrac{m^\frac{m}{2}n^\frac{n}{2}x^{\frac{m}{2}-1}}{(mx+n)^{\frac{m+n}{2}}}\)</span></td>
<td><span class="math inline">\(\dfrac{n}{n-2}\)</span></td>
<td><span class="math inline">\(\dfrac{2n^2(m+n-2)}{m(n-2)^2(n-4)}\)</span></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Consider <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>
i.i.d. <span class="math inline">\(\sim N(0,1)\)</span>; <span class="math inline">\(Y,Y_1,Y_2,\ldots,Y_m\)</span> i.i.d. <span class="math inline">\(\sim N(0,1)\)</span> - <span class="math inline">\(\chi^2\)</span> Distribution：</p>
<p><span class="math inline">\(\chi^2\)</span> distribution with degree
of freedom <span class="math inline">\(n\)</span>：$ =_{i=1}^n
X_i<sup>2</sup>2_n$。 For independent <span class="math inline">\(\xi_i\sim\chi^2_{n_i},\,
i=1,2,\ldots,k\)</span>：<span class="math inline">\(x_{i_0}=\sum_{i=1}^k\xi_i\sim\chi^2_{n_1+\ldots+n_k}\)</span></p>
<ul>
<li><p><span class="math inline">\(t\)</span> Distribution：</p>
<p><span class="math inline">\(t\)</span> distribution with degree of
freedom <span class="math inline">\(n\)</span>：$ T==t_n$</p>
<p>Upper <span class="math inline">\(\alpha\)</span>-fractile of <span class="math inline">\(t_\nu\)</span>, satisfies <span class="math inline">\(\mathbb{P}(T\geq
c)=\alpha\)</span>，$t_{,}=<em>{c}(Tc)=,Tt</em>$</p></li>
<li><p><span class="math inline">\(F\)</span> Distribution：</p>
<p><span class="math inline">\(F\)</span> distribution with degree of
freedom <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span>：$ F=F_{m,n}$</p>
<ul>
<li>If <span class="math inline">\(Z\sim F_{m,n}\)</span>, then <span class="math inline">\(\dfrac{1}{Z}\sim F_{n,m}\)</span>；</li>
<li>If <span class="math inline">\(T\sim t_n\)</span>, then <span class="math inline">\(T^2\sim F_{1,n}\)</span>；</li>
<li><span class="math inline">\(F_{m,n,1-\alpha}=\dfrac{1}{F_{n,m,\alpha}}\)</span>
。</li>
</ul></li>
</ul>
<p>Some useful lemmas in statistical inference：</p>
<ul>
<li><p>For <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>
independent with <span class="math inline">\(X_i\sim
N(\mu_i,\sigma^2_i)\)</span>, then <span class="math inline">\(\sum_{i=1}^n\left(\frac{X_i-\mu_i}{\sigma_i}\right)^2\sim
\chi^2_n\)</span></p></li>
<li><p>For <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>
i.i.d.<span class="math inline">\(\sim N(\mu,\sigma^2)\)</span>, then $
T=t_{n-1} $</p></li>
<li><p>For <span class="math inline">\(X_1,X_2,\ldots,X_m\)</span>
i.i.d.<span class="math inline">\(\sim N(\mu_1,\sigma^2)\)</span>, <span class="math inline">\(Y_1,Y_2,\ldots,Y_n\)</span> i.i.d.<span class="math inline">\(\sim N(\mu_2,\sigma^2)\)</span>,d enote sample
pooled variance <span class="math inline">\(S_{\omega}^2=\dfrac{(m-1)S^2_1+(n-1)S^2_2}{m+n-2}\)</span>,
then <span class="math inline">\(T=\frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}{S_{\omega}}\cdot
\sqrt{\frac{mn}{m+n}}\sim t_{m+n-2}\)</span></p></li>
<li><p>For <span class="math inline">\(X_1,X_2,\ldots,X_m\)</span>
i.i.d.<span class="math inline">\(\sim N(\mu,\sigma^2)\)</span>, <span class="math inline">\(Y_1,Y_2,\ldots,Y_n\)</span> i.i.d.<span class="math inline">\(\sim N(\mu_2,\sigma^2)\)</span>, then
$T=F_{m-1,n-1} $</p></li>
<li><p>For <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>
i.i.d. <span class="math inline">\(\sim \varepsilon(\lambda)\)</span>,
then $ 2n{X}=2<em>{i=1}^nX_i ^2</em>{2n} $</p>
<p>Remark：for <span class="math inline">\(X_i\sim\varepsilon(\lambda)=\Gamma(1,\lambda)\)</span>，<span class="math inline">\(2\lambda\sum_{i=1}^nX_i\sim\Gamma(n,1/2)=\chi^2_{2n}\)</span>.</p></li>
</ul>
<h2 id="分位数速查">分位数速查</h2>
<p>来自 Package stats, version 4.2.1。</p>
<p>其实都可以直接查文档啦（，R 的文档还是很保姆式的。</p>
<h3 id="t-分布模拟">t-分布模拟</h3>
<p>t-distribution 下有四个函数，分别是 density, CDF, quantile
function(<span class="math inline">\(CDF^{-1}\)</span>)，还有一个是随机生成一个模拟数组。</p>
<p><code>dt(x, df, ncp, log = FALSE)</code> 用来计算 PDF 的函数值 <span class="math inline">\(f(x)\)</span>，df 是自由度，ncp 表示非中心化参数
<span class="math inline">\(\delta\)</span>；</p>
<p><code>pt(x, df, ncp, lower.tail = TRUE, log.p = FALSE)</code>
用来计算 CDF 的函数值 <span class="math inline">\(F(x)\)</span>，注意
<code>lower.tail = TRUE</code> 时计算的是左边值 <span class="math inline">\(F(x)\)</span>，否则实际计算了 <span class="math inline">\(1-F(x)\)</span>。</p>
<p><code>qt(p, df, ncp, lower.tail = TRUE, log.p = TRUE)</code>
用来计算分位数，也即 <span class="math inline">\(F^{-1}(p)\)</span>，其他参数意义同上。</p>
<p>一些我的作业里的函数参考：</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">&gt;</span> qt<span class="punctuation">(</span><span class="number">1</span> <span class="operator">-</span> <span class="number">0.025</span><span class="punctuation">,</span> df <span class="operator">=</span> <span class="number">8</span><span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">2.306004</span></span><br></pre></td></tr></table></figure>
<p>这里计算的是 <span class="math inline">\(t_{8,0.975}\)</span>
的下分位数，实际上是一个 level of significance 为 <span class="math inline">\(0.05\)</span> 的双尾检验中用到的分位数。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">&gt;</span> <span class="number">2</span> <span class="operator">*</span> pt<span class="punctuation">(</span><span class="operator">-</span><span class="number">8.529</span><span class="punctuation">,</span> df <span class="operator">=</span> <span class="number">8</span><span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">2.74639e-05</span></span><br></pre></td></tr></table></figure>
<p>这里是在计算一个 P-value，计算的是比 observed data <span class="math inline">\(-8.529\)</span> 更极端的数据的出现概率，单边是
<span class="math inline">\(F (-8.529)\)</span>，注意此处的“极端”包含比
<span class="math inline">\(-8.529\)</span> 更小和比 <span class="math inline">\(8.529\)</span> 更大这两种情况，实际上是 <span class="math inline">\(F(-8.529) + 1- F(8.529)\)</span>。</p>
<p>由于 t-distribution 是对称的，可以简化为 <span class="math inline">\(2 \times F(-8.529)\)</span>。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">&gt;</span> ncp <span class="operator">&lt;-</span> 2.0<span class="operator">/</span><span class="number">0.50</span></span><br><span class="line"><span class="operator">&gt;</span> <span class="built_in">c</span> <span class="operator">&lt;-</span> qt<span class="punctuation">(</span><span class="number">1</span><span class="operator">-</span><span class="number">0.025</span><span class="punctuation">,</span>df<span class="operator">=</span><span class="number">8</span><span class="punctuation">)</span></span><br><span class="line"><span class="operator">&gt;</span> pt<span class="punctuation">(</span><span class="operator">-</span><span class="built_in">c</span><span class="punctuation">,</span> df<span class="operator">=</span><span class="number">8</span><span class="punctuation">,</span> ncp<span class="punctuation">)</span> <span class="operator">+</span> <span class="number">1</span> <span class="operator">-</span> pt<span class="punctuation">(</span><span class="built_in">c</span><span class="punctuation">,</span> df<span class="operator">=</span><span class="number">8</span><span class="punctuation">,</span> ncp<span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">0.9367429</span></span><br></pre></td></tr></table></figure>
<p>这是一个非中心的 t 检验，实际上是在计算 Power Function。</p>
<h3 id="正态分布模拟">正态分布模拟</h3>
<p>常用的三个函数是
<code>dnorm</code>，<code>pnorm</code>，<code>qnorm</code>，含义与
t-分布中的 <code>dt</code>，<code>pt</code>，<code>qt</code> 相似。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dnorm<span class="punctuation">(</span>x<span class="punctuation">,</span> mean <span class="operator">=</span> <span class="number">0</span><span class="punctuation">,</span> sd <span class="operator">=</span> <span class="number">1</span><span class="punctuation">,</span> <span class="built_in">log</span> <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br><span class="line">pnorm<span class="punctuation">(</span>q<span class="punctuation">,</span> mean <span class="operator">=</span> <span class="number">0</span><span class="punctuation">,</span> sd <span class="operator">=</span> <span class="number">1</span><span class="punctuation">,</span> lower.tail <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">,</span> log.p <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br><span class="line">qnorm<span class="punctuation">(</span>p<span class="punctuation">,</span> mean <span class="operator">=</span> <span class="number">0</span><span class="punctuation">,</span> sd <span class="operator">=</span> <span class="number">1</span><span class="punctuation">,</span> lower.tail <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">,</span> log.p <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<p>注意一般正态检验中都是使用标准正态分布，也就是不需要去改变
<code>mean</code> 和 <code>sd</code> 的默认值。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">&gt;</span> pnorm<span class="punctuation">(</span><span class="number">0</span><span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">0.5</span></span><br><span class="line"><span class="operator">&gt;</span> qnorm<span class="punctuation">(</span><span class="number">0.025</span><span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="operator">-</span><span class="number">1.959964</span></span><br></pre></td></tr></table></figure>
<h3 id="f-分布模拟">F-分布模拟</h3>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df<span class="punctuation">(</span>x<span class="punctuation">,</span> df1<span class="punctuation">,</span> df2<span class="punctuation">,</span> ncp<span class="punctuation">,</span> <span class="built_in">log</span> <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br><span class="line">pf<span class="punctuation">(</span>q<span class="punctuation">,</span> df1<span class="punctuation">,</span> df2<span class="punctuation">,</span> ncp<span class="punctuation">,</span> lower.tail <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">,</span> log.p <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br><span class="line">qf<span class="punctuation">(</span>p<span class="punctuation">,</span> df1<span class="punctuation">,</span> df2<span class="punctuation">,</span> ncp<span class="punctuation">,</span> lower.tail <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">,</span> log.p <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<p>注意 <span class="math inline">\(F\)</span>
分布的两个自由度都可以取到无穷，写作 <code>df1 = Inf</code>。</p>
<h3 id="chi-square-分布模拟">Chi-square 分布模拟</h3>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dchisq<span class="punctuation">(</span>x<span class="punctuation">,</span> df<span class="punctuation">,</span> ncp <span class="operator">=</span> <span class="number">0</span><span class="punctuation">,</span> <span class="built_in">log</span> <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br><span class="line">pchisq<span class="punctuation">(</span>q<span class="punctuation">,</span> df<span class="punctuation">,</span> ncp <span class="operator">=</span> <span class="number">0</span><span class="punctuation">,</span> lower.tail <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">,</span> log.p <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br><span class="line">qchisq<span class="punctuation">(</span>p<span class="punctuation">,</span> df<span class="punctuation">,</span> ncp <span class="operator">=</span> <span class="number">0</span><span class="punctuation">,</span> lower.tail <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">,</span> log.p <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<h2 id="其他常用-r-命令">其他常用 R 命令</h2>
<p>持续更新中，基本都是作业里扒出来的。</p>
<h3 id="confidence-interval">confidence interval</h3>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">confint<span class="punctuation">(</span>object<span class="punctuation">,</span> parm<span class="punctuation">,</span> level <span class="operator">=</span> <span class="number">0.95</span><span class="punctuation">,</span> ...<span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<p>注意 confidence coefficient 的默认值是 <span class="math inline">\(0.95\)</span>，<code>confint</code>
函数是用于拟合模型参数的置信区间估计，例如：</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model <span class="operator">&lt;-</span> lm<span class="punctuation">(</span>data<span class="punctuation">)</span></span><br><span class="line">confint<span class="punctuation">(</span>model<span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">               <span class="number">2.5</span> <span class="operator">%    97.5 %</span></span><br><span class="line"><span class="punctuation">(</span>Intercept<span class="punctuation">)</span> <span class="number">8.670370</span> <span class="number">11.729630</span></span><br><span class="line">V2          <span class="number">2.918388</span>  <span class="number">5.081612</span></span><br></pre></td></tr></table></figure>

    </div>

    
    
    
        <div class="reward-container">
  <div>我很可爱 请给我钱（？）</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.jpg" alt="驰雨Chiyuru 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.jpg" alt="驰雨Chiyuru 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>驰雨Chiyuru
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://chiyuru.github.io/2023/02/21/Linear-Regression-Analysis/" title="还就那个线性回归分析">https://chiyuru.github.io/2023/02/21/Linear-Regression-Analysis/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E8%AF%BE%E7%A8%8B%E5%AE%9E%E5%BD%95/" rel="tag"># 课程实录</a>
              <a href="/tags/%E7%BB%9F%E8%AE%A1/" rel="tag"># 统计</a>
              <a href="/tags/%E6%95%B0%E5%AD%A6/" rel="tag"># 数学</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/02/01/Learn-Mathematical-Analysis-or-Die-2/" rel="prev" title="数学分析 I 速通日志（下）">
      <i class="fa fa-chevron-left"></i> 数学分析 I 速通日志（下）
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/02/25/Multivariate-Statistical-Analysis/" rel="next" title="多元问题对我来说太难了，但是多元统计分析">
      多元问题对我来说太难了，但是多元统计分析 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  
  <div class="comments">
  <script src="https://utteranc.es/client.js" repo="Chiyuru/chiyuru.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async></script>
  </div>
  
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-1"><span class="nav-text">Lecture 1</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#galtons-experiment"><span class="nav-text">Galton&#39;s Experiment</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E6%9C%AF%E8%AF%AD"><span class="nav-text">一些术语</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-2"><span class="nav-text">Lecture 2</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#simple-linear-regression"><span class="nav-text">Simple Linear Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E7%BB%84%E7%BB%87%E5%92%8C%E8%A1%A8%E7%A4%BA"><span class="nav-text">数据的组织和表示</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%A4%BA"><span class="nav-text">模型的表示</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E7%9A%84%E6%84%8F%E4%B9%89%E5%92%8C%E6%B1%82%E7%AE%97"><span class="nav-text">参数的意义和求算</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#least-sum-of-square-%E6%96%B9%E6%B3%95"><span class="nav-text">Least Sum of Square 方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mle-%E6%96%B9%E6%B3%95"><span class="nav-text">MLE 方法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8E%A8%E6%96%AD%E5%A4%8D%E4%B9%A0"><span class="nav-text">推断复习</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-3"><span class="nav-text">Lecture 3</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%AD%E7%9A%84%E6%8E%A8%E6%96%AD"><span class="nav-text">线性回归中的推断</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E6%8E%A8%E6%96%AD"><span class="nav-text">参数推断</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#power-function"><span class="nav-text">Power Function</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#blue"><span class="nav-text">BLUE</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-4"><span class="nav-text">Lecture 4</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#estimation-prediction"><span class="nav-text">Estimation &amp; Prediction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B9%B3%E5%9D%87%E5%93%8D%E5%BA%94%E7%9A%84%E6%8E%A8%E6%96%AD"><span class="nav-text">平均响应的推断</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%84%E6%B5%8B%E5%80%BC%E7%9A%84%E6%8E%A8%E6%96%AD"><span class="nav-text">预测值的推断</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%84%E6%B5%8B%E5%80%BC%E7%9A%84%E5%B9%B3%E5%9D%87%E7%9A%84%E6%8E%A8%E6%96%AD"><span class="nav-text">预测值的平均的推断</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#confidence-band-for-entire-regression-line"><span class="nav-text">Confidence Band for
Entire Regression Line</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#summary"><span class="nav-text">Summary</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#analysis-of-variance-anova"><span class="nav-text">Analysis of Variance (ANOVA)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#variance-estimator"><span class="nav-text">Variance Estimator</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#f-%E6%A3%80%E9%AA%8C"><span class="nav-text">F-检验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#general-linear-test"><span class="nav-text">General Linear Test</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pearson-correlation-r"><span class="nav-text">Pearson Correlation r</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-5"><span class="nav-text">Lecture 5</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E5%81%87%E8%AE%BE"><span class="nav-text">模型假设</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#diagnostics-and-remedies"><span class="nav-text">Diagnostics and Remedies</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#diagnostics-of-x"><span class="nav-text">Diagnostics of X</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%99%84%E5%BD%95"><span class="nav-text">附录</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E9%87%8D%E8%A6%81%E5%88%86%E5%B8%83"><span class="nav-text">常见重要分布</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E4%BD%8D%E6%95%B0%E9%80%9F%E6%9F%A5"><span class="nav-text">分位数速查</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#t-%E5%88%86%E5%B8%83%E6%A8%A1%E6%8B%9F"><span class="nav-text">t-分布模拟</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%E6%A8%A1%E6%8B%9F"><span class="nav-text">正态分布模拟</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#f-%E5%88%86%E5%B8%83%E6%A8%A1%E6%8B%9F"><span class="nav-text">F-分布模拟</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#chi-square-%E5%88%86%E5%B8%83%E6%A8%A1%E6%8B%9F"><span class="nav-text">Chi-square 分布模拟</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E5%B8%B8%E7%94%A8-r-%E5%91%BD%E4%BB%A4"><span class="nav-text">其他常用 R 命令</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#confidence-interval"><span class="nav-text">confidence interval</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="驰雨Chiyuru"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">驰雨Chiyuru</p>
  <div class="site-description" itemprop="description">おはよう、朝だよ</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">28</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Chiyuru" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Chiyuru" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:mafy21@mails.tsinghua.edu.cn" title="E-Mail → mailto:mafy21@mails.tsinghua.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/Chiyuru_0417" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;Chiyuru_0417" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/ma-fei-yan-33" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;ma-fei-yan-33" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>知乎</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright">
  
  &copy; 2022 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">驰雨Chiyuru</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv1">
  本站总访客数：<span id="busuanzi_value_site_uv"></span>
</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":-15,"vOffset":-15},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
