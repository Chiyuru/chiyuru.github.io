<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>用相册细碎地回忆一下在 THU 的第一年</title>
    <url>/2022/08/17/2022-photos-and-fragments/</url>
    <content><![CDATA[<p>是前面这一年间一直没有删掉的一些照片，基本按照时间线排列。</p>
<span id="more"></span>
<h1 id="上一个暑假写字">上一个暑假·写字</h1>
<p><img src="https://s2.loli.net/2022/08/17/GCx8sZQVADwObuz.jpg" alt="63a1f4c5cfa930ce0c0794629648cc1"></p>
<p>写这段话完全是因为，高考完的暑假我甚至闲得二刷了一遍甄嬛传。那天晚上正好看到皇帝假意让熹贵妃和亲，在剧里听到了这首词（诗？），顺手就写下来了。</p>
<p>拍下来一直存着是因为，感觉字写的还行（？），一个暑假没怎么握笔的现在恐怕写不出来了。</p>
<h1 id="年底寝室">年底·寝室</h1>
<p><img src="https://s2.loli.net/2022/08/17/DEohdA6IbMxCgZp.jpg" alt="87a3b477375ea7cda5ed7667049d2ab"></p>
<p>年底的一个晚上，在寝室里给自己剪了头发。</p>
<p>其实就是很暴力地拿剪刀把长发改短了，冬天披着很舒服也更好看。</p>
<p>好！等到夏天过去了我还想再剪短一次！</p>
<p>（其实手机里没删的图也有很多是心血来潮的自拍，还是不发了，笑死。</p>
<h1 id="元宵闵大荒">元宵·闵大荒</h1>
<p><img src="https://s2.loli.net/2022/08/17/JDncA9xMH6abCvt.jpg" alt="5db9b9c354c4f40e7c78aa5ab9920ea"></p>
<p>2022
年的元宵节那天，交大已经开学了，华子还没有。于是找了一位朋友带我混进去玩了一天。</p>
<p>骑车从思源门晃到龙宾楼，又从宣怀大道步行回去。到电院附近转了转，恍惚想着如果当初没有拒交大
IEEE，如今会过得怎么样呢，可能也不很满意，又或许会开心一些？月亮很圆，可惜没有拍到电院红色砖墙旁的满月，真的很漂亮。</p>
<p>绿园好吃，菠萝包好吃。rua
了一把包图猫馆长，其实是我第一次摸猫猫，皮毛很温暖顺滑的感觉。过了两周听说猫猫失踪，不知道后来怎么样了。</p>
<p>很快就是上海疫情，交大里面也很严重，人在北京差点被隔离。</p>
<h1 id="寒春荷塘">寒春·荷塘</h1>
<p><img src="https://s2.loli.net/2022/08/17/vx8cyJVFmjsznoe.jpg" alt="8115ccace96242fd836f5129847ce8d"></p>
<p>春季学期在开学的前两天回了学校。开学前一天没啥事情，去逛了逛荷塘和近春园。怂怂地上了冰面，拍了张照片，还摔了一跤。</p>
<p>但是南方人狂喜.jpg</p>
<h1 id="三月成绩单">三月·成绩单</h1>
<p><img src="https://s2.loli.net/2022/08/17/f21cR8hUFydVIB6.jpg" alt="52a50ba1cf1d21152df2f2959376573"></p>
<p>科协第一次部会之前在 C
楼开了成绩单，觉得很荒唐。也是春季学期摆烂的开始。</p>
<p>第一学期其实为了 GPA 卷爆了，然而喜提体育 2.6，又被 C++
选修课爆杀，但我仍然不认为 3.88
有多低。打了排名之后感觉很奇怪，再一问同学才知道保护 GPA
的众多方式，比如学不会就退课一学期 20
个学分，比如培养方案之外只选水课。</p>
<p>我觉得这不值得。于是春季学期改变了下思路，自杀式瞎学占 5
个学分但对我没什么大用的基物，2 学分的高代选讲当成 4
学分的高代来学，甚至翘过 1-3 的工图课去旁听高代，听完课继续在 3300
自习、画图。做了一些和培养方案没关系的事情，也有点伤害
GPA，但是感觉很开心。</p>
<p>不过幸好有两个 PF 的机会，用在了基物和工图上，导致 GPA 上了
3.9，但排名纹丝不动。同时对微积分 A(2) 这门课的评价是啥也不是，喜提 B+
但是没太当回事，感觉状态和<a href="https://mp.weixin.qq.com/s/PD0s8gyXvJ0ugZLRzDhIIQ">文刀日肥的这篇文章</a>有些像。</p>
<h1 id="期中法图走廊">期中·法图走廊</h1>
<p><img src="https://s2.loli.net/2022/08/17/Ac32KtTIVzxeXJg.jpg" alt="0b99e0642055b9ada9a9d4bad7eba32"></p>
<p>在图书馆吃东西是不好的行为，我自裁。</p>
<p>当时期中周连考三门（微积分，基物，高代选）实在绷不住了，考试前夜就补觉，第二天不考试就复习到凌晨三点钟。记得有一天早晨起来实在难受，午饭前在六教的洗手间里吐了。</p>
<p>这张图发生在某天的下午两点，没有什么食欲，然后躲在法图的一个没有灯的（好像和什么设备邻近的）走廊里吃了一个巧克力面包，喝了前一天买的饮料。</p>
<h1 id="生日寝室阳台">生日·寝室阳台</h1>
<p><img src="https://s2.loli.net/2022/08/17/w91BLXYaMf3kRUH.jpg" alt="6a0e77897c65e850aae7bcdeef9fa6b"></p>
<p>生日正好是期中后一天，很有仪式感地点了布歌东京的蛋糕。好贵，但是好漂亮，味道也不错。</p>
<p>从高一开始，自己过生日的时候就习惯半夜到暗一些的地方，去给自己点一下蜡烛。高一是在高中寝室的洗手间里，高二是在家，高三是躲在学校的化学实验室。这一次是在寝室的阳台上，还特地外卖买了打火机，不知道有没有违反寝室条例。</p>
<p>认真地看了许久摇曳的火焰，吹灭之后感到很开心。出门的时候还没熄灯，开门回房间就已经全黑了，室友们在各自做自己的事情，完全没注意到我在做什么。感觉就像是在时间的缝隙里大喘气了一下，不打破原来的平静就是最好的。</p>
<h1 id="期末很丧的时候消费主义陷阱们">期末很丧的时候·消费主义陷阱们</h1>
<p><img src="https://s2.loli.net/2022/08/17/hVjQkCDg5TzrAaq.jpg" alt="6dca668fb099b3fc732323ba261b4dd"></p>
<p>有一段时间很丧，然后就喜欢晚上躲在被子里看一会美食视频再睡，主要是一人食的制作过程那种。然后想着以后也想有一个厨房，尝试着给自己做饭。</p>
<p>不过从来都没怎么做过饭，感觉厨艺会很感人...叶公好龙吧。</p>
<p>甚至还上淘宝找了找餐具，收藏了这套猫猫碗盘XD。</p>
<p>另一个是一直想买的小包，设计很漂亮。虽然想了想使用场景只有偶尔出去玩的时候背，然后就搁置了没买。如果一段时间之后还是惦记着很想要，那就坚定地作为情绪价值买下来吧！XD</p>
<h1 id="周四晚上六点声速实验">周四晚上六点·声速实验</h1>
<p><img src="https://s2.loli.net/2022/08/17/iqz2ErZINy1CV7H.jpg" alt="8be31e368db478ab959dfe281590a11"></p>
<p>越是写请勿碰落，我越想去碰一下（猫猫行为</p>
<p>这个温湿度仪一看就是小米出品，很有感觉，本来想买一个。然后某宝搜了一下价格就劝退了，况且真没必要。<a href="https://zh.moegirl.org.cn/%E4%B8%8D%E4%B9%B0%E7%AB%8B%E7%9C%81%E7%99%BE%E5%88%86%E7%99%BE">不买立省百分百</a>！</p>
<h1 id="时间跨度很长花">时间跨度很长·花</h1>
<p><img src="https://s2.loli.net/2022/08/17/jVh2xnXKryWaHbi.jpg" alt="3345d0637108d7503be1be5246436be"></p>
<p>很喜欢鲜花。</p>
<p>洋甘菊和水仙百合是今年的图，玫瑰是去年生日的，满天星当初偷偷养在高中教学楼的一个阶梯教室里，水杯上的杏花是在（高中的）食堂旁边的树上薅的。（破坏绿化，我自裁</p>
<p>水仙百合（左上）和它们都不一样，凋谢的时候花瓣和花蕊会一点点脱落，然而茎叶还能保持翠绿很久。</p>
<h1 id="暑假梗图">暑假·梗图</h1>
<p><img src="https://s2.loli.net/2022/08/17/8UdAZsOm9fJzWYo.jpg" alt="13c13d5d9fbbdf461e1fae02fa4f7cb"></p>
<p>我 C
系语言的水平实在是不行，之前印象很深刻，刷书写了个链表，成功把我自己弄破防了。开学后的雷系数据结构恐怕要直接退课了...再过一学期吧。</p>
<p>暑假学了一手
Python，写了几个小任务，感觉很优雅。人生苦短，我使电锯（</p>
<p><img src="https://s2.loli.net/2022/08/17/k4lhQRuVgJbDWI7.jpg" alt="246033b05351507996db92b2328d0d7"></p>
<p>制图实习有感：我只是一只小猫咪，你真的确定要给我 3.3 吗？</p>
<p>但是感觉毫无疑问了，真的不是很会搞这个东西（悲</p>
<p><img src="https://s2.loli.net/2022/08/17/FZm73D6hR4Tv8JU.png" alt="image-20220817012039916"></p>
<p>见者落泪（</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
        <tag>睡隙碎笔</tag>
      </tags>
  </entry>
  <entry>
    <title>本科第二年相册里多了些什么</title>
    <url>/2023/07/31/2023-photos-and-fragments/</url>
    <content><![CDATA[<p>不知道为什么就成了一种传统的年度整理照片环节（</p>
<p>去年打开相册：这个好有意思，那个也发一下好了</p>
<p>今年打开相册：这都什么乱七八糟的，怎么全是自拍，这也不能发啊（</p>
<span id="more"></span>
<h1 id="街溜子摄影">街溜子摄影</h1>
<p>寒假去交大那天回来的路上正好路过商汤，可惜雨天拍糊了。看这个楼还幻视了携程总部，灯带挺炫酷的。</p>
<p><img src="https://s2.loli.net/2023/07/18/YP837Cs26yuKaEU.jpg" alt="商汤.jpg"></p>
<p>年初五去了豫园，<del>迫真上海宁</del>。去年新建的 14
号线豫园地铁站风格和我想的完全不一样，这个电梯很高而且还挺有未来感的，怎么会是呢。</p>
<p><del>已加入痞子风 One Last Kiss 豪华摄影套餐（</del></p>
<p><img src="https://s2.loli.net/2023/07/18/WQM5pzqsFlZkbCw.jpg" alt="豫园电梯.jpg"></p>
<p>同样是豫园，来个意义不明的自拍，这个站名幕墙的设计之前就给我整的有点疑惑，不过拍照还挺好看的。</p>
<p><del>挺照骗的，我不长这样（</del></p>
<p><del>友人锐评像白手套白肚皮的黑色猫猫（（</del></p>
<p><img src="https://s2.loli.net/2023/07/18/dTmuIV64EK7YOBi.jpg" alt="豫园.jpg"></p>
<p>在市区想过一条马路，偷懒从旁边的一幢破楼里穿过去的时候遇到一个《超前，空前》（，很难相信是
2023 年（</p>
<p><img src="https://s2.loli.net/2023/07/18/rk9QO8J7tlwVvKd.jpg" alt="IPhone5.jpg"></p>
<h1 id="国博">国博</h1>
<p>看到的时候还在想玉兽具体是个啥，结果这个 unidentified animal
给我整不会了（</p>
<p><img src="https://s2.loli.net/2023/07/18/AMzi2x3BtqZT9vN.jpg" alt="玉兽.jpg"></p>
<p>其实这个小马做得还挺可爱的，甚至是西周的文物。看展包括之前上工艺美术史的时候都是按照朝代顺序，每次都觉得大概是到商周开始的工艺水平就是我手搓达不到的了（</p>
<p>只不过当时我刚看完赛马娘，脑子里只有俺の愛馬が！（</p>
<p><img src="https://s2.loli.net/2023/07/18/VwPMLoD9qpZ2dzN.jpg" alt="赛马娘！.jpg"></p>
<p>单方面认为剔红是最好的漆器工艺，非常喜欢这个：</p>
<p><img src="https://s2.loli.net/2023/07/18/EQeFsJt6nDaTAkY.jpg" alt="剔红.jpg"></p>
<p>看到了李东阳给《清明上河图》的题跋，之前读过这篇文章，但没学过书法没想到真迹会这么好看，喜欢这个字体。虽然在国博看到的并不是真迹而是打印的版本，但还是在现场又读了一遍。</p>
<p><img src="https://s2.loli.net/2023/07/18/UZ9FpGY1yTdXjCb.jpg" alt="清明上河图题跋.jpg"></p>
<h1 id="学校里居然还有能拍的">学校里居然还有能拍的</h1>
<p>某天路过东操靠近新民路的一侧，后来就想到了买玫瑰。</p>
<p><img src="https://s2.loli.net/2023/07/18/sNmlptIQjUGRSx6.jpg" alt="东操.jpg"></p>
<p>秋季学期在法图拍的，实际上是窗帘拉下来遮住了窗外的景象，但看起来很像投影。远处的是校歌里所谓的西山吗（</p>
<p>其实这个远山一下子带我梦回山东老家了，小时候在外婆家住过几次，当时的老房子在费县站对面的家属院里，火车站背靠钟罗山，去爬过很多很多次，<del>然而一切都再也没有了</del>。坐京沪线每次路过山东都会停下手里的事情看看山，<del>毕竟你沪只有
99 米高的佘山（</del></p>
<p><img src="https://s2.loli.net/2023/07/18/TJiPF4o6bICZz9k.jpg" alt="法图.jpg"></p>
<h1 id="来点数学">来点数学</h1>
<p>这张图自然值得单独存放一遍，谢谢 Bowen L。</p>
<p><img src="https://s2.loli.net/2023/07/18/vIpZ8XEb2xjSD3W.jpg" alt="抽代.jpg"></p>
<h1 id="最实用奖">最实用奖</h1>
<p>当然是七港九的点餐二维码！每次想吃甜品的时候在清芬吃饭吃到最后就已经点上了，吃完走过去正好取到（</p>
<p><del>需要可以自取（（</del></p>
<p><img src="https://s2.loli.net/2023/07/18/8ntzEBobqscLKAv.jpg" alt="七港九.jpg"></p>
<h1 id="高下立判">高下立判</h1>
<p>在家里找有没有能替代未央这个文件夹的时候翻出来的一些平替，我的评价是高下立判（</p>
<p><img src="https://s2.loli.net/2023/07/18/eGsL8rmBzRDPwyb.jpg" alt="文件袋.jpg"></p>
<h1 id="最佳梗图">最佳梗图</h1>
<p>来点本年度我最喜欢的两张梗图（</p>
<p>（悲）</p>
<p><img src="https://s2.loli.net/2023/07/18/tCEl2D3cAQ5Tmg8.jpg" alt="空间营业_实际面基.jpeg"></p>
<p>学啥数学，不如研究高能神学（</p>
<p><img src="https://s2.loli.net/2023/07/18/3CdeY1LVPry5NMB.jpg" alt="潜在研究可能.jpeg"></p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>年度相册整理环节 2023.08 ~ 2024.07</title>
    <url>/2024/07/31/2024-photos-and-fragments/</url>
    <content><![CDATA[<p>今年倒是出去玩了好多次，除了日常的乐子还有点别的能发（</p>
<p>由于我对自己是本科第几年这件事现在实在是有一点恐惧，而且延毕也不能真的一直延，换个标题（（</p>
<span id="more"></span>
<h1 id="旅途">旅途</h1>
<p>除了北京上海之外，今年还去了天津，郑州，南昌，武汉，<del>后面这四个除了天津之外无一例外不想再去了</del>（x</p>
<p><img src="https://s2.loli.net/2024/08/01/E3FNnsbz49AQRMV.jpg" alt="IMG_20240429_141438.jpg"></p>
<p>2024.04.29 河南博物院的小鱼干，我把它叫做“我有一种不香的鱼干”。</p>
<p><img src="https://s2.loli.net/2024/08/01/OJ3wc9RnXfZQz87.jpg" alt="IMG_20240630_151851.jpg"></p>
<p>2024.06.30
江西省博物馆的陶瓷雕塑，应该是某个现代艺术作品展厅里拍到的，不是古物（<del>很显然</del>）。印象里作品名是类似于千锤百炼的意思，但我愿称之为：格里沙，看好了，巨人之力是这样用的（</p>
<p><img src="https://s2.loli.net/2024/08/01/XERUzgHkDMxoj4y.png" alt=".png"></p>
<p><del>克鲁格你坐啊（</del></p>
<p><img src="https://s2.loli.net/2024/08/01/cjCQbmpKMB17Hw5.jpg" alt="IMG_20240703_185736.jpg"></p>
<p>2024.07.03
赣江。在南昌的某日，晚上出来吃饭遛弯以及上滕王阁，我姐指着对岸跟我说，她有一个同学就在对面某个楼里上班，我思考了一下说是在对面工行吗？看起来很厉害的样子。她说不是，是对面一个写字楼的有家便利店。我沉默了。</p>
<p><img src="https://s2.loli.net/2024/08/01/tQiRumv6B3Vf5WA.jpg" alt="IMG_20240705_161330.jpg"></p>
<p>2024.07.05 东湖。从武大凌波门出来
<del>找绫波丽</del>，湖边确实凉快一点，就是在这个地方我姐接到了单位的报到通知。</p>
<p><img src="https://s2.loli.net/2024/08/01/TOaIzi16mrDqyVG.jpg" alt="Image_1722007567112.jpg"></p>
<p>2024.07.06
黄鹤楼。从司门口地铁站出来，想从这里拍拍照然后上长江大桥，正好看到这朵云。“昔人已乘黄鹤去”</p>
<p><del>别在意左下角的 M 了就是说（</del></p>
<p><img src="https://s2.loli.net/2024/08/01/NjX7AQvcbm9eTyn.jpg" alt="IMG_20240704_172628.jpg"></p>
<p><img src="https://s2.loli.net/2024/08/01/QYXWD3ndyiv6Khu.jpg" alt="IMG_20240704_183824.jpg"></p>
<p>2024.07.04 江汉路 X118，两款巨人 <del>天价</del> 很伟大的谷子。P2
这个斜角彩窗柄做成贴纸都要卖三十多了，感觉巨人的谷子要么很丑要么价格癫癫的
<del>要么就又丑价格又癫（批评一些 MAPPA
谷</del>，<del>但彩窗这一款某宝盗版亚克力只要 12</del></p>
<p>如果真有钱买的话 P2 的敏宝和三笠肯定会要的，P1
的敏宝和艾伦至少二选一，<del>其实我推阿尔敏（他真的太可爱了（x</del></p>
<p><del>说真的 P2 这个真的好想买盗版啊！12
一个的话恐怕艾伦和韩吉也都想要，但这么一算花 50
买一堆谷又不太符合我的消费能力，甚至还是盗版，唉（好孩子不要学啊！（x</del></p>
<p><img src="https://s2.loli.net/2024/08/01/aZblYreKHMtgoum.jpg" alt="IMG_20240726_233505.jpg"></p>
<p>2023.08.21
北京伊藤洋华堂，和我姐拍了结婚照（。那天正好是七夕，商场里还有挂卡片许愿（乞巧（？））的活动，恬不知耻地写了三张。其中我姐考公上岸这件事倒是已经实现了，那么我五年毕业也没啥问题吧（？</p>
<h1 id="雪">雪</h1>
<p><img src="https://s2.loli.net/2024/08/01/JrRvXbZNnEV4WqL.jpg" alt="IMG_20231212_170219.jpg"></p>
<p>2023.12.12
大草坪前面的小鸭子，<del>好想买个小黄鸭模具夹一排（，但还是这个比较有灵魂</del></p>
<p>前一天凌晨还跑下楼在雪地里拿一次性筷子划拉了《雪赋》，那个就不发了。</p>
<h1 id="猫">猫</h1>
<p>猫，但都是猫猫玩偶（</p>
<p><img src="https://s2.loli.net/2024/08/01/pgxz8TtrA41BuYs.jpg" alt="IMG_20240726_233619.jpg"></p>
<p>车力巨猫（</p>
<p><img src="https://s2.loli.net/2024/08/01/Ld9FvpHsz4JAjRu.jpg" alt="IMG_20240607_180847.jpg"></p>
<p>猫车</p>
<p>（猫：有点扎脚</p>
<h1 id="社聚">社聚</h1>
<p><img src="https://s2.loli.net/2024/08/01/ELWmjgbS3pKJ5Yu.jpg" alt="IMG_20231006_195507.jpg"></p>
<p>去年国庆社聚抽的雷诺曼，卡面真的太可爱力，感谢 neruko 老师。</p>
<p><img src="https://s2.loli.net/2024/08/01/tXsp8M3rDzxaZSJ.jpg" alt="IMG_20240228_152050.jpg"></p>
<p>喝了一个学期瑞幸，但最开始去瑞幸买咖啡其实只是想整两个纸袋做这个（</p>
<h1 id="其他">其他</h1>
<p><img src="https://s2.loli.net/2024/08/01/6QCntyT2LJArFZS.jpg" alt="IMG_20240722_160154.jpg"></p>
<p>我只是来听个报告，你怎么还骂我捏（拍屏幕致歉</p>
<p><img src="https://s2.loli.net/2024/08/01/rq1sZcWiVHanUNI.jpg" alt="mmexport1722496053030.jpg"></p>
<p>（挠头</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>2024 ICM Problem E Thesis</title>
    <url>/2024/04/30/2024-ICM-Problem-E/</url>
    <content><![CDATA[<p>2024 ICM Problem E: <a href="https://www.contest.comap.com/undergraduate/contests/mcm/contests/2024/problems/2024_ICM_Problem_E.pdf">Sustainability
of Property Insurance</a></p>
<p>还在比赛的时候我就想好了，赛后一定要向全世界公布这令人绝望的 S
奖预定论文影像（最后实际上是
H，我真觉得组委会目害了啊不是我们真的很牛逼了），让大家看到一个痛苦的文盲、用嘴建模的废物写出的
25 页论文（喜</p>
<p>最后一天凌晨四点左右才发现要求 summary sheet 字体必须是 Times New
Roman，看了下往年论文也没有用 palatino 的就全文都改了，然后就只有撑满的
24 页了，枉费我写的时候感觉可能不妙就一直压行。</p>
<span id="more"></span>
<h1 id="summary">Summary</h1>
<p>The growing threat of frequent meteorological disasters is
endangeringour planet. To promote the healthy development of the
insurance industry, we established an <strong>Insurance Model</strong>
to measure the impact of weather disasters, and implemented gradient
insurance policies in two different regions. We have also established a
<strong>Landmark Preservation Model</strong> and proposed relocation
suggestions for the <strong>Vizcaya Museum and Gardens</strong> to
evaluate preservation measure, and protect people's beloved
landmarks.</p>
<p>Firstly, we utilized <strong>Entropy Weight Method</strong> to assess
hurricane disaster risk in <strong>Florida</strong> and rainstorm
disaster risk in <strong>Indonesia</strong>. We constructed a climate
risk index (WDRI) with universality in meteorological aspects.
Subsequently, we respectively employed <strong>ARIMA</strong> and
<strong>prophet models</strong> to forecast the <strong>Style Risk
Factor</strong> for both regions. Conducting single-factor analysis and
multivariate analysis at both the logical and empirical levels, we
eliminated or equally weighted factors where risk exposure was not
significant, negatively impacting the goodness of fit (<span class="math inline">\(\textbf{R}^2 &gt; \textbf{0.98}\)</span>), and VIF
indicators (final <span class="math inline">\(\textbf{VIF} &lt;
\textbf{2}\)</span>) of the model. Following this, we performed multiple
regressions of premium pricing on several factors, achieving a model
confidence level of over <span class="math inline">\(\textbf{90}
\textbf{\%}\)</span>.</p>
<p>Furthermore, we devised <strong>graded underwriting
strategies</strong> and obtained a baseline CDVI for insurance companies
targeting regions experiencing an increasing frequency of extreme
weather events. Under the condition of maintaining the <strong>loss
ratio</strong> for insurance companies <strong>among</strong> <span class="math inline">\(\textbf{60}\textbf{\%}\)</span>
<strong>to</strong> <span class="math inline">\(\textbf{100}\textbf{\%}\)</span>, we aimed to
minimize the <strong>insurance protection gap</strong> to the greatest
extent possible.</p>
<p>Then, based on the premium pricing result of the insurance model and
climate risk index (WDRI), we incorporated repair costs to provide a
<strong>multiple linear regression</strong> calculation method and
theoretical explanation for the <strong>Local Livability Index</strong>
(LVI). Furthermore, we presented different land use scenarios under
various LVI conditions, making it possible to better utilize land
resources in the context of population growth.</p>
<p>Afterwards, by understanding the assessment scheme for historic
landmarks in the latest <strong>MAHT model</strong>, we established the
Landmark Preservation Model based on four indicators: historical and
cultural significance, resident satisfaction, disaster risk measurement
WDRI, and building damage level. We developed a <strong>decision
flowchart</strong> for implementing protection measures for landmark
buildings under different circumstances.</p>
<p>Finally, we used this model with <strong>over</strong> <strong>60
sub-indicators</strong> to evaluate the protection measures for the
<strong>Vizcaya Museum and Gardens</strong> in Miami, with a WDRI of
<strong>0.825</strong> thus cannot be insured. By calculating the
corresponding Landmark Weather Disaster Vulnerability Index (LWDVI) as
<strong>2.554</strong>, which indicates a relatively high level, we
identified the need for relocation due to the inability to implement
adequate protection measures and the predicted future submergence. A
community letter was also written accordingly.</p>
<p>Keywords: Property Insurance Model, Prophet Model, Entropy Weight
Method</p>
<h1 id="introduction">Introduction</h1>
<h2 id="problem-background">Problem Background</h2>
<p>Climate change is leading to an increase in the frequency and
severity of extreme weather events across the globe. This phenomenon has
profound implications for property owners, insurers and communities. The
cost of damages from natural disasters is skyrocketing, leading to
escalating insurance premiums and, in some cases, insurers withdrawing
coverage altogether in high-risk areas. This crisis threatens the
affordability of homeownership and the financial stability of the
insurance industry.</p>
<p>To cope with challenges brought by climate change, it's important to
seek methodologies to guide decision-making for both insurance companies
and community leaders. The overarching goal is to promote a sustainable
property insurance system that balances the need for affordable coverage
with the long-term viability of insurance providers, all while
considering the preservation of communities and their cultural
heritage.</p>
<h2 id="restatement-of-the-tasks">Restatement of the Tasks</h2>
<p>Considering the background information and restricted conditions
identified in the problem statement, we need to solve the following
tasks:</p>
<ul>
<li><p><strong>Task 1</strong>: Develop an index to measure the risk of
meteorological disasters in a given location with historical data.
Determine the factors of the insurance model. Devise a rule to obtain
the insurance coverage provided by an insurance company in a particular
region.</p></li>
<li><p><strong>Task 2</strong>: Utilize this index to measure the risk
of specific disaster losses in two different continents (we select
Florida in the United States and Indonesia), calculate and predict
future premiums, and assist insurance companies in determining the
coverage scope of insurance services.</p></li>
<li><p><strong>Task 3</strong>: Apply the developed insurance model to
assist community decision-makers in planning future property
construction, including site selection, construction techniques, and
other aspects in a future where the local population continues to grow
and faces increasing meteorological uncertainties.</p></li>
<li><p><strong>Task 4</strong>: Compare the costs and social value of
protecting buildings by estimating the economic and cultural value of
buildings within a community, and using existing indexes to assess the
severity of disasters.</p></li>
</ul>
<h2 id="our-work">Our Work</h2>
<p>To address the multi-dimensional estimation problem in such a complex
system, we referenced a large amount of relevant work and established
two models: the Insurance Model and the Landmark Preservation Model. The
schematic diagram of our study is shown in Figure 1. First, we
constructed a measure called WDRI to reflect the severity level of
meteorological disasters in a region. The WDRI was obtained through
standardizing data related to specific meteorological disaster factors
and applying the Entropy Weight Method. Next, we used this measure along
with Section/Style Risk Factors to develop a model for predicting
changes in local insurance costs using multiple linear regression and
prophet. Based on this model, we devised a method for calculating
insurance premiums in different regions for insurance companies.</p>
<p>Subsequently, we demonstrated this model using examples from two
different regions and designed a new measure called LVI, which helps
real estate companies determine the geographical location for property
development and strategies for development in various locations based on
empirical rules from relevant literature. Finally, by referencing
relevant literature, we utilized the MAHT model <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> to
design a measure, LV, for calculating the value of landmark buildings.
By combining the previously obtained WDRI, we calculated a measure,
LCDVR, for determining the protection needed for landmark buildings, and
established a decision-making flowchart for protection measures to
assist decision-makers.</p>
<p><img src="https://s2.loli.net/2024/02/06/Ts9YOzZGr53ckXR.png" alt="1.png"></p>
<h1 id="assumptions-and-justifications">Assumptions and
Justifications</h1>
<ul>
<li><p><strong>Assumption</strong>: The average housing rental prices
and insurance premiums in an area change proportionally at the same
time.</p>
<p><strong>Justification</strong>: During severe disasters, risks are
generally positively correlated with property values. Therefore, using
the average rental prices in the housing market to represent insurance
premiums is considered a reasonable proxy.</p></li>
<li><p><strong>Assumption</strong>: The duration of the hurricane
exhibits an exponential relationship with the pressure difference (<span class="math inline">\(P_{normal} - P_{min}\)</span>).</p>
<p><strong>Justification</strong>: We assume that the process of
pressure recovery in the hurricane center from its minimum to normal
pressure follows the Exponential Decay equation<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>
<span class="math inline">\(P(t) = P + (P_{normal} - P) \times (1 -
exp(-t \tau))\)</span>, where <span class="math inline">\(P(t)\)</span>
denotes pressure at time t, <span class="math inline">\(P_{min}\)</span>
represents the minimum pressure in the center of the hurricane, <span class="math inline">\(P_{normal}\)</span> is the normal pressure, and
<span class="math inline">\(\tau\)</span> is the time constant
characterizing the rate of pressure recovery. Also, we assume that <span class="math inline">\(\tau\)</span> remains consistent across
hurricanes.</p></li>
<li><p><strong>Assumption</strong>: The residents' satisfaction and
local viability index (LVI) in an area change proportionally at the same
time.</p>
<p><strong>Justification</strong>: Recent studies show that the life
satisfaction of local residents is mainly related to community density,
population size, economic development level, age distribution of
residents, and per capita income<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. These factors can be
approximated as measures of the local viability index (LVI) and used as
such after standardization<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. This is consistent with
common sense, as there is a very high correlation between residents'
satisfaction and the livability of an area.</p></li>
</ul>
<h1 id="notations">Notations</h1>
<p>The key mathematical notations used in this paper are listed in the
following table.</p>
<table>
<colgroup>
<col style="width: 27%">
<col style="width: 72%">
</colgroup>
<thead>
<tr class="header">
<th>Symbol</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(WDRI\)</span></td>
<td>Weather Disaster Risk Index</td>
</tr>
<tr class="even">
<td><span class="math inline">\(BWDRI\)</span></td>
<td>Baseline Weather Disaster Risk Index for Insurance</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(LRT\)</span></td>
<td>Loss Ratio for insurance companies</td>
</tr>
<tr class="even">
<td><span class="math inline">\(LV\)</span></td>
<td>Landmark Values</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(LR\)</span></td>
<td>Landmark Risks</td>
</tr>
<tr class="even">
<td><span class="math inline">\(IPP\)</span></td>
<td>Insurance premium plan</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(RC\)</span></td>
<td>Projected costs of repairs/rebuilds under potential climate event
scenarios</td>
</tr>
<tr class="even">
<td><span class="math inline">\(LVI\)</span></td>
<td>Local Viability Index</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(LIR\)</span></td>
<td>Inherent Risk of the Landmark</td>
</tr>
<tr class="even">
<td><span class="math inline">\(LWDVI\)</span></td>
<td>Landmark weather disaster vulnerability index</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(r_x\)</span></td>
<td>Radius of Maximum Wind (in nautical miles) in x</td>
</tr>
<tr class="even">
<td><span class="math inline">\(p_x\)</span></td>
<td>Minimum Pressure (in millibars) in x</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(w_x\)</span></td>
<td>Maximum sustained wind (in knots) in x</td>
</tr>
<tr class="even">
<td><span class="math inline">\(t_x\)</span></td>
<td>Temperature in x</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(pop\)</span></td>
<td>Population in an area (million people)</td>
</tr>
<tr class="even">
<td><span class="math inline">\(age\)</span></td>
<td>Median age of an area (year)</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(GDP\)</span></td>
<td>Annual GDP of an area (thousand dollars)</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\text{property price}\)</span></td>
<td>Residential Property Prices for Indonesia (Index 2010=100)</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(RH_{avg}\)</span></td>
<td>Average humidity (%)</td>
</tr>
<tr class="even">
<td><span class="math inline">\(RR\)</span></td>
<td>Rainfall (mm)</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(T_{avg}\)</span></td>
<td>Average temperature(<span class="math inline">\(^\circ
C\)</span>)</td>
</tr>
<tr class="even">
<td><span class="math inline">\(ff_{avg}\)</span></td>
<td>Average wind speed (m/s)</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(ss\)</span></td>
<td>Duration of sunshine (hour)</td>
</tr>
</tbody>
</table>
<h1 id="insurance-model">Insurance Model</h1>
<p>We can categorize risk pricing performance into the following four
implications:</p>
<ol type="1">
<li><p><strong>Return Forecast</strong>: Formulating reasonable and
effective predictions of returns.</p></li>
<li><p><strong>Process Control</strong>: Monitoring the entire insurance
premium pricing process to maintain consistency between pricing and
actual production.</p></li>
<li><p><strong>Cost Control</strong>: Avoiding excessive or inefficient
transactions.</p></li>
<li><p><strong>Risk Control</strong>: Capturing market opportunities
under prudent considerations.</p></li>
</ol>
<p>Taking into account various factors, we can express the claims risk
in the following multiple-factor model, and is interpreted more vividly
in</p>
<p><span class="math display">\[\text{insurance price} = \sum_{k=1}^n
\beta_k x_k +\varepsilon\]</span></p>
<p>In the model, <span class="math inline">\(x_k\)</span> represents the
original values of the factors, <span class="math inline">\(\beta_k\)</span> represents the risk exposure of
insurance price to the <span class="math inline">\(x_k\)</span> factor,
and <span class="math inline">\(\varepsilon\)</span> is the model
residual. Moreover, in the premium pricing model there are three
categories of risk factors: climate risk factors, sector risk factors,
and style risk factors (see Figure 3).</p>
<p><img src="https://s2.loli.net/2024/02/06/iLPfYuHtSIaNxTZ.png" alt="2-3.png"></p>
<p>The <strong>Weather Disaster Risk Factor</strong> reflects the
severity of certain or multiple meteorological disasters on the local
area. This should be quantified by collecting relevant historical data
on disasters and analyzing potential influencing factors
specifically.</p>
<p>The <strong>Sector Risk Factor</strong> mainly include the
characteristics of the insured property, such as the structure of
buildings, materials used, construction age, etc. In other words, we can
assess insurance prices based on the nature of the insured property.
Logically, this assumption is plausible. For example, concerning the
construction age, older buildings are more susceptible to damage,
leading to higher compensations for the property. In subsequent
empirical verification, the establishment of dummy variables for factors
like building materials, structure, and construction age being greater
than a specific reference value to access the overall risk
characteristics of insured buildings in a region.</p>
<p>The third category of factors is <strong>Style Risk Factors</strong>,
including population density, population age, regional gross domestic
product (GDP), and other elements. Logically, we can understand that a
region with a higher population density often indicates a higher level
of economic development and more concentrated housing, resulting in more
assets affected by disasters, which should lead to higher premiums. The
same reasoning applies to factors like GDP. However, it is worth noting
that these factors may exhibit multicollinearity, leading to potentially
inflated estimates of correlation.</p>
<p>After establishing the premium pricing model, we can conduct a
cost-benefit analysis for insurance companies and determine underwriting
policies and reference standards based on the risk index and regional
economic development. The first evaluation metric is the WDRI, and the
second is the loss ratio (LRT) defined as follows:</p>
<p><span class="math display">\[LRT = \frac{\text{Losses
Incured}}{\text{Earned Premium}} \times 100 \%.\]</span></p>
<p>According to relevant surveys, residents' insurance expenses are
roughly around <span class="math inline">\(5\%\)</span> of their average
personal income. Therefore, if, under a given disaster risk scenario,
the predicted premium (denoted as predicted price) exceeds <span class="math inline">\(5\%\)</span> of the average personal income, it is
recommended that the insurance company refrains from underwriting in
that region. The rationale is that residents in that area are likely to
perceive the insurance cost as excessively high, discouraging them from
purchasing insurance.</p>
<p>After obtaining the residents' insurance expenses, we can apply it to
the insurance model and inversely get the corresponding baseline WDRI
(BWDRI). It is advised that the insurance company does not underwrite in
areas with higher WDRI than the baseline.</p>
<p>To access the recommend policies concretely, the loss ratio (LRT)
should be taken into consideration. The lower the value of the loss
ratio, the better the performance of the insurance company in claims
handling.Generally, the profitability of insurance companies relies on
accurate pricing and claims management. If the loss ratio doesn't exceed
<span class="math inline">\(100\%\)</span>, the insurance company has a
surplus in claims expenditures, meaning there is a remainder between the
received premiums and the claims paid, and is acceptable.</p>
<h1 id="application-of-the-insurance-model-in-two-areas">Application of
the Insurance Model in Two Areas</h1>
<p>To illustrate our model, we have selected two regions, Indonesia in
Asia and Florida State in North America, for analysis. Florida is known
to be prone to hurricanes, while Indonesia is susceptible to rainstorms
and earthquakes.</p>
<h2 id="analysis-of-florida-state-usa">Analysis of Florida State,
USA</h2>
<h3 id="background">Background</h3>
<p>Florida is located in the northwestern part of the Atlantic Ocean and
is frequently affected by weather disasters. Home insurance costs in
Florida are increasing substantially, causing concern among
propertyowners, community managers, and potential buyers about the
future of the insurance market in the state.</p>
<p>Among the weather disasters affecting Florida, the most severe ones
are hurricanes. According to data collected by the National Oceanic and
Atmospheric Administration (NOAA), a heat map (see Figure 4) and a
histogram (see Figure 5) both reveal that the severity of hurricane
damage in Florida in the eastern United States is extremely strong.</p>
<p><img src="https://s2.loli.net/2024/02/06/vlxWpu2qr7Dmdyh.png" alt="4-5.png"></p>
<h3 id="conclusions-obtained-by-insurance-model">Conclusions Obtained by
Insurance Model</h3>
<p>Firstly, we construct the Weather Disaster Risk Index (WDRI) to
quantify the <strong>Climate Risk Disaster Factor</strong>. Data on
hurricane trajectories of Northern Atlantic from 1994-2022 was
collected, where Radius of Maximum Wind (<span class="math inline">\(r_i\)</span>, in nautical miles) ,Minimum Pressure
(<span class="math inline">\(p\)</span>, in millibars) ,Maximum
sustained wind (<span class="math inline">\(w\)</span>, in knots) and
temperature (<span class="math inline">\(t\)</span>, in Fahrenheit
degrees) are known. Normalization was applied to the data in order to
balance discrepancies among different measurement units.</p>
<p>The WDRI is accessed through Entropy Weight Method, which determines
the weight of each coefficients. The desired model construction is as
follows<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>:</p>
<p><span class="math display">\[WDRI = r_i^2 \times (\log (p_0 - p_i)+
c_1 \times t) \times w_i^3\]</span></p>
<p>We assume that <span class="math inline">\(r^2\)</span> is
proportional to the hurricane's force range and <span class="math inline">\(\log(p_0-p_i)\)</span> is proportional to the
hurricane's duration. Furthermore, given that a hurricane is powered by
the condensation from heat, <span class="math inline">\(c_1 \times
t\)</span> is used to represent the weakening effect of low temperatures
on the hurricane. The wind force (F) is proportional to the cube of the
wind speed (V), i.e., <span class="math inline">\(F\propto
w^3\)</span>.</p>
<p>Given the climate data of each area in the Florida State, we can
calculate the WDRI index for various regions in the state of Florida. At
the same time, by collecting data on the local population (pop), average
age (age), and GDP to represent the Style Risk Factor, and assuming the
use of local real estate rental prices as the insurance cost indicator,
we can use a multiple linear regression model to estimate and predict
insurance costs.</p>
<p>Now try to identify the effectiveness of the factors by conducting a
correlation analysis among the existing factor sequences (see Figure
6).</p>
<p><img src="https://s2.loli.net/2024/02/06/dwGmJ5Xal8fPKj4.png" alt="6.png"></p>
<p>All four factors exhibit relatively high correlations with insurance
prices, indicating predictive potential. Notably, the correlation
between pop and age is remarkably high at 0.9881, and the correlations
among pop, age, and GDP all exceed 0.9. In light of these high
correlations, we may consider synthesizing these factors for subsequent
calculations.</p>
<p>If we proceed with a multiple regression using the four factors
directly, the model's <span class="math inline">\(R^2\)</span> is close
to <span class="math inline">\(1\)</span>, indicating an excellent fit.
However the average <span class="math inline">\(VIF\)</span> for this
model exceeds <span class="math inline">\(10\)</span>, suggesting the
possibility of multicollinearity among factors.</p>
<p>By continuously adjusting the number of factors and interaction
relationships in the model, we ultimately obtain the model:</p>
<p><span class="math display">\[\text{insurance price} = 19591.13 +
255.7892 WDRI - 496.4459 age + 2.34 \times 10^{-6} GDP +
\varepsilon.\]</span></p>
<p>Its advantage lies in minimizing the <span class="math inline">\(VIF\)</span> value as much as possible, thereby
eliminating the impact of multicollinearity on the model. At the same
time, as a trade-off, there is a slight decrease in the <span class="math inline">\(R^2\)</span> value, but it does not greatly affect
the power of explanation.</p>
<p>By individually predicting the values for each factor and then using
the above model to calculate the predicted price, we obtain the results
shown in the following table:</p>
<table style="width:100%;">
<colgroup>
<col style="width: 7%">
<col style="width: 20%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 15%">
<col style="width: 20%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th>year</th>
<th>insurance price</th>
<th>WDRI</th>
<th>age</th>
<th>GDP</th>
<th>predicted price</th>
<th>bias</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(2023\)</span></td>
<td><span class="math inline">\(2082.748864\)</span></td>
<td><span class="math inline">\(0.164995\)</span></td>
<td>$ 44.58478$</td>
<td><span class="math inline">\(1458543489\)</span></td>
<td>$2012.396311 $</td>
<td><span class="math inline">\(3.38\%\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(2024\)</span></td>
<td><span class="math inline">\(2200.818663\)</span></td>
<td>$ 0.140109$</td>
<td><span class="math inline">\(44.80708\)</span></td>
<td>$1468596527 $</td>
<td>$2119.191825 $</td>
<td><span class="math inline">\(3.71\%\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(2025\)</span></td>
<td>$2318.888461 $</td>
<td><span class="math inline">\(0.294665\)</span></td>
<td><span class="math inline">\(45.02939\)</span></td>
<td>$1470572644 $</td>
<td>$2252.986414 $</td>
<td>$2.84% $</td>
</tr>
</tbody>
</table>
<p>The bias between the predicted price obtained from the model and the
officially predicted insurance price is approximately <span class="math inline">\(3\%\)</span>, within an acceptable margin of
error. Therefore, we consider the model pricing to be effective.</p>
<p>Based on statistical data, the typical annual income for residents in
Florida is <span class="math inline">\(\$52,000\)</span> USD. Using this
data, with <span class="math inline">\(5\%\)</span> as the maximum
predicted premium value, the regression model calculates that the WDRI
should be less than or equal to <span class="math inline">\(0.74\)</span>.</p>
<p>In cases where the predicted premium price is greater than <span class="math inline">\(1\%\)</span> but less than <span class="math inline">\(5\%\)</span> of the average annual income, the
corresponding storm risk range should be between <span class="math inline">\(0.34\)</span> and <span class="math inline">\(0.74\)</span>. It is recommended that the
insurance company can maintain a loss ratio below <span class="math inline">\(100 \%\)</span> (profitable) and selectively
decrease the loss ratio, for example, setting it at <span class="math inline">\(60\%\)</span>. Under this standard, the insurance
company can introduce an insurance product: charging <span class="math inline">\(\$492\)</span> USD per square meter of property at
one time and paying a premium of <span class="math inline">\(\$1560\)</span> USD during a five-year insurance
period.</p>
<p>In situations where the predicted premium price is less than <span class="math inline">\(1\%\)</span> of the average annual income, the
corresponding WDRI is less than <span class="math inline">\(0.34\)</span>, indicating a lower probability of
hurricanes damage. In such cases, the insurance company slightly
increase the loss ratio to enhance its commercial competitiveness, for
instance, setting the loss ratio at <span class="math inline">\(70\%\)</span>. Under this standard, the insurance
company can introduce an insurance product: charging <span class="math inline">\(\$162\)</span> USD per square meter of property at
one time and paying a premium of <span class="math inline">\(\$520\)</span> USD during a five-year insurance
period.</p>
<p>It is important to note that in a specific market environment,
insurance companies may adopt different strategies to adjust the loss
ratio to maintain competitiveness and profitability.</p>
<p>Crucially, a low loss ratio is not always favorable, as it may
indicate the company is overly conservative in risk assessment, leading
to excessively high premium pricing and potential loss of
competitiveness. Also, the establishment of the loss ratio also
reflects, to some extent, the social responsibility of insurance
companies. In areas where residents' annual income is relatively low, we
recommend insurance companies adopt a higher loss ratio insurance policy
to help reduce <strong>Insurance Protection Gap</strong> for vulnerable
people in disasters. This policy not only yields the effect of profits
but also helps to establish the responsible social image of the
insurance company, contributing to the sustainable development of the
enterprise.</p>
<h2 id="analysis-of-indonesia">Analysis of Indonesia</h2>
<h3 id="background-1">Background</h3>
<p>Indonesia, a country made up of thousands of islands, is prone to
severe rainstorm disasters due to its location. The country experiences
frequent flooding, land-slides, and other related disasters, which lead
to destruction to infrastructure, homes, and agricultural land, as well
as loss of lives and displacement of communities. (see Figure 7, 8)</p>
<p><img src="https://s2.loli.net/2024/02/06/2gZ9hv6K57bxtRy.png" alt="7-8.png"></p>
<h3 id="conclusions-obtained-by-insurance-model-1">Conclusions Obtained
by Insurance Model</h3>
<p>We continue to employ a multi-factor model to assess the predicted
insurance premium pricing situation in Indonesia. In the design of this
model, we incorporate three factors to evaluate insurance prices
(substituting Property Prices for Indonesia as the dependent variable,
take Index <span class="math inline">\(2010=100\)</span>), namely WDRI
again, GDP, and population.</p>
<p>First, we create the Weather Disaster Risk Index (WDRI) to quantify
the factors related to Climate Risk Disaster. Indonesia daily climate
data from 2010 to 2022 were gathered to calculate it, focusing on key
factors including the average humidity (<span class="math inline">\(RH_{avg}\)</span>, in %), rainfall (<span class="math inline">\(RR\)</span>, in mm), average temperature (<span class="math inline">\(T_{avg}\)</span>, in degrees of Celsius), average
wind speed (<span class="math inline">\(ff_{avg}\)</span>) and duration
of sunshine (<span class="math inline">\(ss\)</span>, in hour).
Standardization was applied during data processing.</p>
<p>Firstly, <span class="math inline">\(RR\)</span> (rainfall data) is
directly related to floods according to common sense. Secondly, we
investigated the relationship between Temperature and Rainfall, finding
that rainfall peaked near 26 degrees Celsius, so we took <span class="math inline">\(|T_{avg}-26|\)</span> as a related influencing
factor (see Figure 9). According to online materials<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>,
there is a positive correlation between cloud cover and floods. Assuming
the appearance of clouds is negatively correlated with sunlight, we
built -<span class="math inline">\(ss\)</span> as a positively
correlated factor. The desired model construction is as follows:</p>
<p><span class="math display">\[WDRI = c(\alpha |T_{avg}-26| + \beta
(-ss) + \gamma RH_{avg} + \sigma ff_{avg})RR.\]</span></p>
<p>Where <span class="math inline">\(c\)</span> is the scaling factor,
<span class="math inline">\(RR\)</span> is considered as a key factor
indicating the amount of rainfall, and <span class="math inline">\(|T_{avg}-26|\)</span> is applied with reference to
the statistical information shown in Figure 9 that rainfall has a peak
distribution around <span class="math inline">\(26 ^\text{o}\)</span>C.
<span class="math inline">\(\alpha , \beta , \gamma ,\sigma\)</span> are
coefficients to be determined by Entropy Weight Method. The coefficients
obtained are:</p>
<p><span class="math display">\[\alpha = 0.303696, \beta=0.239401 ,
\gamma=0.186802 ,\sigma=0.270101.\]</span></p>
<p>Given the climate data of each area in Indonesia, we can calculate
the WDRI index for various regions here. At the same time, by collecting
data on the local population (pop) and GDP to represent the Style Risk
Factor, and assuming the use of property price as the insurance cost
indicator, we can use a multiple linear regression model to estimate and
predict insurance costs.</p>
<p>Now try to identify the effectiveness of the factors by conducting a
correlation analysis among the existing factor sequences (see Figure
10).</p>
<p><img src="https://s2.loli.net/2024/02/06/u8iQGmlg15sntax.png" alt="9-10.png"></p>
<p>We observe a relatively low correlation between the climate factor
and the dependent variable, suggesting that it may be considered for
exclusion in the regression analysis. The GDP and population factors
exhibit a high correlation, indicating a potential issue of
multicollinearity. In our empirical testing, we will monitor the
Variance Inflation Factor (VIF) values to address this concern.
Regarding the heteroscedasticity of the model, we will not consider it
in the prediction problem at the moment.</p>
<p>When attempting to model predictions simultaneously with all three
factors, we find that the risk exposure on the dependent variable
concerning the GDP factor is not significant. Additionally, the GDP
factor contributes significantly to the VIF. Therefore, we initially
exclude the GDP factor. Subsequently, we conduct a regression using the
climate and population factors, resulting in the following model:</p>
<p><span class="math display">\[\text{insurance price} = -78.36633 WDRI
+6.69 \times 10^{-6} population - 1026.793+ \varepsilon.\]</span></p>
<p>The average <span class="math inline">\(VIF = 1.10\)</span> and <span class="math inline">\(R^2 = 0.9831\)</span>, indicates a good fit of the
model without severe multicollinearity.</p>
<p>Then we utilize the prophet model to forecast future values for
population and property prices. Comparing these forecasts with the
predicted prices calculated using the insurance model, we obtain the
bias as presented in the following table:</p>
<table style="width:100%;">
<colgroup>
<col style="width: 8%">
<col style="width: 23%">
<col style="width: 15%">
<col style="width: 18%">
<col style="width: 21%">
<col style="width: 11%">
</colgroup>
<thead>
<tr class="header">
<th>Year</th>
<th>Property price</th>
<th>WDRI</th>
<th>Population</th>
<th>Predicted Price</th>
<th>Bias</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(2023\)</span></td>
<td><span class="math inline">\(653.8139981\)</span></td>
<td>$ 2.37908 $</td>
<td><span class="math inline">\(275225919\)</span></td>
<td><span class="math inline">\(628.0286297\)</span></td>
<td><span class="math inline">\(3.94\%\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(2024\)</span></td>
<td>$665.8297629 $</td>
<td><span class="math inline">\(2.47889\)</span></td>
<td>$274957915 $</td>
<td><span class="math inline">\(618.4139396\)</span></td>
<td><span class="math inline">\(7.12\%\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(2025\)</span></td>
<td>$675.4485198 $</td>
<td><span class="math inline">\(2.57856\)</span></td>
<td><span class="math inline">\(274697125\)</span></td>
<td>$ 608.8584824 $</td>
<td><span class="math inline">\(9.86\%\)</span></td>
</tr>
</tbody>
</table>
<p>Therefore we have at least <span class="math inline">\(90\%\)</span>
confident that the model is accurate and reasonable.</p>
<p>Statistical data indicates that the per capita GDP of Indonesia in
2022 was <span class="math inline">\(\$4,788\)</span>, and a reasonable
estimate for future per capita GDP is around <span class="math inline">\(\$5,000\)</span>. In a given risk scenario, if the
predicted premium (represented as the predicted price) exceeds <span class="math inline">\(5\%\)</span> of the average personal income, it is
recommended that the insurance company refrains from underwriting in
that region.</p>
<p>Using <span class="math inline">\(5\%\)</span> as the maximum
predicted premium value, the regression model calculates that the
climate risk index should be less than or equal to <span class="math inline">\(0.82\)</span>. This data suggests that if the
calculated climate risk index for a province in Indonesia exceeds <span class="math inline">\(0.82\)</span>, it is advisable for the insurance
company to abstain from underwriting in that region.</p>
<p>In cases where the predicted premium price is greater than <span class="math inline">\(1\%\)</span> but less than <span class="math inline">\(5\%\)</span> of the average annual income, the
corresponding risk index range should be between <span class="math inline">\(0.48\)</span> and <span class="math inline">\(0.82\)</span>. It is recommended that the
insurance company selectively lowers the loss ratio, keeping it below
<span class="math inline">\(100 \%\)</span> (profitable), for example,
setting it at <span class="math inline">\(60\%\)</span>. Under this
standard, the insurance company can introduce an insurance product:
charging <span class="math inline">\(\$38\)</span> per square meter of
property at one time and paying a premium of <span class="math inline">\(\$150\)</span> during a five-year insurance
period.</p>
<p>In situations where the predicted premium price is less than <span class="math inline">\(1\%\)</span> of the average annual income, the
corresponding risk index range is less than <span class="math inline">\(0.48\)</span>, indicating a lower probability of
rainstorm disasters. In such cases, it is suggested that the insurance
company slightly increases the loss ratio to enhance its commercial
competitiveness in the regional insurance industry, for instance,
setting the loss ratio at <span class="math inline">\(70\%\)</span>.
Under this standard, the insurance company can introduce an insurance
product: charging <span class="math inline">\(\$12\)</span> per square
meter of property at one time and paying a premium of <span class="math inline">\(\$50\)</span> during a five-year insurance
period.</p>
<p>Crucially, a low loss ratio is not always favorable, as it may
indicate the company is overly conservative in risk assessment, leading
to excessively high premium pricing and potential loss of
competitiveness. Also, the establishment of the loss ratio also
reflects, to some extent, the social responsibility of insurance
companies. In areas like Indonesia where residents' annual income is
relatively low with respective to the world average, we recommend
insurance companies adopt a higher loss ratio insurance policy to help
reduce <strong>Insurance Protection Gap</strong> for vulnerable people
in disasters. This policy not only yields the effect of profits but also
helps to establish the responsible social image of the insurance
company, contributing to the sustainable development of the
enterprise.</p>
<h1 id="applications-to-building-sites-choices">Applications to Building
Sites Choices</h1>
<p>We aim to establish a multifactorial indicator called the Location
Viability Index (LVI) to assess whether an area is suitable for
developing real estate projects and for living. The three main
influencing factors are as follows:</p>
<ol type="1">
<li><p>Weather Disaster Risk Index (WDRI) evaluated in the insurance
model, which quantifies the disaster risk for each location;</p></li>
<li><p>Recommended insurance premium plan for insurance companies
according to the insurance model (IPP: No insurance / High Premium / Low
Premium);</p></li>
<li><p>Projected costs of repairs/rebuilds under potential climate event
scenarios (RC).</p></li>
</ol>
<p>Recent studies show that the life satisfaction of local residents is
mainly related to community density, population size, economic
development level, age distribution of residents, and per capita
income<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. These factors can be approximated
as measures of the local viability index (LVI) and used as such after
standardization<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. This is consistent with common
sense, as there is a very high correlation between residents'
satisfaction and the livability of an area. Therefore, a linear
regression model for LVI can be established based on the above three
influencing factors:</p>
<p><span class="math display">\[LVI = b_0 + b_1 WDRI + b_2 IPP + b_3 RC
+ \varepsilon\]</span></p>
<p>Where IPP is an integer variable as being <span class="math inline">\(0\)</span> for no insurance case, <span class="math inline">\(1\)</span> for high insurance and <span class="math inline">\(2\)</span> for low insurance according to the
insurance model. <span class="math inline">\(b_0, b_1 ,b_2, b_3\)</span>
are coefficients to be estimated according to the dataset.</p>
<p>After obtaining a Location Viability Index that can fit the actual
situation well, it can be used to estimate the livability of various
areas, and they can be divided into livable and non-livable areas under
meteorological disasters according to proportion.</p>
<p>Livable areas need to be prioritized and appropriately developed to
accommodate future population growth, with specific measures
including:</p>
<ol type="1">
<li><p>Construct higher-density residential communities with supporting
facilities;</p></li>
<li><p>Negotiate with insurance companies and communities to reach
cooperation agreements to reduce the residential insurance costs in the
area, thereby lowering the living cost and attracting
residents.</p></li>
</ol>
<p>In the ongoing urban development, the area will be transformed into a
vibrant community, where abundant facilities can meet the resources
needed for population growth.</p>
<p>For regions that are not suitable enough for living, large-scale
vacant land can be developed for tourism and open during disaster-free
seasons. Local managers should ensure daily warning and management work,
driving the economic development of the local area, and compensating for
possible losses caused by weather disasters.</p>
<p>The standards should be re-evaluated every 3-5 years as new risk
assessments and climate impact projections are available. This allows
development guidelines to adapt.</p>
<h1 id="landmark-preservation-model">Landmark Preservation Model</h1>
<h2 id="value-of-landmark">Value of Landmark</h2>
<p>We construct a metric to quantify the value of each landmark first.
According to existing study <a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>, this mainly includes
two aspects, heritage attributes and residential satisfaction (for the
corresponding MAHT model, see Figure 11). Also, these two indicators are
<strong>complementary</strong> as the Pincipal Component Analysis result
shows that these two together can explain <span class="math inline">\(74.64 \%\)</span> of variance according to the
study <a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>.</p>
<p><img src="https://s2.loli.net/2024/02/06/GLxCZUeQNMSqWOJ.png" alt="11.png"></p>
<p>On the other hand, this approach is reasonable for our research.
Firstly, we discuss landmark historical buildings, which often have
important <strong>historical and cultural significance</strong>. For
example, they may have an exquisite structure or a long history. In
addition, they carry the memories of residents and have strong
<strong>emotional values</strong> of residents. People are proud to have
such a landmark building in their place of residence and love it
wholeheartedly. This is also the important value and significance of
protecting such community historical landmark buildings.</p>
<p>Therefore, we need to consider this issue from these two aspects:
heritage attributes and residential satisfaction. To facilitate the
subsequent calculations, we introduce the following symbols to represent
the main indicators:</p>
<p><span class="math display">\[(LV, PC2, PC3, HA1, HA2, HA3, HA, RS1,
RS2, RS3, RS)\]</span></p>
<p>Where <span class="math inline">\(LV\)</span> represents the value of
the landmark, and <span class="math inline">\(PC2, PC3\)</span>
represent the 2nd and 3rd principal components. <span class="math inline">\(HA, HA1,HA2,HA3\)</span> are heritage attribute
with its sub-level variables, and <span class="math inline">\(RS,
RS1,RS2,RS3\)</span> are residential satisfaction with its sub-level
variables. We approximately describe the result of <span class="math inline">\(PC2, PC3\)</span> as linear combinations of the
main indicators in terms according to the results in the study <a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>:</p>
<p><span class="math display">\[\begin{gathered}
      PC2 = 0.89 HA1 +0.939 HA2 + 0.887 HA3 + 0.971 HA \\
      PC3 = 0.471 RS1 + 0.604 RS2 + 0.67 RS3 + 0.806 RS
\end{gathered}\]</span></p>
<p>The existing results <a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> show that principal
component 2 and principal component 3 can represent the two parts of
heritage attributes and residential satisfaction indicators,
respectively. Therefore, we can set the value of landmark architecture
as the sum of the two principal components, which can explain <span class="math inline">\(37.45\%\)</span> of the variance and has a strong
explanatory power. Thus the value of the landmark can be set as the sum
of both principle components: <span class="math display">\[LV = PC2
+PC3\]</span> Note that according to existing research results <a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>, the calculation of various
indicators for <span class="math inline">\(HA\)</span> and <span class="math inline">\(RS\)</span> involves a weighted summation of 31
sub-indicators, which is relatively complex and lengthy. The specific
calculation method can be found in Appendix 1, which is not provided in
detail here.</p>
<h2 id="risks-of-landmark">Risks of Landmark</h2>
<p>The risks that landmark buildings may face need to be considered in
two parts. Firstly, there are inherent risks associated with the
building itself, such as erosion of building materials or existing
structural damage, which can lead to damage to the landmark under
extreme weather conditions.</p>
<p>In addition, the external risks of meteorological disasters that the
building's location may face should also be taken into account. This is
because the landmark buildings considered are located in regions where
insurance companies perceive a higher risk of meteorological disasters,
thus requiring the inclusion of meteorological disaster risks in the
assessment. For the sake of consistency and generality, the Weather
Disaster Risk Index established earlier can be directly used as an
evaluation indicator.</p>
<p>For the inherent risks of landmark buildings, existing research <a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> indicates that the MAHT model can
still be used, and the first principal component PC1 from the model can
be used as a risk indicator. Therefore, we need to consider this issue
from these two aspects: heritage attributes and residential
satisfaction. To facilitate the subsequent calculations, we introduce
the following symbols to represent the main indicators:</p>
<p><span class="math display">\[(LIR, PC1, SC1, SC2, SC3, SC,
OI)\]</span></p>
<p>Where <span class="math inline">\(LIR\)</span> represents the
inherent risk of the landmark, and <span class="math inline">\(PC1\)</span> represents the first principal
component. <span class="math inline">\(SC, SC1, SC2, SC3\)</span> are
safety conditions with sub-level variables. Moreover, <span class="math inline">\(OI\)</span> is the third layer variable of the
MAHT model. We approximately describe the result of <span class="math inline">\(PC1\)</span> as linear combinations of the main
indicators in terms according to the results in the study <a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>:</p>
<p><span class="math display">\[PC1 = 0.749 SC1 + 0.729 SC2 + 0.76 SC3 +
0.874 SC + 0.908 OI\]</span></p>
<p>The existing results <a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> show that principal
component 1 can represent the safety condition of the landmark.
Therefore, we can set the inherent risk of the landmark as the first
principal component, which can explain <span class="math inline">\(37.19\%\)</span> of the variance and has the
strongest explanatory power.</p>
<h2 id="landmark-weather-disaster-vulnerability-index">Landmark Weather
Disaster Vulnerability Index</h2>
<p>Note that regarding the indicators related to landmark risk and
landmark value mentioned earlier, <span class="math inline">\(PC1\)</span>, <span class="math inline">\(PC2\)</span>, and <span class="math inline">\(PC3\)</span> come from the same evaluation system
and therefore need to be standardized collectively before calculations,
where the maximum value normalization method is adopted. The
standardized results are respectively denoted as <span class="math inline">\(PC1^{&#39;}\)</span>, <span class="math inline">\(PC2^{&#39;}\)</span>, and <span class="math inline">\(PC3^{&#39;}\)</span>. The calculation method is as
follows:</p>
<p><span class="math display">\[\begin{gathered}
    PC1^{&#39;} = \frac{PC1}{\max \{ PC1, PC2, PC3\}} \\
    PC2^{&#39;} = \frac{PC2}{\max \{ PC1, PC2, PC3\}} \\
    PC3^{&#39;} = \frac{PC3}{\max \{ PC1, PC2, PC3\}}.
\end{gathered}\]</span></p>
<p>Moreover, the Weather Disaster Risk Index (WDRI) is already
standardized data and can be calculated directly. Therefore, the final
calculation formula for the Landmark Weather Disaster Vulnerability
Index (LWDVI) is:</p>
<p><span class="math display">\[LWDVI = (PC2^{&#39;} +PC3^{&#39;})\times
(WDRI +PC1^{&#39;}).\]</span></p>
<p>Similarly, the standardized result of value of landmark (<span class="math inline">\(LV\)</span>) can be interpreted as:</p>
<p><span class="math display">\[LV^{\prime} = PC2^{&#39;}
+PC3^{&#39;}.\]</span></p>
<h2 id="construction-of-landmark-preservation-model">Construction of
Landmark Preservation Model</h2>
<p>Existing research <a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a> shows that after obtaining the
above indicators, decisions can be made based on the satisficing model,
making the decision results closest to reality and easiest for policy
implementation. The following decision flowchart (see Figure 12) can
well reflect our recommended decision-making approach.</p>
<p><img src="https://s2.loli.net/2024/02/06/7TLGFwCJa2WkKyg.png" alt="12.png"></p>
<p>This decision flowchart provides various protection schemes for
landmarks with different values and varying internal and external risk
levels. The decision-maker also needs to consider factors such as budget
and available funds and use the landmark preservation model to determine
the appropriate protection measures for the landmark.</p>
<h2 id="application-to-vizcaya-museum-and-gardens">Application to
Vizcaya Museum and Gardens</h2>
<h3 id="background-2">Background</h3>
<p>The Vizcaya Museum and Gardens, a historic landmark in Miami,
Florida, faces significant threats from hurricanes and other natural
disasters. The estate has faced numerous hurricanes over the years,
including Hurricane Irma in 2017. While the property experienced huge
damage, the potential impact of future storms remains a significant
concern.</p>
<p>To make matters worse, with a calculated WDRI of <span class="math inline">\(0.825\)</span> for Miami and the baseline WDRI as
<span class="math inline">\(0.74\)</span>, it is advised that the
insurance company does not underwrite in the Miami region. Therefore, we
need to use the obtained Landmark Preservation Model to consider the
most suitable preservation plan for this historic landmark building.</p>
<h3 id="conclusions-obtained-by-the-landmark-preservation-model">Conclusions
Obtained by the Landmark Preservation Model</h3>
<p>By inputting the collected data into the MAHT model and the landmark
preservation model, the corresponding indicators are obtained as shown
in the following table.</p>
<table style="width:100%;">
<colgroup>
<col style="width: 13%">
<col style="width: 17%">
<col style="width: 13%">
<col style="width: 16%">
<col style="width: 23%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Indicator</th>
<th>Value</th>
<th>Indicator</th>
<th>Value</th>
<th>Indicator</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(HA1\)</span></td>
<td><span class="math inline">\(0.961538\)</span></td>
<td>$OI $</td>
<td><span class="math inline">\(0.657534\)</span></td>
<td><span class="math inline">\(PC1^{\prime}\)</span></td>
<td>$0.53873 $</td>
</tr>
<tr class="even">
<td>$HA2 $</td>
<td><span class="math inline">\(0.789474\)</span></td>
<td><span class="math inline">\(PC1\)</span></td>
<td><span class="math inline">\(1.575885\)</span></td>
<td><span class="math inline">\(PC2^{\prime}\)</span></td>
<td>$ 1 $</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(HA3\)</span></td>
<td><span class="math inline">\(0.611111\)</span></td>
<td>$ PC2$</td>
<td>$ 2.925188$</td>
<td>$PC3^{} $</td>
<td><span class="math inline">\(0.872081\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(HA\)</span></td>
<td><span class="math inline">\(0.809524\)</span></td>
<td>$PC3 $</td>
<td>$2.551 $</td>
<td>$ WDRI $</td>
<td><span class="math inline">\(0.825347\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(SC1\)</span></td>
<td><span class="math inline">\(0.347826\)</span></td>
<td></td>
<td></td>
<td>$LV^{} $</td>
<td>$1.872081 $</td>
</tr>
<tr class="even">
<td><span class="math inline">\(SC2\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td></td>
<td></td>
<td><span class="math inline">\(LWDVI\)</span></td>
<td><span class="math inline">\(2.553661\)</span></td>
</tr>
<tr class="odd">
<td>$SC3 $</td>
<td>$0.5 $</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>$SC $</td>
<td>$ 0.387097 $</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>$RS1 $</td>
<td><span class="math inline">\(1\)</span></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(RS2\)</span></td>
<td>$ 1 $</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(RS3\)</span></td>
<td>$ 1 $</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(RS\)</span></td>
<td><span class="math inline">\(1\)</span></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Based on the obtained results and the decision flowchart, the
suitable preservation plan for Vizcaya Museum and Gardens includes the
following:</p>
<ul>
<li><p>Structural strengthening measures are necessary to ensure the
safety of the building. For instance, steel beams or reinforced concrete
can be added to the building to reinforce its structural
integrity.</p></li>
<li><p>Specific weather hazard protection measures are required; for
instance, hurricane-resistant windows and doors can be installed to
protect the building from harsh weather conditions.</p></li>
<li><p>Relocation should be considered when necessary; for example, if
the building is located in a high-risk area for natural disasters, it
may be safer to relocate it to a less risky location.</p></li>
</ul>
<p>However, according to NOAA's intermediate-high sea-level-rise
predictions for the years 2060 and 2100<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a>,
the gardens will sink in 40 years. To make matters worse, typical
engineered adaptive measures, such as levees, flood walls, and many
flood-proofing techniques are not suitable for Vizcaya. There are no
current municipal plans for hard infrastructure improvements to help
protect Vizcaya Museum and Gardens from future storms or rising seas.<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a></p>
<p>Meanwhile, the insurance model for the Miami-Dade County area shows
that Vizcaya Museum and Gardens is located in a high-risk area where
insurance cannot be obtained. In such unfavorable conditions,
<strong>the best solution to protect this landmark is to relocate it to
a safer location</strong>. The one-page community letter is attached to
the page before the Appendices.</p>
<h1 id="sensitivity-analysis">Sensitivity Analysis</h1>
<h2 id="sensitivity-analysis-for-insurance-model">Sensitivity Analysis
for Insurance Model</h2>
<p>To execute a sensitivity investigation of the flood disaster severity
evaluation model, we held the other indices at their current values and
progressively enhanced the principle components, subsequently
calculating the alterations in the Weather Disaster Risk Index (WDRI)
consequential from this adjustment. The resulting data is illustrated in
Figure 13.</p>
<p><img src="https://s2.loli.net/2024/02/06/oXbpzfj4Jgl8xuF.png" alt="13.png"></p>
<p>The findings demonstrate that the WDRI is most notably affected when
'Rainfall' (RR) increases, denoting it has the most significant impact.
Conversely,less extreme impact of other variables suggest that these
elements, though important, have a comparatively smaller effect. From
these results, it's evident that flood disaster severity is most
sensitive to rainfall levels. This is consistent with the concrete
scenario, as rainfall is undeniably a central factor in determining the
intensity and likelihood of floods. Consequently, in devising disaster
mitigation strategies, the focus should primarily be on developing flood
control measures that can effectively deal with high rainfall
levels.</p>
<p>Lastly, our findings also suggest that the model is robust and can
reliably anticipate disaster severity, even in the face of minor data
errors. This feature enhances the model's practical applicability and
value in real-world disaster planning and management.</p>
<h2 id="sensitivity-analysis-for-landmark-preservation-model">Sensitivity
Analysis for Landmark Preservation Model</h2>
<p>To conduct a sensitivity analysis of the landmark preservation model,
we fixed the other indicators at their current values and incrementally
increased the principle components and then calculated the change in the
Landmark Weather Disaster Vulnerability Index (LWDVI) resulting from
this adjustment. The results are shown below in Figure 14.</p>
<p><img src="https://s2.loli.net/2024/02/06/DnZ9BcQ2RWMoYeU.png" alt="14.png"></p>
<p>The results indicate that the Landmark Weather Disaster Vulnerability
Index (LWDVI) is most significantly affected when the relevant
indicators change by the same proportion and the 3rd principal component
(PC3) increases when the index change ratio is less than 0.174. On the
other hand, the LWDVI is most significantly influenced by the change in
the 1st principal component (PC1) when the index change ratio is greater
than 0.174. This suggests that the LWDVI is most sensitive to the
inherent risk of the landmark building itself because both components
are related with the strength of the landmark. Therefore, under the
condition of limited funding and manpower, repairing and protecting the
landmark itself should be given the highest priority.</p>
<p>The result also shows the model is robust even if there're some
errors in data.</p>
<h1 id="model-evaluation-and-further-discussion">Model Evaluation and
Further Discussion</h1>
<h2 id="strengths">Strengths</h2>
<p><strong>Close to reality</strong>: Our research is based on a large
amount of real statistical data. For example, we obtained historical
hurricane data through the National Oceanic and Atmospheric
Administration (NOAA) and local property data through the University of
Florida's research institute.</p>
<p>The work references a large number of classic methods, as well as
innovative methods that have been verified in specific research fields.
For example, the MAHT model <a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a> referenced in Task 4
was developed by experienced experts and has been convincingly
validated. Therefore, our model is supported by sufficient data and
reasonable methodologies and can be considered a reasonable simulation
of the real world.</p>
<p><strong>Reasonableness</strong>: The Insurance Model can predict the
future trends of weather disasters based on historical data, providing
reasonable insurance advice and arrangements. The resulting real estate
location choices are reasonable and align well with our expectations and
actual circumstances. The Landmark Preservation Model accurately
captures the value and risks faced by historical buildings, guiding
decision-makers to make reasonable judgments. The simulation results are
all intuitive and consistent with reality, so the model is
reasonable.</p>
<p><strong>Humanistic Care &amp; Social Responsibility</strong>: When
setting insurance prices, the Insurance Model takes into account the
difficulties of local communities in the event of a disaster by
achieving a minimum Insurance Protection Gap, which reflects the sense
of social responsibility and care for people. The Landmark Preservation
Model, when assessing historic buildings, considers the satisfaction of
residents. It quantifies this as part of the model and makes it work,
doing its best to protect people's precious memories. Therefore the
model also takes into account humanistic care and social
responsibility.</p>
<p><strong>Objective</strong>: The entropy weighting method is used to
determine the weights of indicators, avoiding the influence of personal
subjective factors.</p>
<p><strong>Robustness</strong>: The sensitivity analysis shows that our
model can still output good results when faced with biased data. It has
a strong resistance to data errors and demonstrates a certain robustness
and stability.</p>
<h2 id="weaknesses">Weaknesses</h2>
<ol type="1">
<li><p>The Landmark Preservation Model does not have a comprehensive
consideration of economic effects, so it still has limitations in
practical application.</p></li>
<li><p>There is potential for enhancement in our selection of
indicators, and certain indicators could be represented with more
suitable and sufficient data.</p></li>
</ol>
<h1 id="conclusion">Conclusion</h1>
<p>We propose a multi-factor model of insurance which takes into account
three main aspects: weather disaster risks, section risk factors and
style risk factors. This model has been used to solve problems from
twodifferent continents, demonstrating its powerful generality and
adaptability. It is also used to assist insurance companies in
formulating insurance strategies and helping real estate companies adapt
to future changes. It has strong versatility and can help people in
various industries.</p>
<p>We have also developed a Landmark Preservation Model based on the
latest research results called MAHT. It considers four influencing
factors: extreme weather risk exposure to the landmark, its
vulnerability, people's satisfaction with it, and its historical and
cultural significance. By categorizing these factors, we obtained
numerical values to assess the necessity of protecting the landmark and
created a decision flowchart to assist decision-makers in formulating
different protection measures based on the circumstances. This model was
used to analyze the preservation measures for the Vizcaya Museum and
Gardens and, based on the results, a community letter was written to
local residents. It can make significant contributions in the aspect of
community heritage preservation.</p>
<h1 id="community-letter">Community Letter</h1>
<p>February 4th, 2024</p>
<p>Dear residents of Miami-Dade County,</p>
<p>We hope this letter finds you well and thriving in our vibrant
community. Today, We write to you with a matter of great importance
concerning one of our most cherished local landmarks, the Vizcaya Museum
and Gardens.</p>
<p>As many of you are aware, the Vizcaya Museum and Gardens suffered
substantial damage during Hurricane Irma in 2017. The increasing threat
of rising sea levels and frequent hurricanes, coupled with unsuitable
repairment conditions, have put this iconic landmark at significant
risk. After thorough consideration with calculations through our
Landmark Preservation Model, the recommendation has been made for the
relocation to ensure its preservation for future generations.</p>
<p>The cost of relocating such a significant site is substantial, and
preliminary calculations suggest that the entire project is about 80
million dollars, considering the difficulties in relocating and
preserving. The financial burden will be borne by government. Donations
are welcome during the whole process, and every donation, no matter the
size, will play a crucial role in safeguarding a piece of our shared
heritage.</p>
<p>The relocation and preservation project will be managed by
professional companies, ensuring that every aspect of Vizcaya is handled
with the utmost care and expertise. The project is planned to unfold in
five phases over the next five years, outlined as follows:</p>
<p>Phase 1: Planning and Fund Collecting - A detailed planning will be
finalized and the initial funding will be secured. (6 months)</p>
<p>Phase 2: Preparing - New foundations will be prepared well. At the
same time, stabilization works to ensure minimal damage will be done to
the building. (18 months)</p>
<p>Phase 3: Initial Relocation Phase - Beginning the physical relocation
of smaller structures and artifacts, including small collectibles,
sculptures, plants, and so on. (12 months)</p>
<p>Phase 4: Main Relocation Phase - Relocating the Main House and larger
structures, alongside significant restoration works. (12 months)</p>
<p>Phase 5: Finalization and Restoration - Completing the relocation,
with a focus on restoration, landscaping, and public reopening. (12
months)</p>
<p>We extend our deepest gratitude for your love for Vizcaya and invite
you to be a part of this monumental effort to preserve our history and
culture. It is this collective passion that has kept Vizcaya's spirit
alive through challenging times, and it is this same passion that we
call upon now to ensure its future. It takes a village, but it's worth
it.</p>
<p>Thank you for your attention and support.</p>
<p>Sincerely,</p>
<p>COMAP's Insurance of Catastrophes Modelers (ICM)</p>
<h1 id="appendices">Appendices</h1>
<h2 id="calculation-details-of-the-maht-model">Calculation Details of
the MAHT Model</h2>
<p>According to the existing study <a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a>, we can obtain the
design thinking and calculation methods behind the MAHT model. For the
sake of simplicity, this part has been used multiple times in the main
text's Landmark Preservation Model, but it has not given specific
calculations for HA, SC, and RS, as well as the relevant evaluation
criteria. Therefore, it is supplemented in the appendix for future
reference.</p>
<p>The MAHT's first dimension considers the Heritage Attributes (HA) of
the urban landmark, which identifies the physical features and
constructive characteristics of urban fabrics. Its second dimension
evaluates Safety Conditions (SC), which identifies the presence of
damage, malfunction, and fire dysfunctional conditions. Also, its third
dimension considers Residential Satisfaction (RS),which is assessed
through face-to-face interviews.</p>
<p>The detailed sub-indicators with weights designed by experienced
specialists are listed below.</p>
<p><img src="https://s2.loli.net/2024/02/06/eIZXjlbWOBQrCa6.png" alt="HA.png"></p>
<p><img src="https://s2.loli.net/2024/02/06/kQwBqUv8Rrb1Ajg.png" alt="SC.png"></p>
<p><img src="https://s2.loli.net/2024/02/06/27N8rEgZvuF36VG.png" alt="RS.png"></p>
<h1 id="references">References</h1>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>C. Ornelas, F. Sousa, J. M. Guedes, and I.
Breda-Vázquez, “Monitoring and assessment heritage tool: Quantify and
classify urban heritage buildings,” Cities, vol. 137, p. 104 274, 2023,
issn: 0264-2751.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>L. Liu, Y. Wang, and H. Wang, “The performance of three
exponential decay models in estimating tropical cyclone intensity change
after landfall over china,” Frontiers in Earth Science, vol. 9, 2021,
issn: 2296-6463. doi: 10 . 3389 / feart . 2021 . 792005.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>S. P. Cottrell, J. J. Vaske, and J. M. Roemer, “Resident
satisfaction with sustainable tourism: The case of frankenwald nature
park, germany,” Tourism Management Perspectives, vol. 8, pp. 42–48,
2013, issn: 2211-9736.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>K. Irandoost, A. A. Isaloo, and B. Shahmoradi,
“Viability index in urban environments (case study: The central part of
holy city of qom),” Journal of Urban Economics and Management, vol. 4,
no. 13, pp. 101–118, 2016.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>L. Liu, Y. Wang, and H. Wang, “The performance of three
exponential decay models in estimating tropical cyclone intensity change
after landfall over china,” Frontiers in Earth Science, vol. 9, 2021,
issn: 2296-6463. doi: 10 . 3389 / feart . 2021 . 792005.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Protecting the world from flood risk: Why we invested in
cloud to street,
https://www.preventionweb.net/news/protecting-world-flood-risk-why-we-invested-cloud-street,
Accessed: 2024-02-05.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>S. P. Cottrell, J. J. Vaske, and J. M. Roemer, “Resident
satisfaction with sustainable tourism: The case of frankenwald nature
park, germany,” Tourism Management Perspectives, vol. 8, pp. 42–48,
2013, issn: 2211-9736.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>K. Irandoost, A. A. Isaloo, and B. Shahmoradi,
“Viability index in urban environments (case study: The central part of
holy city of qom),” Journal of Urban Economics and Management, vol. 4,
no. 13, pp. 101–118, 2016.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>C. Ornelas, F. Sousa, J. M. Guedes, and I.
Breda-Vázquez, “Monitoring and assessment heritage tool: Quantify and
classify urban heritage buildings,” Cities, vol. 137, p. 104 274, 2023,
issn: 0264-2751.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>C. Ornelas, F. Sousa, J. M. Guedes, and I.
Breda-Vázquez, “Monitoring and assessment heritage tool: Quantify and
classify urban heritage buildings,” Cities, vol. 137, p. 104 274, 2023,
issn: 0264-2751.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>C. Ornelas, F. Sousa, J. M. Guedes, and I.
Breda-Vázquez, “Monitoring and assessment heritage tool: Quantify and
classify urban heritage buildings,” Cities, vol. 137, p. 104 274, 2023,
issn: 0264-2751.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>C. Ornelas, F. Sousa, J. M. Guedes, and I.
Breda-Vázquez, “Monitoring and assessment heritage tool: Quantify and
classify urban heritage buildings,” Cities, vol. 137, p. 104 274, 2023,
issn: 0264-2751.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>C. Ornelas, F. Sousa, J. M. Guedes, and I.
Breda-Vázquez, “Monitoring and assessment heritage tool: Quantify and
classify urban heritage buildings,” Cities, vol. 137, p. 104 274, 2023,
issn: 0264-2751.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>C. Ornelas, F. Sousa, J. M. Guedes, and I.
Breda-Vázquez, “Monitoring and assessment heritage tool: Quantify and
classify urban heritage buildings,” Cities, vol. 137, p. 104 274, 2023,
issn: 0264-2751.<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>C. Ornelas, F. Sousa, J. M. Guedes, and I.
Breda-Vázquez, “Monitoring and assessment heritage tool: Quantify and
classify urban heritage buildings,” Cities, vol. 137, p. 104 274, 2023,
issn: 0264-2751.<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>C. Ornelas, F. Sousa, J. M. Guedes, and I.
Breda-Vázquez, “Monitoring and assessment heritage tool: Quantify and
classify urban heritage buildings,” Cities, vol. 137, p. 104 274, 2023,
issn: 0264-2751.<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>H.-J. Wang and Z.-T. Zeng, “A multi-objective
decision-making process for reuse selection of historic buildings,” vol.
37, no. 2, pp. 1241–1249, Mar. 2010, issn: 0957-4174.<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>S. F. R. C. C. Compact, “Unified sea level rise
projection southeast florida: 2019 update,” vol. 27, 2022.<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p>L. R. Hall, “Preemptive strategies and collaboration
for emergency planning: Lessons learned at vizcaya in miami,” APT
Bulletin: The Journal of Preservation Technology, vol. 52, no. 2/3, pp.
15–24, 2021, issn: 08488525. (visited on 02/03/2024).<a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p>C. Ornelas, F. Sousa, J. M. Guedes, and I.
Breda-Vázquez, “Monitoring and assessment heritage tool: Quantify and
classify urban heritage buildings,” Cities, vol. 137, p. 104 274, 2023,
issn: 0264-2751.<a href="#fnref20" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21"><p>C. Ornelas, F. Sousa, J. M. Guedes, and I.
Breda-Vázquez, “Monitoring and assessment heritage tool: Quantify and
classify urban heritage buildings,” Cities, vol. 137, p. 104 274, 2023,
issn: 0264-2751.<a href="#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <tags>
        <tag>这里面看起来很好玩</tag>
      </tags>
  </entry>
  <entry>
    <title>高等数理统计 I 比统计推断多了啥</title>
    <url>/2023/09/20/Advanced-Mathematical-Statistics-I/</url>
    <content><![CDATA[<p>挂机养生了，统计中心的课在这学期乱七八糟的课中间显得像个弟弟（x</p>
<span id="more"></span>
<h1 id="lecture-1">Lecture 1</h1>
<p>我为了这门课给 Weichi Wu
发过两封邮件，一封是上学期问这课有多高等、能不能手选，另一封是前两天因为实在查不到上课教室问了他一下，然后都被已读不回了。最后是找一个去了统计中心的九字班环友问了教室线下偷袭的。</p>
<p>本来以为他是不欢迎手选，课后问了一句他说没看到邮件（，想选就选，怎么回事。然后他问我有没有学过今天的内容，跟我说这课到后面可能会很难，可能以为我是统辅的，我又懒得再解释一遍也不知道怎么说能让他放心点（，脑子一卡就说了一句“没事我是数学系的”（，挺起腰杆体验卡了属于是。</p>
<!--虽然很菜，虽然很多东西都没有学过，然而接触过一些真·数学系的同学之后（，我还是觉得也不是没有资格说这句话。-->
<p>第一节课非常典，讲 probability theory &amp; Lebesgue
measure，挂机了，在写生导思考题（</p>
<p>但还是学到一个之前没怎么注意过的 abuse of
notation（写完感觉中英混杂写得好丑）：</p>
<h2 id="product-measure">Product Measure</h2>
<p>对于一组 measure space <span class="math inline">\((\Omega_i,
\mathcal F_i,\mu_i)_{i=1}^n\)</span> 存在唯一的 product measure <span class="math inline">\(\mu_1 \times \mu_2 \times \cdots \times
\mu_n\)</span> on <span class="math inline">\(\Omega_1 \times \Omega_2
\times \cdots \times \Omega_n\)</span> 使得</p>
<p><span class="math display">\[\mu_1 \times \mu_2 \times \cdots \times
\mu_n (A_1 \times A_2 \times \cdots \times A_n) = \mu_1(A_1)  \mu_2(A_2)
\cdots \mu_n(A_n)\]</span></p>
<p>这是一个非常基本的定理，里面主要可能在记号上有点问题的是一个 <span class="math inline">\(\sigma-\)</span>field 的写法。</p>
<p>最常用的 product measure 就是在 <span class="math inline">\(\mathbb
R^d\)</span> 上的 Lebesgue product measure，一般我会直接写成 <span class="math inline">\((\mathbb R^d , \mathcal
R^d,m)\)</span>，但是注意这里的 <span class="math inline">\(\mathcal
R^d\)</span> 并不是常见的 Cartesian product（显然对于 <span class="math inline">\(d\)</span> 个 <span class="math inline">\(\mathcal
R\)</span> 直接做 Cartesian product 得到的并不是一个 <span class="math inline">\(\sigma-\)</span>field，至少对取补是不封闭的），实际上是
<span class="math inline">\(\sigma(\mathcal R \times \mathcal R \times
\cdots \times \mathcal R) = \sigma(\mathcal R^d)\)</span>。</p>
<p>更一般的形式可能会产生的问题同理。</p>
<p>但实际上我是没啥误解（，只是之前没想过这个问题。而且我理解 <span class="math inline">\(\mathcal R^d\)</span> 从来都是从
basis（迫真）的角度理解的，就类似于一维的情况先定义一个 <span class="math inline">\(\mathcal A = \{(a_1 ,b_1) \times (a_2, b_2) \times
\cdots \times (a_n ,b_n) \}\)</span> 然后直接认为 <span class="math inline">\(\mathcal R^d = \sigma(\mathcal
A)\)</span>，或者有的时候会把 <span class="math inline">\(\mathcal
R^d\)</span> 写成 <span class="math inline">\(\mathcal B(\mathbb
R^d)\)</span> 的形式，毕竟手写的话其实写快了可能看不太出来我的 <span class="math inline">\(\mathcal R\)</span> 和 <span class="math inline">\(\mathbb R\)</span> 有什么区别（</p>
<h1 id="lecture-2">Lecture 2</h1>
<p>仍然是实分析和概率论复习，摸了。</p>
<p>有一个简单的小问题和计算问题，也是之前没注意过的，稍微写一下。</p>
<h2 id="radon-nikodym-derivative">Radon-Nikodym Derivative</h2>
<p>怎么又是你（，简单回顾一下：</p>
<p>Let <span class="math inline">\(\nu, \lambda\)</span> be two measures
on <span class="math inline">\((\Omega, \mathcal F)\)</span> and <span class="math inline">\(\nu\)</span> be <span class="math inline">\(\sigma\)</span>-finite. If <span class="math inline">\(\lambda \ll \nu\)</span>, then there exists a
nonnegative Borel measurable function <span class="math inline">\(f\)</span> on <span class="math inline">\(\Omega\)</span> such that <span class="math inline">\(\lambda(A) = \int_A f \; d \nu\)</span>, <span class="math inline">\(A \in \mathcal F\)</span> holds. Furthermore,
<span class="math inline">\(f\)</span> is unique a.e. <span class="math inline">\(\nu\)</span>.</p>
<p>上次用 R-N Theorem
还是条件期望，但其实这个定理的使用早在随机变量就出现过了，事实上如果
<span class="math inline">\(P(A) = \int_A f \; d \nu\)</span> 且 <span class="math inline">\(\int f \; d \nu =1\)</span> 对某个 <span class="math inline">\(f \geq 0 \; a.e. \nu\)</span> 成立，那么 <span class="math inline">\(f\)</span> 是概率测度 <span class="math inline">\(P\)</span> 关于 <span class="math inline">\(\nu\)</span> 的 probability density
function。本质上 <span class="math inline">\(\nu\)</span> 又是 <span class="math inline">\(f\)</span> 对应的随机变量 <span class="math inline">\(X\)</span> 在 <span class="math inline">\((\mathbb
R , \mathcal B)\)</span> 上的测度。</p>
<p>特别地，如果 <span class="math inline">\(F\)</span> 是随机变量 <span class="math inline">\(X\)</span> 的分布函数且是绝对连续的，即 <span class="math inline">\(F(x) = \int_{-\infty} ^x f(y) \; d y, x \in
\mathbb R\)</span>，则对于 <span class="math inline">\(F\)</span> 对应的
probability measure <span class="math inline">\(P\)</span> 有 <span class="math inline">\(P(A) = \int_A f \; dm\)</span>，其中 <span class="math inline">\(m\)</span> 是 <span class="math inline">\(\mathbb
R\)</span> 上的 Lebesgue
measure，这就是概率密度函数的基础。此处的概率密度函数 <span class="math inline">\(f\)</span> 也称为 <span class="math inline">\(P\)</span> (or <span class="math inline">\(F\)</span>) 关于 Lebesgue measure 的 probability
density function，也就是 R-N
derivative。初学（高等的）概率论的时候我完全没明白这些，满脑子都还是初概那一套积分法，符号一团糟但也完全不在乎，好菜（</p>
<p>有个简单有趣的例子可以在这里写一手，就当熟悉记号了。</p>
<p><strong>Example</strong>: Let <span class="math inline">\(F_i\)</span> be a c.d.f. having a Lebesgue p.d.f.
<span class="math inline">\(f_i\)</span>, <span class="math inline">\(i=1,2\)</span>. Assume that there is a <span class="math inline">\(c \in \mathbb R\)</span> such that <span class="math inline">\(F_1(c) &lt; F_2(c)\)</span>. Define</p>
<p><span class="math display">\[F(x) = \begin{cases} F_1(x) \quad
-\infty &lt; x &lt;c \\ F_2(x) \qquad c \leq x &lt; + \infty
\end{cases}\]</span></p>
<p>Show that the probability measure <span class="math inline">\(P\)</span> corresponding to <span class="math inline">\(F\)</span> satisfies <span class="math inline">\(P
\ll m + \delta_c\)</span> and find <span class="math inline">\(dP / d(m+
\delta_c)\)</span>.</p>
<p>(in which <span class="math inline">\(\delta_c(A) = \begin{cases} 1
\quad c \in A \\ 0 \quad c \notin A \end{cases} \quad A \in \mathcal
B\)</span>.)</p>
<p><strong>Solution</strong>: Take</p>
<p><span class="math display">\[f(x)=dP/d(m+\delta_c)  = \mathbb
1_{(-\infty, c)} (x) f_1(x)+ \mathbb 1_{(c , +\infty)}(x) f_2(x) +
\mathbb 1_{\{c\}}(x) (F_2(c)-F_1(c))\]</span></p>
<p>and verify that it's the desired expression of Radon-Nikodym
derivative.</p>
<p>For any <span class="math inline">\(A \in \mathcal B\)</span>, there
is</p>
<p><span class="math display">\[\begin{aligned} \int_A f(x) \; d(m
+\delta_c) &amp;= \int_A \mathbb 1_{(-\infty, c)} (x) f_1(x)+ \mathbb
1_{(c , +\infty)}(x) f_2(x) + \mathbb 1_{\{c\}}(x) (F_2(c)-F_1(c))
\;  d(m +\delta_c)\\ &amp;= \int_A  \mathbb 1_{(-\infty, c)} (x) f_1(x)
\; dm +\int_A \mathbb 1_{(c , +\infty)}(x) f_2(x)  \; dm +
\int_A  \mathbb 1_{\{c\}}(x) (F_2(c)-F_1(c)) \; d\delta_c \\
&amp;=   \int_A  \mathbb 1_{(-\infty, c)} (x) f_1(x) \; dm +\int_A
\mathbb 1_{(c , +\infty)}(x) f_2(x)  \; dm  + (F_2(c)-F_1(c)) \\
&amp;=P(A)  \end{aligned}\]</span></p>
<p>Moreover, <span class="math inline">\(f(x)\)</span> is a nonnegative
Borel function, thus <span class="math inline">\(P \ll (m +
\delta_c)\)</span> and <span class="math inline">\(dP /
d(m+\delta_c)=f(x)\)</span> is the R-N derivative.</p>
<h2 id="interchange-of-differentiation-and-integration">Interchange of
Differentiation and Integration</h2>
<p>就记一笔。</p>
<p>Let <span class="math inline">\((\Omega, \mathcal F, \nu)\)</span> be
a measure space and for any fixed <span class="math inline">\(\theta \in
\mathbb R\)</span>, let <span class="math inline">\(f(\omega,\theta)\)</span> be a Borel function on
<span class="math inline">\(\Omega\)</span>. Suppose that <span class="math inline">\(\partial f(\omega, \theta) / \partial
\theta\)</span> exists a.e. for <span class="math inline">\(\theta \in
(a,b) \subset \mathbb R\)</span> and that <span class="math inline">\(|\partial f(\omega, \theta)| \leq
g(\theta)\)</span> a.e., where <span class="math inline">\(g\)</span> is
an integrable function on <span class="math inline">\(\Omega\)</span>.
Then, for each <span class="math inline">\(\delta \in (a,b)\)</span>,
<span class="math inline">\(\partial f(\omega, \theta) / \partial
\theta\)</span> is integrable and,</p>
<p><span class="math display">\[\frac{d}{d\theta} \int f(\omega,\theta)
\; d \nu = \int \frac{\partial f(\omega, \theta)}{\partial \theta} \; d
\nu\]</span></p>
<h1 id="lecture-3">Lecture 3</h1>
<p>学期过 <span class="math inline">\(\frac 1 4\)</span>
了，为什么还在学概率论，这课不是叫数理统计吗（挠头</p>
<p>简单复习几个条件期望的东西。</p>
<h2 id="conditional-expectation">Conditional Expectation</h2>
<p>Let <span class="math inline">\(X\)</span> be a random <span class="math inline">\(n\)</span>-vector and <span class="math inline">\(Y\)</span> a random <span class="math inline">\(m\)</span>-vector. Suppose that <span class="math inline">\((X,Y)\)</span> has a joint p.d.f. <span class="math inline">\(f(x,y)\)</span> w.r.t <span class="math inline">\(\nu \times \lambda\)</span>, where <span class="math inline">\(\nu\)</span> and <span class="math inline">\(\lambda\)</span> are <span class="math inline">\(\sigma\)</span>-finite measures on <span class="math inline">\((\mathbb R^n, \mathcal B^n)\)</span> and <span class="math inline">\((\mathbb R^n , \mathcal B^n)\)</span>
respectively. Let <span class="math inline">\(g(x,y)\)</span> be a Borel
function on <span class="math inline">\(\mathbb R^{m+n}\)</span> for
which <span class="math inline">\(E|g(X,Y)|&lt;+\infty\)</span>.
Then:</p>
<p><span class="math display">\[E[g(X,Y) | Y] = h(Y) = \frac{\int g(x,Y)
f(x,Y) d \nu(x)}{\int f(x,Y) d \nu(x)} \quad a.s.\]</span></p>
<p>这很 trivial，但稍微沾点具体的 p.d.f.
计算的这种问题我就搞不太清楚，只能说 dwl 的初概真的遗害无穷。</p>
<h2 id="dominated-convergence-theorem">Dominated Convergence
Theorem</h2>
<p>上节概率论 2 的时候讲了一个 lemma：</p>
<p>Suppose <span class="math inline">\(Y_n \to Y \ a.s.\)</span> and
<span class="math inline">\(|Y_n | \leq Z\)</span> for all <span class="math inline">\(n\)</span> where <span class="math inline">\(EZ
&lt; \infty\)</span>. If <span class="math inline">\(\mathcal F_n
\uparrow \mathcal F_{\infty}\)</span> then <span class="math inline">\(E(Y_n | \mathcal F_n) \to E(Y|\mathcal F_{\infty})
\quad a.s.\)</span></p>
<p>其实大致来说就是分成两步证明 <span class="math inline">\(E(Y_n|\mathcal F_n) \to E(Y|\mathcal
F_n)\)</span>，然后 <span class="math inline">\(E(Y|\mathcal F_n) \to
E(Y|\mathcal
F_{\infty})\)</span>，最后套一个三角不等式。前一步其实就可以类似一下
conditional expectation 的 dominated convergence
thm。这个东西虽然学条件概率的时候学过但是果然到这种时候还是什么都不记得（</p>
<p>Suppose <span class="math inline">\(Y_n \to Y \ a.s.\)</span> and
<span class="math inline">\(|Y_n | \leq Z\)</span> for all <span class="math inline">\(n\)</span> where <span class="math inline">\(E|Z|
&lt; \infty\)</span>. Then <span class="math inline">\(E(Y_n | \mathcal
F) \to E(Y|\mathcal F) \quad a.s.\)</span></p>
<h2 id="conditional-independence">Conditional Independence</h2>
<p>很混乱（</p>
<p><strong>Definition</strong>: We say given <span class="math inline">\(Y_1\)</span>, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y_2\)</span> are conditionally independent iff</p>
<p><span class="math display">\[P(A|Y_1,Y_2) = P(A|Y_1) \; \text{a.s.
for any }A \in \sigma(A).\]</span></p>
<p><strong>Lemma</strong>: If <span class="math inline">\(Y_2\)</span>
and <span class="math inline">\((X,Y_1)\)</span> are independent, then
given <span class="math inline">\(Y_1\)</span>, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y_2\)</span> are conditionally independent.
Suppose <span class="math inline">\(E|X| &lt; +\infty\)</span> then:</p>
<p><span class="math display">\[E(X|Y_1,Y_2) = E(X| Y_1) \;
a.s.\]</span></p>
<p><strong>Proof</strong>: First of all, <span class="math inline">\(E(X|Y_1)\)</span> is measurable in <span class="math inline">\(\sigma(Y_1,Y_2)\)</span> for <span class="math inline">\(\sigma(Y_1) \subset \sigma(Y_1,Y_2)\)</span>. We
only need to show that these two conditional expectations are a.s. the
same measurable function from <span class="math inline">\(\sigma(Y_1,Y_2)\)</span> to <span class="math inline">\(\mathbb R\)</span>.</p>
<p>Then show for any <span class="math inline">\(B \in \mathcal B^{n_1+
n_2}\)</span>,</p>
<p><span class="math display">\[\int_{(Y_1,Y_2) \in B} X dP =
\int_{(Y_1,Y_2) \in B} E(X|Y_1,Y_2)dP = \int_{(Y_1,Y_2) \in B} E(X|Y_1)
dP\]</span></p>
<p>Note that</p>
<p><span class="math display">\[\begin{aligned}\int_{(Y_1,Y_2) \in B}
E(X|Y_1)dP &amp;= \int E(X|Y_1) \mathbb 1_{(Y_1 \in B_1)} \mathbb
1_{(Y_2 \in B_2)}dP = \int_{Y_1 \in B_1} E(X|Y_1) dP \int \mathbb
1_{(Y_2 \in B_2)}dP \\ &amp; = \int E(X; Y_1 \in B_1) \mathbb 1_{(Y_2
\in B_2)}dP =  \int_{(Y_1,Y_2) \in B}X dP \end{aligned}\]</span></p>
<p>The second equality above is a resslt of independence.</p>
<h1 id="lecture-4">Lecture 4</h1>
<p>不是我说不会有人已经把依分布收敛那些个分析结论忘完了吧？（</p>
<p>报一下菜名好了，就，不然也没啥可写的，大部分都学过只是忘了（</p>
<h2 id="weak-convergence">Weak Convergence</h2>
<h3 id="analytical-properties">Analytical Properties</h3>
<ul>
<li><p>(Polya's Theorem) If <span class="math inline">\(F_n
\stackrel{w}{\to} F\)</span> and <span class="math inline">\(F\)</span>
is continuous in <span class="math inline">\(R^k\)</span>, then <span class="math inline">\(\lim_{n\to \infty} \sup_{x \in R^k}|F_n(x) - F(x)|
=0\)</span>.</p>
<p>Proof: Truncate <span class="math inline">\(-\infty = x_0 &lt; x_1
&lt; \cdots &lt; x_k = +\infty\)</span> s.t. <span class="math inline">\(F(x_i) = \frac i k\)</span>, therefore we can
bound <span class="math inline">\(|F_n(x) - F(x)|\)</span> with finitely
many upper bounds.</p>
<p>for any <span class="math inline">\(x \in R\)</span>, consider <span class="math inline">\(x_i \leq x &lt; x_{i+1}\)</span>, therefore</p>
<p><span class="math display">\[F_n(x) - F(x) \leq F_n(x_{i+1})-
F_n(x_i) = F_n(x_{i+1})- F_n(x_{i+1})+\frac 1 k\]</span></p>
<p><span class="math display">\[F_n(x)-F(x) \geq F_n(x_i) - F(x_{i+1}) =
F_n(x_i) - F(x_{i})-\frac 1k,\]</span></p>
<p>and <span class="math inline">\(|F_n(x)-F(x)| \leq
\max_{i=0,1,\cdots,k} |F_n(x_i) - F(x_i)|+\frac 1k\)</span>. By taking
<span class="math inline">\(n \to \infty\)</span> the desired result
follows.</p></li>
<li><p>(Skorohod's Theorem) If <span class="math inline">\(X_n
\stackrel{w}{\to}X\)</span>, then there are random vectors <span class="math inline">\(Y,Y_1,\cdots\)</span> defined on a common
probability space such that <span class="math inline">\(P_Y =
P_X\)</span>, <span class="math inline">\(P_{Y_n} = P_{X_n}\)</span>
holds for any <span class="math inline">\(n \in \mathbb Z^+\)</span>,
and <span class="math inline">\(Y_n \stackrel{a.s.}{\to}
Y\)</span>.</p></li>
<li><p>If <span class="math inline">\(X_n \stackrel{w}{\to} X\)</span>,
then there is a subsequence <span class="math inline">\(\{X_{nj}, j
=1,2,\cdots\}\)</span> such that <span class="math inline">\(X_{nj}
\stackrel{a.s.}{\to} X\)</span> as <span class="math inline">\(j \to
\infty\)</span>.</p></li>
</ul>
<h3 id="tightness">Tightness</h3>
<p>A sequence <span class="math inline">\(\{P_n\}\)</span> of
probability measures on <span class="math inline">\((R^k,B^k)\)</span>
is tight iff for every <span class="math inline">\(\varepsilon
&gt;0\)</span>, there exists a compact set <span class="math inline">\(C
\subset R^k\)</span> s.t. <span class="math inline">\(\inf_n P_n (C)
&gt; 1-\varepsilon\)</span>. That is, <span class="math inline">\(P(C)\)</span> is large uniformly for any <span class="math inline">\(n\)</span>.</p>
<p>If <span class="math inline">\(\{X_n\}\)</span> is a sequence of
random <span class="math inline">\(k\)</span>-vectors, then the
tightness of <span class="math inline">\(\{P_{X_n}\}\)</span> is the
same as the boundedness of <span class="math inline">\(\{\|X_n\|\}\)</span> in probability.</p>
<ul>
<li>Tightness of <span class="math inline">\(\{P_n\}\)</span> is a
necessary and sufficient condition that for every subsequence <span class="math inline">\(\{P_{ni}\}\)</span> there exists a further
subsequence <span class="math inline">\(\{P_{nij}\}\)</span> that
converges to <span class="math inline">\(P\)</span> in distribution as
<span class="math inline">\(j \to \infty\)</span>.</li>
<li>If <span class="math inline">\(\{P_n\}\)</span> is tight and if each
subsequence that converges weakly converges to the same probability
measure <span class="math inline">\(P\)</span>, then <span class="math inline">\(P_n \stackrel{w}{\to} P\)</span>.</li>
</ul>
<h3 id="characteristic-function">Characteristic Function</h3>
<ul>
<li><p><span class="math inline">\(X_n \stackrel{w}{\to} X\)</span> is
equivalent to any of the following conditions:</p>
<ul>
<li><span class="math inline">\(E[h(X_n)] \to E[h(X)]\)</span> for every
bounded continuous function <span class="math inline">\(h\)</span>.</li>
<li><span class="math inline">\(\lim \sup_n P_{X_n}(C) \leq
P_X(C)\)</span> holds for any closed set <span class="math inline">\(C
\in R^k\)</span>.</li>
<li><span class="math inline">\(\lim \inf_n P_{X_n}(C) \geq
P_X(C)\)</span> holds for any open set <span class="math inline">\(C\in
R^k\)</span>.</li>
</ul></li>
<li><p>(Cramer-Wold) <span class="math inline">\(X_n
\stackrel{d}{\to}X\)</span> iff <span class="math inline">\(c^TX_n \to
c^TX\)</span> for every <span class="math inline">\(c \in
R^k\)</span>.</p></li>
<li><p>(Levy-Cramer) Let <span class="math inline">\(\phi_X, \phi_{X_1},
\cdots\)</span> be the ch.f.'s of <span class="math inline">\(X,X_1,X_2,\cdots\)</span> respectively. <span class="math inline">\(X_n \stackrel{d}{\to} X\)</span> iff <span class="math inline">\(\lim_{n\to \infty} \phi_{X_n}(t) =
\phi_X(t)\)</span> for all <span class="math inline">\(t \in
R^k\)</span>.</p>
<p>The proof should be remembered.</p></li>
<li><p>(Scheffe) Let <span class="math inline">\(\{f_n\}\)</span> be a
sequence of p.d.f.'s on <span class="math inline">\(R^k\)</span> w.r.t.
a measure <span class="math inline">\(\nu\)</span>. Suppose that <span class="math inline">\(\lim_{n \to \infty}f_n(x) = f(x)\)</span>
a.e.<span class="math inline">\(\nu\)</span> and <span class="math inline">\(f(x)\)</span> is a p.d.f. w.r.t. <span class="math inline">\(\nu\)</span>. Then <span class="math inline">\(\lim_{n \to \infty} \int|f_n(x)-f(x)| d
\nu=0\)</span>.</p></li>
</ul>
<h3 id="mapping">Mapping</h3>
<ul>
<li>Let <span class="math inline">\(X,X_1,\cdots\)</span> be random
<span class="math inline">\(k\)</span>-vectors defined on a probability
space and <span class="math inline">\(g\)</span> be a measurable
function from <span class="math inline">\((R^k, B^k)\)</span> to <span class="math inline">\((R^i, B^i)\)</span>. Suppose that <span class="math inline">\(g\)</span> is continuous a.s <span class="math inline">\(P_X\)</span>, then:
<ul>
<li><span class="math inline">\(X_n \stackrel{a.s.}{\to} X\)</span>
implies <span class="math inline">\(g(X_n)
\stackrel{a.s.}{\to}g(X)\)</span></li>
<li><span class="math inline">\(X_n \stackrel{p}{\to} X\)</span> implies
<span class="math inline">\(g(X_n) \stackrel{p}{\to}g(X)\)</span></li>
<li><span class="math inline">\(X_n \stackrel{w}{\to} X\)</span> implies
<span class="math inline">\(g(X_n) \stackrel{w}{\to}g(X)\)</span></li>
</ul></li>
<li>(Slutsky) Let <span class="math inline">\(X,X_1,\cdots, Y,
Y_1,\cdots\)</span> be random variables on a probability space. Suppose
<span class="math inline">\(X_n \stackrel{w}{\to} X\)</span> and <span class="math inline">\(Y_n \stackrel{w}{\to} c\)</span>, where <span class="math inline">\(c\)</span> is a real number. Then
<ul>
<li><span class="math inline">\(X_n + Y_n \stackrel{w}{\to} X_n
+c\)</span></li>
<li><span class="math inline">\(X_nY_n \stackrel{w}{\to}
cX_n\)</span></li>
<li><span class="math inline">\(X_n / Y_n \stackrel{w}{\to} X_n
/c\)</span> if <span class="math inline">\(c \neq 0\)</span></li>
</ul></li>
</ul>
<h2 id="notations-from-calculus">Notations from Calculus</h2>
<p>就，我真的不是很喜欢大 O 小 o 这些，但是就是很常用（</p>
<p>一般来说对于数列也有这样的记号，如果两个数列 <span class="math inline">\(\{a_n\}, \{b_n\}\)</span> 满足 <span class="math inline">\(|a_n| \leq C|b_n|\)</span> 对任意的 <span class="math inline">\(n\)</span> 成立，那么称 <span class="math inline">\(a_n = O(b_n)\)</span>；如果满足 <span class="math inline">\(a_n / b_n \to \infty, n\to \infty\)</span>，则称
<span class="math inline">\(a_n =
o(b_n)\)</span>。在概率里也有类似的用法：</p>
<p>Let <span class="math inline">\(X_1, X_2, \cdots\)</span> be random
vectors and <span class="math inline">\(Y_1,Y_2,\cdots\)</span> be
random variables defined on a common probability space.</p>
<ul>
<li><span class="math inline">\(X_n = O(Y_n)\)</span> a.s. iff <span class="math inline">\(P(\omega: \|X_n(\omega)\| \leq C|Y_n(\omega)|
\text{ holds for any }n \geq 1)=1\)</span></li>
<li><span class="math inline">\(X_n = o(Y_n)\)</span> a.s. iff <span class="math inline">\(X_n / Y_n \stackrel{a.s.}{\to} 0\)</span>.</li>
<li><span class="math inline">\(X_n = O_p(Y_n)\)</span> iff for any
<span class="math inline">\(\varepsilon&gt;0\)</span>, there is a
constant <span class="math inline">\(C_\varepsilon&gt;0\)</span> s.t.
<span class="math inline">\(\sup_n P(\omega : \|X_n(\omega) \| \geq
C_\varepsilon |Y_n(\omega)|) &lt;\varepsilon\)</span></li>
<li><span class="math inline">\(X_n = o_p(Y_n)\)</span> iff <span class="math inline">\(X_n / Y_n \stackrel{p}{\to} 0\)</span>.</li>
</ul>
<p>Therefore</p>
<ul>
<li><span class="math inline">\(X_n = o_p(Y_n)\)</span> implies <span class="math inline">\(X_n = O_p(Y_n)\)</span></li>
<li><span class="math inline">\(X_n = O_p(Y_n)\)</span> and <span class="math inline">\(Y_n = O_p(Z_n)\)</span> implies <span class="math inline">\(X_n = O_p(Z_n)\)</span></li>
<li><span class="math inline">\(X_n = O_p(Y_n)\)</span> does not imply
<span class="math inline">\(Y_n = O_p(X_n)\)</span></li>
<li>The same conclusions can be obtained if <span class="math inline">\(O_p(\cdot),o_p(\cdot)\)</span> are replaced by
<span class="math inline">\(O(\cdot)\)</span> a.s., <span class="math inline">\(o(\cdot)\)</span> a.s..</li>
<li>If <span class="math inline">\(X_n \stackrel{w}{\to} X\)</span> then
<span class="math inline">\(X_n = O_p(1)\)</span></li>
<li>Since <span class="math inline">\(a_n = O(1)\)</span> means <span class="math inline">\(\{a_n\}\)</span> is bounded, <span class="math inline">\(\{X_n\}\)</span> is said to be bounded in
probability iff <span class="math inline">\(X_n = O_p(1)\)</span>.</li>
</ul>
<h2 id="delta-method">Delta Method</h2>
<p>Let <span class="math inline">\(X_1,X_2,\cdots\)</span> and <span class="math inline">\(Y\)</span> be random <span class="math inline">\(k\)</span>-vectors satisfying <span class="math inline">\(a_n(X_n - c) \stackrel{w}{\to}Y\)</span>, where
<span class="math inline">\(c \in R^k\)</span> and <span class="math inline">\(\{a_n\}\)</span> is a sequence of positive numbers
with <span class="math inline">\(\lim_{n \to \infty} a_n
=\infty\)</span>. Let <span class="math inline">\(g\)</span> be a
function from <span class="math inline">\(R^k\)</span> to <span class="math inline">\(R\)</span>.</p>
<ul>
<li><p>If <span class="math inline">\(g\)</span> is differentiable at
<span class="math inline">\(c\)</span>, then <span class="math inline">\(a_n [g(X_n) - g(c)] \stackrel{w}{\to} [\nabla
g(c)]^TY\)</span>.</p></li>
<li><p>Suppose <span class="math inline">\(g\)</span> has continuous
partial derivatives of order <span class="math inline">\(m
&gt;1\)</span> in a neighborhood of <span class="math inline">\(c\)</span>, with all the partial derivatives of
order <span class="math inline">\(j\)</span>, <span class="math inline">\(1 \leq j \leq m-1\)</span> vanishing at <span class="math inline">\(c\)</span>, but with the <span class="math inline">\(m\)</span>-th order partial derivatives not all
vanishing at <span class="math inline">\(c\)</span>. Then</p>
<p><span class="math display">\[a_n^m [g(X_n)-g(c)] \stackrel{w}{\to}
\frac{1}{m!} \sum_{i_1=1}^k \cdots \sum_{i_m=1}^k \frac{\partial^m
g}{\partial x_{i_1} \cdots \partial x_{i_m}}\mid _{x=c} Y_{i_1}\cdots
Y_{i_m} \]</span></p></li>
<li><p>If <span class="math inline">\(Y\)</span> has the <span class="math inline">\(N_k(0,\Sigma)\)</span> distribution, then <span class="math inline">\(a_n [g(X_n) - g(c)] \stackrel{w}{\to} N(0,[\nabla
g(c)]^T\Sigma \nabla g(c))\)</span></p></li>
</ul>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>统计</tag>
      </tags>
  </entry>
  <entry>
    <title>在 THU 上过的第一无聊的课——制图实习</title>
    <url>/2022/07/26/Computer-Drawing-for-Engineering/</url>
    <content><![CDATA[<p>是我可能这辈子也不会再碰到的领域了。</p>
<span id="more"></span>
<h1 id="实习摸鱼和辩解">实习、摸鱼和辩解</h1>
<p>拔智齿前准备一周，拔完恢复拆线一周。正好这两周还要兼顾专业制图实践，甚至去医院拔牙、拆线的路上还在紧盯着答雨课堂的选择题。<del>不过在家的时候早晨上课睡着，还错过了几道题</del>。刚把水工图交上，CAD
大作业还没改完，快了快了。</p>
<p>工程制图是一个我完全无法理解的东西，无论是纸面上的工图基础还是 CAD
制图实习，过程都很崩溃。我以前还以为上机制图是用软件画一个 3D
模型，然后计算机直接就能通过模型得到各种图纸。没想到还是和纸面作图一样，要自己脑补，然后一根一根画线调整，制图标准也很繁琐。觉得两周下来变笨了一点，一直没动过脑子。</p>
<p>当然，上述确实可以通过 AutoCAD Revit
实现，做出电子模型之后拿学校的科创基金去淘宝做个 3D
打印实物还能有加分。但我对造房子实在不感兴趣，拿学校的钱做废物模型都有点担忧全球变暖（x），这课也打算摆烂拿
3.6 了。所以大作业还是和何老板组队选了平面图。</p>
<p>选课的时候有四个老师可以选，<del>学姐说其中一位男老师很帅，所以就选了他</del>。<a href="https://linjiarui.net/">老师个人网站</a>上的照片也挺帅的，<del>就是和他本人长得不太像</del>。说实话我对每一门专业课都不感兴趣，<del>还不如我那数值分析好看呢</del>，不太想学，真的也学不会。自己和这个专业一点都不合适，分流就打算去建管系混到毕业了，完全是当做副业在玩。</p>
<h1 id="大作业死斗至黎明">大作业，死斗至黎明</h1>
<p>何老板和我的意见一样，懒得卷。于是我们查了查淘宝，20
块钱可以请一位（不知什么水平的）设计师从设计开始一直到出图，一块钱可以买一份有
50
张固定主题的图纸的素材包。感叹这个行业的高端劳动力也真的很廉价，于是一掷一块买了素材包。</p>
<p>动工之前还有个类似开题报告的会议，这我不得画个大饼？这时候想起来<a href="https://www.bilibili.com/video/BV1mx41187DZ?spm_id_from=333.337.search-card.all.click">母校有一个
MC
工程和视频</a>，作者还发布了存档文件，这下我不就可以说自己是从中产生了灵感，通过参考
MC
工程（甚至可以代替实地考察测绘）画的设计图吗？<del>我真是大聪明！</del></p>
<p>于是问题就来了，我们没有真正的图纸啊。结果我还上网找了找，有个所谓“华东师范大学某附属中学扩建工程”的图纸，华东师大一共就两个附属中学，赌了一把还真是二附中。不过这图纸要价不菲（50
块，淘宝卖
13），于是贫贱不能移。所以这种施工图是可以透露出来的吗？问题是，除了我们这种奇葩大学生，还有谁会买呢？</p>
<p>然后又打算去素材包里东翻西找一个合适的图，魔改一下再称其为母校的魔改产物，结果真的发现了一个很合适的。</p>
<p><a href="https://imgtu.com/i/jxBXtg"><img src="https://s1.ax1x.com/2022/07/26/jxBXtg.png" alt="jxBXtg.png"></a></p>
<p>这张图戳到我的原因是，真的有点像母校的连廊和北教学楼。阶梯教室就在北教学楼的东面，即使是独立的一个楼，起码方位很对；教室前后门和三扇窗，被我戏称储藏室的选修教室，两侧楼梯的位置，如出一辙。最像的地方是那个同心弧形，母校的连廊和教学楼连接的地方有个小门，下三级楼梯可以通向中庭的鹅卵石小路。只可惜虽然建筑很美，但我并不怀念学校里的人和事，所以没有留下过什么照片，无从对比了。</p>
<p>当然，左边的连廊本来只是一个宽敞的通道，并没有这么多房间。连廊更西侧的实验楼里的确有这些房间，于是被我搬进图纸上的连廊来了。</p>
<p>后来魔改的过程中还是出现了很多问题，比如图上有飞在天上的承重墙，还有弧形楼梯处的其他建筑关系不好处理（主要是我对真实的建筑没印象了，不然还可以拿来照抄）。我甚至还灵魂画手了一张图给何老板看，当然最后还是按照最简单的模式改了。</p>
<p><a href="https://imgtu.com/i/jxBjhQ"><img src="https://s1.ax1x.com/2022/07/26/jxBjhQ.jpg" alt="jxBjhQ.jpg"></a></p>
<p>这图怎么右上角还签了个名，精神状态看来不是很好。</p>
<p>过程中还在 QQ
上发了个求助，希望有能提供石阶处图片的高中同学联系我，最后也没有。<del>只有
ex
很震惊地来问我到底读的是土木还是建筑</del>。<del>有必要吗有必要吗几年没说话了啊您交大
CS
在读了不起是吗</del>。想了想当初是自己执意退出高中校友的圈子，连班群年级群都退了，也不奇怪。</p>
<p>反正总算是已经做好了，但是解释视频和文档还没写。图画的很烂，不知道能不能一通爆吹挽回一些。不能也无所谓，并不是我在乎的专业课，3.6
不亏。</p>
<h1 id="后记">后记</h1>
<p>电脑下面垫着一本白天看的《数值分析基础》，耳机里在放《Bet On
Me》，然后改完图纸写了摆烂记录，准备传到两周没更新的博客上去。我本科四年里看图纸的生涯结束了，下次再看到图纸可能是搞装修，可以在包工头面前装一下懂哥，<del>我当年在清华二学位学的是工程管理，别想糊弄我！</del>有一种很轻松快乐的感觉。</p>
<blockquote>
<p>You should bet on me</p>
<p>Like I'm Apple in the 90s</p>
<p>You should bet on me</p>
<p>Gonna wanna get behind me like I'm 23</p>
<p>Before Mikey was on Nike's</p>
<p>You should be-be-be-bet on me (Woo-ooh)</p>
<p>——《Bet On Me》</p>
</blockquote>
<p>对了，这里发一下我的三次折磨小作业。虽然分数不高，但是起码把苦力都做完了，改一改就可以拿出手了，造福后来者。差不多已经实名上网了，也没多少人看我博客，就<a href="https://cloud.tsinghua.edu.cn/d/295dfd9c151d4c8ea3ee/">清华云盘</a>吧。</p>
<h1 id="后后记">后后记</h1>
<p>这门课已经不是无聊的程度了，而是令人无语...我指的是给分方面。</p>
<p>吃一堑长一智，希望大家要么在春季跟着大类一起选课，那还有开摆的机会；要么就放到大四拉倒，当
PF 来上。</p>
]]></content>
      <tags>
        <tag>躺平</tag>
        <tag>课程实录</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇一·22年9月</title>
    <url>/2022/09/07/Diary-2022-09/</url>
    <content><![CDATA[<p>好无聊，写写日记（</p>
<p>博客彻底变成日常了。</p>
<span id="more"></span>
<h1 id="月7日">9月7日</h1>
<ul>
<li><p>下午收了两个快递，理了理桌子，可以摆得下两个电脑了。找出来了去年新生舞会之前买的一双高跟鞋（5cm
算高跟吗，还是说叫增高鞋比较好？），但实际上并没有去。试了一下感觉蝴蝶结和蕾丝不算很夸张，也挺舒服的，打算之后天气不冷就日常穿了。</p>
<p>但是骑车不太方便，踩空/踩偏都是常有的事，加上我三个月没骑过车了，差点摔了。晚上为了写实习报告，跑去节水博物馆那里拍了照，没看清脚下有个凸出来的井盖，又差点崴了脚。不过多穿几天习惯一下可能就好了，给自己的身高多焊五厘米主要是为了自己开心，鞋子也很漂亮，心情会好很多。</p></li>
<li><p>傍晚去 C
楼新学期注册，遇到了高中同班的两个男生在贴贴（？），还有隔壁班的一个男生。本来不想打招呼，心里还很焦虑，结果他们好像没认出我来，直接无视了。笑死，太棒了。</p></li>
<li><p>今天数值分析建群了，看到群里有
cy，才想起来三年前的金秋营之后就没什么联系了，他确实拿着牌顺利进强基数学了来着，他来上数值也很正常。不过还是不太确定是不是他本人，于是截了个图发给
ycj，ycj 说 cy 也来问他群里那个是不是我了，笑死。</p>
<p>看到群里有很多未央的学长，毕竟这是培养方案里的数理课，正常。</p></li>
<li><p>晚上隔壁信科双学位的友人给我看了 csapp
的课前准备，大概就是拿到账号然后自己试着连到 Linux
服务器上<del>，或者自己装个系统</del>。回想起来酒井暑培的时候文档里说“会给班号为
{计**，计**-经**，经**-计**，计科**，智**， 量信**}
的同学们分配服务器资源”，<del>致理信计在哪里，软院又在哪里，救一下啊</del>。我没有账号就直接跳过了
Linux
环节，自己去看了看然后虚空操作了一下。可以理解，报名的外系人那么多，我们班几乎一半都报了，结果去上课的根本就没有，怎么可能给外系也分配服务器。</p>
<p>因为开博客的时候就配过 ssh，ssh-keygen
之类的操作稍微有点忘记了，就翻出来了 SAST skill docs
又看了下。看着他们老师的意思虚空写了份教程和参考资料。干完之后又回去写我的认识实习报告，写我并不关心的怎么修大坝。</p>
<p>这种感觉...其实稍微有点麻。竞赛，高考，数学，cs，我好像永远是编外人员。</p></li>
<li><p>问同专业的学长要了份实习报告参考一下，我刚 say hi
他就问我是不是来要报告的，笑死。本来没什么思路，看了看他的觉得不错，但是卷出
36 页是真的离谱，痛死我。</p></li>
</ul>
<h1 id="月8日">9月8日</h1>
<ul>
<li><p>写了一天实习报告，水到了 1.4w，还有两个工程实例没写。</p></li>
<li><p>傍晚感觉很烦躁，于是出去骑了会车。想起来后天闭社社聚的地方我还不知道在哪里，就往近春园去了。</p>
<p>然后错就错在我看的是管理群里 TA
发的的那张地图，而不是社聚嘟文里的，群里那个标的不太对。然后就只找到了园林科，在附近晃了半个多钟头才醒悟不是这里。还遇到了一个也反复在园林科附近晃悠的路人，说不定也是社友呢（x</p>
<p>实际位置就在清华路熙春路路口那里，有一个通往近春园的小入口，走进去就是了。</p></li>
</ul>
<h1 id="月9日">9月9日</h1>
<ul>
<li><p>实习报告写完了！最后摸到了 1.8w 字，得知可以交
PDF（意思是不查重）之后就放飞自我了。</p>
<p>其实我是用 Typora
写的，因为一开始列的是大纲，慢慢往里面填东西的。这才知道 Typora
可以导出成 word，又加了封面和目录凑到了 30 页，看起来还不错。</p>
<p>报告放在<a href="https://cloud.tsinghua.edu.cn/f/5a2b4ad57de24eefb3f9/">这里</a>了，希望后来者做这种苦力活的时候能有个参照。</p></li>
<li><p>室友通过我写报告的时候摇晃的频率，推测出来我的 BGM 是 One Last
Kiss，这也太恐怖了。</p></li>
<li><p>傍晚去找何老板拿了认识实习的安全装备，一个红色的安全帽和一件反光衣，拿来单纯是为了整活的（</p></li>
<li><p>班里同学来给我发纸条，说是要写给班主任的节日祝福。我一边写一边想为什么偏偏要祝班主任中秋节快乐，怎么不祝国庆节校庆日快乐，然后半天才想起来是教师节orz。</p></li>
</ul>
<h1 id="月10日">9月10日</h1>
<ul>
<li>今天是教师节，是全体济南人的节日！</li>
</ul>
<p><img src="https://s2.loli.net/2022/09/11/lGoIecsNVnqQSXK.png" alt="image-20220910011006883.png"></p>
<ul>
<li><p>晚上中秋社聚，成就包括但不限于：</p>
<ul>
<li>淋雨，穿高跟鞋从中水池跑到临漪榭，真·驰雨（）不过回来也没觉得脚很累，说明鞋子不错</li>
<li>和校友聊天，一起骑车回紫荆</li>
<li>23:40 到紫荆楼下，赶在 00:00 停水之前洗完了热水澡，舒服www</li>
<li>还是没有克服社恐一起玩狼人杀QAQ，下次一定</li>
</ul>
<p>虽然一半时间都在一边坐着看手机，但还是很开心的w</p>
<p><img src="https://s2.loli.net/2022/09/11/BclSGJxKR5wp3OI.png" alt="image-20220911021521811.png"></p>
<ul>
<li>9/16：突然发现，我和 neruko 的手机怎么看起来像同款（</li>
</ul></li>
<li><p>pre 组员全部卡今晚 23:59 的 ddl
交出来自己的部分，把他们拼到一起改成一个画风搞到凌晨两点，然后约了个早八的排练会议，我要猝死了。</p></li>
<li><p>半夜辅导员突然给我打电话说因为北化中传疫情，现在有新规定。因为我在北京还不满
7 天，所以不仅要置灰码，还要把我室友们的一起置了。</p>
<p>所以，我待会去挨个寝室串门的话不违反防疫规定吧？万一我携带的话那不还是寄（</p></li>
</ul>
<h1 id="月11日">9月11日</h1>
<ul>
<li><p>今天是认识实习答辩验收。早八爬起来带大家试讲了一遍，超时一倍。救命（</p>
<p>讲风暴潮的 AI
辅助预警的时候，提了一些暑假里做图片识别神经网络的经验，用来“用自身已有经验”说明
GPU
并行计算加速对支撑决策很重要，然后胡扯了几句未来要继续加入数据科学技术什么的。</p>
<p>我其实并不想在类似的场合这样讲，一个代码填空的作业罢了，框架又不是我搭的，很有少做多说之嫌...但还是希望让这个毫无技术含量的答辩看起来有亮点一些，尽管我自己也什么都不懂。结果效果还不错，...唉。</p></li>
<li><p>二刷了 EVA TV 版，自闭了一天。</p>
<blockquote>
<p>Adam and Eve are still in Paradise when Samael, with a little boy in
tow, accosts Eve. "Would you mind merely keeping an eye on my son?" he
asks her. "I will soon return." Eve agrees.</p>
<p>Returning from a walk in Paradise, Adam follows the piercing squeals
of the child back to Eve.</p>
<p>"It is Samael's," she tells a vexed Adam. His anxiety increases along
with the screams of the little one, which grow unbearably violent.
Beside himself, Adam delivers a blow that kills the youngster then and
there. Yet its body continues to wail at a fever pitch, monstrous groans
that do not stop when Adam cuts the corpse into bits.</p>
<p>Then Adam cooked the pieces of flesh and bone that remained, to wipe
out this fiend. Together with Eve, he ate all that was left. They had
hardly finished when Samael called for his son. Denying all knowledge of
his son, the culprits were protesting their innocence when suddenly a
louder voice cried out from within their stomachs to silence them: it
was the dead boy's voice, come straight from their hearts, his words
directed to Samael.</p>
<p>"Leave me, now that I've pierced the hearts of both Adam and Eve. I
remain in their hearts forever, and in their children's hearts, their
children's children-until the last generation I abide here."</p>
</blockquote></li>
<li><p>看到了天格计划（GRID）的<a href="https://mp.weixin.qq.com/s/yjhr3fUTWdApy2-RL24Uyg">招新</a>，报了名。我第一次看清华的宣传片是高三的时候，招生组来学校面试，给等候区放宣传片，
就是关于天格计划的。物理我是一窍不通，然后发现群里都是工物系/物理系的（</p>
<p>就，来写写代码？（代码也一窍不通（那我是来干嘛的</p></li>
<li><p>然后开了个班会，选新班委什么的，感觉就是不认识的 10
个人接替了另外 10 个不认识的人的班级职务。导员说明年的班委就是剩下的 10
个人，救命。</p>
<p>这学期好像有个一二九大合唱，据说每周要排练两次，每次是晚上的两小时，好麻烦...。那我还是努力去后勤组吧
:D。</p></li>
<li><p>艰难地开始 <a href="https://csdiy.wiki/">csdiy</a>，看了半天决定从 CS61B: Data
Structures and Algorithms 开始。数据结构迟早要学，捆一个 Java
不亏。试了试属于是可以一边写一边学了，另外 Copilot 真好用（</p></li>
</ul>
<h1 id="月12日">9月12日</h1>
<ul>
<li><p>难得做梦，梦到在三教里溜达，走着走着从一条很长的走廊里走到了一个饮水机面前，饮水机上有两行红色的字，我还以为是什么警告，结果凑近一看，写的是“上海交通大学”还有“饮水思源，爱国荣校”（可达鸭抱头.jpg）。</p>
<p>还遇到了以前的一个考去交大的高中同学，正在从他们的教室搬椅子到三教。我问他固定资产可以动吗，他说没问题，我们要去
3300上课啦。（#每日坐椅子</p>
<p>懂了，我这是在梦里坐上复兴号了（</p>
<p>想起来女生节的时候，同学给我送的礼物之一是上交的笔记本和书签，笑死。就是很放不下，原因可能至少有两条吧。</p></li>
<li><p>今日无事。开始随缘听课和写 CS61B 的 Lab。</p>
<p>Lab 1 是配环境，Lab 2 是教怎么
debug。想起来我第一学期的时候过半了才知道打断点调试，此前一直崩溃地肉眼
debug，好惨。为什么呢，因为新手期也没人告诉我（（</p></li>
<li><p>看了眼高中校友群，好像一年一度地聚会了。去年就没去，今年更不会去，并且没有理由去。</p></li>
<li><p>晚上出门散步，不知何故脑袋里盘旋着一句话：小时不识月，呼作地卫一（</p></li>
</ul>
<h1 id="月13日">9月13日</h1>
<ul>
<li><p>灰码进不去公共场所，所以早八的工程力学基础，以及体育课，对不起了！</p>
<p>（那你怎么进教室上抽代和数值的）</p>
<p>（哎呀这不是魔法嘛）</p></li>
<li><p>半夜腰疼疼得睡不着，怀疑是因为久坐有点腰肌劳损/腰间盘轻微突出了。<del>啥都还不会，职业病先得上了。</del></p>
<p>喜欢布面木腿的椅子，也不想要轮子，感觉人体工学椅坐着很不舒服...于是把狗狗抱枕从床上拿下来当靠垫了，感觉好了很多。</p>
<p>然后开始思考，高三的时候不也是久坐吗，怎么没有类似的问题。想起来当时确实也带着这只狗狗上学（冬天太冷了抱一会&amp;睡觉的时候放桌上趴着），其他时候就是垫在背后的。难怪。</p>
<p><a href="https://imgse.com/i/vjQBvV"><img src="https://s1.ax1x.com/2022/09/13/vjQBvV.md.jpg"></a></p></li>
<li><p>网慢了，软院离散没选上。放弃了基础拓扑学，虽然当时是用任选一志愿抢上的，笑死。</p>
<p>给 myc 和 lsx 都发了邮件，lsx
那边不会扩容了，但是运气好的话还可以手选
myc。挺好的，混个绩点去。</p></li>
<li><p>发了个水利新人奖学金的通知，花半个小时填了个表。试试就试试，万一评上了就混到两个月生活费，那不是挺好的。</p>
<p>写材料时候感觉就是，每一句话说的倒也都没错，但是前后逻辑没对，比如我绝对不是为了搞海洋科学前沿研究才学数学和计算机的，里面关于我导“带我专业认知”的内容也很对不起她，我早就和她说过我不太喜欢工科...而且这些话连起来就好
nb 的样子，这真的是我吗（hx：简历上的干货有一页吗？</p>
<p>然后又稍微有点难受，做的事情没那么厉害为什么要这样写。友人劝我不要拧巴，穷学生何必跟钱过不去，况且就算有夸大的成分，本来也不比别人差。笑死，也对啦。</p></li>
</ul>
<h1 id="月14日">9月14日</h1>
<ul>
<li><p>想起来曾经有一段时间也是一样的苦闷，和一位学长聊过一些东西。</p>
<p>“如果想做理论研究的话，迟早要面对困难的数学的，基础越好显然对以后越有好处。”</p>
<p>“很多时候想知道自己对什么感兴趣，还是得去学一些困难的东西看能不能带来快乐。”</p>
<p>“不要做名词党，不要叶公好龙。试试看丰富自己的武器库。”</p></li>
<li><p>不管是上有成绩的离散还是没有成绩的，总归要有本书。收了一套二手，回寝室包了个很怪的书皮，因为这是我能找到的大小最合适而且没啥用的纸张了，对不起了化学系科协（</p>
<p><a href="https://imgse.com/i/vxQdgI"><img src="https://s1.ax1x.com/2022/09/15/vxQdgI.md.jpg" alt="vxQdgI.md.jpg"></a></p>
<p>这套题还是去年晚上从六教出来，一个小姐姐像发传单一样塞给我的。一共四张纸，还能再包两本书（什么</p></li>
<li><p>下午来技科楼上通识课，这个地方好难找啊。好不容易骑到东南门门口，就已经累了，课上好困（</p>
<p>还要在 15
分钟内赶到六教上初概。不过亲测顺利的情况下，骑到六教再打杯水还能剩五分钟摸鱼。</p>
<p>出来的时候抄近道，被花坛里喷灌的水喷了一腿。想起来认识实习的时候说那个水是中水，又想起来社聚的时候见到的中水池，我不淡定了（</p></li>
</ul>
<h1 id="月15日">9月15日</h1>
<ul>
<li><p>工程计算机制图拿了
2.3，老师口口声声告诉我最终绩点和百分制成绩没有映射关系，大受震撼...在评奖学金的关头
GPA 直降
0.06，一年的努力毁于一旦。本来不想完全打散培养计划的，这下是学院逼我把专业课堆到大四了。</p>
<p>写了个复议申请，但感觉毫无悬念的会没用，但实在是，实在是忍不了。</p>
<p><a href="https://imgse.com/i/vxbPKS"><img src="https://s1.ax1x.com/2022/09/15/vxbPKS.png" alt="vxbPKS.png"></a></p></li>
</ul>
<p>和学长们暴论了一下午，在大群里讨论被辅导员锤了，然后开了个润学小群激情对线。不到此时我从未认识到这个院系的问题到底有多少，极其陈腐二十年不变的授课内容和方案，还有顽固不化的老师，绝不承认存在“课上的每一个同学都能掌握相应内容所以可以都给高分”。倘若在数学系的硬课上吃一个
2.3
那我心甘情愿，至少公平给分，恐怕只是能力不足且过分自信而已；在这里的水课上被迫接受一个历史最低分，很难不说恶心。</p>
<p>然后一怒之下报名了课咨委的招新，问同学收集了点数据，结果很多很多平时根本没说过话的同学都来给我加油，好像马上就要面试了一样hhh，虽然知道他们其实都是出于对这门课的不满，但是好神奇的感觉。收到的数据面试的时候说不定能用到。万一呢，万一选上了呢，万一选上了又能做到一些事情呢？Make
some difference,
我多羡慕的事情，在科协没有做到，在院系没有做到，但是再试试，再试试，这次说不定呢？</p>
<p>“你这是出于公义，还是报私仇啊。”</p>
<p>“这能分得开吗？”</p>
<p><a href="https://imgse.com/i/vznbM6"><img src="https://s1.ax1x.com/2022/09/15/vznbM6.md.jpg" alt="vznbM6.md.jpg"></a></p>
<ul>
<li><p>聊了一下午的天，然后紧急开始看抽代（难得空闲的一天计划完全乱了...），看到六点半打算去吃饭，结果卡了一个题；嗯把它做出来之后突然弹出来核酸过期的提示，于是上晚课前的时间全部用来在听涛旁边排核酸了...</p>
<p>一边往教室骑车一边回想包里有没有什么吃的可以对付一下，结果只有半瓶咖啡。<del>人类还是不如喰种，不能喝咖啡就饱。</del>想念法图地下那个售卖零食的机器，如果教学楼有的话至少可以买个面包哇，放那么多做出来并不好喝的咖啡机干嘛。</p>
<p>上了一节如果能手选到离散就会退掉的通识课《中国城市规划史》，感觉属实是没什么意思，还被作为土木类的学生点到回答专业认知了，但是我真的不感兴趣...就算没选上离散也不想上这个了。</p></li>
<li><p>最近很烦闷的时候拍了不少痞式风景，包括暑假在上海拍的一些无意义照片，加上最近的心情，就有点想剪一个
EVA 风的个人向 One Last
Kiss。素材都没攒够，但到冬天拍的东西又很难营造出来 EVA
里终年长夏的氛围了，真·错过等一年。</p>
<p>先把不常用的 b 站号资料改成可辨识的，然后又立了个
flag，但鬼知道我会鸽鸽掉还是拖到寒假剪一个稀碎的东西出来...</p></li>
</ul>
<h1 id="月16日">9月16日</h1>
<ul>
<li><p>早八有 ODE，于是八点半才醒，支持正义睡眠！开始自学！</p>
<p>周五要上 ODE，离散，抽代，初概（前八）/统推（后八），加起来有 10
个学时，一天收获了四份作业，绷不住了。当初是出于什么心态排的这些课啊。</p></li>
<li><p>发现离散一共三个助教，其中有两个都是上上学期 C++
的助教（#每日TA们</p>
<p>雨课堂弹幕好欢乐啊，（相比新生）我不会是老了吧。</p>
<p>课间听到有人跑到前面问
myc：老师我是自动化系的，我想转到计算机系，您有什么建议吗（</p></li>
<li><p>抽代课简直悠闲得不真实，hx 讲课感觉比较 book
reader，我又喜欢课前自己手推一遍定理公式然后做完书后题，这样的话上课又快乐又有复习的感觉，<del>你甚至能在数学系的专业课上摸鱼</del>。《近世代数300题》还没到货，到了之后认真刷一刷。</p>
<p>（为什么不在学校的书店里买呢）</p>
<p>（对啊为什么呢）</p></li>
<li><p>初概开始讲测度论相关了，但是就只讲一点点。就像之前 wxf
的微积分一样，知识下放但是只放一点，也不讲得很透，我其实感到很难受。要不下学期再去选个概率论（1）（暴论</p></li>
<li><p>今晚洗衣服，手伸进水里的时候才感觉到，夜温确实不高了。</p></li>
<li><p>本来想写完 ODE
作业再睡，结果腰背痛得实在受不了，写了两道题就上床躺平（物理）了。况且遇到了一个要用
mathematica
解数值解的问题，还有一个物理题。从小到大我都看到物理就头晕，实在没心情睡前继续搞这个。</p>
<p>友人让我努力保护腰肌，万一越来越严重了可能要正骨，不清楚是不是危言耸听，但是很吓人。以后睡前要多做几次坐位体前屈，疼得受不了的时候趴着睡或者把腿缩起来会好一点。（可是那样的话不会腿疼吗（x</p>
<p>买了个朴实无华的靠背，随便带出门也不心疼的那种。</p></li>
</ul>
<h1 id="月17日">9月17日</h1>
<ul>
<li><p>周日就可以出校了，打算先去水利系奖学金答辩，然后出去找隔壁的友人吃饭。一查才知道以前去吃的中关村那家火锅店关门了，<del>总不可能是因为无限布丁制吃穷了</del>。顺便趁最近比较闲，而且还是夏天，出去拍点素材。</p></li>
<li><p>虽然初概10.7就要期中了，非常恐怖。测度学不会。</p></li>
<li><p>今天奖学金候选人公示，我们班居然报了 14
个，别的班少则四五个多则七八个，非常恐怖。这个奖不知道是不是按班级分名额的？求你了我只是对那两个月的生活费感兴趣，让我恰恰烂钱吧（</p></li>
<li><p>H△G（幻视</p>
<p>希望助教能看得懂这一堆小写 n 和 h
的区别，反正我是看不出来，算的时候还因此把自己绕进去了（</p>
<p><a href="https://imgse.com/i/xSyg78"><img src="https://s1.ax1x.com/2022/09/17/xSyg78.md.jpg" alt="xSyg78.md.jpg"></a></p>
<p>（那为什么不打 LaTeX 呢）</p>
<p>（嗨呀这不还是喜欢一边算一边写嘛）</p></li>
<li><p>很久很久没去过北馆了，这次想去借一本中译的《概率导论》。结果去之前一查状态是不可获取，是被借走了吗，还是不能借？我还没在学校的图书馆借过书，都是用教参平台。本来还想这次去正好装作是新生不会弄就行了（</p>
<p>食堂同理，不过也还没去过新的食堂，仍然是清芬战士。</p></li>
<li><p>在学堂路看到了课咨委招新的海报，开始思考到底是为什么要参加。</p>
<p>其一当然是私自的原因，我不想再被土水学院的专业课恶心。零字班有 xyx
带头冲锋（x），已经有改观了；我也想利用一点校级组织的力量，万一能有变化呢？</p>
<p>其二嘛，其实我还有不少别的问题。比如 PF
时间能不能后移一点，我到现在都没有用过每学期一门课的那个 PF
机会，感觉第五六周的时候完全看不清楚记哪门课能利益最大化，或者仍然属于课程前期，天真地希望所有的课程都以绩点的形式出现在成绩单上。还有一些别的稀碎的问题，万一进了再说。</p>
<p>其三其实是，这么说吧，我时常还是想绕到很多迷惑政策背后看一看有没有正当的理由，其实多数时候是有的。也没有参与过决策一个条例的过程，可能多少还是不会考虑各种现实情况，喜欢口嗨（</p>
<p>然后好像还有工资（（bushi</p></li>
<li><p>作业写完了！！</p></li>
<li><p>晚上把睡衣拿去洗了，另一件死活找不着，但是居然翻出来了 2019
女子赛时候发的T恤，还印着武外的校徽和那一年比赛的 logo（</p>
<p>于是翻了翻相册，只有比赛<del>糊掉</del>结束之后去一个类似城市规划馆的地方玩的照片了。当时感觉武汉是个很神奇的地方，先分成汉口汉阳武昌，还有各种区的划分，然后还有武昌区和汉阳区，反正这几个字可以排列组合（</p>
<ul>
<li>查到了，当初去的地方叫“武汉市民中心”。</li>
</ul>
<p>（现在想想，这不就类似于有浦东浦西的叫法，然后还有浦东新区吗（</p>
<p>惟楚有材诶。</p></li>
</ul>
<h1 id="月18日">9月18日</h1>
<ul>
<li><p>睡大觉。醒来看到 xyx
在群里问“数值分析里矩阵不可分拆等价于强连通怎么证”，我焦虑了。</p></li>
<li><p>水利系奖学金参评名单公示期过半，突然被辅导员塞进来一个人，不会是钦定的吧（x）</p>
<p>面试前一个半小时紧急开始编自我介绍，发现说满三分钟可太容易了。强调团结合作和院系贡献的话，我感觉自己也没戏，凑个热闹去。</p></li>
<li><p>去五道口，今天解封然后感觉到处都是华子的学生（</p>
<p>拍到了纯正的痞风电线杆，如果能有个类似的但是是红色的塔让我在白天拍拍就好了。</p>
<p><img src="https://s2.loli.net/2022/09/18/OD5zLoXlV8aFwY4.jpg" alt="D26028836B2B9176FDFE7CE23EB0C64B.jpg"></p>
<ul>
<li><p>天空中的白点是星星吗？今天的确看到了星星，但是手机的传感器真的能拍出来吗？</p>
<p>不会是我手机镜头上的灰尘吧（</p></li>
</ul></li>
</ul>
<h1 id="月19日">9月19日</h1>
<ul>
<li><p>一点开始特殊原因选课，一点半才想起来这回事，我超，希望离散还能选上qwq。明理楼的教室原来这么大吗，甚至可以放下
310 个人，快赶上建馆报告厅了。</p>
<p>看了一眼，zmx 的抽代居然有 7 个课余量了，不会有不少人从她那里润到 hx
这里来了吧？不过我还是选的
hx，人少一点感觉体验良好，至少能一人占一排桌子（</p></li>
<li><p>室友慷慨地把五月疫情期间屯的泡面都送我了，草。起得不早不晚的时候吃饭有备选方案了。</p></li>
<li><p>话说大家都选基物（1-2）了啊...早晨十点钟醒来寝室里空无一人，恍若隔世。</p></li>
<li><p>不太行，群论还没过半我就被各种名词绕进去了。于是有了茴香豆篇（</p></li>
</ul>
<h1 id="月20日">9月20日</h1>
<ul>
<li><p>看到一张梗图，笑死，这不就是我和闭社的大家吗www</p>
<p><a href="https://imgse.com/i/xCmiXq"><img src="https://s1.ax1x.com/2022/09/20/xCmiXq.md.jpg" alt="xCmiXq.md.jpg"></a></p></li>
<li><p>早八工力懒得去上了，作业还得交。于是早起跑去交了作业，然后去清芬吃早饭，再去六教找地方睡会儿。</p>
<p>好像是今年第一次在食堂吃早饭，因为寝室里没东西吃了（</p></li>
<li><p>抽代教室的人变多了，果然有从 zmx
那里过来的。所以第三节课开始突然课后有掌声环节了，hx：？</p></li>
<li><p>水利系的奖学金果然没我的事儿，都给几个班委了。我导安慰我说这个奖本来就不是给学术型的人的，笑死，<del>就我还学术型，她太看得起我了</del>。</p>
<p>嘛随便了，反正还有书院的奖学金可以申。<del>就我这个面试能力，真的申得上吗</del></p></li>
<li><p>已经是第三节课了，数值分析还在带大家复习高代，预计还要复习一节课（</p>
<p>突然感觉这学期上掉是个明智的选择，不然越往后越忘完了。</p></li>
<li><p>今晚科协开会，讲新学期安排，领导要求要和行健一样搞一个“和学生节差不多规模的科创日”，这事儿居然交给学术部来办，我只感觉会创死我。</p>
<p>所以今晚我说干完这学期就跑路了，搞答疑坊或者课咨委（如果可以的话）去，部长说理解。课程和各种任务本来就多，科研相关的事儿我根本就又焦虑又理不清头绪，剩下的时间要用在有意义的事上。</p>
<ul>
<li>其实并不是学术部的问题，我感觉是未央的问题。学院太大了，大家说话儿都说不到一块去，每个人的终极梦想都是开润学讲坛，但是不行。</li>
</ul></li>
</ul>
<h1 id="月21日">9月21日</h1>
<ul>
<li><p>一边写题一边改茴香豆篇，之前想的是这个东西不能出错（<del>虽然没人看</del>），结果第一次
post 就大翻车，之后考虑找同学 review
一下。查出一个问题来，是预习的时候没看清楚搞反了 <span class="math inline">\(Inn(X)\)</span> 和 <span class="math inline">\(Aut(X)\)</span>。</p>
<p>同学：这抽象代数真抽象啊</p>
<p>我：你要不听听自己在说些什么（</p></li>
<li><p>吃饭之前在教室里有一只绕着我飞来飞去的蚊子，努力了半天没拍死，吃完饭回来教室里多了好几个人，但它还是只绕着我飞然后叮了我四五下（</p>
<p>不是，我就不明白了，在我离开的 40
分钟里，这个房间里就没有你感兴趣的人然后恰饱了晚饭吗？？又不是只有我穿裙子露着腿啊，再说别人的胳膊你就不能叮吗？？</p>
<p>好像我特别吸引蚊子，社聚的时候也替大家在近春园被咬了好多下（悲</p></li>
<li><p>今天第一次骑车被撞了，被后面的车的车轮撞到了腿，擦破点皮，问题不大。</p>
<p>大概就是，在下课高峰期有一排人贴着新民路路边骑车，旁边就是停车的区域；然后我前面的人突然拐进了停车位的空隙里并停了下来，就把往前的路堵住了；这个时候我要么刹住，要么创上去（因为路上很挤，所以也没有退一退然后往旁边拐的选项），于是我选择了刹住。但事实证明，不论我选哪个后面都会追尾一串人，区别只是在于停车的那个人会不会被创（她很幸运，我应该创她的（混沌暴论</p>
<p>发呆想了小半节课这个事故责任人在谁（好无聊啊）（肯定在前面唐突停车的那个人罢），还去查了查针对汽车的交规（没考驾照不好意思），才知道一般是后车承担全部责任或者后车主要责任、前车次要责任。那么这种情况下，究竟我是前车，还是前面刹住的那个人是前车（#每日迷思
（难道不是因为骑自行车不用考虑安全车距的问题，所以才会创吗hhh</p></li>
</ul>
<h1 id="月22日">9月22日</h1>
<ul>
<li><p>早八网课，上完实在困麻了，上床补了一觉。</p>
<p>做了一个在梦里就知道是梦的梦，在梦里还问了一句“我这是在做梦对吧”，但还是笑醒了（草</p>
<blockquote>
<p>"那我的梦在哪里？"</p>
<p>"那是现实的延续。"</p>
<p>"那我的现实在哪里？"</p>
<p>"那是梦的终结。"</p>
<p>——《EVA》（或许是TV版）</p>
</blockquote></li>
<li><p>现在六门课里感觉最不好的其实是初概...进入不了状态，偏偏第四周就要期中了qwq</p>
<p>大家都说 dwl
讲课很好，可是我总觉得...emm，我更喜欢给一个靠谱的教材然后比较 book
reader 的讲法，换个说法就是更喜欢自学，课上 check
一遍，有补充或者新的启发就更好了。</p>
<p>dwl
的讲课水平绝对是超出贵校平均很多的，但是听到的东西未必能记住和用好，看到的和写下来的往往才可以。而且概率论里有好多东西很反直觉...有点绷不住。</p></li>
<li><p>今天跟室友学到了一个词，她用来形容电子系一个老师的，叫 PPT
rapper（</p></li>
<li><p>草，这个版本一直没加上，在清芬遇到了
ouuan，为自己没有脸盲而开心（所以没有认错吧没有吧草</p></li>
</ul>
<h1 id="月23日">9月23日</h1>
<ul>
<li><p>感冒了，喉咙很痛，吃了半包龙角散才缓过来。还是学不会看了天气预报再穿衣服出门啊。</p></li>
<li><p>于是中午的时候还喉咙痛，午饭吃得很少；下午上一堆课，感觉到有点发烧的症状，又冷又困，一测体温其实偏低，吃了顿饭就缓过来了。所以说其实是饿的，草，听起来好惨啊（</p></li>
<li><p>抽代课的时候看到闭社的投票，然后观察了一眼，选课的 40
个人里就两个不戴眼镜的。我戴眼镜也有十年了吧，中间调散光什么的换过两次，已经感觉它长在脸上了，完全想象不出来不戴眼镜是什么感觉，原来人类不是一出生就戴着眼镜的啊（好怪</p></li>
<li><p>还是抽代：</p>
<p><img src="https://s2.loli.net/2022/09/23/SnEKRf3exhrV8ql.jpg" alt="49DDB8D33E5C8D284799B9406FE386C6.jpg"></p>
<p>注：友人在隔壁信科，本学期 ics 五学分（</p></li>
</ul>
<h1 id="月24日">9月24日</h1>
<ul>
<li><p>再一次被本科生科研搞焦虑了，和数学系的朋友聊了会，他说他也想搞应数，又完全不知道咋办。系里的氛围就是都在看书做题。转数环里加了个好友。</p>
<p>为啥我院人人都在科研啊？早的大一下就开始了，晚的现在也已经找到组了，但是都是跟着自己的学业导师干活儿。我不想找本专业的老师科研，我导也知道我的想法，鼓励我去和外系的老师交流一下，但我就是毫无头绪，只想等
SRT 报名的时候天降大腿...</p>
<p>而且课业繁重是只有我这样吗？每天看书写作业就绷不住了，又觉得打不好基础很难谈做什么应数的研究，但是看了看选的课很多又是水课（比如离散和工科
ODE，就是去混绩点的，现在也很怀疑统辅的意义何在），就是忙得莫名其妙。</p></li>
<li><p>面试课咨委，李兆基楼就是个大型迷宫，分 AB 区不说，AB
区内部还是隔开的，早到了半个小时用来找路，太明智了。面试的时候我说我如果进了，一年就只有一个目标，就是把工程计算机制图这门课<del>橄榄</del>优化一下。</p>
<p>人家一眼就看出来我是在口嗨，笑死。虽然但是，
要是进去之前就已经有一个完美的想法了，那还进去干啥（</p>
<p>随便啦。</p></li>
<li><p>仍然是感冒的状态，喉咙也不大舒服。而且最近好能睡觉啊...。认真看了看初概，写了笔记总集篇，我又觉得我行了.jpg</p></li>
<li><p>睡前听到同学说上交不允许强基学生打印出国成绩单的事，垂死梦中惊坐起，半夜两点下楼和同学打了二十分钟电话。</p>
<p>我没对跨保抱有任何希望，一开始就是打算跑路的，不能这点机会都不给我留吧...</p></li>
</ul>
<h1 id="月25日">9月25日</h1>
<ul>
<li><blockquote>
<p>驰雨（x）同学： 你好！
祝贺你通过面试，正式成为<strong>2022-2023学年度秋季学期本科生课程咨询委员会委员</strong>，请扫描二维码加入委员群。
本科生课程咨询委员会自2014年成立以来，持续地在学校各项教育教学改革工作中贡献学生力量，保证教学相关问题的及时反馈和解决。
希望你能在未来的学习和工作中<strong>保持敏锐、理性思考、勇于表达</strong>，肩负起委员的责任。
让我们共同发声，从而让改变发生。</p>
<p>清华大学本科生课程咨询委员会 2022年9月25日</p>
</blockquote>
<p>蛤？怎么就过了，一定是报名的人太少了（x</p>
<p>这样的话答疑坊我直接就不面试了，等下学期退了科协再去。</p>
<p>课咨委群里有一个高中的学弟，貌似是物竞组的但是具体不认识，也不知道他去什么院系了。但很多事情让我高度怀疑上下两届理科班的人都认识我，草，社恐了。</p>
<p>“保持敏锐，理性思考，勇于表达”，我还蛮喜欢这个说法的，很酷，虽然总有画大饼的味道（x）。时而怀疑自己哪个都做不到，尤其是最后一项（x）。</p></li>
<li><p>闲来无事上 bangumi 翻了翻我比较喜欢的几部番的评分，除了 EVA 和
Fate/Zero 之外怎么都爆低，不大符合身边统计学（x</p>
<p>想来想去，可能是我会比较具体地喜欢某部番里面特别出彩的某一话，因此而去喜欢这一部番，具体故事讲得怎么样，结尾走向怎么样，好像没太当回事。比如
Fate/Last Encore
里关于童谣的两话和尼禄面对扎比子真名解放的一话真的百看不厌，Re:Creator
里军姬出场的一幕对我来说是童年回忆式的美好印象，紫罗兰的天文台回（甚至和主线和少佐没啥关系，电影我至今没看），猪头少年的学妹回和双叶回，魔眼收集列车的首次圣枪解放回都是这样。其实这些番的结局咋样我都记不大清了，甚至
n 刷的时候也不会去完整地看。</p>
<p>浅翻了翻评论感觉大家都好在乎整体的走向啊...好累哦（x），也有可能是当初追番到结局时候的评价吧。</p>
<p>如果要说完整故事的话，我觉得昨日之歌、3
月的狮子和恋如雨止其实都是不错的，很流畅细腻的感觉，EVA 和 Fate/Zero
又是另一种意义下的很好。和朋友浅聊了几句这个问题，他说我沉迷型月尤其是
FGO
太久了，我说有没有一种可能若干年前型月就是顶流，本老月厨只是单推很久了，久到现在谁还看型月啊（</p></li>
<li><p>今天是 runzhi 生日，runzhi 是我竞赛以来认识最久、关系最好的 MOer
了（其实本校范围内也没有别的关系好的 MOer
了，整个高中期间都是自闭形态，好像气氛上来说也有是女生的关系，总之很不擅长和大家交流），一直都还有联系，算来也四年多了，蛮开心的。本来说中午去找他吃饭，结果因为各种原因（包括又社恐了）鸽了。去年的时候给他快递了本高代入门，今年既然已经成为隔壁数院英才升级人了，于是去
C
楼书店给他买了本华子的概（1）教材，写了个明信片让友人帮忙带过去当礼物。他说他给我寄了一本代数来，笑死。</p>
<p>写明信片的时候不知道怎么结尾，于是惯例地
modmodmod，虽然有点好笑但是还蛮真诚的（？？）。竞赛的时候有学长抨击过
modmodmod 的氛围，但我一直觉得只要不 mod
得太夸张，还是挺单纯可爱的。</p>
<p><img src="https://s2.loli.net/2022/09/25/MjF516TCAS9HDQI.jpg" alt="3257B56F17056285F01D87BD8FCE718E.jpg"></p>
<p>晚上和另外几个同学一起聊了好久的天，其中一位还在外面吃饭，大概是喝高了开始笑骂我说，初三开始在卷省和比我多学了八年的同学一起数竞，简直是不要命了。我说反正我也失败了，正好当个教训，让后人不要模仿（真的还会有这种情况的后人吗x）。</p>
<p>其实如果没失败的话，我可能已经高考选文科，然后运气好的话去隔壁、运气不好去复旦读中文、法律什么的了吧。物化生没有一门是擅长的，新高考下勉强凑了个物化地，还是被物化直接拉下裸分线。不过现在又开始少学一年半数分并继续不要命地上课了，究竟什么时候能真正地吸取教训呢x。</p></li>
</ul>
<h1 id="月26日">9月26日</h1>
<ul>
<li><p>今日无事。短暂享受一下作业清零的生活，明天又要塞了。</p></li>
<li><p>课咨委迎新例会还没开，就已经有院系里的学长找我问能不能反映问题了...大概就是你院（据说也是所有书院？）推研要求的课程还没有定下来，教务目前的说法是大家要把前三年的必限课修完以防万一。虽然很无理而且又是只牺牲零字班，但是好像也没办法，唯一的办法就是让教务赶紧决定要求哪些课。</p>
<p>虽然不知道这事在不在课咨委的管辖范围，但是交给课咨委肯定是来不及的，哪怕全速提案调研上报审批，可能也赶不在零字班保研前完成。于是甩锅给生权的去找教务沟通了，加油啊（</p></li>
<li><p>重写了
About，当初写的时候有点随意，以及过往的事情提得太多了，看起来很莫名其妙。旧的版本当做第一篇文章，存档在博客的底部了。</p></li>
</ul>
<h1 id="月27日">9月27日</h1>
<ul>
<li><p>不痛经的一个月，太梦幻了。</p></li>
<li><p>早八 + 早十 + 体育课 + 大型手洗两盆衣服现场 + 打扫卫生 +
晚课前做核酸 + 晚课 + 晚上十点开课咨委例会 +
再绕李兆基大迷宫两圈，本肥宅是真的力不从心了，明明什么都没干，却好累（悲</p>
<p>于是回来把东西放下，想出去遛个弯减轻精神内耗，又不知道去哪里，就去看南区的垃圾分类垃圾桶去了（草）。本来惴惴不安，万一它真的很响，吵醒一堆人可怎么办？不过还好远离宿舍楼靠近清芬的一侧还有一个，过去晃了半天无事发生，传感器居然晚上还断电，这也太文明了（</p>
<p>回到楼下又晃了一下紫荆的垃圾桶，它没断电，大晚上还骂我垃圾，草。太可恶了，睡觉！</p></li>
<li><p>突然意识到我一直记错了自己物理实验的组号，明晚要做一个暑假里没有准备过的实验（因为没拿到讲义），虽然应该不太难但还是要突击看一下，更蚌埠住了。也行，正好时隔俩月去补充一下物理实验备忘录。</p>
<ul>
<li>后来发现不用了，这个实验貌似是竞赛题，能找到<a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&amp;dbname=CJFD2012&amp;filename=WLSL201212006&amp;uniplatform=NZKPT&amp;v=VF8dWg8gSk74BaVl_1UiEnR4HspnO_EY0f4QKnDJFjzHctWCnb6zmRdQmz8C38Ok">文献</a>，讲得很清楚。</li>
</ul>
<p>这不是才第三周吗，感觉已经进入考试周状态了（</p></li>
<li><p>我是照着抽代的教学大纲来准备预习的，说是第三周讲置换群，怎么第三周的第一节课就把它讲完了（</p>
<p>所以周四还要再往下看一节，然后刷刷近世
300，上面还是有有趣的题目的，上次和 runzhi
讨论了其中一道题觉得很不错，在筹备开新的坑来记录一些优雅的题目（。</p></li>
</ul>
<h1 id="月28日">9月28日</h1>
<ul>
<li><p>太累了，中午十二点整起床，梦幻开局。</p>
<p>晚上又 17:50 下初概课，18:00
做实验，所以今天三顿，啊不是，两顿饭都得凑合着吃，破防了。</p></li>
<li><p>醒来想到的第一件事是下周五就初概期中了，我怎么还在忙各种别的破事？</p>
<p>抽代前半周作业有 14 道题，合理推断这周有 28 道；于是第一周 20，第二周
24，第三周 28，再用等差数列合理推断一下，第十五周会有 76
道题（混沌思考），这学期有 720 道题，完爆近世代数 300 题（</p></li>
<li><p>一晚上有三个在上唐宏岩概随的人向我求助同一份作业题，但问的题目都不一样，一个是上机实验，一个是一星附加题，一个是二星附加题（</p>
<p>横向比较的话我觉得纸笔题比初概差了十万八千里，倒是上机有点麻烦（如果想认真点写的话，但要是想写一个很丑的也很简单），不知道为啥这课风评很难，可能是先修要求没提代码这一项？</p>
<ul>
<li>今天起来一看，一股浓浓的傲慢的感觉...sigh。</li>
</ul>
<p>等我下学期进了答疑坊，要找他们把工时都要回来（</p></li>
</ul>
<h1 id="月29日">9月29日</h1>
<ul>
<li><p>离散作业明明一堆主观题，为什么非要用雨课堂交，交了就不能改了；但又在网络学堂开补交窗口，于是一堆人说自己雨课堂上交错了，又在网络学堂重交。</p>
<p>助教：我谢谢你（</p></li>
<li><p>睡得挺晚的，但躺下之后看到 runzhi
的消息还是回了，于是产生了一些今日至理名言：</p>
<p>学竞赛的时候我最喜欢几何题，学了高代和解析之后我最讨厌几何题。</p>
<p>查了一下隔壁数院的培养方案，怎么专业课都是 3
学分，想想给分阴间的话还挺文明的，而且学的东西也不会比华子的普遍 4
学分少吧。runzhi
说这学期要边上数分高代几何边学抽代，寒假要冲完概率论和抽代，下学期去先修，我只感叹相比之下我真的是摆烂得厉害。然后吐槽了半天丘班，不愧是北大甘中心主任，那个超过了丘的男人（开始暴论</p>
<p>好！那我也立个
flag，寒假摸完测度积分，如果能再在初概的基础上看看概率论就更好了。</p></li>
<li><p>还是昨天那个唐宏岩概随的问题，起来看到又一个来求助的同学上机题用的是
Python，写出来的东西不知道怎么弄才能改参数复用，于是帮忙改了一下，然后发现写得稀碎，基本重写了一遍。改完突然意识到自己也太好说话了，但是对方好像又是初学嗯写，又想起来很多
fly bitch 的经历，不帮一下又于心不忍。就这一次，就这一次.jpg</p>
<p>可恶，等我进了答疑坊，快还我半小时工时！记小本本上了！</p></li>
<li><p>今天其实特别摆。提不起精神来，奖学金的申请表填了一下午，虽然想恰点烂钱实现财务自由，但是莫名就是很烦...内容都是照抄水利系奖学金那一次的，除了经历里加了几句关于课咨委和天格计划的内容，就没什么变动了。</p>
<p>然后也没干什么，就写了抽代作业，然后整理初概整理到半夜，效率低下。</p></li>
</ul>
<h1 id="月30日">9月30日</h1>
<ul>
<li><p>又有保研政策的风声，感觉好像离正式公布不远了。润学小群聊了一晚上，我其实都不大想看了。不能跨保也好，不能外推也好，哪怕不能打印出国成绩单也好，已经麻了，爱咋咋地。最不济毕业之后直接就业做一年
RA 再申请，权当 gap 了，也能养活自己，迟早能有学上的吧。</p>
<p>上次去打成绩单，知道是带夏季小学期的时候就已经有点破防了，看到 29/60
的时候更是有点无奈，分外怀念起上学期的
18/60，尽管当时也不满意。一直以来，我到底在为什么而骄傲呢？是为一点点
coding 的雕虫小技，还是基础就不大扎实很难说会走多远的数学学习？Loser
竟是我自己（</p>
<p>emo 归
emo，目前还是要相信，我的想法一定不会错，我做的事情明明都很有趣，所以打算把一切归结为华子的问题，就这么决定了！</p></li>
<li><p>今天早八 ODE 点名了，但是我在睡大觉（。）决定把它记 PF
然后随便上上拉倒，其实也是课太多有点蚌埠住了。</p></li>
<li><p>交了奖学金申请表才开始看奖项分布，感觉综奖给 20%
的话还有戏。多给点吧，孩子还要考托福，好贵啊。看到社友说挣钱如搬山花钱如流水，草，别骂了。</p>
<p>上抽代的时候看到好几个人都正装来上课，观察了一下都是我认识的（但其实对方不认识我）致理的同学，那大概是今天奖学金答辩吧，印象里宗桑发空间说他们申报比较早来着。</p></li>
<li><p>不知不觉就到月底了啊...写日记是一个突发奇想的尝试，9 月的日记长达
1.2w
字，也不知道都说了什么废话。而且好像一直有朋友在看的样子，非常感谢！</p>
<p>三次元生活真的是已经完全自闭了，进大学以前的朋友都没有来华子的（runzhi
和友人都在隔壁，以及我姐一直在江西读书），大学之后其实也没有认识什么线下经常接触的朋友，每天会在线下说几句话的好像只有室友。所以花在网络上的时间蛮多的。开博客以来最重视的事情之一其实就是和自己交流，倒是也做到了。</p>
<p>感谢陪伴！十月见！（鞠躬</p></li>
</ul>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇五·23年1月</title>
    <url>/2023/01/01/Diary-2023-01/</url>
    <content><![CDATA[<p>日复一日，年复一年</p>
<span id="more"></span>
<h1 id="月1日">1月1日</h1>
<ul>
<li><p>这个系列居然存活到了 2023 年！</p></li>
<li><p><del>表白成功了！</del>收到抽代助教回复的邮件了！还加了好友，好哦！（</p>
<blockquote>
<p>驰雨（x）同学：</p>
<p>你好！非常抱歉现在才抽出时间来回复你，虽然已经向你发送了微信好友申请，但是还是认为同样给你回一封邮件比较有意义。</p>
<p>其实我早就有留意到你不是数学系的学生，在和老师闲聊的时候曾有提到过这件事，大致意思是在本门课中给我留下最深刻印象的同学居然是学土木（hhhhhh当时我是猜测你是这个专业）的同学，许多我本以为他们并不会做出来的题目她也有认真去做。</p>
<blockquote>
<p>没猜错，只是我写邮件的时候还掩盖了一下，我说我一学位是物理，二学位是交通建管（确实也是实话</p>
</blockquote>
<p>实际上我和你的经历有许多的地方有一些相似，我本科入学的时候的专业并不是数学，而是某个工科专业，而且高中的时候数学学的一塌糊涂，对竞赛什么的也一窍不通。只是在大一的时候才觉得大学接触到的数学和高中完全不一样，更加有趣更加吸引人，于是才在大二转到了数学系，但不幸的是转专业的过程也不是一帆风顺，我被调剂到了计算数学专业。于是我在本科的后三年一边补大一落下来的课程，一边修基础数学高年级的课程，还不得不修计算数学的课程（听起来是非常狼狈）。</p>
<blockquote>
<p>其实我很难想象，在华子要是高中时没学过竞赛，甚至高考数学学得也不太好，大一再继续上那个锤的微积分
A，真的能培养出兴趣甚至想转去数学系吗？那个微积分 A2
直接给我上厌学了，真的烦死了...这是否说明隔壁的基础课教学质量已经远超世一大了（</p>
</blockquote>
<p>由于并不是科班出身，实际上我最初面对那些学基础数学的同学的时候还是有很大大大大一点自卑的（特别是自己本不属于这里却来旁听），总是不敢和他们去交流问题，或者是和他们交朋友，担心自己暴露出自己什么都不会的事实（x）所以我的本科时光过的并不快乐。一个转折点或许是自己成功跨保到了基础数学的直博，意识到自己或许也没有那么差劲，开始敢于和别人交流，敢于面对自己的不足。我感觉做数学有时候真诚非常的重要，自己不会就是不会，不会就要去搞清楚，和别人交流（hhhhhhhhh或许需要一大点厚脸皮吧x）这使得我之后的收获很大。</p>
<blockquote>
<p>太强了..要是我在隔壁成功转到计算数学的话可能只会想往统计挣扎一下，要么就既来之则安之，干脆不动了。在应用方向想往基础跑，真的相当有热情。</p>
<p>不敢和原住民（？）们交流也真的很真实，我甚至都不太敢在转数环里说话，<del>不过转数成功的同学平均水平好像远超原住民（？）</del>。恐怕自己也是，等到有朝一日获得一点点小成就的时候，才能挺起腰杆来吧
qwq</p>
</blockquote>
<p>另外一件事是，在学数学的时候你真的能碰到非常非常非常多厉害的人，比你厉害无数倍的人，这可能会击碎你的信心，可这又有什么关系呢？做好自己就好了！进一寸有一寸的欢喜，能比昨天的自己多会一些东西我认为就已经非常不错了。如果真的是想学数学，那就是一辈子的事情，早学一些晚学一些也没有什么大不了的。</p>
<blockquote>
<p>非常同意！x</p>
<p>说起来我之前也一直这么想，后来被别人批评说不求上进（qwqqqq），难过了很久。不过人家是神，确实在他眼里我努力学习的东西都很
trivial，所以并不是很能互相理解。那就不要互相理解了，坚持做自己就好。</p>
</blockquote>
<p>所以做自己最喜欢的事情就好啦，无论之后能不能做出来什么成果，无论这个领域已经聚集了多少大佬，但行好事，莫问前程。</p>
<p>祝眉头舒展，顺问冬安。</p>
</blockquote>
<p>然后微信上还聊了很久，听他讲了一些大一没上数分高代还选了平转数学，一边补这两门，一边顶着计算数学的课还要学基础方向的小故事，在隔壁冲基础真的很强了，这又是怎么做到四年顺利毕业的qwq，我都想主动延毕了。我大概讲了讲自己遇到的一些小的困惑，一起吐槽了背书般痛苦的数值分析（，还闲聊了些别的，非常愉快。</p>
<p>另外他给我看和 hx 的聊天记录，hx 的意思好像是要按比例调
4.0，现在这个情况再按比例调的话岂不是要向下调分了，害怕，<del>连我这种彩笔期末都能按题目顺序通畅地
ak 甚至还给一个题加强了结论，感觉人均 90</del></p>
<p>尴尬的是聊完我翻了翻他朋友圈才意识到，他本科好像是隔壁的，不是华子的。我虽然觉得“转到了计算数学”这个说法很奇怪，还以为四年前一个系里面专业都分得这么细，一直都给他预设成是在华子本研一起读的。更好笑的是我还跟他吐槽了半天诸如数分这样的几门本科生基础课稀碎的给分，和后续上课知识储备的问题，沃日，他还真的认真答了，反正对话里就感觉很奇怪又说不上哪里怪（</p></li>
<li><p>找到了一张两年前的照片，其实昨天本来想发的，结果给忘了。</p>
<p><img src="https://s2.loli.net/2022/12/31/vChpQ35jKeDbLXM.jpg" alt="firework.jpg"></p>
<p>我的高中有年底最后一天开<a href="https://www.bilibili.com/video/BV1NJ411h7Et/">跨年晚会</a>的活动，也是为期一个月的校园艺术节的尾声。大家说这是二附中最盛大的节日，但是说不清为什么我就是不喜欢这个活动。可能是因为当时不喜欢身边的人们，所以不愿意和谈笑中的大家坐在一起看演出，感觉尤其孤独，或许是天然抵触这种很有玫瑰色的青春氛围的节日，总之三年三次晚会我都没去过。晚会有一个高三大合唱的环节，高三的同学会一起拿着荧光棒唱排练了一个月的歌，然后<a href="https://www.bilibili.com/video/BV11m4y1Q77M/">被拍成视频</a>（沃日，还真找到了），很情怀的样子。轮到我高三的时候我也没去，哪怕我的手完全是做题家的手。</p>
<p>记得高三的那个跨年晚会之前刚考完一模，班主任买了蛋糕给大家分着吃。我太自闭了，一到这种时候就觉得真的好压抑，直接从教室里逃了出来。看到丢在垃圾桶旁边的蛋糕包装盒里有小的烟花棒，可能原来是要插在蛋糕上的，估计他们不会要了，就拿走了一支。晚上开晚会的时候大家去了体育馆，我也不是很想回家，就一个人坐在漆黑的楼道里看了会剧，突然摸到外套口袋里的烟花棒，忘了是去哪里找到了打火机，在楼道里点了一下，拍下了这张照片。看到四散的火花，一下子就雀跃了起来，现在还记得当时的心情呢。</p>
<p>我和友人一直以来是非常好的朋友，突然意识到即使这样她也有不理解我的时候——比如上述的这个时刻，她正在体育馆举着荧光棒为大合唱泪目，并不理解我为什么不愿意投身这种气氛之中。高中的时候写过很矫情的话，叫做：</p>
<blockquote>
<p>就像我们无法看到一生中全部的雪，也不能完全知道彼此叹息中的故事。</p>
</blockquote>
<p>尬死我了（，但确实大概就是这种感觉。不过又有什么关系呢。</p>
<p>说起来原来想投给朱自清文学奖的稿今天基本上改完了（有些人期末周是真闲啊），但现在已经不想投了，自己留着就好。何必为了一个奖把自己的心剖出来给不相干的人看呢。虽然最后好像不会公示参赛作品，但一想到评审阶段我也还是觉得算了。（才不是觉得自己这水平根本没希望，才不是（</p></li>
<li><p>今年（去年？）的跨年夜是观影马拉松！一个人在寝室连着看了《色，戒》、《血观音》和《牯岭街少年杀人事件》（这个实在太长，看了不到一半就睡了），翻到上面这张照片突然好想给自己点个烟花棒看，可惜买不到（。翻出来了生日买蛋糕时候送的蜡烛点了一下，烛光也很好看呢。（没有照片</p></li>
</ul>
<h1 id="月2日">1月2日</h1>
<ul>
<li><p>这网络学堂真的有点乐，老师给了成绩之后可以选
<code>display:none</code>，但只要会按 F12 就可以查到抽代成绩啦（</p>
<p>还挺符合预期的，ak 了就是 ak
了，<del>简单的数理问题确定性很强，很给人安全感啊</del>。想起来期中考完的时候破防了一晚上，觉得肯定是寄了，甚至梦到了
4 学分的抽代喜提 2.6，只能带着日渐贫弱的 GPA <del>在一个均绩 3.8+
的院系里</del>过一个相对失败的人生，<del>在紫荆公寓的浅色床单上痛哭</del>。没想到期中并没有想象得差，虽然没考过一个半小时的试，整场基本都在慌乱之中，浆糊一样的脑子根本写不出构造，但真的落笔写下的东西都写对了，学得还算扎实。而期末翻盘真的是存在的啊。（其实微积分
A2 期中爆炸的时候也想期末翻盘，结果期末比期中更烂（</p></li>
<li><p>虽然没有过生日的习惯，但是我还是会在生日前后借这个名义送自己一点小礼物，获得一个冲动消费的理由。去年生日的时候订了《恋爱的犀牛》的演出票，可惜四月底北京疫情，演出取消了。后来有点不开心，改成给自己买了一身看中了很久的裙子，也很喜欢。</p>
<p>期末考之后打算在北京玩几天再回家。本来是想直奔江西，结果我姐说二月份要去上海实习，就约在了上海见。原来规划去故宫什么的地方走走，刚才突然想起来这件事，不抱希望地查了查《恋爱的犀牛》演出档期，居然
1.4-1.15 之间真的在北京有场次，目测是空花组的演出。订了 1.10
的票打算去看，非常幸运。</p>
<p>本来是考虑订上海场的票的<del>（才不是因为票价比北京场便宜一半）</del>，但上海场演出是
2.14 开始，那天我就要回北京打 hpv
第二针了，恐怕是去不了的，就回家之前在北京看吧。</p>
<p>现在不用再担心封校出不去，或者演出取消了呢。</p>
<p>虽然不觉得会超过郝蕾段奕宏版的经典，而且真的已经在 b
站看过很多很多次了，但还是想去一次现场。</p></li>
<li><p>和我妈打电话。她一如既往地劝我快去找对象，不存在的，乐。我也懒得和她讲自己的很多打算和考虑，就像现在告诉她我打算延毕一年她恐怕要应激，会争执很久，没有必要，暂且按自己的思考来生活就好，每次就糊弄过去。不过她今天问了我一个很有意思的问题：会喜欢学数学的男生吗？我很干脆地回答说大概率不会，把自己惊到了。</p>
<p>想了想喜欢过的人们（不要细问，太羞耻了x）性格气质爱好甚至外貌特征都基本完全不一样，<del>平等地在不同阶段同等水平地喜欢不同的人，不存在哪个人是白月光一直念念不忘甚至希望别人身上还带有他的影子之类的情况（什么啊。</del>但确实有一个共同的特点是他们都不是很擅长或者至少不那么喜欢数学，读的专业五花八门但也都不是数学（啊其实基本后来都收敛到去搞
CS 了，大家都好成功 qvq），大概是巧合吧。</p>
<p>可能是竞赛的时候觉得数学组里很强但又有些怪的人（不好意思有点冒犯，或许叫做“比较独特的人”比较好，哪里独特我也说不出来但相信大家都有体会
x）明显比别的组要多，相比之下化学组就很欢快随和，我经常被暴打完就去找他们玩，有几个曾经关系不错的同学，<del>ex
也是化学组的（？</del>。加上自己很菜，所以几乎从来不敢和神交流，导致有点刻板印象了。但是“学数学的人里面比较独特的比别的专业里要多”这件事貌似确实是真的，为什么呢。</p>
<p>说到这里突然想起来，竞赛的时候一直非常自卑，以为我这么菜，组里的神应该都不认识我吧。最后一次联赛前我们在做模拟，彼时距离进
IMO 国家队还有三四个月的 wyc
负责监考和发准考证，遇到不认识的人他会叫一下名字问座位在哪里，我还以为会叫到我，结果他最后是走到我面前把准考证递给了我。大一下学期上排球课，左爷爷正好和我同一个时段上课，我本以为他肯定不认识我，结果他还和我打了招呼，两次都挺意外的。</p>
<p>不过想来大家认识我，根本不是因为我那羸弱的水平，甚至不是因为我菜得像个笑话（，而是因为我是组里非常少有的一直坚持到高三才退役的女生吧，混到了脸熟。高三那次联赛是省一里的唯一一个女生，同年拿了
CGMO
Au，两件事叠在一起被沪上某个小有名气的升学公众号拿来大做文章蹭流量，从小学开始的经历都被扒了一遍。一想到这些还挺不高兴的，当时又要装作开心的样子被人祝贺（有什么好祝贺的，退一万步从功利角度来说这不就是纯纯竞赛落榜生），和现在被迫过女生节时接受礼物和祝福的感觉差不多。我之前提出来我能不能不要过女生节，我也不想给班里的男生过男生节，还被约喝茶了，不利于团结的话不要说（（</p>
<p>不要再写青春疼痛文学了，快去复习啊（</p></li>
<li><p>看了一眼下学期的网络学堂，故宫学这门课的英译是
Gugongology，Google 了一下这个词一共有 19
条结果，草，什么冷门绝学（，很难想象交出国成绩单的时候国外学校会怎么想这玩意（</p>
<p>看到了一个说法：</p>
<blockquote>
<p>如前所述，故宫学于2003年正式提出，而敦煌学的出现要远远早于故宫学。学科名词出现的先后次序是衡量学科之间自觉性程度的标尺，即使是从英文拼写情况来看，两者的差异也十分明显——敦煌学已有一个国际公认的英文拼写，即Tunhuangology，而故宫学则有Gugongology、National
Palace Museum Studies和Studies of the Imperial
Palace等不同拼写形式，说明前者已是国际性学科，而后者的国际化程度还有待提升。</p>
</blockquote></li>
</ul>
<h1 id="月3日">1月3日</h1>
<ul>
<li><p>8
号考数值分析，而我连着摆烂了两天，复习时间突然变得紧张了起来，考完之前更新大概会比较咕（</p>
<p>虽然觉得对计算数学研究的问题不太感兴趣，不想往这个方向走了，但基本的数值方法毕竟是应数各个方向都会用到的，也是培养方案里（说得好像是我的培养方案一样）挺重要的必修课，不能摆过去啊
qwq</p></li>
<li><p>和甘主任唠嗑，他怎么大一上学期就已经在看 stein 了（</p>
<p>虽然一直说别人学得多快有多升级都和我没关系，自己学扎实就足够了，但压迫感来自身边的朋友的时候果然还是有一点点难绷
XD</p></li>
<li><p>今天顿悟了最近作息混乱的原因——是光线的问题。拉上窗帘之后，台灯和白炽灯是寝室里仅有的光线来源，而且楼道里的灯坏了，从楼道那一侧也不往房间里面透光。如果一整天不出门也不看表，还独处一室的话，真的是感觉不出白天黑夜的区别的。从这个方面来说人和植物还挺像的，都很依赖自然光呢（</p></li>
</ul>
<h1 id="月4日">1月4日</h1>
<p>数值分析一天看两个章节的话正好能看完，这个工作量水平基本上是肝一肝能保证完成的，还好。沃日，怎么感觉这课跟没学过似的，虽然我平时确实没怎么花时间，但这书我至少抄过一遍，PPT
课后也读过，这些内容都是学会过的啊（，怎么现在印象这么模糊。4
个学分的课考试前一周学完，真有点刺激了，大家以后上这课的话千万不要学我。不过还好沾了这学期线上考试所以开卷的光，沃日，要是不开卷的话我更想象不出来这课要怎么考，感觉这玩意和别的理论还不一样，好多优化方法都像拍脑袋想出来的，只能嗯背。闭卷的话真要把公式全背下来吗，也没必要这样折磨人吧（</p>
<p>6
号的两个娱乐项目打算缓考了，寒假里复习的话加起来不会花超过三天时间，但这三天放在现在太宝贵了，匀不出来。</p>
<p>这个破工程经济学，我一边上一边在心里骂，我将来既不做实体工程，又对经济不感兴趣，为什么非要我学。有时候入戏太深了，还真以为自己是数学系和统辅的了，每次想起来培养方案里的专业课是什么测量学，工程地质，工程力学，更好笑的是还得学量子力学，都觉得像个小丑（。没一个有用的，还难的要命，得花巨量时间处理，甚至可能要付出把更多一年的青春年华（）用在在华子里坐牢的代价。都到这份上了，给分还给得巨烂，这院系真是有毛病。</p>
<p>虽然天天骂华子，但还是终于明白了当初 SJTU IEEE
之类的选项是一个局部最优解，选华子仍然是不错的（陆本都差不多烂是吧x），中二一点讲，哪怕被折磨了这么久但总算是找到了<a href="https://zh.moegirl.org.cn/%E7%9C%9F%E7%89%A9">真物</a>（？啊？），尽管这个过程实在太漫长、太痛苦了，而且还远远没有结束。的确处处都取局部最优的话是到不了全局最优的，终值在取初值的时候就定下了。</p>
<p>读过了许多算法和定理，仍然过不好这一生（点烟.jpg</p>
<p>之前看学长写的“都是贵系的问题”那一部分，光是看都看得我焦虑不已，太累太绝望了，很难想象他那两天是怎么过的。后来一想其实华子大多院系的生态也就这个水平，拿我院出来一比，贵系好了不知道多少倍，又把我整破防了。不知道为什么想起
ex 来（上次在博客里试着搜了一下 ex
这两个字母，出镜率过高了x），只记得他也是要润，正常情况的话最近大概也在套暑研？不知道会不会沾点
UM-SJTU Joint Institution
的光，不了解。当然他看起来菜的离谱（，也或许并不会走 researcher
的路，我之前说觉得他去当翻译最好
XD，现在也还是这么觉得。现在还偶尔会去翻翻他的各种社交媒体，我之前和朋友戏称，这也算我的人类观察活动之一。确实是这样的，和平时随手打开一个社交媒体的时候会试着搜搜看朋友的
id
有什么区别呢？区别在于真的已经变成赛博幽灵，肉眼可见的将来不会再有多少联系了而已。这也很正常，举个例子来说就像我大概永远不会认识迟先生（，但是自从知道是校友之后就也时不时会去看看推。有时候看着看着
ex
发的很多东西，会觉得真的也只是个再普通不过的一般路过肥宅罢了，和我从前写的青春疼痛文学里的那个带恶人似乎没什么重叠，才发现自己的心态也已经发生了挺大的转变。怎么说呢，祝大家都顺利吧。</p>
<h1 id="月5日">1月5日</h1>
<ul>
<li><p>又看了一遍，昨天这是在说啥？倒不是抽象，感觉早晨六七点写的东西未免有些，太随机了吧（</p></li>
<li><p>数值分析，不过如此！学的时候觉得最困难，心理阴影最大的几个章节顺利过去了，后面是一些轻松愉快的多项式数值方法，感觉明天能速通完。</p>
<p>无论如何它都算是数学系的养生课，分方向之前的那些基础课哪有考前速成能学得会的。</p>
<p>不知道考试考多难，bcl
老师风格看起来比较友善，我也没题目可以拟合，就把课后题刷完了，感觉还好。</p></li>
<li><p>今天发现只有概率统计方向不必修泛函分析 (1)，有点震惊。</p></li>
<li><p>wjd 老师在鸽了我的邮件 13 天之后终于回了，笑死（</p>
<p>寒假的事好像实在有点多，先抽几天写完统推讲义和基物实验指南，今年基物实验
3
不能再退课了，我超，这课明年就停开了，因为二字班修订培养方案之后只需要做两个学期实验了，羡慕。然后还得速通数分到一个不至于原地去世的水平，以及
learn R in 24
hours，可以的话打算再浅看下统辅的两门理论课来着，毕竟下学期的难点在复和概还有统计学习导论这个码课，尽量得压缩下留给那俩半娱乐项目的精力。而且我还有期末缓了没考！草（</p>
<p>我还想多整几次江浙一日游呢，到底是假期，抚平在华子造成的精神创伤最要紧。</p></li>
<li><p>遛弯的时候不知怎么想起来，之前找一位学长问凸优化这门课的情况的时候，他简单介绍了下，然后说这课不卡优秀率只卡
A+，“虽然我最后只有 A-”。我 mod
了一下，然后他说“数学人之间还是可以相互理解一下追求的嘛”。</p>
<ul>
<li>我懂了，不是早上六七点钟写东西导致产物非常随机，而是我这个人就很随机，时不时“突然想起来”（</li>
</ul>
<p>我当时还蛮奇怪这个数学人是啥意思的，只知道他要转 AI
相关，难道转的是理论方向所以也自称数学人？还有点震惊他怎么知道我想转数的，我感觉我在现实世界的社交里一直还算低调，基本避开不提这些事。今天回来随手一搜才知道他以前也是
MOer，原来是这个意思，不知道为啥我一直以为他是物竞的，报道上出了点儿偏差（</p></li>
</ul>
<h1 id="月7日">1月7日</h1>
<ul>
<li><p>数学记号真是混乱...头大</p></li>
<li><p>摸鱼的时候看了会 <a href="https://v1ncent19.github.io/SummaryNotes/">summary</a>，发现统计计算的一大半内容好像就是数值分析的三个章节在统计问题里的应用，大概又要从头讲一遍数值方法，其余是一些统计里的特化（？）算法。眼前一黑，所以说我明年还得再学一遍这玩意是吗（，虽然会轻松很多就是了。</p></li>
<li><p>点疯狂星期四经常拿咖啡凑单，正好还有券，最近把他家号称不同口味的咖啡都尝了一遍，没尝出区别，感觉都是刷锅水的味。虽然也没喝过刷锅水，但是我就觉得应该是刷锅水的味（</p></li>
<li><p>最近不分白天黑夜地在复习数值分析，也努力让自己别再记忆随机游走了，没啥可记的，简单写个流水账。</p></li>
</ul>
<h1 id="月8日">1月8日</h1>
<ul>
<li><p>早知道这数值分析考这么简单，我复习这些天干啥呢，还为它缓考了另外两门（x</p>
<p>这话是不是考完抽代的时候也说过来着（</p>
<p>一半都是没有布置成作业的课后习题，正好这两天刷完了，剩下的有手就行，我共轭梯度法呢我牛顿法解非线性方程组的几个变式呢我特征值方法呢怎么全都没有啊（x。不过学到了不少有用的东西，好耶（</p>
<ul>
<li><p>说起来包老师的课真的讲得很好，虽然这门课是第一年开，他也是刚来华子不久的青椒（没有影射哪位老师的意思，没有
x）。课堂上讲得很清楚，思想也很深刻，强推给之后也要修这门课的朋友。</p>
<p>另外，这课的 PPT 简直仙品啊！我觉得不输 dwl，看着太享受了。</p>
<p>讲课讲得好，内容充实，不在课后刷题量和奇技淫巧上为难人，考试顺利过，这不就是很理想的课程设计吗
555，这几天备考卷昏了说出上面这些话才奇怪吧。可惜这种好处恐怕只有第一年能享受到，后来知道某个老师考得没那么难，可能就不会这么用心了。说到底好像还是学习态度有点问题（</p></li>
</ul></li>
<li><p>总算考完了，开摆！</p>
<p>明天摆一天，看看电影写写统推讲义，去图书馆借几本书带回家看以及给下学期用，后天出去走一走，大后天打扫卫生收拾东西，12
号回家。不过这周还得连夜卷一个工程经济学的加分论文，过两天再说吧，这破课还这么卷，好烦。</p></li>
<li><p>总的来说，这学期虽然开局选了六门数学课，结果最后退了一门水的，又
PF
了一门卷的，剩下的要么本来就不难要么碰巧选到了水一点的老师。所以似乎还是没体验到数学系的课劲有多大，在一个并没有做好心理建设的状态下，下学期就又选了六门，而且还要去碰瓷实复概里的复和概，感觉人肯定会出事的（悲</p></li>
</ul>
<h1 id="月9日">1月9日</h1>
<p>一天啥也没干，好不容易考完试，想摆烂却不知道怎么摆了，感觉是很空虚的疲惫。勉强补完了跨年观影马拉松时候没看完的《牯岭街少年杀人事件》，心情更沉重了。</p>
<p>下午写了会统推讲义心情就好些了，参考着统计计算的讲义和刚刚考完还热乎的数值分析，给
Newton 方法求解 MLE 的部分补充了一些变式和收敛条件，挺好玩的。</p>
<p>晚上二刷了 BBC
神探夏洛克的第二季，我小时候不爱看巴斯克维尔的猎犬这一部，拍出来整体很昏暗，有很多丛林里穿梭的场景，稍微有点恐怖。所以其实不记得这一部的故事了，就二刷了一下。中间有一个猎犬来袭时，委托人把脸贴在家里的落地窗上往外张望的场景，玻璃里映出了他的脸，我就在想为什么要在家里装这么大一面玻璃幕墙，感觉很没有安全感。</p>
<p>然后想起来（又开始 random walk
了是吗）高中在图书馆负一层自闭的时候，曾经随手翻开过书架底层的一本看起来有些奇怪的书，是阳版的《哈扎尔辞典》。前几页大概讲了这样一个故事：哈扎尔民族会因为在睡梦中被人叫醒而暴怒，因为他们认为人在睡觉的时候最脆弱，容易被恶人偷袭。阿捷赫公主为了在睡眠中保护自己，每晚命仆人在眼睑上写上毒咒字母，看到字母的人就会死去，早晨起床前由盲人婢女服侍自己梳洗，擦掉字母后才睁开眼睛。某天有人为她送来了一面快镜和一面慢镜，快镜可以映照出不久后的未来发生的事，慢镜映照出刚才已发生过的事，时间差是相等的。这两面镜子碰巧在她睡觉时送到面前，于是阿捷赫公主睁开眼睛时在慢镜中看到了自己眼睑上的字母，在快镜中看到了已经睁开眼睛的自己，危险的睡眠中安然无恙的她死于清醒的瞬间，镜子无法映照出的当下正是死亡时分。“她是在来自过去和未来的同时打击之下亡故的”（不知道会不会和原文出入很大，但我对这句话印象很深）。</p>
<p>当时甚至还不知道这是真实存在过的民族的传说，还是完全的虚构，看完有点吓到了，没有把它借走，也一直没有再往下读。但这个关于镜子的隐喻一直记到现在，时不时会想起来，尤其是每次意识到想起它的时刻正是过去与未来的间隙，是阿捷赫脱离危险的梦醒时刻和死亡时分，总是会吓自己一跳。电影里的委托人满含恐惧地把脸贴在玻璃上，这既不是快镜也不是慢镜，因此玻璃里映照出一张一模一样的脸，而当下正是充满着死亡气息的恐怖时分呢。</p>
<h1 id="月10日">1月10日</h1>
<p>今天出门借书之前想起来昨天说到的《哈扎尔辞典》，搜了一下北馆也有馆藏，考虑要不要借一本来继续读，但是印象里很厚，带回去有些麻烦。然后在搜索结果里看到了一本《爱情故事的两个版本》，才知道《哈扎尔辞典》背后的小故事，太浪漫了：</p>
<blockquote>
<p>题名：哈扎尔辞典 Dictionary of the Khazars</p>
<p>作者：帕维奇, M [1929-2009]. (Pavic, Milorad)</p>
<p>描述：这部类似“民族志”式的“辞典小说”写了一个幻想的古代民族“哈扎尔”人的历史以及有关这个民族的各种轶事。此书是《哈扎尔辞典》的阳本。阴本跟阳本并无多大差异，有人曾对照阅读，发现仅十一行文字有所不同。</p>
</blockquote>
<blockquote>
<p>题名：爱情故事的两个版本 Ljubavni roman u dve price</p>
<p>作者：米哈伊洛维奇, J. (Mihajlovic, Jasmina) ，帕维奇, M, 1929-2009,
(Pavic, Milorad)</p>
<p>描述：本书是雅丝米娜·米哈伊洛维奇与米洛拉德·帕维奇共同创作的一部作品集。其中，“科托尔文具匣”收录夫妻二人围绕一个神秘的文具匣进行的同题创作，写作因此也成为作家夫妻间亲密而浪漫的约会方式；“爱情故事的两个版本”记录雅丝米娜向帕维奇“定制”故事的有趣经历，文学大师不同寻常的写作状态可见一斑；“迟到的情书”由帕维奇的小说碎片展开，引发出雅丝米娜对二人过往爱情生活的追忆和对丈夫深情的怀念；游记“哈扎尔海滨”记录雅丝米娜寻访《哈扎尔辞典》中那个“消失”的民族——“哈扎尔人”的见闻、体会和奇遇，也记录下二人对历史、时空、死亡等问题的思考和感悟。</p>
</blockquote>
<p>其实高中的图书馆地下一层有很多大家都不知道的藏书，比如《中等数学》合订本（字面意思，真的是图书馆老师自己把月刊订在了一起），我还拿来刷过题，还有
1940
年代出版的李四光先生的《地质力学之基础与方法》（当时为了给地科社写科普推送，我甚至还读过这本书，是否预示了被调剂进土水学院的未来。这个故事也充分告诉我们，随意把普通爱好变成职业是行不通的啊！），村上春树的《刺杀骑士团长》，阿列克谢耶维奇的四件套《切尔诺贝利的悲鸣》，《锌皮娃娃兵》，《我还是想你，妈妈》，《我是女兵，也是女人》，还有《岛》也是在这里见到的，后来因此去读了维多利亚希斯洛普的其他作品，我更喜欢《线》。甚至新海诚三件套《秒速五厘米》《星之声》《言叶之庭》的轻小说都有。</p>
<p>不过要说馆藏里最冷门的恐怕还是井上靖的作品《天平之甍》（甍读音通萌），是从日本视角讲唐代僧人东渡的故事，还有《孔子》。《天平之甍》里最后讲到，僧人淡海三船为敬谢来到日本时已经失明的鉴真，写下了“我是无明客，长迷有漏津。今朝蒙善诱，怀抱绝埃尘”的诗句，大意是称自己才是“无明客”，承蒙鉴真以佛法善诱，从而心怀脱俗。后两句分手的时候被我写下来送给了
ex（开始青春疼痛文学了是吧），原本是想最后给他一点安慰（因为分手是我提的，我真善良）。但我后来想想觉得他一定永远不会关心这一句我从哪里见到、是什么意思，说到底他也一直都根本不太在乎这些，很难相互理解，罢了。<del>并不是说我是文青（？）就要求他也得是的意思</del>，只是说完全不在乎别人的心意的话会很令人失望，一向如此。</p>
<p>在半退役的苦闷高二，我在地下一层兜过无数圈，上述这些以及见到过的其他有趣的书几乎都借来看过一遍，它们是在这个学校里待了三年，真正影响我、改变了我的东西。只是一直都是崭新的，似乎不太有人会去地下一层的书库找书。一层也有一点比较有意思的书，印象里看到过一本全英文的烘焙书，放得很高，里面写了各种面包的做法，适合画饼充饥。但我想它在那里可能是因为书脊比较漂亮，被用来当装饰物的吧。但实际上一层书架不多，大多数放的是教辅和给竞赛的同学用的大学教材。桌椅很多，桌上还有台灯，基本是作为阅览室使用的，在里面卷自习的不少，我也曾经是其中的一员，后来遇到一些困扰（这个故事或许下次可以讲），就再也不去了。</p>
<p>对了，想起《哈扎尔辞典》和《天平之甍》的时候是我难得的会为我的高中感到骄傲的瞬间，尽管我猜这两本书几乎不会有别人借来读过，但它至少存在于一个中学的图书馆里，这让我无比幸福。</p>
<p>感觉在很没水平地掉书袋...实际上我确实喜欢阅读，但是并不算擅长写作。高中语文考试阅读从来都能随手拿高分，作文就不一定，太擅长写
random thought
和不停堆放读到过的东西，要么就是刹不住地表达情志，写不来议论文，经常被骂。<del>虽然只是和同班同学相比的话，根本不需要作文写多好就能爆杀大家（？）</del>。Anyway
我写的东西实在没什么水平，感谢大家忍受我（，要我做读者的话还好一些，但坚持阅读，思考和写字，这才是我理想的生活啊。</p>
<p>好啦，碎碎念完之后，我要准备出门去看话剧啦~</p>
<h1 id="月11日">1月11日</h1>
<p>写个流水账。一边收拾东西一边摆烂，收完发现就一个行李箱，还有一个平时背的单肩包。单肩包里就放了贵重物品（其实除去电脑之外，我包里最贵重的东西是一支不算常用但一直带着的口红和一小瓶香水，草），证件，水杯和路上想读的《汴京残梦》，甚至没装满。说来惭愧，《汴京残梦》还是去年五月从毕业的社友那里收的二手，听说是黄仁宇（就是《万历十五年》的作者）的作品，就买了，到现在也没读，那位社友也很久没上线了。</p>
<p>暑假来北京的时候带了行李箱，一个书包，一个单肩包，一个放在行李箱上的袋子，回去反而少带了很多。一想到明天在车上还要找个路人或者乘务员帮忙把行李箱抬到架子上，有点绷不住（。但是装了书之后我是真的拿不动，拿不动还要带这么沉的箱子回去，是不是我有点问题（#每日内疚
#每日社恐</p>
<p>晚上骑车出门兜了兜风，友人送了一张奈雪的券要过期了，就到东南门外的奈雪买了一杯。前两天趁最近闲着没事，还报了个今天的被试，赚点奶茶钱，其实就是在
FIT 楼玩了会 VR，采集动捕数据。运动量超过一个月总和了（</p>
<p>有道理，下次可以把打赏的提示改成 buy me a cup of bubble tea（奶茶用
cup 吗（</p>
<h1 id="月12日">1月12日</h1>
<ul>
<li><p>今天在回家的路上，原本写了个长的，到家看看觉得不大适合发出来，就算了（</p></li>
<li><p>我经常和朋友说我真的很焦虑，真的很焦虑，我和 Bowen L
（就是抽代助教啦，以后就这么称呼了）聊天的时候或者和 wjd
老师发邮件的时候也说过，焦虑已经成为了我生活的状态之一。然后大家都告诉我，不要焦虑啦，但不要焦虑的原因往往是因为焦虑也没用，只能消耗能量，所以不要焦虑。这话虽然没毛病，可是我听了之后更焦虑了——我在为因为自己的焦虑而消耗了做别的事的能量这件事而焦虑，为什么我这么辣鸡，每天要不停地破防和焦虑，别人不都克服了焦虑然后把时间花在有意义的事情上了吗，我怎么做不到呢？</p>
<p>下次换个说法劝我吧，骗骗我也好啊（</p></li>
<li><p>差点忘记了，1 月 11 日或者 12 日的话，要放一首歌在这里呢：<a href="https://music.163.com/#/song?id=1862533181">《またねがあれば》by
當山みれい</a></p>
<p>去年第一次遇到这首歌之后为旧事又破防了四个月之久，自闭太久了连破防都算是给自己找事做，有点傻。关于这两个日期就不细说了，总之还是青春疼痛文学（。其实除了第一段歌词和歌曲的封面之外也没有特别贴合的地方啦。</p>
<p>很久没听过，才发现现在居然也要 vip 了（</p></li>
</ul>
<h1 id="月13日">1月13日</h1>
<ul>
<li><p>在北京苟了一个月没有感染，回家第一天就病倒了（</p>
<p>虽然可能和不适应没有暖气的室内有关，应该只是感冒，总之是发烧了，躺平。</p></li>
<li><p>工程经济学的加分论文到最后还是放弃了，实在是没兴趣做，算了吧。以前我还愿意为自己的专业课付出一点时间挣个好成绩，但自从找到兴趣点之后就越来越难以忍受这种被迫卷的工作，它们对我此后的人生毫无意义啊！</p>
<p>但其实暑假里的工程计算机制图就是前车之鉴，因为没兴趣卷，被 curve
后吃了 2 学分的
C。工程经济学据说给分正常，老师教这门课已经至少十年了，理应不会有太大的改变。我真的不想做额外的工作了，开学之后补考完期末拉倒。</p>
<p>说实话，我真心钦佩院系里多数同学的吃苦耐劳。明明被这个专业恶心得不行，还兢兢业业地按计划完成培养方案里的每一门课，把加分论文卷成不写就等于减分的任务，在所剩无几的时间里塞几门
CS 或者金融的课程，已经活成被华子 PUA
出的形状了。我从前还能做到，现在只生理性抗拒。当然可以说我是逃避，自己懒惰加上水平不行就赖学校和院系，但每个人展现出来的状态不也和环境有很大的关系吗（</p>
<p>昨天在高铁上，半梦半醒中被一个同学拉着问软软和贵系还有工工几个组的差别（我也不是很懂啊！），听他谋划限制保研方向后还可以做的几个最优解，说软软某个导师门下几乎都是非清本，所以觉得自己可以去碰下瓷，以及“再不济软软总比土水强”（怎么乳软啊！），etc。</p>
<p>华子从来不培养人，它只会 judge 人。你想接受这套逻辑，乖乖躺下给它
judge，它还说你不配被 judge。</p></li>
</ul>
<h1 id="月14日">1月14日</h1>
<p>还在发烧，睡了一整天，所以没啥可写的。晚上好多了（</p>
<h1 id="月15日">1月15日</h1>
<ul>
<li><p>两天睡了至少 30
h，总算缓过来了，感谢关心捏。做了三次抗原全都是阴性，烧了两天还没获得新冠抗体，真是有点亏。</p></li>
<li><p>下午写了会统推讲义，差不多把统计量约定和性质写完了，<del>发现以前的理解还有点不很对的地方，什么叫费曼学习法啊</del>。打算发个邮件给老师，让她先检查一部分。说起来开个
Repo
做这件事的话比较方便吧，不用时不时手动发邮件了，<del>社恐狂喜</del>，但不知道老师习不习惯。</p>
<p>中学的时候似乎也学过样本方差的概念，当时就搞不懂为什么系数是 <span class="math inline">\(\frac{1}{n-1}\)</span> 而不是 <span class="math inline">\(\frac{1}{n}\)</span>，不过这一部分高考和竞赛貌似都不考，也没讲过。现在才知道是作为统计量看待的话，修正系数之后才能作为无偏统计量来估计分布方差。</p>
<p>上了大学才知道好多省份的高考还考线性回归，修统辅之前我连这是什么都没听说过，突然有些担心把这些东西写上去的话会不会太浅显了。不过上海高考连导数、动量这些东西都不学（听说现在要考导数了），还真的挺利好理科苦手（指我自己</p></li>
<li><p>啊对了，暑假里写的几何题解终于<a href="https://mp.weixin.qq.com/s/XKpAcD2xH7XY_RFtueGbbw">发出来了</a>。我之前和组长说我下次应该不会再写这个了，真的做不来难题，收几个水题跑路有点丢人，另一个是大龄玩家（？）好像也不应该再在高中生的游戏里浪费时间，该往前看了。</p>
<p>不知道为什么，组长给冷老师发的邮件里说这是我们组最后一次写 Sharygin
了，卖了个情怀。别人也都是这个意见吗？</p>
<p>但我对大学的数学竞赛似乎也没什么兴趣。觉得丘赛离自己太遥远，根本什么都还没学会，又觉得全国大学生数学竞赛那个报名非数组不大合适，数学组的话一样没学会。新生基础大赛的时候也是这样犹豫着，既没有报非数也没有报数学组，最后咕掉了。但当时到底是不是因为微积分
A2
学得太拉，怕在非数组里暴毙，我也记不得了，似乎有这个原因，那真是有点菜啊。麻了，快去学习（</p>
<p>草，上面那个推送又把我名字写错了。虽然也不是第一次被写错名字，但找一下这个字很难吗（恼</p></li>
<li><p>下雪了，但远远没到能积起来的程度，在半空中看雪是很大的，飘落到地面就没有了。</p>
<p>本来想拍点什么，然而相比北方的大雪实在是寡淡。发现楼下有一只猫猫在打滚，橘白可爱捏。</p>
<p><img src="https://s2.loli.net/2023/01/15/rHLMyAdGwazoBJt.jpg" alt="miaomiaomiaomiao"></p>
<p>晚上去盒马拿了我妈预定的两盒水果，看了眼价签，三斤小番茄 20
块钱，六两草莓 30
块。感觉自己真的是很没生活常识，常见的菜价我恐怕基本都说不出来，这种精细的水果自己一个人的时候也不怎么买，更不清楚了。想起来最近好多（？）up
主都在打丹东红颜草莓的广告，点开过一次链接才知道真挺贵的。又想起墨茶去世前几天说想吃草莓，大概也是现在这个时候。所以雪下得薄一些也没什么不好，在楼上看雪时埋怨雪不够大没有积起来，因为在楼上啊。</p>
<p>#每日为赋新词强说愁 #每日不知道为什么但是感觉会被骂
#每日叠甲</p></li>
</ul>
<h1 id="月16日">1月16日</h1>
<p>好像距离最后一门考完已经过了一个星期了，这一个星期没怎么玩但也没怎么学，到底干嘛去了呢（</p>
<p>今天去了嘉兴，大概是规划过的江浙一日游的第一站，<del>其实也只规划了第一站</del>。来回火车票
25 块，似乎比坐 16 号线去滴水湖还便宜。</p>
<p>嘉兴是我长大的地方，出生之后直到上小学之前都在这里度过。在南湖区逛了逛，除了父亲曾经供职的嘉兴学院和小时候住过的小区，就没看到什么和记忆相符的地点了，连幼儿园都搬走了，怎么会事呢（。本来是来治疗精神内耗的，结果光是迷路就给我走迷茫了。</p>
<p>以前有一段时间对轨交线路比较感兴趣（倒不算车迷），玩过几次随机公交/地铁挑战，买一张一日票，不用动脑子，随机在换乘站下车搭另外的线路，还挺开心的。<del>结果有次在复兴岛下车之后发现没地方去了，骑共享单车到五角场吃晚饭，草。</del>后来虽然不怎么尝试了，但大多数换乘通道长什么样子我都有印象。也想过乘公交车省际来往，但是一直没有成行，这个肯定会更辛苦，不太有精力。</p>
<p>没拍什么照片，也没去乌镇和西塘，没买东西带回来。路上翻了翻包发现还带着学生证，随手打开一看，学籍注册栏的那两页一共有五个大框，可以贴十个学期的注册章，是否在暗示我延毕一年也贴得下（x</p>
<p>所以为什么要跑这一趟呢？我也不是很清楚啊！</p>
<blockquote>
<p>就这样，他（波塞冬）几乎没有察看海洋，只是在匆匆攀登奥林匹斯山的途中，飞快地瞥上一眼，而且他的确从未在海洋里航行过。他常说，他以此等待世界末日的来临，到那时候，也许会出现一个安静的时刻，就在末日快要来临之前，在检查完最后一笔账目之后，他还来得及做一次快速而短暂的旅行。</p>
<p>——卡夫卡《海神波塞冬》</p>
</blockquote>
<h1 id="月17日">1月17日</h1>
<p><img src="https://s2.loli.net/2023/01/17/neGRXiAIU3Shp9E.jpg" alt="sleeeeeeep.jpg"></p>
<h1 id="月18日">1月18日</h1>
<ul>
<li><p>昨天开 Learn Mathematical Analysis or Die
的时候其实根本没想好写什么，写好序言就直接传上来了，当时想的是就算不知道写啥，先给我一种“大家都知道我在学这个东西了所以不能再鸽下去了”的感觉也行，不然真的一天睡
20
个小时。后来发现我话挺多的，不愁没得说，以及真的开始看了之后觉得挺有意思的，不像以前一样恐惧了。</p>
<p>可能是因为学过了抽代和数值，高代虽然没上课但除了多项式也基本学完了，所以再回头看数分觉得以前搞不懂的东西有些其实很好理解。总之确实，可以用很多种不同的顺序完成培养方案。</p>
<p>不过明天要出门和友人小聚一下，就不 learn mathematical analysis
了，我选择 die（</p></li>
<li><p>摘自 Learn Mathematical Analysis or Die：</p>
<blockquote>
<p>要开始构造实数了！用的是 Dedekind 分割。这个我也在 wxf 的微 A
课上听过，但他讲得并不认真，仅限念了一遍定义。后一节课课前有同学提问说，为什么一左一右两个集合就能代表一个实数呢？他不是很愿意理会的样子，反问说你是不是补退选进来的所以没听过第一节课啊，一只羊为什么代表
<span class="math inline">\(1\)</span>
呢，两个集合怎么不能代表一个数呢。</p>
<p>他可能是觉得这个问题太 trivial
了吧，也或许只是当天心情不好而已，然而提问的同学看起来还是没理解的样子，还平白无故被敲打了一下，就茫然地坐下了。Anyway，在这之后我对这个课堂的印象就不是很好，后续也很少再去上课了。只是觉得，为什么不能好好讲清楚道理呢，就告诉同学理由是从几何直观的角度来看，把实数轴任意截断的一点都是实数，有这样的一个定义不就好了吗。当然，当然，应该是我吹毛求疵了，他可能真的只是当天心情不好，所以不太想解释，后来我也没怎么再听过他上课，不清楚还有没有类似的状况，可能属于是不小心碰到了一个极端情况。</p>
<p>另外，单是讲过这个有什么意思呢，不说 Dedekind
分割满足序公理所以确实可以定义出实数，也不拿来用一下，就莫名其妙放一个定义在这里，课后又让做题目，感觉是在炫技。后来我也看过一部分他的讲义和回放，挺多莫名其妙的安排都有点像炫技，就彻底放弃跟进度，自己单开了。不过确实也没人逼你选他的微积分课，接受不了的话，换别的老师的课堂就好了，或许是个伪命题吧。</p>
<p>虽然大多数同学都吹 wxf
讲课有多好，但我其实相当怀疑他们有一部分并没有听明白课堂内容，觉得老师讲的内容很高深，自己吹捧老师的话会显得很厉害而已。另外听说
wxf
的答疑确实很认真，或许大家说他好是指这一部分吧，还是指他喜欢在课堂上和群里讲笑话？PPT
和讲义是准备得挺认真的，可惜我并不觉得设计得好，<del>感觉白认真了</del>。总之我是不太喜欢这种不彻底也不成体系的高阶知识下放，或许它自有意义，带大家了解一下也好。当然，和我相反的典型就是
wl 他们，是真的学得很好，也喜欢 wxf
的课堂，所以我这些话很可能只是弱者的托词而已。也是啊，我觉得他讲得不好，大一的时候干嘛不自己去看一千零一页，而是单开去拟合微积分往年习题了呢，乐。</p>
<p>弱者的牢骚暂且发到这里，下面继续说点正经的。</p>
</blockquote>
<p>画风其实是这样的，想到啥说啥。不过很奇怪吧，我觉得 wxf
的高级课堂没什么意思，几乎不怎么听课，也从没参与过课后的讨论班和群里的讨论。说到底我也不咋喜欢群里的氛围。前段时间那个课程群还在不停弹消息，大概是
wxf
被推到校级的清韵烛光去了，大家又在膜，说到底这个也很正常，但不知道为什么我就觉得有点烦，直接退了群，第一次结课后退课程群。笑死，单从这些来看，我并不像是对数学很感兴趣的样子。</p>
<p>wxf 爱好者（如果有的话）请轻点喷我（</p></li>
<li><p>沃日，这个月评论区好热闹啊，<del>社恐震惊</del></p></li>
</ul>
<h1 id="月19日">1月19日</h1>
<ul>
<li><p>前两天读完了一千零一页讲义的实数理论部分，又写了习题，给我乐死了。学完代数再来看这个也太爽了，完全解决了我秋季学期学抽代的时候想过的<del>一个看起来很蠢的</del>问题——实数域和普通的特征为
<span class="math inline">\(0\)</span>
的域到底有什么区别，特殊在哪里？明明它们在素域的层面上看起来还是一样的（实际上也不一样，没有序关系，但至少形式还是一样的），为什么素域之外的元素差别这么大？举个例子来说，普通的域在素域之外完全可以没有元素，为什么实数域却比有理数域多了那么多元素？</p>
<p>何宝在课上时不时会指出，我们研究的域比较抽象，没有序关系。我虽然也觉得这个是重点，但并没有觉得是一种决定性的不同，以为是有什么别的更本质的不同，导致了在实数域上存在序关系，或者它只是“不同”之一。至于序是什么，不等号究竟是什么，序公理是什么，一概不知了。</p>
<blockquote>
<p>吾尝终日而思矣，不如须臾之所学也。</p>
</blockquote>
<p><del>感觉真的很丢人啊！怎么会有人这个时候才学这些东西</del></p></li>
<li><p>顺便把那一篇改成数分 I
速通日志了，感觉会写很长，就别合在一起了。</p>
<p>后面和一元微积分重合比较多的部分大概可以快很多，毕竟这个我还是有胆量说自己学得不错的，感觉又有希望能学完了。</p></li>
<li><p>和友人来吃了暑假一起吃过的烤肉，当时也是在这里填了用餐人数 999
人，点完单后收到了 4995
元的餐位费账单，草。一个测试工程师走进烤肉店，烤肉店溢出了（（</p>
<p>一些今天的智慧发言，记之：</p>
<blockquote>
<ul>
<li><p>为什么只有 Elden Ring，没有 Elden Field，Elden Group，<del>Elden
Principal Ideal Domain</del>，etc. ？</p></li>
<li><p>就像得证可以写作 Q.E.D.，或者直接画一个小方块（我 MO
时期甚至比较喜欢画完再涂黑，或者画上阴影）一样，我觉得良定义也可以有一个比较新的代词，叫
happily ever after 就很好。中文的话 FGO 里翻译得不错，叫做夜话团圆。</p>
<p>友：为什么不能叫做“你看看，我帮你把 bug
修完啦！”呢，我觉得这个也很合适（</p></li>
</ul>
</blockquote></li>
</ul>
<h1 id="月20日">1月20日</h1>
<ul>
<li><p>突然觉得是不是下学期不该选复概而是应该选实概来着，它俩关系还大一点，读一千零一页还攒了点信心。</p>
<p>现在选也来不及了，实分析只剩何凌冰，大概是听过他的数分之后接着上比较好，别折腾我了。至于取并集三门一起学，那要退统辅课才能活下去，我又不舍得，不要再动了。又要表演一个以任意顺序修培养方案。</p></li>
<li><p>期末怎么只出了 8
个学分的成绩，看来听说可以查成绩了就在大年二十九蹲点刷新 THUInfo
的我还是不够摆烂，还不如老师摆。数值分析和抽代都没有出，有点担忧是不是要看缓考的情况向下调分，我真的怀疑这两门课要调分就只能向下调（</p>
<p>一学期没打开 THUInfo
的成绩单界面，于是时隔好几个月又看到小学期那门拿了 C
的工程计算机制图，麻了。</p></li>
</ul>
<h1 id="月21日">1月21日</h1>
<ul>
<li><p>除夕啦。已经十多年不回老家过年了，说实话老家也没有给我们去的地方了，一直都是和我妈在家里过。过年的一天感觉和平时也没什么差别，除了上海外环以内全域禁燃烟花爆竹，我家正好在外环外面一点点，放得格外凶，傍晚开始爆竹声就没有停过。</p>
<p>聊起来父亲那边的亲戚，说起堂哥（？是这么叫吗），是父亲的大哥的儿子，比我大六岁。上初中的时候听说他大学考得不好，最近又听说他考研考了三次，考上了一所二本，再读三年就要工作了。</p>
<p>因为不怎么回老家的原因，我对堂哥的印象很模糊，但总感觉到亲近，印象里觉得他是个可爱、腼腆的人。大概只有两个记忆点，一个是五六岁的时候在父亲那边的农村老家过年，他把他的悠悠球拿给我玩儿，但我没玩过狭义上来说是男孩子的玩具，差点给他摔了，他好一顿大呼小叫。后来在院子里放鞭炮，大概是打了什么赌然后我赢了，他摘下毛线帽子，蹲下来让我弹他脑瓜崩。</p>
<p>还有一次可能是刚上小学的寒假，大伯带他来上海，找姑姑一家和我家一起出去玩，也是最后一次和父亲那边的亲戚见面。姑父是生意人，很豪气，到陆家嘴请大家吃了披萨，然后还一起去了水族馆。大伯只买了堂哥的票，让他跟着大家进来玩，自己在外面等他出来。姑姑姑父带着堂妹玩得很欢，堂哥一路默默跟在我父亲身边，跟我们一起逛，也不怎么说话。最后到了纪念品店里，我挑了一串贝壳手链和一个小冰箱贴，冰箱贴是一个小瓶子，里面是水和油，界面处浮着一条塑料小鱼，无论怎么倾斜小鱼都会浮在界面上，不会沉下去。付了钱出来之后父亲在我身边轻声说，哥哥一个人来玩的，没人给他买东西，你把小鱼当做礼物送给他好不好。但我当时不愿意，父亲劝了两次之后还掉了眼泪，最后堂哥安慰我说他不想买东西，没关系的。</p>
<p>长大了才懂得为什么大伯只买了哥哥一个人的票，懂得他为什么听话懂事，想起他的时候都会很难过，想着当初为什么没有把小鱼送给他。后来知道他在受教育的过程中一直在跟着大伯辗转，不停地转学，经常在一个省市读一学期，就要跟着大伯再去别的地方，来过上海，去过徐州，周口，也在山东的几个地方待过。分明各地学制教材都不一样，慢慢被折腾得成绩越来越差。即使我也经历过很长的贫乏的生活，但至少始终被母亲重视，安定地成长，还是幸运太多。现在也不知道他身在哪里，长成什么样子了，在学什么专业，将来打算做什么。最后的印象就是十多年前在纪念品商店里，他一个人站在货架前面看恐龙模型，后来仓皇地来安慰我，以及在水族馆里逛的时候他跟在父亲身后半步，怯生生的样子，父亲每每和他搭话，他都腼腆地笑。</p>
<p>写完之后眼泪汪汪（）地去找那个小鱼瓶子，一下子找不到，更加难过了，而贝壳手链带到北京去了，现在还放在学校里。住在上一个家里的时候小鱼瓶子还在呢，不知道是搬家搬丢了，还是搬来新家之后不知道放到哪儿去了，一定要好好找找。我想我一直为在事件上的记性好而烦恼，倒也没有必要，许多事情还是一定要记住，能记录下来的话会更可靠些。</p>
<p>他的名字叫云飞。</p>
<p>来点 TA 文学 #每日TA #终将成为TA（？</p></li>
<li><p>今年的最后一天看到了 MashPlant
更新了学期总结，于是又去把之前的一些文字读了读。他的文章大概是所有我在线上能够
reach
到的人的随记里面最喜欢的，每一篇都在不同的时期读过很多遍，甚至搭这个网站的时候没有多看，直接选了
NexT 系列的主题大概也是因为看习惯了他的博客，随手就选了，实际上 NexT
很旧了吧。不过他不可能认识我就是了（</p>
<p>我一直觉得我以前和 MashPlant
的心态很多都很像，无论是做题还是人际关系，当然他做题的水平比我强一万倍。像是之前他说在假期就开始做
project，lab
一布置下来就要赶快做完，否则会很焦虑。我大一一开始也是这样的，网络学堂的剩余日期变成橙色的
7 天就会很焦急，熬夜写 ddl
还有相当远的作业，结果非但没有减轻压力，反而疲于面对变化，甚至有几次不得不把提前完成的任务推倒重来。后来偶然看到了<a href="https://mp.weixin.qq.com/s/uFgyMgCBuuxXRNAmxfkvLw">果壳的文章</a>，感觉被戳到了痛处。因为知道作业是有确切答案的，才会这么积极去做，真正需要思考的事情反而不会想提前做完，像脑容量很小一样，慢慢就努力改掉了。</p>
<blockquote>
<p>高中积累作文素材时记过一句话，叔本华说：“人生实如钟摆，在痛苦与倦怠中徘徊”，应该从来没有真正在作文里用到过。但现在看好像挺有道理，至少对我是很贴切的，有作业的时候我会非常焦虑，完全不会考虑ddl，甚至是在作业还没发布的时候，我就是必须马上把它做出来，这里的痛苦是不少的。但是做完之后，我实在想不到我还能做什么。很多人对我说我这种性格应该去读PhD，我知道自己读不了，这种劲头仅限于有确定结果的事，也就是广义的做题，我害怕探索，不能接受失败。</p>
<p>——《<a href="https://mashplant.github.io/2022-spring-summary/">研一下总结</a>》</p>
</blockquote>
<p>然而本科学习数学，确实还是做题为主。我后来焦虑的点就转移了，变成怎么能通过我这四年（五年？）擅长做题（实际上也不很擅长）这件事推出以后能够胜任研究。我和
Bowen L
前段时间有很多次交流，有一次也谈到这个，他开玩笑说来读纯数吧，博士毕业都不硬性要求能发出来论文，导师觉得你有独立做研究的能力的话，就可以毕业了。<del>说实话差点心动了。</del>单纯用身边统计学的话的确大家从做题到研究的转换也没有什么大的困难，但我总是不知道自己能不能面对失败，或许该尽早去试试。</p>
<p>另外，从高中开始，我总是希望通过复现他人的选择，来努力过好自己的人生。强基的时候我想利益最大化，研究和打听了学校里上一届几乎所有人的情况，也没有匹配到和自己相似的（=
=），最后也没有成功，于是把自己的失败也总结成了一个样本来告诫后人。现在也是一样，在恐惧的时候总是试图看看某几个前辈是怎么做的，来劝慰自己暂时不做额外的尝试也没有关系，好好读书。只是想起从前复现的失败，心里还是会持反对意见，复现是不可靠的，一定要自己去尝试，走不一样的路。就像
MashPlant 说他在复现
n+e，到底还是因为害怕失败，不敢去走前人没有尝试过确定可以成功的路，但我心里知道自己如果这样做，一定会失败的，可能是因为自己能力不足，但我更相信生活没有复现一说。</p>
<p>人际关系嘛，更是很像了（。MashPlant
的文字读起来最大的感受就是孤寂。</p>
<blockquote>
<p>近期n+e写了他的<a href="https://trinkle23897.github.io/posts/cmu-2nd-year-part1">研二上学期</a>，全都是connection，与此完全相反，我的主题是“我将孤单度过一生”。我没学到他的精髓，甚至可能是学到了糟粕。这也没什么，他能力比我强，理应拥有更远大的未来。读的时候我就有感觉，数据也确实证实了，他的约八千字中有93个“我”，我的约一万字中有337个“我”，这还是我反复精简，删去很多主语之后的结果。我的文章，我的世界，唯一的核心永远只能是我自己。</p>
<p>——《<a href="https://mashplant.github.io/2021-fall-summary/">研一上总结</a>》</p>
</blockquote>
<p>但是确实，往好处想，至少始终忠于自己。</p>
<p>至少写到这里我还是发现，心态到底比从前好了很多。当然我不可能始终留在从前，一定会往前走。</p></li>
<li><p>一大早数值分析出成绩了，很怪。我知道这个消息还是因为早上醒来，看到课程群里有人要求复核成绩。我是不需要复查，但我很好奇这课怎么评定谁是
A 谁是 A+，每个人的表现似乎都一样，难道真的是看总评有没有拿到 98
分及以上吗，那真有点无聊了（</p></li>
<li><p>今天的怎么这么长（</p>
<p>祝大家新年快乐！ qwq</p></li>
</ul>
<h1 id="月22日">1月22日</h1>
<ul>
<li><p>按家里的习惯年初一要吃素，<del>还好可乐也算素食，</del>感觉几乎没听说过别人家也有这样的习俗。据说是鲁东南和港台、广东部分地区都这样，你鲁省为什么会和南方有一样的习惯（</p></li>
<li><p>今天发现个离谱的事情，成绩单上必修的工科概率论显示为被初概替代了，但是初概在期中之前就被我
PF
了，应该不能替代才对，而且我也没交过替代申请表。问了一下才知道，那门工科概率论开课容量太少，所以院系里很多人都去上了初概来替代掉自己的必修；需要办课程替代的人太多，教务直接和开课的工工系对接，给所有修了这门课的人统一办了替代，不需要交申请；上学期碰巧可以给必修记
PF，阴差阳错地就把我的也标记成已修了（</p>
<p>我是想用概率论（1）替代的来着啊（恼，不过问题也不大，必限绩点对我来说没有意义。</p></li>
<li><p>想着每天浪费时间都不知道浪费在什么上了，<del>还不如冤有头债有主</del>，于是把明日方舟下载回来玩了一下，打算试试
nano 的长草期插件。不过玩了一会就明白当初为什么退坑了（</p></li>
</ul>
<h1 id="月23日">1月23日</h1>
<p>好像也没什么可写的（</p>
<p>普通地读一千零一页，普通地做课后题但是没有答案，时不时怀疑自己伪证，要么就是最后一问不会做然后疯狂
Google / Math
StackExchange（。期间还时不时切换到模拟器的界面去玩一下方舟，我完全理解什么叫凉性循环了。虽然年初二在读一千零一页这件事听起来很卷（，但是一直以来过年的状态都和正常的日子没什么区别，就是普通的寒假嘛。</p>
<p>而且感觉读不完了，下学期要寄（</p>
<h1 id="月24日">1月24日</h1>
<p>今天好像也没发生什么有意思的事情（，修了半天博客的 LaTeX，发现不是
NexT
的问题，松了一口气。过程在数分日志里简单写了一下，最后也没搬家到新版
NexT
但是已经把新家装修好了，万一哪天旧房子真的塌掉了的话可以一键搬家（？？</p>
<p>相比之下感觉还是数分比较简单。</p>
<p><img src="https://s2.loli.net/2023/01/25/1FkScU8xRrQbZzD.png"></p>
<p>回坑之后第一次打新主题肉鸽，一遍通关，还是有点运气的。但一遍通关的代价是没想到会花
40 分钟，接近三点才睡。舟已经不太能吸引我了，不玩了（</p>
<p>平凡即是喜乐，还挺符合今天的心情（，旧版 NexT 没出问题的每一天也都是
precious daily（（</p>
<h1 id="月25日">1月25日</h1>
<p>推推数分，感觉那一篇已经根本不能叫速通了（悲</p>
<h1 id="月30日">1月30日</h1>
<p>我怎么感觉这一篇要烂尾（或者说已经烂尾了），在家摸数分实在没有什么可写的。</p>
<p>昨晚和转数环里一个正在申请的学长聊了会天，<del>备受打击，</del>被锐评上课上得太慢了，<del>申纯数基本没希望（但我也没这个打算啊
kora）</del>，这也没办法。总之有点怀疑之前的估计恐怕是太乐观了些，延毕也成大概率的事情了，毕竟我根本没有先读个硕这个选项，在华子多读一年书单从花费上来看就便宜一万倍（倒也没有一万倍那么多（。不要花多少钱的硕又有点看不上（？），要花钱的又读不了/申不到，有申交换的时候那感觉了——把配不上我（？）的项目删掉，再把我不配的删掉，然后就啥也不剩了。</p>
<p>草，说到交换的事情，想起来之前在同学的年终总结里看到一句话：</p>
<blockquote>
<p>按照院系的标准，我似乎总是离一流差一点。</p>
<p>但我好像从来没明白是差在哪里。</p>
</blockquote>
<p>那我就不一样了，在院系的标准里我根本就不入流。或许他们是对的，我也不知道。</p>
<p>我现在真在考虑退复分析然后去选 hlb
了，或者至少蹲一下能不能有机会选上另一个实分析的老师。之前想的是如果压力太大的话，大不了退掉
statistical learning 换 bayesian
statistics，对我来说理论课总归比码课轻松很多。然而我现在只觉得悲观，大概早点学些应用也没什么不好的。</p>
<h1 id="月31日">1月31日</h1>
<p>写完昨天这些事之后觉得好烦。今天老姐来上海了，带她去天文馆玩了一下午。</p>
<p>选天文馆也没什么特殊的意义，大概就听说是前两年新建的，还没有去过，以及它算是东南方向上地铁能够到达的最远的地方，我家在北面。</p>
<p><img src="https://s2.loli.net/2023/01/30/XsEcUuAdkeYpgq4.jpg" alt="IMG__131626.jpg"></p>
<p><img src="https://s2.loli.net/2023/01/30/KYgTIoOhuALf4bv.jpg" alt="IMG__132222.jpg"></p>
<p>装置很炫酷，然而我物理太拉胯了，老姐读的文科，最后就变成了一起惊叹“好大！”“好漂亮！”“好闪！”，和来玩的小朋友没有区别。试了几个印纪念卡的机器，基本都是坏的，或者可能没墨/没纸了，总之就成功印出来两张，正面是天文馆的照片，背面印了（一些并不认识的）物理学家的生平。总之感觉其实比较适合中学生来玩，果然已经是过期
jk 了（</p>
<p>离滴水湖挺近的，出来之后租了个双人脚踏车绕着湖转了一圈，虽然天气不算好。或许是这边离海不远了，水汽多的原因吗，今天明明很热，坐地铁来的路上看市区也比较晴朗的样子。</p>
<p><img src="https://s2.loli.net/2023/01/31/vpELSIcnHk4uXj2.jpg" alt="A5643A51606C6E23814387DF9E626213.jpg"></p>
<p>找到一个前年暑假在这边车站拍到的广告，上面新兰下面柯哀，官方是懂端水的。</p>
<p><img src="https://s2.loli.net/2023/01/31/jSZLeKx4QD8GTAs.jpg" alt="BA40109B6E49A2EFC20A150474084925.jpg"></p>
<p>楼上往家里漏水，把天花板的墙皮泡起来了。上去问了一下他家房主在外地，还有个二房东在本地，租客今晚才从老家回来。要了二房东的联系方式，好像不是很愿意赔也不太想修，在嗯拖延，总感觉这个情况会很复杂，说不定还要找物业或者明天上楼吵架，麻了（</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇二·22年10月</title>
    <url>/2022/10/01/Diary-2022-10/</url>
    <content><![CDATA[<p>不知道能坚持写多久呢？</p>
<span id="more"></span>
<h1 id="月1日">10月1日</h1>
<ul>
<li><p>深切感受到了听力的衰退，七八年前在放学回家的公交车上听一格音量的耳机也能屏蔽噪音，现在要两格；昨天在抽代课上有个旁听的同学小声叫住我，问我要微信想要点课程资料，说了两遍我都没听清楚，凑近一点才听清楚他在说啥，感觉很抱歉。</p>
<p>说起来那趟摇摇晃晃的宝山 8
路，已经是七八年前的事了吗，我还记得很多细节。当时家住宝山这个小破郊区的边缘小镇，小破初中在宝山所谓的核心位置，其实说是核心也远不如城区繁华，只是靠近码头，发展得早一些。每天放学从友谊路挤上车，在牡丹江路上一路堵车，开到市三医院（现在叫市九北院了）门口才好一些。如果到了绕城高速上还堵，那这十公里恐怕就不是一个小时能走完的了。</p>
<p>还记得遇到过几次意外的堵车，我还在绕城高速下过车，去旁边的铁力路站乘地铁去学校，那是
3
号线唯一一个地下站，据说是旁边的宝钢不让站台建在地上，出钱改到地下去的。现在已经记不清楚怎么从高速的一侧去往另一侧的地铁口了，想想当时为了上学还挺勇的，放在高中的话我就请个假打道回府了（什么啊</p>
<p>人生会有几个七八年呢？（#每日悲观</p></li>
<li><p>室友：你为啥要和刚高考完的小朋友卷离散啊？卷得过吗？</p>
<p>我：我超，对啊，为什么呢（</p>
<p>不过暑假上逻辑课之前大致看了一点离散（1）的内容，想来补完（x）一下；另外貌似会有图论，这玩意在我有关数竞的印象里非常恐怖，来看看.jpg</p></li>
<li><p>看了一天初概，很破防，这课用英文讲不好吗（暴论）。连续型联合概率密度（Joint
PDF）还叫做联合密度，联合概率，明明直接拆成 Joint 和 PDF
就知道是什么了；Joint PMF，CDF 同理，Marginal
同理。什么边缘密度，边缘分布，离散型
blahblah，甚至作业题题干上老师还把联合密度写成了联合分布，白浪费了很久和同学研究这是什么意思，中文太难了（</p></li>
<li><blockquote>
<p>John Von Neumann once said to Felix Smith, "Young man, in mathematics
you don't understand things. You just get used to them." This was a
response to Smith's fear about the method of characteristics.</p>
</blockquote>
<p>破防了，记之（</p></li>
</ul>
<h1 id="月2日">10月2日</h1>
<ul>
<li><p>给同学讲题目，题面反正就是这张图，然后求这个种群灭亡的概率（</p>
<p>感觉画得很好玩就放上来了。</p>
<p><img src="https://s2.loli.net/2022/10/02/2v68M9GKQmZ1UDH.jpg" alt="D0865D0B17B0ADE1113068911DD85746.jpg"></p></li>
<li><p>开学第三周就破防了，睡前喝了两大杯热豆浆。加蜂蜜还是没有直接加白砂糖甜，但是感觉健康一点（？</p>
<p>这工程力学开始看不懂了，虽然必修但考虑中期给它退了，太闹心了。</p></li>
</ul>
<h1 id="月3日">10月3日</h1>
<ul>
<li><p>梦到课咨委例会，我敲门进去发现里面的人都不认识，然后问了一句：</p>
<p>“这里是告白实行委员会吗？”</p>
<p>不是很懂你们这些二刺猿.jpg</p>
<p>还梦到抽代期中一道题也不会做，何尝不是一种未卜先知（</p></li>
<li><p>来到百京的第二年，还是学不会降温的时候怎么穿衣服。</p>
<p>傍晚友人约了恰饭（其实是大倒苦水，大家过得都好惨），急着出门的时候实在不知道穿什么，扯了一件粉衬衫一件浅绿的风衣出来，草。还好颜色都偏浅，其实也没有难看，友人评价是像一颗草莓（</p></li>
<li><p>到半路拍了张照片，其实拍的不是特别好，<del>也不是很庵野，毕竟电线杆太远了</del>。</p>
<p><img src="https://s2.loli.net/2022/10/03/xmHcun6CVGjgtKv.jpg"></p>
<p>学校东门对面的那个地方（叫东升乡八家村）真的挺庵野风的，有电线杆有护栏有<del>电车</del>地铁有路灯，高楼大厦之间一小片低矮的村庄。今天的天空也很有层次感，是我没抓住机会好好找个位置拍，残念。</p>
<p>其实如果能再晚一点，在有地铁经过的时候骑车拍一段运动的录像就更好了，但是试过一次会非常抖，远远超过手持拍摄的那种抖动感。考虑买个手机支架（？？</p>
<blockquote>
<p>黄昏是我一天中视力最差的时候，一眼望去满街都是美女，高楼和街道也变幻了通常的形状，像在电影里。你就站在楼梯的拐角，带着某种清香的味道，有点湿乎乎的，奇怪的气息。擦身而过的时候才知道你在哭，事情就在那时候发生了。</p>
<p>——《恋爱的犀牛》</p>
</blockquote>
<p>据说这话原来是陈建斌说的，廖一梅（还是孟京辉？）曾经和陈建斌是同学，改了一下放到了剧本里。一到这种时候我就很想圣经吟唱（</p></li>
</ul>
<h1 id="月4日">10月4日</h1>
<ul>
<li><p>看抽代看到凌晨，感觉每个地方对于置换群、对称群、对换群这三个概念的描述都不一样，真的很破防。我个人倾向于
Undergraduate Algebra 的解释，把对称群认为是作用在 <span class="math inline">\(\lbrace 1,2,...,n \rbrace\)</span>
上的置换的总集，把置换群认为是对称群的子群，比如说 <span class="math inline">\(A_n\)</span>
也是一个置换群。然后对换群是比较广义的可以对于任意集合上的一一对应的一个说法。hx
给的解释是混淆置换群和对称群这个行为本身是为了避免混淆（？？），我迷茫了。</p>
<p>怀疑 hx 的进度现在已经是 zmx 的 1.5 倍了，<del>难怪作业也是 1.5
倍</del>，已经 Sylow 了。很难想象这课不自学 or 预习的话怎么上。</p>
<p>然后发现助教会在习题解答里面塞 bonus
题，我趣，好阴啊（不是），我一直都不看解答的来着。</p></li>
<li><p>破防
2.0：为什么要热衷于给每一个概念取名字，就按照符号叫不好吗（暴论</p></li>
<li><p>破防
3.0：我院另一个上抽代的人要退课跑路了，最开始还是她把我骗过来的，乐。</p></li>
<li><p>破防
4.0：听说好几个隔壁的高中同学都降转成功/目前有降转打算了，呜呜，我也想降转（暴论</p>
<p>多读一年的话恐怕基础会好很多吧，不像现在一样畏畏缩缩，sigh。</p>
<p>所以要不延毕吧（恶魔低语</p></li>
<li><p>今晚课咨委和科协会议撞了，选了课咨委，20
分钟搞定，听说科协开了一个钟头，<del>太棒了</del>。</p></li>
</ul>
<h1 id="月5日">10月5日</h1>
<ul>
<li><p>睡前破防了，点开空间发现宗桑也在破防，万恶之源：</p>
<p><img src="https://s2.loli.net/2022/10/05/jewmQWNodMJaZqy.jpg" alt="Screenshot_20221005_014725.jpg"></p>
<p>礼貌问候和开端：</p>
<p><img src="https://s2.loli.net/2022/10/05/89tAVilqfhw1WOL.jpg" alt="Collage_20221005_190452.jpg"></p>
<p>对抗训练：</p>
<p><img src="https://s2.loli.net/2022/10/05/xkXEDw5dPq64r8o.jpg" alt="Collage_20221005_190433.jpg"></p>
<p>太艺术了，改天打印出来贴床头。笑了半个小时，快乐地睡着了。让我们说，谢谢宗桑！（</p></li>
<li><p>何老板找我问统辅的问题，我才知道他想转
quant，蛮意外的，以前以为他想去类似于经管那种不太技术的方向发展。胡言乱语了几句，其实就是提供了一下我知道的金融统计和金融数学的课和老师，quant
关于码的方面属实不是很了解，就不乱说了。</p>
<p>然后他问我什么打算，我说我嘛，应该就是应数了，stat，bio-stat
都有可能。（注：生统和生物没啥关系，在会考之前我高中生物就垫底过 114514
回</p></li>
</ul>
<h1 id="月6日">10月6日</h1>
<ul>
<li><p>睡觉就是短暂地从世界上死掉。</p></li>
<li><p>佛了，复习个初概期中搞的鸡飞狗跳，这样的话真到期中了的话怎么办，到期末了又该怎么办。</p>
<p>感觉更多的是心态问题，有一种《这个东西最好是一直复习下去》的感觉就会搁置很多别的事情...</p></li>
<li><p>看了一个 runzhi 给的抽代题，收获一张 runzhi 梗图：</p>
<p><img src="https://s2.loli.net/2022/10/06/yZvUVzrwqYKpfsC.jpg" alt="9222EC13EB1374906BFBEDBDDC01D74A.jpg"></p>
<p>最喜欢的一集.jpg</p>
<p>他问我为什么不跟着茶园上抽代，理应平均水平比数学系低一点，还好卷一些吧？我超，为什么呢。</p>
<p>不过茶园的数学水平和数学系相比，我还真不是很清楚，知道的数据就只有大一上微积分期中，茶园平均好像没到
85，我好像 95 = =，所以感觉也不算很好？反过来如果让数学系考微 A
的话会咋样呢。</p>
<p>罢了罢了，来都来了 XD。</p></li>
<li><p>功成不必在我，我在必不成功。</p></li>
<li><p>和 jdc 说了几句话，因为求真割据，现在数学系只有一个班 30
个人，转入比例不能超过 15% 的话，今年只有 4
个名额。现在有一个茶园人一个贵系人加入竞争，还有两位准备降转已经上了很多专业课的同学，这样就已经满了...实际上开放给物理系的互转名额每年都是浪费掉的，外面的又转不进来。</p>
<p>大家都不容易啊。</p></li>
</ul>
<h1 id="月7日">10月7日</h1>
<ul>
<li><p>和室友聊天，发现一屋子人里就我没学过小学奥数 = =</p>
<p>拥有一个快乐的、无所事事的童年也不错
XD，虽然代价是高中竞赛的时候猛造各种轮子，尤其体现在概率计数里（</p></li>
<li><p>初概期中考完了，明明小分值的难题都做得挺好，结果我飘了看错一个水题，当成无放回抽样了，三小问全寄掉，感觉很危。</p>
<p>从竞赛做一试的时候就知道不能做快了，会寄，怎么总是记不住呢。sigh</p>
<p>据说这课 50% 优秀率，所以如果出分之后在平均分上那就不记
PF，不在的话就记了算了，之后再去摸一个概随。下学期还要上数学系的概率论
(1)，真就全都来一遍啊w</p></li>
<li><p>然后发现没进综奖奖学金答辩，想了想确实是因为实践和志愿为零，虽然社工和学习拉的比较高，有自我感觉良好的嫌疑。麻烦给两个单项吧，真的缺钱（</p>
<p>没做志愿是因为一直打算去答疑坊蹭工时，但又一直没去（x），实践的话单纯是不喜欢和一群不熟的人旅游，所以没参加过，罢了罢了。看了一圈认识的几个神也没进，又不破防了（？</p></li>
<li><p>怎么全是坏消息啊！</p>
<p>感觉最近是一个慢慢意识到自己也没有想象中那么厉害的状态，蛮消沉的。属于是难的不会，简单的又糊，中间的倒是会，又有啥用呢
XD。</p>
<p>于是晚上翘了一二九分声部的环节，叫上何老板去玉树吃了夜宵。没吃晚饭，然后夜宵一份烤冷面半份馄饨下肚感觉整个人都好起来了，食物治愈一切。辅导员也没来找我的茬，总感觉他早就放弃在类似的事情上说教我了，蛮好的x</p></li>
</ul>
<h1 id="月8日">10月8日</h1>
<ul>
<li><p>开始赶一些落下的作业，尤其是抽代的 34 道题（</p></li>
<li><p>张京华怎么塌房了...前段时间学 One Last Kiss
的时候才刷到过他的直播切片（</p>
<p>很遗憾用这样的方式这么快又看到你一次.jpg</p></li>
</ul>
<h1 id="月9日">10月9日</h1>
<ul>
<li><p>仍然在赶作业，别的啥也没干，甚至又通宵了（</p>
<p>不过顺便在 Math StackExchange
看了一些问题，学到许多；以及写完了之前的 Bonus 题，Wilson
定理什么的梦回高中竞赛，然后我查了一下这玩意怎么证，弹出来的第一条结果居然是
OI Wiki（</p>
<ul>
<li>数竞正统在 OI！（</li>
</ul>
<p>其实写完作业我也理解 hx 为什么从 Sylow 子群开始就加速冲了，从 Sylow
开始到有限生成 Abel
群（以及可解群）之间都是一个很连贯的逻辑，但是您有没有考虑过，就是没必要把所有课后题都布置成作业呢（</p>
<p>我现在看到抽代就想吐，预习什么的还是留给睡一觉起来之后吧。</p></li>
<li><p>目标是到周一晚上写完工程力学，抽代，离散和初概作业，然后抽代看到有限生成
Abel 群。感觉很难。</p>
<p>然后周二下午要 check
一下数值分析的进度，据说这周会有一个上机实验，但是要用
MATLAB，我还不是很会。可恶啊可恶，为什么不能用 Python（</p></li>
</ul>
<h1 id="月10日">10月10日</h1>
<ul>
<li><p>你院综奖答辩前后怎么这么多瓜...听室友讲了两个，自己到处瞎看浪费时间的时候又不慎发现一个。</p>
<p>其一大约是一个学年满绩的同学（其实他在 b
站有一个更为人熟知的称呼）没进综奖答辩发了一些牢骚，后来和好几个（？）辅导员闹起来了。我原以为他的重点在于质疑入围标准不够公开透明（不过标准是否应该公开透明又是另一个值得讨论的问题，在此略过），但实际不是；还有一个是听说有人出钱灌了篇环材类的
SCI 然后拿出来吹什么的，盛名之下其实难副。</p>
<p>有点意思。虽然一些了解到的信息让我觉得的确该骂，但到底还是有可取之处。我向来缺乏始终保持严谨的能力，上学期
PF
了两门不擅长的专业课都没满绩，这学期刚开头初概就大翻车；又连开始了解一个课题该如何完成的勇气都尚且不足，空诩兴趣和热情有什么用呢。</p></li>
<li><p>常怀谦卑之心。</p></li>
<li><p>上周五 129 分声部咕咕了，今天辅导员才来找我，弧是否有些长。</p>
<p>说是让我晚上去跟着行健重新分，我才不去呢。所以我有点笨比了，当天晚上虽然跑路了，但事后直接微信编个分数发给他不就好了嘛。现在想到倒也不算晚，至少少跑一趟蒙科楼。</p>
<p>室友说她 233 但是没选上，据说这三个数字是音高音准音色，满分是
5。想了想 111 不太符合美少女（？？）的形象，那就 212 吧。</p></li>
<li><p>昨天列的 to-do list
基本是搞定了，真不容易，但抽代只看了个大概。不管了，睡觉。</p></li>
</ul>
<h1 id="月11日">10月11日</h1>
<ul>
<li><p>约了 dwl 老师下周三的
OOH，没想到这个东西真的没人约啊。点完预约之后又开始纠结，系统会不会给老师发通知说有学生约了
OOH 呢？我要不要再给她发个邮件说一声...</p>
<p>我想说的一些东西：</p>
<ul>
<li>为初概翻车诚恳致歉并寻求一些建议（</li>
<li>问问她对读研半路出家转数的一些想法，可行性分析（？），包括方向选择（数据科学？计算数学？统计？生统？</li>
<li>求求她带我进组 or 推荐一些相关的组 or 做做
SRT，我需要尝试一下知道自己能否有能力和兴趣做研究</li>
<li>关于数学系那边选哪些课（实复概全覆盖？点集拓扑泛函分析等偏向基础数学的内容？回头补数分？？）来辅助统计学习这件事，以及我的现状（感觉抽代比初概好玩得多这正常吗）</li>
</ul>
<p>希望不要临场丧失语言功能，另外伟清楼在哪里啊（</p></li>
<li><p>数值分析上机题允许 Python
了，然后看了一眼还是没啥思路（乐死），这好像是我的问题（</p>
<p>总比从头学 MATLAB 好，总比从头学 MATLAB 好</p></li>
<li><p>老姐给我发了篇<a href="https://mp.weixin.qq.com/s/YUz57MwQW-tpKUNTWPzrKg">文章</a>，我还以为标题党，点进去一看还蛮喜欢的，遂摘录。</p>
<blockquote>
<p><strong>S：</strong>人总是会喜欢自己擅长的东西，我也不例外。那些在小学阶段能很快掌握鸡兔同笼，牛吃草问题和抽屉原理的小孩很容易对自己的智商感到自信。说实在的，自信是一个中国小孩能得到的最好祝福，尤其是在我们这片不会歧视书呆子的文化土壤上，你学好奥数的那几年会在同龄人中活得风生水起——你由此能从一众每天买干脆面开水浒卡的小学生中脱颖而出，进入一个好的中学，学会圆锥曲线和三角函数，由此能从一众每天去网吧抽中南海的中学生中脱颖而出，进入一个好的大学，学会拉格朗日中值定理和多重积分……</p>
<p><strong>B：</strong>等等，这一切的终点在哪儿？</p>
<p><strong>S：</strong>一个祝福，也是一个诅咒。</p>
<p><strong>B：</strong>那是？</p>
<p><strong>S：</strong>去华尔街当操盘手。</p>
<p><strong>B：</strong>我不明白。</p>
<p>......</p>
<p><strong>S：</strong>（打断）我的一个同学炒币挣了200万；另一个同学在私募基金工作，已经快要拿到美国绿卡；还有一个同学去了高盛……</p>
<p><strong>B：</strong>呵，这就是精英的圈子吗？</p>
<p><strong>S：</strong>我知道你会生起一些朴素的嫉妒心，但就像我说的，他们是自信的数学天才，已经习惯了成功。</p>
<p><strong>B：</strong>我现在明白你刚才那句话的意思了。</p>
<p><strong>S：</strong>哪句话？</p>
<p><strong>B：</strong>一个祝福，也是一个诅咒。从鸡兔同笼走向在华尔街功成名就之路，你被这种幻觉困住了。</p>
<p><strong>S：</strong>甚至更早，珠脑速算。</p>
<p>......</p>
<p><strong>S：</strong>你像是在面试我。</p>
<p><strong>B：</strong>并不是，说出你真实的看法就好。</p>
<p><strong>S：</strong>我真实的看法（停顿）…就是没什么看法。这就是现在我对大多数事情的看法，对，没什么看法。怎么看爆款？没什么看法。怎么看朝鲜？没什么看法。怎么看北京？没什么看法。怎么看大海？没什……哦，大海还不错。</p>
<p><strong>B：</strong>（痛心）你这样找起选题来会很困难的。</p>
<p>......</p>
<p><strong>S：</strong>（打断）你还要说，派对上人与人的联结让你很感动。他们托举着彼此翻墙进入现场，总是会有陌生人问你是不是需要水，喝醉了会有人搀扶着你别摔下天台……这些我都看到了。</p>
</blockquote></li>
</ul>
<h1 id="月12日">10月12日</h1>
<ul>
<li>今天又双叒叕做实验，
顺利苟过去了，很感谢暑假开头时候写了实验备忘录的我自己。</li>
<li>玉树的烤冷面不知怎的感觉不如上周好吃了，可能是太干了。下次试试馄饨。</li>
</ul>
<h1 id="月13日">10月13日</h1>
<ul>
<li><p>躺床上听早八最多坚持半个小时...数值分析老师对不起，但是被窝真的太舒服了（</p></li>
<li><p>然后就又还是肝一天，今天的 TODO 是写完 ODE
作业，抽代看完群论（太可怕了）然后修茴香豆，写前半周的抽代作业，可以的话工程力学作业也写了，实在没事干了就去搞本理力来补一下我看不懂的工程力学。</p></li>
<li><p>SRT 看了半天，要么一看就好水，要么就是贵系立的项（</p>
<p>丘数学中心就一个项目，统计中心没项目。梁鑫老师那个项目说是会线代和群论就行，<del>那岂不是我上我也行</del>。报了一下试试，邮件约了周六去唠嗑。资金
500 块，是要拿来买演算纸和笔吗（</p>
<p>和 lzy
聊了一下，他已经去过梁鑫老师那边了，大意就是这是个搞矩阵论的课题，属于比较冷门的方向，和未来方向不搭的话不建议去。</p>
<ul>
<li>可是我还能有啥选择呢？去吧。</li>
</ul></li>
</ul>
<h1 id="月14日">10月14日</h1>
<ul>
<li><p>随口问了一句何老板有没有看中的
SRT，结果他想进的那个项目的立项人是我高中的一个学姐...这下内推了（bushi</p>
<p>世界真小，让人喘不开气。</p></li>
<li><p>hx 今天终于在讲完有限生成 Abel
群之后停下来讲了点低阶群结构，没继续冲可解群（</p>
<p>Anyway，不影响他下周肯定能讲完群论。</p></li>
<li><p>今天要稍微研究一下数学中心那个矩阵论 SRT 的内容：</p>
<blockquote>
<p>双随机矩阵与置换矩阵群凸包的谱集探索</p>
<p>双随机矩阵是一类特殊矩阵，它的所有元素都是非负实数且每行每列元素之和都是1。这类矩阵在图论、概率论、矩阵论中都有广泛应用。确定一个复数是否可以作为某个矩阵的特征值，是特征值反问题研究的基础。例如，经典结果告诉我们，所有实对称矩阵的特征值的并集就是实数集，我们称之为实对称矩阵集的谱集是实数集；根据Schur-Horn定理就可以解出实对称矩阵的特征值反问题。类似地，为解决双随机矩阵的特征值反问题，首先就要考虑双随机矩阵集的谱集。1965年，Perfect和Mirsky提出猜想：n阶双随机矩阵集的谱集是所有内接于单位圆且一顶点位于实数1的正k
(k&lt;=n)边形的并集。后人称之为Perfect-Mirsky猜想。当时二人就已证明该猜想在n=2,3的情形。n=4的情形在2015年被Levick、Pereira和Kribs证明。n=5的情形在2007年被
Mashreghi和Rivard通过反例否定。其他情形至今仍无确定结论。Harlev、Johnson和Lim在2020年通过一系列数值实验侧面证实n=6,7,8,9,10,11应当是正确的。</p>
<p>根据Birkhoff定理，所有双随机矩阵组成的集合就是所有同阶置换矩阵的凸包。因此双随机矩阵集的谱集就是对称群的凸包的谱集。2020年Jankowski、Johnson和Lim试图通过探索不同的置换矩阵组成的群的凸包的谱集来逐渐逼近Perfect-Mirsky猜想，他们考察了交换群、二面体群和四元数群。这些群都是比较简单的群，其结果与Perfect-Mirsky猜想相吻合。</p>
<p>本项目试图沿着这一道路继续探索，利用矩阵分析、有限群论、群表示论等领域知识，逐步考察更复杂一些的群，例如两个或多个循环群的半直积、由两个或多个轮换复合出的置换生成的群等来进一步靠近Perfect-Mirsky猜想。</p>
</blockquote>
<p>看着好高深！（但是老师说群都不必学得多好就能做（在画饼</p>
<p>TODO：</p>
<ul>
<li>了解一下双随机矩阵和谱集的结论</li>
<li>Perfect-Mirsky 猜想，Levick、Pereira 和 Kribs 的证明，Mashreghi 和
Rivard 的反例</li>
<li>Jankowski、Johnson 和 Lim 对于交换群、二面体群和四元数群的考察</li>
</ul></li>
<li><p>搜了一圈感觉这个猜想下面就没几篇文章，全都列在这儿了，难怪说冷门（</p>
<p>一开始没大明白什么叫复数集是一个什么 n 边形覆盖而成的凸包，看了
Pereira（上文那位证明了 n=4 情形的教授）的<a href="https://media.ed.ac.uk/media/Rajesh+Pereira+Eigenvalues+of+n+by+n+doubly+stochastic+matrices+and+the+Perfect-Mirsky+conjecture/1_lgq1j7r6">讲座</a>才明白这个猜想是在说啥。呃，然后讲着讲着就量子物理了，怎么会事呢，不看了（</p></li>
<li><p>睡前读了谢惠连的《雪赋》。</p>
<blockquote>
<p>未若兹雪，因时兴灭。</p>
</blockquote></li>
</ul>
<h1 id="月15日">10月15日</h1>
<ul>
<li><p>原来近春园西楼不是指理科楼啊...还以为要回到伤心地（x）了。19
年金秋营的时候于品说物理系要搬到更好的地方去了，将来整个理科楼都是数学系的，到现在新物理馆好像也还没造好，xs。</p>
<p>聊之前我还想着就算做不出东西来试试也好，结果老师劝我三学位课本来就多，还是珍惜时间打好基础为妙（</p>
<p>很对，很对，跑路了。</p></li>
<li><p>其他就没啥事了，今天要写完初概作业，然后复习数值分析第一章的内容，写上机作业。但愿能写出来（</p>
<ul>
<li>写出来了，开心，虽然中间破防了 114514 次（</li>
<li>你猜我为什么不想转码了.jpg</li>
</ul></li>
<li><p>头一回见到 ddl 延长（</p>
<p><img src="https://s2.loli.net/2022/10/15/7E8pUoiJnhMB5us.png" alt="ZUWJ5_LUWG2_1_G_6CM9_MO.png"></p></li>
</ul>
<h1 id="月16日">10月16日</h1>
<ul>
<li><p>今天就更没啥事了，继续把数值分析复习完呗，没事干了就预习抽代/看理力。写写数值分析的证明，虽然不知道这课最后考试有多看重证明，反正平时的纸笔作业又少又水，完全没有四学分的感觉。</p></li>
<li><p>整理了一下昨天数值实验的内容，打算水一篇长期的博客，但是要等作业
ddl
过了再发，不然万一被判协助抄袭，徒惹是非。还蛮有趣的，我是说如果这样轻量级地使用编程语言，debug
的痛苦还并不大于快乐。</p>
<p>我越发觉得自己还是应该转数，并且意识到自己的 coding
能力在数学人里面还算可以，比较乐。</p></li>
<li><p>暑假写的 Sharygin Geometry Olympic
题解终于成文了，指导老师还是写上了杨丕业老师，虽然他这次也没指导什么（x）。</p>
<p>和他聊了一会，才知道他现在已经不在质心教竞赛了，而是去了长沙的一所高中教书。还记得
19
年金秋营（又是金秋营，那次金秋营确实对我意义蛮大的）考完第二天的试，我还去质心找他玩了，也帮忙完善了第二天的两个几何题解，似乎他们公众号上当时在题解里还写了“鸣谢外心姐姐”之类的话——因为质心的吉祥物是质心姐姐，于是我也随口编了个类似的名字。</p>
<p>聊到最近在学什么，才知道 hx
是差不多和他同期的华子数学系学生。末了听他感叹同是丘赛优胜，走的路却完全不一样了。</p></li>
</ul>
<h1 id="月17日">10月17日</h1>
<ul>
<li><p>今日仍然无事，早起感觉发烧了，休息了一天。</p>
<p>还好不是第八周，还好不是第八周（</p></li>
<li><p>CW：这一条是很暴躁的吐槽。（是时候去搞个折叠块的功能了（懒了，下次一定x</p>
<p>这两天有高中同学又一次来邀请我参加情系母校，今年还是非常不想去。</p>
<p>和母校并没有多少可以情系的，这似乎的确是我的问题。一个对竞赛（哪怕包括小学奥数）和高考都几乎没有了解的野鸡学校初中生在升上高中之后，先花两年多一点的时间学自以为的数学，摸了几个竞赛的破奖，又花八个月从零开始学习高考，最后摸了个相对高考生来说也还算不错的成绩，那当然是以一副做题家的姿态度过这三年的。任何“二附中人为之骄傲的高中快乐回忆”，中二一点讲就是“玫瑰色的青春”，对我来说既社恐地狱又真的是没时间。还有理科班夸张的
9:1
男女比下压抑的氛围，唯一一位关系好的女同学高二生病休学，无数竞赛和高考过程中的焦虑、自我怀疑，<del>失败的恋爱经历</del>，都无疑加重了自闭。或许也是一种好事，至少我现在自闭得挺快乐的（</p>
<p>另一方面，我实在不认为这种活动有什么意义。举个例子来说，今年课咨委有一位二附中的学弟，物理竞赛拿了金牌，却跑到未央来读机械。原因是决赛现场被华子口头签约了钱学森力学班，于是强基报了行健，结果被华子以“二类生不报致理就是违约”调剂来了未央。天知道从第一届强基开始，你校有多少被华子口头签约的人（当然也包括本人）被毁约（当初华子给我的理由是求真分走了致理数学一个班，听起来还算合理吧），我这点破事当年还人尽皆知呢。当然，我这样的的确是没什么办法，没有过硬的成绩握在手里，被毁约也没话说，谁叫我无心间勾了那个“服从调剂”，不然现在岂不是在交大电院逍遥自在？但一个金牌，因为这种信息差毁掉四年（无意表示未央在价值上不如致理，我敬佩真正热爱这个学院里的学科的同学，只是对于他个人的期望来说，的确是毁了），尤其这还是曾经在零字班出现过的惨剧，我无法理解。</p>
<p>校友二月办情系母校活动，四月又是校友导师交流会，五月随华子招生组去学校强基预面试和宣讲，六月招生干的离谱事情更多（比如今年某位学姐以假意承诺计金的伎俩，从北大信科挖了一个裸分线上分不是特别高的学生过来，最后扔进自动化。当然这是另一回事了），上下年级之间的交流不计其数，却连这种已经见多了、简单说几句话就可以避免的错误都改变不了，实在不知道在做些什么。须知在高三学生眼里，诸位是“可靠的有经验的学长学姐”乃至在招生季是“手握大权的朝廷命官”（尽管并不是）（这话并不恰当，但就那意思），但凡能负点责任呢？毁约自然是华子的不是，我已经骂不动了，但就任其发生吗？</p>
<p>我的确在想我加入的话能不能至少改变点什么，这样直接逃跑只张着嘴数落别人的不是，也还是不负责任。然而我一向人微言轻，加入了情系母校和各种宣传也就是做边角杂活（校友导师活动的时候试过一次），哪里抵得过几位核心成员鼓吹华子幸福生活的安排呢？要说尽我所能，也就是真的对几个报强基的时候找我咨询的同学，说了所有的实话而已。</p>
<p>还记得今年五月的时候在质心的公众号上看到了一位东北某校（记不清了）的同学，物理银牌却报了未央，把自己回归高考的心路投稿了出来。我托在质心认识的老师联系到了她，才知道她误以为报了未央可以任选工科专业，可以进她心仪的自动化，然而未央根本没这个专业；她的学校里不曾有过考进清华强基的前辈，本是寒门贵子，我最欣赏的类型；她更不知道这是一种华子眼里的毁约行为，在未央的分流排名也会垫底。可惜她的文章晚发了一步，我也晚来了一步，已经过了强基计划报名截止时间，今年也不再有六月确认志愿的环节。如今她在未央读生化环材之一，我拼尽全力，还是什么都没有做到。</p>
<p>我痛恨信息差，痛恨“你不知道的东西正在伤害你”，而我如今混得还行，一部分还是托趁早认识到这一点的福。尽管在努力，也还是几乎没有帮助到任何人，落得只有在这里无能狂怒，真是
loser 啊。</p></li>
</ul>
<h1 id="月18日">10月18日</h1>
<ul>
<li><p>早晨起来还是低烧，于是摆烂翘了两节早课继续睡了，这下大概彻底是好了。下午室友发烧了，昨天下午何老板说也发烧了，草。明天要是华子搞出来三管阳性的话必有我们一份功劳（</p></li>
<li><p>看北大猫协的推送在玩 EVA
梗，点进去一看是一只左眼瞎了的小猫起名叫明日香，我超，地狱笑话。</p>
<p>结尾处这张照片怎么看抱着猫猫的人都像真嗣，不知道是巧合还是特意安排的（x</p>
<p><img src="https://s2.loli.net/2022/10/18/HI9DtuzyeAQo4Rs.png" alt="PM_BTOT_4H5DFAG@_VU_1.png"></p></li>
</ul>
<h1 id="月19日">10月19日</h1>
<ul>
<li><p>今早去找 dwl 聊天，其实和 lx
聊完之后我对很多问题都大概是有数了，但这个 OOH
是早就约好的，不能鸽掉。正好统计中心这边的方向对我来说是退路一般的存在——基础数学搞不了可以搞应用，理论统计搞不了可以搞应统，总不至于饿死（</p>
<p>wljj 好像不是很会画眉毛（什么啊和她聊天就盯着这个看去了吗</p></li>
<li><p>我认为数值分析应该改名高代（3）（逃</p>
<p>第三周的时候我还在担心会不会根本讲不完，现在发现不用担心了，进度还蛮快，马上第三章又要讲完了（</p>
<p>但也不是 hx 那种快，是这课内容本身不算太多。以及 bcl
的教学水平也是我见过的老师里相当不错的，起码是这学期听得最舒服的一节课，虽然好像他是第一次上这课？选课的时候我还为没选上
hzy 而悲了很久，现在发现也不错。</p></li>
<li><p>SRT 报名一点也不顺利...退了 lx 老师的组之后打算找个水一点的 CS
项目<del>来加两学分
4.0</del>，结果分别给两个学生立项发了邮件，一个过了两天才回复说招满了，另一个到现在都没回复我，有点烦。<del>为什么学长
check 邮箱的频率还没我高啊！</del></p>
<p>于是换去工工系的一个组了，老师回的很快，过了俩小时就过审批了。感觉工工在各方面就是一种，下位替代一般的存在（...）</p>
<ul>
<li>我倒也不 care
到底是哪边，工工的话还可以靠一下统计中心的现代统计什么的，蛮好。</li>
<li>业余爱好，业余爱好（所以水平也业余x</li>
</ul></li>
</ul>
<h1 id="月20日">10月20日</h1>
<ul>
<li><p>怎么感觉要期中考试了？我超，如梦初醒（</p>
<p>接下来两周时间基本都让给抽代就行了。期中考三门（然而期末要考 8
门，很难想象到时候该怎么办），初概 PF
之后轻微摆烂并且后半期也不是很难，工程经济学第九周周末才考，有丰富的往年题，拟合一下就行。抽代反正也没有往年题，<del>zmx
均分 50 的卷子就算能拿到又有什么用呢</del>，可以去看看 PKU
的题，然后就注重把书和习题吃透。</p>
<p>大致的计划是：</p>
<ul>
<li><p>复看一下茴香豆，很担心万一忘了什么东西（</p></li>
<li><p>按章节重写当初不会做的课后题，有很多东西前后有联系，也有值得当做引理记录的</p>
<p>我的群作用仍然一片混沌，困难的课后题主要指这个</p></li>
<li><p>手推重要定理，第一遍看书的时候自己没推出来的定理例题什么的都可以再试试。不过主要是
Sylow 及以后的一些东西，可解群，直积（这个简单点），有限生成
Abel</p></li>
<li><p>复习一些助教给的有点难度的 bonus 题，以及一些 Math StackExchange
上遇到的东西</p></li>
<li><p>还有时间的话不妨看看近世 300 和 pku-lib
里的抽代题，感受一下隔壁是什么难度。虽然纯做怪题也没啥意思，考试所迫吧。</p></li>
</ul>
<p>何宝你要是打算考到环论中段的话，能不能把题出简单点.jpg</p>
<p>（为什么要叫何宝）（反正和同学平时就这么叫的）</p></li>
<li><p>于是今天的进度是，浅看了一遍正规群列和可解群（bgm
是不是可以放花譜的不可解（x）），写了作业的前半部分，然后狼狈地带着我破碎的群论知识打开了环论章节。但愿能先看完环的定义那一节，写完课后题，再回头看一看上一节里
hx 没布置的题目。有空的话把低阶有限群看了。</p>
<p>越发觉得自己很多地方学的都有问题...</p></li>
<li><p>何老板放弃了我的 Python 安利，转头用 R
写概随作业去了，某种意义来说也没问题，R
对统计方面的很多东西封装的更好。但他还在同步听机器学习的课，那为啥不善用
Python 捏。据说他还上了微积分 C
和社科线代来复习和刷绩点，呃，每一件事我都不是很能理解（算了我估计也没人理解我在干什么</p>
<p>总感觉他最近在问我很多 STFW
就能解决的问题，但是我觉得教会他怎么向搜索引擎描述问题比我自己去搜了发给他还费劲，稍微有点暴躁。想来他不知道我博客的存在，问题不大（好阴暗！x</p></li>
</ul>
<h1 id="月21日">10月21日</h1>
<blockquote>
<p>贪婪，自私，残暴，冷酷，放荡，背叛，软弱，渺小</p>
<p>贪婪，自私，残暴，冷酷，放荡，背叛，软弱，渺小</p>
<p>渺小，渺小，渺小，渺小，渺小，渺小，渺小，渺小</p>
<p>——《恋爱的犀牛》</p>
</blockquote>
<p>奖学金入账 0 元有感（x</p>
<p>虽然但是，该干嘛干嘛，我又没有错。自有能兼顾迎合你院评价体系和自我发展的神，我恐怕不行，那还是自己混好比较重要。（草但是损失四到五位数人民币还是肉疼啊！</p>
<h1 id="月22日">10月22日</h1>
<ul>
<li><p>邮箱的垃圾箱里塞满了 Bridge Base Online
的广告邮件。上次打桥牌还是去年马杯之前，最后马杯我也没上，不过你院似乎成绩还不错，打过了求真，挺意外的。</p>
<p>你院的桥牌队到现在还是只有 7
个人，凑不出两桌，始终没有训练过（或许他们有练，没在群里说，我不知道）；另外六个同学都是清华附中的，身为外人话说不到一块儿去。当然听说他们高中的桥牌队很强，我在二附中的时候从未听过有什么针对高中生的桥牌比赛，也就把学过的东西当做又一个不同于人的记忆，直接搁置掉了。于是我的水平还停留在初中，这也是初中学校留给我少数有意义的、较好的记忆之一。</p>
<p>其实也有必要复健，桥牌是一项很有趣的棋牌运动，但暂时没心情。</p></li>
<li><p>用北京健康宝拍的头像当参考生成了一张猫娘.jpg</p>
<p>更新到 About 里了，我宣布我差不多就长这样（确信（确信</p>
<p><img src="https://s2.loli.net/2022/10/22/hFxSUZe5l3dWVaE.png" alt="00007-2160745036-masterpiece,____.png"></p>
<p>然后同样的咒语拿同学（男）的照片试了一下，生成了更多比这好看的猫娘，我不理解.jpg</p>
<p>存档一下咒语和反咒（其实是在猫车老师发的咒语的基础上改的，反咒就没动），哪天闲了再玩玩（</p>
<blockquote>
<p>masterpiece, illustration, extremely detailed CG, comic style,
professional light, one girl, beautiful, white shirt with lace
collar,glasses with gray and thin frames, artistic, nekomimi, black
necklace ,small ear rings ,hair pin, long black hair, spread hair,shiny
hair, curvy hair, smile gently ,doll face ,closer interpupillary
distance,small nose, big gem brown eyes, bright eyes, necklace,
nekomimi, fringe,small pink lips,slightly flushed cheeks, classroom-like
background,</p>
</blockquote>
<blockquote>
<p>fat, lowres, bad legs, bad anatomy, text, error, extra digit, worst
quality, low quality, jpeg artifacts, blurry, forehead,</p>
</blockquote></li>
<li><p>今天 AK
了环理想那一节的习题（好多...），虽然写了一个下午，但是真挺爽的。</p>
<p>以前觉得代数题依赖灵感，<del>现在发现的确</del>，但是摸清结构的话对于矫正思路还是比较有用的。</p>
<p>然后去吃饭，在食堂遇到了上学期的高代选老师，远远看他和别人聊天，突然觉得他也是和何宝一样单纯可爱的人，总之很有数学中心青椒的气质。<del>尽管他俩上课都是
book reader</del></p>
<p>女老师的话印象比较深的是 yh，尽管我也没怎么听过她上课，但看 handout
觉得思路应该很清楚，<del>就是字有点丑</del>。但不知为何大家都说她教得不好，或许是有时会讲一些写在
Remark 里面的内容，对工科的同学来说显得有些发散了吧。感觉 yh
很酷的样子，有事发邮件写公告不看微信群之类的举措我也觉得很棒，还有一次看她穿写着类似于
Love is Love 句子的 T 恤来上课，这在华子是可以的吗（x）。</p></li>
</ul>
<h1 id="月23日">10月23日</h1>
<ul>
<li><p>写 ODE
作业写得无比暴躁，课讲得又水作业又麻烦，我还漏过几次签到，打算二阶段退课了。其实如果不是初概裂开用掉了
PF 资格，本来就是打算给 ODE 一个 PF 的...</p>
<p>往好处想，工科 ODE
不可能够用，迟早得学完整版；后期还有从零开始的统计推断，这个在统计中心上过就不打算去数学系再上了（据说数学系的统推也没啥意思，复习半个学期概率论），所以不能再像初概一样就云过去了。集中点精力吧，该抛弃就抛弃。</p></li>
<li><p>体测完之后就变成了一滩史莱姆，今天基本没干啥事，肥宅瘫倒.jpg</p>
<p>今晚发现了笛子姥爷以前画的小漫画《笛子的单恋史》，目测是实际事件改编。看得津津有味的时候突然发现没完结...已经好多年了，估计不打算继续画了。想来过去了这么多年，笛子姥爷早已组建家庭，大概也不把（现实中的）这事儿放心上了，弃坑情有可原。但是身为读者，草，好难受（</p></li>
<li><p>最后碎碎念一条：看离散的 PPT 觉得右上角那个华子计算机系的 logo
蜜汁熟悉，再仔细一看最下面有个“1958”，大约是贵系成立的年份。这个要素让我感觉更熟悉了，然后想起来，二附中也是
1958 年建校，校徽上也写了年份。四舍五入二附中 =
贵系（这个差距就像我今天体测仰卧起坐满分但 800
米恐怕也就是刚及格，于是四舍五入我 = 鲤鱼姐（</p>
<p>丢个图：（可以看出除此之外二者没有任何关系（（</p>
<p><img src="https://s2.loli.net/2022/10/23/9Chx3iDEAIqT1Gu.png" alt="N6N5_0TFY@_P9U~__5__F.png"></p>
<p>以及想明白了一个问题：我觉得转数比转码更好的一小部分原因是（最大的原因是学不会
=
=），如果让我一边上课一边磕盐一边实习，我恐怕会疯掉，至少会非常焦虑。我不清楚贵系的普通人是怎么生活的，至少我看到的神都三头六臂，白天上班晚上写作业还有空娱乐运动甚至保障睡眠，人脉也很广阔。另外转码其实就是一个相对功利的选择了，不见得走得太远。相比之下转数生活就单纯很多，沉下心来扎实基础，多看多思考，你甚至不需要（至少不必要，也不很主流）过早开始磕盐。</p>
<p>如果能认识更多的转数人就好了。书院里自然极少，只认识两位，一位已经退学重考隔壁数院去了，我很钦佩，祝他成功。另一位还不知道是否确定要转，没有详聊。尽管有转数群，我还是和他们中的绝大多数人都不熟。其实我真的很羡慕本科就可以肉身到达数学系的同学，不说别的，主要是有机会降转甚至
gap
一年的话，这个时间可以好好补一些基础，更自信些。或许现在不必多想，真需要了就赶快去补就好（</p></li>
</ul>
<h1 id="月24日">10月24日</h1>
<ul>
<li><p>体测完浑身疼，鼻子也难受，咸鱼。推抽代进度。</p>
<p>抽代复习目前还在同态那里磨蹭，我到现在才终于明白了对应定理是干什么的，原来是一个类似于反演的操作，草。之后的置换群和循环群学的时候就没什么问题，感觉可以过得快一点。然后就是群作用，一些没见过的变换和几个式子的应用是难点，周四应该可以处理掉。此后的路径稍微平缓一些，精力放在
check
重要定理的证明上即可，印象里没有非常困难的习题了，估计周日能搞完吧，吧。</p></li>
<li><p>这周还有马原的读书报告，zad 今年任务量真大，不过 2000
字好说。另外又要做实验了，稍微有点烦，实验报告 5000
字起步还得卷拓展知识，比如说弦振动报告里还得给他写点 PDE
知识装一下，劲比马原大多了。</p></li>
</ul>
<h1 id="月25日">10月25日</h1>
<ul>
<li><p>我真的很怀疑有必要把工程力学退掉，或者期中之后抽一个周末集中把它学会了，不然要寄。</p>
<p>能动系室友 4 学分的工程力学从牛顿力学讲起，我 2
学分的工程力学实质是理论力学，草。受不了。</p></li>
<li><p>最近经常会陷在思考抽代的难题里面，有的时候想得出来皆大欢喜，想不出来就又痛苦又浪费时间，甚至还想下次再抽时间继续想。何况有的时候我甚至没有答案可以去参考，感觉收获不大。唉。</p>
<p>从小开始老母亲在学习上最爱和我说的一句话是“没有答案的题目不要做，做了也不知道对不对，浪费时间”，小时候为了考试做训练自然是对的，放到科研里自然又不对，所以现在这样的话究竟好不好呢（笑</p>
<p>抽代期中才考
1.5h（顺便吐槽下周五的下午，我要连考抽代期中和初概期末，中间相隔 15
分钟。所以还好把初概 PF
了...），反正肯定是不适用在多个题目上停留很久的。范围到整环分式域。今天冲进度横跨三个小节，很震撼。不过昨晚刚复习完群同态，环同态就完全复读，洒洒水啦（错乱</p></li>
<li><p>抽代助教可爱捏。<del>看本人照片（微信头像）也感觉蛮可爱的</del></p>
<p><img src="https://s2.loli.net/2022/10/25/pAI6j41JtWg9OrT.png" alt="_GAXPK_O3TQ3XX_N6JXG2.png"></p>
<p><img src="https://s2.loli.net/2022/10/25/tQHCGD5dA8kSJPs.png" alt="ZKA2Z_PX_BDMW@9B_55_C8Y.png"></p>
<p>P1 是我刚发现有 bonus
的时候，那一周作业巨多，于是我交作业时备注了一下之后会慢慢写之前的题目，他还回了我一下；P2
是后一周我把 bonus 补齐了交上去还给他纠正了几个地方之后，乐。</p></li>
<li><p>剁手了一套世图的 GTM
风格笔记本，之前精装的那个摸鱼学导论和划水学导论 60
一本，买不起，买了也不舍得写。这个平装的就亲民很多，四本六十多（虽然也不便宜）。</p>
<p>说到这个，今天翻开 Pin
的一千零一页看了两眼（不要越到期中越爱干别的啊...），感觉没有想象中那么恐怖，至少不是全都那么恐怖。有希望但没信心寒假看到足够应对概率论（1）的位置。但我的优势可能在于上过初等概率论，在应用方面会好一些，尽管这对神们来说掌握起来并不困难。我发觉面对数学方面问题的时候就会心态平和很多，不在乎神能做到什么，只在乎自己是否竭尽全力。<del>可能是没卷到那个程度，大家都有光明的未来</del></p>
<p>我对数学分析的恐惧最早来自于高二，和 ycj
他们一起备考丘班（自然是失败了）的时候。当时看的是同济数分，现在看来和华子的微积分
A
差不多难度，但对于高中的我（尤其上海高考不学导数，高中竞赛也不很需要导数）来说还是有些费劲。后来大一上了传说中的王晓峰老师的两个学期微积分，拼命下放各种高阶知识又不讲得很详细，让我感到非常难受，后期就没怎么听课了。lx
老师说得对，什么东西到最后，都会收敛靠到自己读书上去，而且只有靠自己。</p>
<p><img src="https://s2.loli.net/2022/10/25/YMZk9jT8pREvhSN.jpg" alt="942193fce2db8321e5ab7aadad21cd6.jpg"></p>
<p>（还没到货，在世图读者群里看到打样是长这样</p>
<p>Introduction to that thing, but only for people who already known it.
—— Carol Firedman</p>
<p>Whatever who wrote, none is understandable. —— Dave Firedman</p>
<p>到时候自己留两本用，送 runzhi
一本，还有一本暂且留着，蹲个有缘人（什么</p></li>
</ul>
<h1 id="月26日">10月26日</h1>
<ul>
<li><p>昨晚睡前想的是我这周就算不睡觉也做不完事情了，然后还是一觉睡了七个半小时，罪过。</p>
<p>最近的 ddl 们：</p>
<ul>
<li><p>下周五交抽代作业，预计得有三四十道题，习惯了。</p>
<p>当天还有这周的离散作业，周日晚上嗑着瓜子二倍速看回放然后写一下。</p></li>
<li><p>下周四交数值分析纸笔题，四道题，但我好像还不大会，但也问题不大。</p></li>
<li><p>下周三交实验报告，哈哈，五千字起步。</p>
<p>当天还要交初概的两次作业，哈哈，哈哈。</p></li>
<li><p>下周一交工程经济学作业，还没学，预计又是罚抄五到六页左右。我认为土木系每一门课脑子都有问题。</p></li>
<li><p>本周日交马原读书报告，两千字，大概知道写什么了所以问题不大。</p></li>
</ul>
<p>抽代也没复习完，初概虽然 PF
但还完全没复习，你怎么睡得着的.jpg</p></li>
<li><p>于是保守估计这周末要通一宵，也可能要通两宵。</p></li>
</ul>
<h1 id="月27日">10月27日</h1>
<ul>
<li><p>一边往前写抽代，一边往后看抽代。今天进度推的还行（</p>
<p>暂时感觉环的一些东西有些不符合直觉。比如绿皮上整环分式域的第一个结论就让我摸不着头脑，刚拿到的时候自己独立证不出来，第一反应是困惑，在群论学习中倒是没有的。</p></li>
<li><p>“我经常在想能回到那个时候就好了，但‘那个时候'究竟是什么时候呢，我也不知道。”</p></li>
</ul>
<h1 id="月28日">10月28日</h1>
<ul>
<li><p>充电台灯坏了，于是紧急翻出来了开学时候送的台灯，甚至还有当时的小卡片，谢谢李贤凯先生。</p></li>
<li><p>月底了啊...今天凌晨解决完了群作用，重做课后题的时候发现除了 2 和
4
那两个相对重要的结论还是证不出来之外，别的题目都能速通了，感受良好。然后又通了半宵刷
zmx 的抽代卷子，但没有计时，可能做了 2h
左右就困得不行了。最后两题还没看，前面做的应该能及格，貌似也没那么恐怖（貌似，但愿没有伪证，我真的很擅长伪证x</p>
<p>先砸瓦鲁多一下，等我去把群论最后几节复习完回来再继续（</p></li>
<li><p>初概最后一课了，下周两节课一节复习一节考期末。后半期我都没有很认真学，想想也挺遗憾的，上个学期一直对统辅的第一门课满怀期待来着。不过，后面还有多元和统计计算，这倒不是我最后一次见到婉璐姐姐，今后如果在统计中心做项目的话，想必会更经常见吧。</p>
<p>大数定律 &amp; 中心极限定理 &amp;
收敛性，感觉倒是全学期最有意思的一节课。嗅到了很多分析的气息，但是这课凡是涉及到的都不要求，下学期概率论（1）再来。</p>
<p>然而初概的笔记从期中之后就没有再写了，sigh。等下周五考完，在统计推断开始之前简单理一下，主要是自救。如果咕咕了的话就把那一篇撤掉吧。</p></li>
<li><p>今晚包括明晚甚至后天晚上，都要刷夜做各种 dirty
work，白天要推抽代进度，还有复习 /
学习各种稍微有点用的东西，写作业。</p></li>
</ul>
<h1 id="月29日">10月29日</h1>
<ul>
<li><p>插播碎碎念笑话一则：</p>
<p>我：先做 ddl 最晚的作业，然后往前慢慢推，就能正好在最早的 ddl
之前写完所有作业</p>
<p>室友：那要是最早的 ddl 之前没完成怎么办</p>
<p>我：不会的，闭区间套定理保证哪怕有无穷个
ddl，也还可以有一个实数（时刻）在“做完所有作业”和“第一个 ddl
到来”这个区间里（开始伪证</p></li>
<li><p>算工程经济学从一点算到四点，我靠，校园贷借了 10 万最后只还了 30
万，这多吗，这不多</p>
<p>华子搞那些防范诈骗的宣传还不如带大家都学学经济学x</p></li>
<li><p>反正就是做了一天 dirty
work，凌晨算工程经济学，下午写读书笔记，晚上写实验报告，烦死。光栅衍射直到我缝合完报告都没理解到底是在干嘛，罢了罢了。</p>
<p>能找到的公开的往年报告很少，貌似大物也不做这个，这给我造成了不小的麻烦。我放一份我的在这里：<a href="https://cloud.tsinghua.edu.cn/d/9eec91a1826542e79d93/">Click
Here</a>，也更新到物理实验备忘录里去了，因为当初看不懂就没有写这个实验，现在这样当做补完了。</p></li>
<li><p>本来今晚还想刷个夜，一鼓作气写完作业明天就开启复习，结果 hx 发<a href="https://mp.weixin.qq.com/s/ab19q32CMV-xamC644FOwg">链接</a>说明早有致理的抽代讲座，还是去一下比较好。结果报名的人太多了，群里说非致理的人只能线上参加，这话说得，虽然也没什么毛病但是，好吧没有但是。</p>
<p>也挺好的，线上的话九点半开始可以九点一刻起床，线下得八点多就起。</p></li>
</ul>
<h1 id="月30日">10月30日</h1>
<ul>
<li><p>我是
five，我虽然早睡（指三点就上床了）了但还是没听抽代讲座，就早晨醒来坐在床上看着腾讯会议，觉得画质真不咋地，看着看着就迷糊过去了，醒来就开始白板讲题了，更拍不清楚了，直接退出会议摆烂。</p>
<p>早晨起来感觉眼睛很不舒服，不能再熬了。今天处理完所有
ddl，然后开始继续复习之前暂停掉的抽代，以及总要挤出点时间留给初概，总之其实压力还是很大。</p></li>
<li><p>和何老板对了一下实验报告，发现我真是...只要不是所见即所得的写作，就能写出
114514 个 typo，又改了一中午。给老板安利了我暑假里在 Overleaf
上投的物理实验报告模板，然后意识到那可能是我给科协学术部打的最后一份工了——这学期的活我都是能咕就咕，开了三次例会我找各种理由最后就去了一次，完全摆烂。等学期结束换岗的时候就走了，实在没有继续待下去的必要。</p></li>
<li><p>晚上考完期中的友人来看我，去西门口和她聊了一会天，大倒苦水，吐槽我自己
PF
了一门退了一门课还是忙不过来，回想了一下平时还是太摆了。然后从哼歌逐渐变成了一起戴着耳机唱歌（当然音量不是很大，周围没什么人，社恐.jpg），唱了告五人的《爱人错过》，还有
EVA 的两首经典老歌，心情好起来了。</p>
<p>说到这个，上次北大那只叫明日香的正在找领养的小猫，得猫瘟死掉了，唉。</p>
<p>Can you give me one last kiss？</p></li>
</ul>
<h1 id="月31日">10月31日</h1>
<ul>
<li><p>今天倒没啥别的事，刷了一天抽代，书差不多摸完了。这一遍感觉把之前模糊的内容都处理好了，此前不会的习题大多数也能速通，但是还是觉得有些题目真的是，奇技淫巧。</p>
<blockquote>
<p>数学上不应该回避技巧的提升。——PIN</p>
</blockquote>
<p>好吧，我谢罪（</p>
<p>明天抽代课上写一下 PKU 题。</p></li>
<li><p>晚上去吃了清芬一楼的羊肉泡馍，还蛮香的，汤的味道调得不错，北方人面食基因觉醒.jpg。热乎乎的一大碗，冬天破防时候的
comfort food 又增加了（</p>
<p>突然在想陕西人会不会觉得不好吃或者至少不正宗，就像我觉得清芬的生煎不是一般的难吃，但室友觉得还不错一样（</p></li>
<li><p>十月的尾声，日记系列的第二篇也如期完结了。我以前以为这个系列至少会见证自己慢慢的改变，但这两个月中确实没有什么变化，除去学习的东西变了之外，生活还是那样，ddl
追着 ddl，摆烂，自学，摸鱼。</p>
<p>不过，像我这样运气的人，一旦面临变化恐怕就是往不好的方向在改变，亲友离散（什么离散），生活不顺，诸如此类。因此没有承担可能发生的精神内耗，或许已经是一件很幸运的事了。</p>
<p>昨天和友人在西门外轻声唱歌，唱《爱人错过》。这也是前几天偶然在你社看到，然后一听就觉得很喜欢，于是加入循环了的歌。其实歌词就那么几句话：</p>
<blockquote>
<p>我肯定 在几百年前 就说过爱你</p>
<p>只是你忘了 我也没记起</p>
<p>走过路过没遇过 回头转头还是错</p>
<p>你我不曾感受过 相撞在街口 相撞在街口</p>
<p>你妈没有告诉你 撞到人要说对不起</p>
<p>本来今天好好的 爱人就错过 爱人就错过</p>
</blockquote>
<p>很奇怪吧
XD，倒是和恋爱经历都没关系（x）。我想是因为听出了一种不安定的感觉而喜欢，尽管很担心这样的事情发生，但如果改变就在面前，还是要勇敢些。</p></li>
<li><p>什么胡言乱语（</p>
<p>好啦，下个月见！</p></li>
</ul>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇三·22年11月</title>
    <url>/2022/11/01/Diary-2022-11/</url>
    <content><![CDATA[<p>聊以对抗记忆的变形。</p>
<span id="more"></span>
<h1 id="月1日">11月1日</h1>
<ul>
<li><p>在 hx 课上看了 <a href="https://bicmr.pku.edu.cn/~lxiao/2022fall/Midterm-solution-2021.pdf">PKU
去年的抽代题</a>，还好，还好，也就是最后一题有点懵。困得我降智。虽然这个
110
分钟真有点难绷，看来也是两节课加一个下课随堂考的，或许有参考意义呢？</p>
<p>现在已经没人在乎何宝在讲的新课了，感觉大家课上都在复习（</p></li>
<li><p>焦虑地过抽代定理证明，毕竟何宝课上从来都只讲几个概念和证明，又说“考试和课堂内容相关”，很难不怀疑他要考定理。然后就麻了，这就是古老的神秘吗，我真的好菜（</p></li>
<li><p>看了看天气，下周要降温了，这周恐怕是最后一周穿衬衫的机会了罢。冬天（或者说秋季学期）的状态明显比春夏要好，一方面是春天我会过敏，总是昏昏沉沉的，然后就是怕热，夏天也过得很不舒服。</p>
<p>倒是有点期待北京的雪，去年初雪的时候徒步从法图走回寝室，感到了来华子之后从未有过的宁静。然而上次在上海看到纷纷扬扬的雪，已经是四五年前的事情了。</p></li>
</ul>
<h1 id="月2日">11月2日</h1>
<ul>
<li><p>好，一晚上学完初概后半学期内容！也不难嘛！（</p>
<p>刷完样题之后就当做没初概期末这事儿了，摆烂。但心里到底还是有点难受。这课唯一的弊端就在于没有能很好地匹配的教材，MIT
的概率导论自然好，但是二者进度之间有太大差异，实在不方便。然而没有参考书对我来说就是毁灭性的，我现在越来越难以集中精力听谁说话，在听课里学到一些本来从书上就能得到的东西，或者在
PPT 里学习什么的，真的不是很擅长。</p>
<p>又开始焦虑自己后半期的统计推断能不能行，以及毫无分析基础，我这样真能寒假速通一下测度积分然后就去上概率论（1）吗，可是不上就来不及了，草，真想延毕一年。</p>
<p>明天的时间还是让给抽代，虽然我觉得复习得差不多了，反正再复习该不会的也还是不会，何宝太
book reader 导致我甚至不知道自己不会什么，草。</p></li>
<li><p>听室友破防说来华子之前从没想过日子过成现在这样，还有她高中时对于华子的所有瑰丽幻想，实话说我有点无感（笑）。毕竟考进高中的时候就幻灭过一次了，而幻灭过一次就不会再有第二次，如果有，至少也不会那么严重。</p>
<p>现在对华子幻灭，以后就不会再对另外的环境幻灭，一下子就降低了试错成本，好事（确信</p></li>
<li><p>说到幻灭，为什么还有“如果有”这个选项呢，因为我对科协也幻灭过一次，只不过不太严重（</p>
<p>我之前写过一篇文章表达过对你院科协的美好设想和一言难尽的现实，如今我已经不想改变它了，而是打算下学期直接跑路。你院对科协的定位就是主体在从游部，而学术部既边缘又臃肿，于是今年被丢了个举办科创日的任务，做其他部门懒得做了的杂活，（对我来说）很没意思。</p>
<p>搭网站这个设想最后一次被提出是这学期的第一次例会，有一位新成员说可以给你院科协搭个网站写东西，把公众号的内容迁过去。部长说是那种用来宣传活动的网页吗，可以挂靠在书院的官网上。不了了之。我也没说什么，当时就觉得算了。</p></li>
<li><p>看到 ex 之前的发言，虽然我一直在尽职地扮演一个合格的死去的
ex，但也没必要向共同好友宣告我真的死掉了吧（笑</p>
<p><img src="https://s2.loli.net/2022/11/02/s1aEA8PQCB9Um4g.jpg" alt="C7BFE0FF17EB5040EC2505C17C3B1327.jpg"></p>
<p>那你怀疑吧，你活该（错乱（好恶毒啊（啊不，其实已经很善良了 x</p></li>
</ul>
<h1 id="月3日">11月3日</h1>
<ul>
<li><p>吃到了社友的安利，于是今天一边听《万千花蕊慈母悲哀》一边写抽代，感觉要把自己超度了（</p>
<p>和 illion 的《GASSHOW》很像诶，但是更偏向于悲伤了。</p></li>
<li><p>然后又去听了<a href="https://www.bilibili.com/video/BV1sP4y1p797/?spm_id_from=333.337.search-card.all.click">源的
Tokyo Dome
演唱会</a>，以前很喜欢一边刷这场一边写作业，但是当初刷的那个视频下架了，只有缓存还在我的手机里。东蛋场每一首歌感觉都比专辑还好听...而且还有源的各种即兴演出
&gt; &lt;</p></li>
<li><p>草...明天不是连着两场考试吗，今天怎么净听歌去了。早点洗洗睡了，pray
for tomorrow</p></li>
</ul>
<h1 id="月4日">11月4日</h1>
<ul>
<li><p>抽代期中...题肯定是不难的，但相比之下我还是宁可考 zmx
的卷子，扎扎实实做三个小时。具体问题详见<a href="https://chiyuru.github.io/2022/09/19/huixiangdou/">本篇</a>篇末的“赛博猫猫敲键盘”。复盘越想越头痛，大概就是：</p>
<p>第一题愣了一下不变因子组是什么来着，有惊无险。第三题没构造出来之后就直接做
<span class="math inline">\(105\)</span>
阶群去了，结果又手抖抖半天，慌得要死，浪费不少时间。然后是环同态，看完题大概五秒钟就想出来了，不夸张。我愿称之为最水的一题。回头写了一下循环群同构的第一问，手抖写错了
114514
遍，涂得乱七八糟。又看到最后一题第一问就作业原题，写完，第二题就一定义+归纳，结论对了但我过程也有点乱，不知道给几分。最后去做了循环群同构的后两问，用一下第一问结论感觉就那样。？问题是我第一问结论对了没有，至少我感觉是有问题的。然后又去想群运算构造，想不出来，但明明已经想到
<span class="math inline">\((a+1)(b+1)=0\)</span>
什么的了，就是没再往下想。交卷了。</p></li>
<li><p>下午同时在物理上告别了初概，然而从现在开始我要复习初概了，因为过几天统计推断就开课了。</p></li>
<li><p>emo 一下（</p>
<p>大一的时候意气风发，大概是在我院这个舒适圈里躺着的缘故，觉得自己能做到很多事情，能去到很远的地方，又到底是怎么变成现在这么破防的呢x。这学期好像一直就没什么好消息，初概期中先裂了，不得已送了个
PF，结果期末没复习都考得还不错，吗的。奖学金入账 0
元，然后又是抽代期中，最近物理实验还崩。</p>
<p>又想到上学期紫十二 remake
的同学，先但愿自己去数学系混的这两年不要有生命危险。绩点不知道能不能在申请之前苟住
3.8，本来上学期期末还有 3.89，夏季学期土木系的烂课一出分直接给我送到
3.83，容错率一下子无了，这学期体育 +
抽代又不知道要扣到哪去了。软弱的时候就很想往回退，什么申个 ms
算了，再想想花不起这个钱，又有哪家招我这种 five 当
PhD，留国内容易点，吗的强基书院又各种限制，想往复旦退可能都没得退...</p>
<p>一阶段 PF
了初概，二阶段要退常微分和基物实验。前者是没必要再上下去了，后者是上次光栅实验莫名其妙吃了个
80 分，也没给出什么理由，我又不想在这种课上送一个
3.6。问了一下老师，退实验课也几乎没有沉没成本，先前做过的实验明年想保留成绩的可以申请保留，不想保留的可以重做。</p>
<p>实在不行的话跟现实低头一下，统辅为主，少上点 / 多 PF
一点数学系的课。真是弱者。</p></li>
<li><p>后半期就，不得不转换一下重心，这下一定要苟住数值分析、统计推断和离散。工程力学也是，不能太拉胯，然后就，抽代尽力而为。</p>
<p>我感觉我之后必须搞点水课来刷成绩了，真的是。</p></li>
<li><p>还有些别的更令人难受的事情，但现在先不说了，暂且这样吧。</p>
<p><img src="https://s2.loli.net/2022/11/04/84o2aCwkKnMA5fx.jpg"></p></li>
</ul>
<h1 id="月5日">11月5日</h1>
<ul>
<li><p>今天又是新的一天！（试图麻痹自己</p></li>
<li><p>是不是全世界今天都在考物化，我下午一点起床的室友三点要考物化，偶然说了几句话的同学三点也考物化，来三教自习，坐我前面的人也在量子波动速读蓝皮的《简明物理化学》，两点半左右离开了。</p></li>
<li><p>同学锐评我：本来桑海宁装的蛮好的，桑海话讲的也蛮好，最近看到桃李的大闸蟹就绕路，连胶东人都装不下去了吧（x</p>
<p>的确家里一直没有吃水产的习惯，甚至还有点排斥，而我对某些范围不明的水产过敏，就连鱼虾都很少吃。之前偶然吃了一次桃李二层做的一种扁平的多宝鱼片，用辣椒和葱蒜点缀，再浇一勺鱼汤，感觉还不错。可惜现在似乎不做了，不知是不是也有丰产的时令，秋冬是吃不到的。</p>
<p>在南方吃了 12
年学校食堂，从来只有米饭，来到华子还是忍不住买面点做主食，母亲也叮嘱我寒假回家之前去牛街买些北方特产的面食带回家，那都是上海买不到的东西。小麦的香气还是刻在我和我的祖辈的记忆里。实际上我在记事后几乎从未踏足故乡，跟着父母几度辗转，在嘉兴度过童年，又来到上海。母亲对她家乡的县城、生长的环境颇有微词，于是我也迷茫，自己对几乎未曾谋面的故乡的依恋，大约只是经过了想象的粉饰吧。</p>
<p>不说了，最近家里的事实在令人难受，在肉身还远在上千里之外的时候，先集中精力干点别的去..</p></li>
<li><p>想起来三四月份的时候看过一部电影，情节还很清楚，但是电影名还有角色的名字一个也不记得了...最后还记得的一个特征是据说男女主拍完这一部电影之后真的出轨在一起了
= =，然后就搜到了...</p>
<p>叫《夜以继日》。B 站评分不高，8.4，<del>（B
站评分有啥参考价值）</del>，查了一下 bangumi 是 7.4，<del>远超我对
bangumi 的预期</del>，再一看是样本量太小了，才 24 个...</p></li>
</ul>
<h1 id="月6日">11月6日</h1>
<ul>
<li><p>今天开始速通之前放掉的数值分析。真的很想喷一下这教材的排版，标题和正文的字体几乎差不多大，节与节之间连点空隙都没有，但凡做成
A4 大小的书，或者加到 400
多页，也不至于阅读体验这么差。虽然它写的很详细，难得有证明全都在书上能找到的书，而且已经很厚了，但还是很难绷。</p>
<p>这课只有期末，并且明确了不调分。但我感觉考试之外的 50
分有手就行啊...数学系专业课还把出勤算 5
分，作业也有手就行，真的蛮不可思议的。或许这是门专业课里的水课吗？我不知道。</p>
<p>之前觉得老师长得很帅（甚至早八上课会觉得啊老师好帅还是别睡了（什么啊），就去搜了一下，包老师是中山大学的本科，在坡读的博。他的微信头像是他的一双儿女，眉眼都和他很像。</p>
<p>其实我觉得去坡也是很不错的选择...</p></li>
<li><p>和室友聊起来才知道你院（一字班）到现在还有 GPA 4.00
的人，还不止一个。别的不说，我觉得体育能稳定拿 4.0
就已经和我不是同一种生物了，根本没必要去了解人家的情况（</p>
<p>说到这个，该刷月光长走了，我还差 21
次呢。之前实验了一下，走路的配速略大于最低要求了，跑是不可能跑的，只能每天晚饭后走骑结合一下消消食这样子（</p></li>
<li><p>老姐在南昌住院的复诊结果出来了，不是强直性脊柱炎，只是腰间盘膨出和炎症，（《只是》），值得庆祝。等她假期来上海请她吃饭。</p></li>
</ul>
<h1 id="月7日">11月7日</h1>
<ul>
<li><p>今天马原课上读完了 PIN 多年前连载的 《Heroes in My
Heart》，很喜欢这个结尾：</p>
<blockquote>
<p>到这里就真的结束了吧，要毕业了。又想到了一个小故事是 Halmos
的，他写了一本著名的书叫做 Measure
Theory，当他完成此书的时候，心中喜悦难以抑制，向众人宣布：“我刚写完了
Measure Theory 的最后一个字！”有人问：“最后一个字是什么？”Halmos
当时愣住了，连忙赶回办公室，再跑回来，告诉他们说是什么什么。</p>
<p>我也写完了，最后一段话和本文无关，写给远在千里之外的一个女孩，每一天到
bbs 上的时候，我总是假设你也上
bbs，你也来看我的连载，希望你能喜欢这些故事哪怕只有一个，尽管你不喜欢数学也不喜欢我。</p>
<p>--</p>
<p>美丽有两种</p>
<p>一是深刻又动人的方程</p>
<p>一是你泛着倦意淡淡的笑容</p>
</blockquote></li>
<li><p>一周以来的效率高峰发生在工程经济学课上，我没听，预习完了环的 3.7
节还写完了课后题，搞定了之后居然又过了十几分钟才下课，第一次觉得时间慢得不可思议...</p>
<p>恐怕也不是第一次，高三的时候我喜欢在数学课上写英语卷子，因为英语太烂了，要恶补。当时总觉得在数学课上伴着老师的安徽口音写作业，正确率比回家写的要高很多，甚至写得也快些。这是什么原理（</p></li>
</ul>
<h1 id="月8日">11月8日</h1>
<ul>
<li><p>昨天提到了我的高中数学老师，才想起他也是华子毕业的，大约是 2006
年入职二附中，可能是最早一批来我校教书的清北人。现在学校里清北毕业的老师就很多了。据说他本硕读的是核工程，理应是工物系的。他既是班主任，也是数学老师，倒并不是竞赛教练，我们的数竞教练是隔壁班的唐立华老师，<del>往往被叫做立华奏</del>。</p>
<p>前段日子看到他貌似升职了，简历上写着“培养出
blahblah，blahblah，及女子数学奥林匹克金牌学生一名”（大意），恐怕指的是我。虽然我这个破铁牌和他没半毛钱关系，但人在他班里，功劳就归他了吧。当然除了名额是隔壁班唐老师给的之外，也和<del>立华奏</del>唐老师没什么关系。这么说好像很忘恩负义，但事实如此（</p>
<p>不过其实我到现在也没理解的是，为什么高中三年他一直就当我不存在一样。同学当我不存在我可以理解，当时的男女比例比华子夸张多了，感觉大家甚至不好意思和女生说话，也没必要和我说话，我也自闭。毕业之后我就主动离开了高中同班同学的圈子，想来大多数人现在都已经不认识我了吧。</p>
<p>扯远了，虽然班主任这个态度也很好，毕竟我即使不是什么刺头，倒也是热衷于自己默默搞事和钻空子的类型，只要不捅出篓子（事实上也没捅出过篓子，高中生在学校里能捅什么篓子x）他就懒得说我什么。于是我的日常就是轻微违反一些针对个人的规定，但能比较好地提高自己的生活质量和精神状态，比如带手机听个歌、不在气氛令人窒息的教室上晚自习、肥宅不出操，于是也没人管我，很爽。</p>
<p>然而以前倒也有令我很难过的事情，比如我高三竞赛结束回头补高考，花了三个月就从年级
50%
的地方冲到了一模区第二名（还是第三来着）什么的，还有中间大大小小的进步的时候，整个高三他在班上鼓励过几乎所有取得了进步的同学，却从来，从来没有一句话提到过我。到最后还是想开了，就把他当做一个给我批改作业和试卷的工具人就好，美中不足的是不交作业的话他会派人来催。</p>
<p>虽然现在想想当时为这种事情难过有点傻，毕业之后我时常在友人面前喷他，尤其看到他简介上写我的铁牌是他教出来的之后，觉得这人，啧。但时至今日，我也还是对他当初的态度感到困惑，究竟为什么要这样呢？</p></li>
<li><p>抽代出分了，还挺乐的，我一共就做了 85 分的题，得分效率竟超过了
95%，就扣了群同态的一个没说明清楚的情况，我的很多担心都没有发生，说明运气不错，何宝相当温柔了。</p>
<p>虽然他说“考试题目很难”，从成绩分布来看的确（大约是两个一伯分，六个
90+，两个 80+（为什么这一段断档的这么厉害），在这之后还有 22
人，具体忘了，其中有 10 个没及格）。恐怕是这边人均水平确实不如 zmx
的大班，想必她那里藏龙卧虎，而我们更不可能和求真比了。</p>
<p>话说回来干嘛非要比，我（一部分原因）就是觉得数学中上水平的人也能有不错的出路（润应用），而且还能保持精神状态正常，才润来这里的。尽力学好自己的东西，享受乐趣，雨露均沾统计中心和数学系，差不多得了。</p>
<p>另外何宝居然把答题纸发回来了，拿回去裱起来。我还从来没见过这种操作，一时不知道他是真傻白甜（错乱），信任大家不会搞出点查卷的幺蛾子，还是其实已经保留了电子版的原卷等碰瓷。想起我大一的线代老师，期中查卷时全副武装，要求预约排队不许携带纸笔并全程录像（听说的），笑死。</p>
<p>一想到那个搞不出来的构造还是很蚌埠住，期末能不能多给点扎实的证明题...但至少做的基本都对了，对我来说也是大进步（</p></li>
</ul>
<h1 id="月9日">11月9日</h1>
<ul>
<li><p>统计推断开课了，会 follow
经典教材，这对我来说是个太好不过的消息了。数理课看电子教材有点难顶，这书又很贵，而且只用七周，于是我下课后速速去逸夫馆借到了最后一本书，乐到把手机忘在了书库里。回去找还迷路了，非常抓马。（为了几十块钱好卑鄙啊，这就是穷吧.jpg</p>
<p>洗心革面，好好学习统计推断！（但愿不是 flag</p>
<p>北馆和逸夫馆里好新哦，逸夫馆的绿色小台灯让我想起了高中图书馆里桌上的台灯，很温馨的感觉。可惜人实在太多了，有点社恐地狱，起码我觉得不是一个很适合（我）学习的地方，还是法图和三教比较好（悲</p></li>
<li><p>月光长走的时候突发奇想打算去找找宁斋在哪里，何宝和上学期高代选老师的办公室都在宁斋，他俩都是近两年来华子的青椒，看来不仅是理科楼，近春园西楼也已经满了，<del>为什么不是希尔伯特的旅馆呢</del></p>
<p>在近春园西楼门口遇到了一只猫猫，旁边两个姐姐貌似在劝它“你就吃点吧，特地给你带的”，笑死。然后它真的低头开始吃了，说明猫猫爱世人，喵门。</p>
<p><img src="https://s2.loli.net/2022/11/09/JZ3WAOH7d5uoNsC.jpg" alt="4EB767DECB315BF82ECF62D8B675D233.jpg"></p>
<p>从近春园西楼后面的小门进去，再走一段路就是宁斋，门外的院子是华子校园巴士的停车场。我以前路过这里多次，一直以为这个小楼是司机的休息室，没想到是宁斋啊。拍了两张对焦不同的照片，里面亮着灯的一间房间里似乎在开
seminar，在寒风中远远望进去，很温馨的感觉（？</p>
<p><img src="https://s2.loli.net/2022/11/09/HfqrFN9d4o35ugL.jpg" alt="EBD7A54843467E19AF3EFE34107867BD.jpg"></p>
<p>还看到了西楼社区，没想到都是那种很有北方特色的平房，有小院子和爬着植物的篱笆。我原以为会是楼房，原来华子的家属区也分为破的和豪华的，就像紫荆和南区
/ 20-29 号楼一样（</p>
<p>总的感觉西门附近的建筑都缺乏修缮，近春园西楼算是最好的了，后面的小院子也很破败，到处是杂草和碎石。</p></li>
</ul>
<h1 id="月10日">11月10日</h1>
<ul>
<li><p>查了一下下学期的课表，统计中心的课和数学系居然正交，太感动了。而且下学期放掉基物之后就没有必修的物理课了（如果不把数学物理方法当物理课的话），我去，太爽了，是打数学基础的好时候！</p>
<p>分析基础非常悬，实复概三选二的话实分析暂时不打算上了，尽管它比复分析更有用，留给大三补好分析基础再来，改复分析
+ 概率论（1）；水一个概随，权当弥补这学期初概 PF
的绩点了；统辅的话是周在莹老师的线性回归分析和邓婉璐老师的多元统计分析，又能见到婉璐姐姐了，好耶！</p>
<p>此外可以补一个统辅导论课，比如生物统计学导论或者统计学习导论（其实从
workload
和对于进组细分方向的帮助来看，我可能还是更倾向于生统？），也了解一下应用场景，还能多认识一下统计中心其他的老师。没有意外的话（指确定不换方向的话）准备暑假进组。我真没想到统计中心还有
NLP 的组（俞声老师），果然工工里面什么都有，但我是想走数理统计 or
Bio-Stat 的。</p>
<p>数学物理方法是必修，还替代不了。我不是很清楚和 ODE+PDE
相比是不是弱化了数学强化了物理建模，那样的话有点恐怖，学不下去就退。土木系还有两门一看就很屑的必修课，测量学和工程地质，估计属于难度不高破事一堆给分还不好的那种，到时候再说。然后选一下基物实验，选一下政治课，选一下体育（或许可以再上一遍这学期的剑术？那不是爆杀吗
x）再加个通识课。</p>
<p>这样的话肯定是 30
学分往上了，稍微有点恐怖，但考虑到概随约等于没有，可能也还好吧？反正学期中间要是觉得受不了了，就优先退掉必修课明年再来（草），没什么可顾虑的...。我每学期都嚷嚷着想选点水的通识课提绩点，但最后还是会
all in 能学些东西的课，乐。</p></li>
<li><p>最近想把之前看到的统辅课程测评重新排个版搬过来，我的博客读者中有几位统计学潜在选手，想卖个安利；另外原来的排版太糟糕了（x）。当时读到的时候给作者留了联系方式认识了一下，找他问问是否同意。</p>
<p>UPD：搬过来啦。V1ncent19 学长还非常慷慨地表示欢迎以 CC BY-NC-SA 4.0
继续传播。</p></li>
<li><p>友：你大三下学期修不完必修课，不是不能保研吗？</p>
<p>我：我不保研，我现在担心的是到大四春季还剩超过三门必修课的话毕设不能开题，别千辛万苦拿到
offer 结果延毕了（</p>
<p>想给我自己颁一个乐观抗压奖，真的，太乐观了</p></li>
<li><p>聊到凸优化的时候想起来 xyx
上学期说在上包老师的凸优化，就去简单问了一句测评，确实是研究生课，40%
作业和 60%
两人一组大作业，和下学期求真那个应该会不太一样。他说他和包老师关系很好，我当即的感觉就是<del>现充好可怕</del>，啊不是，擅长
social 的人太厉害了。</p></li>
</ul>
<h1 id="月11日">11月11日</h1>
<ul>
<li><p>学习数值分析的最好方法是抄书...梦回高中的时候看化学竞赛的同学抄各种砖头。抄了一遍就会了。</p>
<p>抄到矩阵扰动了，还有线性迭代方法和非线性迭代要抄，我觉得我行了（确信</p>
<p>开了一本 GTM 笔记本抄的，草，感觉很神圣（</p></li>
<li><p>大雨天，中午出门的时候久违的闻到了湿润的空气的味道，一瞬间以为回到了南方。又想起来友人之前和我说“讲吴语的齐国人”的时候还说，有两个故乡是很幸福的事情吧，我说不是的，这样我根本没有故乡。</p>
<p>晚上未央开推研会议，我懒得去，就让室友文字直播一下，然后去吃李先生了。李先生的牛肉烧饼真的好吃，塞得满满的，饼也很酥松，比牛肉面好吃，八块钱一个感觉不算太贵。吃完那边会也开完了，反正就是列了一个不允许跨保的黑名单（尚未公布），明确有金融和管理类，我觉得肯定也有计算机类，这样的话大家倒是沾了未央软件那十个人的光，软软怕是要被未央人卷了。然后据说大概率不能外推，出国不限制。其他消息还有只要能在未央毕业就能拿到推研资格，但是不自带名额。</p>
<p>这已经比我想的要好一万倍了，我之前甚至想过，如果不能开出国成绩单的话，就先去做一年
RA 再申请..</p>
<p>所以这个会确实和我没关系，我想哪怕校内跨保他们也不会闲到限制去数学系和求真，而统计中心目前流落在外倒有可能被制裁。而我大概率是要出国的，就更没关系了。听完消息之后我第一个想起的还是大一的时候，看
xyx
在小群里说想跨保去茶园要发多少顶会什么的，而我那个时候还在痛苦地纠结是转码还是转数，也还会因为码不出来而深夜破防，看到他的话更加焦虑了。不知道推研具体卡不卡茶园，他现在又在怎么想呢。</p>
<p>吃完饭去做核酸，听涛的核酸队伍排得都要打结了，于是去了祖龙广场，才知道这个规模原来也算广场，和社友起名的“有鼎广场”差不多嘛x。人相比之下不算很多，而且没有灯，把脸埋在围巾里就没人看得出来我没戴口罩（</p></li>
<li><p>抽代课上看转数环友吹水下学期的课哪个老师更好，我看了半天才意识到，我一没有必修志愿，二还得手动选课，哪个老师好和我有啥关系？</p>
<p>概率论是王小群和梁宗霞，前者以前开概统，今年第一次开概率论，后者好像是定理原题默写大师，学不到东西，但我可能只能选他了。不过好像只要背诵得当给分就还好，也就算了，出卖灵魂就出卖吧。</p>
<p>复分析是张广远和薛金鑫，虽然复分析不限数学系选课，但我没必修志愿可能也抢不到薛金鑫。环友评价张广远至少算是本手而不是俗手（而梁宗霞是断手x），那也还能接受。</p></li>
</ul>
<h1 id="月12日">11月12日</h1>
<ul>
<li><p>熬大夜抄数值分析，抄完了 Jacobi，G-S 和 SOR
方法才睡觉，早晨起来又继续抄，太惨了。</p>
<p>乐子一则：SOR 方法的迭代矩阵是 <span class="math inline">\(S_\omega=(D-\omega L)^{-1}((1-\omega)D+\omega
U)\)</span>，推导完之后觉得这怎么记得住啊，难道每次都要推一遍吗。结果自从把第一项幻视成
dwl 之后就记住了：这个矩阵是 dwl 的逆再乘一个 <span class="math inline">\(D\)</span> 和 <span class="math inline">\(U\)</span>
的线性组合（对不起邓婉璐老师，真的对不起（</p>
<p>这学期结束，我的代数学习可能就接近尾声了吧...线代，高代选，抽代，数值分析，遗憾的是高代全靠自己拼拼凑凑，没有很扎实地上完两学期，但暂时还是够用的。代数很有趣，我觉得初学的情况下远比分析有趣，毕竟还是具体一些，（但真让我做那种矩阵的怪题目我觉得也未必行），这几门课也很好地把我带进了转数的坑。之后看情况可能再去上个代数学前沿基础，或者上拓扑学，就真的要说再见了。听说下学期的代前基是
zmx 讲，她这时候不应该在开高代 2 才对嘛。</p></li>
<li><p>下午，翻开书，抄共轭梯度法。阅读定义的我：梯度是什么来着？（</p>
<p>然后又想起来上学期各种暴躁，摆到最后喜提 B+ 还没记 PF 的微积分
A2，果然是学得不行。但我在重读分析之前暂且先拒不承认自己有问题，一定是这课太破了（（</p></li>
<li><blockquote>
<p>因为享受着它的灿烂</p>
<p>因为忍受着它的腐烂</p>
<p>你说别追啊 又依依不舍</p>
<p>所以生命啊 它苦涩如歌</p>
</blockquote>
<p>歌单 ++（</p></li>
</ul>
<h1 id="月13日">11月13日</h1>
<ul>
<li><p>抄完数值分析了，数了一下抄了 50 面 GTM
的本子...真麻了。不愧是古老的神秘（虽然相比之下不是很古老），idea
还是很多的。有一些东西我感觉还不是掌握得特别清楚，先搁置一下之后再来看。</p>
<p>想起来友人和我说过的一句话，idea 远比调参重要，当然我对 AI 一窍不通啦
:3</p></li>
<li><p>昨天忘记发了，出寝室的时候看到楼下的叶子被扫成了一堆，非常漂亮：</p>
<p><img src="https://s2.loli.net/2022/11/13/NOg1BPbql4VuZwQ.jpg" alt="2E6BFDAE5E197EDE1F46EB071A7C2976.jpg"></p></li>
<li><p>室友今天给我表演了一个在床上爬（</p>
<p>其实看到各个高校爬行的视频的时候，我第一反应是想到了《春宵苦短，少女前进吧》里面女主跟着在玩行酒令（？是吗，忘了）的人们一起爬的情节..太阳底下无新事（？？这是什么结论</p></li>
<li><p>看到小学期工程计算机制图给 85 分的我一个 2.3
的那个老师，成为了土木系“良师益友”提名教师，听我说谢谢你（。这学期在课咨委做完导论课的提案，下学期应该可以去改这门屑课了，当然应该不是我来带提案组，所以期末之前要和
lyf
还有土木系那个学长再提一提这件事，不然还得拖一学期，还得伤害一批人的绩点（。</p></li>
<li><p>摸鱼的时候排了一下下学期的课表，这已经 32
学分了，还想加通识课，使不得。</p>
<p>上学期选课的时候纠结无比，大改了 114514
版才变成现在这样，而实际上也还是不完满，甚至数据结构还在我的课表里待过很长时间，开学后最终还是退掉了。这学期感觉不怎么需要纠结，难点在于顺利把这些课都选上</p>
<table style="width:100%;">
<colgroup>
<col style="width: 5%">
<col style="width: 22%">
<col style="width: 16%">
<col style="width: 22%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;">Mon</th>
<th style="text-align: center;">Tue</th>
<th style="text-align: center;">Wed</th>
<th style="text-align: center;">Thu</th>
<th style="text-align: center;">Fri</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">工程地质</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">概率论（1）</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">概率论与数理统计</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">毛概 &amp; 习概</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">剑术</td>
<td style="text-align: center;">测量学（后八周）</td>
<td style="text-align: center;">基物实验</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">概率论（1）</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">基物实验</td>
<td style="text-align: center;">数学物理方法</td>
</tr>
<tr class="odd">
<td>5</td>
<td style="text-align: center;">复分析</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">复分析</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">数学物理方法</td>
</tr>
<tr class="even">
<td>6</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">线性回归分析</td>
<td style="text-align: center;">生物统计学概论</td>
<td style="text-align: center;">多元统计分析</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>这样来看的话没有多少用来大卷一场的下午和晚上了，所以下学期得努力早起，草，对我来说好难</p></li>
</ul>
<h1 id="月14日">11月14日</h1>
<ul>
<li><p>今日无事，记录一则和友人的扯皮：</p>
<blockquote>
<p>友：我感觉你从放弃转码之后状态好多了</p>
<p>友：说点你不爱听的，我觉得你就算当时去交大可能也会很痛苦，搞不好和
xxx（指 ex）一样</p>
<p>我：？倒也不至于，他这个单纯是因为实在不大聪明</p>
<p>友：这是报复性发言吗（</p>
<p>我：不是，我一直都这么觉得，反正感觉还不如我
=。=，而我也不算什么聪明人</p>
<p>我：我觉得他应该去读个文学硕士什么的，然后当翻译去，比较适合 XD</p>
<p>友：小绿和小蓝吗</p>
<p>我：嗯，感觉是一个本该成为小绿的人去做了小蓝的事情</p>
<p>友：不是，我是想起来小绿要被小蓝开发的同声传译 AI 取代了</p>
<p>友：（笑）说起来笛子已经很久不更新了，感觉是想不出来后面的剧情了</p>
<p>我：所以现在有类似于同传的 AI 了吗</p>
<p>友：有类似的产品吧，我用过 Otter.ai，遇到有口音的人就表现一般，还不如
Chrome 字幕</p>
<p>我：所以同传的场景会有人有口音吗</p>
<p>友：不知道诶</p>
<p>我：不知道诶</p>
<p>友：不过你要是科班出身，有环境、资源还有 fellow
的话，可能也不会像在华子自己转码这么焦虑</p>
<p>我：不知道，我的性格就很难有 fellow，也不擅长利用资源</p>
<p>我：还是传统式的学习比较容易啊</p>
<p>友：小镇做题家吗</p>
<p>我：小镇做题家哦（笑）</p>
</blockquote></li>
<li><p>突然想起来还有门期中没考...周六的工程经济学，感觉可以周三再开始复习（</p>
<p>就，过一遍 PPT，再拟合一遍往年题就行了。希望人没事。</p></li>
<li><p>明天跑 1500，去年跑了
8'20''，真的太强了，不知道怎么做到的。今年可能根本跑不进
9'40''，但愿活着回来。</p></li>
</ul>
<h1 id="月15日">11月15日</h1>
<ul>
<li>活着跑完了 1500，正好 9'20''，比去年慢了 1
分钟。其实我跑的时候还觉得自己挺快的（乐），以为能进 9 分钟。Anyway
这不重要，我这个羸弱的体质，跑完还活着 &amp; 甚至能拿到 3
分就很不错了。</li>
<li>今天也没啥别的事，只剩下跑完 1500
之后腿还在疼，早点睡了，明后天还得预习工程经济学（悲</li>
</ul>
<h1 id="月16日">11月16日</h1>
<ul>
<li><p>一些碎碎念：</p>
<p>经常遇到一些需要找人合作完成的任务，有时是小组作业，有时单纯是想在课程群里随机抽样一个人对对作业答案。每当找到这么个组织的时候，如果其他成员是大腿，总是一件令人高兴的事情。我也比较喜欢预设其他成员是大腿，一般都会先发出来一个自己的解决方案请别人提提意见，尽管里面有很多我知道而且暂时解决不了的
bug，总之是希望从别人那里得到一点启发。</p>
<p>然而比较差的情况下别人根本发现不了 / 发现不全 bug
在哪里，欢欢喜喜地拿着我的破烂方案就跑了；比较好的情况也只是能把 bug
提出来，再反问我一句怎么办啊，能得到解决方案甚至只是能得到启发思路的情况极少。到最后总还是我自己吭哧吭哧把
bug 修完，然后再让对方 check 一遍没有伪证。</p>
<p>所以，难道到头来大腿竟是我自己（？有的时候又觉得有点好笑，<del>希望以后读研的导师别是这样的。</del></p>
<p>为什么突然这么想呢，因为最近统计推断的课上没有认识的人，于是抽样了一个经管
+ 数辅的同学讨论作业。本以为数辅应该很强，没想到也只负责对我提
issue（。刚刚上课的时候没听讲，自己把问题修完了，对方 check
了一下表示这下就不是伪证了，快乐地抄进了自己的作业里，而我课后还得补一下课堂内容x，感觉愣是给自己找了个甲方。SRT
也是，做工工 AI
的项目本以为能抱到大腿，看了另两个人的申请书才知道他们都没学过
Python，这下大腿（暂时）真的是我自己了，感觉很艰难啊。</p></li>
<li><p>另一些碎碎念：</p>
<p>首先要向阅读这一段的朋友道歉，我理解并尊重大家不同的卫生习惯，但我也确实洁癖，希望不要冒犯到（</p>
<p>冬天手洗衣服会困难很多，冬衣一盆只能洗下一件，水也很冷，要戴橡胶手套，洗一次衣服要耗费不少心力。但我恐怕还是永远不会用楼里的公用洗衣机...今天洗了好几盆衣服，站在水池边上重复着搓洗的姿势，感觉像罚站一样。然后想起来了
EVA TV 版里明日香的一段话（是的我还真的去找了，在 22 话）：</p>
<blockquote>
<p>美里和笨蛋真嗣用过了的热水，谁会走进去啊？
被美里和笨蛋真嗣洗过内衣的洗衣机，谁会来用的啊？
美里和笨蛋真嗣用过的洗手间，谁会坐啊？
美里和笨蛋真嗣呼吸过的空气，谁会来呼吸啊？
讨厌美里，也讨厌真嗣，我更加讨厌第一适合者！
讨厌爸爸，也讨厌妈妈，但最讨厌的便是自己！</p>
</blockquote>
<p>我的洁癖倒还没有到精神崩坏的程度（，但感觉也是分两方面的。</p>
<p>其一是对“卫生”的标准问题，还比较表象。我自觉自己对卫生的要求算是很高的，也是从小受母亲的影响，慢慢养成的各种习惯。就像进出洗手间会多带一张纸，用来包一下门把手和冲水的按钮，就像室友洗杯子就是在水龙头上冲一下，我要拿洗洁精洗，洗完再用饮水机的热水烫一下，就像在教室自习的时候坐下之前会拿张纸简单擦一下桌子，等等等等。以前有个朋友说我矫情，不过后来他就不是我的朋友了（笑）（倒不是因为他说了这句话，而是别的矛盾（（</p>
<p>其二是心理方面的。比如说，我在寝室里总是感觉很局促，最近越发这么觉得。身后的室友换衣服或者找东西的时候，喜欢把椅子推得很远，于是我和她之间的过道会变得很窄，甚至她搭在椅子背上的衣服会碰到我的椅子。这个时候我就很难受，会想到她的衣服在公共洗衣机里洗过又拿出来感觉不是很干净。另一个室友从前有一次晾衣服的时候，把拿不下的衣架放在了我桌上（因为我的位置离阳台很近），然后我就去买了两块桌帘把自己的桌子围了起来（其实也早就想这么干了，只是那也是一个这样做的契机）。因为感觉她的衣服在公共洗衣机里洗，又要挂在衣架上，好像也不是很干净...天啊怎么对公共洗衣机怨念这么大。</p>
<p>而且这似乎也是一个亲疏的问题。我向来想要保持和世界保持距离的状态，不喜欢不熟悉的人碰到我，我的衣服，我的东西，我总感觉“不是很干净”，平时也尽量不会碰到别人的东西。但想了想友人在隔壁也一样把衣服放进洗衣机里洗，我和她见面也还是会亲亲热热地打闹，也会拉她的衣袖和手<del>（首先，我不是女酮（</del>，感觉矛盾起来了。</p>
<p>但话说回来，和室友倒也不是特别疏远，对于寝室里和我关系最好的室友，我也还是不愿意和她、她的物品有物理上的接触。不过她也很尊重我的习惯，还蛮感谢的。但是想起来社聚的时候我也把自己的耳环（其实是耳夹啦，不敢打耳洞
= =）摘下来给好奇的社友把玩过，还分着吃了月饼（当然是掰着分的 =
=），却感觉很开心。是因为寝室对我来说是一个“更加私人，所以更需要保持洁净”的地方，还是因为和室友生活在一起，知道她们的生活习惯所以排斥？有点难说。</p>
<p>这么听起来好像确实挺矫情的...草，感觉有概率会被喷。虽然这么说的话听起来很奇怪好像有点严重，但其实也还没到影响生活的程度（，一般遇到类似的情况都还是往自己身上找问题，会想“为什么我要把东西放在室友不小心会碰到的地方呢，下次要注意点”这样，稍微有点内耗，不过问题不大。</p></li>
</ul>
<h1 id="月17日">11月17日</h1>
<ul>
<li><p>重新看了一眼昨晚的碎碎念，有点草，感觉这么形容之后自己看起来好像很难接近的样子，那倒也不是（</p>
<p>仍然希望没有冒犯到大家，如果有的话，我还是再谢个罪吧（</p></li>
<li><p>早上和朋友闲聊，才知道高中的时候很看好的一对情侣分手了，大概是异地的原因。当然，这件事已经过去一个月了，但我今天才知道，或者应该说才过去了一个月我就知道了，已经很快了。身边很多人都在不停地
crush 和 break
up，吃瓜吃久了也多多少少会在某一对官宣之后就产生“他们会很长久”还是“不会很长久”的预感，虽然有这种预感似乎很罪恶，但还好我们都不是三体人。</p>
<p>然而他们分开的消息还是让我小小的惊讶了一下，我不解的根源在于，算来都至少五年了，五年的情意分开也这么容易吗？或者我还想知道的是，五年的情意在分开之后会带来多大的惯性？</p>
<p>我没什么可类比的，就反思了一下自己的人际关系。也就和老姐的关系最长久，大概认识了七年多了。顺带解释一句，虽然我这么叫她，但是没有血缘关系，只是
15
年的时候在网上认识的赛博朋友（草），她比我大一岁，也就这么叫了。一般来说和别人解释这个问题会很复杂，所以我会直接称呼她为姐姐，可以避免很多麻烦。其他线下也熟悉的朋友还没有超过五年的，友人还不到三年；认识
runzhi
倒是已经四年多了，却也算不上非常熟，仅限于数学同好（？），有过很多长期断联的时间。</p>
<p>虽然很不一样，但要我想象和老姐今后因为什么原因闹开，就不再联系了，我还是会认为不太可能。</p>
<p>想起来之前友人向我抱怨自己感情方面的情况，我只想说，这都是很幸福的烦恼。人似浮萍，来体验一下我这种三年后地理位置在哪里都不知道的生活，再体验一下每天脚不沾地忙各种破事，就会只有迷茫，不会对这种事上心了。另一部分内容我本来想说又没说，毕竟每次和别人讲自己家里的事情，总是会让对方愧疚提起了这个话题，又一顿道歉。实际上从小的家庭环境确实让我对此无比悲观。悲观之后就会想开，怎么样都无所谓啦，有猫有狗就行。</p>
<p>又想起来高考完之后，老姐给我的礼物里面夹的纸条，上面写，“驰雨小姐自由如风”，当然是祝愿。让我想到上一个叫我
xx 小姐的还是 ex <del>这个
b</del>，当初还觉得很浪漫，乐死。然而如今想想，自由如风的另一层意思，恐怕是漂泊和无牵无挂。</p></li>
<li><p>说到这里，打算周六考完试去把给老姐的礼物寄出去，倒也没什么大件，就是日常积攒的一些小东西，像之前去古北水镇买的兔儿爷泥塑，去故宫买的香膏和书签一类的东西，等等等等。把日常攒成一个小箱子之后，再写几张明信片附在里面寄给她，她也同样会这么做。小时候是互相写信，贴上邮票等邮政慢悠悠地走，虽然寄丢过一次。现在是用快递寄一些实体的东西，也很令人开心。</p>
<p>箱子已经满了一阵子了，一直在我桌上放着。今天想到人似浮萍的说法，总觉得给她寄东西也寄不了几回，我就要离开这里去往不知道什么地方了，一阵凄凉。于是想着要赶快寄出去。</p></li>
</ul>
<h1 id="月18日">11月18日</h1>
<ul>
<li><p>很有必要提醒一下自己，早晨睡醒 /
午睡睡醒反正总之刚睡醒的时候，千万别急着回消息别急着看社交媒体，不知道迷迷糊糊的时候会说出什么
b 话，昨天也是今天也是，肠子悔青了</p></li>
<li><p>更离谱的是，我已经连着咕了两节抽代了，本来觉得也无所谓，出勤率有
30% 就不错了。咕了 5-3 的抽代之后来六教上 5-4,5-5
的统计推断，先是在六教的斜坡上迎面遇到婉璐姐姐，想起来我摆烂的初概<del>还有超松弛法矩阵</del>，不过她至少没认出我来。结果往前走了走又遇到了刚下课出来的
hx，我去，我觉得他至少脸熟我，还盯着我看了很久，真绷不住了。</p>
<p>下周二去上课的时候还是换件衣服吧（</p></li>
<li><p>无奖竞猜，这是哪里↓</p>
<p><img src="https://s2.loli.net/2022/11/18/lR46TBUkNmFOtgW.jpg" alt="8AB1E97D681A7340E830D856FCDEB1C2.jpg"></p>
<p>这是晚上的华子招生办（</p>
<p>其实我也不是很清楚这是不是招办，没做过招生工作。是从一教 104
的后门走出来的时候拍的，拿去骗到了好多人。室友猜工字厅，何老板猜是网图，友人问是不是深山老林里的古寺（，看来是氛围到位了。</p>
<p>右下角那个房间的屋顶看起来很独特，像日漫里的弓道场（？）不知道有没有机会进去看看是干什么的。</p></li>
<li><p>明天考工程经济学期中怎么办怎么办怎么办怎么办怎么办怎么办怎么办怎么办怎么办</p>
<p>当然是先学一会统计推断，再看一会番（</p>
<p>本来天气预报说是今晚下雨，于是吃完晚饭就回寝室了。把工程经济学的卷子拿出来，看了五秒钟，然后写了一会统计推断笔记，又打开了赛博朋克边缘行者（，其实已经很久没看过新番了，这部还挺戳我的。</p>
<p>可是明天考工程经济学期中怎么办怎么办怎么办怎么办怎么办怎么办怎么办怎么办怎么办（</p></li>
<li><blockquote>
<p>Data don't make any sense, we will have to resort to statistics.</p>
</blockquote>
<p>统推讲完了数据简化原理，这句话戳到我了（如果有看我统计推断那篇文章，会知道此处
statistics
指的是“统计量”而不是广泛的“统计”，所以其实是知识点哦（错乱</p></li>
</ul>
<h1 id="月19日">11月19日</h1>
<ul>
<li><p>工程经济学寄了，但好像相比别人也不算完全寄，不管了。</p></li>
<li><p>去刷了一下 Mili 从 Iron Lotus
之后的作品，感觉风格都差不多，没有特别喜欢的...，收藏了一首 Dandelion
Girls, Dandelion Boys，但是之后可能也不太会再听。</p>
<p>早期有很多（我认为的）神曲，印象最深的是幾年月，Nine Point
Eight，Vitamins，Cerebrite（入坑作x）和 world.execute(me) 这些。Mili
的歌词一贯都是在讲故事，几乎不会一句唱好几遍，但是早期的曲风相当多变，抓耳的也很多，这种感觉从
Millennium Mother 这张专之后几乎就没有了。</p>
<p>Iron Lotus 不错，开始进行一个单曲循环x</p>
<blockquote>
<p>Without you I could never be</p>
<p>So sincerely thank you for everything</p>
<p>It pains me to think</p>
</blockquote></li>
<li><p>我的学业导师（土水学院的）跟我聊了很久，中心思想就是——我这样全然不顾物理课，真的有可能延毕</p>
<p>但是没办法，这学期进行到这里，我感到很焦虑。我唯一的愿望就是好好地完成每一门数学学习，无论是抽代还是统推还是数值分析，甚至回溯一下初概并往高等概率论过渡，或者着手做
SRT，对我来说都比那个什么工程力学更有价值。工程力学从开学到现在，作业全靠抄何老板的先交上，只等着“某个周末有空了补一下”，可是没有一个周末能有空留给它。我深知如果拖着它这样下去必定什么都做不好，于是就退了。说起来这个
SRT （对我来说）还是有点难度的，找了一下发现是把 <a href="https://www.kaggle.com/datasets/shivamb/real-or-fake-fake-jobposting-prediction">Kaggle
上的一个题</a>搬过来了。老师比较 nice，至少没有在学期中 push 大家。</p>
<p>这样，这学期我落下了 8 学分专业课，包括 4 学分的基物，2
学分的工程力学，还有意料之外的 2
学分实验。实验倒不是问题，退课是遇到了给分巨烂的意外，且没有沉没成本，下学期或者明年这时候就可以补上。所以实际上有
6 学分会堆到未来。下个学期我还会推掉 5 学分的基物，不知道会不会退 3
学分的数学物理方法；大三上学期要把工程力学的 2
学分补上，但有可能又要推掉 3 分流体力学或者 4
分工程力学进阶，大四上学期还有 4
分量子力学...真的太好笑了，土水专业居然要学量子力学。</p>
<p>大三下学期会稍好一点，数学基础课除了实分析就都上完了，可能会去补一门基物。但无论怎么算，总是要有至少
3 门物理课放在大四上学期完成，即使目标只是
Pass，也依旧很困难——我真的很讨厌物理（如果有物理系的朋友读到，真的不好意思（。而且一旦
Failure，我去，我不好说。当初如果不是为了读数学专业，我早就去学文科了，那样的话高考怕是真能上线，何苦被困在这里。（然而家里没钱读什么文科，还是会很挣扎罢x</p>
<p>说实话，我自己真的觉得延毕没什么不好，这就和降转一样从容了。可惜我妈肯定会应激（，后面本来还有一段话，但被我删掉了。</p></li>
</ul>
<h1 id="月20日">11月20日</h1>
<ul>
<li><p>写统推写到
04:50，绷不住睡觉了。本来不打算同步昨天的日记了，刷牙的时候脑补了一下，是否会有朋友看我一天没更新以为我猝死了，草，还是更一下的好。</p>
<p>建构定理解决问题的过程很有意思，但我现在是越来越讨厌做题。然而技巧的提升是必要的，所以还得做，唉。</p></li>
<li><p>今天又一次自动审批从西门出去，在中关村北大街上呼吸了一会，回来就收到了封校通知，草。</p>
<p>下周四我是真的有一趟就医，是八个月之前约的 HPV
九价疫苗，竟然八个月就排上了，感觉北京算很快了。要去顺义，祈祷那边不要封，以及祈祷院系的直男老师（非贬义x）们不要以为这是一件非必要的事情（，并已经做好了回来就被通知隔离的准备。<del>去近春园或者紫光大厦住单间不比和室友住一起爽多了</del></p>
<p>从西门回来的时候遇到一只小黑猫，本来想给它拍个照，结果窜出来一只狸花把它打了，有幸拍到了全过程。小黑猫需要法律援助的话可以联系我（不是（顺序是从右下角开始顺时针观看，手机自带的拼图愣是没有调换顺序的选项，我淦</p>
<p><img src="https://s2.loli.net/2022/11/20/yLDf1pwZNPXg67R.jpg" alt="AAC17794A9BCEDF8AD890E8F8E2FBF7A.jpg"></p></li>
<li><p>刚写完上一条，我室友就被隔离了。她为了 SRT
去李兆基做实验，结果李兆基封楼了，草（</p>
<p>顺便吐槽一句，感觉她那个导师挺逆天的，开了好几个 SRT
招了几十个本科生进去给博士生打下手，还要求每周投入时间不得小于
10h，进实验室要打卡计时什么的，这就是生化环材吗x。相比之下我导师真是仁慈，不停强调学业为主，每周啥也不干都行，大不了寒假再做。</p></li>
</ul>
<h1 id="月21日">11月21日</h1>
<ul>
<li><p>昨天刚说周四要出校一趟，今天紫四就封了。本来封的这个点我应该在上课，结果早课被我翘了，就被封了，好似。</p>
<p>昨晚失眠睡不着，翻来覆去到六点钟才睡，十点不到就被室友喊起来说封楼了，草。实际上我们都翘了课，所以正好在宿舍里被封；另一个室友昨晚就因为热爱科研住进了紫光，还有一位早晨上课去了，流落在外盘算了一天要不要跑路回家（是百京人</p>
<p>今天解封之前也实在无心学习，一则睡得太少了，根本集中不了注意力，二则第一次封楼，又戒备又迷茫。于是和室友一起在宿舍里扯皮了半天，甚至久违地打开了朋友圈刷了刷其他被封同学的情况，不过看了一会觉得还是老样子，又光速关上了（</p></li>
<li><p>十混一重新检都是阴性了，也解封了，仿佛除了给我带来生活失序外，没有对华子产生任何影响，渺小啊</p></li>
<li><p>本来以为封楼会有上门核酸，结果并没有，解封了之后还得自己去做一天一检，华子从不让我失望。盘算了一下，今晚六点到十点的紫荆篮球场人流量可能类似于一个
U-quadratic
distribution（x），于是八点左右去的，确实人不多。统计推断大胜利（不是</p></li>
<li><p>看了一眼工程经济学出分了，瞄了一眼答案，上来 10 道判断题错了 4
道，别的地方一分没扣，真的离谱，不愧是我。不过分数也还可以，期末只要不大寄就没事。<del>除非这老师也给
85 分 2.3，90 分 3.3</del></p></li>
</ul>
<h1 id="月22日">11月22日</h1>
<ul>
<li>停滞不前</li>
</ul>
<h1 id="月23日">11月23日</h1>
<ul>
<li><p>我为上周抽代作业里不会的题破防了整整一天一夜，无数次怀疑自己这个水平是不是后半学期要寄了，最后才知道是把差集
<span class="math inline">\(R-P\)</span>
当成了环上类似于环理想的加法的逆运算。我真的，我甚至还给它定义了半天这个运算是怎么一回事，怎么调整才良定义（没调出来），最后才意识到居然是差集，那写成
<span class="math inline">\(R \backslash P\)</span> 不好吗（</p>
<p>看来是我离散水平不行，总之还是寄。</p></li>
<li><p>统计推断是后半期唯一一门我打算线下全勤的课，结果老师封小区里了（</p>
<p>下午纠结了半天还是决定出门去三教找个教室上网课，常去的教室就 3203 和
3303 空着。本来打算去 3203，走到门口看到里面只有一对情侣在聊天（，就去了
3303。结果遇到了欧老师，很久没见了，蛮巧的。不过果然这种情况下基本上都是别人叫住我，不然我好像不会特地去看周围的人长啥样（x</p>
<p>单人行动久了总会有和世界逐渐脱节的感觉，在线下遇到熟悉的朋友还是很令人开心的。</p></li>
<li><p>最近的破事感觉必须列个单子才能来得及做完且不遗漏了：</p>
<blockquote>
<ul>
<li>√ 写完抽代上周作业</li>
<li>√ 补上周课堂内容的 huixiangdou</li>
<li>√ 抽代本周进度 + 作业</li>
<li>√ 统计推断上周作业有个题可能还要再改改</li>
<li>大数定律，中心极限之类的问题再回顾下，下周统推期中了</li>
<li>准备个微雕的统推期中
cheatsheet，其实可以直接删改一下然后缩印博客文章（</li>
<li>√ 统计推断这周的内容 &amp; 作业</li>
<li>√ 把离散二倍速放完，作业随手写了</li>
<li>√ 周四打九价
hpv，据说很疼，但友人封着出不来只能自己去了，希望不要昏在半路</li>
<li>√ 工程经济学小班课的作业</li>
<li>√ 周五之前登选课系统把工程力学退了，这课必退无疑但是上周还在蹲
PF，乐</li>
<li>周末数值分析抄书，写作业</li>
<li>工程经济学最后一次纸笔作业</li>
<li>工艺美术史期末的 cheatsheet，题目已发，可以准备了</li>
</ul>
</blockquote></li>
<li><p>睡前听说何老板脱单了，他知道我不看朋友圈，特地在官宣前来告诉我了一声（？？），以及明天是他的生日。蛮好的，虽然我这时只是想起他也是要出国的，不知道到底是已经确认了和对方能有未来，还是一时上头（。倘若是前者，那在概率上更是一件值得祝贺的事情。<del>（虽然我很怀疑是后者（</del></p>
<p>然后想起来之前在紫四楼下遇到他在等人，封楼的时候他问我四层什么情况（而不是问我什么情况，屑同学
x），甚至上学期问他实验报告写了没的时候他说正在写，结果我 10 min
后出门做核酸遇到他和一个女生走在一起，等等。诸如此类的事情总是有迹可循，感叹我自己虽然记性好，但到底还是不够敏锐，何尝不是一种缺点。</p>
<p>草，怎么听起来像是败犬发言，其实就是普通朋友，甚至如果冷漠一点的话，应该叫做“同学”。</p></li>
</ul>
<h1 id="月24日">11月24日</h1>
<ul>
<li><p>去打了第一针九价，就，我姐之前恐吓我半天她打完之后的副作用，包括并不限于发烧头痛恶心
blahblah，结果我打完除了胳膊有点酸（感觉是扎一针之后的正常现象）之外就没什么感觉了（</p>
<p>我这个孱弱的身体素质，在（或许有必要的时候）倒还挺值得信赖的（</p></li>
<li><p>ddl 要爆了，而我还在不紧不慢地摸鱼，这不对吧（</p></li>
<li><blockquote>
<p>为什么会这样呢？我很难形容在肉眼可见的将来要失去一个好朋友的感觉，还阻止不了。</p>
</blockquote></li>
</ul>
<h1 id="月25日">11月25日</h1>
<ul>
<li><p>晚上 SRT 线上开周会：</p>
<p>这周你做什么了？什么都没做。你做什么了？什么都没做。你做什么了？什么都没做。好，散会（</p>
<p>我估计至少我自己持续到学期结束都会是这个状态了，哪有空管这些事啊（（</p></li>
<li><p>草，何宝不是说抽代课会有助教组织线下上课来着吗，我下午冲到教室，怎么就六个人，怎么助教都没来啊（。我才不会承认我是想看微信头像照片看起来很帅的助教才特地去教室的，所以他为什么不来啊（悲（好变态</p>
<p>虽然但是，<del>蛞蝓</del>扩域好抽象，一遍看不太懂了x</p></li>
<li><p>貌似可以回家了，上学期我跃跃欲试，这学期我希望室友能不能早点走（草好阴暗</p>
<p>北京的冬天更舒服一点，没必要回去，除了室内外温差有点大，刚进楼的时候很热之外，一切都还不错。想起来上海连绵的冬雨，总是有各种不太开心的回忆。印象很深的是高中时候的一次圣诞节，回家的路上雨水灌进了鞋子，好冷（。况且还没有看到北京的初雪啊，不急着回（</p></li>
<li><p>给大家表演一个耳机线拧花（什么鬼</p>
<p><img src="https://s2.loli.net/2022/11/26/sZiroNqOuWyAM56.jpg" alt="flower.jpg"></p></li>
</ul>
<h1 id="月26日">11月26日</h1>
<ul>
<li><p>虽然现在是 26 号，11 月似乎还有好几天，但是看到下周五要交的作业的
due 是 12 月 2 日的时候，还是比往常更深刻地感受到了时间的流逝（</p>
<p>据说现在不回家就跑不了了，稍微有点动摇，但目前还是不打算走。不知道为什么我甚至已经做好了在学校过年的准备（只是一个心理预期），为什么会这样呢，夏天的时候明明很乐意回家的来着。</p></li>
<li><p>月光长骑路过二教，旁边是周培源应用数学中心，停下来看了一眼。想起来之前还查过这个地方是干什么的，结果连个官网都没有，华子发的关于周培源中心的文章还是
20 年前的，离谱。里面的老师似乎也很少，我知道的就雍稳安（下学期开 PDE
的老师）和章梅荣（好像是室友以前的微积分老师），有点怪。</p>
<p>跟友人吐槽了一嘴，然后她问我怎么不直接冲进去问问里面是干啥的，我：？不社恐的人真恐怖，虽然也有一定道理</p></li>
<li><p>室友今天突然让我去树洞自搜一下（名字首字母），总之好无语（</p></li>
<li><p>补统推去了，最近的状态感觉就是快冬眠了</p></li>
</ul>
<h1 id="月27日">11月27日</h1>
<blockquote>
<p>因为享受着它的灿烂</p>
<p>因为忍受着它的腐烂</p>
<p>你说别追啊 又依依不舍</p>
<p>所以生命啊 它苦涩如歌</p>
</blockquote>
<p><img src="https://s2.loli.net/2022/11/27/VRXcaEruPMn9N7Q.jpg" alt="zijing.jpg"></p>
<h1 id="月28日">11月28日</h1>
<ul>
<li><p>连着通了两宵，其实今天凌晨熬夜做的事情本该放在周日的白天就做完，就是看一章数值分析然后写个作业罢了，时间上也绰绰有余。但很显然一天什么都没做，政治性抑郁的体验达到了最顶峰。昨天日记里一直在删删改改，到最后还是没更新出来，说过的话也全部删掉了。</p>
<p>虽然不断地告诉自己这样不好，但果然还是很难克制住这种心情。好好地把精力放到自己的生活上罢。</p></li>
<li><p>看我这个作息，不知道的还以为我是负责半夜做核酸样本检验的。</p></li>
<li><p>今天刷了一下 QQ 和微信，发现 MO 时期同班的一个 MOer
删了我的好友，嘛。其实也可以理解，当时一起交流题解交换讲义的同学，现在已经是陌生人了啊。</p>
<p>高中毕业之后（准确来说是收到录取通知书，回高中取到了档案，确认自己不会再回到这个地方之后），我就把绝大多数同学（包括上述这一位）迁移到了不常用的
QQ 账号或者微信上，还退了班群。从此用自己的 QQ
发癫就感觉舒适了很多（，列表里还有友人，我姐，runzhi，竞赛时认识的赛博同好（？？）们，和少数初高中阶段相处下来觉得还不错的同学。</p>
<p>我也不清楚为什么要这样做，但就是很想脱离那个让人不舒服的环境，以至于用了有点极端的方式。但其实要让我说这个环境哪里让人不舒服，我也说不上来，明明从自己的角度来看过得自闭又自在，却还是平等地毫无理由地不喜欢身边不熟悉的人们，<del>很难不怀疑是不是有什么心理问题</del>。其实现在比从前还要自闭，<del>倒没有类似的心理问题了</del>。强行解释的话，就是高中时候班级的概念还很强，在人群里自闭的感觉就和被孤立了一样（什么中二日漫剧情（，而现在不是这样，多数人不都是独行的么。</p>
<p>我妈之前还数落我不懂得积攒人脉，不能总是这样在大多数人面前表演一个原地失踪，还和我讲把谁删了都不能把去学医了的同学给删了，万一以后有需要还得找人家（噗。可能再过若干年我会发现她说的也对吧，但是果然还是不愿意那样。</p></li>
<li><p>尽管凌晨爆了两管阳性，又封了一栋楼，时至今日我还是不太想回家，甚至抱有一丝大不了寒假在学校里推
SRT，学学分析的想法。暑假在家待了三个月，躺得很爽，但确实啥也没干，倘若寒假回不去，至少在家时间的总和没有太大变化。</p></li>
<li><p>最近的想法又在改变了，主要是数值分析这课越到后来我越觉得学着很不爽，至少不太喜欢这个思维模式。又很难说清哪里出了问题，而统计推断渐入佳境，因此不是特别想考虑计算数学了。下学期看看能不能干脆删改一下，再挤一门统计学习导论进来（感觉要牺牲数物方法（</p></li>
</ul>
<h1 id="月29日">11月29日</h1>
<ul>
<li><p>马原再见，体育再见（（PF 了</p></li>
<li><p>看了眼考试周安排，抽代 16 周周六，其他三门都在 17
周的周末，又要坚守到考试周的最后一天晚上。不过比较硬的几门课考试时间上还挺松散的，蛮好。</p></li>
<li><p>怎么上海的同学基本都回家了，大家都好快，怎么就我还在这儿苟着（x</p></li>
<li><p>明天统推期中，希望人没事，睡了。其实更要希望的是今天紫四别有人混管阳了，那恐怕只能在寝室里考了，真的很难想象（</p></li>
</ul>
<h1 id="月30日">11月30日</h1>
<ul>
<li><p>十一月的最后一天，被封控了（</p>
<p>昨晚睡得早，早晨六点半左右不知怎么就醒了，嘴唇上感觉怪怪的，一摸裂了个小口子，问题不大。七点迷迷糊糊的时候楼道里广播响了，说楼里有人十混一阳，我超，我成预言家了。七点一刻左右广播说抗原阴性，于是想着大概问题不大，躺了一会直到八点左右才重新睡着，九点半再醒来的时候抗原已经阳了。</p>
<p>然后还是在宿舍考了统推。晚上八点半吃上饭，八点三刻就解封了，大概华子的隔离床位也真的快顶不住了。出门刷了个月光长骑，给我妈打了电话，回来之后看到好几对情侣冲出单元门拥抱，我的第一反应居然是，晚上不冷吗，不能明天白天再说吗（（</p></li>
<li><p>这统推考两个半小时，然而我不到一个小时就写完了，后一个半小时全在找计算错误，还真的找出来一堆。本来想提前点交了，结果给老师发消息之前正好意识到一个题有问题，草，真的危。</p>
<p>考的全是经典分布的性质，甚至矩法、MSE、多元 C-R Inequality
这些东西全都没考，所以没什么意思。不过也可以理解，太复杂的问题好像也不适合拿来考试，而且这课也没多少证明可做。</p></li>
<li><p>室友跑路了俩了，我把书和电脑都搬到其中一位的桌上开卷（x）了，感觉很爽。效率低下难道是桌上太乱了的原因吗（</p></li>
<li><p>首尾呼应一下（bushi），十一月北京没有下雪，印象里去年微积分期中的时候（大概
11 月 8
号左右？）就下了。然而看到南方都在飘雪了，南京上海武汉什么的，上海的第一场雪（虽然目测很小）很难得会这么早。是今年夏天大旱的原因罢？不是很懂，地理知识高考考完之后就全还给老师了
x</p>
<p>之前说留下来想看百京的初雪，结果不仅百京初雪遥遥无期，还错过了上海难得的雪，太亏了
x</p></li>
</ul>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇四·22年12月</title>
    <url>/2022/12/01/Diary-2022-12/</url>
    <content><![CDATA[<p>好冷好冷好冷好冷好冷好冷好冷（</p>
<span id="more"></span>
<h1 id="月1日">12月1日</h1>
<ul>
<li><p>十二月的第一天，又被封控了（。这次只封了宿舍楼三分之一的区域，居然还没躲过。</p>
<p>抱着乐子人的心态起床洗漱，看到有封控区的人拉着箱子闯过楼里的警戒线，从别的单元门走了，大概是定好今天返乡的。与此同时，楼群里还有人在问订了今天下午的车票走不了了怎么办，笑死，你猜怎么办（</p></li>
<li><p>偶然得到了一份早年数学系统计推断的期中题，看了一眼前半期确实在复习概率论（，涉及数理统计的就一点点
statistic 的知识和 Delta
Method，这样的话在统计中心学好就没必要去重新上了。不过也有可能是早年卷子的原因，或许现在不一样了。</p>
<p>然后发现 V1ncent19 写的<a href="https://v1ncent19.github.io/SummaryNotes/">统辅课程知识概要</a>一直放在我的桌面上，昨天考前只顾着焦虑封楼去了，居然没看一眼。</p></li>
<li><p>今天和室友说好了不去做核酸，解封的时候都晚上六点多了，这栋破楼现在本来就够危的了，实在不想去综体。</p>
<p>让我看看几天不做核酸会有人找上门.jpg</p></li>
<li><p>友人告诉我二附中有个<del>升级人</del>学妹选上了丘班，给我发了推送。打开看了一眼：</p>
<p><img src="https://s2.loli.net/2022/12/01/hVPNieoJlQj8GLn.jpg" alt="E7C0EBA17270713133741BACC4DC371A.jpg"></p>
<p>《并不算早》《小学二年级》</p>
<p>可能，可能确实不算早吧（，我的童年很幸福，不知道市区的学校是怎么养蛊的
x。但是这个属实给我一种，高中开始学竞赛已经半截入土了的感觉，很难形容（</p></li>
</ul>
<h1 id="月2日">12月2日</h1>
<ul>
<li><p>今天没封楼，去了趟教室。不仅完整听完了一节课，不用课后返工，一天还做了之前三天的工作量（，感动死了。</p>
<p>遇到了欧老师
++，<del>坐在欧老师前面莫名有一种背后被班主任盯着的感觉然后抽代也做得比往常快很多</del>（什么啊草</p></li>
<li><p>晚上打算把几周没做的抽代 bonus
刷完，其实也没几道题。还是有点难的，主要问题是我现在感觉自己的基础摇摇欲坠（，扩域扩了好几天了还没太学会
&amp;
前学后忘，学环的后半部分的时候刚考完期中正好在摆，好像也没特别会（</p>
<p>放一个友人的名言在这里：</p>
<blockquote>
<p>感觉从哪里开始一片混沌了的时候，就不要继续往后学了，从头看一遍，虽然很有可能再看一遍也只能学会之前已经会了的东西（</p>
</blockquote></li>
<li><p>希望周末两天还能出门，毕竟数值分析还没学呢，马原论文也没写（</p></li>
</ul>
<h1 id="月3日">12月3日</h1>
<ul>
<li><p>凌晨两点饿了吃了点东西，算不算吃早饭？（</p></li>
<li><p>今天突然翻到了一些文章，是我高考之后的那个暑假，以及再往前的时间里写的东西。当时知道了一个可以印实体书的网站，只要自己排版就可以，于是兴致勃勃地把自己写过的青春疼痛文学（。）找出来排到了一起，还多写了很多篇。当然弄到一半就咕咕咕了，也幸亏没弄出来（</p>
<p>今天拿出来看的时候让我自己都震撼，感觉现在贫瘠的表达和从前不可同日而语。是什么时候失去的？不知道。</p>
<p>说都说了，放几张给大家当当乐子（</p>
<p><img src="https://s2.loli.net/2022/12/03/DtVrINfAX9j3TOa.png" alt="cover.png"></p>
<p><img src="https://s2.loli.net/2022/12/03/CVmJifqpR6F4aDe.png" alt="1.png"></p>
<p><img src="https://s2.loli.net/2022/12/03/9FA2ZjcM65ywVCn.png" alt="2.png"></p>
<p>实际上和 ex
分手已经过去三年了（，现在看这个古早青春疼痛文学好羞耻啊，码掉的内容更羞耻，草（</p>
<p><img src="https://s2.loli.net/2022/12/03/NJsFCXfKmax6hGy.png" alt="4.png"></p>
<p>这怎么比上一篇还羞耻？脑袋不清楚的时候写的东西是这样的</p>
<p><img src="https://s2.loli.net/2022/12/03/4YZk5g1OAsGv3Xp.png" alt="3.png"></p>
<p>为什么配图是华子的录取通知书？我搞不懂（</p></li>
<li><p>气氛都渲染到这儿了，想起来一件关于 ex
的事儿。大概是我高一寒假（2019
年初）的时候，他比我高一级，要去参加华子举办的一个创新冬令营什么的项目，交几万块钱去美国游学。据说有升学优惠，<del>但从结果上来看确是没有的。</del>印象里临行前吵过一架，还见过这个活动华子给每个人发的一件长款羽绒服，以及他说中耳炎还要坐飞机之类的事情。</p>
<p>有的时候我觉得记性好真不是一件好事，记得这些破事，又没有任何原因地就是忘不掉，真离谱。要说记性好似乎也不是特别好，昨天统推讲的东西现在就不记得了（x），我好像只对事件的记忆力稍好一些，除了翻黑历史之外完全没用的技能（</p>
<p>找到了<a href="https://www.admissions.tsinghua.edu.cn/info/1033/1182.htm">一份
2020
年的报名通知</a>，但看这个日程感觉当年肯定因为突发的疫情没有成行，之后就再也没有过了。</p>
<p>经过了这三年之后我现在想起来这件事，都觉得太遥远了。华子组织高中生出国游学，每个词听起来都似乎不太可能发生在我生活的这个星球上，但愿未来还能变回理所应当的范围。</p></li>
<li><p>统推期中出了，和预期差不多。看了看班级成绩样本的次序统计量（草），感觉也挺符合预期，不知道到期末能不能混个
A+（</p>
<p>刚开课的时候老师说统推是基础五件里最难的，但我反正觉得是比初概简单，也有意思多了。初概里面初等的技巧让我抓狂，有一种回到高中竞赛的时候最讨厌概率计数题的感觉。想起来印象很深刻的一件事，高一的时候，学校的一试周常练习里有一个插板法的计数题，我当时想了半天自己找规律（草）糊出来了。结果老师讲评的时候轻飘飘地说“小学奥数都讲过插板法了，这个不用讲了吧”，给我的震撼是全方位的。</p>
<p>后来就很不喜欢概率计数的题目，感觉联赛的这类题也和小奥没什么区别，一想到同龄人近十年前就掌握了我到当时也不知道的各种方法，就感觉太狡猾了。水平也菜，但高三联赛一试里的计数题是枚举法，倒也做对了，那次一试成绩很不错。这样的我现在居然打算去学统计了，令人感叹。</p></li>
</ul>
<h1 id="月4日">12月4日</h1>
<ul>
<li><p>一直想靠赖在学校里不回家、每天去教室自习什么的来保持一些秩序感。</p>
<p>今晚去开完组会之后也刷完了最后一次阳光长跑，又看到所有考试都要求线上，似乎不回家的理由又减少了两个。然而给我妈打电话的时候还是借
SRT
的实验需要在校做（笑死，虽然确实是这样没错，但是我根本还没开始）又拖延了一下，心里想的却是，考完试再回去罢。</p></li>
<li><p>晚上饿了，突然想起来 2020 CGMO
的时候，在鹰潭一中食堂吃到的上清豆腐，好想念，但是从没在别的地方见到过，呜呜。</p>
<p>跑到隔壁寝室问了当时也参赛了的同学一句，她说完全没印象了，怎么这样。</p>
<p>突然在想要不要寒假报个什么去鹰潭的实践（有吗），然后去吃口豆腐，一瞬间一口上清豆腐的价值居然超越了克服社恐的困难，草。最近总有一种“想做的事情不赶快去做之后就没机会了”的感觉在脑袋里回荡，不知道是什么意思（</p></li>
</ul>
<h1 id="月5日">12月5日</h1>
<ul>
<li><p>下午打起精神写了个统推作业，结果写完交了被告知所有的分位数要查表
/ 用 R 算出来，然而我全都写了符号就交了，还得返工，可恶啊（</p>
<p>况且我还不怎么会用 R，更不爽了。</p></li>
<li><p>吃完晚饭去七港九买了杯奶茶，感觉那边人好多，点了单之后对这个决定很后悔。想起来上次喝七港九是上个学期，在某门课上帮一个同学
de 了个
bug（虽然纯属期中考完闲得），后来他告诉我买了一杯奶茶放宿舍楼下作为感谢了，还挺开心的。</p>
<p>之后还交流过几次作业，不过结课后就再也没说过话了。感觉人和人之间的关系真的很脆弱（这又是什么结论，不仅要看认识时的动机（，而且似乎如果没有见面
/ 做同一件事 /
至少线上交流之类的事情连接在一起的话（好像这甚至只是必要条件），曾经有过的联系也会很快断开。越发觉得要珍惜当下的朋友啊（</p></li>
<li><p>晚上回寝室，室友问我还记不记得紫四前几次封楼的时候，解封了之后楼下有好多情侣贴贴（确实还记得，11
月 30
日的日记里还写了）。结果今晚听说有人疑似发烧了（虽然不是我们楼层的），因为她男朋友住
29 号楼（（</p>
<p>一边觉得相当不妙，一边又不想回去。不回家的理由要我说可以说出来很多，效率不高啊，好几个朋友也都还在校啊，在学校过年也没什么啦，之类的。但最本质的似乎还是没什么求生欲（，就像这段时间除了买了两管牙膏之外什么也没屯，很难为自己找到一个积极准备的动机。</p></li>
</ul>
<h1 id="月6日">12月6日</h1>
<ul>
<li><p>难得早起，难得在楼里有区域被封（虽然不包括我的寝室）之前润出了寝室，结果在三教逛了一圈，找不到一张平静的书桌（误），就回寝室了。</p>
<p>之前周二下午这个时间是有体育课的，从来没去自习过，现在体育场馆关门不上课了，才知道实际上也没地方可去（</p>
<p>于是今天可以预料地无事可记，就这样吧，卷抽代和数值去了。</p></li>
</ul>
<h1 id="月7日">12月7日</h1>
<ul>
<li><p>太魔幻了最近，从防疫到身边的各种事，唉不说了。</p>
<p>在寝室里暴躁了一晚上，最后室友劝我算了算了，还是想想办法怎么期末考的时候不要发烧比较好，草，这就是华子人的务实罢（</p></li>
<li><p>室友的电脑寄了，拿我的电脑码了一会，锐评要被我的 IDE
亮瞎了（，人类的悲欢并不相通。</p>
<p>其实是我散光，dark mode
的话就看不清了。近视快十年了，度数几乎没涨，散光却越来越厉害，怪事（</p></li>
<li><p>终于找到了三教小教室里最舒服的自习姿势，很难不想分享一下：</p>
<p><img src="https://s2.loli.net/2022/12/07/FuPexljAtUOZa9T.jpg" alt="DB3C927E507CB82D86BBE7E71ED673B7.jpg"></p>
<p>今天下午五小节网课，被迫带了充电线出门，到三教来仍然找不到一张平静的书桌（x），要么是情侣要么是结伴来自习的占着教室，都挺吵的。虽说有人推门进去的话可能就不会吵了，但说实话不太想尝试。看到旁边的小教室还有空的，虽然这个桌椅不舒服但也还是进去了。</p>
<p>这个椅子是从讲台前面推过来的，腰不大好，习惯坐软的椅子，所以比较喜欢三教
30
人容量的教室。桌子拼起来也差不多够用，唯一不好的地方是中间拼起来的地方凹凸不平，不过书厚的话也问题不大。</p></li>
<li><p>以上三条呈倒叙关系（</p></li>
</ul>
<h1 id="月8日">12月8日</h1>
<ul>
<li><p>最近一直在流水账，我自己都有点难以忍受。写日记的初衷之一是日省，之二是表达想法。实际上前者现在不需要写也可以做到，甚至有演变成内耗的趋势。而最近有关大环境的想法相必人人都有，我也就不多说了，另外的（主要是家里的）破事也根本不可能简短地写完，更不可能发出来，何况这是一个我一直在回避细说的话题。</p>
<p>所以没话说就先把日记停了吧，应该不会很久。有兴趣蹲重新开更的话不用天天来看，不妨
RSS 订阅一下（懒得研究的话直接点<a href="https://follow.it/chiyuru">这个链接</a>就行，虽然我还没来得及在
follow.it
上确认作者身份；以及须知等我确认作者身份之后在后台能看到订阅者邮箱，介意的话可以换别的订阅平台
/
使用不常用邮箱）。本来一直不打算开这个功能的（可是为什么呢，好像也没什么理由），现在还是开了。</p>
<p>我怎么看起来情绪不是很稳定的样子（，三次元里不是这样的，向赛博朋友们道个歉（（</p></li>
</ul>
<h1 id="月10日">12月10日</h1>
<p>不是又开始写了，是因为交换申请的事情 emo 了（</p>
<blockquote>
<p>这两天在认真思考一个听起来很奇怪的问题：为了交换延毕一年是值得的吗？</p>
<p>已知：</p>
<ul>
<li><p>不考虑保研，打算申请；</p></li>
<li><p>我的培养方案太过稀烂 &amp;
本科期间不能转专业，近两个学期加上政治课每个学期都选不到 10
个学分的必限，全在修数学课准备跑路。交换的话又少一个学期，算了算无论是春季交换还是秋季交换，第八学期毕设都肯定开不了题；</p></li>
<li><p>我自己的培养方案是双学位，这样下去哪怕不交换也有概率修不完。不过大四的时候全身长满肝
&amp;
多数没用的课都仅以通过为目标的话，应该还是能毕业，以及申请应该也不看到时候的成绩了；</p></li>
<li><p>遗憾的是我很菜，GPA
绝对值看起来还可以，但在院系的排位比较抱歉，恐怕也申不到非常好的交换项目，不知道单纯为了提前护照到手（x）&amp;
增加一段海外经历而交换值不值得；
（其实今天看表格的时候感觉，我院分到的项目要么我不配申请，要么配不上我（暴论</p></li>
<li><p>延毕或许还可以带来一些别的好处，比如说我现在的数学基础像筛子一样就开始往后学了，再多学一年至少会好点。现在也还没开始嗑盐，多一年或许能多做一两段，etc；</p></li>
<li><p>没钱，不考虑其他需要自主申请的不免学费的交换项目。</p></li>
</ul>
</blockquote>
<p>本来以为这是个博弈问题，以为不知道年级里有多少人想申请，不知道大家会怎么填志愿，甚至还想填个
ETH，Cornell，南洋理工什么的口嗨一下。晚上室友告诉我其实大家的选择都在院系发的共享文档里，<del>看了一眼
ETH
肯定是没戏了</del>，感觉把目标定在曼大或者滑大是比较合适的，更倾向曼大，因为在春季。本来觉得莱斯也可以考虑，看了一眼在德州，算了（</p>
<p>其实如果有法国的项目是最好的，去法国学数学本来就是个很妙的决定，我甚至还会点法语（单指学了两学期二外，再学学可能勉强能过法语四级，现在记得多少也是另一回事）。可惜今年巴黎高师什么的都没有交换项目，不然就不用纠结了，我一定选这个。</p>
<p>问了友人一句北大有没有交换项目，她说不知道，没关心。不知道为什么突然又
emo 了。</p>
<p>几个月前我还不太能懂“我将孤单而度过一生”，会想世界很大，一定有某个人在或远或近的地方等着告诉我“我等你很久了”，假设没有，也不是一件非常值得在意的事。如今我才知道这种不关心是因为，远方的爱人是虚无的，把视线落到身边的朋友身上才能体会到难过。最近我时不时会想站在上帝视角看到朋友们的安稳人生，这两年按部就班地完成培养方案，上课考试，跟着院系的大流磕盐，然后选一个导师轻轻松松地保研，再建设自己的家庭，人生就这么顺利地按照预设的也是令自己满意的轨道进行下去，是一件相当幸福的事情。后来猛地一惊，发现自己实在是沉溺在自己的世界里太久了，这种简单幸福的生活明明属于这个学校里的大多数人，我才是与我的朋友们不同的那一个。不过还算清醒的一点是我知道，任何人所拥有的这样的安稳都不值得为我而改变，我将孤独而度过一生——这是其中的一部分含义罢。</p>
<p>话说回来我又有什么资格随便把人家的生活概括为“平静”，“幸福”，这不还是很傲慢吗。只是他人生命中的暗流不全为我所知，而我关注的又是他们觉得理所当然的部分。突然又想到以前写的这一段话：</p>
<blockquote>
<p>我想我也不是很绝望。楼下的女人和男人开始争吵了起来，这是意料之中的事情——我也会和我的母亲吵起来，因我在这里碌碌无为坐了这么久。如果人生沿途风景秀丽，那么死亡也并不可怕，然而现实给予的往往恰如其分，令人无话可说。把实践作为真理的理想也是很好的，乐观积极昂扬的一生。人生在适当的时候做出选择也是极好的，明智无悔。沉浸在日常的幸福里，睁大眼睛去看一切也是很好的，及时行乐，盲目无知但无可辩驳的一生。尼采说要高蹈着前行，我说伊卡洛斯飞不远。木心说艺术就是一切，我说它只是遮羞布。一切一切的理想在我来看都是欺骗，是仓皇人生面前的金碧辉煌的童话。这些意义和价值存在一天，人们就长醉不复醒一天，因为梦就是梦，而现实不为始终在做梦的人所知，他以为自己不该死亡，层见错出的痛苦也是不应当有的。</p>
</blockquote>
<p>emo 完之后看看自己说的话，啧，不就出个国吗，矫情什么（</p>
<p>UPD：最后一志愿填了 2024 春季的东大（实际是 4-7
月），二志愿不知道填啥就填了墨尔本大学，也是春季。实际上如果东大申不上我可能就不去了，所以有点乱填的意思。虽然院系里只有一个人和我争东大的名额，还是有点虚的。</p>
<p>虽然交换这个东西是铁没用的，尤其我选了东大，更没用了，反而一堆问题。包括并不限于短期考不出
N1
证书只能上研究生课（挑了半天没看到太多特别好的课），华子这边铁要延毕，影响春研暑研（但是都延毕了的话可能也不算很大的问题）。现在暂且想用出逃和延毕来逃避目前发生的事情，也想着还有很多个反悔的选项，毕竟没上飞机什么都还好说（</p>
<p>不过选东大的话其实，真要去的话我自己差不多能用存款 cover
全程（从考托福一直到买机票回国）的费用（除去最近社工发的补贴，其余竟还是高考完家教的剩余），顺便
push 一下自己赶快把语言成绩考出来，目前来看一切都还好..</p>
<p><del>为什么朋友们都劝我快去东大然后帮他们代购专辑周边啊！</del></p>
<p>UPD 2：笑死，东大和墨大的名额都没拿到。</p>
<p>其实我感觉凡是在这个院系里争取什么东西，哪怕觉得十拿九稳，也从来没顺利过。奖学金也是，交换申请也是，哪怕事实上自己的数值就是碾压别人，哪怕竞争者只有一个，也还是拿不到，真的有点奇怪呢。与我完全相反的是何老板，虽然我觉得他并不强（对不起但是我真的这么觉得，这是可以说的吗），但就是能在这些事情上一路顺利。性格决定命运（不是</p>
<p>真说不在意也有点假，毕竟失去了一个延毕的好理由和平价旅游的机会，而春研暑研的目的地也不再可能是日本了。</p>
<p>几天前 zcy
学长看完日记和我说不要去交换，看他评价自己说“我觉得这么久了，我已经是个完全不同的人了。先后两年心思已经收敛，很多东西以前觉得有意思，也许可以玩玩，后来发觉其实我有明确的主线，根本不想沾染”。</p>
<p>我深深地觉得自己至今也没能明确主线，甚至怀疑我自己就是一个爱好
wandering 的人。</p>
<p>仅仅是确定方向，我就花了一年半的时间。从想润 CS
开始发现学不会，虽然现在想想绝对是入门的姿势有问题，郑莉的 C++
我劝所有人都别上，不过我也自认为不是很有工程思维的人，早些放弃至少减少了沉没成本。然后逃避去了
DS，但苦于 DS
找工的潜力实在有限（尤其国内），我又对金融非常排斥，纠结了很长一段时间。这时候发现了统计学科（当时指的是统计中心这种类似工科的应用型统计），虽然当时的认识不够准确，还被一位数学系的老学长批评过，但我现在深深感谢他没有让我一直当名词党，不然太可怕了。从这个时候开始发现自己不得不出国了，无论是隔壁数院还是华子数学系还是求真还是统计中心，跨保到合适的方向都十分困难，身为走过的省份还不如别人去过的国家多的小镇做题家又
emo
了很久。不过真的开始准备追求学术之后又觉得出国是不错的选择，现在只会为
settle down
遥不可及而感到可惜，没有以前那么痛苦了。后来按照学长的建议试着学习困难的数学，才意识到还有很多应数的分支。又因为初概出师不利，还在计算数学和统计之间举棋不定了一阵子，甚至还想过要不要再去了解一下运筹学和控制论。直到觉得数值分析寡淡无味，而统计推断更合我的审美（？），又名词党式地看了一些非参数检验和贝叶斯学派的东西，感觉很美妙，才在后半学期终于收敛到了统计，也有了一些认识上的更新。包括更倾向于统计理论，而不是生统这种偏应用型的方向了什么的。</p>
<p>但事实上统计理论（其实计算数学理论也一样）的发展已经日趋成熟，搞不好未来还要继续变化，混不下去了折腾半天又回到应用（。除此之外这一年半没有做任何其他的准备，对磕盐仍然一片迷茫，连语言都没考没学（虽然准备一下也不费劲就是了（。</p>
<p>当然可以说这是一种成长，但我想想只觉得太艰难太费时间了。一年半以来计划从来赶不上变化，修了一些没必要的课，做了很多和未来没关系的事，有的甚至因为开了个头，现在还不得不继续做下去（说的就是你我的破
SRT，还有这个破离散还得期末考试，缓考算了）。每隔一阵子就会发现之前在做的事情失去了意义，斗志也因此磨灭了很多，会习惯性怀疑自己，这真的很可怕，也很令人难过。</p>
<p>Just lose it（</p>
<h1 id="月15日">12月15日</h1>
<ul>
<li><p>本来没啥事，看到抽代助教把作业批出来了，文件比交的时候大了一丢丢，就好奇地点进去看了一眼。</p>
<p><img src="https://s2.loli.net/2022/12/15/6FX2Ltb3OZQdqrN.jpg" alt="7D0127AA78480E52318E182619427884.jpg"></p>
<p>其实那次写了以前遗留的一堆 bonus 题，遇到一个用理想引入 Zariski
Topology
的题，但背景不够写不出来后一问，所以就证了一半，然后写了句话掩饰做不出来的尴尬（</p>
<p>我写的是“好酷！可惜我不懂
Topology”，虽然现在都不太记得是什么东西了，但印象里写证明的时候确实觉得很酷。</p>
<p>呜呜呜呜呜呜可惜助教可能都不知道我本科连转数的资格都没有（，更不知道各种原因导致以后要走统计，而这已经是我的倒数第二门代数课程了（</p></li>
<li><p>课咨委说是按工作量发了调研补贴，我也不知道为什么我除了开例会喝奶茶一共就做过一个推送，还给我发了最高那一档，乐得我规划了一晚上期末考完去江西找我姐玩的行程（草</p></li>
</ul>
<h1 id="月19日">12月19日</h1>
<ul>
<li><p>我的环和域到底学了个什么玩意？这课真的能过吗？</p>
<p>——观 PKU 抽代期末题有感</p>
<p>——观自己写前几节的抽代作业有感</p>
<p>——观 Galois 理论证明有感，定理证明我基本都写不出来的水平</p></li>
<li><p>坏了，我认识的人和目前还留校的人取交集的话，只剩下我和室友这一对共轭健康责任人还没感染过了（</p>
<p>室友锐评：有的时候都怀疑是因为我们俩的作息太阴间，醒着的时候奥密克戎要睡觉，感染不到。</p>
<p>晚饭感觉吃得有点油腻，加上很长一段时间以来为了期末前都不要阳，我除了睡醒了去食堂提个盒饭回寝室、下楼拿外卖之外都没有实质上地出过门，于是今晚打算去散个步，顺便散到七港九买杯奶茶。还蛮有仪式感的，我还特地卷了个头发，挑了耳饰和发夹才出门。</p>
<p>本来以为路上不会有什么人，可以在新民路中央横着走，没想到倒也没那么空旷，还是时不时有过路人的。我走位比较花，半路走着走着到了一个要么绕路，要么从苏世民旁边过去的境地。本来想心一横抄近道的，远远看到几个洋大人一边抽烟一边往我这边来了，遂放弃，赶紧跑。又不甘心绕路，就从路边的树林里钻进去了（</p>
<p>路上顺便给我妈打了个电话，我说我在饭后散步，她说你吃饱了撑的。那倒也没错。</p>
<p>提着奶茶回来的路上也不敢摘下口罩一边走一边喝，这次走了学堂路，工作日的晚上七点本来应该挤满了去上晚课的人，不禁想现在学校里人还少，还要为了期末考前的状态而躲人，下个学期会怎么度过呢？恢复正常了就躲不过，也没必要再这么躲下去了，甚至我就算这样自我隔离到期末，坐高铁回家的路上也十有八九要寄，就算不寄，寒假规划的几次近距离出游里也大概率会寄。</p>
<p>又想起来一直觉得使用“正常”这个词的时候应该谨慎些，“normal”里面到底含有一个“norm”，可以理解为标准、规矩，意味着一些有话语权的人制定了一个规则。这个规则被人们或主动或被动地认同后，符合规矩的才会被称之为“正常”。所以正常到底是哪种正常，至少我认为的正常是已经再也回不来了。</p></li>
</ul>
<h1 id="月20日">12月20日</h1>
<ul>
<li><p>姑妄言之，姑妄听之。</p></li>
<li><p>开始复习一学期都没听过课的中国工艺美术史（，虽然没听过课但我小测还一直分挺高的，毕竟是历史课（</p>
<p>看讲义看到元代的章节，里面讲蒙古人的传说里他们的祖先是“苍狼白鹿”，就是苍青色的狼和惨白色的鹿，于是人们很崇拜这两种颜色，元代青花瓷的风靡也和这种颜色崇拜有关。后半句听起来有点扯，查了一下好像苍狼白鹿之说也是明代译者对蒙古文的误读，原文是讲蒙古人的祖先是两个人，他们的名字在蒙语里的意思分别是苍狼和白鹿。但是这个说法听起来就很酷，很野性的感觉，比原文还酷（，所以流传得广也是有道理的吧（</p>
<p>（对不起我虽然自称文科生但我没文化，到现在才听说这个，轻喷 x</p></li>
<li><p>写数值分析的时候突然意识到，这门课上真的学了很多 Newton
创造的数值方法。我现在一边学理论一边写代码来复现计算方法、和理论互证，看到它可以投入应用，而
Newton 当初用的还真是纸和笔。</p>
<p>之前想定要转数的时候思考过很久关于数学研究（尤其纯数，虽然我不去x）有什么意义的问题，迷糊了很久是做理论还是做应用更有价值（虽然我能力有限，做哪个可能不是价值决定的（。尽管这个问题非常老套，也有很多答案了，但我自己还是不可避免地会想。竞赛的时候我天真地认为数学的意义就是纯粹地攀登人类智力的巅峰，是一种艺术，听起来非常美好。但长大后脱离了竞赛这一套游戏规则，我觉得这个理由是站不住脚的。比如很容易就能推翻这个想法的问题是，为什么还要给为了满足自己而做研究的数学家大笔经费呢。</p>
<p>另外一个中学时代听起来有点傻的困惑就是，怎么能创造出这么多数学理论的，你让我一个人在家憋着空想构造一个体系，哪怕是比较简单的，我也想不出来（当然我能力极其有限，Galois
就可以x）。甚至会因此而苦恼，觉得自己恐怕不是做理论的料（多少有点降智（。现实是不仅有暂时看起来没用的数学，其他许多理论的提出往往是一群人为了解决某一问题服务的，我还看不到意义，可能是因为在学习过时的（可能引起争议但我想不出来怎么形容
XD）课程而没能走到前沿去（还得看磕盐啊x</p>
<p>今天写 Newton-Cotes 公式笔记的时候，看到 Remark 里写到 <span class="math inline">\(n \geq 8\)</span> 的时候稳定性失去保障，<span class="math inline">\(n\)</span> 更高维的时候会发生 Runge
现象，因此在大规模计算中不会采用高阶 Newton-Cotes 公式进行数值积分。</p>
<p>Runge 是二十世纪的人，去世的时候都还没有计算机，谈不上科学计算，而
Runge 现象是 1901 年提出的；Newton
构造这个公式是为了纸笔计算某个积分的近似值的时候更加容易，服务于其他应用；教科书上紧随其后介绍的
Gauss 求积作为一个性质巨好的优化，和 Newton-Cotes
公式本质的思想差别也不大，重在对余项的修正，不注意的话还以为是过了十天半个月（x）就拍脑袋想出来的，实际上比
Newton 晚了一百年，但比 Runge
还是早一百多年。看起来很理所当然的一句性质，实际上是由很多后人整理起来的吧。突然意识到自己对数学细部的发展过程还是很缺乏认识，尽管这个例子也没有那么恰当。</p>
<p><del>第一次觉得 Yau 让求真学数学史也不是那么没意义</del></p>
<p>姑妄言之，姑妄听之（</p></li>
<li><p>我不会计算，我只是在算术.jpg</p></li>
<li><p>随手给博客改了个名，之前一直不知道叫什么，就直接拿 id
当了标题。</p>
<p>『姑妄言之姑妄听之』，非常符合实际情况。不知道会不会因为太长而被迫换行，万一发生了我就把这一条删掉，当做无事发生（</p>
<p>正好撑满，好耶！</p></li>
</ul>
<h1 id="月21日">12月21日</h1>
<ul>
<li><p>工艺美术史考完了期末，感觉良好，大部分靠
cheatsheet，小部分靠小时候东看西看积累的历史小知识推断。想起来小的时候胡乱想以后要做什么的时候考虑过读历史、中文或者法律，总之是觉得读文科很不错，没考虑过理工科呢。</p>
<p>下学期抢了一门人文课组的故宫学，我从大一开始就挺期待这门课，虽然听说讲得很无聊，但有个课上的时间读读书也不错。</p></li>
<li><p>华子这个楼内疫情防控真有点一言难尽，紫荆六个单元分别有一个卫生间，原本是按照阳性的同学单独使用就近的卫生间。结果现在阳的太多，改成阳性统一最短路径用三单元的卫生间，就在我寝室门口（</p>
<p>尝试在群里和一拍脑袋想出来这个主意的驻楼老师
argue，为啥不能改成一三五单元给就近的阳性用，二四六给其他人，这路径岂不是更短（，也不至于某一个地方气溶胶浓度特别高，大家风险共担。然后被无视了（。不知道是不是还有什么别的考虑，打算等他们明天上班再面对面问一下。</p>
<p>然后意识到实际上还是铁拳不砸到自己头上就不会刻意想着去反对的道理，虽然也人之常情，但多少还是有点莫名的愧疚，为曾经可能有过的事情。</p></li>
<li><p>找了一些双厨狂喜的怪图，感觉很适合放在之后整理的讲义末尾整活（</p>
<p><img src="https://s2.loli.net/2022/12/21/6IoqJymjuntP9b2.jpg" alt="QED.jpg"></p>
<p>我最喜欢的还是这张，是 FGO 某个亚种特异点章节通关之后的 CG。印象里
1.0 的特异点通关就直接显示圣杯，2.0 空想树通关 CG
都是“空想切除”，只有几个 1.5 亚种特异点的章节的通关 CG 是不一样的。</p>
<p>新宿章节是“证明完毕”，下总国章节是“一切完胜”，雅戈泰章节是“夜话团圆”，效果都很棒。可惜我玩的时候截的屏找不到了，就去
b 站找剧情视频截了一下图。另外两个分别是这样的：</p>
<p><img src="https://s2.loli.net/2022/12/21/6TEM1vSosXLcwOg.jpg" alt="HEA.jpg"></p>
<p><img src="https://s2.loli.net/2022/12/21/5MWHjG1ciV4Q7Xf.jpg" alt="GS.jpg"></p>
<p>这年头谁还玩 FGO 啊，哦原来是我（</p></li>
<li><p>写完了统推最后一讲的内容，感觉还有很多需要补充的东西，主要是实现和一些证明，还有一些我想要去了解的内容。导出了一下发现目前大概是
80 页左右，排版排得密实一点，删一些图，可能也差不多会有这么多。</p>
<p>预感最终会是一本不错的小册子，真期待啊。</p></li>
</ul>
<h1 id="月22日">12月22日</h1>
<ul>
<li><p>室友原定后天回家，今早起来说喉咙不舒服，晚上就 38°C 了（</p>
<p>我不知道我什么时候会开始发烧，只觉得抽代大概是复习不了或者考不了了，但明天的统推还是可以考罢。</p>
<p>晚上摸鱼翻了翻 b
站收藏夹，发现有一段时间非常爱看一人食量的做饭视频，虽然几乎没有下过厨，肯定会是炸厨房选手，从前还是很期待有朝一日独自生活的时候自己做饭吃。</p>
<p>又想了想虽然可以预料的是将来独自生活会成为常态，但好像从小到大还没有真正意义上独居过。要么住宿舍，要么走读，出省外培或者比赛也要么和家人一起，要么和同学拼房间，空间上自己一个人过夜就几乎没有过，还挺意外的。后天室友走后大概要住两周左右单人间，潜伏期长一些的话说不定跨年的时候会自己躺在床上发着烧跨（，第一次的独居生活怎么也没想到过会是这样的，令人感叹（</p>
<p>与此同时我妈在上海也阳了，当初回不回家现在结果也都是一样的，令人感叹
<span class="math inline">\(\times 2\)</span>（</p></li>
</ul>
<h1 id="月25日">12月25日</h1>
<ul>
<li><p>现在陷入了一个 dilemma——目前我还是没有症状，甚至我室友除了 22
号晚上发了烧之外后来也没有症状了，但抗原确实是阳的。我也不好说后面几天会不会再有症状。如果现在复习抽代，31
号不一定能正常考试，还耽误后面的科目；如果直接放弃抽代复习后面的，实际上又防护得好根本没有中招，就得缓考然后寒假继续学域论了，也好痛苦。实际上这两天光折腾搬寝室做清洁和根本没睡好觉，就耗了不少精力，没做什么事。</p>
<p>更草的是昨晚终于回到自己床上睡觉之后，梦到抽代期末又考了一堆群论，而且全是稀奇古怪的初等技巧，既熟悉又不熟悉，好崩溃（</p></li>
<li><p>给 wjd
老师写了封邮件想和她聊聊天，讲了一下自己打算整理一份讲义的计划（立 flag
防止咕咕），不过她一直未读，想了想也确实不该周末发邮件，等等吧。然后给统推讲义选了个封面（某些人期末周是真闲啊</p>
<p><img src="https://s2.loli.net/2022/12/24/F1xgu4lJOTrSiRk.jpg" alt="cover.jpg"></p>
<p>是高一的时候在学校破坏绿化的产物，花瓣上的水珠拍出来很漂亮。再一次在相册里翻到它的时候第一反应是朱熹（？没记错吧）写的『山桃落乎，辛夷开未』，但其实山桃就是桃花，辛夷是玉兰花苞，和樱花都没关系。</p>
<p>背后还有个小故事，和选这张图的原因（单纯觉得好看）没关系，讲出来给大家当乐子。高中的时候学校里有一大片樱花树，春天开花的时间大概有两周。高一那个春天我缠着
ex
晚自习下课陪我去看（现在想想多少有点毛病），他不理我，然后我自己摘了一捧樱花放在水里拍照给他看，他还是不理我（所以说不只我有毛病，他更有毛病）。（怎么
ex 小故事都听起来又惨又好笑</p>
<p>所以这就是那张照片。下面垫的本子是草稿本，翻出来的时候才发现封面的法语我已经能读懂了；再下面垫的大概是化学试卷，高考拖我后腿没进新雅的元凶（。说起来我觉得新雅真不错，还可以分流去学数学（x），考上的话是做梦也能笑醒的程度。室友说新疆高考前几名一般都会选新雅，但新雅貌似每年在上海的录取分数线都是最低的，甚至经常因为没人要而顺延给分数更低的同学。高中时候的一个同学就高考压线，在新雅和复旦经管之间选择了后者，大概是被“理科实验班”这个名字唬住，以及不愿意离开家吧。我当初想的倒是如果进不了华子就去中科大，总之不是很想再留在上海，不过最后还是被家长老师逼着用交大兜了底。当然胶带也很好，我每年寒假都和同学约去交大玩一天，但现在想想真的去
IEEE
或者致远的话恐怕也会很痛苦。但是本科可以转专业诶！可恶。不过想想我读过很多遍的<a href="https://survivesjtu.gitbook.io/survivesjtumanual/">《上海交通大学生存手册》</a>和迟先生的<a href="https://zhuanlan.zhihu.com/p/345269981">《与恶龙斗，其乐无穷》</a>，真进了世俗意义上非常成功的电院的话，还会有转出来的勇气吗？恐怕就在中游吊着，卷也不是躺也不是了。总之也很难说。</p>
<p>扯远了。我还是很喜欢花的。高二的春天在上网课，五月才复学，没看到学校里的花；高三的春天我就自己又去看了几次，折了两枝插在水杯的挂绳上，那张照片在<a href="https://chiyuru.github.io/2022/08/17/2022-photos-and-fragments/">这一篇</a>的倒数第二个一级标题里可以找到，花蕊偏绿色，应该不是樱花而是梨花。不过之后决然不会再回高中母校了，再也看不到了罢。大一的春天我在华子里薅了不少花瓣，夹成书签拼在一起，寄给了我姐，很有江南（？到底谁在江南）无所有，聊赠一枝春的感觉。</p></li>
<li><p>发现 hx 下学期开了一门 2
学分大水漫灌（说它水是因为看了一眼考卷，真的水）的初等数论，知道这个消息还是因为竞赛时候认识的几个来了华子的神下学期选了这门课水成绩。所以
hx
两个学期上的本科生课程估计都是没人听的，他要是一直就教这两门课，恐怕也不会改善教学质量了罢，令人感叹（</p>
<p>说到本科生教学的问题，今天给 wjd
老师发邮件的时候去统计中心官网确认她的邮箱，发现她的职称其实是讲师而不是助理教授，感觉在华子真的非常少见了。想起来她确实从来没说过自己搞科研或者带学生之类的事，倒是在课咨委听说过评教数据有效性判断的工作是她做的，大概还有为学校提供统计咨询之类的职责。dwl
老师也是讲师。<del>难怪她俩上课上得比我见过的大多数老师都好，</del>而且确实都是热爱教学，上课很有热情的类型。</p>
<p>实际上感受下来统计中心已经是非常重视本科生教学的单位了，珍惜罢。</p></li>
</ul>
<h1 id="月26日">12月26日</h1>
<p>Warning：今天是真的很碎又很长的碎碎念，有点
biased，个人体验为主，谨慎阅读。要喷的话也请轻点（</p>
<p>昨天说到《上海交通大学生存手册》，今天吃饭的时候又读了一遍。我第一次读这本小册子是大一的寒假，彼时九年义务教育时代从郊区卷到某个超级中学，和高三零基础速成高考的这十年时间给我留下了很强的做题家的肌肉记忆——高三的时候我还在知乎上自嘲力速双
A
做题家。顺着这个惯性，第一学期做题的热情还很高涨，在微积分线代和法语这三门稍微重一些的课里随手卷出了三个
A，让我产生了哪怕是华子的课业，也可以通过不断刷题练习轻松掌握，然后这四年就会这样在不断巩固基础之中过去，我学会了这一百多个学分的课程，就会摇身一变成为优秀的博士生预备役，这样的错觉。所以，当初这本小册子让我最震撼的是这一部分：</p>
<blockquote>
<p><strong>悲壮的学习方式</strong></p>
<p>古人刻苦学习的故事，直到现在还在我们的身边不断上演。据说每天在新、东上中下院和图书馆都有几千人在自习。学生趴在山一样高的习题集边上苦苦奋斗，绝对是我校作为国内一流大学的亮丽的风景线。挖空心思研究解题技巧的学生们，与同样挖空心思研究出题技巧的老师们，构成了一个完美的圆环。在二者日复一日的机械劳动中，我只看到纸张、电力，以及粮食不断被浪费，却看不到中华之崛起。</p>
<p>我无意全盘否定同学们吃苦耐劳的精神，但这份精神充其量只能称为悲壮。我们耗费了大量的时间和精力掌握的那些考点、技巧，在真正的知识殿堂里根本登不上大雅之堂。哪怕我们特征值求得再熟练，积分积得再复杂，中国的载人飞船也不会因此而顺利上天。</p>
<p>我手上一本1300页的数学手册，上面记录了人类文明从远古直到二十世纪后半叶的主要数学成果。而我校高等数学教材（上下册）所涵盖的内容，不超过其中的130页。一个真正有志于建造科学大厦的人，是不应抱着一块儿砖头精雕细琢的。</p>
<p>学习最需要的，不是悲壮的毅力，而是对无限未知的渴求。</p>
<p>最终来说，学习知识的目的是为后继的知识铺垫，以及培养创造性的思维。所谓有效率的学习，应当是以最高的效率获取知识，服务这两个目标。从现状来看，我们想要把什么都搞扎实的学习习惯，其效率是极端低下的，而在我们通过大量习题，最终扎实掌握的信息里，有效的“知识”却又是如此的少。</p>
<p>今天，你学了多少？</p>
</blockquote>
<p>22
年寒假偷渡进交大玩的时候，我还去东下院和包图朝圣了一下，观察了一下作者
2008
年记叙的这种悲壮的学习方式，到现在也还是一样的。当然这个观察毫无意义，毕竟华子里也是一样的，我现在每天也还是一样的。</p>
<p>现在想想，其实仅有的没当传统做题家的两年，要么在摆烂，要么又被竞赛带进了另一个做题的怪圈，弱者是这样的。学到的东西有些是奇技淫巧，有些是高阶知识在初等平面上的投影，对现在也没有太大用处，偶尔会心一笑而已。这学期抽代里面用
Eisenstein
判别法的时候，我只记得是高一看北大初等数论的时候看到过的一个判断多项式能否分解的定理，具体内容还得临时去查。其他东西也基本都忘得一干二净，只记得名词了。其他的获得大概就是认识了一些强度离谱的神，还有初步地完成了一些自我认识，这个是好事，虽然停留在比较浅薄的层面，但总比只学高考的话要好些。</p>
<p>之前看到隔壁数院一个校友写的一篇文章，大概说学习珠脑运算、鸡兔同笼，带给一个中国小孩最宝贵的礼物是自信。我想了想竞赛被爆踩的两年好像也没自信过，更加焦虑、自卑，焦虑到高二的联赛喜提省三倒数（。后期逐渐变成了摆烂乐子人，退役前的愿望只是能完成最后一场比赛就好。我最自信的时候反而是高三退役变回做题家，因为这个我太熟了，我之前做了九年的题，相信再做一年的话绝不会差。哪怕高三第一次月考考了两百多名（注：我们年级一共
350
个人，所以真的很草）也还是非常自信，老师一度觉得我乐观得脑子有问题（。竞赛方面仅有的成绩都是退役前的最后一个月出的，不值一提，拿到奖牌奖状的时候我也不是很在意了。真正的高光时刻可能是几次
ak，还有在场上切过几个得分率很低的题目，其实也没什么可说的，这些属于自己想起来的时候可以偷着乐（？）的范围。</p>
<p>同学之前给我看过求真升级人的报道，大一爆杀丘赛，速通代数几何之类的神话，问我转数压力是不是很大。我说一点都没有啊，我又不和他们一起上课。实际上我上数学课甚至会尽量避开数学系的同学选课，打不过数学系和求真，但暗中欺负一些数辅统辅的同学还是可以的（不是x，其实就是没那么有压力）。反正也不是第一次被爆踩，而且我润应数了，来自神的压迫感根本追不上我。最重要的是，learn
at my own pace
才有可能学好。说实话这是逃避没错，但我真的不是很喜欢时时刻刻都要竞争，人和人之间何必在学习阶段就非要互相为难..（一厢情愿而已，因为资源不足啊。而且什么时候都不要互相为难才好吧
= =）（开始暴论了</p>
<p>Anyway，填强基志愿的时候没怎么纠结，就因为学过竞赛而随便填了数学，非常方便。填平行志愿时我一心想离开，本来填的一志愿是中科大，最后还是拗不过家长老师不断和我强调这样浪费了
20
分、虽然强基综评基本稳上但还是要保底什么的，改成了交大。科大数学放到了二志愿，人大统计放到了第三志愿。实际上有点好笑的是，我高三的时候真的很一心只读圣贤书，根本不知道
CS
和金融很热门，直到出了分之后被按头报交大综评志愿，看往年的分段表才知道交大分数线最高的是
IEEE 和 AI，然后就对着表格从上往下依次填了
IEEE，AI，密院，理科试验班。</p>
<p>综评面试之前一个自称 IEEE
的什么招生老师还给我打过电话，有一种钦定的感觉（？），还不断强调我报的前两个是他们的“王牌专业”，我听到这个词也不是非常感兴趣。其实理论上这些信息应该校友宣讲的时候就知道了，<del>但交大那一场是
ex 讲的，被我咕了</del>。还有就是来华子之后实在学不会<del>这个 b</del>
物理，混不下去，思考转专业做研究转什么的时候有数学这个备选项，也很方便。不然我可能现在还在纠结以后要做什么。虽然一直都稀里糊涂的，时不时用脚投票，但总之最后发生的都是好事。</p>
<p>现在在 Yau 的驱动下，高中生超前学习数学似乎分成了两条路径，一是传统的
MO，二是基本以求真选拔为目标的、提前学习高等数学的升级途径。我记得上海取消初中数学竞赛之后，六年级（冷知识：上海的九年义务教育是五四制，六年级已经是初中了）的小朋友就不做初中竞赛题了，开始卷高中联赛，在不禁止初中生参加高中联赛的时代，被他们屠榜是很正常的现象，<del>还好我高一的时候就禁了</del>。所以现在最升级的六年级小朋友应该也是两条线一起准备的，令人感叹。</p>
<p>与此同时，今年暑假回了一趟我的初中母校，它是宝山区最好的学校，是全市排第三名的公办学校，不需要交学费。但实际上在市里根本没人听说过。在我读初中的时候学校里还有课外讨论班，老师会讲一些轻微超越课堂难度的知识，<del>我经常在课上稍微动下脑子就能表演薄纱所有人，很爽</del>。那位开数学讨论班的老师从前和我关系很好，这次回去他告诉我双减之后对公办学校抓得最严，连课外讨论班这种东西都已经没有了，除了学习课本，就是在“素质教育”——听起来有点像日本曾经的“宽松教育”。没有资源、资本和信息，然而十几公里外市区的孩子们就享受着这一切，要我暴论一句的话，我觉得郊区做题家的处境和小镇做题家一样艰难。</p>
<p>前阵子听说竞赛时耳熟能详的一个机构，假期要开分析系列讲座，为求真选拔做准备，突然有一种做题范围只是扩大了的感觉（。当然也还是不错的，能在中学阶段就被驱动着一窥前沿，至少知道
MO 之外还有很广阔的天地，比天天搁那一边猜联赛四个大题的顺序一边学
ACGN（x，指竞赛意义下的 Algebra / Combination / Geometry / Number
Theory）有用多了。虽然只要有升学优惠刺激就还是会收敛到做题，好在数学也不应该规避依靠做题提升技巧，至少做题掌握的知识对今后更有用了，这也是好的。每年牺牲两三个或许有那么一点希望的郊区做题家，换取集体升级，..大概还是很值得的吧。</p>
<p>写完之后发现每两段话之间都没有衔接关系，毫无逻辑..随便看看吧</p>
<h1 id="月27日">12月27日</h1>
<ul>
<li><p>我感觉大概是终于理解域论了，从头到尾走了一遍逻辑到处都通了，有点狂喜。但并不代表会做题了，为了考试还得进行一个拟合。</p>
<p>周六就考试了，这是否进度有点慢（</p></li>
<li><p>半个多月来一直摸鱼和阴间作息，肉体还在东八区，睡眠已经到东三区了。昨晚（今天凌晨？）干脆直接没睡，实际上是躺下了睡不着，就起来了。</p>
<p>已经很久没见过早上六点多是什么样子了，实际上天还没完全亮。看着外面黑乎乎的，上次冬天里起这么早大概还是高三，高中生真惨，还好我大二了（x</p>
<p>所以今晚可以早点睡了，然后就调整回来了吧。</p></li>
<li><p>喉咙很不舒服，感觉危。但是喝了一天热水吃了一板润喉糖就又好了，搞不清楚什么状况。</p>
<p>后来大概理解了，住单人间之后我经常一边听歌一边跟着鬼哭狼嚎（别细问，要脸，不好听），加上附近的寝室都没人，更加肆无忌惮了，大概是有点劳损。</p></li>
</ul>
<h1 id="月28日">12月28日</h1>
<ul>
<li><p>学完了域又回头学习了一下环论，这下终于明白之前多项式里看起来莫名其妙的定义有什么用了，高情商说的话就是，教材和课程设计都还有可以优化的空间（。</p>
<p>我又觉得我会了（</p>
<p>刚看完域论再回去看环定义的时候，有一种“世界上怎么还有环不是含恒等元的交换环”的感觉（恼</p>
<p>然后明天还得继续拟合近世代数 300 题，感觉 hx
很喜欢出一些不太抽象的题目，平时没怎么练习过。后天复习一下拟合过的题目，就要考试了。这本书买来一共做了两次，一次是期中之前找了几个题拟合，一次是期末之前再拟合一下。其余时间里连翻开看一眼的欲望都没有（难怪我做题这么菜
qwq</p>
<p>实际上细看觉得这书是对绿皮的一个挺好的辅助，一些绿皮上答案写得不好的练习题这本书上都有补充，另外也给了不少风格类似的题目。</p></li>
<li><p>听说明天 CMO，于是去给 runzhi
加了个油（？），才知道他还真的在现场，去年是考生，今年已经是招生志愿者了。甘主任也太成功了（</p></li>
</ul>
<h1 id="月29日">12月29日</h1>
<ul>
<li><p>听说假期常和友人聚会去吃的一家烤肉店要关店了，在上海一共四个门店，暑假里关了一个，年底又关了一个，不知道还能不能撑得下去。北京有一家，不过也好久没去过了，不知道现在怎样。</p>
<p>感觉到记忆的崩塌..</p></li>
<li><p>网易云说我一年听歌听了 2516 小时 50 分钟，也就是平均每天 7
个小时，真恐怖。特地打开朋友圈看了看，听得最多的人大概就是我的一半左右，其实也很多了，对听力不好。</p>
<p>不过实际上真的听进去的没那么多吧。大多数情况下是当
bgm，和白噪音没区别，习惯之后不听歌反而专注不了。平时走在路上也会戴耳机，虽然基本听不清在放什么，但是会有一种，虽然身在人流中，实际仍然蜷缩在自己的世界里的安全感呢。（注意交通安全啊
kora</p></li>
</ul>
<h1 id="月30日">12月30日</h1>
<ul>
<li><p>距离室友测出抗原阳已经过去七天了，我还没啥事，是否说明已经平安度过了（</p>
<p>可能有在别人寝室坐椅子睡觉的那两晚上的功劳，毕竟我不想承认它是无用功（逃</p></li>
<li><p>卷了一天抽代，但愿明天遇到的都是含幺交换环，睡了。</p>
<p>hx
说期末的题目比期中容易一点，但我对他估计题目难度的能力表示悲观，所以还是很怂（</p></li>
</ul>
<h1 id="月31日">12月31日</h1>
<ul>
<li><p>最近几天卷抽代卷麻了，连日记都懒得同步，干脆到月底把最后五天的攒在一起发了，基本都不长。</p>
<p>不是，这抽代早说考这么水，我也不至于一周全复习这玩意去了啊（（</p></li>
<li><p>考完第一门，晚上打算报复性看两部电影，然后写一下马原期末论文。</p>
<p>一个是期待很久的《血观音》，一直很喜欢惠英红。说起来这里本来还有一段话，想想有点剧透，发出来的版本里就删掉了。其实如果是我自己的话完全不介意被剧透，甚至看电影之前一般会先去看看梗概，对情节有一个基本的想象之后再去看，能发现更多出色的地方。（推理剧剧透论外x</p>
<p>说起来暑假里看的《不完美的她》就是周迅和惠英红主演的，她们两个我都很喜欢。但是这剧翻拍了日剧《母亲》还翻得完全变味了，卡司和原剧明明都这么棒，实在可惜。<del>周迅近年来真的演了好多烂片</del></p>
<p>二刷了《色，戒》，第二次看王佳芝给易先生唱《天涯歌女》的片段还是很难过啊（</p>
<blockquote>
<p>人生呀谁不</p>
<p>惜呀惜青春</p>
</blockquote>
<p>想起来了</p>
<blockquote>
<p>人生が秒速で塗り変わる青春は風になる</p>
<p>人生也在秒速中改变 青春将幻化为风</p>
</blockquote>
<p>（是花譜的《そして花になる》里的歌词（这不是一模一样嘛 x</p>
<p>还想看《芳华》和《颐和园》（这个可以说吗），今年是来不及了，后面几天还得复习好几门课，考完数值分析（实际上就是考试周最后一天了）一定。</p></li>
<li><p>考完试给抽代助教写了封邮件，这个学期收到了很多来自他的正反馈，夸张一点说，其实这些鼓励很能精准安抚一个基础像筛子一样甚至选课的时候有点战战兢兢的外系自卑菜狗（定语好长但都是实话），想表达一下感谢。写
bonus 每次都有批复，在作业里提出的小问题也能得到解决什么的，感觉他很
nice。</p>
<p>然后被已读不回了（。上周给 wjd
老师写的邮件她也还未读，草，我以为我室友一周看一次邮箱就已经频率够低了的，怎么还有老师也一周不看邮箱的。有一种表白了之后还被人鸽了的感觉，还是两次（（</p>
<p><del>看微信头像的照片感觉助教很帅，但是一个学期以来根本没见到过真人啊
kora！太遗憾了罢</del></p>
<p>想起来一件事，大一的时候微积分 A
有位选课的时候总被抢爆的烫门老师（据说课讲得不错 &amp;
调分力度大，别的老师基本都不调，我上 wxf
的课是一点调分都没有），一到期末学生就扎堆给她写感谢信，有的真的很肉麻。肯定有一些是出于真心，但只是为了在几百个人的大班上给她留下印象的，估计也不在少数。</p>
<p>找了找和室友的聊天记录，甚至还有当时的两张图。反正我挺讨厌这样的，尤其是老师会把收到的话发朋友圈，自己也在助长这种风气。我实在不太相信写右边这段话的人多喜欢数学，这也太假了，看着好难受..</p>
<p><img src="https://s2.loli.net/2022/12/31/KugUAZFvdyHkw7p.png" alt="calculus.png"></p></li>
<li><p>一年就要过去了呢。感谢陪伴！祝大家新年快乐，明年也继续来听我讲废话的话就更好啦！（x</p></li>
</ul>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇六·23年2月</title>
    <url>/2023/02/01/Diary-2023-02/</url>
    <content><![CDATA[<p>总感觉假期快结束了，但是假期真的开始过吗（</p>
<span id="more"></span>
<h1 id="月1日">2月1日</h1>
<!--2 月的第一条是一些不太成熟的想法，怕自己日后看着尴尬干脆写在注释里了，如果看到了就当彩蛋吧。-->
<!--最近申请相关看多了实在焦虑，打算开学挑一位 Yau Center 的幸运青椒和我聊聊天（啥啊），开始认真地思考一些磕盐和推荐信相关的问题，这也没有之前想得那么不重要。找一个愿意丢给我一本书读一读的老师都不错啊！-->
<!--上官网开始筛选，关键字大概首先得是概统方向的老师，其次我希望他/她入职得尽量晚，最好 homepage 上已经把个人信息写得尽可能详细，让我入场前就能先找点能聊的话题（什么）。结果第一步几乎就筛掉了所有人（，是不是数学系和 YMSC 近年来已经不怎么招概统方向的老师了，但统计中心近两年也没怎么招吧，总之咋这么少呢。然后又筛了一些目前在校内已经过于有名，我感觉我高攀不起的老师，比如吴昊姐姐。此时我就基本已经没得选了，只剩下两个杨帆和一个顾陈琳（草，真的是两个杨帆，一男一女，都是 YMSC 的青椒，还都是概统方向-->
<!--顾陈琳的名字感觉在哪里听到过，后来发现是 19 年的首届（？应该是首届吧）Alibaba 竞赛获奖者之一。看了看他今年给求真开分析-0，感觉还是高攀不起，后来想想 YMSC 的哪个老师在任意阶段的强度不都比我高一万倍，聊个天罢了，~~华子这么大，我又脸盲，聊得不愉快的话就算死生不复相见了也不难，冲！~~-->
<!--第二天早上醒来：不行，我还是社恐（-->
<!--在他的 homepage 上看到了这一段话，感觉会是个很有意思的人。-->
<blockquote>
<!--This page is strongly inspired by one of my friend. Since this page is just for fun, I suggest you skip it quickly and do not waste much time on it if you have some affairs more important to do on hand.-->
<!--Here is [my blog](https://guchenlin.blogspot.com/). Its birth comes from one debate with one friend. He thought I just give a lot comments to the others' rather than running a proper blog. Thus I decided to run my own blog as a counter-attack. Time proves it hard to always keep writing (interesting) ideas, but I try my best.-->
<!--You can find me (easily?) in the following videos: [X - a magic world](https://www.youtube.com/watch?v=1agseoOoQO8), [X - TV5Monde](http://www.tv5monde.com/emissions/episode/destination-francophonie-destination-x-l-ecole-polytechnique), [IHES - a temple of maths and physics](https://www.youtube.com/watch?v=rwoFdfIxUVA), [Ali - maths](https://www.youtube.com/watch?v=ee04r3d6TBk).-->
<!--In 2019, I am qualified in the final of the Alibaba maths competition sponsored by Jack Ma. It is a nice memory and another video touched me so much during the ceremony [A running Pi](https://www.bilibili.com/video/av45016307?from=search&seid=16178416153134018730). It seems that we became superstars that week and we appeared in many interviews and reports, but in fact I am only a random walker attempting to solve some maths problems.-->
<!--Finally, let mention [the guy](https://qingyunwu.com/) who teaches me a lot. We have once trained for maths olympiad in high school and also collaborated for (maybe) my first paper. I always remember the epoch when I was younger and those friends with who we studied maths together. I missed the old days, but perhaps to do maths is the only way to keep them in my mind.-->
</blockquote>
<!--刷了一下博客，~~看不懂~~，不过反正人家是正儿八经在思考问题，不像我搁这天天水字数。简单开了个盒，发现还是江苏的前前前前前前前 MO 选手，笑死，反正当年的省一含金量是比我强多了。-->
<!--我大概是飘了，还思考了一下 connection 强不强的问题。看了一下他从复旦毕业之后就去法国了，~~要么我去讲两句法语给他班门弄斧一下~~，以及后来去过 NYU 和 NYU Shanghai。我大概会首选北美，法国数学的地位也不低但是不清楚就算拿推荐了能有多大作用，问题是能拿他的推荐这件事是不是在做梦来着。以及出于~~一些愚蠢的私人雷区~~和 NYU 的统计不太行的问题，除非最后 bg 一塌糊涂担心失学，或者有非常心仪的导师和方向，否则也不会考虑申这个。不过现在是有老师愿意带我我就谢天谢地的情况，先差不多得了。-->
<!--顾陈琳老师的方向是概率和随机过程，以及 PDE。随机过程我还没学，还处于一个名词党的好奇阶段。-->
<!--另一个可以考虑的是杨帆老师（男），简单看了下 CV 发现他花十年时间读了两个 PhD，一个物理一个数学，本科的时候还是华子的国奖，强度和经历都有些惊人。他是做随机矩阵理论的，这个我实在是不太了解了。俗话说本科生选方向如同抽卡，~~那还不如多抽几发~~，我的评价是，可以的话大概去问一问也不亏。-->
<!--另一位杨帆老师（女）是做因果推断的，目测也是生统。她为啥不去统计中心（错乱），之前简单看过生统引论的 handout，直觉上不是特别感兴趣，暂时先算了。另外顾陈琳老师和杨帆（男）都是 2022 年 9 月入职的，属于目前青椒里最新的一批（？）本外系菜狗只敢碰瓷这种别人大概还没碰瓷过的了。-->
<!--不知道为什么，在统计中心虽然心里清楚老师本科的时候也必比我强一万倍，但还是能很自然地谈笑风生，之前随手就给没上过课的老师发邮件，初概期中考砸了还敢约 dwl 老师的 OOH 问一大堆奇怪问题，但让我去数学系/YMSC 找老师我就腿软。可能是觉得（只是觉得）自己高于统辅同学的普遍强度，所以非常普信吧，以及也听说过统辅老师们都出了名的心慈手软。如果我愿意直接接受应用统计，那还在这里纠结什么呢，直接去麻烦统计中心的老师带我就好了，也自信很多。可惜我不愿意。总之，想先把目标定高一点，必要时向下兼容也是可以接受的。-->
<p><img src="https://s2.loli.net/2023/02/02/pCU1j65TyFtKa8m.jpg" alt="holiday.jpg"></p>
<h1 id="月2日">2月2日</h1>
<p>今天去了苏州。实际上目的地也是乱选的，之前看到一个<a href="https://mp.weixin.qq.com/s/ebIAaMziYYW9Wm6Wx512Qg">上海一小时高铁交通圈</a>的文章，第一个就是苏州，所以就去了。然后也没什么目的地，除了去了普渡寺（离苏州北站很近）之外，其他都是漫无目的街头瞎逛了。</p>
<p>在普渡寺看到的逆天祈福牌：</p>
<p><img src="https://s2.loli.net/2023/02/03/lT6wSPmc3EIu8yo.jpg" alt="henguai.jpg"></p>
<p>我也买了一块挂上去，付完钱也没想出来写些什么，最后写的是亲友平安健康。没有更大的愿望，也没有什么关于自己的愿望。</p>
<p>晚上吃了苏州汤面，<del>其实感觉和在上海吃到的差不多</del>。在上海吃的最多的一家苏州面馆叫松鹤楼，最频繁去吃的一段时间是高三，自闭的时候就借走读的便利，出校吃了晚饭再回来上晚课。一般就是去离学校最近的商场吃松鹤楼的清汤面，非常香，借此短暂逃避学校里的氛围，是难得的很幸福的记忆。当时还不会骑车，走路太累了而且来不及，两公里的路还要坐地铁去，一碗面不到十块钱，来回地铁票六块，成本爆炸。</p>
<p>回程买了最慢的车次，只要十二块五，在车站附近买了一小袋热乎的板栗在火车上吃，属于是给自己找点事情做。<del>平凡即是喜乐</del></p>
<h1 id="月3日">2月3日</h1>
<ul>
<li><blockquote>
<p>古廖夫一生积攒下的挫败感，在这一刻突然汹涌而至。他想起年轻时，有那么几年，毫不怀疑自己是个天才，他忘情地写着，稚拙的作品曾备受师友的夸赞；他沉醉在自己手造的光芒里，对未来满怀热望，相信自己能成为任何想成为的人物……他想起一个醉醺醺的夜晚，他坐在音乐学院的广场上，旁若无人地指挥着月光下飞驰的云影，澄鲜的乐句像从天外直灌入他的灵魂，他在黑暗中放声大笑……可到头来他又做成了什么呢？如今他跌坐在岁月的尽头，沮丧地认识到，这一生非但不是幸福的，甚至也不配称为不幸，因为整个的一生都用在了战战兢兢地回避着不幸，没有一天不是在提防，在忧虑，在克制，在沉默中庆幸，屈从于恐惧，隐藏着厌恶，躲进毫无意义的劳累中，期盼着不可言说的一切会过去，然后在忍受中习惯……</p>
<p>古廖夫再也绷不住了。他捂着脸，在荒野中嚎啕起来。</p>
</blockquote></li>
<li>今天 b 站突然给我推了<a href="https://www.bilibili.com/video/BV1LY4y1d74r/">体育中考跳横箱</a>的视频，突然想起来我当时还真的选了这个，每次跳着跟玩似的，最后拿了满分。打开视频一看，感觉这个项目好恐怖，不知道以前是怎么做到的，后来又是怎么变成现在的体育废物的（</li>
</ul>
<h1 id="月4日">2月4日</h1>
<p>今天是友人的生日，实际上和往常一样，她是和家人以及其他朋友一起开趴度过的，我并不会参加这种活动，感觉参加了也会败大家的兴。中学的时候会等到寒假结束再把礼物当面送给她，今年我想了想早点拿到总比晚点拿到要好，况且我是那种只会送书的无聊人类，早点拿到的话寒假还来得及读完，开学就没空读了。所以就直接寄了个快递。</p>
<p>我之前一直纠结应该怎么面对朋友的生日，代入自己的话就会纠结别人到底有没有过生日的习惯这件事，后来觉得就算不过生日的话收到祝福应该也会开心，所以要努力知道大家生日的时间然后至少要送一句祝福。不过经常觉得自己做得还不够，又担心会给别人心理压力（比如说要等价回报之类的负担），稍微有点想不清楚呢。</p>
<p>上次给自己过生日还是上次，也不算过生日，就是馋蛋糕了所以找借口买了一个，点蜡烛也是觉得火苗摇曳的样子很好看。近几年来唯一一次生日许愿是
18
岁的时候，煞有介事地希望自己能尽快独当一面，当时所说的主要是想尽快经济独立。于是高考后的暑假还用华子的
title
骗了些家教钱，尽管我不喜欢这样，但它支持我毫无心理负担地生活到现在，感谢所有当时找我上课的小朋友们，我想我也付出了等价或者超额的，真诚的劳动。</p>
<!--一点暴露阴暗面（？）的彩蛋：非常巧，写完这些的第二天我姐就给我发了[这篇文章](https://weibo.com/ttarticle/x/m/show/id/2309404866530147172656?_wb_client_=1) ，然后她对我说的大意是她很快就要工作了，如果留学前的准备开销大，保持不了经济独立的状态，缺钱可以随意问她要。我知道她的意思，她也在努力表达对我的担忧和关心，我很开心，但是，笑死，我怎么会在北京上海花她在二线城市（也或许会是南昌）挣来的钱呢。-->
<!--当然在华子搞钱的方法有很多种，课咨委每学期都有补贴，如果有答疑坊或者助研岗位这种稳定的来源会更好，我想下学期总能搞到其中一个，吧，另外可惜我拿不到奖学金，不然还真挺宽裕的。所以我还是幸运的，不需要付出太多代价就能维持这样一个随心花自己挣的钱来在家人面前维持体面的状态，甚至说得恶毒一点的话，我总是有路可退的，哪天实在需要大笔的花费，低下头找我妈要钱日后再还总是可以的，尽管我不想这样。老姐安慰我说其实已经比大多数同龄人都独立了，我说不是这样的，把参照系放大的话，我真是幸运的人，在这里忸怩作态地争取所谓的“体面”“随心所欲”而已。就像杨绛说的一样，我想自己还是一个多吃多占的人，至少要对不幸者保持愧怍。-->
<h1 id="月6日">2月6日</h1>
<!--今天看到 [#218607](https://thuhollow.github.io/##218607) 稍微有点麻，三教又一次安放不下一张平静的书桌（？）了，开学之后看情况搞不好要爬回法图自闭，可是法图只开到下午五点，真的要去北馆吗，社恐很害怕。-->
<p>消失了几天没写什么东西，甚至有朋友发邮件问我的生命安全情况（，感谢关心（，看来等我年纪大了以后可以在博客或者别的什么媒介上立遗嘱，并且和人约定好，如果若干时间没有更新的话有可能是我出事了，要试着联系一下我。</p>
<p>说起来前段时间和友人有一段关于遗嘱的对话，她的意见是说不定多感染几次新冠人就没了，最好提前准备个有法律效力的遗嘱。然后我就她告诉我的遗嘱注意事项提出了
114514 个 corner
case，发现都已经被安排好了，看来<del>法师</del>律师们就是现实世界的测试工程师。我当时想着这段话会聊得比较有意思，还（征得同意）录了个音，想把对话复刻到日记里，却一直没有做这件事。</p>
<p>其实我也不知道最近在干嘛，或者说可能是单纯不想把平庸的日子记下来，就没写什么。一直写不出来第二篇数分的前言，干脆就摆烂没有更新。说着
everyday matters
但是失去的日子就是找不回来，往前回忆的时候也想不出来除了在尝试怎么用
Python 替代掉 R 之外做了什么，替代也不是很成功，<del>难怪大家都用
R（草这是什么结论</del></p>
<p>查了一下教学门户发现缓考的科目三月份才考（不是科目三，是科目/三月份），那还可以再摆几天。</p>
<p>今日最佳：</p>
<p><img src="https://s2.loli.net/2023/02/06/SdyAbfTuWrFURO8.png" alt="no-analysis.png"></p>
<p>然后发现我其实是练习时长零年半的数学练习生，2022
年我的数学学习最大的收获是我终于开始学习数学了，听起来像绕口令。</p>
<h1 id="月7日">2月7日</h1>
<p>今天和一根扎进手指里的木刺搏斗了一下午，我为什么不去医院呢.jpg，传授一点自己处理的经验：</p>
<ul>
<li>据（我妈）说可以把盐和醋 1:1
兑热水，然后手指放进去泡几分钟就能掉了，我试了一下可能是因为扎的有点深，总之是没用的，而且已经有伤口的情况下泡盐水会痛啊！（我不会是个笨蛋吧.jpg）</li>
<li>wikihow
上还有别的稀奇古怪的方法，什么醋和苏打水兑热水之类的，原料不充足，没试。</li>
<li>但是直接泡热水还是有用的，让刺吸一下水变软一点就不那么痛了。</li>
<li>如果只是扎在表皮的话可以用消毒过的针把皮挑开然后把刺取出来，听起来很痛但应该是没什么感觉的。但我的扎的明显比较深，刺只露出来一个小头，直接用镊子夹不住，所以是用针伸到扎进去的地方把刺的角度调整了一下（这一步真的痛但是也真的有效），然后用镊子（掌握好力道的话指甲刀也可以）夹出来的。</li>
<li>注意消毒，处理完之后要消毒，工具用之前也都尽量消毒。</li>
<li>用胶布粘出来或许也是可以的，但我觉得不如用镊子能掌握好力度，万一断在里面就很麻烦。</li>
<li>扎得深的话不要试图把刺挤出来，一方面刺的边缘可能还有小的毛刺，另外试图挤出来的过程可能会越扎越深。我把刺拔出来之后手指还是明显肿了，应该是因为试着挤了很多次，发炎的地方就是用力挤的那一片。把刺拔出来之后可以轻轻挤一挤，大概可以防止感染。</li>
</ul>
<p>当然，还是去医院比较好，用一次性筷子的时候要小心啊。附<a href="https://www.wikihow.com/Remove-a-Splinter">一个 wikikow
的链接</a>，大概也是这些方法。</p>
<h1 id="月8日">2月8日</h1>
<p>想了一天也没想出来怎么写今天的日记。</p>
<p>起因是突然想起初中时认识的一个学长。当时我对初升高还一无所知，不懂自主招生的规则，或者说觉得那和我这种郊区做题家根本没关系，我就该去争上中分给全区的唯一一个中考名额，更完全不懂竞赛。我妈机缘巧合认识了他妈妈，获得了一些当时来说很救命的信息，最后临时抱佛脚考到了不错的高中也该感谢他最初的帮助。</p>
<p>高二上学期（2019
年末）的时候看到了他的水滴筹信息，才知道他患了白血病，还有他化疗后拄着拐杖在开学典礼（或许是别的什么活动）上讲话的照片，他家已经变卖了所有家产，几次配型也不成功，当时在一个医疗团队里试用新药之类的信息。我妈试着联系他妈妈，发现微信被删掉了，就在水滴筹里捐了
200
块钱。后来再也没有音信，也逐渐淡忘了这件事，直到今天我突然想起他来，就问了我妈一句，才知道从那之后他的病情急转直下，似乎
2020 年没到一半就去世了。</p>
<!--虽然这么久了也没听说过他康复的消息，问之前早就做好了心理建设，但最后听到这个消息我还是挺难过的。然而我妈得到的结论是独生子女的风险太大，建议二胎。或许因为她早就知道了这件事所以已经过了震惊和难过的阶段，或许父母辈在政策社会经济各个方面影响下就会是这个想法，我不想多说什么来反驳，只是觉得更难过了。-->
<p>想了很多，写下来总觉得词不达意，干脆删掉了。最后上网尝试了很多搜索的组合，他的名字，初中和高中学校，入学年份，甚至我记得他在某个知名初中数学竞赛得过奖，这些信息都试着搜了搜，努力拼凑起来了一个形象，谢谢互联网的记忆。遗憾的是我只见过他一次（现在想想那时也已经算是他生命的末期，当初怎么会想到其实死神就在身后，令人感叹），不记得他长什么样子，只记得水滴筹上的照片很憔悴，没记住意气风发时的样子。虽然不了解他的亲朋好友如今的生活如何，但我想只要我每带着这一丝记忆多生活一天，就能保证他还没有被世上的所有人遗忘，所以要努力记得，要写下来。（这个格式听起来像在做证明题，我是不是不会说话了</p>
<p>人世多为憾。今朝蒙善诱，怀抱绝埃尘。</p>
<h1 id="月9日">2月9日</h1>
<p>来点轻松的二次元相关。</p>
<p><img src="https://s2.loli.net/2023/02/09/4nI9wicuVGq7J6O.jpg" alt="2-dimension().jpg"></p>
<p>其实第一版填了五个 EVA TV 或者剧场版，想想实在太多了，去翻了翻
bangumi 换了几个也很合适的。</p>
<p>入坑作本来想填守护甜心（，和柯南都是小时候同时看的，那个太子供向了，写出来恐怕大家都不认识。这么说来我已经是十多年的老二次元了，看的番好像还是不多，近两年基本就没看过新作。</p>
<p>看最多次的是天气之子纯属意外，高二的时候我自己看了两遍，又和 ex
去电影院看了一次（草（其实并不愉快，然后可能是因为这个所以疫情网课的时候<del>（已经分手力）</del>经常
emo 就会拿出来看一看，也没什么别的原因。令人感叹。</p>
<p>最喜欢的我一直都选不出来（About 里面也提到过），硬要说的话还是 EVA TV
或者紫罗兰二选一，但是好像也都没到最喜欢的程度，就给一个最想安利和一个最佳画面。最佳配音是因为《春宵苦短，少女前进吧》里面的前辈是由星野源配音，我不太关注声优，掺点三次元爱好。C
&amp; T 的配乐真的很不错但是被剧情拖得太惨，所以选它一下。</p>
<p>友人评价说 Fate/Zero
远远没到最虐的程度，但我觉得也很可以了，大概是因为我没看过魔法少女小圆。FZ
也是我 fate 系列的入坑作，如果入坑第一部看的是 Fate/Stay Night
的话可能根本就不会入 fate
系列的坑，<del>子世代比亲世代差远力！</del>卫宫家今天的饭在 fate
世界可以算是最轻松治愈的了，大家远离圣杯战争围在一起吃饭，印象挺深刻的。</p>
<p>然后是觉得四谎实在很单薄所以说它过誉，樱花庄的宠物女孩看了一半忍受不了就弃坑了，实在是不喜欢但是被身边的人安利过很多次，在心里直接拉黑成最讨厌了。离谱的那个是歌舞伎厅夏洛克，本土版的福尔摩斯改编，一开始觉得很新奇还追番了，前面看着也还行但剧情走向越来越离谱，我又比较喜欢原作（指小说），所以别看。这几个都挺主观的，因为也没看过太多离谱/不喜欢的番。</p>
<h1 id="月10日">2月10日</h1>
<p>今天可以用一句话总结：时隔四年还是五年，总之我二刷了一下秒速五厘米，发现自己终于看懂了，令人感叹。</p>
<!--轻度破防还是放到注释里啦。其实是看到了 ex 在空间里发的动画喜好表，还蛮多高中的时候一起追/讨论过的番的，FZ、兔女郎、秒五、君名、春物、京紫、天气之子什么的，才想起来兔女郎当初也是我安利给他的（笑），不知道他现在看到天气之子会是什么心情，估计也没什么波动。虽然这些番剧出镜的位置和我有轻微的差别。位置差别最大的是他把樱花庄放在了前两行里（x），我才想起来当时反复给我安利这一部的也有他啊。那我还蛮有原则的，不喜欢就是不喜欢（-->
<!--然后细看了一下，发现他填的最喜欢的番剧是秒速五厘米，我想想我以前好像不知道这件事，如果知道的话从前就会牢牢记住导致现在也没忘掉，我还以为他最喜欢的会是春物、兔女郎或者终将成为你之类的日常系恋爱番。秒五讲的是什么故事我也已经淡忘了，上个月的日记里提到我在学校图书馆里读过秒速五厘米的原版轻小说，也不记得具体内容了，只觉得好像是一个有点平淡又很遗憾的故事。-->
<!--直到今天把秒五和 ex 联系在一起，才突然想起来一些往事。他没有说过他最喜欢秒五，但是情意最深时和我说过【数据删除】（这个哪怕是在注释里也不能写出来，抱歉啦ww），我才因此去第一遍看了秒速五厘米，却没有很明白。或者说当时我只看到了《樱花抄》的故事，却没有明白《宇航员》和《秒速五厘米》，并且还乐观地认为只要一直在一起就不会有《樱花抄》里传达出的不安感受。从一个郊区做题家的角度来说，毕竟我们当时约好一起考华子或者上交的呀（笑），我觉得自己一定能履约，然后就可以一同昂首迈进看似硕大的人生。-->
<!--笑死，根本做不到。至少他不像我这么乐观，已经预见到了哀愁的未来，我一直自诩更聪明一点，但现在看来我才是笨蛋。-->
<!--《宇航员》和《秒速五厘米》是今天才看懂，讲的是分别后的故事，可能确实也只有分别后才能懂。但无论是去年寒假的我（这是一个过两天会在注释里讲的故事，暂略）还是现在的我，可能在结局的电车通过后，也一定还会追上去，轻快地打个招呼。当然他一定是走开的那一个，而我是期望能够重新普通地见面的那一个啦。我想也可能是因为时间仅仅过去了三年，况且各自也还都是独自一人的状态而已。-->
<!--虽然这段往事里面快乐的部分到 2018 年末就已经结束了，以上提到关于 ex 和秒速五厘米的故事也发生在 2018 年的冬天，2019 年一整年距离都很远。虽然我经常隔空说 ex 不好（他也确实不好就是了（，但是现在想起来 2018 年的三个月仍然是一段小有遗憾的幸福时光，非常感谢，我会尽量把它和之后发生的事情分开。-->
<!--我之前写日记都会分成表里两份，一份发布在博客上，另一份里面会有一些多出来的内容自己留着。前段时间忽然觉得里日记多出来的大部分内容并不是介意被人看到，只是直接展示在网页上的话我会觉得有点尴尬，所以能够写在注释里让人看到我会很开心的。当然我还是不确定有没有人会注意到这个，如果有的话向你说一声谢谢你能读到这里。-->
<h1 id="月11日">2月11日</h1>
<p>最近躲着（？）没更新是因为这两天摸鱼读统计计算去了，<a href="https://zcrabbit.github.io/courses/smcm-f22.html">PKU
的统计计算课</a>是真不错，薄纱华子统辅的那个版本。</p>
<p>我觉得我下学期干脆别上复分析了，去上个数分 2
吧（，或者不上课但自己同步读实变函数论，总之现在就是非常不自信。</p>
<!--今天刷树洞眼前一黑：-->
<!--申 stat phd 还是 connection > 磕盐 = gpa >> 其他，其中磕盐和 gpa 的占比在各个项目不同，值得注意的是顶校的 phd 基本定点输送华五和数学强校的数院前几名，建议转专业鼠鼠别去送钱/浪费时间。----Hans https://thuhollow.github.io/##221541 -->
<!--反正按我现在这个进度延毕是很正常的，但是如果延毕补课了还是会被专业歧视的话，多读这一年真的值得吗。我也想找一些享受知识带来的快乐之类的理由说服自己，但好像根本就没有精神富足的基础。-->
<p>看了一眼 V1ncent 的申请结果，Biostat 的项目里 Umich MS/MPH 和 Emory
MSPH 都中了。不知怎的我也稍微缓解了一点失学焦虑，祝贺他。</p>
<!--羡慕 Umich，安娜堡可以排进我最向往的城市的前几名，也是我觉得最适合孤单度过一生的地方之一（笑）。一大原因是因为很冷。群友天天说西海岸的阳光很好，适合 PhD，我觉得天气热的话真挺难受的。-->
<!--其实我更在意的是 Umich MPH 的 funding 能给到多少，估计是不多的，sigh-->
<h1 id="月12日">2月12日</h1>
<ul>
<li><p>今天发现 V1ncent
更新了统辅课程测评，于是也同步了一下最后的几门课，有兴趣可以去看一眼。</p>
<p>通过另一个统计申请洞认识了
Mariana，简单聊了聊。<!--他说的很对的是现在觉得对什么东西感兴趣，做一做就说不定了。我觉得我应该搞很理论的概统，但开拓一点视野或许会发现新的兴趣点。不过数学课还是坚定地要上，这个学期结束基本上要紧的基础课就上完了。统计中心我觉得合适的导师主要是 Pengkun Yang 和 Qian Lin，开学可以考虑先和 Pengkun Yang 联系一下毕竟他更帅（你们颜狗怎么这个样子啊 --></p>
<p>真惨，我一切学业学术相关的 connection 目前都还得靠树洞发展，包括认识
LagrangeKMnO4 和 V1ncent19 也都是在树洞。</p></li>
<li><p>好像真得改改选课。大概有几个 plan：</p>
<p>Plan A：维持原状，但问题是数分 2
我还没补完，原来多元微积分学得就很烂，直接上复分析是否有点送死。况且复分析除了留数之外对概统似乎都没有多大帮助，单纯是补课的话<del>既然要延毕了那</del>也不用现在就急着去学。</p>
<p>Plan
B：把复分析退了，蹲一蹲林勇的实分析还能不能有课余量，或者能不能法外开恩手选上，可以的话就去上，没有就把时间空出来自己读实变函数教材，或者把时间用在多去和意向导师沟通上面也可以。</p>
<p>Plan C：把复分析退了选数分
2（说实话最好是行健那个班，保护绩点），但问题是它和概率论冲突了，让我放弃概率论是不太可能的，真麻烦啊。</p>
<p>Plan
D：把复分析退了，选点自己培养方案里的课上谨防退学。我是不想选这个选项的，宁可自学实分析。</p>
<p>Plan
E：把复分析退了，补一门统辅课。最好是能补到贝叶斯统计导论，不行的话实验设计分析也可以。</p>
<p>我比较倾向 B 和 E，更倾向
B。先前做的决定后来才发现问题很大，本来又是可以避免损失的，这种事情真的很讨厌。</p></li>
<li><p>实际上今天是寒假在上海的最后一天，明天就要出发回学校了。今天要去上交见以前的同学，这个从去年开始就变成寒假的固定项目了。晚上会回来得比较晚，可能也来不及写日记，所以半夜更新一下，如果有想补充的东西的话可能明天会在高铁上补。</p>
<!--看我博客的朋友去年寒假的时候都还不认识我，所以在这里简单说说为什么变成固定项目，又是一篇小小的青春疼痛文学 XD-->
<!--刚来华子的第一学期我是真的全程自闭，当时还没有常驻贵社，所以是线上线下都基本没有社交的状态，好在现在终于有赛博朋友了。自闭的同时，在大一刚开学的时候 ex 把我的好友加了回来（单纯是为了问一些问题）又没有再删掉，所以就这么恢复了最浅薄的联系——我又能看到他在空间里开理发店了。-->
<!--所以因此时不时触景生情想起以前的事情，所以一天到晚 emo，也是正常的吧？（正常个头啊-->
<!--我那一整个冬天就是在不停地回忆以及反思----发现自己在从前的亲密关系（或许吧，好像也不是很亲密）里也有很多做得不好的地方，尽管对方做得更不好。然后反复思考如果怎么怎么样或许事情不会变得那么糟糕，做过的什么事情应该也真实地伤害到了对方（虽然客观一点说我觉得对方更应该反思反思怎么伤害我的 = =，但愿他有想过），之类的。每天都是一个很 emo 的状态，不是在为了卷 GPA 而大量刷题，就是在想两三年前的这些破事，试着转码阻碍也很大，现在想想也挺惨的。-->
<!--寒假快结束的时候发现华子比交大晚一个星期开学，就试着联系了一个初中的时候关系还好，后来去了交大的同学，能不能带我去学校里转转。当时还是动态清零时代，所以是借了她的校园卡混进学校的，今天是走了正常的学生亲友入校渠道。那天和她一起在学校里走了走，聊了一些初中时候的事情和未来打算之类的无聊现充话题，感觉这种和以前的朋友偶尔见面的方式也不错，就约好成为一年一度的传统了，笑死。-->
<!--我也不知道当时为什么要去，并不是还希望和 ex 见面说多少话，和他见面也没有话说，我想他大概还在讨厌我，如果我试图提起从前的事情反而会更讨厌？那天我让同学带我去龙宾楼（密院系馆）坐了很久，有一搭没一搭地和她聊天，我也不知道有什么意义。或许并不想再和 ex 见面，但是我当时就是还想再看到他一次，最大的愿望就是能够打个招呼----你看我来到这里了哦，猜猜我怎么进来的，怎么找到你的？-->
<!--就好像高一的时候，学校组织高一高二学生出校看音乐剧，我社恐发作，打算直接偷溜回家。当时随手发了个消息告诉他我不想去看剧，抱歉不能一起了，先回家了哦。结果他说他也不想去看，出发去黄浦图书馆写作业了。于是我就换了个路线，也去图书馆找他坐了坐。在图书馆电梯开门的时候他就在走廊上，看到我的时候惊喜地问，你是怎么找到我的？我说不管在哪里，我一定可以找到你。-->
<!--这种一看就发生在 2018 年末的幸福瞬间我全部都清清楚楚地记得，实际上也没几个这种快乐的瞬间，因为后一年我也还是靠回忆这些事情来艰难地对抗生活里的诸多不幸，维持脆弱的精神状态。听起来对于高中生来说很夸张吗，但我这几年来真的就是这样的，要不断从快乐回忆里汲取养分，才能打败现实的困难，继续生活下去。-->
<!--尽管时过境迁，我甚至不一定能够认出他来。-->
<!--其实自从常驻在贵社，认识了社友们以及和其中几位社友有了相对多的来往之后，我就很少会想以前的这些事了。即使想起来也是释然的，不会再因此长时间地 emo，还会时不时在日记里把以前的事情当笑话讲，因为生活里终于有新的快乐了。今天去交大就完全是和一年没怎么联系的老朋友见面，sync 一些无聊的现充话题，毕竟她对我的认识还留在一年之前，每年来 sync 一下可以从别人口中发现自己也变化了很多，我觉得也挺有意义的。-->
<!--所以还是要谢谢社友们一直以来的关照，friendship is magic（？），能够读到这里的话也辛苦了，非常感谢你。-->
<p>补点图：</p>
<p><img src="https://s2.loli.net/2023/02/12/h8W75fVtYTiSEzH.jpg" alt="ups.jpg"></p>
<p>思源湖边 up 主聚会.jpg</p>
<p><img src="https://s2.loli.net/2023/02/12/pWeoVIGdK2Y6rh1.jpg" alt="tianshilu.jpg"></p>
<p>建议新民路吸取一些先进经验（</p>
<p><img src="https://s2.loli.net/2023/02/12/3Bels5LQ4rW2w7m.jpg" alt="efz-like.jpg"></p>
<p>看着感觉穿越到了 efz 办公楼，不确定，再看一眼（</p>
<p>其实是你交药学院（，路过的时候随手点了个位置。</p>
<p><img src="https://s2.loli.net/2023/02/12/6oKTYUHiwc4yV53.jpg" alt="local-optimization.jpg"></p>
<p>以前一直以为对我来说是个最优解的电院，现在看来只是局部最优来着。</p>
<p>不过在楼上直接写电院两个字是否有点太草率了（</p></li>
</ul>
<h1 id="月13日">2月13日</h1>
<!--把底端实际上没什么必要的字数统计去掉了，本意是为了注释的纯净阅读体验，直击 additions & deletions（-->
<p>回北京了。昨晚这个时候我还坐在交大玉兰苑旁边的凉棚里，和同学一边喝奶茶一边吹风，听后面一桌打麻将的声音，附近都是各种小店，很有烟火气，甚至恍惚觉得总算感受到了现充式的大学生活。今晚我就在北京挨冻了，令人感叹（</p>
<p>明天的计划是去打九价 hpv
第二针，本来友人说怕我打完副作用大晕在路上，要陪我一起去，结果她今天和我说私密马赛她明天要过情人节去了，哈哈.jpg</p>
<h1 id="月14日">2月14日</h1>
<!--友人的情人节：和 npy 出去玩了一天-->
<!--我的情人节：白天出去打了个巨疼的针，下午回来倒头就睡，晚上醒来之后也不想学只想摆烂，最后闲着没事干，翻了一个小时 ex 的推特点赞记录，一边看一边感叹这个人完全没有改变过，乐死。-->
<!--我怎么就这么无聊啊.jpg，当赛博幽灵也要有个度吧（-->
<p>刚睡醒！</p>
<p>今天去打九价，没想到第二针和第一针不能打在同一个胳膊上，要好几天抬不动右手了。这针不仅贵，还让我很有参与感，推药进去感觉每一下都巨疼。不过敲键盘和写字没什么问题，那这两天不得大卷一场？.jpg（不是</p>
<p>下午回来在校门口听到有人一番论证之后得出结论“我们是 Bocchi the
cyclist！”，回头一看还真有四个人，草。</p>
<!--想起来社友也安利过孤独摇滚，晚上回来打算补一下。这才知道原作也是芳文社的，觉得有点不妙，因为我对芳文社真的没什么好感（这是可以说的吗），大概要追溯到以前身边有好几个特别喜欢点兔的同学，被安利了好多遍之后感觉完全看不下去，像进了少儿频道（草，大概我不太喜欢这种类型。 -->
<!--看了三话，果然不喜欢，搁置了（-->
<h1 id="月15日">2月15日</h1>
<ul>
<li><blockquote>
<p>I’m always oscillating between “I’m crap” and “I have a vast, vast
soul”.</p>
</blockquote>
<!--然而如果是后者的话为什么我的脑子仍然空空如也，如果是前者的话我又为什么痛苦不已？-->
<!--少想一点，多做一点罢 qwq--></li>
<li><p>到了北方的一些直观感受：洗完头之后头发又干又糙还起静电，洗完手之后手指轻微起皮按不开指纹锁。</p>
<p>如果有和北京差不多冷但是又不这么干燥的地方就好了，最好水质也好一点。我一定是在做梦.jpg</p></li>
<li><p>早晨又一次被楼上活动室装修砸醒，又一次以为这个破楼要塌了而狂喜，但它并没有塌，真遗憾。等了一会没声音了就又睡了个回笼觉。中午起床本来想出门，结果收拾东西的时候直接给平时用的单肩包的带子拉断了，真不愧是我。干脆以此为借口去处理了一些琐事，通过假装很忙来给自己一种今天没学也没关系吧的感觉，太罪恶了。</p></li>
</ul>
<h1 id="月16日">2月16日</h1>
<ul>
<li>今天要被友人拉出去看国家地理的展览，但其实这几天身体上就很疲倦很疲倦，包括昨天去买了下学期要用的
Kai Lai Chung
的书之后原地开始非常焦虑，我什么都还没学会啊。不知道能不能打起精神来。</li>
</ul>
<!--大型废话预警：-->
<!--其实我是不想去的，但实在是不知道怎么拒绝才好，我也从没拒绝过她----所以她早就把票定好了，默认我一定会陪她去所以订票时也没有告诉我，以及展览 19 号结束所以这两天最好要去看掉，票也不能退，之类的原因。-->
<!--12 月还是 11 月的时候我在日记里写过一次“肉眼可见要失去很好的朋友”这样的话，其实指的就是她（现在想想但愿不要被别的朋友误解成指的是自己然后造成焦虑吧..，如果有的话很对不起，当时还没想到可以写注释（草，我只是觉得距离越来越远了，当然早就看到了这一天。认识的时候就知道并不是相同性格的人，不如说一直相处到现在就是个奇迹。-->
<!--主要是，经历和心态有巨大的不同，性格上的差别仅仅是这些东西的外在表现。她是那种从小在爱和关怀里长大的典型阳光美少女（阳光开朗大男孩~.mp3（不，从来不需要担心家庭、收入一类的问题，从小学竞赛但学得不那么好及时回头高考就可以，完全不必在意家庭投入的沉没成本，一切顺风顺水地就去了隔壁信科，已经提前找到了合适的导师，顺利的话本组保研就可以，学业感情家庭都不出任何差错，我写那句话的时候她其实是刚找了 npy。成长经历暂且不论，至少从个人发展的角度来说她从来不必和我一样纠结，被迫要润出去，无数次选错方向，不停地修改，要做出延毕之类的奇怪选择，到现在还因为转数没什么钱途而没得到家人的认可，每年付完学费还肉疼很久。当然我只是在拿自己没有的东西来和别人比较，从自己的角度出发一定会 biased，虽然像她一样成长会很幸福但也会失去些什么，她也会有我没看到过的不那么愉快的时刻。叠甲叠了这么多，道理我都懂，但是能选择的话我也会在成为这样的阳光开朗美少女（阳光开朗可能能选，好像美少女也选不了，xs）这个选项上犹豫很久的，虽然我也该觉得自己幸运了，各种意义上来说。-->
<!--所以我也想不通她当时为什么要和我做朋友，或许只是一个年级里理科班的女生实在太少，一直受她关照之后说出上面这些话来是否也有点忘恩负义（？）。只是我始终觉得她对我的关照，是因为她有建立在富足的物质和精神基础、良好的教养和家庭氛围上之后会自然地拥有的善良，而我试着同样对待她，单纯是因为很长时间以来她是现实里唯一一个和我说话的人。所以真的很难很难共情，我也很少对她说这种事，在她面前只是努力表现得和她一样天真无邪（这是在写术术曲歌词吗？）。我大抵也是嫉妒，听起来很阴暗但是真不好说。-->
<!--退一步的话做朋友可能也不是非要共情，共情也未必能做成朋友，前者大概是我和友人，后者很典的就是我和 ex。前天闲着没事干刷了半天他的推特点赞记录，竟然产生了“他还是一直都没有变过”这样的感叹，这种话大约一年之前他也和我说过，彼此的语气并不是怀念，只是简单地在叙说记忆而已。从前也是很互相理解才到一起去，甚至要说共同点的话和他远远多于大多数的朋友，但又怎样了呢，还是在相互沉默和不会表达之中把这份共情失去了。所以说《花束般的恋爱》属实很纪实，这部电影后来在反复回忆之后真的在各种亲密关系里都触动到我（这个之后可能会写罢，现在不写了），可惜初见的时候给它打分并没有很高。扯远了，怎么什么都能写青春疼痛文学。-->
<!--其实我并不认为现实世界中波奇式的人物遇到虹夏之后能有很大的改观，换到现在让我认识一个友人这样的朋友的话我恐怕会直接逃走，甚至觉得绝大多数情况下这种友情并不会持续很久。当然这种事情都可以代入在二次元里寻找真实简直是脑子有毛病的名言，我大概还是缺少一些图一乐的心态。-->
<!--Anyway，我该睡觉了，但愿起来能有一个良好..及格的精神状态罢。-->
<ul>
<li><p>来回的路上看完了柯南衍生
TV《零的日常》，想想剧场版砸了那么多钱水平也就那样，我就不应该对这个小小的衍生剧抱有什么期待。也或许我该认清一个事实，就是现在的柯南和我小时候爱看的柯南已经根本不是一回事了，《零的日常》远远达不到《魔术快斗》的水平，现在的剧场版作画再精致也不会有
M6，M12 那样的剧情了。到底是制作组变拉了，还是我长大了，或许都有吧（</p>
<p>虽然这样我也还是每年都会看剧场版，哈哈（，情怀党最好骗了捏。</p></li>
</ul>
<!--看了一眼统辅几门课的群，里面怎么还是一堆未央的人。我是真不喜欢和自己院系的人一起上课，卷得要死要活，上课做题考试成绩比天还大，还喜欢互相倾轧。这些话针对的是氛围，不针对任何个人，说到底大多数这样做的人也是受害者，罪恶的是强基的安排和培养方案。-->
<!--感觉自己说这话好阴暗（，但至少不是我先阴暗的（。现在读者有一两个是未央的且热爱自己院系，所以还是放注释了，搁以前我大概就直接甩在明面上。-->
<!--想起来前段时间在树洞上看到有人提前拿到了下学期未央的基物实验题目，问哪几个是要写完整报告的，想提前准备。我寒假之前邮件问过老师实验安排的事情，于是回答了一下，结果一刷新就看到洞主把整个提问都删掉，自己带着信息跑路了。之前上统辅课也发生过一些不愉快的事情，被同院系的人在背后指责也不是第一次。-->
<!--还好逃到数学系的课堂就好了，不会有人追到这里来，这边也没什么人认识我。致理数的人以为我是数 11 的，数 11 的以为我是致理的，太棒了（ -->
<!--Anyway，我还是想做有真诚的合作意愿的人，也想减弱信息不对称带来的困扰。问问题之后得到了答案的树洞被人删了我就自己重新发一个，向我提问的我也一定知无不言。除了自己这么想之外，大概 Eren Zhao 的作为也给了我坚持下去的信心罢。-->
<h1 id="月17日">2月17日</h1>
<ul>
<li><p>为什么秋季选课的时候感觉想上的课都只有春季开，春季看选课的时候又反过来了（？</p></li>
<li><p>今天攒够了蚂蚁森林的能量，种了一棵沙柳。今年大概是已经完成 KPI
了（？</p>
<p><img src="https://s2.loli.net/2023/02/17/Q8fUeM2R76a4IoF.jpg" alt="preservation_tree-2023.jpg"></p>
<p>查了一下，去年种了 4 棵不同种类的树，保护了 7
平方米不同地区的土地，应该是能远超平均的：</p>
<p><img src="https://s2.loli.net/2023/02/17/fqh9Dg7WlmuOnyV.jpg" alt="preservation-2022.jpg"></p>
<p><img src="https://s2.loli.net/2023/02/17/X5qc6RNtLGuTOpm.jpg" alt="tree-2022.jpg"></p>
<p>当然经费不是我出，种树也不是我去现场挖坑（，说自己“种了树”“保护了土地”心里还是有些忐忑。据说云杉是最长寿的树，去年恰好攒了很久的能量种了一棵，它会在赤峰带着我的名牌比我多活很久很久，守护一小片土地，还是挺令人期待的。花棒和山桃是会开花的灌木/树，都种植在甘肃，有机会的话真想去看一看，<del>虽然理性上来说，我去一趟甘肃产生的碳排放比这几棵树能够转化的可能还多（，</del>如果是山桃的话会有落英缤纷的场景吗？</p>
<!--题外话：我妈每次劝我以后要结婚生子都用孩子是自己生命的延续之类的话术，我寻思着种几棵树不更是生命的延续吗，活得比我长多了。大大大大大大概率来说还比多个人对地球更有好处一点（草 -->
<p>高中<del>因为学不会生物而</del>选考了地理，答过很多和保护生态相关的题目，也听老师讲了许多远方的故事。两年两位地理老师都是很有感染力的人，也都来自中西部，时不时谈起当地的生态情况。我不知道别的同学怎么想，但我大概是非常容易为这些事情难过的笨蛋，当时还挺揪心的。再往前可能要追溯到小时候看过的科普、《寂静的春天》之类的书籍，讲世界上的各种环境问题，每次看到都揪心不已，还会为自己没有力量帮助任何事情变好而难过。如今做的事情也微不足道，大概也尽力了。我大概从
2019 年开始在蚂蚁森林种树和参与保护地项目，到现在为止种了 12
棵树了，那有生之年好像还能再完成一些。</p>
<p>正好昨天去看国家地理摄影展的时候，有一个放映纪录片的区域，讲的是国家地理杂志的发展过程，里面还讲到现在投入了很多经费用于环保事业、生物和生态研究工作。之前好像也有报道说中西部地区的水土流失正在因为植树而改善，还提到蚂蚁森林项目在其中起了很大作用。虽然单说前两天
Ohio
的事故就让人揪心，但至少还有人在努力让世界变好，作为普通人大概也只能紧紧抓住这种微小的希望。</p>
<p>向所有负责以上项目的基金会和奔赴现场完成工作的专业人士表示微不足道的感谢，也感谢支付宝公益。</p></li>
</ul>
<!--另外，晚上看到 LagrangeKMnO4 说丘赛开始报名了，我本来寻思着和我有啥关系，明年再来。不过看他好像打算去体验一下，想想~~既然不用交报名费那~~去玩一下确实不亏，就也报了个概率统计方向。报完才发现考纲还包括随机过程，没学过，寄。回网站看了一眼已经撤销不了了，既然这样就再多报点项目（草），又加了个代数与数论。分析是不会的，应数和数物都有物理题和 ODE/PDE 相关，几何完全没学过，所以别的这些也没必要考虑。-->
<!--纯纯是去体验了，反正也没人认识我，想丢人都没处丢，嘿嘿。-->
<!--Yau 说优秀的数学工作者至少要精通两个方向，或许概率和统计算两个吗（不是），我想之后也了解一下计算或者代数，可能计算更有用一些。不想把主方向定成计算主要是觉得研究的问题没意思，但是统计计算也不错呢。-->
<h1 id="月19日">2月19日</h1>
<ul>
<li><p>数了一下培养方案里已经修完的和选了课的有 88 个学分，还有 76
个学分没有选课。这个剩余数量对大二下学期来说大概确实是太多了，然而恐怖的是里面竟没有一门是我想上的了。</p></li>
<li><p>晚饭饭点不是很饿就忘了去吃，但到了晚上又饿了，遂吃夜宵。去玉树看了一眼二楼夜宵还没恢复，灰溜溜爬回桃李，在最右边的窗口点了一份烤冷面，一串糖葫芦，又去点了一杯饮料，加起来不到十块。太棒了，下次还不吃晚饭（什</p>
<p>室友返校看到我第一句话是“你胖了”，可恶，这种事情不是非得说出来罢（悲</p></li>
<li><p>晚上本来在复习缓考，复习着复习着开始折纸（</p>
<p>然后还翻相册找到了高中的时候折的东西，印象里挑战过非常多花球，但折完之后基本拍个照就送人了，大多数连照片都没拍。</p>
<p>我其实是觉得只有折纸的过程比较有意思，折完了之后又没地方放，大多数作品还不能碰不能压，就很麻烦。正好同学觉得不需要自己研究就能获得成品简直太快乐了，这下各取所需了——以前折完之后就拍个照发空间，如果有人想要的话直接要走就好了。</p>
<p>随便放几个，别的照片都找不着了，sigh。</p>
<p><img src="https://s2.loli.net/2023/02/20/bON4GCYXLkeySgu.jpg" alt="origami.jpg"></p>
<p>其实我忘了这个是我折的还是存了别人折的照片了，当时在空间里看到另一个喜欢折纸的学长折了这个，就自己也去做了一个。看水印时间确实像当时做的，hmmm</p>
<p>忘记是不是送给 ex 了，哈哈，如果是的话大概已经进垃圾处理场了（（</p>
<p><img src="https://s2.loli.net/2023/02/20/MR3waSIlK5UgVbs.jpg" alt="cabbage.jpg"></p>
<p>这是个家里没纸了但还是想玩，所以做出来颜色很诡异的凡尔赛花球，我管它叫卷心菜。难得有手不能完全解决问题的情况，花芯好像是用镊子卷的，如果只是手工卷的话很容易散开，最后还挺牢固的。这个实在觉得有点脆弱，送出去的时候还找了个泡沫塑料的盒子当包装（</p>
<p>可恶怎么只找到这两张啊（</p>
<p>看起来还挺厉害（真的吗），不过我现在的水平仅限于下面这种立体贺卡难度的了（，今晚做了半个小时（</p>
<p><img src="https://s2.loli.net/2023/02/20/U9D5ZYHnpQPvyXa.jpg" alt="maybe-sakura.jpg"></p>
<p>也没有合适的纸（，问室友要了粉色的格纹便签，努力假装是樱花（迫真</p>
<p>Anyway，至少这个是可以收起来的，不太占地方。</p>
<p>单纯是折的话就没什么难的，只是跟着别人做，耐心细致一点也就好了，集中精力的话很少有一遍不成功的情况。之前看过一些作品的设计过程，感觉我也就是能模仿一下成品罢了，啥也不是（</p></li>
</ul>
<h1 id="月20日">2月20日</h1>
<ul>
<li><p>体验了一下实复概连上，但是复分析上课的这个点我就已经饿了，遂退课。</p>
<p>薛金鑫看起来很和善，大概是年轻老师的原因，一节课讲 114514
个笑话。听起来这门课也比较轻松，不过最大的问题还是对概统都没太大帮助，以及我数分
2 还没学完。所以补课完全可以明年再来。</p>
<p>实分析感觉顶得住，谢谢 PIN 的讲义（狂喜</p></li>
<li><p>今天才知道基物实验 2
也是最后一次开课了，我还以为我们院系要倒闭了所以以后不开课了，知道是二字班又修订了一遍培养方案之后感到非常失落。上学期把它退了，所以这学期我得上
4 学分实验课（恼），2 的时间还和别的课冲突了，破事真多啊这个书院。</p>
<p>每学期必修课超过 10
个学分我就会想似，所以一换一退了工程地质，不用上早八了。</p>
<!--2 是和故宫学冲突了，那可是我一志愿砸下来的，达咩。不过好像老师那边直接帮我把实验的二级选课选上了，也没触发冲突选课，所以时间重合的一级课和二级课不会冲突吗？还是说老师来操作的话是不会出问题的。既然这样的话我想试试需要做实验的时候让 Eren 帮我给故宫学签到，如果需要签到的话。-->
<!--草，突然在想 Eren 会不会本来是希望我帮他签到，看起来他最近找到了很好的春研项目，不知道会不会很忙，真的有空每周来线下坐一个半小时吗？实在不行的话，找找还有没有别人能帮忙的，反正这两个我全都要。-->
<!--原来故宫学还有未央计划，这下可以一边做实验一边听了（啥啊--></li>
</ul>
<!--最后来点今天在 Eren 的日记里看到的关于延毕的提问-->
<!-- ![Untitled1.png](https://s2.loli.net/2023/02/20/4TDzdjWkHp1w8Rl.png) -->
<!-- ![Untitled.png](https://s2.loli.net/2023/02/20/fKXxCedvj4Al56L.png) -->
<!--你觉得他人见你眼光是异样的，那是因为你还期望活在贵系的期望里，然而贵系期望你拿特奖，期望你保研，却从不期望你活成自己。-->
<!--钥匙在你手上，自己留在牢笼里，那便是你的选择么？-->
<!------Quote from Eren -->
<h1 id="月21日">2月21日</h1>
<ul>
<li><p>杨不亚 (x)
老师今天找我拐弯抹角地问认不认识化工系的人，跟我扯了半天最后才说明来意：他想要一些华子的微积分和线代期末题，拿去给他现在带的小朋友准备丘班考试；他还在华子读书的时候（应该不止十年前了）只有化工系学生会会收集保存这些资料，所以以为现在还是这样，希望我找那边的同学委婉地要一点。</p>
<p>大人，时代变了。</p>
<p>我都高中毕业一年半了，退役也两年半<del>（警觉）</del>了，质心这个不知名竞赛机构（不过社友说很知名
x）咋就还喜欢盯着我。到下午他们那个负责宣传企业文化的吉祥物（？）质心姐姐还来找我，说三月初要来华子玩，问我有没有空面基，可以给我带点新款质心周边小礼物来。<del>我心里想的是咱们好像也不熟啊，以及你又是怎么能进学校的，新款质心周边不会还是氛围灯款加湿器吧</del>，心理活动很丰富，最后只怂怂地回了一句没课的话一定来。</p>
<p>问题是我也从来没在质心上过课，只参加过一次全国联考<del>结果因为参加的人太少喜提
rank
1</del>，另外就是以前给新星写题解的时候会让杨不亚老师帮忙翻译小语种题面，别的交集不保证没有<del>但感觉应该零测</del>。结果又是被邀请写软文，又是找我要题，现在还要面基，<del>难道是看我比较好骗</del>，非常恐怖.jpg</p></li>
<li><p>前三个学期都是把体育课放
2-3，回来瘫倒然后洗个澡点个外卖洗洗衣服再打扫下卫生，就差不多磨蹭到晚课时间了，再出去上课。这学期终于意识到这样的话一天直接没了，实在划不来，于是<del>冒着猝死的风险</del>把体育课提到了
2-2，顺便选了个不怎么累的项目。今天试了一下，下午两点多就能休息完然后出门进行一个卷，然而困难变成了这个时段教学楼没合适的地方可以卷，太乐了。</p>
<p>晚课是线性回归，放 PPT
各种出事故。我还想发生甚么事了，一看老师的电脑是
surface，那倒也正常。</p></li>
<li><p>青春上海：今天是 neruko 老师的生日，但是今晚为 TA 庆生！（</p>
<p><img src="https://s2.loli.net/2023/02/21/QH3jYNAFivm65fr.jpg" alt="7AE6AB933FC45B0A834276F5FFDE31AF.jpg"></p>
<!--笑死了，倒不是咕咕，我是打算把这篇日记留到 neruko 老师在自己的日记里宣布过生日之后再发出来，留一些亲自来执行（？）的仪式感。结果她今晚才更新x --></li>
</ul>
<h1 id="月22日">2月22日</h1>
<ul>
<li><p>Statistical Learning，一门刚上了一节我就打算 PF 的课.jpg</p>
<p>其实是 V1ncent19 说俞 sir
给分并没有其他统辅老师那么慷慨，我大概投入不了太多精力，水平不行花了时间也卷不出来，毕竟不是理论课，太弱小了。<del>另外他还说俞
sir 很帅，确实，不过 not my type（草</del></p>
<!--另外，今天知道 V1ncent19 拿到了 Northwestern 的  PhD，申请季平稳结束，太强了。突然觉得我的失学焦虑大部分还是被 CS 那群人带起来的，倒也没必要，还有一小部分是担心专业歧视，反正这个也没办法了，现在退学重考的成本显然是大于延毕（，所以慢慢安心补课，到时候努力解释解释也就好了。-->
<!--上了下树洞看到他在统辅洞里还有更新：-->
<!--今天终于也收到理想的 stat phd offer 了，忽然感到非常有感触所以加更一期。-->
<!--因为一开始修统辅完全是作为对天文感兴趣的一个附属品，所以可以说我直到大二，甚至大三都没想到我一个物理系学生，怎么就跑到统计读研究生来了，应该说对我而言机缘巧合是很多的：-->
<!--大二纠结来纠结去还是报了统辅（我至今还记得我决定添上初概和统推课的场景）：统辅的老师们都很好（指在应该好于清华平均不少的意义上）让我能一直坚持学下来并获得了大量指引；-->
<!--莫名其妙 (?) 开始整理统辅笔记 & 收集有趣的话题一起挂在 homepage 上，并最后发现其实对拿到录取意外地蛮有帮助（老板的话：从你的 homepage 来看你应该会是喜欢学术的人，不然不会在 homepage 里敲那么多公式）；-->
<!--暑假病急乱投医的时候跟 NUS 的老师做了个冷门小课题，结果刚好是未来老板以前做过的方向，他对此很感兴趣所以面试的时候我得以大聊特聊；-->
<!--去向学校去年的新 AP 刚好是对 physics 感兴趣的 statistics 人所以很幸运 & 意外地能拿到 offer 并以后很可能还能做两个学科的 interdisciplinary 科研，是我理想的 phd 方向了……-->
<!--总之概括来说 dz 是一个运气非常好的人，很多时候都是顺其自然 + 有贵人相助才走到现在的吧；-->
<!--话说听说今年工工 9 有一位 bg 很强的同学拿到了 harvard 的录取（消息不保熟，但是她的背景真的很强），dz 看到她的履历属实自愧弗如远甚，那种才是真的对自己的未来 well-organized 的强者，我更多就是在简单地做一些舒服/我觉得会有趣的选择，所以能有现在的好去处不得不说是 timing 好，毕竟一个人的命运不仅要靠自我奋斗，也要考虑历史的行程（bushi）。-->
<!--总之很高兴有个去处就是了，希望留下的课程测评和笔记整理能帮到后来的同学们，很惭愧，做了一点微小的贡献（x），欢迎 23/24/25fall (and etc.) 的统辅同学来交流，另外也感谢在这个洞留下自己的经验/测评的洞友们～祝大家未来学习生活顺利！-->
<!------Quote From THUhollow-->
<p>还有就是这课紧跟在实分析早八之后上三个课时，今天一边听 linear models
for regression 一边觉得我也要 regress 了。</p>
<!--题外话，前两天忘记在哪看到一些观点，大意是哪怕在信息时代，不被性别主导生产力的工作仍然很少，即便是脑力劳动，女性也有生育之外的弱势，比如精力、体力相对不足。虽然听起来不那么正确而且让人泄气，我觉得还是有一定道理。身边统计学来说我觉得我比起室友已经很能卷了，然而相比 Eren，LagrangeKMnO4 充沛的精力仍然差得远，看他俩的日程我觉得一天都坚持不下来。-->
<!--不过有没有一种可能是田忌赛马了，个体比较菜，请勿随意上升整体（--></li>
<li><p>今天第一次在三次元遇到和我发型完全一样的人——王天颖老师！（</p>
<p>虽然我一直觉得挺普通的，<del>放到二次元的话就更普通了</del>，但是在生活里观察到的就是几乎没有人留普通的齐刘海和普通长度的头发，很怪。我妈的评价是太土了，草，我觉得还好吧（心虚</p></li>
</ul>
<h1 id="月23日">2月23日</h1>
<ul>
<li><p>这学期开始晚上熄灯总是卡不准 12 点整，似乎一直都是在 12 点 02
分，不知道是所有本科生楼都这样还是只有我们有偏差，看来至少我们宿舍楼已经平移到了东七又三十分之二十九区，马上就到九又四分之三站台了。</p></li>
<li><p><img src="https://s2.loli.net/2023/02/23/gObFfvMK4qyVEwj.jpg" alt="AAF91AF8D91B061F209D83C511D487FF.jpg"></p>
<p>（草</p></li>
<li><p>昨晚在四教上生统概论，出去打水才发现斜对角教室在上我们的专业课，这话听起来真荒谬啊。起因是认出了教室里坐着个同专业的认识的人，绕到前门一看
PPT
上写的是一门我这学期没选的必修课的名字，往里面望了一下好像班里认识的几个人都在，怕被人发现就赶紧跑了。</p>
<p>所以为什么要怕被人发现呢，我也不是很清楚，但我一直希望尽量降低自己在人群里尤其是班级里的存在感，希望被人暂时忘记，然后也尽可能不要唤醒别人的这一部分记忆。我做过很多这样的尝试，集体锻炼去其他班级的组，班会活动人间蒸发，以为只要不出现就自然地不会被想起来。糟糕的是大家会求补集，后来反而被班级同学津津乐道，因为只有几个女生却从来到不齐的情况实在太显眼了，大家纷纷猜测这个只有入学的时候见过几次的人是卷王还是什么神秘人。当然都不是，我可能只是社恐，可能也不止和社恐有关。<!--甚至有时候觉得反正大家都是调剂进来的，和抽卡有什么区别，彼此能有什么话说，为什么要待在一起？-->其余情况不便详述，有些氛围我也不大喜欢。</p>
<p>回去之后稍微有点感叹，家人一直不同意我延毕再申请，让我“过正常的生活”，觉得延毕“会被人在背后指点”，笑死，哪来的别人。夸张点说我的生活已经
out of 3<span class="math inline">\(\sigma\)</span>
了，怎么能用正常形容，既然这样就不可能被平庸的标准桎梏。</p>
<!--不恰当地引用一句，失去的只是枷锁，获得的将是整个世界啊！--></li>
<li><p>今晚在转数环看到有二字班的茶园转数爷问 Atiyah
的交换代数书哪里找，我看着打出来的前面这句话陷入了沉思，感觉每一个字都在告诉我我一无是处（x</p></li>
</ul>
<h1 id="月24日">2月24日</h1>
<ul>
<li><p>睡前（指今天凌晨）磨蹭着写完了实分析作业，不仅胡说八道而且不停道歉（不），寒假写一千零一页的习题的时候总感觉自己在口胡但又没有证据（没有标答），搞得现在也不是很自信。结果做梦梦到实分析的特殊原因选课被拒绝了，这也能吃拒信？吓醒了（</p>
<p>我现在课表上还只有 23
个学分，这学期真是很轻松呢（迫真），这种要到开学第二周才能把课选满，第一次作业还得找助教交的日子啥时候才能结束啊（恼</p>
<p>说起来实分析第一次课介绍助教的时候好像说了其中有一位上学期是抽代的助教（不确定，没听清），我还以为会是
Bowen L，抬头一看是一位学姐，可能是 zmx
班上的，轻微失落。好想给他展示一下我糟糕的分析水平啊（什么啊草</p></li>
<li><p>写完实分析作业之后刷了一下树洞，看到一个问能不能去隔壁数院做本科生科研的问题，于是又开始了我的数洞
connection
环节，没想到（其实也有点想到了x）洞主是之前就认识的朋友，<!--其实就是 LagrangeKMnO4，本来觉得不要开盒，不过看他日记都自爆了，-->笑死了。</p>
<p>我还真没想过这个，这下开阔思路了。2 月头上我焦虑地筛了一波 YMSC
的意向导师，发现把范围放宽到概统各个方向了也还是几乎没得选，还得回统计中心。顺便还摇到了一位隔壁数院本科然后来华子读研的学姐，下午简单聊了两句，她觉得我补课的进度尚可，可以考虑联系导师选方向了，推荐了几个北大的组。</p>
<!--我还记得数洞摇到 kyf 向他了解九字班出国情况的那天直到凌晨四点都没睡着，因为上课太慢被敲打了一番，就很害怕。现在想想他毕竟是纯数，上课就是比概统多很多，属于是无端带起了我的焦虑。说到底寻求别人的意见也有风险，多收集 datapoint 是好事，但不能被别人的评价左右。-->
<!--和 LagrangeKMnO4 sync 了来自数 11 的情报之后觉得，多数人的进度和我也没啥差别。-->
<!--现在是又有点自信了，然而情绪是钉到墙上的钉子，过了低谷期可以把钉子拔下来，但墙上的洞还在那里，焦虑的滋味不可能忘记。-->
<p>然后她问了我一个一下子让我破了防的问题：概统是两个方向，总得选一个，你选哪个？</p>
<p>我不到啊！</p>
<p>简单概括一下，概率就又往基础跑了，当然是要基础扎实的，可能得上完实和概再说。统计的话生统也还行但是理论性太弱，先不要优先考虑，优先考虑就路走窄了，我之前倾向数理统计但是现在似乎版本已经有点落后了，目前的版本之子自然是
learning，但真的能少写点代码就想少写点（悲）。最近另一个令我破防的事情是第一周上统辅课的体验简直不要太地狱，比实分析和概率论还地狱，这俩顶多就是纯粹的难（x）罢了，学不会是我的问题，而且目前还能学会，统辅课就一点也不难，但很玄学。万事万物跳过推导看结论，还有各种我理解不了的“我们凭感觉想想这个问题就是
blahblah”，恐怖的是好像大家都是直感
A，就我理解不能，血压很高，直觉真的是这么用的吗（悲）。不过也别找适不适合之类的借口了，理论的学不会，应用的理解不了，那必是我的问题。</p>
<p>Anyway，好消息还是有的（这算哪门子好消息：</p>
<p><img src="https://s2.loli.net/2023/02/24/reXKwl8ORzgvPUn.jpg" alt="64F33DBDFCC7FC68A20400CD31BFF179.jpg"></p></li>
<li><p>明天把作业写完，整理一下两门统辅课的笔记丢上来<del>盖住烂尾的数分</del>，又该继续学缓考了。</p></li>
</ul>
<h1 id="月25日">2月25日</h1>
<ul>
<li><p>我真服了 lzx 了，一次作业布置三本书，记号还不太兼容（也可能我 4-1
听数分去了没上课的原因罢），难怪环友说他是断手（</p>
<p>昨晚写完 Kai Lai Chung
的习题美滋滋睡了，还想着就这吗，今天一看科大教材破防了。</p>
<p><img src="https://s2.loli.net/2023/02/25/YIPobnG2xH5jAsE.png" alt="lzx1.png"></p>
<p>“不管是好懂的地方难懂的地方，他讲完就通通听不懂”，笑死了。</p></li>
<li><p>天气很好，中午去 C
楼的路上看到紫操上好多人，西南角还有人唱歌。回来写概率论作业，大周末的室友都出去玩了，我在寝室一边破防一边写了
6
页纸的作业。晚上去教室坐了会写统辅课笔记，回来看到室友带着四五个人在中厅聊天（</p>
<p>属于是围观了一天现充生活，鼠鼠我好羡慕啊（x，为什么我啥也做不完啊（</p></li>
</ul>
<h1 id="月26日">2月26日</h1>
<ul>
<li><p>突然意识到这学期我有四个大作业（，统辅每门课各有一个，草，怎么会这样。</p>
<p>那还有什么五一假期，两天写一个的话正好写完（悲</p></li>
<li><p>今天好像又循环了。天气很好，紫操上很多人，两个室友分别带着自己外校的同学来逛华子，我一个人在寝室阴暗地爬行，外放甘き死よ、来たれ的时候一个室友带着她的朋友进来了，变成橙汁吧你们这些现充（无慈悲</p>
<p>唯一不同的是我昨天写完了作业，于是今天就破防地去教室继续学缓考了。这工程经济学怎么就不进脑子啊，完全不想学不感兴趣的东西。问了没缓考的同学意思是这课好像就是严格按原始分给成绩，大概就是
4.0 和 3.6 的差别，而且也就 2
学分，似乎影响不大。<!--~~但我上学期能不能满绩就看它了啊草~~，这是可以说的吗（-->但还是认真拟合一下吧，反正也没几天了，在刚递补上的实分析给我一个绩点震撼之前先攒一攒（</p></li>
<li><p>群友给我发梗图：</p>
<p><img src="https://s2.loli.net/2023/02/26/mtFchw8xzpRa3bK.jpg" alt="0C53341A97F135ADC19154B8755061A9.jpg"></p>
<p>我：哇这是一个 confidence coefficient 为 1 的 confidence
interval（昏过去</p>
<p>啥也没学会，人先魔怔了（x</p></li>
</ul>
<h1 id="月27日">2月27日</h1>
<!--睡前转数环友给我转发了一个环里前辈的朋友圈：-->
<blockquote>
<!--文刀日肥上那篇文章的标题叫我与数学的恋爱故事（有（I）（II）两篇），可能就像是恋爱会有矛盾，争吵，冷战等种种不愉快一样，或者说恋爱的时间长了爱情就会失去最初的激情（有没有谈过恋爱的 uu 来讲讲是不是这样，我完全没谈过），感觉现在自己大概率就处于一种“失去激情”的状态，导致自己偶尔会想想自己不读数学了还能干什么（虽然和同学讲的时候很开玩笑，但自己想的时候还挺认真），大概是当围棋老师？但自己的棋那个水平，在爱好者里算是有点水平的，但是靠围棋吃饭？我该教小孩子什么呢，自己的棋本来就是力量大计算稳定基本功好小官子细腻，缺点就是对棋的理解判断感觉奇差无比，大局观约等于 0。那能带他们干啥？教他们嗯练力量，每天带着他们狂做死活？然后培养出来的小孩一个个都乱砍乱杀，力量嘎嘎猛然后其他啥都不会，也挺抽象的。-->
</blockquote>
<!--虽然还没体验到，但按这个理论的话看来我现在和数学刚开始半年，还在蜜月期（，目前上课学东西还很乐。想了想高中竞赛的经验，可以肯定的是到退役的时候就早已进入所谓失去激情的状态了，虽然有很多外在因素的影响，竞赛那点东西也不能随意和学科类比。然而和别的理工类的东西根本都没体验过蜜月期，都是凑合凑合过吧还能咋的又不能退学，要么试了试就直接 break up 跑路了（草 -->
<!--文科的话以前擅长一点的也只有语文和地理，别说蜜月期了，类比恋爱的话是那种彼此还不完全了解，但感到一点点好奇和有好感的关系（草，你怎么这么熟练啊.jpg），根据经验来说（草）真的了解了之后也有不小的可能就没有发展了，甚至就凭这些贸然开始的话可能出大问题（有参考：我和 ex（。中学时候有段时间逃避理科，觉得将来读中文和法律也挺好，但到底是不了解，真去深入了解的话可能也不喜欢那一套，只是高中的文科答题技巧掌握的不错所以误以为喜欢而已，笑死。-->
<!--Anyway，我要是哪天彻底不做数学相关了，可以去考个教资，找个高中教语文去。但这有个前提假设，就是到那一天的时候我人在某个需要学中文的地方。果真会如此吗？我不知道。-->
<p>浪费了人生中宝贵的半个小时，获得了一个站在矿泉水瓶盖上的天使（真的能看出来吗，拜托超酷的诶（</p>
<p><img src="https://s2.loli.net/2023/02/28/7T2HisMwGeJQkNA.jpg" alt="angel.jpg"></p>
<p>别问我为什么是格纹的天使，又是问室友随便借的纸。背景是 Stein
的实分析，莫名很搭，下面发光的是我的一个圆形小夜灯（</p>
<p>图纸附后：</p>
<p><img src="https://s2.loli.net/2023/02/28/p4Sx3Fs9KEmNHuT.jpg" alt="angle-origami.jpg"></p>
<h1 id="月28日">2月28日</h1>
<p>最高温度零下的时候我和室友都穿羽绒服，最高温不到十度的时候我穿开衫室友穿羽绒服，今天最高温
17 度，我穿冲锋衣但室友还穿羽绒服，真有那么冷吗（</p>
<!--周四缓考的课和故宫学冲突了，这课怎么和谁都能冲突。在寝室里吹水的时候我随口说懒得请假了，想找个人替我去签个到，其中一个知道我知道她这个时间没空的室友抢答说她这个时间不想出门，尽管我其实没这个意思。她这样说我反而终于松了一口气，我一直单方面觉得我们也并不熟，直白一点说其实是住在一起没办法才互相谦让一点而已，实在无聊才会偶尔在寝室里一起吹水而已，我甚至一向害怕对方对我抱有什么类似于朋友的期待。如今知道自己是自作多情了，对方也是这个想法（虽然单从这句话来推并不可信，但就让我这么相信吧），让我无比欣慰，不用去回应不对等的期待真是太好了。什么阴暗 b。-->
<p>咋结尾呢（，请大家看个天吧。我以前一直觉得天黑就是单纯变黑，尤其上海阴雨天多，往往就是从灰白直接变黑，但也偶尔会有晚霞。总感觉先变成深蓝再变黑只有在北京见过。实际上感觉北京的天空饱和度很高，不是雾霾就是大晴天（怎么听起来是句废话），很少有阴云，是不怎么下雨的原因吗。</p>
<p><img src="https://s2.loli.net/2023/02/28/qTcbpL9GirmQFt4.jpg" alt="531F48FDB52FAE541DFB0B42702CFF7A.jpg"></p>
<p>在线性回归课上一边敲这一段话一边思考这个月到底写了些什么，但好像没什么印象。实际上在公开连载之前我也一直有写日记的习惯，最开始的时候写的还是纸质版，写完了的日记只是存起来，基本也不会回来再看。唯一的用处是别人提到某一个时间点的时候如有需要可以回来查阅一下对应的时候我在做什么，尽管这也没有意义，只是我想让自己确信对生活是有把握的。</p>
<p>咋这么沉重呢（，总之感谢你能读到这里。</p>
<!--能看到的话也感谢你读到这里，写注释以来好像就在疯狂暴露阴暗面（，满意地离开.jpg（啥啊-->
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇七·23年3月</title>
    <url>/2023/03/01/Diary-2023-03/</url>
    <content><![CDATA[<p>某些人学都学不完了，还有空写日记？（</p>
<span id="more"></span>
<h1 id="月1日">3月1日</h1>
<ul>
<li><p>摘要是在骂我自己（</p></li>
<li><p>昨晚睡得太少，早晨嗯撑着上完实分析之后来上统计学习导论，找了个有太阳的地方坐，照得我基本看不清电脑，不过还是想晒晒太阳，感觉会好很多。</p>
<p>视野还是很好的，阳光透过百叶窗的这个效果真不错。这个仰角拍摄充分体现了我坐着时候的身高，悲（</p>
<p><img src="https://s2.loli.net/2023/03/01/ZFbYnd6W9lgxjKo.jpg" alt="6A305.jpg"></p></li>
<li><p>概率论 (1)
特殊原因选课卡在院系审核两天了，我还以为我填的有什么问题，结果今天转数环友在环里问了才知道大家都一样。环友发了邮件，我打了电话，无果，最后想起来环里一年前有人转发过数学系两个教务的微信名片，试了一下还能加，于是加到了秦清老师，解决了。</p>
<p>获得了一个冷知识：微信的好友名片分享是不会过期的。</p>
<p>把环名片改成了名字 + 25 Fall 转，在一堆 21 转 22
转之间格格不入但好像又统一了格式，莫名很好笑（</p></li>
<li><p>把 surface
和手写笔带出来本来是想拟合一点工程经济学的往年题，然后也没做题：</p>
<p><img src="https://s2.loli.net/2023/03/01/xbPKvIg3EDdBMN9.png" alt="cats.png"></p>
<p>为什么要把儿童画发出来丢人啊（（</p></li>
</ul>
<h1 id="月2日">3月2日</h1>
<!--今天搁树洞看到一个这个，绷不住了：-->
<blockquote>
<!--列举一下求真我所知道的抽象操作：-->
<!--将数学系和求真拆开，和数学系切割，然后诸多中心师资被调去上求真基础课，导致需要开很多重复的课（上学期三门《常微分方程》，包括两学期代拓 (2) 然后没有代拓 (1) ），双输。-->
<!--“多元化培养”，声称要将求真成绩不好/跟不上进度的同学送入数学系进行“面向多元化数学人才需求”的培养，并在公布此通知数日内举办了一次心理健康讲座，最终是否实施有待考证，但此时求真已表现出明显拉踩数学系的倾向。-->
<!--2023 年冬令营期间，求真声称数学系研究生课不能替代求真研究生课，说“我们的研究生课程体系比较完备”，也能表现出求真有拉踩数学系嫌疑，但目前相关政策未出，此条没有意义。-->
<!--强制听课：可能是因为选修 birkar 双有理几何课程的人员过少，本学期求真大规模拉人去旁听这门课程，（一门课程课程群中助教说“【you know who】下了死命令，让选修本门课的人都去参加 Birkar 周四的课”，并不顾不同学生的研究方向和基础情况，强制所有参加求真冬令营并获得候补优秀营员的同学通过选修该课来进行进一步评定（此课程需要一定代数几何基础，但又不是所有基础数学方向的人都是要做代数几何的）。-->
<!--金戈铁马，气吞万里如虎：来自【you know who】在求真本科生通知群中所发的消息，部分内容节选如下：“我们已经誓师，五年小成，十年大成，尽快追赶世界先进水平。金戈铁马，气吞万里如虎”。-->
<!--现在数学系和数学中心这边有些课开不出来了；举个例子，春季学期本来应该有代数拓扑 1（同调论）的，但是没了。顺便一提，上学期数学系开了代数拓扑 2，这学期求真那边又开了个代数拓扑 2（都讲的是向量丛，示性类，指标定理等应用），这或多或少是一种浪费？这样安排是为了照顾求真书院的本科生，得给他们开课；并且求真开的课追求“小班教学”，每门课的容量四十顶天了，所以这需要相当的教学资源倾斜过去-->
<!--【you know who】不把数学系的学生当人看，资源全部集中在求真上。听说中心的博后还要强制给求真学生当保姆，每周要请吃饭。以【you know who】的人品，如果求真的学生几年后达不到他的要求，会被当垃圾一样抛弃吧，就像他对以前的学生一样-->
<!--目前研究生每年招百来人，但只提供 48 个工位(所有博士年级加起来)，博士生无处办公。中心博后办公室也是 10 人间。博士生需要自己做助教才有达到清华博士的最低补助 5 万 1。而隔壁北大数院博士生工位三到五人间，博后有双人间或单间，待遇差距太大了。在培养上，博士和博后招进来就是弃子，自生自灭，中心的师资都集中用于培养求真，往年每学期十几门高级研究生专题的公开课，现在只剩三门统计课。-->
<!--鼓励纯数发展是一回事，限制非纯数发展是另一回事。【you know who】干的事很大程度上是独裁，把所有学生拱到他想发展的这些领域；过去数学系虽然也鼓励纯数，但大部分人从事非纯数的工作也不会受到院系方面的限制；而【you know who】现在干的事情，只是把这些学生当作筹码，赌赢了自己名利双收，赌输了换一批筹码再入场罢了。J 君看着也是懂数学的人，相比也明白数学领域的突破不是靠一小批人狠干十年就能干出来的吧-->
<!--这个地方就要来点欧老师名言了：所以说 X 自信就是要允许 Y 才能有，以 X 自信为名打压 Y 到底是什么操作（-->
<!--再来个段子，求真去三亚期间，【you know who】请技术人员查了三亚那个数学中心的网络流量消耗情况（我不懂技术，不知道具体可以查的多细），然后发现白天也有很多因为打游戏产生的流量/网络资源占用，于是就在通知群怒斥学生白天也打游戏，我确实不好评价-->
<!--学生选课后的课表必须交给“学术导师”审核，目前暂未实施，但已有传言如此-->
</blockquote>
<!--草，这个 you know who 好好笑。我一直听说求真逆天，打压应数，倒是不知道这么逆天。此前求真切割带给我和身边人的最大影响无外乎这些：我被调剂到我院的时候，招生老师的解释是求真当年临时成立，从致理划走了一个班，虽然给过承诺但是没有办法，虽然我觉得这也不是理由，我认识的竞赛比我还拉但高考比我高的人也进了致理数学；转数环里的同学都很焦虑，从前数学系随便转，现在转系名额限原班级人数的 15%，也就是每年转进数学系只有 4 个名额，供不应求；虽然求真也可以转，但门槛太高，另外求真连数学系都拉踩，更别提外系转入，这就一博弈问题，sxt 和 hyx 转系的时候都没选求真，可见一斑。-->
<!--说点阴暗的，求真切割之后倒是利好我申请了，唉。仅剩的两个可以出国和选应数的班级里，实力 top + 应数 + 出国的并不多，在统辅这边我也自认算基础扎实的，毕竟在跟着数学系挨揍，我还挺抗揍的嘛（x）。求真的选拔政策在我眼里还是很不错，之前也提过，结果招进来之后这么抽象，我其实觉得挺可惜的。-->
<!--说点更阴暗的，未央保研政策出来之后我发现并不会限制我润去本校的数学方向（但限制不能去工工，所以统计中心是不可以的），还考虑了很久是否要努力一下直接本校保研算了，朋友们都在这里。然而数学系帮派林立，也没有概统方向的青年教师，要保就只能去 YMSC 少数几个老师那里，纯数氛围 + 转专业背景下很可能会被歧视，也就作罢了。今天知道 YMSC 的其余博士生不过是给科班这些人铺路的，科班也迟早成为代价，打死我也不会再考虑本校保研的问题。-->
<ul>
<li><blockquote>
<p>实分析目前还算比较友善，但我听闻林勇给分一学期不如一学期，数分三似乎均分
2.6 ，令人发指</p>
</blockquote>
<p>沃日，我倒是不怕绩点被削，给我 2.6
也动不了我小数点后第一位，大不了多水点统辅课扯回来。我只在意实分析是概统方向要紧的一门基础课，拿个
2.6 成负面 signaling 了，事实上未必那么拉啊（</p>
<p>看期中排位吧，要是不行就别继续了，旁听然后明年选光叔保命。</p></li>
<li><p>楼下正对着百团大战的鲁协，看起来他们要现场做饭的样子，锅碗瓢盆都带了，是要摊煎饼吗（</p>
<p>犹豫了一下也没走近去看，我大概也不算山东人。往前走了一段没看到沪协，其实沪协我就更不感兴趣了，虽然一般为了方便我会说自己来自上海，但并不会说是上海人之类的话，毕竟最简单的，我连上海户口都没有（</p>
<p>说到底对社团就不是很感兴趣...加过的唯一一个社团是天格计划，也并没有社交的打算，只是来看看是做什么的，待了一个学期就跑了。高考那年招生宣传片似乎就是拍了天格的故事，感觉把探测器送上太空这件事很有趣。至于他们在勘测什么，收集的数据有什么意义，我不喜欢物理，就觉得没意思了，只做过数据清洗和写文档的工作。这就和我对生统的态度差不多。</p></li>
<li><p>我不打扰，我走了哈：</p>
<p><img src="https://s2.loli.net/2023/03/02/L7C6RDiU2pH9AXf.jpg" alt="AE7865DE189F6DEC077114CEC86A1228.jpg"></p></li>
<li><p>我的柜子像个无底洞，昨天从一堆纸巾里摸出一瓶咖啡以为是最后一瓶，今天翻了翻又找到一瓶。不过每天找到一瓶之后我就不再翻了，把能不能再找出一瓶的悬念留给第二天（</p>
<p>光速又下单了一箱，这学期两节早八都不得不上，消耗还挺大。</p></li>
<li><p>考完工程经济学，管他考得咋样呢，新学期总算开始了，cheers。</p>
<!--UPD：寄了，3.6，看来工程经济学比抽代还难。--></li>
</ul>
<blockquote>
<!--与此同时的是在润群看到了 n+e 结婚的消息。...但有些俗气的讲，我最吃惊的是他竟然能在这个年龄就能组建家庭，毕竟六字班最多也就 25 岁的样子，在这个年龄就结婚组建家庭，对清北华五级别的学生、甚至绝大多数 985211 的学生而言，几乎不可能。毕竟大部分人这个年龄要么就在读博，要么处于事业初期根本没有资产积累，剩下的人还有一大半找不到合适的配偶。对我而言，更是刘慈欣都写不出来的科幻小说。如果说社交方面我还有一丝乐观和希望的话，在未来的成家方面我只有无尽的悲观。-->
<!--毕竟我博士只能出国，就清华数学如今糟糕的环境，已经不存在留在华子读博的可能；而对我而言，出国之后的人生轨迹，又是一个完全不可预测的混沌系统，可能博士毕业就会灰头土脸的回国找工；可能学术小有所成，读个博后再回国找教职也并非不可能；又有可能在国外对未来的认识有了改变，选择留在国外发展；又有可能遇上风波，导致我无法出国而又错过保研，或者博士未能毕业就被遣返甚至更坏的结果…总之，我的未来实在是完全未知的状态，而寻找配偶或是组建家庭需要的恰恰是确定性，更何况我并不善于交际，尤其是和异性的交际，这一来实在是悲观。-->
<!-- ----LagrangeKMnO4-->
</blockquote>
<!--虽然也在骂我但我看得好乐啊，记之。骂我也骂不到，LagrangeKMnO4 和 Eren 显然是对此还抱有期待，和我就完全不一样。房子着火我拍照，人生乱套我睡觉。-->
<h1 id="月3日">3月3日</h1>
<ul>
<li><p>emo 的时候就要多看源的 Tokyo Dome 演唱会。20 年和 21
年我真的看了无数遍，一直都觉得 Tokyo Dome
这一场单论歌曲的效果都比专辑还要好，源的演出也非常有感染力。</p>
<p>但其实我现在也不怎么听源的新歌了，常听的还是 20
年之前的一些，也主要就是 Tokyo Dome 这一场演出唱过的歌。和 Mili
一样，虽然都喜欢了很多年，但我好像从某一个时刻开始就停在了从前，没有和他们再一起往前走了。</p>
<p>之前提过 Mili
近两年的新歌里我甚至只挑出来两首觉得好听的，一个是《Iron
Lotus》，另一个是《Dandelion Boys, Dandelion Girls》，然而 18
年左右发《Millennium
Mother》这张专辑的时候我几乎每一首都喜欢。源也是一样的，《Pop
Virus》这张专辑我也基本都喜欢，甚至为此去玩了死亡搁浅，大概也就是停在了
19 年。</p>
<p>那么后来的这几年我找到什么新的爱好、有新的喜欢的歌手了吗？哈哈，完全没有呢（</p></li>
<li><p>昨晚在课咨委开会，讨论哪几个副主席今年负责带提案组的时候，听闻一位七字班的副主席大哥今年终于要毕业了，这学期光是上课就修了
40 多个学分，附带两个毕设，一共 70 多个学分，草（</p>
<p>群友之前调侃他说是因为关心课程改革而延毕两年多上了一堆课，听他的想法似乎也并不是完成不了培养方案而延毕，只是想多学点东西，挺有意思的。</p></li>
</ul>
<!--Quote from robinliu：-->
<!--提醒一下大家，如果大家要留课到大三大四然后准备冲突选课，那一定要先把 sb 土木的课留着，先选土木的课，手选其他课。土木系的教务授意老师不会给任何冲突选课通过，即使毕不了业了-->
<!--我和土木系教务拉扯一天了，被气哭了都，她和授课老师一并拷问我凭什么能同时上两门课，甚至只是 18:40 下课和 18:30 上课这种我觉得根本不算冲突的。真的是我是来上大学的，不是来被土木系恶心的-->
<!--我只能说逆天。不负责任地攻击一下，越烂的院系教务越是脑子有问题，未央也是土木系也是，烦死了。-->
<ul>
<li>我到现在都没去过二教上课，还以为可以一直坚持到毕业都不用去（？，结果这周实分析习题课安排在二教了，悲（</li>
</ul>
<!--今天在统辅课上遇到了高中时候的一个强度惊人的学姐，不写注释的话开盒开太猛了，还是算了。除了因为强度知道她之外还有一些高中以前的别的没啥意思的渊源，大概就是她和我初中的一个学长谈了很多年恋爱。总之直到去年暑假之前，对她最后的印象大概就是听说她高考去了计金，来华子之后和我初中那位学长分手了，我从来没参加过高中校友的什么活动，别的都不清楚。-->
<!--去年暑假友人参加了北大招生，回来告诉我有个从华二去清华的学姐，从他们那里抢走了一个高分考生，承诺来清华就可以给计金，最后骗进来就毁约，塞进了自动化。而原本北大给的是信科。我也算是被华子毁过约，听到这种事情就血压高，所以多问了一句这么缺德的事是谁干的。然后她和我说了这位学姐的名字，对着我愤愤不平了很久，甚至还 AOE 攻击了经管和贵系。后来的话我都没怎么听进去，只觉得，啊这，怎么会这样。-->
<!--其实原本也不熟，只不过曾经在同一个楼道里待过一年，由于一些再往前的渊源互相认识，偶尔会打招呼，她和人打招呼的时候都笑得很温和。当时知道这件事的时候我突然有点难过，去年好几次拒绝参加招生，就是隐隐怀疑里面多少肮脏龌龊，不愿意插手，没想到我当时所想的这些事情是她做的。虽然不知道这之间是否有什么误会，或许她也只是给那两个天杀的上海招生组老师背了黑锅，也可能以讹传讹了，不知道。今天看到她的时候又觉得分明和高中的时候看起来一点也没有变，好矛盾啊。-->
<!--省流：idol （疑似）塌房了（-->
<!--我把这段注释截图给了友人看，结果她回我说，啊，你怎么还记得这件事啊，我都不记得了。我不明白。为什么不记得啊，为什么都这么健忘啊。-->
<h1 id="月4日">3月4日</h1>
<ul>
<li><p>实分析作业写了半个通宵，想着写完就睡，结果真的写完再睡了。到最后已经纯纯变成了胜负欲的斗争，就是单纯的想写完再睡，其实并不好。但如果不是新学期周四才开始，倒也不至于这么赶。</p>
<p>写到最后一题脑子已经转不动了，我觉得它毕竟是放在 Problem
1，提示也就一句话，理应并不难，但就是卡住想不出来。上床之后上 Math
StackExchange 查了一下，看到有人说它
easy，一下子激起了胜负欲，关上手机闭眼想了两分钟就知道怎么做的了。看来下次有不会做的作业只要找个人来告诉我
so easy 就能做出来了（</p>
<p>白天起来把躺着想到的解答写下来发现没有伪，真是太好了（泪）。把作业交掉之后想到，大一的春季学期经常周末半夜写代码写到绷不住，要么对着电脑呜呜抹眼泪，要么写累了上床缩在被子里呜呜抹眼泪（，怀疑自己可能怎么样都解决不了问题，更害怕早晨起来也还是写不出来，然后就抱着这样的恐惧睡去。太惨了。虽然上学期为了写抽代
bonus 也通过好几次宵，各种半夜上 MSE
高强度冲浪，心情至少还挺平稳的（</p></li>
<li><p>花了一天把概率论作业写完了，但是感觉并没有学会，很危。</p>
<p>为啥室友周末永远约得到人出去玩，一到周末我就觉得自己进循环了。以后每个单周周六要做物理实验，每个周日还要上实分析习题课，约等于一周七天无休，除此之外就是赶作业，学一些学不会的东西。咋这么惨。那咋办，自找的嘛（（</p>
<p>趁现在还是三月，空闲时间大概要赶紧往后推一推两门数学课的进度，希望人没事。</p></li>
<li><p>自从上次提过之后连续观察了几天晚上六点半的天空，还是很不一样的，我谢罪，以及确实天黑得越来越晚了（废话）。除了
P2
之外都是同一个地方拍的，这个时间基本上就是我从教学楼爬出来去吃晚饭的时间，某种程度上来说也是过着一种非常规律的生活（</p>
<p><img src="https://s2.loli.net/2023/03/04/prg6AvDZO5iR1qo.jpg" alt="sky.jpg"></p>
<p>晚饭后买了春季学期的第一支甜筒（为什么这个也要记得是第一支啊草，一边舔一边走回教室，如果回去不用写
Kai Lai Chung
的习题的话还挺幸福的（。清青快餐的甜筒的话，冰激凌部分还不错就是稍微有点少，但蛋筒实在太甜了，吃完齁嗓子。下次试试七港九。</p></li>
</ul>
<h1 id="月5日">3月5日</h1>
<ul>
<li><p>解锁了二教地图（</p>
<p>以前在树洞看过一些二教鬼故事，这几个学期也都没有排课到这里，感觉很神秘（，本来以为是什么阴暗破旧的大教室（，没想到还挺新的。椅子是软的，腰突（疑似）人士好评。</p>
<p>昨晚睡前担心起来找不到 403
在哪，还搜了下教室平面图，到了才知道其实指路指得很清楚，属于是毫无必要的担心。然后还特地上知乎找了一下二教鬼故事，看了一遍，满意地睡了（草（唯物主义战士.jpg</p></li>
<li><p>和 runzhi
交接了实变函数教材，<del>精北人就要用北大教材（其实是辅助，笑死）</del>，和
MO 时代看过的黄皮初等数论一样的配方，泪目了，爷青回
（x。<del>虽然社恐但还是努力鼓起勇气</del>一起吃了个饭，sync
了一下现状，了解了一点隔壁数院的情况。<del>听说他也不会码我就放心了（数院同学的代码水平都那样.jpg</del></p>
<p>吃饭的时候邮箱一直在跳消息（x），看到了一些去年暑培的时候知道的神的
id（草，我居然还参加过贵系暑培，真蚌埠住了）出现在社友的博客评论区，一个吐槽了一句求真的（伪）数学人混在里面瑟瑟发抖（（</p>
<p><img src="https://s2.loli.net/2023/03/05/bXKi5BtLWSGC1Tw.jpg" alt="84670501B286AFA082D8BDC324E82B69.jpg"></p>
<p>来个很怪的改图（</p></li>
</ul>
<h1 id="月6日">3月6日</h1>
<p>上课上着上着感觉有点难顶，statistical learning
的作业也有点写不来，想来是我头铁没把它安排在线性回归之后的原因，正常情况下应该统辅第四学期再上。感觉迟早要退点课，但是看了看课表又觉得明明全都是任选课，却完全没有可以退的，要退只能退必修，怪事。</p>
<p>下节课开始概率论目测要讲点初等的（我乱说的，我真的是目测的），这我熟，趁机缓一缓，补一下之前的东西吧。</p>
<p>轻微破防，所以晚饭后光速测评了七港九甜筒：好吃，比清青快餐不知道高到哪里去了。不过今天这支甜筒从下面往外漏融化了的冰激凌，很怀疑是不是最下面的尖尖没闭合，实际上这个蛋筒只有一个面。走在路上手忙脚乱找纸巾的时候想起来，有点像画画的时候轮廓线没闭合就往里填色，结果整张图都填上了（</p>
<p>胡思乱想着就一边走一边乐了，没心没肺活着不累。</p>
<!--好吧，其实到晚上就又 emo 了。有时候觉得我就是干啥啥不行，来学数学了数学学不好，统辅课也寄，自己专业的专业课更学不会，即将延毕一年并且一事无成，乐。朋友们都是卡密的结果居然是我一直觉得自己也还行，而不是意识到自己是个废物，这是否有些（-->
<!--寒假应该听 V1ncent19 的学一下线性回归的，但我寒假也不是什么都没干啊，我学数分去了。好像也没什么问题才对？既然没什么问题那怎么就是忙不过来啊 kora（-->
<p>天气好热，是要放暑假了吗（错乱。过两天我都想穿裙子了，室友还在穿羽绒服，respect。</p>
<h1 id="月7日">3月7日</h1>
<p>非常累，浑身疼，晚上上线性回归整个人都是麻的，推断课上学得很熟的东西都反应不过来，应该是最近缺觉缺太多了。感觉有可能要考虑把
statistical learning
退掉，肝不动，而且也不用太急，重点还得是那两门数学课。</p>
<!--看了下今天抽代终于登成绩了，虽然早知道是 4.0，但之前还在做一些 A+ 的梦（，果然还是期中拉胯了。想了想我觉得自己上得还可以的课基本都是稳定拿 A，既不是挂边拿 A-，也不是能展现强度的 A+，某种意义上来说属于是很平庸。数值分析、推断和抽代都是，还有个古早的逻辑专题也是（草（我现在想想当时还真的是一点基础没有，直接冲过来上这课，真的猛 -->
<!--笑死了，强度可能确实有一点，但是是平凡的。无论做什么都有人比我做得更好而已，在竞赛的时候不早就接受了吗，现在怎么忘记了。小事。-->
<!--算了，想想也别计较这个了，还是看看近处的实分析罢，最后绩点由 3 开头就是我赢了，或者说不退课遗憾离场就不错了。虽然我完全不理解数学系为什么要给成绩给成这个样子，为什么非要和学生过不去（或许下周例会可以去课咨委讨论一下，笑死）。想起来一个古早笑话，忘记是坚坚子还是齐齐子说的了，说绩点高低不重要，清华数学系已经很好了，大家没必要出国读书，本系保研就大家一样烂；C 和 D 不是放在那里看的，是要给出去的。乐。-->
<!--草，今天看了下教学门户登的原始成绩才意识到，抽代每次的 bonus 是加在作业分里的，但我作业本来就是满分所以全做完了也没加，我怎么会做梦会因为 bonus 而拿到 A+ 的（，总成绩还得是期中期末两锤子买卖，这下白做了（x）。开玩笑的，其实 bonus 比书后习题设置得深刻多了，到后面还趁机学了些拓扑，以此为契机还和 Bowen L 认识了一下，对我来说是非常珍贵的记忆。-->
<p>趁明天要上早八，找借口早点睡了，大家晚安。</p>
<!--来点转数环里看的求真笑话再睡：-->
<!-- - 据求真书院的同学说，数学史现在是六学期，每年一篇 50 页论文-->
<!-- - 求真的花活越来越多了，而且为什么求真这么喜欢很多事情都强迫学生干-->
<!-- - 为了十年大成-->
<!--想想我之前还憧憬过保研到 YMSC 去，真是脑子有问题。虽然出国这个问题至今让我轻微难过，然而为了更好的发展，没有别的选择。前两天晚上看到一些东西，于是给一个我猜会直接保研的朋友手写了一小段话：-->
<blockquote>
<!--虽然我想在未来的动荡里，我的确很难和你再相遇。离开华子后，这个世界还有千千万万，很抱歉我无法停留。-->
<!--但是，[someone] 的存在就已经证明了，我的拐弯抹角、难以表达的想法总有人能理解，而这便是我最大的愿望了。-->
</blockquote>
<!--写完之后又有点想笑：我还在落款里标好了时间，想着毕业之类的时间点能把它送出去，然而真的可以一直做朋友到那个时候吗？以及，到那个时候各自的计划真的顺利进行了吗，不如说，我真能有那么顺利？（-->
<!--所以先贴在书架上了，万一真有机会送出去呢。-->
<h1 id="月8日">3月8日</h1>
<p>无事发生。只是一边焦虑一边做事情，才第三周就各种挫败，预感到了这个学期的艰难。想想还是不写下来释放负能量了（</p>
<h1 id="月9日">3月9日</h1>
<ul>
<li><p>最近一直在考虑换个头像，但又不知道换什么。现在这个裁成圆形或者看小图似乎有点抽象，尤其小图看起来像意义不明的三个色块<del>（可以抬头看一眼
favicon）</del>，<del>主要是，根本看不出来是个人啊！</del></p>
<p>还有一些来自同学的吐槽，上次有同学告诉我没放大看之前一直以为我微信头像是美少女抽大烟，我真绷不住了，还有不少以为这疑似是个情头，<del>难道是背对着背，或者是把泡泡吹对面的人脸上吗（</del></p>
<p>但是又用习惯了，恐怕认识我的人也看习惯了，<del>按头像和 id
开盒也习惯了</del>。以及按我的强迫症要换必然是全平台换掉，好像根本找不全，有点麻烦啊。就算要换也不知道换点什么，<del>现在觉得换什么似乎都没那味儿</del>，毕竟想长期使用而且希望能有辨识度，这个也用了四年多了来着。<!--沃日，说到这个时间节点就想吐槽一句，还没和 ex 分手的时候我就在用这一套了，前两天看到他都又找到 npy 了（真是个奇迹），我怎么还在用这个（--></p>
<!--说起来今天想了想我的青春疼痛文学连载（草）也该到此为止了，完结撒花。（？？-->
<p>果然好麻烦，算了，这辈子很快就过完了，先忍一忍罢（草</p></li>
<li><p>时间管理大师了一整天，什么都没做但反正挺忙的，怪事。</p>
<p>晚上做物理实验一共四排座位，结果第四排就我一个人，在一个阴暗的角落里面壁做实验。现在还在做基物实验
2
的不是电机班的就是上学期退了课的，我这一组好像电机的同学格外多，实验课上大家像团建一样快乐，恐怖，还好有个角落可以给我面壁，没有被夹在人群中间（。不过面壁做实验倒是格外快，安排了
4h 的时长，不到 2h 就速通完跑路了，下次还面壁。</p>
<p>回教室坐了一个半钟头又来课咨委开会，大家以庆祝女生节和迎新的理由一起分了蛋糕和奶茶。把女生节单纯当团建就挺好的，<del>虽然不要有这个节日直接团建更好</del>，没有单独的礼物就是好文明（。越来越感觉我在课咨委的开会环节就是混吃混喝的，每次来吃完东西就开始一边和大家讨论一边写日记，写完日记就去写线性回归的代码作业，写完代码就该回寝室给电脑手机充电了（（</p></li>
</ul>
<h1 id="月10日">3月10日</h1>
<!--来到了传说中的秋季学期成绩录入 ddl，我的体育课到底过没过啊，咋还不出分（。离散确实是让我白嫖了 GPA，虽然我上学期无数次怀疑自己是不是脑子有问题才选了这门课折腾自己。这学期一上来居然发现还好离散给我讲了可列集和基数，不然我缺的这块营养谁给我补啊.jpg-->
<!--在寝室里跟室友开理发店痛骂工程经济学，同样是开学速成的，离散怎么就能 4.0，明明还多 1 个学分（x）。室友锐评说因为离散里面带了数学俩字，那我肯定会往 4.0 冲，我超，笑死了。-->
<ul>
<li><p>早晨去技科楼上课，路过中央主楼的时候看到门口的草坪上喷灌装置开了，室友特地绕到旁边骑了过去，溅了一身水，说很凉快。</p>
<p>我一时不知道该不该告诉她，学校喷灌用的水是中水，大概就是把污水净化了一遍，水质在排水和给水之间，达不到自来水的标准。这可能是我认识实习学到的唯一一件事情，想了想打算下次在寝室吹水的时候假装随口说一下（</p>
<!--草，又想起来去年社聚时候那个中水池了，茨月老师往假山上爬的时候我真的在想他要是掉进去怎么办（--></li>
<li><p>上学期在<a href="https://mp.weixin.qq.com/s/4HQE2Hpq2sWjvxodKtfL9A">果壳的文章</a>里看到，玉兰花苞的手感像狗狗的额头（好怪，当时是秋天，不能立刻实验一下，就想着今年春天要记得去摸一摸玉兰花苞是什么手感。今天在人文学院旁边的斜坡上看到了玉兰树，去摸了一下才意识到，没摸过狗狗，好像也没法对照（</p>
<p>一回头正对上一个路人看着我的疑惑的眼神，社死了。</p>
<p><img src="https://s2.loli.net/2023/03/10/S4JdsMxfyUWPqe9.jpg" alt="magnolia.jpg"></p></li>
<li><p>闲来无事扒拉统计中心的网页，发现 dwl
老师从讲师升副教授了。所以这个是教学系列的副教授，还是她跨过 AP
直接升了两级？她带科研吗？不是很懂诶。</p>
<p>上学期在她初概课上记 PF
开摆，今天在她多元统计课上做题的时候她还来和我聊天，还叫出了我的名字，我超，怎么还记得我（，绷不住了，越想越尴尬。</p></li>
</ul>
<h1 id="月11日">3月11日</h1>
<p>这两天被《Young And Beautiful》戳到了：</p>
<blockquote>
<p>Will you still love me when I'm no longer young and beautiful?</p>
<p>Will you still love me when I got nothing but my aching soul?</p>
<p>I know you will, I know you will, I know that you will.</p>
</blockquote>
<!--晚上去面试了下答疑坊招新，坐在旁边等的时候听别人的问题：黎曼函数无理点连续性，指数分布无记忆性，听别人答不出来我还有点急，想着这不有手就行。轮到自己：上来一个当初就没学会的多元微积分，再来一个矩阵微分，后面一个要用特征值做的线代到底是看出来了，然后一点统计相关。-->
<!--乐死了，感觉很寄，希望人没事。-->
<h1 id="月12日">3月12日</h1>
<p>植树节好耶。看到蚂蚁森林有新的树种了，准备继续解锁一个全图鉴。</p>
<p>突然想起来一个 MO
时代的同学的生日似乎就是植树节，不过之前发现他把我联系方式全删了，倒是没删明日方舟的好友（，寒假回坑的时候看到还挺感慨的。</p>
<p>我到现在怎么还记得他的生日呢，但其实印象也不深刻，不确定是否真的是这一天。这段记忆可能本应到明年就彻底忘记了，但我今天写了这些话又加深了印象，就不会忘了。他又为什么要删我好友，因为看我已经远离了高中同学的圈子，或者太久不联系了觉得没必要保留联系方式吗，感觉应该没什么矛盾才对，<!--倒也可能是我太糙了，有矛盾但是并没有感觉到（悲），-->还是说觉得我太菜了（，天知道（</p>
<h1 id="月13日">3月13日</h1>
<!--今天在两边的日记里看到了 Eren 和 AQ 的割席，尽管我对 AQ 只是单向赛博认识，以及在 statistical learning 课上见过几次。又想到了 Eren 年终总结中真诚的话语，令人感叹。-->
<!--我印象里的 AQ 是一个性格鲜明，生活饱满的人，大概是和我这种天天阴暗自闭爬行的人截然相反的类型，Eren 也一样。所以才会因为事关理想的争论而割席吗？以及因为认识 Eren，受到过一些关于交换、延毕方面信息的帮助，读他的文字也更多些，觉得他是一个善良真诚的人，或许他所认可的 AQ 也是一样的？-->
<!--其实我不是非常能明白啦。倘若有朋友愿意和我谈论理想和未来，我大概是能包容多元的想法就尽量包容，能避免冲突就尽量避免的。不仅是因为我的性格没那么鲜明，只要是合理的想法我都能理解，我也实在害怕失去愿意和我谈论这些的朋友，太稀少了，对我来说相当珍贵。如果是面对和更亲近些的朋友的分歧（印象里倒也没怎么发生过），我真的不知道我会不会反复思考自己是否有问题，甚至愿意去改变自己。说得严重些的话，我实在是过着一种得过且过的生活（，这也没有办法。-->
<ul>
<li><p>右边智齿旁边的牙龈肿的越来越厉害了，昨天还因为发炎低烧了，以为是甲流，跑了一趟发热门诊，检查了半天最后开了一盒甲硝唑片被赶回来了，笑死。真神奇，我总是能在某一种传染病流行的时候，生一些其他症状类似的病来吓唬自己，实在不知道这算是身体好还是身体不好（</p>
<p>去年这时候是左边智齿在发炎，痛得不行，三月某个下大雪的日子心怀愧疚地用美团买了一堆药，吃了一周才好。适逢上海封城家里一团乱，加上身体上的不适，天天自闭，看到玉兰树（白玉兰是上海市花，街上随处可见）都会
emo
的程度，笑死了。这次只是肿但并不痛，情况稍微好些，只是这几天大概不能吃辣了。</p>
<p>所以吃点冰的可以给牙龈消肿吗，我指的是，冰激凌什么的（x</p></li>
<li><blockquote>
<p>其实我不是非常能明白啦。</p>
<p>倘若有朋友愿意和我谈论理想和未来，我大概是能包容多元的想法就尽量包容，能避免冲突就尽量避免的。不仅是因为我的性格没那么鲜明，只要是合理的想法我都能理解，我也实在害怕失去愿意和我谈论这些的朋友，太稀少了，对我来说相当珍贵。</p>
<p>如果是面对和更亲近些的朋友的分歧（印象里倒也没怎么发生过），我真的不知道我会不会反复思考自己是否有问题，甚至愿意去改变自己。说得严重些的话，我实在是过着一种得过且过的生活（，这也没有办法。</p>
</blockquote>
<!--这段话是可以完全公开的情报，只是叙述我自己的懦弱而已，想到说这些的原因还是塞注释吧（--></li>
<li><p>抄了一天 Caratheodory Extension Theorem 的证明，用了<a href="http://www.probability.net/WEBcaratheodory.pdf">这个框架</a>，还参考了一下<a href="https://www.mat.univie.ac.at/~westra/caratheodory.pdf">这个注解</a>，拼拼凑凑做完了，感觉挺有意思，<del>之后还可以把解法发出来水一篇文章</del>。<!--感觉可以周五毛概课上写（，闲着也是闲着，就当练练打 LaTeX 也好啊，我写 LaTeX 的速度完全跟不上思考的进度，上次试着写了一次电子版的统辅作业，脑子比手快，太痛苦了。-->某次课上听到
lzx 好像是说这个 bonus
反正是不大可能独立做出来，能完整抄一遍就算是有收获，<del>所以这是否就是他把考试设置成默写的原因</del>，他讲话我也一直不是很能听得清（。我的收获大概就是觉得好玩吧，那倒也值了。</p>
<p>实际上在实分析课上自己看书跟不上进度，想了想别人比我多学一年半又不是白学的，也正常。概率论一如既往不知道
lzx 在说什么，写完 bonus
回头一看发现正课一地鸡毛，全靠面向作业题看书，挺惨的。</p></li>
</ul>
<h1 id="月14日">3月14日</h1>
<ul>
<li><p>Happy <span class="math inline">\(\pi\)</span> day！</p></li>
<li><p>本来觉得沙尘暴也没什么，今天在路上骑车看到被风卷起来的树叶渣子和灰尘对着我飞过来，突然明白了最近为什么头发油得这么快（，是否有点后知后觉了。</p>
<p>上体育课手被毽子划破了，怎么听都很离谱但确实是这样，不愧是我；下午开始腰疼得像要断了一样，不知道是不是本来就腰肌劳损，上个体育课反复捡毽子还仰卧起坐，结果加重了。好痛的一天（</p></li>
<li><p>（昨晚）睡前读完了《春琴抄》<del>不是写不完作业了来着吗</del>，还挺不错的，打算买本纸质版的留着。有空再去读一下《细雪》。</p>
<p>我经常读书第一遍是读电子版或者是读借来的书，看完觉得很喜欢才会买纸质的收藏，买来可能就留着偶尔再翻看，或者朋友过生日之类的时候直接当礼物送出去（<del>经典除了送书之外不知道礼物还可以送什么</del>。<!--稍微暴论一下，其实吧，与其说是不知道送什么就直接送书了，不如说我根本是不想思考还能送点什么，就直接在几个朋友面前立了个直男（？）人设，于是送书也皆大欢喜了。以前给 ex 的各种礼物还真是没重过样。说好不写青春疼痛文学了（，只不过想起来还是觉得，莫过热忱少年心，可惜全被无视了。他真是不配（划掉-->数学书倒是反过来的，因为会一边读一边在上面写写画画，就直接买纸质版，也不会当二手再传给下一届什么的。</p>
<blockquote>
<p>一天清晨，佐助偷偷地到女仆的屋里拿取了女仆用的镜子和缝衣针，端端正正地在床铺上坐好，对镜把针插向自己的眼睛。佐助之所以这样做，并不是掌握了用针一刺眼睛就会看不见的常识，他无非是想试试可否用尽可能简便、痛苦又小的办法来变成盲人。他试着用针插入左眼的眼珠，但是要刺中眼珠，好像很不容易。而眼白部分较硬，针刺不进。眼珠毕竟软些，他轻轻刺了两三下，才咯吱一声响，刺进了两分光景，眼珠旋即一片白浊。他觉得失去了视力，既没有出血、发烧，也没有感到什么痛苦，这是因为水晶体组织遭到破坏，便成了外伤性的白内障。佐助又以同样的办法刺中了右眼珠，顿时双眼都瞎了。当然，听说刚刺瞎后的那几天，还能蒙蒙胧胧地看到物体的形象，但是过了十天光景，就完全看不见了。</p>
</blockquote>
<blockquote>
<p>佐助能自然而然地领会春琴肚里的意思。佐助觉得，迄今为止，他俩虽然有着肉体关系，但是师徒关系一直使他俩不能心心相印，而今才真的合二而一，汇到一起来了。佐助想起了少年时期在壁橱中的黑暗世界里练习三味线的事，但是彼时的心境同现在是不可同日而语的。盲人大多只具有光的方向感，因此盲人的视野是朦胧有光的，而不是一片漆黑。佐助明白，自已今日虽然失去了观察外部世界的眼睛，却也同时睁开了审视内在世界的眼睛。“呜呼!
这才真正是师傅居住着的世界呀! 我总算能和师傅居住在同一个世界里了。”</p>
</blockquote>
<blockquote>
<p>春琴问:“佐助，痛吧?”</p>
<p>佐助把瞎掉了的眼睛朝着能感觉到有春琴脸庞存在的发出浅白色光晕的方向，答道：“不，我没有感到痛。同师傅的大难相比，这一点儿事算得了什么呢?
那天晚上，歹徒潜入房来，使师傅遭此大难，我却一无所知地睡着了。这实在是我的疏忽造成的。师傅命我每晚睡在隔壁，原是要我注意警戒，不料铸成了这样的大祸，使师傅蒙受苦难，我自己却安然无事。想及这一点，实在难以安下心来，唯希望得到惩罚。我朝夕向神灵叩拜，祷告着：‘务请也赐给我灾难吧。如此下去，我实在无地自容哪。’
我有幸能感动上苍，遂了却了心中的夙愿。今天早晨起床，发现两眼就这么瞎了。这一定是上苍同情我的志向，使我如愿以偿的吧。师傅啊师傅，我已不能看到师傅受难后的面容了。而今我所见到的，只有师傅三十年来根植在我眼底深处的可亲的面容。请师傅像从前那样，放心地留我在左右伺候吧。唯猝然失明，可恨举止不能如意，伺候上会有欠敏捷。但是，师傅至少得把日常生活上的琐事交给我来伺候呀。”</p>
</blockquote>
<p>意犹未尽，去看了一些豆瓣书评：</p>
<blockquote>
<p>谷崎以闲笔写出了这个故事的本质：春琴嗜养黄莺，将野生的小雏鸟在尾巴还没长出来以前活捉，让其跟随师父黄莺练习啼唱。若等到尾巴长出来之后就为时晚矣，“因为已经学会母亲的粗笨啼声，再也无法矫正了。”佐助的境遇犹如黄莺，他的恋情全然建立在自己的盲目之上，不管盲的是心灵还是眼睛。这个爱情故事让人打心眼里哆嗦，谷崎真是太爱阴翳之美了。</p>
</blockquote>
<blockquote>
<p>有些「不知怎的」实则是有意为之，有些「诞罔不经」原来只是习若自然，「雪中春来黄莺冻
泪眼如今正模糊」以后告白可以用----你就是我的初音之鼓</p>
</blockquote>
<p>太会写了，笔能不能借我用用（落泪</p></li>
</ul>
<h1 id="月15日">3月15日</h1>
<p>我总觉得实分析和概率论我都学得很云，实分析作业日常绷不住，概率论还好点，作业也老是被挑一堆小问题，麻了。</p>
<!--哪天实在绷不住了就跑去搞实用统计罢，横扫数学做回工科生。今天看了一眼 V1ncent19 的 offer list 发现他还中了 UCB 的 MA 项目（虽然我不明白为什么会是个 Master of Art），是否说明统计真没那么难申请，虽然目测是一年制 + 就业导向，但还是震撼我。退路大概就是问家里借钱读个 MS 然后毕业找工还债算了（恼）。我不完全是开玩笑的，虽然不影响现在还是努力学啦。-->
<p>花了半天紧急重制了 Proof of Carathéodory’s Extension Theorem
顺带往前复习了一下，发现第一版写出来好多口胡，麻了。最后完全放弃了修改我也看不懂了的手写版答案，虽然手写理应更容易混过去（，打算交打印稿了。<del>逐渐被同化</del></p>
<p>中午吃饭回来的路上已经开始第三节课了，于是在空无一人的六教车棚里一边走一边（用正常说话的音量）哼了几句歌（不好听x），回头一看角落里坐着一个看车的大爷在盯着我。很久没有这么极致的现实世界的社死体验了，记之（</p>
<h1 id="月16日">3月16日</h1>
<p>没啥可写的，一如既往、普通的写作业写得想死的一天（</p>
<!--晚上来课咨委喝奶茶治愈了一下，点了杯加了麻薯的，黏黏糊糊，可能时间太晚了，喝得有点难受。喝完回寝室不久看到欧老师说去跑步了，绷不住了，负罪感拉满（x。想想我确实是缺乏一些身材管理，不过我并不是很 care 这个，~~另外穿衣合适的话还可以掩盖掩盖（草~~-->
<!--这学期打算社工全面开摆，课咨委这里的工作量只有心情不好的时候找那门工程计算机制图的老师吵架。答疑坊的结果什么时候出啊，缺钱了（不是x -->
<h1 id="月17日">3月17日</h1>
<ul>
<li><blockquote>
<p>我每天都在“我想确定每日挽住同样的手臂”和“我不是火车不需要终点”之间起伏徘徊</p>
</blockquote>
<p>太会写了，笔能不能借我用用（落泪</p></li>
<li><p>坏消息：发现包里随身揣的香水瓶子好像漏，可这明明是个玻璃瓶？</p>
<p>更坏的消息：我看不出来它哪里漏，但就是漏一手（（</p></li>
<li><p>昨天写概率论作业，看到书上有一个 direct mapping
还打了引号，稍微有点不知道是什么意思。于是查了一下，啊，怎么看起来是个计算机术语？<del>还点进去看了一下，以为能从中获得什么启发，草</del></p>
<p>一定是我打开的方式不对，就去 MSE
查了，结果只有随意用这个词的，没有解释它是什么的。自闭了，开始自我怀疑，不会是我缺的这一年半的某些课里讲过的概念吧，看着也不像啊，抽代里都没有这个，难道是什么黑话（？呜呜那怎么办，我好菜我为什么要来上这些课会不会被迫期中退课啊那我以后怎么办我真的要转数吗我行不行啊（虽然听起来很草但真的在这么想（</p>
<p>直到今天翻到前面的定理，突然发现习题指向的定理里写的是 inverse
mapping <span class="math inline">\(X^{-1}\)</span>，习题问的是 “direct
mapping” <span class="math inline">\(X\)</span>。恍然大悟，看来就是指
<span class="math inline">\(X\)</span>
罢了，没有暗含什么性质的意思。可恶啊，直接说 <span class="math inline">\(X\)</span> 不好吗，非要讲 direct mapping
也就算了，打引号干什么（</p></li>
</ul>
<h1 id="月18日">3月18日</h1>
<p>我完全理解了，睡六个小时可以学统辅课，睡七个小时可以学概率论，只有睡八个小时才能学进去实分析，睡六个小时以下只能看物理实验（</p>
<p>今天睡足了之后来教室看了一天实分析，感觉自己又行了。不过一写作业又不行了，乐（</p>
<p>晚上去知乎<a href="https://www.zhihu.com/question/583634968/answer/2942599052">答了个题</a>，感觉肉眼可见迟早会变成我的知乎黑历史之一，但是无所谓，黑历史多到已经没有什么可害怕的了（（</p>
<!--草，怎么也没想到第一个也是到现在唯一一个给这个回答点赞的会是 ex（虽然这样就开盒了，不过看他知乎也没什么，罢了），我真绷不住了（-->
<!--草，今晚看到 ex 还关注我知乎账号了，我绷不住了，然后想想也没什么绷不住的，他早就当我死了，ok，又绷住了（，进行一个毫无必要的礼貌回关（（-->
<h1 id="月19日">3月19日</h1>
<p>一下午写完了实分析作业，我是真能拖。每次都美其名曰先把别的写完周末再用整块的时间写，但其实平时整块的时间也不少，为什么不能像统辅课一样一布置就写完呢（。想来还是之前进度落下太多了，一直畏难。不过这周末把前四周的内容串（抄）了一遍，之前觉得理解不能的东西现在再看倒也还行（什么暴论，作业不会写倒也不是我的问题，是
ly 每次都非要布置还没讲过的内容（恼（什么暴论</p>
<p>晚上难得在外面电脑没电了，只好放下生统概论的 ANOVA
作业，回头想了想概率论没做出来的题，在教室关门前几分钟写出来了，运气不错。</p>
<p>感觉我的 ddl
是稠密的，好不容易赶上进度，晚上还得接着写别的。下周两个物理实验都要交完整报告，很难绷，不过还好光栅上学期写过最后又退课了，改一改就好，大概。</p>
<h1 id="月20日">3月20日</h1>
<!--今晚在寝室吹水，室友说她妈妈对她的期待就是，“能从清华毕业就好，反正你以后就是要去做家庭主妇，有知识有文化能教育好小孩就行了”，以及她也乐于接受这种听起来轻松的人生，从现在开始往后就不必太努力了，考上华子就是终点。听得我难过不已。她家甚至还是上海土著..-->
<!--咋说呢，我也没说什么，另一个室友已经开劝了，我是没有这个心情，想起来《不能承受的生命之轻》，摘一段放这儿好了：-->
<!--最沉重的负担压迫着我们，让我们屈服于它，把我们压到地上。但是，最沉重的负担同时也成了最强盛的生命力的影像。负担越重，我们的生命越贴近大地，它就越真切实在。相反，当负担完全缺失，人就变得比空气还轻，就会飘起来，就会远离大地和地上的生命，人也就只是一个半真的存在，其运动也会变得自由而没有意义。那么，到底选择什么？是重还是轻？----《不能承受的生命之轻》-->
<ul>
<li><p>上上周末在答疑坊面试，表演了一个裸考结果被刘通问到自闭，一周多时间都没有消息还以为<del>被默拒了</del>挂了。最后还是过了，<del>我那个筛子一样的数理基础都能过，看来标准确实不高</del>，<del>好哦，长期饭票有了</del>。下午看到消息乐了小半节实分析课，最后忘了记作业是哪些就走了，草（</p></li>
<li><p>骑车出门上课的时候随便哼了几句歌，可能是昨晚刷 b 站看到一个 AI
模仿姚贝娜声线的视频，今天突然想起来的是她的《画情》。想了半天才发现她已经去世八年了，从前我很喜欢她，也循环听过不少，在那之后却很少再听这些歌了。今天发现这么多年过去，我还是能完整地把《画情》的前几句词唱下来，<del>不知道脑容量都用来做什么了</del>，开玩笑的，还记得就真是太好了。</p>
<p>于是又去听了些从前听得很熟的歌，是一听到就会感叹不愧是当年的青歌赛冠军这样的程度。</p>
<p>一时兴起开了下随机播放，于是听到了歌单里一段时间没听的《<a href="https://y.music.163.com/m/song?id=416554199&amp;uct2=mGxNldB64AuRISyRFGJ2PQ%3D%3D&amp;dlt=0846&amp;app_version=8.9.50&amp;sc=wmv&amp;tn=">Promise
with You</a>》，我的社交媒体终于有一个统一的意义不明的背景图了：</p>
<p><img src="https://s2.loli.net/2023/03/20/IZF8TUWtfeBgXkY.jpg" alt="banner.jpg"></p>
<p>但是写歪了啊（恼</p></li>
<li><p>概率论课上随手翻了一个社友的主页，找到了一个 Recursion
几个月前发的<a href="https://zhuanlan.zhihu.com/p/24709748">矩阵求导术</a>，看了两节课。正好最近多元统计要用这些东西但我不是很熟，答疑坊面试的时候被问了一个矩阵微分还挂了（悲），不知道是不是因为数分高代没学完整。谢谢雷克森老师（逃</p></li>
</ul>
<h1 id="月21日">3月21日</h1>
<ul>
<li><p>我之前还以为 lzx
这个概率论完全不打算讲常见分布函数了（指的是，布置成自学
x），倒也没那么恐怖，看他这周布置的作业基本都披着初概题的皮（，一时没什么压力。这两天大概可以顺便把第二次
bonus 写完，大概。</p>
<p>——这是我中午写的。理论上确实是这样的，但是今天下午去教室直接先睡了一个小时致敬世界睡眠日，啥都没写完，吃饭来回路上一直在纠结一个
trivial
的分布问题，差点被车创（，感觉周二上了体育课就会很降智。</p></li>
<li><p>期中真打算把统计学习导论退掉了，第一次作业直接表演了一个没交（，时间不充裕的话我还是不想把它水过去。前两天在课咨委听了一个冷知识，本学期全校排课最多的时段是
3-2，这也确实，3-2
根本找不到教室<del>自习</del>摸鱼。所以说不会退课了还要因为没地方去而跑到俞
sir
那边听课吧（，这也太捞了。不过大作业汇报的时候倒确实可以去浑水摸鱼偷师一下，<del>感受下大家的卷度来判断明年是不是记
PF，草</del>。</p></li>
<li><p>几天没上树洞，今天才发现 V1ncent19 和 Mariana 在筹备整 THU stat
wiki，正好晚上 V1ncent19
还来私聊我了，真不错，我也打个广告。详细的打算见<a href="https://thuhollow.github.io/##246458">树洞帖</a>，需求调查可以填这个<a href="https://wenjuan.tsinghua.edu.cn/s/FzAFfa/">问卷</a>，如果搞得起来（x）的话大概会在上面看到一些我的稀碎笔记，真挂上去感觉要被<del>拷打</del>勘误到邮箱爆炸（</p></li>
<li><p>我已经想好下个月日记的摘要写什么了，就写“点击查看驰雨老师两年来最艰难的一个期中月
↓”。</p></li>
</ul>
<h1 id="月22日">3月22日</h1>
<ul>
<li><p>Sophomore = Suffer More</p>
<p>不知道为什么，实分析早八是我造梗最密集的时段<del>（前情回顾：困难，五教
=
午觉但是早八）</del>，虽然今天咕掉了，九点在床上醒来（）的时候还是突然想到了这个（</p>
<p>早八确实还是去上一上比较好，让一天早一些开始（</p></li>
<li><p>本来以为今天是 Statistics &amp; Probability
Day，可以处理完概率论和线性回归，没想到 statistics 蒸发了，虽然
probability
也没完全学会（，线性回归又往后拖了一天，急急急急急。写完作业和第二次
bonus，读 Kai Lai Chung
的进度差不多赶上了上课的进度，这周的概率论就学到这里了，感觉学每门课的时候都还是得提醒一下自己这学期还有很多别的课（</p>
<p>不过还是很有收获，学初概的时候怎么也不可能想过构造随机变量期望函数和构造一般可测函数积分是一回事，可测函数积分是用简单函数一步一步逼近得到的，对应到随机变量期望就是用离散分布逼近。本来还抱怨过实分析太难、这学期还不如就选复分析养生顺便水成绩来着，到这里才觉得开学后临时换课这个操作太正确了，不然看到
Kai Lai Chung 第 44
页那串不加证明的定理恐怕要昏过去，实际上不过是照搬了可测函数积分那一套。</p></li>
</ul>
<h1 id="月23日">3月23日</h1>
<ul>
<li><blockquote>
<p>A:</p>
<p>我局的需要夹带一些私货了！</p>
<p>大家可以判断一下自己是喜欢“学”数学还是“研究”数学</p>
<p>如果只是前者的话你在本科可能过得挺爽但是到研究生回比较痛苦！</p>
<p>B:</p>
<p>首先排除喜欢学x</p>
<p>真的卷不动力！</p>
<p>研究没试过，不知道（</p>
<p>A:</p>
<p>而且如果单纯是前者那其实不转来数学系也许会有更好的体验！（？？？？？</p>
<p>C:</p>
<p>但一般人很难判断清楚</p>
<p>比如我这种菜鸡到现在也没有搞明白</p>
<p>D:</p>
<p>这种在学习初期还是很难判断的吧</p>
<p>A:</p>
<p>感觉还是得跟个老师进一下科研状态感受一下</p>
<p>E:</p>
<p>太难判断了</p>
<p>A:</p>
<p>也对 我也是这段时间才开始考虑这个问题</p>
<p>而我现在已经大五下了</p>
<p>E:</p>
<p>而且研究还看天分？</p>
<p>A:</p>
<p>看但没那么看</p>
<p>不好说 我还正式没开始做研究！</p>
<p>这个是前人告诉我的</p>
<p>B:</p>
<p>我知道，做研究反正很看重睡眠质量</p>
<p>睡不好是没精神做研究的</p>
<p>嗯，所以早八见了各位x</p>
<p>A:</p>
<p>这个看个人习惯</p>
<p>比如我一般两点到12点是睡觉时间</p>
<p>但是9小时+的睡眠一般是能保证的</p>
</blockquote>
<p>原来环友们也都没整明白，那我就放心了（（什么</p>
<p>最喜欢的一集：</p>
<p><img src="https://s2.loli.net/2023/03/23/bhgYkfa8xUCEiPd.jpg" alt="804E98F016E4D5E40841D83D8FC83F04.jpg"></p></li>
<li><p>答疑坊迎新会来太早了，感觉大家都不怎么社恐，而且人太多了，就很害怕（</p>
<p><del>啊啊啊啊啊救命我为什么要加入 30
个人以上的社工组织，为什么要来这种大家原来就看起来已经很熟了的地方，为什么为什么为什么为什么，好可怕啊好可怕啊我能不能现在就走啊，但是好不容易通过面试的好不容易找到一个长期饭票的不要在这一步就放弃比较好吧，啊啊啊啊啊啊啊啊啊啊啊啊啊啊</del></p>
<p>——开会之前我是这么写的，草。</p>
<!--午饭后揣着个电脑走去五教开会的时候对着玻璃门里的影子看了看自己，感觉像是从三教偷了个电脑出来。本来以为会来很多人教室很局促，就没有带包，结果到场人数并不多。看了一眼用来请假的那个共享文档才知道其实很多老队员都没来，大家不是在开软工例会，就是作为助教在开软工例会，要么在从游节，也有实验、组会之类的理由（--></li>
<li><p>其实物理实验室是我在教学楼里见过插座最多的地方，<del>下次能不能来实验室自习</del>。日常
2h 速通实验，今天再来 2h
就能把实验报告写完，好事。<!--八点做完了实验，十一点半就把报告交上了，实在有点抽象--></p>
<p>翻了下近一周写的日记，感觉，怎么看起来就一直在写作业，此外啥也没干（好像我其余确实也不干啥（悲</p></li>
</ul>
<!--说起来今天吃完午饭走的时候正好遇到了 neruko 老师，虽然她并没有认出我来，我当然也没敢上去打招呼~~毕竟甚至不知道有没有认错~~，就事后发了个微信问问，确实是她。#每日食堂迷你社聚 #每日脑内社聚成真-->
<!--一天被各种事情切成了很多段，说实话我一点也不喜欢这种生活节奏，光是通勤就很累，而且事情一多我就容易犯蠢，连带瓶咖啡出门这种基本操作都忘了。-->
<!--下午还睡了一觉，最近腰疼本来就有点发作，加上生理期，痛得我感觉人要断成两截。暑假回家（如果回家的话）想去中山医院检查一下脊椎和腰椎，不知道除了腰肌劳损之外还有没有什么别的毛病，别给我整个什么脊柱侧弯、腰间盘突出之类的惊喜。-->
<h1 id="月24日">3月24日</h1>
<blockquote>
<!--我要求你们将物理学最基本的四大力学学好，就是经典力学、电动力学、统计力学和量子力学，还有广义相对论也都要学好，这对你们以后有很大的帮助。----摘自丘成桐先生在求真书院 2023 年全国优秀大学生冬令营开幕式上的讲话。-->
<!--四大力学 = 0 学分必修证实了，不会是四大力学 + 广义相对论 = 0 学分吧？！-->
<!--傻孩子们，快跑，快跑啊！-->
<!--已经报名定段赛了，15 盘如果能 9-6 就撕（求真推研）约转行练棋去了，反正我这个水平也毕不了业-->
</blockquote>
<!--每天都能在转数环看到新惊喜，不跨保求真的理由又多了一个，我就算历尽千辛万苦去成了也毕不了业。基物我都拖着不敢上，还搁这四大呢，还搁这广相呢，而且我一个搞概统的学这些有啥用啊，又要把本科毫无必要的痛苦再来一遍吗？哦，求真也基本上没有概统方向，那没事了，哈哈（-->
<!--地狱笑话：PIN，薛四金和谢丹都已经从 YMSC 润回数学系了，搞不好到我推研的时候数学系已经被求真多元化建设得很好了。哦不对，数学系推研只看 11 门必修，我没上完，没资格推研（（-->
<ul>
<li><p>我不是昨天才做过实验写了报告吗，为什么明天又要做实验写报告了？</p>
<p>光学电学都没学过就硬刚实验，虽然做实验也不需要会这些，但每次看讲义的时候我真都觉得自己挺抽象的。</p>
<p><img src="https://s2.loli.net/2023/03/24/keYIcxwGv1LjOSR.png" alt="approx.png"></p>
<p>瞳 孔 地 震，想起来这个梗图：</p>
<p><img src="https://s2.loli.net/2023/03/24/anM3PxhRWHZ89OL.jpg" alt="pi3.jpg"></p>
<p>但是把 <span class="math inline">\(\frac{3\pi}{8}\)</span> 近似成
<span class="math inline">\(1\)</span> 感觉已经不只是 pure mathematician
会暴怒的程度了（（</p></li>
<li><p>下午突然被拉进了 THU Stat Wiki Contributors 的群，里面居然还有
Vica，太梦幻了。V1ncent19 的速度是真的快，<a href="https://thu-stat-wiki.github.io/">已经搭好了</a>，虽然里面除了一篇测评之外还啥都没有（</p>
<p>好，下一步就是写内容了！所以是谁来写呢？（环顾四周）好像没有看到写内容的人诶？（思考）哦原来是我（</p>
<p>不过反正形式、板块分类之类的问题都还在商讨，不着急把我的破烂笔记搬上去。</p></li>
<li><p>刷了下空间，是人是鬼都在看铃芽，就我又写了一天作业（</p>
<!--看到 ex 和他现在的 npy 去看了铃芽，想起来三年前一起去看了天气之子，气的抓耳挠腮（quote from Revolver（，反手给他点了个赞（草什么啊（--></li>
</ul>
<h1 id="月25日">3月25日</h1>
<p>熬大夜写统辅课作业，睡大觉，起来半睡半醒中做实验，写了 16
页报告但是预计还要再多几页（，报告都快写完了也不知道霍尔效应到底是什么，一天毫无意义地离奇蒸发了。</p>
<p>有的时候我甚至觉得自己还挺擅长做物理实验的，虽然完全没学过，但一般都是前几个做完顺便把结果算好跑路的，还有过助教问我以前是不是学物理竞赛的，我想起上海高考那个近似于文科的物理我都实在是学不来，真的绷不住了（，只是在做实验之前就对已有资料拟合好了罢了。这学期到现在都是
2h
结束跑路，<del>把急急急急急发扬光大</del>。这是否说明理论课对实验有反作用（，或者说其实我这种一帧一帧做实验的方法就是最优的（</p>
<p>做实验的时候有同组的同学直接跑到我面前问问题，对话并没有“同学你好我想问一下”这样的开头，就直接问了，把社恐人惊到了。后来我对着号码查了下名单，才发现是自己班的同学但我完全不认识他（悲）但他应该是认识我，听起来很离谱但发生在我身上倒真的很正常（（</p>
<p>今天就光搁那儿大力录数据画图做线性回归 <del>顺便搞个 ANOVA table
玩玩</del>
然后说车轱辘话去了，结果到教室关门还缺一个分段拟合的图没画完，左半边是二次回归右半边是线性回归还要让它们连接得光滑一点，绷不住了，待会还得研究一波这怎么玩。数了数霍尔效应的实验有三百多个数据，又破防了一次。</p>
<p>做这些事情实在不需要动什么脑子，就开着随机播放写实验报告，结果感觉至少有五分之一的歌随机到就觉得不大想听，直接切掉了。这个歌单还叫“我喜欢”，看来也不是很喜欢（</p>
<p>明天又要踩 ddl
进行一个实分析的学，还好这周作业不多，可以的话想顺便把测度里面最基础的部分再看一看，然后再从头梳理一遍。对我来说学数学多迭代几遍教材还是有用的（大概吧，我自己是这样的，可能太菜了）<del>实变函数学十遍</del>。这周的时间投入显著不够，只能说都怪两个要写完整报告的物理实验叠在一起了，我还嗯逞能在周中写掉了概率论
bonus，<del>活该</del>。上学期学工程经济学的时候老师一直在强调资金有时间价值，或者说感觉学了一个学期就是不停在用这个事实，我现在感觉时间也有时间价值，不同时段的时间的价值也不太一样（</p>
<p>以及今天被提醒了是认识欧老师一周年（x），也说明我水社已经水了一年三个月了，一年多了啊，时间过得好快，完全没有感觉。这样的生活能一直继续下去的话也真的很快乐，<del>所以放心地延毕吧！（什么结论</del></p>
<h1 id="月26日">3月26日</h1>
<p>怎么大家都看完铃芽之旅了（</p>
<p>我不是不急着看，我是不想跑一趟电影院还要被夹在现充和情侣中间看，不过更重要的是我真的没空（悲）。来自社友们的风评并不是很好，吃午饭的时候又看了一遍《星之声》，<del>诚哥已经回不去了</del>。</p>
<p>今晚在路上遇到了 <del>近一年未见的</del>
班主任，和她打招呼的时候本来想叫一声 x
老师，但半天没想起来她姓甚名谁，她走了之后我翻了下班级群才想起来。我真绷不住了，我到底过着一个什么样的奇怪生活（</p>
<!--但至少说明我单方面和水利系，和书院都割席得很彻底，这是好的.jpg-->
<h1 id="月27日">3月27日</h1>
<ul>
<li><p>后面几天最高气温都在 20
度以上，可以放心地穿一周裙子了。前两天刚拿到今年买给自己的生日礼物，虽然生日还没有到，但还是在合适的时间就穿到裙子比较重要，就提前买了。去年也是买了裙子，明年能不能买点别的（</p>
<p>虽然有个很大的问题是大多数裙子都没有口袋，这次买的也是除了这个问题之外一切都很好，或者说，女装的口袋就是显著比男装少，设计师出来挨打。<del>不仅是社恐走路不插兜就感觉很不自在的问题</del>，去吃个饭我手里要捏着手机纸巾和卡包，还要拿托盘点餐刷卡，点个面的话汤还会漏出来所以也不能把别的东西放在托盘上，就很手忙脚乱。</p>
<p>第二天穿着这件裙子洗衣服又发现一个问题，手要用来搓衣服的时候手机就没地方放了，不能一边洗衣服一边听歌。也或许我需要买个蓝牙耳机，把手机放寝室里然后出去洗衣服，但感觉有点远，不知道能不能连上。我是真觉得耳机线挺重要的，没耳机线的话摔手机的次数
/ 丢手机的概率会增加很多，而且有线耳机不需要充电，非常方便（</p>
<p>花自己的钱买想要的东西果然非常爽。家人的审美和我向来不太合，所以我其实从小就很憧憬能够为自己的喜好买单。小学初中九年我的头发一直被剪成短的不能再短的短发<del>（我现在自己都很难想象是什么样子，还好没怎么留下照片</del>，直到初三的时候在家大闹一场才把头发留起来。从前还挺困扰的，一直对外表没有自信，会很害怕拍照甚至害怕照镜子，<del>还好我心大，后来就忘得差不多了，逐渐心安理得地接受了美少女的人设（草什么啊</del>。来华子之后陆陆续续给自己添置了不少喜欢的衣服，差不多把衣橱更新一半了，虽然是有点点浪费，但是可以自己决定自己每天怎样出门，对我来说就是很开心的事情了。</p>
<p>前两天和 neruko 老师发邮件 <del>瞎扯</del>
的时候正好聊到目前正在紧张刺激的奔二的末尾，笑死了。<del>至于是哪一天奔到二就不说了，虽然开盒应该也能开出来但只是我自己都不是很
care
的普通一天而已，还请大家不必当回事，hhh（感觉有点自作多情，为什么会预设成会有人当回事啊，草（</del></p></li>
<li><p>第一次在周一晚上就写完了前半周的实分析作业，这是好的；今天退掉了统计学习导论，这也是好的；上周四咕掉了概率论早八，今天发现还在讲经典分布，下节课应该还接着讲经典分布，相当于一下子让我摆过去三节课，这也太好了（</p></li>
</ul>
<!--最后一条是把晚上发的嘟嘟搬过来，太乐了，一定要在日记里记一下（-->
<!--晚上指导室友进行了一个拆机清灰，开始之前她还在说电脑散热越来越不行，打算周末去找 npy 看看怎么办 ~~（果然泛 CS 专业就是修电脑的）~~，现在她的评价是拆电脑真好玩 ~~靠男人干什么~~，草，感觉日行一善（1/1）了（-->
<!--不过考虑到最近博客的访客真的是激增（，被她 npy 看到的概率也轻微增加了一些，单纯记录就还是塞注释了（草-->
<h1 id="月28日">3月28日</h1>
<ul>
<li><p>我原来的打算是这个夏季学期不回家了，把大三的施工实习和大二的测量实习一并冲完，不影响明年可能会存在的暑研。测量实习是临近开学的两周，施工实习是前五周，二者本来也不冲突，但施工实习和军训撞了。草，太离谱了，一字班还没军训（</p>
<p>土水学院真的逆天，在大三小学期安排 4 个学分持续 5
周的现场实习，不允许任何形式的替代。虽然我不知道这个实习具体是做什么，但是听起来就像是要去打灰（。这下延毕的概率又变大了很多，<del>虽然本来就已经逼近
1 了</del>，毕竟暑研可能要推迟。</p>
<p>之前零字班的学长还为了小学期的安排和书院 argue
了很久，听到过一个可能的替代方案是大三暑假不实习，大四的寒假再用别的方式补上，也不知道可行性怎么样，之后再细问一问他们。</p>
<p>上次刚说单方面和院系割席了，我每天上数学课上得那个乐，时常还真以为自己就是数学系的。到这种时候才会意识到，果然还是没有冲破牢笼。</p></li>
<li><p>今天有个失联已久的高中同学突然来加我好友，想了想和他唯一一次说话可能是拍毕业照那天，我在边上自闭的时候他突然来和我打招呼，问我能不能合个影，“这样的话我和全班所有人的合影就齐了”。绷不住了（</p>
<p>没加，假装不用微信了（这也能装？.jpg</p></li>
</ul>
<h1 id="月29日">3月29日</h1>
<p>课太多学不完了，很急（</p>
<p>一个不太妙的事情：我现在觉得统计有点丑陋。这话说的有点大，准确来说，我觉得统辅课上讲的统计有点丑陋。再具体点的话，我被线性回归课上各种跳证明用结论、用一些不知道哪来的看起来很怪的人名命名的检验方法给整破防了（。有点想象不来，不推导怎么能
<del>在良心上过得去</del>
确信它是对的然后就拿来用呢，退一步说，不推一遍的话到底是怎么记住结论的呢，我有点做不到（</p>
<p>但我现在实在也没有多余的时间去验证这些东西，更别提为了了解各种检验方法去读文献，有那空不如学实分析。现在就只是被推着走。感觉很好高骛远，不太妙。</p>
<!--另一则是久违（并不久）的青春疼痛文学，虽说还是不写了为好，但果然还是想写（-->
<!--上晚课之前浅睡了十几分钟，居然梦到了一段记忆，完全就是把记忆呈现出来，没有什么来自梦境的加工。四年前的清明假期去镇海集训了一次，好像持续了五六天，可能学校原因不明地多放了几天假。最后一天从镇海回来的时候没有回家，带着行李箱直接去了学校寝室，然后去教室取了些东西，在桌上看到了 ex 提前给我的生日礼物，是一条项链，回寝室之后趴在阳台栏杆上一边把玩一边傻乐了很久（。-->
<!--感觉是最近清明、生日之类的话题都有提过，以及老姐送我的生日礼物也是项链，所以才想起来这件事。当时拍了一张从吊坠的透明部分里倒映出红色的教学楼的照片，今晚回来扒拉了好久各种相册，就是找不到了，也许在旧手机的相册里没有迁移过来，罢了。然后又想了想也不知道这条项链放哪去了，肯定没被我丢掉，至于实物在哪里，完全想不起来，对我来说真的很奇怪。-->
<!--想起来那句“他还太年轻，尚不知道回忆总是会抹去坏的，夸大好的，也正是由于这种玄妙，我们才得以承担过去的重负”。怎么仅有的好事还被我忘记了，坏事都还记得（-->
<h1 id="月30日">3月30日</h1>
<p>虽然我咕了概率论，疑似漏听了一些期中安排，但是我获得了下午可以用来学实分析的充足睡眠，没亏（（</p>
<!--中午接待了上个月日记里提过的（这谁还记得啊.jpg）质心的一位负责宣传的姐姐来华子，~~全程社恐自闭绷不住希望快点结束~~，单向回答各种问题配合尴尬的笑容，绷不住了，结束之后光速跑去教室睡了一觉，感觉才把消耗的心力补回来，开始学实分析。不过趁机转了转理科楼，嫖了个质心的帆布袋和，一些一言难尽的周边（。上次来理科楼还是 19 年金秋营的时候，真正来华子之后倒是一直专业 PTSD 没再去过，最开始的时候路过都会绕一下，乐。-->
<!--印象里金秋营考完那天于品在中央主楼宣讲，说新物理馆快造好了，等物理系搬走之后整个理科楼都是数学系的。怎么现在还没好（。这样想想好像每次华子数学招生都是于品出来宣讲，CGMO 的时候也是，不过我只记得当时强调了数学中心有很多优秀的女性学者，然后被 PPT 上吴昊姐姐的照片美到了（。-->
<p>晚上写作业第 114514 次被 Stein 实分析的中译本气晕：</p>
<p><img src="https://s2.loli.net/2023/03/30/rvKMEnjO51GX4uw.png" alt="RA-stein-EN.png"></p>
<p><img src="https://s2.loli.net/2023/03/30/l6OG5euoknNq7FS.png" alt="RA-stein-CN.png"></p>
<p>不是，把并不是 good kernel 的 kernel
翻译成好核倒也就算了，这个结论怎么都抄不对啊，这道题不会是直接复制了前面那个关于
good kernel 的结论吧（（</p>
<p>我写个作业对着这个结论愣了半个小时，感觉数学不存在了（，又真切地觉得自己的脑子没有问题。后来想了想读这本书遇到问题不能怪自己，先去看原版书，然后血压爆了（。下次还是就看原版罢，为我买书的钱感到不值。</p>
<h1 id="月31日">3月31日</h1>
<p>完结撒花，说好这个月有 300 条评论的，怎么只完成了五分之一（</p>
<p>五天了，终于断断续续读完了<a href="https://mp.weixin.qq.com/s/UH5kism9Bt04P--D1E1rLg">《再见了，小查》</a>，感觉吃饭的时候还是看不了这么长的文章，<del>只能毛概课上看</del>。翻了翻公众号发现文汇笔会也挺久没读了，下次看这个。一天一篇感觉正好，虽然质量不是很稳定。</p>
<p>一个现在在复旦读数学的以前数竞组的同学突然来找我说了几句话，主要是问对于大三分方向有什么打算
&amp; 是不是也没开始磕盐（绷不住了）&amp;
吐槽实变函数太难了（。我又一次和人解释了一遍我人真的不在数学系不过倒也还是在学数学这件事，毕业后不联系了的同学<del>（毕业前好像也没怎么联系过）</del>基本都以为我肉身就在华子数学系，绷不住了。也可能数理基科这个专业名很有迷惑性，毕业的时候学校发的喜报写我的专业也只写了这个一学位，只看过那个的话可能真会这么以为吧。</p>
<p>一个很智慧的对话，太棒了，FDU = PKU（</p>
<p><img src="https://s2.loli.net/2023/03/31/fYemzMcWZPGiVhd.jpg" alt="fdu_pku.jpg"></p>
<p>又看了一遍，感觉问题出在我以为他说的第一句话是个没有主语的问句，但实际上是个陈述句（</p>
<p>最后发个今天拍的照片罢，感谢陪伴，四月见。</p>
<p><img src="https://s2.loli.net/2023/03/31/Tm9lqXOzWRu4t5v.jpg" alt="3-31.jpg"></p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇八·23年4月</title>
    <url>/2023/04/01/Diary-2023-04/</url>
    <content><![CDATA[<p>点击查看驰雨老师两年来最艰难的一个期中月 ↓</p>
<span id="more"></span>
<h1 id="月1日">4月1日</h1>
<ul>
<li><p>今天进行了一个 Montgomery’s method for ANOVA table construction
的学，大概是这学期统辅课上到现在我觉得 <del>唯一</del>
最好玩的一个东西了。感觉三门课有意思的程度是生统概论 &gt; 多元统计 &gt;
线性回归，多元统计胜在理论推导多一点，虽然还是感觉有些地方有点虚浮，线性回归就真的好无聊（恼</p></li>
<li><p>中午出门之前在寝室转了好几圈，感觉有东西没拿，但是就想不起来，到教室才发现没带咖啡。保命起见还是去自动售货机买了瓶雀巢，六块五一瓶的摩卡不到
300ml 还难喝，到底怎么敢的啊。普装贝纳颂我的神！</p></li>
<li><p>我感觉白天的时候想起来好几件事可以写进日记里，但当时在写实分析，就没打开电脑记下来，晚上回来想不起来了，
草。</p>
<p>不等明天了，以下两条是补档：</p></li>
<li><p>还是出门之前正好看到社友在讨论新概念英语的一篇课文，看起来大家都学过，顺便问了问室友，室友也都学过，<del>就我没学过</del>。我大概初中的时候听说过班里有一些同学在外面补课学这个，但上高中之前一直信息闭塞，而且也没有培养需要花钱的特长/兴趣爱好的条件，就都是一个以为跟上学校进度正好、完全不知道要提前学习的状态。加上我不大喜欢英语（这门课）成绩也没有特别好（，就觉得和我没什么关系。到了高中也是一个大家都学过就我没学过的状态了，当时是觉得毕竟上海早培比较猛，可能这也很正常，今天才知道来自五湖四海的大家也都学过，看来还蛮普及的（</p>
<p>怎么说呢，我一向是觉得，自己资质平平，小奥和初中奥数没学过，英语物理化学都没提前学过，也还是混进了不错的高中甚至还混进了竞赛组，后来又混进了华子，所以说这些东西的用处或许没有想象的那么大啦。虽然提前学过确实是很好的，也不至于进高中之后一直感觉很
EFZ
shock（，时常有失群落伍的迷茫了。但是有一个用来读书、挖土、折纸和打游戏而不是从小开卷的童年，也是我时不时想回到的无忧时光。</p></li>
<li><p>还有一个是今早又看到了昨天拍的照片，突然想起来从前非常喜欢的那句“华枝春满，天心月圆”，大概就是这样一种意境了。</p>
<p>虽然这几天的月亮完全不圆，手机拍出来倒是像圆的，笑死了（</p>
<p><img src="https://s2.loli.net/2023/03/31/Tm9lqXOzWRu4t5v.jpg" alt="3-31.jpg"></p></li>
</ul>
<h1 id="月2日">4月2日</h1>
<ul>
<li><p>昨晚和社友浅聊了一下儿童文学的话题，我发现我小时候读的儿童文学好像也不是很一样，我读的最多的居然是猫武士系列，其次是查理九世、老鼠记者和读者、意林，都来自小学的图书馆。我超，我现在想想我那个乡镇小学的教学生源和氛围全市垫底，但单论图书馆还是非常强的。</p>
<p>然后又去研究 &amp;
回忆了一下猫武士的设定，我超，这真的只是儿童文学吗，感觉完全可以同哈利波特的理，成年人也爱看。<del>期中月不要突然找到想看的东西啊草</del></p></li>
<li><p>今天本来想补一补多元统计的笔记，写掉生统概论的
project，结果到教室从包里掏出教材和笔记本之后就又学了一天实分析。虽然不知道第几遍了，但感觉确实在践行实变函数学十遍。</p>
<p>不过每一遍理解确实都更新一个版本，但是要到哪个版本才能应对好考试呢，或者说我真的能达到可以应对考试的水平吗（，单说我那个脆弱的临场发挥就觉得很悬（。说实话我都不知道
ly 期中会怎么考，<del>可以像课后题一样给每个题都来点提示吗（</del></p>
<p>打算今晚把生统概论的 project 写完，其实 mixed effects model
昨天就设计好了，但涉及很多不太熟悉的 R
code，类似于数据得稍微洗一下然后搞一个 balanced test
这样的琐碎问题也很多，<del>我果然还是只想做一点纸面的工作</del>，就一直没动手。<del>待会去和
ChatGPT 聊聊</del>（全是调函数读文档的问题有必要问 ChatGPT
吗（关于文档的问题问 ChatGPT
才好使吧（这个思路还是上次社友提起来的，绷不住了（</p></li>
</ul>
<h1 id="月3日">4月3日</h1>
<ul>
<li><p>我居然有一节概率论是听得懂 lzx 在干什么的了，主要还是很初等，顺便
cue 了很多统计相关的东西，<del>好评</del></p></li>
<li><p>答疑坊小程序的志愿者权限有了，终于可以阴暗地观察大家都在提些什么问题了（不是，数学相关很多都比我想象的简单。<del>实分析写不来就接两个单子秒一下别人的题，回来就觉得自己不那么废物了（好阴暗</del></p></li>
<li><p>昨晚说想写完生统概论的 project
再睡，结果今晚才写完，绷不住了。</p>
<p>大部分时间都花在犯蠢 &amp; 跟 assumption check
大力搏斗上了，第一遍的时候蠢到随机删数据删成 balanced test 再 check
assumption，outlier 和 normality
直接爆了。第二遍先做了检验，检查出来数据点最少的一组（也就是本来打算作为
balanced test 基数的一组）里面 outlier
反而多，绷不住了，删的话别的组也得跟着删，还没做检验我数据先少了一半，牙白。</p>
<p>最后这一组里不太离谱的就都保留了<del>（就当是增强模型
robustness（心虚</del>，别的组里稍微有点离谱的都删了，检验出来的结果倒是还不错。</p></li>
<li><p>室友今天问我为什么不把笔盒里贴的价签撕下来，从外面看一大块白色的，很怪。其实是
2019 CGMO
的一张贴纸，我真觉得挺好看的，<del>那年的美工水平非常巅峰</del>。原本是贴在发的矿泉水瓶上，把瓶子丢掉之前被我撕下来随手贴到笔盒里了。</p>
<p><img src="https://s2.loli.net/2023/04/03/ONMBKTJaiz4bpgl.jpg" alt="2019-CGMO-sticker.jpg"></p>
<p>当时还想着能不能集齐三年的贴纸，但 2018 CGMO
的贴纸太大了贴不进去，2020 CGMO
疫情原因压缩了行程，整体也很草率，上午开幕下午就考试，第二天上午考试下午宣讲，第三天上午查卷
&amp; 清北面试 &amp;
参观活动三线并行，下午就闭幕把大家赶走了<del>（为什么记这么清楚，因为我去翻了一下当时的日记，草）</del>。甚至数学会的老师忘了带公章没法给证书盖章，证书还是事后补寄的，闭幕式上大家拿着空壳证书和奖牌合影（，绷不住了。也没发什么有意思的纪念品，更没有我心心念念的贴纸了。<del>不过无所谓，我有
Au 当纪念品（</del></p>
<p>真的很想吐槽一下 CGMO
发的纪念品，每年一个粉色/红色的书包，一身粉色非常显黑的衣服还要求必须穿，真的有让人赛后再背出去/穿出去的打算吗，不要因为是女子赛就连这些东西的颜色都刻板印象啊数学会！</p>
<p>所以最后就只有这一张，贴在斜角上，不太对称但也不敢撕下来再重新贴了。还导致笔盒明明是透明的，却因为贴纸上有字不能带进高考考场，当时握着一把笔和一堆其他东西进出考场，手忙脚乱弄丢了一支手感很好的铅笔（悲</p>
<p>倒说明笔盒质量很好，一直用到现在。<del>安利一下（，是无印良品的，门店价格
18 块钱（不保证实时）物美价廉（18
块钱一个塑料盒子到底哪门子物美价廉（但是是质量很好也很好看的塑料盒子（</del></p></li>
</ul>
<h1 id="月4日">4月4日</h1>
<p>数学系周四办了个<a href="https://mp.weixin.qq.com/s/kqvQdwTVPp1KEtdoiPQlyA">交流会</a>，大概是和选方向相关的，看了看六个主讲人有（至少）四个都是转数环环友，<del>是否说明数学系有三分之二都是转系进来的</del>。虽然期中月了但还是打算去听听几个应用方向的部分，顺便单向面基一下。<del>看到推送里写欢迎其他院系对数学感兴趣的同学参加我就放心去了！（不会指的是求真吧（推送里不是还说有学长学姐分享经验吗，学姐在哪里</del></p>
<!--今天答疑坊接了个数学系同学的概率论问题，大概是 wxq 那边的作业，轻松水完，满意离开.jpg（好阴暗！-->
<p>感觉还有一吨重的事情没做，重要的几门课也没复习完，压力好大。压力一大我就想去秒答疑坊概统课的单子，今天一整天小程序里的概统类全被我答完了，绷不住了。多元微积分并不是每个都一眼会（，这学期也没有线代，就只能答点概统。现在觉得工科数学学得真简单啊，我一秒一个（x，但我什么时候能秒自己的作业呢（悲</p>
<p>这两天答的概统好像都是同一门课上的同学的作业，目测是一门英文的概率论与数理统计。看起来还是有点神奇的，第七周就在讲
confidence interval
了，很好奇概率论只讲六周的话到底能讲多点。作业题里还有什么 Erlang
distribution，据说课上还讲了这玩意的理论期望和方差，我都没听说过这是啥（虽然还是一秒一个（逃</p>
<p>晚课机缘巧合面基了一位非常 nice 的社友，但我又全程社恐了，悲（</p>
<h1 id="月5日">4月5日</h1>
<p>我觉得我实分析很拉胯，但我更担心考试的时候问题出在数分的东西不扎实/甚至有的没学过<!--讲个笑话，我这周写作业之前研究了很久 limsup f(x) 到底是什么意思，另外 Gamma function 和 Beta function 这些东西微积分也完全没讲过，全靠一些初概的积累，很不熟，还蛮难受的-->。多元统计也还没学完，下周两门期中，绷不住了。</p>
<!--上午和队友讨论了一下统辅大作业选题，越讨论我越想单开。感觉其实这个工作量完全可以单开，而且本来说的就是 1~2 人一队完成，单开的话估计我五一抽两天时间肝一下就结束了，带队友就不知道时间安排怎么样，反正我是真不想把这个放到平时做。其实要不是群友找上我的话我也没打算和人组队。稍微有点纠结要不要在开题之前赶快提出来拆组，说到底一开始为什么要答应组队，感觉好像是不知道怎么拒绝然后就答应了（悲-->
<p>这个概率论是真迷惑到我了，分布函数左右连续问题我也忍了，虽然书上是左连续但我一直按习惯用右连续，只要不是离散分布也不会出什么问题。但这个
Gamma distribution 和 Beta distribution
的两个参数怎么也是和常见形式反过来的，作业里一上来给了一个 <span class="math inline">\(\Gamma(\frac 1 2 , 1)\)</span>
一下子还看不出来到底反没反，感觉哪个放在 Gamma
函数里都没什么问题，绷不住了。</p>
<h1 id="月6日">4月6日</h1>
<p>又是被切碎的周四，稍微有点难受。</p>
<p>下午去听了数学系分方向宣讲。没想到来这么多人，教室差不多坐满了，又社恐又混进来浑水摸鱼的我戴上口罩在角落里缩了俩小时，绷不住了。我原来还想等基础方向结束了再来，还好按时到了，不然都没地方坐，而且其实也没按照推送上的顺序讲。总之感觉还是
<del>值回票价</del> 期中周花俩小时去听感觉也值，大概这样。</p>
<!--社恐了，于是找了个最后一排最左边的位子坐，走的时候看到 LagrangeKMnO4 坐在最后一排最右边，lzr，djc 和 cm 一直站在左前方的角落，右前方的角落是另一个环友，四舍五入转数环合围数学系！（-->
<!--一些半梦半醒里记下来的废话，纯当乐子看，塞注释了。-->
<blockquote>
<!--数学系这边推研也不怎么需要科研，也不用提前联系导师啥的（绷不住了-->
<!--如果想去前三个地方（茶园，统计中心，贵系）的话还是得早进组。进组也不用会啥，别急，进去之后需要学的东西老师会发给你读的，一般就是两三本书-->
<!--不是数学系那种很折磨的教材，都是比较轻的东西，会一些概统、运筹优化就好了，一两个月肯定能看完了（-->
<!--——CS 交叉 ljw-->
<!--最重要的课程当然是数学分析，后续分析方面的知识点都是在换了一个背景下的求极限求积分连续性分析等等问题，只是换了一套语言所以初学会比较艰难。-->
<!--后续很多课程都是简单的，只有数学分析本质上是困难的（绷不住了-->
<!--所有的方向都在讲一件事情就是我们要尽早去找老师聊科研相关的问题，熟悉一个领域入门的时候还需要哪些基础知识。当然来宣讲的学长们大一大二的时候都没进组因为比较慌基础（-->
<!--Evans PDE，搞不搞分析都可以学学（-->
<!--——分析 djc-->
<!--计算方向的必修课（数值分析，PDE，PDE 数值解）都不是特别难，会讲比较古典的方法，了解基本理念即可，更现代的研究还是要和老师讨论。不搞计算的也可以选着听，不会亏的（我要是有这个时间就好力！-->
<!--线性代数很重要，要学好，主要强调一个理解（高代，我稀碎的高代.jpg-->
<!--PDE 数值解不需要会 PDE，用不到性质，会 Taylor 展开就行（，需要写点码。PDE 也比较古典，学习几类典型方程的性质，各种情况下的解法和解的唯一性，计算这几门课就考试前努力学一下就行（这个确实），没有基础课那么耗时间。-->
<!--凸优化，数学规划，深度学习理论都可以上，不上也行，研究有需要了再说-->
<!--数学系的计算方向还是很理论的，不要害怕磕盐，本科生做的工作也就是努力看点文献和老师讨论就好了。数学系最传统的计算方向就是 PDE 数值解所以教学也围绕这个展开，其他方向也很多，可以自己找老师聊-->
<!--学完数值分析就可以去考计算的丘赛了，难度和数值分析课后题相似，复赛题目其实更简单，难在全英面试和临场发挥。每年春季数学中心会组织丘赛培训把知识点过一遍，重点是数值分析和数值格式（数值格式是啥，感觉没学过（？-->
<!--——计算 & 应用 gyh（他的风衣和我的一个配色，还挺好看的（草-->
<!--代数的课有这些，书有这些，学这些也不够，用到哪补到哪好了（，我写在黑板上不代表我会啊，我只是知道这个事，可千万别来问我（-->
<!--抽象代数没学好的话，你可能之后就和代数没啥关系了（草，我走了.jpg-->
<!--你要是决定走代数的话，就别太在意绩点了（草-->
<!--一个线性空间上的可逆变换是可以用矩阵写出来的，但是一个群就很虚无缥缈，很烦，所以有表示论-->
<!--基础课学完之后开始为前沿研究方向打基础的时间，感觉是概率一年 < 分析一年半 < 几何两年半 < 代数三年，坑比较深，建议还是选择要慎重（绷不住了-->
<!--客观上来说求真就是比数学系强，是可以看到差距的，做代数要和他们竞争，这也没办法。但是心态要好，别太在乎短期，你可能二十岁出头的这两年弱一点，但是你的研究生涯还有 40 年（绷不住了-->
<!--上学期上的课肯定这学期就忘完了，很正常，不要慌，多备工具书查阅。也别把基础课之外的基础看得那么重，从现在开始读代数的圣经到每一题都会做的程度的话，到读完该 30 岁了（绷不住了（（-->
<!--肖杰老师要去北师大了，和我们没关系了，悲（-->
<!--（太困了后面的没细听，我反正是不可能搞代数，当听笑话了-->
<!--——代数 lzr（总算是单向面基到当初拉我进转数环的 lzr 了，好（-->
<!--虽然基于测度论的高级观点很重要，有助于理解的更清楚，但是初等的东西的熟练程度也很要紧。回归非常重要。数学系的课程安排比较慢，科研会寄，大三才学统计推断，这个不太行，建议去修统辅（优势在我x-->
<!--除了回归之外多元统计也要重视一下，尤其是降维问题；数科导还是有必要上的，数学系的同学码太弱了（草（-->
<!--统计相对数学来说更繁琐而不是抽象，其实还是有难度的，代码的话我也不是很懂大家看着办吧.jpg。统计中心的方向差别很大比如说俞 sir 那边是码为主，招本科生的时候会要求代码熟练，也经常带大二的同学。理论方向进实验室晚一点，基本是要学好回归多元再去。-->
<!--——统计 lbf-->
<!--概率论 1 的话 lzx 和 wxq 讲的不够深，不如当年的 jwj 和 wh。数学系开的概率论 2 研究生课其实是给外校来华子的研究生补基础的，并没有想象中那么难，参考书是严士健《测度与概率》，这书不咋地。求真的概率论 2 是我们想象的那个概率论 2，作为 1 的加深。下学期开始要开概率论 3 了（绷不住了），会有 Ito 函数什么的（那是啥.jpg-->
<!--随机过程和那门应用随机过程完全不一样，后者是开给全校研究生的公选课（好像确实看到 TA 上过），选课不要选错了。应用随机过程不引入测度论，只要会初概就可以提前去水一下。-->
<!--lzx 还开随机分析，参考书是 GTM 113（风评一般），概率方向核心课就是三门，概率论 1，随机过程和随机分析，自学的话就是先 Kai Lai Chung 再 Durrett，然后可以考虑下 GTM 274。前两本读完差不多够了。-->
<!--一些 wh 老师的书单：Kai Lai Chung（可以读到前五章或者前六章），然后转去读 Durrett 的马尔科夫链，遍历性理论和布朗运动，后面这本书非常好，观点和编排比 Kai Lai Chung 都先进一点。后面专精方向的话可以考虑读 Markov chain and mixing time。另外很好的一本书是 GTM 274，是关于布朗运动和随机分析的，建议细读把题刷完，可以替代 lzx 用的 GTM 113。另外一本不太需要测度，偏向初等的是 M.Ross Introduction to Probability Models（这个是私货，不是 wh 的推荐），会初概就可以，刷书的话最好把题做了。-->
<!--还有一些别的推荐，我就拍了个照，太升级了，先不记下来了。-->
<!--建议：早去找老师，没了。不可能把所有东西都学好再去做科研的，把概率论 1 学完（或者把 Durrett 读完）发现对概率感兴趣就可以去找老师了，建议是大二暑假，不要拖。（绷不住了，字字都在骂我-->
<!--学基础的时候抄书很正常，听起来很扎实，但迟早是要忘掉的（别骂了），并不是每本教材都要精读。一个人单打独斗可能在初学的时候很常见，但是进入研究状态的话最好还是能有 fellow 一起开讨论班。（这个也好困难！-->
<!--顾陈琳目前没有学生，可以去找他（和我之前想的一样）。概率组就四个人，吴昊（统计物理），杨帆（随机矩阵理论），顾陈琳（PDE 方法做随机过程），姜建平（好像和 wh 方向差不多，这位不大了解）。每周概率组都有组会，目前还基本都是 wh 的门生（-->
<!------概率 cm-->
</blockquote>
<!--顺便也刺探了一下数学系一二字班的情况，真的值回票价。总之，我最近（也不是最近，寒假以来吧）一直觉得也可以考虑考虑概率方向，学习路线给得很齐全了，如果逐渐发现不那么喜欢统计的话完全可以跑。-->
<p>想了想觉得想学的东西果然还有好多啊（那为什么现在还在摸鱼），不仅是概统目前还没有深入，像代数方向虽然我并不打算走，以后某一天突然拿起一本
Atiyah 来读也是完全有可能的事情，毕竟真的很有意思啊。</p>
<h1 id="月7日">4月7日</h1>
<!--看周六要做的物理实验，打开班级云盘里发的祖传报告，开幕雷击，居然是四年前 TA 的真迹，世界未免太小了点（-->
<!--后来想了想大概是从 THU CST Cracker 上搬下来的，那倒也正常（（-->
<!--昨天还读了 Mariana 的[申请回忆录](https://mariana2000.github.io/posts/2023/04/blog-post-summary/)，只能说读大家的申请回忆录都会觉得，申请季是个相当漫长痛苦的过程。我尤其难以面对这种长期的又无法由自己掌控的焦虑，如果只是短期的困难咬牙坚持过去倒也没那么恐怖，希望到时候人没事。再说吧，还早。-->
<!--现在说到出国申请我也还是觉得好烦，我只不过是被很多个机缘巧合推到了这一条路上。上次群友问我为什么选择出国，难道我有得选吗，大多数人的人生都是没有选择的，有一个看起来还可以的解就不错了。我想我不会碌碌无为，但我会平凡度过一生，大概也是这个道理。-->
<ul>
<li><p>昨天居然忘记写了，吃饭的时候读到了冯渊老师的《<a href="https://mp.weixin.qq.com/s/-f1EoUSF8xykRrdSPiFP1g">四十年前，桂坝的月光</a>》，一边读一边感叹，好嫉妒，怎么这么会写，我怎么就写不出这种文字来。</p>
<blockquote>
<p>第四个十年，农历十一月的下半月，我在长江入海口看月亮。这里霓虹闪烁，月光下是金属冰冷的反光。江水进入大海之前，波翻浪涌，蓄积了太多的能量，在辽阔的江海交汇点，我原以为那些几千公里奔腾过来的力量会掀起万丈浪涛，排山倒海，形成惊天动地的海天胜景。</p>
<p>并没有。</p>
<p>大海宽阔无边，低伏着，毫无声息就将这些奔涌的豪情吸收到它渊默的深深深深处。激荡、相拥、抚慰，都藏在深深的水底。江海交汇处的水面上，只有寂寞的天空，在做一面无边的镜子，与大海互为镜像。</p>
</blockquote></li>
<li><p>中午在路上骑车，刚从新民路的坡上冲下来的时候突然好像有什么东西卡进了车链子和踏板那一块，一下子蹬不动了，当时速度还挺快，路上一堆人，非常恐怖。还好车轮还能往前转，就一边刹车避障一边往路边靠然后停下来检查，试了试让车轮往后转就会卡住，应该确实是车链子的原因。最后我也不知道发生了什么，用力往后一推，车链子发出了很响的咔的一声，还以为彻底断了可以去换新的了（不是），没想到恢复正常了。听起来很不靠谱，感觉确实有必要去换个链子了，<del>说到底好想换辆车啊</del>（</p>
<p>以及又忘记带咖啡，逛了下清芬猫超就只有圆柱装的贝纳颂，冰柜里全是酸奶。也挺久没买酸奶了，还是大一有集体锻炼
&amp;
天气很热的时候经常跑路溜进猫超挑酸奶，然后坐在操场边上一边喝一边摸鱼，<del>以及面基社友</del>。圆柱装的贝纳颂果然比普装贵好多，<del>但总比瑞幸便宜</del>。感觉味道上还是更苦一点，对比了下配料表目测是香精和奶粉加得少，<del>喝咖啡不就喝那个糖和奶和轻微的咖啡香气吗</del>，上次好像误导社友了。</p>
<p>瓶子很好看，打算带回去洗一洗拿来插花。其实已经攒了两个好看的可以插花的瓶子了（，问题可能出在一直不怎么买花上。说到底还是
<del>没钱</del>
在寝室的时间太短，每天就回去洗个澡睡个觉，买了花却不能在短暂的花期欣赏和陪伴它的话也太可怜了呀。</p></li>
<li><p>最近在努力回忆以前看到过的两句诗，几个意象（地铁，幽灵般的面孔，花瓣，枝条）都还记得，但是就忘了原句是怎么组织的。最后想了想把地铁写进去的诗句肯定也不多，于是今天查到了：</p>
<blockquote>
<p>The apparition of these faces in the crowd；</p>
<p>Petals on a wet, black bough.</p>
<p>——Ezra Pound《In a Station of the Metro》</p>
</blockquote>
<p>...虽然地铁其实是在标题里，没出现在正文。我当时看到的是中译版本，看了几个翻译感觉应该是这一版：</p>
<blockquote>
<p>人群中这些面孔幽灵般显现；</p>
<p>湿漉漉的黑枝条上朵朵花瓣。</p>
</blockquote></li>
<li><p>看了看最近写的这几条，我的期中周到底在干些什么（</p></li>
</ul>
<h1 id="月8日">4月8日</h1>
<ul>
<li><p>期中前最后一次基物实验不仅没速通，还成功做到了几乎最后一个走，绷不住了。</p>
<p>实验用的光阑有好有坏，倒也正常，但是不太正常的是能用的光阑数量小于实验台的数量。我抽了两发抽到的光阑全都透不出光，建议改名叫遮光板，最后只能等有同学做完实验然后借他们的光阑，绷不住了。期间我还在想能不能不加光阑直接做，一边等一边调了一个小时，也没调出来波纹，麻了。</p>
<p>走的时候写了两个小纸条塞进我抽到的那两个不能用的光阑的盒子里，纸条上面写“这个用不了，快换一个”，什么当代金圣叹。</p></li>
<li><blockquote>
<p>1958年冬，范成法师回到了阔别十二年的掘港西方寺。在上一年的佛教协会第二届全国代表会议上，他发宏愿要编一部《人民大藏经》，得到众多缁素的赞同，他便汲汲于此。此次回到西方寺，就是来查找收藏在那里的《龙藏》影印本。当来到由他创办的僧伽私立图书馆时，却发现这里的藏书空空如也。原来在新中国成立，如东县中学迁进西方寺，因学生需要宿舍，故将图书馆的房子让出，包括《龙藏》在内的十六万册图书，被人打捆装了满满三大船，卖到南通县造纸厂去，早已化为了纸浆，所藏的佛教文物也损失殆尽。一辈子心血化为乌有，法师心中一片悲凉。不久，寒流骤至，内外交并，他喘疾复发，徒孙宝惠想送他回苏州。他淡淡地说：“生有处，死有地。我自西方寺生，仍在西方寺终。”12月17日，法师沐浴更衣，跏趺而坐，于念佛声中至辰时圆寂，世寿七十五岁，戒腊五十四年。</p>
<p>——<a href="https://mp.weixin.qq.com/s/EfPRHIp8ALNOG39OTsDbuw">《他创办了中国第一家佛教图书馆》</a></p>
</blockquote>
<p>晚饭读到的时候非常震惊，立刻就想到了《天平之甍》里业行抄写毕生的经书在风浪中沉入碧海，那样的残酷和虚掷。</p>
<blockquote>
<p>去年秋，我因写《王燧其人》一文到如东县图书馆查阅《东院王氏家谱》，发现馆藏有两册乾隆刻本《杭州府志》，黄色封面上盖有“皋东僧伽私立图书馆”椭圆形印章，首页右下角钤一方印，细辨乃“范成藏书”几个字。这里怎么会有这种藏书？我心中一动，颇为诧异，因为工作人员年龄较轻，不知此书来历，虽有不解，却无处释疑。直到前不久遇到如东县图书馆原副馆长丛国林先生，向他询问，才知道其中原委。原来就在七十余年前那次打包装船准备运往南通县造纸厂时，如东县工人俱乐部的吴功伟听说后，赶到船上，拎回了两大捆，《杭州府志》便是其中之一。吴功伟为如皋白蒲人，那时还只是一个十几岁的少年，后来担任了如东县图书馆第一任馆长。对于吴功伟老人，我也很熟悉，每次遇见，总要交谈几句，他绝少谈及自己，故而从未听他说过此事。如今老人故去好几年，已经无缘了解其中细节了。</p>
<p>......</p>
<p>为了古本大藏经，范成法师衲衣麻履，寒暑历尽，一直在寻经的路上奔波不息，把细碎的足迹压在辽阔的山河之上，他的功绩，已经被载进史册。而他用尽全身气力收集来的图书，却在时间的碾压下，化为片片飞舞的蝴蝶，散入遥远的虚空。过去的珍本古籍中，藏书家往往会钤盖一枚“在在处处有神物护持”的印章，希望它们能够得到神灵的呵护。世人皆知僧伽私立图书馆藏书尽毁，连范成法师也觉得片纸无存，但谁又能想到，岁月竟然为我们留下了些许残存，这也许是冥冥中自有天意。留下这些图书，就是为了告诉后人：一脉文心，当不可绝。</p>
</blockquote>
<p>一脉文心，当不可绝。太会说了。</p>
<p><del>这日记怎么逐渐变成文汇笔会摘抄了（</del></p></li>
<li><p>写了一下午一晚上多元统计的
cheatsheet，写不完了，感觉实分析和多元统计都要凉，概率论也快要凉了，草。今晚争取写完
cheatsheet
顺便纠正一下笔记里有问题的地方，然后多元统计就学到这里了，明天开始抢救实分析。</p>
<p>没写完，果然什么都写不完，绷不住了。</p></li>
</ul>
<h1 id="月9日">4月9日</h1>
<ul>
<li><p>一直忘记写，前天和昨天都在清芬旁边看到美团校招宣讲的展板，第一反应总是来华子招骑手吗，我这就去。今天再看撤掉了，可恶。</p>
<!--时不时也会思考自己的未来这样的问题，但是完全看不到未来！（x）每次我妈问我学数学出来到底做什么我都说不出来，一般就只说，可能找教职吧，要么就来点她爱听的经典说辞，数学万金油以后去哪都行。她骂我的时候最常见的一句就是“你和你爸（当然她不会这样讲，她会直呼他的名字）一个样”，包括未来职业、我嗯要转数这样的问题也会扯到像他，大概她觉得我将来会和他一样挣不了什么钱，偏还带着一样的执拗。-->
<!--我小时候最讨厌听到这个评价，会觉得很委屈，不仅为她说我像一直以来她口中的这个反面角色而难受，而且我总也能有一点点理解父亲的为人处事，我妈就完全不理解。有时会觉得换我也一样，无论他所做的事情的好坏，我总是会想如果是自己的话或许也会这样，至少不太会像我妈一样做选择。后来才觉得这就说明我确实更像他，我也一点都不像我妈，虽然她才是一个好的伴侣。事实如此，她说得对。--></li>
<li><p>我这周末的两天都有上午，真的说明学不完了。</p>
<p>今天上午花了一个小时就写完了多元统计里双总体/大样本检验的
cheatsheet，这个地方之前一直觉得混沌，但其实 1h
就能搞懂。单纯是应对考试的话，统辅课再繁琐到底也没什么思维量。其实一个小时也很有用。现在想想倒也不是急着非要很快写完，周五才考试，早写完不早就忘了（，不如一天写一点，每次迭代一遍。</p>
<p>然后花了一天才又刷了一遍实分析第二章，现在在二刷课后题，感觉很寄。</p></li>
<li><p>虽然复分析去过一节课就退课了，但是课程群一直留着（，晚上在群里看到有人说自己阳了，明天的课要线上上。结果过了几分钟就听到有人在楼道里讨论（大意）：</p>
<blockquote>
<p>新冠第二波是不是又来了啊</p>
<p>xxx（群里那哥们的名字）不是在群里说自己阳了吗</p>
<p>他怎么想到去测抗原的，现在生病不应该先怀疑甲流吗</p>
</blockquote>
<p>世界真小（</p></li>
</ul>
<h1 id="月10日">4月10日</h1>
<ul>
<li><p>有点想看赛马娘，期中考完一定（难道期中考完就有空看了吗</p></li>
<li><p>在答疑坊线上接单到现在还没有遇到过管我叫学姐的（，要称呼的话都是叫学长。单看名字可能确实看不太出来，头像是二次元美少女的话，好像是学长的概率更大了（草（我没有点名的意思但是在座的各位都.jpg</p>
<p>好像把学姐叫成学长也没什么关系，但如果把学长叫成学姐就比较尴尬（为什么呢），所以直接叫学长可能确实比较方便。不过何必带称呼呢（</p>
<p><del>草，突然想起来 ex
的名字怎么看都是个女生的名字，升高中的暑假里不慎（现在想想确实太不慎了）加到他好友之后，我通过空间和年级群发言观察了一个星期这个人到底是学长还是学姐，绷不住了。</del></p>
<!--草，说到 ex 就想起来昨天在和老姐发癫，说最近压力好大，想凌晨三点给 ex 发个消息再光速撤回，让他纠结一天发生甚么事了。-->
<!--#每日时光飞逝，升高中的暑假都是快五年前的事了，过了这么久我还在骂他，感觉不出意外的话健康工作五十年之后我还在骂他（-->
<p>今天被问了一个特殊矩阵的行列式怎么求，我盯了一会觉得是把特征值盯出来（毕竟不同的特征值就两个，一个是
1 重，另一个是 n-1
重），特征值乘积就是行列式值。然后被追着问是怎么想到用特征值算行列式而不是嗯拆，怎么把特征值观察出来，而不是再套娃用行列式算特征值的，绷不住了，#每日
Recursion</p>
<p>我也不知道，我就是盯了一会盯出来的，就很难跟他解释，最后只好坦白了就是看出来的（，实在不行可以从低维开始尝试找规律，虽然我其实觉得正常人不会这么干（。感觉大概就是经验而不是知识，真的很难传授。多练.jpg（死去的音游梗开始攻击我（</p></li>
<li><p>学不完了，急急急急急急急急</p></li>
</ul>
<h1 id="月11日">4月11日</h1>
<p>现在晚上困的时候半躺在床上学的频率越来越高了，已经演变成一回来收拾东西光速上床了（，但真的舒服。</p>
<p>中午上完体育课洗了个头，但是下午还得出门，而且看起来沙尘暴也没有要停的意思，犹豫着拿出了衣橱里一顶买来觉得不好看/比我的头大很多戴着不舒服，但最后也没退货的
<del>二元正态分布</del>
帽子（没有运费险，退货的话运费比本体还贵）。戴帽子口罩出门感觉看起来很神秘人，不过也或许是女明星呢（草（但女明星的帽子不会这么丑（</p>
<p>正好晚上在路上遇到了一个穿着我高中的冬校服的同学，看颜色应该是 mod 3
余 1
的年份从华二毕业的，大概是二字班（或者九字班？六字班？三字班？（。第一反应是这衣服又丑又难受怎么有人毕业了还想穿（，我上学的时候都不怎么爱穿，经常穿另一件自己的大衣糊弄过去。又想到如果是二字班的话单向认识我的概率还不小，慌忙准备低头逃跑，然后想起来既戴了口罩又戴了帽子，安全感
up up（</p>
<p>说起来高中的时候还听说过有个什么 efz
校服日，某一天毕业生聚在一起穿校服拍照之类的，不知道是近两年没有，还是大家早都不记得我这个人了所以没人来叫我（，虽然就算有人来叫我我也不会去（（</p>
<p>回寝室用湿巾擦了下帽子，一层灰，太恐怖了，还好戴了。</p>
<p>实分析作业卡题，看完提示困惑只增不减，完全看不出来和题目有什么关系。中英文一起看的所以也不是翻译的问题，查了
MSE 才发现是 Stein
比较谜语人，提示了但是只提示了一半，绷不住了。学不完了，急急急急急。</p>
<h1 id="月12日">4月12日</h1>
<ul>
<li><p>昨晚发完看到了高中的气象台发布了浦东的沙尘预警，<del>想你的沙终于从北京吹到了上海，今天又随东南风吹了回来</del>，草。不知道现在是谁在运营了，我高二的时候还运营了一年这个东西，主要是因为当时开始禁手机，气象台的大家都乖乖不带手机，就我还带，所以让我当了一年台长，方便发预报。绷不住了。</p></li>
<li><p>今天在教室自习遇到了带接线板来普度众生的人，虽然他没停留很久但还是学到许多（</p>
<p>晚上发现四教的教室里插座其实非常多，两侧每两排一个，最后面有四个。但四教隔音实在太拉了，一层楼六个教室的声音一起在走廊里回荡，<del>来上一节课更比六节强</del>，此外冬凉夏热，桌子比三教还矮。不爱去。</p></li>
<li><p>拿大一下学期的工图作业当草稿纸。我当时好强，现在完全看不懂是在画什么。学这些东西有什么用吗，就像后八周我还得去上一个叫做测量学的东西，暑假还有测量实习，到底有什么用啊。骂的很大声，但其实
Galois
理论也肉眼可见地对我来说没用了（当然我也差不多忘完了（心虚，但至少我觉得它好玩（</p></li>
<li><p>咕了早八，醒来之后躺在床上开始秒答疑坊堆积的订单，秒了半个小时（，突然觉得期中周这样是否有点太奢侈了，于是暂时关掉了新单提醒，打算考完再打开。</p>
<p>我微信除了一个室友之外没什么人经常给我发消息，自从开了新单提醒之后还产生了消息很多的现充错觉，今天关掉之后又没有了。感觉这个月的津贴很危（</p>
<p>下午在小程序上问了个多元统计的问题，到晚上都迟迟没人接单，我急了，这下医者不能自医了（悲</p></li>
<li><p>很急很急很急很急很急很急，<del>比昨天更急了</del>，我的实分析真的拉胯。学的时候很乐，一到快考试就绷不住了，拟合了一堆题目，越拟合越慌张。说到底还是底力不行，数分
3
没学过，函数列理论啥也不会就来上这个。虽然期中要是裂了大不了退课然后毫无心理压力地把后半学期跟完，<del>不损失
GPA
还能学到知识，赚死了</del>，暑假再回头从更高的观点补数分，明年这时候补上光叔的实分析，<del>或者干脆摆烂去薄纱经管那门实分析来充成绩单</del>。听起来也很不错的样子，但果然还是不想这样。</p>
<p>现在又很想喷自己的选课策略了，每个学期都想喷。倒不如实复概全选，退一门至少还剩俩，还能在薛四金那里蹭成绩，进度也不算慢。完全是不负责任的暴论罢了，如果真的实复概全选加三门统辅（一开始甚至是四门）再加两个基物实验的话，我早猝死在三月（二月？）了。</p>
<p>算了，考完再说吧。</p></li>
</ul>
<h1 id="月13日">4月13日</h1>
<p>从早晨就非常倒霉的一天。早晨不是被闹钟叫醒的，是腰疼疼醒的，在床上翻了两圈感觉这个早八上不了了，挣扎着下去拿了护腰，绑上之后靠在床头写了会作业。这两天也没什么额外的活动，一边写一边思考自己是不是真的腰突了，害怕。</p>
<p>稍好一点之后出门去理科楼交概率论
bonus，又是不幸的开始。我就进去找个信箱再出来的空，远远看到有个人把自己的车从一堆自行车里推出来的时候，是先一脚把左边的车踹倒，再把右边的车踹倒，让出来一大片空间，然后轻松地把自己的车推出来，骑上车走了。绷不住了。恰好我的车就被压在了被他踹倒的一排车里面，忍着腰痛扶好车把自己的破车抢救出来，发现车链子断了。磕了一下就寄了，这么脆弱的吗。或许如果去上早八的话就可以在课上交掉了，然后就没这些破事了罢（</p>
<p>好想去调监控让他赔我车，然而既没这个时间，成功率也不高，就只能自认倒霉。</p>
<p>走了一路把车推到了听涛后面停下，在想有没有什么无痛修车的方案。决定吃完晚饭推到清芬修车铺看一下，想着据说这边很坑换配件很贵（UPD：确实），在考虑要不要这一段忙完之后自己买个链子
DIY 顺便学习一个修车技能（UPD：就打算这么干
w），虽然到处都是修车铺，但是如果自己会弄的话感觉会比较有安全感！想学拆车！但是后面几天怎么办捏，周末或许可以借北京室友的车，但明早还要去技科楼上课，不知道共享单车好不好找。胡思乱想着上楼吃饭，发现裙子侧边蹭到了什么东西脏了一片，简单擦洗了一下弄不干净，还得晚上回去洗。说到底今天这么热我为什么要穿这条裙摆这么大的长裙，绷不住了。</p>
<!--是这样的，清芬旁边的修车铺有三个摊位，目测属于三个不同的师傅。昨天去的时候只有中间那个摊位的师傅在，问了一下价感觉完全不值，晚上回去问了上学期在这边换过链子的室友，得到的价格要稍微便宜一点。虽然并不打算在这里换了，但是今天还是出于好奇（某些人的期中周是不是有点太闲了）又去碰瓷了一下左右两个摊的价位，也并没有开到室友当时那么低的。不知道是不是看起来有点好欺负（草）所以被看人下菜碟了（混沌思考.jpg），还是说涨价了，总之知道手工费值好几十之后越发觉得还是自己处理就好，还能 get 一点新技能。-->
<p>到教室坐下理好东西发现今天这边的教室全都被借用了，又把东西全都收好换了地方，好累。但至少没有到下午被赶出来才发现被借用，倒也不算太坏罢（</p>
<p>贝纳颂，一个月喝了两箱，今晚仰头灌完剩下的小半瓶之后突然觉得好难喝，空瓶摆在桌上看着都觉得有点胃酸上涌，感觉该换了。于是上某宝挑了半小时咖啡（完全没有期中周的紧张感.jpg，也没挑到太满意的，最后想起来社友<!--（茨月）-->之前安利过
Onebox
的挂耳，买了十包打算试一试<!--，如果我觉得不好喝的话能不能出给茨月老师（错乱）-->。如果囤货的话
99 块 40 杯，价格还不错，不过代价是以后每天要多带/多洗一个杯子（</p>
<p>明天考多元统计，然而今天看了一天实分析，现在合上书是能把第三章的每一个定理和证明口述出来没错，<del>不知道明天还能不能做到</del>，但属实是不知道这对考试有没有任何帮助，又到底有多大意义。多元统计的
cheatsheet
上还空着小半页但感觉没什么可写的了，决定摆烂早点上床睡觉，希望人没事。希望不要考太多理解性的玄学东西，多考考技术细节吧求你了.jpg</p>
<h1 id="月14日">4月14日</h1>
<p>考试前晚我一般都会早点睡，防止因为太困犯一些申必错误。我一直以为这是个很正常的操作，结果大一的时候每个期中期末的前晚，都是我早就上床睡了，三个室友还在下面通宵复习。微积分
A1
的期末前晚那次不知道为什么她们还一直在下面轻声讨论问题，台灯也都很亮，绷不住了，一直到两点多才睡着，然而这个时间室友也还没睡，很难想象没怎么学会（实话）又没睡够的话要怎么考这个。那次不知道我有没有睡到六个小时就起来考试了，<del>虽然并不影响薄纱这门课但是其实心情挺差的</del>。后来就经常想起来这个阴影（，考前早睡的时候总是担心会被室友吵睡不着，不过倒也都还好，可能是因为不再有和室友一起参加的考试了罢（</p>
<p>我以为我会在毛概课上复习多元统计，再不济把不考的那一章的笔记写了，结果我上
<a href="https://www.bridgebase.com/">Bridge Base Online</a>
打了三课时桥牌，最好的一局赢两墩。草。初中毕业之后我再也没在认识的人里面凑齐过四个会打桥牌的人，所以要谢谢
BBO。</p>
<p>考前不到一个小时的时候发现没带计算器，回寝室拿了一趟，正好撞见室友吐槽今天电电考试忘了带手表，我超，谢谢她提醒（。拿了计算器和手表，到教室发现把口罩落在寝室里了，多带了一样东西就需要丢掉一样，看来物品栏满了。</p>
<p>最近都有点想通了，实分析期中还就那个背水一战（，考不好大不了退课，积累不够的情况下硬碰硬一点也不值。虽然最好别退啊（悲</p>
<!--答疑坊值班的事情还是写到注释里好了，不想被线下开盒（-->
<!--第一次在答疑坊线下值班，鼓起勇气推门进去之后感觉有点不知所措（）。其实期中周也不是很想答，就只写了答疑科目是概率和统计类，没写微积分。本来想全程戴口罩（社恐面具.jpg）结果下午落在寝室里了，绷不住，感觉也有点希望大家不要找一个看起来在生病的人答疑（。这么说稍微有点阴暗罢，我本来就不咋喜欢做题，更不想翻来覆去倒腾微积分那点东西，干这个活确实只是轻松攒点钱罢了。-->
<p>这个多元统计的考试就很迷，不仅是这个题感觉又简单又难（，考试的时候我斜前面的人手机响了两三回才交出来。第一次来电话她还把手机拿出来，把电话挂掉，然后操作了半天又塞回口袋（，然后又响了一次微信消息，来第二个电话的时候，助教走到她面前了她才从座位上起来，把手机放到包里，我超，好离谱。</p>
<!--下午考完试打开手机瞳孔地震了。今天发了一张好人卡给一个...之前在我的视角里觉得基本不认识的人，我觉得挺抽象的。令人感叹。-->
<!--倒也没必要当谜语人，是高中时候的一个同学。我知道他这时候说这话大概只是想解开心结什么的，但也还是有点 shock，毕业快两年了我再也没见过以前的同学，而且一直都觉得几乎就不认识，说话也不多（相对和其他人还是有一点点多的但是真的不多，现在想想倒也确实都是被搭话（，没想到对方以前一直怀着这样的心情而我毫无察觉，还挺愧疚的。不过最绷不住的是，他以为明天是我生日所以赶在今天说了，搞得我都没好意思说出真相，草死了，我就真的这么没存在感是吗（（（-->
<h1 id="月15日">4月15日</h1>
<!--我绷不住了，昨天提到的那哥们今天还来祝我生日快乐，感觉死也不能透露出来并不是 15 号这件事了（（。问题是到底怎么让他知道在这附近的呢，不是很懂，是偷看过我身份证但没记对吗（（-->
<p>急急急急急急急急急急，非常急，今天丢下周民强返璞归真看 Stein
去了，希望明天人没事。我感觉我高三联赛之前都没这么慌（，当时已经乐子人了，考完这一场估计就结束了，但现在是明天要是寄了还得再重新上一遍，而且后半学期的负担也不会减轻，不管怎么样这课我都会跟完，我超。</p>
<p>想起来上次环友在环里说大家最好判断一下是喜欢学数学还是喜欢做数学研究，虽然仍然不知道这个问题的答案，但反正首先排除喜欢考数学（不会真有人喜欢考数学吧我超），太折磨了。</p>
<p>听说今晚泛函期中是真的有人考哭了，<del>看到了明天的自己</del>。真心实意感到辛酸，学这么难的东西给分还烂，身为普通人（我比普通人还菜很多）的话得不到多少来自外界的正反馈。<!--谢谢求真和 you know who，给本就不怎么健康的生态雪上加霜。--></p>
<p>周四的时候发现三教的桌子其实是可以通过调四条桌子腿底下的旋钮来改变高度的，感觉很冷知识。总觉得这个设计不是很对劲，本来桌子是平的，想通过调四个旋钮把桌子调高不难，让四个桌脚在同一个平面上也不是太难，但是想把桌子调水平听起来就很困难了。想了想感觉要是在旋钮和桌腿上各画一条基准线，然后转的时候可以数旋转的圈数来判断的话会好一些<del>（什么物理实验后遗症</del>。我发现这件事就是因为当时坐的桌子左边低右边高，不知道是不是上一个调这张桌子的人弃疗了。<del>微调旋钮什么的，听起来很光栅衍射实验，或者迈克耳孙干涉仪，有点
PTSD 了</del></p>
<p>今天坐了一张四个桌脚不在同一个平面上所以会晃的桌子，随便一调倒是就不晃了，虽然还是不平，但其实写字没太大感觉，只觉得电脑有一点点斜。所以这个设计的本意或许并不是用来调高度的，是防止桌子晃的（，对它降低了一些期待之后就觉得还不错了（</p>
<h1 id="月16日">4月16日</h1>
<p>实分析期中七道题，拿到卷子眼前一黑还以为每一道都不是很可以做，结果前
90
分钟切掉了六道（半？），还是很可做的。听起来是还不错，但是剩下一个是证明函数项级数和的导数等于导函数的级数和，我草，我哪里学过函数级数，整个破防了。虽然微积分
A2 确实讲了那么一点点级数但也不是重点，早忘完了。</p>
<p>遇到级数我就不太敢乱动，又不能瞎换序，记不起来是不是一致收敛可以判交换了，瞎想了半天能不能用
Egorov 定理，最后也没乱写，就寄了。交卷之后听人唠嗑，感觉大家都 ak
了，虽然觉得做得还行但等出成绩观望一下大概率还得退课，现在这样就算期中成绩过得去，期末肯定搞偷袭，ly
也有概率根本不调分，顶不住。</p>
<p>其实觉得挺可惜的，难得遇到一张水题，别的也都做的不错，还是寄在了我早有预言的数分没学完整上，<del>好不甘心</del>（。不管怎么样还是有信心了一点，感觉自己也没那么糟糕。也确实警醒我还得好好补数分，也想这学期学完
Stein 之后再回头认真刷一刷周民强，扎实下基础。下学期选个数分 3
好了，草，好混沌的选课顺序（</p>
<p>和 LagrangeKMnO4
浅聊了一下才知道都是周民强原题，草，没时间认真看过这书真的输麻了。</p>
<blockquote>
<p>真的很 drama ，我回来用了不到 10
分钟在周民强及其习题册上找到了几乎所有的题目，而且唯一没找到的那个还水的一批。但是复习的实在是太粗糙，导致考试的时候总有一种<del>这个妹妹我曾见过</del>的感觉</p>
<p>无论是如果考前能多拟合一下周民强的习题集和教材，就不至于发生在试卷上看到七个自己似乎见过又记得不是很清楚的<del>妹妹</del>题目的情况</p>
</blockquote>
<p>两句话让我在教室憋笑了十分钟（</p>
<p>下面这个引用块里的东西是我博客右下角的赛博猫猫敲键盘敲出来的，和我没半毛钱关系，也不是实分析的期中<del>妹妹</del>题目，反正我不知道这是什么，别问我。</p>
<!--今天看看突然觉得为什么连实分析期中考试都要复卷呢，感觉这个行为有点蠢。可能是觉得明年还要上这课所以想保存一份历史遗迹，也可能是看到 LagrangeKMnO4 在日记里复题目复得太草率了，就写了个完整一点的吧。-->
<blockquote>
<ul>
<li><p><span class="math inline">\(\{E_k\}_{k=1} ^{+\infty}\)</span> 是
<span class="math inline">\([0,1]\)</span> 上的一族测度为 <span class="math inline">\(1\)</span> 的集合，证明 <span class="math inline">\(m(\cap _{i=1 }^ {+\infty} E_i) =1\)</span></p>
<p>De Morgan
律取余集是可列个零测集的并，所以还是零测集，所以原集合的测度是 <span class="math inline">\(1\)</span>.</p></li>
<li><ul>
<li><p>对于任意集合 <span class="math inline">\(E\)</span>，存在一个
<span class="math inline">\(G_\delta\)</span> 集 <span class="math inline">\(G\)</span> 使得 <span class="math inline">\(E
\subset G\)</span>，且 <span class="math inline">\(m(G) = m^*
(E)\)</span></p>
<p>从取矩体覆盖出发总能倒腾出来的（</p></li>
<li><p>对于任意集合 <span class="math inline">\(A,B\)</span> 如果 <span class="math inline">\(A \cup B\)</span> 是可测集，<span class="math inline">\(m(A \cup B) = m^*(A)+m^*(B)\)</span>，那么 <span class="math inline">\(A,B\)</span> 也都是可测集</p>
<p>反正感觉挺麻烦，但总能倒腾出来的（</p></li>
</ul></li>
<li><ul>
<li><p>对于一个可测集 <span class="math inline">\(E\)</span>
和定义在其上的函数 <span class="math inline">\(f\)</span>，有对任意
<span class="math inline">\(\varepsilon&gt;0\)</span> 存在闭集 <span class="math inline">\(F\)</span> 使得 <span class="math inline">\(m(E -
F) &lt;\varepsilon\)</span>，且 <span class="math inline">\(f\)</span>
在 <span class="math inline">\(F\)</span> 上连续，那么 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(E\)</span> 上是可测的。</p>
<p>你看它长得像不像 Lusin 定理，但其实是逆定理哒（</p></li>
<li><p><span class="math inline">\(\mathbb R^2\)</span> 上的实值函数
<span class="math inline">\(f(x,y)\)</span> 对任意固定的 <span class="math inline">\(x\)</span> 关于 <span class="math inline">\(y\)</span> 连续，对于任意固定的 <span class="math inline">\(y\)</span> 关于 <span class="math inline">\(x\)</span> 可测，于是 <span class="math inline">\(f(x,y)\)</span> 是可测函数。</p>
<p>我总感觉这个是在作业里见到过，总之这个妹妹我见过的（，但是回去找了半天没找到，anyway
是构造函数列做的，懒得细说了，感觉算是前面这些里面最复杂的一个了（</p></li>
</ul></li>
<li><p>对于 <span class="math inline">\(\mathbb R^d\)</span>
上的可积函数 <span class="math inline">\(f\)</span> 定义 <span class="math inline">\(E_\alpha = \{ x : |f(x)| &gt;
\alpha\}\)</span>，证明 <span class="math inline">\(\int_{\mathbb R ^d}
|f(x)|^p dx = p\int_0 ^\infty \alpha^{p-1}
m(E_\alpha)d\alpha\)</span>.</p>
<p>原型是 Stein 实分析第二章 19 题，但是改成 p
次方形式了，好像助教在习题课上也讲过这个变形（虽然我一直咕咕习题课但是看过讲义），把集合测度换成特征函数积分，然后一个
Fubini 带走。</p></li>
<li><p>对于定义在区间 <span class="math inline">\([a,b]\)</span>
上的实值连续函数 <span class="math inline">\(f\)</span>，<span class="math inline">\(f\)</span> 有界变差当且仅当 <span class="math inline">\(|f|\)</span> 有界变差。</p>
<p><span class="math inline">\(f\)</span> 有界变差显然 <span class="math inline">\(|f|\)</span> 有界变差，如果 <span class="math inline">\(|f|\)</span> 有界变差且 <span class="math inline">\(f\)</span> 连续，对每一组 <span class="math inline">\([a.b]\)</span> 的分割，如果发生变号的情况就在
<span class="math inline">\(f=0\)</span> 处多取一个点做加细，就有 <span class="math inline">\(|f|\)</span> 的变差和 <span class="math inline">\(f\)</span>
的变差相等，放缩一下就有界变差。</p></li>
<li><p>对于 <span class="math inline">\(f : (0,\infty) \to
(0,\infty)\)</span> 有 <span class="math inline">\(f\)</span> Lebesgue
可积，那么 <span class="math inline">\(\frac{1}{f(x)}\)</span>
一定不可积。</p>
<p>我感觉这是个微积分的书上都有的结论，对 <span class="math inline">\(\int_{\mathbb R^2} \frac{f(x)}{f(y)} dxdy\)</span>
用一下 Tonelli Theorem，然后取 <span class="math inline">\(x=y\)</span>
方向的积分发现是正无穷就可以了。</p></li>
<li><p>函数列 <span class="math inline">\(\{
f_n(x)\}_{n=1}^{+\infty}\)</span> 满足对任意的 <span class="math inline">\(n\)</span> 有 <span class="math inline">\(f(x)\)</span> 是 <span class="math inline">\([a,b]\)</span> 上的递增函数，且有 <span class="math inline">\(\Sigma_{i=1}^{+\infty} f_n(x)\)</span> 对于 <span class="math inline">\(x \in [a,b]\)</span> 收敛。于是 <span class="math inline">\(\Sigma_{i=1}^{+\infty} f_n(x)\)</span>
几乎处处可微，且它的微分是 $ <em>{i=1}^{+} f_n(x) = </em>{i=1}^{+}
f_n(x)$</p>
<p>几乎处处可微是因为是递增函数，微分的级数和不会处理。但这玩意在周民强上面是个定理，输麻了。</p>
<p>看了答案觉得如果知道微分级数和怎么动，稍微有点经验的话倒也不至于开天窗，所以真有点不爽。</p></li>
</ul>
</blockquote>
<p>早晨提前了半小时出门，但还是被校园马拉松封路给整破防了，为什么要这么多人一起绕着紫荆区跑啊，有没有一种可能住紫荆的人也是要出门的呢。最后集合了四五个人一起从明德路突围了，结果大家一起骑到了明理楼，才知道全是实分析课友，乐死了。虽然这样其实也还算是到得比较早的，<del>到了之后助教盯着我看了半天，看得我很慌，不知道是不是衣服比较明显，让他发现我前天还在三教自习顺便围观他谈恋爱了（</del></p>
<p>明理楼这个教室，我坐的那一列前面还有块镜子，最后 45 min
基本心里有数推不出来这个东西，知道要寄了，<del>就一边思考一边从镜子里欣赏美女（指我自己（草，顺便还发现后排有两个帅哥。不过现在想想也未必是帅哥，只是距离比较远又是从镜子里看的，或许有美颜效果。感觉在华子几百年没见过帅哥了，欣赏了一会心情大好，很乐</del>。</p>
<p>不想了，等退课。考完了也还是一样的急急急急急急，急的是这周概率论作业还没写完，期中也还没复习，所以真也没空再想实分析的破事了。无论如何，至少半学期以来真的学到许多，概率论也没那么云了，退课我也赚麻，轻松地把后半学期跟完就好。</p>
<p>最近发现没车骑确实还是有点费劲，晚上找共享单车找着找着就走回寝室了（，上次在六教门口确实找到过几辆，但都是坏的，这次沿着学堂路找，是一辆也没有（</p>
<h1 id="月17日">4月17日</h1>
<p>上周急完实分析，这周开始急概率论（，现实是不仅要急概率论，还要急上周为了复习积攒下来没做的一堆其他事情，太惨了。</p>
<p>Onebox
的挂耳到了，喝着有一股很熟悉的，不太好喝的味道（，然后意识到，这不就和肯德基的咖啡那个刷锅水味儿一样吗（。香气还可以，但可能是我牛奶和咖啡的比例调的不太行，或者说这个牛奶就不太行，明天调整一下试试。</p>
<p>找到了一些主要是高中的时候写的东西，每次看都觉得是过去的自己在嘲讽现在自己支离破碎的思考和发言（</p>
<blockquote>
<p>不祈求任何人的庇佑，不祈求温柔长留。祈求我能温柔别人，祈求我在失去一切的风险面前仍敢于温柔。祈求神就住在我的镜子里，祈求我是冒险家，是猎手。祈求沉静耐力和任何时候都不为自己编织粉色梦境的勇气。祈求宇宙可能吞没我，而我能恒久凝视宇宙。</p>
</blockquote>
<blockquote>
<p>做一枝被剪玫瑰，到底值不值得。</p>
<p>我惠存这重击。是错是颠簸是曲折，我都记得。</p>
<p>（看起来像是青春疼痛文学，当时到底是什么心情呢</p>
</blockquote>
<blockquote>
<p>皮肤上经常会出现莫名其妙的淤青，我身边的物件也是，笔突然写不出来，手机好好贴着钢化膜屏幕突然出现裂痕，被人提醒才发现裤子膝盖上沾满了灰。只有我自己没有意识到，我正在不停摔跤。</p>
</blockquote>
<blockquote>
<p>在写过的语文阅读里我一直最喜欢《命若琴弦》。意义是要虚构的，拉紧的弦才能弹响。永远扯紧欢跳的琴弦，不必去看那无字的白纸。可明知道结局是虚妄的还是在跑的人，不是比为自己虚构一个假想的美好结局更有勇气吗，人是在战斗中证明自己存在的。</p>
<p>你从不觉得他们会战胜猝然临之的一切，就连他们自己也知道不能。但是他们的所作所为却能成为一种善因，你找不到克服虚无的理性因果，却能在他人克服虚无的决心与虔诚中受到震撼，并投身其中。</p>
</blockquote>
<p>我前前后后因为各种原因注销过三四次网易云音乐的账号，现在用的号也没有公开，主要就是因为中学的时候在上面写了很多东西，经常也会把当时日记的片段写上去，实在是不方便公开出来。</p>
<p>因为当时缺乏坐下来好好叙述的时间，思维又很活跃，经常在晚自习、走路回家、坐地铁之类的碎片时间里突然产生吉光片羽的想法，这种时候往往在听歌，就善用（？）了一个网易云的音乐转发功能，随手转发出去自己正在听的歌顺便写一些这样的东西。注销掉的几个账号不清楚有多少条动态，现在用的这个就有
1.5k
条，有一些现在看来还（相对）挺有灵气的文字的同时也有巨量的黑历史（，虽然有存档但也懒得去删掉，也不那么舍得删。所以完全没办法公开，就把
id 改成了乱码，随便挑了个头像。</p>
<p>前段时间发现已注销账号的动态、账号信息什么的现在都看不了了，以前似乎还是可以的。虽然早就把自认为写得不错的东西都存档了，<del>黑历史（大概主要还是和
ex
在一起时的种种破防发言吧）被抹掉了也是一件好事</del>，就算还能看我也并不想再回去看，但其实它就这样消失了也还是让我感觉有点难过。</p>
<h1 id="月18日">4月18日</h1>
<p>今天好热，是要放暑假了吗？</p>
<p>下午有点晒以及线性回归作业没写完，在寝室里一直拖到快上晚课才出门。大概是今年第一次把头发扎起来出门，稍微有点长了，扎双马尾吃饭也还是会扫到碗里，又懒得剪，试了下两边麻花辫。本来还在想会不会有点像
1980s 穿越过来的（，其实也还好，而且真的方便啊（</p>
<p>感觉概率论非常急，说一堆急然后再扯一堆别的根本不叫急，真正的急是现在这样的（悲</p>
<h1 id="月19日">4月19日</h1>
<p>听两个室友讲五一安排，感觉我甚至有可能五一会住单人间，被 ESXX
人吓晕（</p>
<p>后八周有个测量学，这学期唯一被我保留了的专业课（，是真的无聊。中午出门太晒了，走在路上差点想掏出手机问何老板出门了没有，后座能不能让我白嫖一下<del>反正他刚和
npy
分手了</del>，结果想起来他好像没选这课。那我夏季学期的地质实习和测量实习得和他组队了，工程地质我没上，测量学他没上，两个人正好凑出来两门理论课，大概只能互相捞了，很乐（</p>
<p>学不完了，还好周四的实验上学期做过可以抵掉，打算看看周六的实验能不能调组（UPD：太好了调到下周六去了），最好改到下周做，真的急。</p>
<blockquote>
<!--当我生活在那里时，将生与死视作了一种魔咒。在恰当的时机念出咒语，就能启动一台引擎，而带来某些改变。我确信，如果在那时它恰当地发动，会带来一些好的结果。在随后的几年内，因不再具备将其发动的条件而长期地痛苦着，在现在我回头看才意识到这句咒语已经失效了。-->
<!--我在青春期不得不回答了一个问题，即人为何不立即选择死亡；我当时给出的答案是，我当然想要选择，因为已经见过足够的挚爱。而后来我意识到，当见到从未见到过的美好之物、然后将其视作生命的全部意义、想要在它被其他的恨意覆盖之前用生命来交换其永恒时，恐怕不会想到在未来它将也可被称为井蛙之见。如果我及时念出了咒语，那么是美的；而如果没有念出，似乎也算不得遗憾。-->
</blockquote>
<!--上个月才在日记里写过：-->
<blockquote>
<!--想起来那句“他还太年轻，尚不知道回忆总是会抹去坏的，夸大好的，也正是由于这种玄妙，我们才得以承担过去的重负”。怎么仅有的好事还被我忘记了，坏事都还记得（-->
</blockquote>
<!--昨天中午删了（并不是删，哪一条我都不舍得删掉，只是改成仅自己可见）一些完全不能看的东西，晚上发现剩下的也有一些没那么看不了但也还是有点看不了的，又紧急删了一波，虽然还是不够快（。一边读一边删的时候感觉以前怎么这么惨（，但又非常陌生，不像是真的在自己身上发生过的事情。然后就想起来上次写的这句话，才知道和 ex 争吵以及经常因为他破防实际上算是那两年里的好事了，至少让我感觉到还活着，更坏的事确实是暂且忘掉了。还得是马尔克斯。某种程度上来说最近去读了当时写的东西也是承受了一次来自过去的重负，我惠存这重击。-->
<!--突然理解了我竞赛为什么这么菜，高考为什么也这么菜（。倒也不是，我突然觉得自己还是蛮强的，华子不过如此（草-->
<!--草，好谜语人。等 survive 了概率论期中再看要不要具体说一下（肯定不是写在这儿）到底发生甚么事了，我现在学不完了。-->
<h1 id="月20日">4月20日</h1>
<p>急。</p>
<!--可能是昨天转数环里劝退力度太大了，晚上梦到自己不知道在和谁抱怨说到底怎么想到要上这条贼船的啊（，现在想了想确实觉得到底咋回事啊怎么被骗到这里来的（，不过来都来了（-->
<!--~~进行一些自己都不信的自我安慰：现在比较菜只是说明别人接受数学训练的年限比我长，倒也未必真不行，这才活了没多久，数学也没学多久，学了五年的就已经很多了，那每多学一年都是多学 20% 的东西，所以我比别人菜是很正常的（。再多过几年拉平效应就会明显了，等我把课补完了你们一个都别想跑（恼），总之以后会好的（确信（确信~~ -->
<p>下学期统计中心有一门给研究生开的高等数理统计，我倒有点想去上一下，毕竟数学系没有测度论规范下的数理统计课。<del>之前挺馋这个的，差点想去北大统计系蹭这门课，还好统计中心有开，虽然不知道靠不靠谱，可能也没有本科生的课余量</del>。这学期的课还没上完，甚至概率论期中都没考，就已经在想下学期了（</p>
<p>晚上在紫操边上一边看路人跑步一边吹风喝酸奶给家人打电话，感觉自己坐着看别人痛苦面具跑步好爽（好阴暗！</p>
<h1 id="月21日">4月21日</h1>
<p>实分析这个期中成绩，感觉又用排位浅浅地挽留了我一下，但成绩绝对值实在是不太行，哪怕做出来的题也扣了分。写作业我也老感觉在伪证<del>而且真的伪证过好多次</del>，说到底基础的东西不太清晰，再加上数分题没做出来，有点不爽。</p>
<p>平心而论我觉得我本质上学得很烂，再来一遍当然会好很多。期中运气好卷子简单，<del>而且后排的一退课我的排位不就没了吗</del>，应该还是要遗憾退场了。</p>
<!--LagrangeKMnO4 也要退实分析了，我更没有跑路的负罪感了（-->
<!--什么嘛，数学系的平均水平也没我想象的那么强嘛（暴论，考完我还真以为要全员 ak，就我不会数分题了。上学期在 hx 抽代班里薄纱还以为是他这里样本点不正态分布的原因，现在觉得也差不多。-->
<!--但是今天看了多元统计的期中成绩，刚过平均，有点寄。我就觉得，为什么上统辅课会觉得统辅这边的人都这么强，上数学课反而觉得数学系的同学并没有我想象中强呢。感觉真得好好考虑一下要不要转去概率，统辅课真的上得不好，唯一一门学得好的也就是数理统计罢了，还得是全理论的那种（。这学期上多元和回归，天天搁那儿拷打数据，动不动看老师对着 dilemma 表演用直觉做选择，这种事情我真的不行，所以其实一直觉得很烦躁。我也不知道怎么办，我已经在选专业选方向上走了两年的弯路了，看来还远远没有到头。-->
<!--来个每日环友发言摘录，乐死了（-->
<blockquote>
<!--A：-->
<!--我一直觉得代数几何这种方向就是得快-->
<!--从高中开始学什么数分高代最好-->
<!--我上大一不知道极限的定义就是比求真慢两年-->
<!--B：-->
<!--到现在依然慢两年是吗-->
<!--毕竟 Lebesgue 测度平移不变-->
</blockquote>
<p>周日考完概率论就去写这周的实分析作业，笑死。</p>
<p>昨晚想着今天习概好像是在东阶，以前一直以为东阶是和西阶在同一个地方，查了一下才知道居然是在东主楼旁边，还觉得非常侥幸提前看到了。然后又查了一下教室安排发现东阶今天没课，震撼了，再一看发现课其实是在西阶，抽象（</p>
<p>晚上重写之前概率论的一个作业题<!--（指路科大 Page 77 例 2.6.3）-->，当时不太会就直接抄了书，今晚重新算发现和科大那本书上的结果死活对不上，而且我感觉我算的比较的对，就很迷惑。</p>
<p>正好晚上助教值班答疑，就去教室看了一眼，好多人，比习题课来的人还多，在门口社恐了一会还是进去了。等的时候顺便听大家提了很多神秘问题，突然觉得自己学得还行（这个可以说吗）。这份作业当时是
ws
批的，冤有头债有主，就问了他而不是另一个助教姐姐，结果把他问自闭了（，还承认了自己批作业的时候也是照抄了书，没算过，绷不住了（</p>
<p>最后感觉是书上的做法不太对。这个班 60 个人加两个助教甚至还有 lzx
本人都没发现书上写的有问题吗，难道大家都直接抄的答案，还是说我今晚也把助教带到沟里去了，好慌，不会考这个题吧，考了的话怎么办（</p>
<!--草，问助教的时候他让我在他面前把一个二元积分算一遍，虽然算对了而且真的是很简单的积分，但是莫名就好害怕，差点在动手之前先脱口而出承认自己不是数学系的没学过数分 Fubini Thm 也是这学期在实分析上重新学会的（根本没用到）所以很可能会积错来保命，绷不住了。果然不补数分二还是不行，自信上就完全过不去（-->
<!--另外虽然 lzx 的课很神秘，但其实我对他印象还是不错的，感觉他底力实际上很强，据说指导博士生的产出也不错。-->
<!--华子能不能让科研很强的老师就专心科研别教学了（，上学期摊上个念书机器人 hx，我有次做梦还梦到他拿着那个绿皮对着我不带一丝感情地一边往黑板上抄一边念，真的难绷，这学期又遇上 lzx。虽然是我自己没选 wxq 的问题（-->
<!--草，说到这个，昨天和樊硕还有书院转数的同学聊天的时候吐槽这个事情，樊硕说有些老师做的那个科研的方向在有生之年可能还不如给本科生好好上课有价值，绷不住了。-->
<h1 id="月22日">4月22日</h1>
<!--概还是统的问题今天和 V1ncent19 讨论了下（V1ncent19，我的人生导师！），悄悄骂了线性回归和多元里面各种不当人的直觉判断，绷不住了。其实本来还想问问 Mariana，但 V1ncent19 毕竟人在理学院，就先问了他统辅人有没有转了概率的成功案例，果然是没有，都做应统去了，统计中心也没有做概率的组。上次在答疑坊坐班的时候听 sxt 暴论说统计中心那帮人有几个是真的懂数学的，都是 applied statistics 罢了，乐。那我确实可能要离开统计中心再往数学系 / YMSC 收敛了，当然还要看我这学期结束之后去和顾陈琳 or 杨帆谈一谈的结果怎么样，万一因为基础太烂被大力劝退的话还得回来找林乾搞数理统计（悲-->
<!--我总感觉很奇怪，一年半的时间落下了三门数分罢了，我又不是完全没学这些东西，微积分到底还是学得可以的，为什么差距会这么大？大概的确只有数学分析是本质困难的，后面的课都是本质简单的（by 分系宣讲的时候忘记谁说的了x-->
<!--我走了两年的弯路，今后还要继续走下去。虽然现在还在痛苦地做选择，但其实已经收敛到很小的范围了，也是值得庆贺的事情。上次突发奇想在 about 里写了我是 random walker in maths，这才没过几天就真的又开始 random walk 了。还要动荡不安到何时啊！-->
<!--打开统计中心官网确认没有概率组的时候才发现他们换新 UI 了，不大好看（直白），感觉不如以前的。-->
<!--果真要换去概率的话后面的应统课也没什么好修的，不必再折磨自己。这又极大地影响了我下学期的选课，只能说还好选课之前这个问题突然摆到了面前，否则之后不知道是不是又要离谱操作一波。原来想下个学期开始大力修统辅课，现在只想随便选个非参数 / 高等数理统计这样的东西充课表了，为的是万一被劝回来的话不会太被动，要是开学之前发现走概率是可行的就直接删掉换别的，其他统辅课我也实在没什么接着上的心思。只能说还好概统是相似的，学过的这些东西也不很浪费，再不济沉没成本也不大。-->
<!--只是这样一来延毕就是板上钉钉的事情了。我其实并不介意，甚至会为多争取到了一年时间留在这里而欣慰。-->
<p>最近唯一一次见到和我发型一样的人，是今天在清芬门口，遇到了一个看起来不超过六岁的小女孩，也扎了两个麻花辫，草。</p>
<p>希望明天概率论期中没事，考完这一门期中月就结束了，<del>五一去哪玩呢</del>。<!--刚说完在考虑转概率，要是概率论期中反而寄了的话，是否有点太丢人了x--></p>
<h1 id="月23日">4月23日</h1>
<p>五一去哪玩呢（，求一些社恐友好的去处/活动推荐（，晚上看了 1h
各种测评也没发现特别有意思的，很急（这也要急吗）。感觉实在没得选的话我可能就逛一天二手书店然后去吃个火锅回来摆烂了，听起来好无聊（</p>
<p>下午去了一下转系推研宣讲的一个会，主要是因为看到是一个工物转概率的学长讲，感觉成分非常相似，而且期中也考完了，就去玩了一下。其实只讲了半个小时，主要说的是推研笔试面试之类的事情，说实在的和我没什么关系，但是比较有意思的是结束之后和学长以及一些书院转数人聊了会（一个多小时）天，<del>像回到家了一样</del>。<!--其实我真觉得和转数人相处起来都挺舒服的，虽然今天这个聊天一开始对我来说是纯纯带有目的性，我只是想找樊硕单独问概率组的一些事情，问问他的学习路径，顺便稍微了解下书院转数的情况。说实话带有一点功利目的的对话对我来说倒没那么社恐了，感觉有点把对方当工具人，眼一闭心一横问完就赶快逃（，反正这辈子也不怎么会再见面了（。但最后其实和书院转数的大家各种聊数学，从抽代到实分析，还有选方向的各种考虑和心路，也听了大家讲自己辗转的故事，在今天笑颜相会（其实是源的 Tokyo Dome 演唱会上的梗）在这里之前都走了好长的泥泞的路啊，真的都一样不容易。还挺开心的。-->最后加微信的时候还因为头像和
id 被社友线下开盒了，草，世界真小。</p>
<!--其实这哥们直到推研上的数学课也没我多，他大四之前甚至没学过实分析和泛函，绷不住了，拿头做概率。本科生科研也趋近于零，但也顺利推研到吴昊门下了，只能说保研是真的事少，一个笔试一个面试罢了。从他那里探了一下概率组的底细，感觉也不必把顾陈琳的优先级放那么高，他做的东西比较难，本科生未必能做出来多少成果。完全可以考虑找吴昊谈，姜建平和荆文甲（虽然环友评价 jwj 是带恶人x）也行。樊硕跟我讲吴昊开玩笑说想让他从这一届大二找个学妹过来，万一真想去找她的话记得说是他的内推，绷不住了。-->
<!--其实书院转数人比我想象的多一点，今天光是零字班的同学就遇到三个，一个探微一个未央一个行健钱班，两个数学物理一个概率。把大家都拉进了转数环，新元素增加了！未央零字班那哥们也说没想到书院转数的这么多，还以为就自己一个，另一个哥们说你也不想想我们是怎么被招进来的，还不都是数竞落榜生吗。绷不住了（-->
<p>今晚重新开始答疑坊<del>秒</del>接单了，这个月的津贴非常的危，等级也没升上去，吃的还是最低一级的低保，就很失败。毕竟几乎两周都没干活。不过其实稍微有一点补贴就够了，感觉我除了一日<del>三餐</del>两餐之外是真的没什么消费，恩格尔系数逼近
1 了捏。</p>
<p>明天上午打算动手修车，今晚把以前打 maimai
的手套翻出来了，明天修车的时候用一次然后可能就不想要了（。不过我现在也不打
maimai
了，其实也就打过一次，肥宅的音游就应该阴暗地躲在床帘里打，为什么要在线下健身，好恐怖（</p>
<p>复分析这个课程群总是带给我很多乐子：</p>
<blockquote>
<p>A：</p>
<p>请问可以公布一下（期中考试的）主要分位数吗</p>
<p>xjx：</p>
<p>什么叫分位数？</p>
<p>B：</p>
<p>老师好，大概就是 1/4，1/2，3/4 的同学考了多少分这样子 ()</p>
</blockquote>
<p>薛四金啊薛四金你的概率（或者说这也算是统计吗）学哪里去了（逃</p>
<h1 id="月24日">4月24日</h1>
<p>早上早起修车（虽然又拆出新问题了！），晚上回来接着修，太暗了遗憾离场明天下午继续，回寝室又帮一个室友给手机贴了膜，上次还帮她清了一次灰（。突然感觉我以后应该是饿不死，实在不行再去学学洗抽油烟机，然后去天桥下面摆摊，主打一个啥都能干。</p>
<p>今天在概率论课上读了点 Durrett，相见恨晚，比 Kai Lai Chung
友好。后半期把多元统计也退了，不太想继续上了，把从统计转概率提上日程。<!--这个选择到底对不对，我怎么知道啊，总之先试试罢。-->看起来课表空了很多，但愿不要太懈怠，打算一边学概率论一边学一点随机过程。总而言之就是跟着
lzx 过 Kai Lai Chung，自己再读 Durrett 后几章，以及把实分析跟完。</p>
<p>我总觉得我干啥啥不行。<!--我妈对我走了两年弯路的评价就是我干啥啥不行，这也不行那也不行，别人为什么干什么都行（虽然不知道别人在哪里）。虽然感觉自己相比别人就好像少学了十多年，小学初中在义务教育（，高中又精神状态很差也没怎么学进去，竞赛的有效学习时间可能都不超过半年罢，大概还是来了华子之后才真正开始学。找了这么多借口，但有的时候还是很难不承认她是对的。--></p>
<blockquote>
<!--第十四届丘成桐大学生数学竞赛报名已结束，本年度共有来自 500 余所高校的 2800 余名学生报名参加个人赛，56 支队伍报名参加团体赛，涵盖个国内 29 省市自治区，以及中国香港、台湾等地区。-->
<!--新变化：今年数学物理考试大纲进行了修订，增加四大力学内容。-->
</blockquote>
<!--好多人啊.jpg，但感觉又没那么多（-->
<!--You know who 到底为什么对四大这么有执念（-->
<!--我急了，丘赛之前总要学完 Markov Chain 吧（，说到底我居然还想着去考丘赛这件事，绷不住了。我就报了计算和概统两场，正好是第 12 周周末的两个下午，不用早起，这是好的。当然不指望计算方向能做出来什么题，数值分析我也不记得啥了也不打算再特地复习，搞不好概统考完心态爆炸就弃赛了。就连学了半年多（好寒酸）的概统也完全没法指望有什么成绩，主打一个体验，（两场加起来）不爆零就是好的。说到底我也不想再考竞赛了啊，昨天还在暴论说不会真有人学数学是喜欢做题吧，不会吧不会吧（。学数学多有意思，考试和大量做题简直是在磨灭兴致，但是为了掌握技巧又不得不这样做（-->
<!--草，上次希望两场加起来不爆零还是 2018 CGMO，学了俩月就被推过去考试了，第一天大约确实是爆零了，第二天抢救回来两个题，最后 Cu 第一名回家，很难绷得住。-->
<!--我在华子考数学课的期中期末偶尔还会觉得数学系的大家也没有我想象的那么强，不知道丘赛会是什么体验。可能也没法和期中期末类比吧。-->
<!--怎么说呢，我想跑到概率来，有一点原因大概是上学期学了个初等版本的概率论，然后这学期同时学实分析和测度论规范下的概率论的时候被震撼到了，把实分析搬运使用得严丝合缝，真的很美妙。我之前开玩笑说统计中心那个统计算什么应用数学，顶多是数学应用，但我心里好的应用数学可能就是概率这样。-->
<!--绷不住了，说到底对学科的全貌就没有什么好的理解，就在这里暴论。-->
<blockquote>
<p>正因战争带走了她的心上人，她开始意识到在菲殊洛之外，还有更远大的世界：“已经领略过山谷外面的世界，但选择回到家里——这是一回事；从未有过离开的机会，于是只得待在这里——这是另一回事。”这是一个
14
岁、还没有接受良好教育的女孩自我教育的历程。她很爱这个人，但她更想像他一样出去看看。至于另一个女孩、她的情敌，则是其次的原因。</p>
<p>她也没有对旧情人的孩子说，当她打来电话的时候，她曾“感到一阵战栗，如同紫罗兰迎来了春风的吹拂”。细腻的女性心理描写，是菲奥娜∙基德曼的长处。比起借由小说女主人公放纵欲望的爽快，小说叙述者却选择了另一种别致的方式，以理性驯服感性，没有摧毁爱情的信仰，而是告诉我们它的力量。爱丽丝知道有过这样的一件事，很动人的一件事，但比起当时心里想做的事、心中想成为的那个人，爱意只是一阵很美好的微风。“走出去”，是菲奥娜∙基德曼小说中的重要主题，爱情则成了这一主题的试金石，考验出走的决心。</p>
<!--呜呜，教教我吧.jpg（什-->
<p>如此的心灵微风，在《帽子》《红甜椒》两则故事中亦有相似的微妙呈现。一位在儿子婚礼上心思浮动的母亲、一位逛超市却遭遇不愉快经历的妇人，她们都感觉到即刻内心秩序被打乱的威胁，那都是生活中“自我保护机制自行启动”的时刻，很难说它来自于什么明确的教诲书，而是来自于女性敏锐感受到危机的本能：“我们在变幻莫测的际遇中求索自己的道路，与此同时，我们一遍又一遍地质疑它，留心地雷与突然的爆炸，追寻每一刻的真相。”（《红甜椒》）</p>
<p>——<a href="https://mp.weixin.qq.com/s/le_SbWL5Y4R10u_0VF48vg">《怪姑娘感受大世界：“我们也是古怪的移民”
| 张怡微》</a></p>
</blockquote>
<p>好久没在文汇笔会看到喜欢的文章了。今天读到这个，突然很想去读读这本书。然而什么时候能有空呢
x</p>
<h1 id="月25日">4月25日</h1>
<ul>
<li><p>下午把车修好了。其实昨天就把链子换好了，就是钳断原来的链子 +
调整新链子的长度 +
把它套上去卡紧然后试试能不能转起来罢了，我会了！不过感觉这个轮盘其实也有点不太行了，不知道这破车啥时候会把零件都换一遍成为忒修斯之车，希望之后万一出问题也还是能自己解决。</p>
<p>但是昨天修完之后得意忘形开始拆别的部件试图学习一个其他修车技能，最后把后轮拆下来装不上去了，实在很难绷得住。今天还是装回去了，以及发现这车之前感觉不好骑其实也有车链子的问题。</p></li>
<li><p>下个学期居然是于品开抽代，我急了我急了我为什么没有今年上这课，输麻了！<del>但是
hx 给我 4 学分 4.0 而且或许更重要的是认识了 Bowen L
这么可爱的助教而且更坚定要转了所以也完全不亏</del></p>
<p>打算是数分 3 + ODE +
拓扑（这个东西虽然我不做基础但听起来就会有用！<!--不会拓扑算甚么数学人（暴论-->，泛函肯定上不动，硬上就是实分析这个下场。前两个也可能二选一，感觉已经很硬了。但是统辅课不需要继续上的话还可以再塞点偏应用的东西，随机过程肯定是要的，说起来求真的概率论
2 不知道开不开课。不开的话就去水一个优化/计算相关的课好了，PDE
数值解？其实应数的这些课听起来都蛮有意思的，<del>虽然上起来就不一定了</del>。</p>
<p>ODE
有新老师开课，居然是台湾人，感觉有点意思，想选他的。其实还是和原来一样，想避开数学系的同学上课，不想去抢李思的课。虽然我也不知道时至今日为什么还要避，一起上其实感觉也还好，何况我这次面对的是二字班呢。另外感觉新老师的给分可能普遍好一些罢，绷不住了，怎么有人大三了还在雕花成绩单，当然我这个本科要读五年了，就当我还是大二好了（</p>
<!--btw 前天樊硕告诉我还有一个 4 学分的科研论文训练可以选一下，可以跟吴昊蹭科研，感觉这就很满了。不知道为什么要放进注释里，可能是这事目前还没谱吧，我甚至还没联系过吴昊。-->
<p>等等，所以我到底是哪个专业的，我的专业课呢？什么工程与法律、房地产经济学之类的东西呢？绷不住了。</p></li>
<li><p>今早刷空间看到了 dmy
回忆录，太乐了，查了查这篇文章早就有，以前居然没看到过（</p>
<blockquote>
<p>初三集训队测试后，<strong>我水平忽然长进许多</strong>。我并不知道原因，但当拿出从前无法解决的题目看时，<strong>发现几乎都会了</strong>。</p>
<p>一月份的时候，我去了上海复旦附中。那时我的好朋友<!--（总感觉指的是左爷爷，不确定，再看一眼x）-->在上海的另一处，于是我们逃晚自习坐了一小时的地铁见面。<!--从复附出发需要俩人各坐一小时地铁见面，那感觉另一个人确实应该是在浦东，那真的很有可能是左爷爷或者 wyc（-->坐回去时，天已全黑，我艰难地在黑暗中溜回了宿舍。</p>
<p>那年测试似乎没什么波澜。<strong>我把会做的题认真写写就进了国家队</strong>。</p>
<p>在国家队选拔的地点上海中学的那段时间频频下雨。于是，我和同学总是撑着伞漫步。伞檐和天色一样阴沉，常走着走着就迷失了方向，到了庞大校园的另一角。</p>
</blockquote>
<p>上海的学校提了俩，猜猜四校里面还有谁没出现（x</p>
<!--正好昨晚突然又梦到一些数竞往事，高中的时候班里有个数竞的同学曾经有一阵子和我关系不错，当然现在我联系方式都已经被他删完了，之前其实讲过，就是某一位植树节过生日的同学（。当时他经常出几何题给我看，其实我对各种结构拼在一起造出一堆题目来一点都不感兴趣，也对做他出的题没什么热情，后来他也就自己搓着玩不给我看了。不如说我当时觉得平几就是个挺无聊的东西，当然添线看结构做几何题可以很有趣，但其实我做乐了的几次都是在几何里面算东西，金秋营归纳法手算的 Japanese Thm 大概是巅峰状态了，现在想想还是感觉很鬼才。扯远了，总之，并没有某个现代的研究领域叫做平面几何吧。当时知道代数几何很前沿（当时就好云，现在也还是云），知道真正的几何大约已经脱离纸面上的形了。概率计数奇技淫巧的初等题目同理，我想做概率，自然不是去研究那些可以给小学生讲懂但我现在也未必会做的古典概型。-->
<!--我当时想的就是我真的不是很想考这个竞赛，但如果可以（精神状态允许x）的话我会想漫无边际不限时不闭卷地思考，以及一直学数学，当然主要是别的学科也都学不大会。大概当时还没有做研究的这个意识，但听起来还蛮像的，为什么要这样不停地做题，甚至身边还有选手沉迷出题来为难我，这有什么意思吗。最后两个月刷中数增刊自救之余还是自学了一些冬令营之前都用不上的东西，印象最深的是正交多项式理论，上学期在数值分析里又看到它真的很激动。-->
<!--当然最后的结果是我耻辱退役，没进营自然也用不上这些东西了，前面说的那位哥们拿了牌去北大读数学了。已经完全失联了，不知道他如今怎样，总之还是祝他还能继续找到乐趣，其实我也相信他可以，希望我也一样。--></li>
<li><p>今天终于错峰看到了铃芽之旅，谢谢华子在周二加了一场，谢谢可以调到明早去上的线性回归，谢谢谢谢谢谢。本来其实没抱什么期待，来看就是情怀，<del>以及庆祝活过期中月</del>，不过我还挺喜欢的。</p>
<p>虽然但是为什么环姨妈随手从草地里捡起来的一辆破自行车看起来比我的车还好骑，哪里也没坏，能正常骑上坡，还能带人，车筐也没破还能带猫，羡慕（</p>
<p>本来坐我前面那哥们太高了，我还以为全程可能都要被挡着看不到左下角的画面了，结果开场十几分钟他就把头靠在了
npy
身上直到结尾，绷不住了，但是谢谢（。吃完饭觉得提前半小时来得太早了，没想到真的是不对号入座，还是很庆幸能坐到自己挑的座位上。一起来的朋友开场前十分钟出去了一趟，就两三分钟的时间里我至少和五个人说了“不好意思这里有人了”，最后绷不住了直接把手按在了旁边座位上，但还是继续被问（</p>
<p>前半部分还在乐，从听到男主变成要石之前喊出来“明明都遇到你了”以及环姨妈和铃芽在停车场的争吵之后还是开始代入了
qwq，另外我其实一点也不觉得恋爱线奇怪。</p>
<p>如果看完回教室之后我想打开主题曲再洗一下脑的时候耳机没坏，没犯蠢放出来那几秒钟就好了，好社死（。当然我也不是第一次在教室摸鱼的时候社死了，上次是睡觉定了个闹钟结果太困了忘记关声音，上上次是帮室友买了东西结果她给我打钱的时候没关声音，只能说幸亏不是收到打赏的时候那个商家到账的声音，上上上次，草，不能再回忆下去了，好想死（</p>
<p>想了想上次看电影还真是天气之子，翻了一下猫眼小程序的购票历史记录里还有我
19
年买两张天气之子的电影票的记录，绷不住了，不要在这种时候这样给我一拳啊（。又想起来我以前给老姐形容过，当时看完出来，ex
把票根丢进垃圾桶的时候那个垃圾桶翻盖的声音比我心碎的声音还要大，哥们就不能给我点面子过会再扔吗，乐。<!--照这样下去健康工作五十年之后还在骂他感觉也不是没有可能--></p></li>
</ul>
<!--今天写了好多啊，大概这就是期中月结束了罢。虽然每一门都裂了（-->
<h1 id="月26日">4月26日</h1>
<p>今早突发奇想试了一下发现耳机插电脑还能用，手机就不行，感觉可能是手机插孔坏了，清了下灰也没啥效果，比坏一个耳机的问题还大。想找人借个有线耳机测试一下耳机插孔有没有问题，都找不到还在用有线耳机的人了。这下真得买蓝牙耳机了（（</p>
<p>看课表发现林勇下学期去求真讲实分析，绷不住了，他总不会还这难度吧（</p>
<p>晚上写概率论作业遇到一个要用留数定理做的题，在听说复分析期中很摸之后再一次为没保留这门课小小地破防了。</p>
<h1 id="月27日">4月27日</h1>
<p>发现数分 3 和拓扑冲突了轻微破防，就像这学期发现概率论和数分 2
冲突的时候差不多感觉。只不过我可能也还是倾向于选拓扑罢，就像这学期选了概率论一样，数分是可以自己补的，我也没有完成培养方案之类的需求。<del>本质简单</del>的高级课还是上一个比较好，学得越多回头看越容易。没人逼着我读的话我真不知道拓扑会拖到猴年马月再学。</p>
<p>我只能说 lzx
真的带善人，看大家期中寄了就把比例往下调了。虽然我期中其实是小寄在分布函数没背熟全靠考场手推了，期望也没背，证明倒是都没啥问题，草。为什么不能直接写个分布名拉倒啊（，感觉是学统计遗留的毛病，天天构造
F
分布做检验但是没在意过具体的概率密度函数。但密度函数有什么用吗，不都是通过统计量构造出来的吗（（</p>
<p>已经不知道第几次在三教自习遇到某位实分析助教和他的 npy
了，<del>既学得会数学又有
npy，太赢了（</del>。退课了还要遇到他，绷不住了。我说你们数学系的博士生是真的没有工位吗，为什么天天往教室跑啊，那我更不要保研了（</p>
<p>别人拍六教是 key hole
而且可以放在三教展览，我之前拍出来是铁臂阿童木（挠头</p>
<p><img src="https://s2.loli.net/2023/04/27/vt5J9CxKrinLfyb.jpg" alt="AF2C7B9DB52A91F436A5A3D3B73208F2.jpg"></p>
<h1 id="月28日">4月28日</h1>
<!--听说高中班主任作为校友今天来华子参加校庆了，很难绷得住。看高中班级来北京的那个群里的同学基本都去和他吃饭了，就我主打一个消失（，晚上又被我妈骂说不懂维持人脉（（-->
<!--没办法，我实在不想看到他，也实在不想看到以前的同学，相信大家也不想看到我（-->
<p>四月份把自己冻感冒了，我觉得我也挺行的。今天下雨之前回去拿了伞，属于是有进步，但是还是穿少了。摊牌了，我真的不是抗冻，我只是实在不会按天气预报穿衣服，经常穿太少，还从来不带伞（</p>
<p>花一节习概写完了我半年前报的笨蛋
SRT，实在很难绷得住，当时为什么要报这么个玩意。一开始以为是个 NLP
的题目，完全不懂，抓耳挠腮，昨晚给我逼急了试了一些极其 trivial
的统计方法，来自多元统计的
EDA（俗称计数然后用眼睛瞪）和来自一阶段就退掉了的统计学习的 RFC
往上一套，accuracy 高达 <span class="math inline">\(0.984\)</span>，我真绷不住了。</p>
<p>就这样吧，忙活三课时，2 学分 4.0 到手，再见。本来想把 notebook
往云盘上一扔跑路，但之后可能还得写个结题报告之类的东西，我不好说。同组的两个哥们还搁那读文献呢，我本来一直啥也没干也不想多花时间学<del>（那我报这个到底是打算干啥）</del>，结果现在进度率先满了，哈哈。本来准备下午组会开始吹结果下大雨组会没了，反正这俩哥们也不懂统计，问就是数学的水太深了你们把握不住别管是什么方法做出来的反正你看我这个结果是不是挺好的啊我们快结题吧什么时候把我的绩点打到账啊.jpg</p>
<p>是的，抓耳挠腮逼出 <span class="math inline">\(0.984\)</span> 的
accuracy
是因为今天原定是久违地要组会，今天组会也是因为老师想提醒我们这玩意快要结题了。反正就开摆，比的就是谁更不急。<!--这玩意甚至还有五千块经费，第一次开会画大饼的时候说用来买算力或者真能做出什么东西的话投期刊用，拉倒吧。不知道这笔钱最后会怎样，难道还给学校吗，乐（--></p>
<!--早知道 SRT 这么水，明年再整一个。-->
<p>答疑坊统计第一次津贴了，才知道我吃的还真不是最低一级的低保，已经升了一级了。工时严重的缺，但是期中月拿这些也差不多得了，况且我只答小程序不在群里捞问题，已经不少了，而且稍微有一点真的就够用。</p>
<!--其实我每个月的支出经常不到四位数，总感觉在吃草活着（-->
<p>晚上下大雨教室里没人，想着一个人躲在后排用插座这么好的机会拿来写概率论第
12
周的作业（草，我写了一周概率论了，终于要把下下周作业写完了！（UPD：写完力！））也太可惜了吧，于是连刷了
7 话赛马娘，真不错啊真不错。</p>
<p>来个（和当年给我大力安利赛马娘的群友的）生草对话！（实际上感觉 21
年就被安利了，现在才看（</p>
<blockquote>
<p>我：</p>
<p>今天北京下大雨，教室里没人，正在绝赞补赛马娘第二季</p>
<p>开始看之前：马娘跑步有什么好看的</p>
<p>看了一半：米浴我的米浴，帝皇我的帝皇，太帅了 qwq</p>
<p>群友：</p>
<p>下雨天就适合看大米洗澡</p>
<p>我：</p>
<p>下雨天先给我洗了个澡</p>
<p>这雨大得给我感觉像回上海了一样</p>
<p>群友：</p>
<p>雨知道你五一不回上海 它真的 我哭死</p>
<p>我：</p>
<p>？草</p>
<p>我今天看赛马娘，越看越觉得麦昆会非常是我 ex 喜欢的类型！</p>
<p>结果看了一眼他的知乎 id 还真是 McQueen，绷不住了</p>
<p>群友：</p>
<p>傲娇温柔大小姐，还真是（</p>
</blockquote>
<h1 id="月29日">4月29日</h1>
<p>看赛马娘看到两点半，一晚上冲动刷完了第二季，本来是想五一假期慢慢看的，但果然停不下来。感觉短暂地变回二次元了（。上次冲动熬夜看番还是赛博朋克边缘行者，也是上学期期中之后，看来每学期都得有一次。</p>
<p>新买的耳机到货了，其实有线无线各买了一个，但是当时为什么要买两个来着，怎么感觉想不清楚了。试了一下有线的发现，我超，我手机的插孔还真没坏，原来的耳机在电脑上也用得好好的，就只是不能插在手机上用。好怪啊，<del>你俩是分手了吗</del>。但是新耳机的一格音量比我原来的两格还响，有点受不了，退货了。</p>
<p>早晨被紫操的校庆活动叫醒，绷不住了，但是听到有一个节目是有个男生在唱<a href="https://music.163.com/#/song?id=22635185">《letter
song》</a>。听前奏听出来是 letter song
了，但是听他唱一开始硬是没听出来歌词（</p>
<p>今天看到社友说 MBTI
的测试题更新了，正好也很久没占星了，又去测了一遍，从 INTJ-A 变成了
INTJ-T，四舍五入精神状态稳定。不过之前一直没关注过最后这个字母是什么意思，简单看了一下讲<a href="https://www.16personalities.com/articles/assertive-architect-intj-a-vs-turbulent-architect-intj-t">两种
INTJ 差别的文章</a>开始深刻怀疑之前是怎么测出来 A 的，我怎么看都是 T
才对（</p>
<h1 id="月30日">4月30日</h1>
<p>自从补了赛马娘之后，在路上骑车从外侧超别人的车的时候都充满了信念感，草（</p>
<p>昨晚三点三十五把实验报告交上去才睡，按说 ddl
还有六天完全没有急的必要，但我每次做完实验不知道为什么都非常的急着写。交掉之后突然很想给我院院长打电话把他叫醒，问他睡了没有，我还没睡，因为他让我学基物（虽然我没学）还让我做基物实验（</p>
<p>果然大家五一都出去玩了，教室好空。我和室友吹水的时候开玩笑说我不要
996，润出去享受 WLB
去了，但是有的时候真的很怀疑在肉眼可见的时间之内，我的 work 就是
life，life 就是 work，WLB
对我来说到底会意味着什么呢。<!--我还在 about 里面写 I have a vast, vast soul，就这？（--></p>
<p>似乎认识的上海的同学都回家了，<del>不认识的也回家了</del>，不是上海的同学也有好多去上海玩了。能有勇气（？）和兴趣去
CP29 或者音律联觉玩的宅宅和我就已经不是一个物种了，太可怕了（x</p>
<p>今天发现我分不清王府井和外滩的照片，但是如果拍外滩拍不到黄浦江的话不就和王府井看起来差不多吗（。群友还问我五一去上海有什么好玩的地方，这种问题我哪里知道，上海能有什么好玩的（暴论</p>
<p>之前说五一打算清理一下之前做不完的事情，补作业和写一些课程论文，然后浅学一下留数定理和
Markov Chain，补一补咕了的 Hilbert
Space，其实也全都是在为概率服务。如果可以的话前两个还挺想在博客上写一写的，不知道能不能忙得过来。结果严格来说五一还没开始，我今天就完全没有干劲，一共就写了一点生统概论的作业，预习了一个物理实验（绷不住了，好像永远在做物理实验），<del>睡了一大觉</del>，腰还非常疼（</p>
<p>看到一个<a href="https://mp.weixin.qq.com/s/UK6TJ9Ztl-KCZM8ZiPZi-g">《走出校园，有什么是清华没有教给你的……？》</a>，虽然一看就是校庆期间会发的校友采访文章，但我第一反应是，华子连课都讲不清楚，别说有什么没教给我了，你就说说到底教会我啥了吧（</p>
<p>这个月的日记有整整三万字，到底在说些什么呢。三万字是什么概念啊，听起来大水漫灌（</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇九·23年5月</title>
    <url>/2023/05/01/Diary-2023-05/</url>
    <content><![CDATA[<p>是不是快期末了（</p>
<span id="more"></span>
<h1 id="月1日">5月1日</h1>
<p>之前买的 Onebox
挂耳咖啡怎么整都不好喝，加牛奶也没有拿铁的感觉。前两天给我搞烦了，直接冲了当清咖喝，这个味儿，只能说没在教室里吐出来就是我尊重它。本来还在想要不要买点椰乳粉或者奶球之类的东西调一调，今天突发奇想融了一颗牛奶巧克力进去又加了奶，居然变好喝了。巧克力也是少不更事的时候买的代可可脂的，吃两颗就腻歪，属于是一次解决两个大麻烦，就是洗杯子有点痛苦，以及似乎会长胖的样子（</p>
<p>晚上在答疑坊补班，<del>主要是来帮朋友抢救概率论作业</del>，劳动节真就来劳动了。向一些我觉得讲课讲得很烂的老师道歉，对不起错怪了，我没想到其实我线下讲题也非常烂。也就是写了一个星期的
characteristic
function，今天再回头看条件期望的东西就觉得要昏过去了，对着第九周写过的作业题前言不搭后语（</p>
<p>我还以为假期自愿值班就没志愿者会来了，结果除了我之外还来了一位。与此同时我还以为假期也不会有人来问问题，来问个数学的话只要不是复变或者数理方程我也基本能
handle，结果唯一一个来的是问 OOP
的，绷不住了。还好另一个志愿者正好是计算机类的<del>不然可能就要靠 ddl 前
rush 概率论作业的朋友帮忙答了（什么荣誉队员（</del>不然就寄了（</p>
<h1 id="月2日">5月2日</h1>
<p>好热，今年第一次穿上了去年中秋社聚时候穿的裙子，想了想还配了一下当时穿的高跟鞋，然后就明白了为什么社聚之后半年多都没再穿着出门上过课——声音太响了，走在教学楼里好有负罪感（</p>
<p>半年没穿还差点摔了一下，不过问题不大。回忆了一下，社聚的时候我还穿着它绕着近春园跑了一圈，今天在清芬门口踩到一个不太平的地方差点摔了，看来确实是我变菜了。</p>
<p>夏天来了啊。月寒日暖，来煎人寿。</p>
<p>无线耳机到货了，音质不错，续航还行，最好的一点是大小非常合适，是我戴过最舒服的耳机了。但是它到底为什么要在贴近脸的一侧设计一个按钮（要真是按钮也就好了，甚至只是个触摸区，不知道的情况下就按到了），长按五秒关机，拿在手里找想听的歌的时候直接关机了，毫不知情的我又一次在教室里打开了音乐，社死记录
+1，已经没有什么可在乎的了。睡觉的时候也直接压关机了。另外开关机和快没电了的提示音也太响了罢，不戴都能听得见（</p>
<p>5.14 UPD：贴贴的时候也会压到，很难绷得住（</p>
<p>总的来说还行，<del>毕竟无线耳机，说不定在我因为这些问题彻底绷不住了之前就已经弄丢了，而且就算这样也比我以前用的那个美丽废物
BeatsX 好点，那还要什么自行车。</del></p>
<p>看空间感觉全世界都在
CP29，太恐怖了。有个高中同学还给我发消息，问我是不是也在
CP，还说好像看到我了，草，我说你们要是真的不认识我了的话就假装没看见不也行吗.jpg（</p>
<p>破防了，写个概率论作业要用留数定理，写个实分析结果看半天 Hilbert
Space
给我来个法图定理，又拐到复分析去了。这玩意不学是不行了，明天至少得把留数定理学了。<del>好崩溃，我到底为什么没选复分析啊（</del>，感觉这个实分析要是不退也真的上不下去，底力不行，<del>能不能放置飞升呢</del>，自己慢慢学吧。</p>
<p>更破防了，昨天带着朋友 rush 的概率论作业比我自己的还高了 1 分（10
分制），明明还少写了几个题。我的概率论作业一直只有 10 分和低于 9
分，不是很懂评分标准到底是啥，这样的话以后不会做的题真的也不想写了。写了自己做出来的步骤还备注了哪些地方卡住想问问怎么做的的结果就是被打低分，打低分然后不回答我也就算了，助教也从来不发完整的作业答案，之前还有一点点提示，最近几周直接没了，不会的题还真的就永远不会了。有几次有题直接没写<del>（主要是完全不会，一点也写不出来）</del>的时候助教连我漏题了都没看出来。我的评价是算了吧，不值得（</p>
<h1 id="月3日">5月3日</h1>
<p>无效社交一中午，好痛苦（</p>
<p>骑车回来的路上复刻了下铃芽之旅名场面，下坡的时候把脚荡起来离开踏板，看的时候还觉得这个动作好危险，实际上也没什么，也就是继续骑的时候腿被踏板打了（。所以这个时候不是会偶遇到帅哥的吗，帅哥在哪里（</p>
<p>本来觉得速成留数定理好像很捞，问了一下电子系的室友才知道她上学期那个
3
学分的缝合课复变函数与数理方程上都教了留数定理，单纯会算的程度的话找本工科的复变函数读一下就好（<del>虽然这么干感觉很罪恶</del>。随便找了一本一天读了
150
页（，所以我终于会留数定理了！现在不管看到什么积分都想求留数，在清芬的垃圾桶上看到翻译似乎是
residual 的时候还愣了一下（</p>
<p>赛马娘第一季也快看完了，虽然显著不如第二季但也还可以。<del>第三季什么时候放送，OVA
最终话这周日才更新，好漫长，好急好急好急好急好急</del></p>
<h1 id="月4日">5月4日</h1>
<p>今天是 Star Wars Day! May the 4th be with you（</p>
<p>今早迷迷糊糊醒过来的时候看到答疑坊单子多到堆起来了，看来大家五一已经玩得差不多开始赶作业了（</p>
<p>听《<a href="https://music.163.com/#/song?id=1399849876">不可解</a>》的时候突然觉得，中间有一段（01:55-02:10）把精力集中在伴奏上忽视人声，似乎会更好听（暴论</p>
<p>写了一天思政课论文，本来以为是放松的一天但体感是比学数学学不会还痛苦（，还以为能把故宫学的报告/习概的作业一起水掉的，然而精神损伤太严重了（，没来得及。明晚/后天再说吧。一天没拿笔手上的感觉都不一样了（</p>
<p>赛马娘第一季看完了，铃鹿的跑姿真的好漂亮啊（。突然感觉不如第二季的原因可能是帝皇（以及米浴，麦昆）原型的故事本来就太传奇了，重点很容易落到帝皇的自我突破上，关于米浴的两话我也非常喜欢，是但不完全是制作组的问题。所以相比之下第一季也有可取之处<del>（魔改铃鹿结局）</del>但还是无聊了一点，<del>怎么看都有一种主线是早恋小情侣被督促好好学习的既视感</del>。如果先看第一季再看第二季可能就不会有失望的感觉了，但是那样的话还会有耐心看第二季吗（。</p>
<p><del>第三季什么时候放送，好急，想看北黑和光钻，赛马娘四格风评没那么好但也看一下好了，OVA
最终话还有三天，我好急，我好爱看成田路掉小珍珠</del></p>
<p><del>和群友暴论的时候突然觉得，赛马娘本质上也是偶像番，甚至还有胜利舞台这个意义不明的形式上的爱抖露设定，我逐渐理解拉拉人（。还说如果竞赛那两年看到赛马娘大概会更喜欢，但实际上第二季
21 年才放送，还是早生了两年（。群友评价 ex
既是拉拉人又是爱马仕，他纯度真的好高（</del></p>
<h1 id="月5日">5月5日</h1>
<p>其实实分析直到今天我才退掉，我也不知道为什么要这样，多少是有点依依不舍了（，也真的很不甘心。</p>
<blockquote>
<p>Tomorrow I'll come back again</p>
<p>So wait for me please</p>
<p>Just wait for me please</p>
<p>——Mili《<a href="https://music.163.com/#/song?id=435005007">Meatball
Submarine</a>》</p>
</blockquote>
<p>为什么会想到这个呢（</p>
<p>出去玩了一天，逛了国博之后发现，我上学期学得最好的一门课其实是中国工艺美术史。什么抽代，Galois
理论已经整个忘记了，数值分析的几个章节都不记得叫什么了，然而今天在国博看展的时候还是精准识别了剔红剔犀螺钿金银平脱，以及甜白釉天青釉影青兔毫盏还有它们分别来自哪个窑厂，激动地拍了
114514
张照片给老姐云看展。我真绷不住了，实在不知道脑容量都用在了什么地方。</p>
<p><a href="https://chiyuru.github.io/about/">about</a>
更新了，欢迎一些找不同，奇迹般地开始绝赞恋爱中（（（</p>
<!--5.9 UPD：我今天才想起来这天其实是我爸生日，其实好像也不是他真正的生日，他说他生日是 4.12，就在我之前几天，只是出生后在村里报户口的时候记错了，身份证上是这样写的。我妈也是，她说她实际的生日是 12.9，但是身份证写的是 2.3，你鲁省的户籍管理制度实在令人担忧。当然 12.9 可能也不准确，外婆都不知道她的生日，说大概是这附近，只清楚地记得舅舅的。现在想来之前说自己几乎不回老家似乎是抛弃了故乡还是太仁慈了点，实际上我们早就被故乡抛弃了，我大概确实还是直接说自己是上海人比较好，这种外人看起来无比迷惑的事情真的是，太多太多了。-->
<!--又扯远了，原本是想等晚上回来心情不那么复杂（x）总之就是趁心情还好的时候给他发个祝福和红包，没想到被表白了（，心情更复杂了（？）然后就直接把这事忘了，直到今天才想起来。当然读者可以从“今天才想起来”看出来我和他的关系大概不怎么样，事实上也并不是非常不怎么样，这很难说，我自己的事情里很难说的有太多了，一般我都不说。今晚收拾好心情发出去之后他也暂时还没有回我，不知道他现在过得怎样，住在哪里，哪怕是在哪个省份我都不知道，还拮据吗，现在到底在做什么工作呢。这些问题也太奇怪了吧，但我也很难解释，还是不说了。-->
<h1 id="月6日">5月6日</h1>
<p>读了一天
KNNL，不知道学进去多少。总的来说非常的困，不知道是昨天太累了还没缓过来（肥宅出门并感）还是感冒还没好全还是没喝咖啡（</p>
<p>总之假期就这么结束了，Markov Chain
也没学，概率论也不会，大作业也没写完，到底在干什么呢.jpg</p>
<h1 id="月7日">5月7日</h1>
<p>早说今天的测量学是现场勘测的话我就穿条裤子（x）了啊，故地重游（x）六教后面的小树林在里面测高程，前天被蚊子咬了一腿，今天又被蚊子咬了一腿，绷不住了（</p>
<p>班里有奇数个人，两人一组测量，猜猜是谁没有队友一个人扛了所有的仪器（，体验是比体育课还累，回教室大睡一节课。想到暑假里测量实习要干一周这种破事，感觉这个破专业实在是待不下去了！</p>
<p>感觉还没结束假期的状态，有点摆烂。或者也可以说假期干的活都比今天多。可能是缺少贴贴（x）也可能单纯是被测量累麻了，不过还好也没什么要紧的
ddl 就是了。生统概论的期末 Pre
和两个大四的同学组了队，感觉非常的危，但是这课上好像大多数都是大四的，或许整体就是一个摆大烂的气氛，希望人没事。</p>
<p>回来的路上看到了新生数学基础大赛的海报，我感觉印象里这个东西往年是秋季举办，从去年开始移到春季之后就不再动了吗，怪事。</p>
<h1 id="月8日">5月8日</h1>
<p>中午骑车出门的时候突然在想能不能整个电动轮椅坐（，骑车也好累，正好遇上第二大节下课，想往食堂拐弯都拐不进去，最后多绕了一段路把车推过去的。电动轮椅的话会不会看起来威慑力强一点，会有人给让路呢（。不过突然从轮椅上站起来的话也挺吓人的吧，以及这玩意能和自行车一样锁起来停在路边吗（？</p>
<p>前几天还在急赛马娘 OVA
的最后一话，昨晚放送之后反而差点忘了看。好歌剧和成田路的线写得都不错，但我实在是没太看懂织姬到底是一个<del>马</del>人在发什么癫（，最后又怎么就突然就解开心结了，可能是不了解游戏原案的问题，不过整体还是挺好的。第三季，我的第三季，好急（</p>
<p>今天听 lzx 说实复概期末 6.10-6.12
连考三天，<del>想起来去年就有谣传说数学系有人三门连考心态爆炸 remake
了，</del>实在不是很懂他们教务在想啥，然后想起来我居然还有秦清的微信，草。概率论是
6.11，第 16 周周日，统辅课也都是 16
周随堂考，只剩一个测量学不知道安排在哪里。虽然这样的话 17,18
周基本没啥事了可以<del>幸灾乐祸着</del>看大家复习（，但第 16
周考三门数学，15
周写两个完整实验报告还是非常恐怖，大概要早点开始行动了。</p>
<p>答疑坊单子好多，感觉过一会微信就有新消息，但是不知道为什么今天就一个都没接，<del>可能不是在学就是在忙着贴贴</del>，津贴要寄了。不过也还是有一点就够用，问题不大。<!--以前看到情侣在教室里贴贴除了羡慕（x）之外倒也感觉稍微有点怪，自己恋爱之后才觉得能贴贴真好啊呜呜，我完全理解了，就是忍不住想贴嘛（x，怎么样才能一天贴贴 16 小时啊（不是（草好糟糕的发言啊--></p>
<h1 id="月9日">5月9日</h1>
<p>看到教务在院系群里说：</p>
<blockquote>
<p>个别专业的课表中出现课程因特殊情况导致授课时间冲突，请同学们提前关注并安排自身教学计划。</p>
<p>如课程冲突但两门课想都想修读，有以下办法：</p>
<p>...</p>
<p>2、找该课程的替代课程，办理课程替代（如数值分析除了数学系还有其他院系开设）；</p>
</blockquote>
<p>我想了半天难道是要用贵系 3 学分的数值分析替代数学系的 4
学分课吗，这不对劲吧。然后才意识到她说的“还有其他院系开设”指的是求真（，我超，这也太害人了，你院不会真有人信了她的鬼话去选求真数值分析吧（</p>
<p>体育课测了<del>鲤鱼打挺</del>仰卧起坐，之前一般都是在 45
个左右徘徊，很少能做上 50 个（50
个满分），<del>当然也有可能练习的时候都在摸鱼，没用上全力（黄金船行为</del>。加上做完仰卧起坐之后都腰疼得受不了，开学到现在课上的练习全被我咕掉了。本来是没抱什么期待，一上来就开始全速做了（<del>大逃，是无谋大逃</del>，想着中间要是做不动了就开摆，下次再测或者不满分也都行，然后做了
52 个（，属于是大成功了。感觉上限可能在 55 左右，剩 10
秒的时候其实就已经满分了，于是又<del>敷衍</del>做了两个就躺下装死了（，<del>我怎么总是在这种莫名其妙的事情上好强</del>（</p>
<p>下午回来在腰开始疼之前搓完了衣服，到教室就有点疼了，光速倒下睡觉（。这算什么，腰腹力量还可以但已经腰肌劳损了吗。明早也不知道还能不能顺利起床（，总之护腰已经拿上床了，希望人没事。往好处想的话至少下次不用再测了（</p>
<p>好！下周看我表演 50 米跑 9 秒 9！<del>那怎么办，就腿短啊</del></p>
<h1 id="月10日">5月10日</h1>
<p>我还以为我五一之前就把第 12
周的概率论作业写完了，今天定睛一看，上次布置的是这周的前半部分作业，看题量真以为是全周的了，很难绷得住。5.12
UPD：问题是，这都周五了还不布置另一部分作业吗，真的还有吗（</p>
<p>听说下次测量实验是四人一组，不知道这个班里的人数 mod 4 余 1 还是余
3，如果是余 1
的话那余下的必然是我，要扛别的组四个人扛的仪器了是吗（，太恐怖了（</p>
<p>最近在努力练习坚持每天对欧老师说“我喜欢你”，感觉是很有必要的尝试但确实是稍微有一点难（，感觉不是社恐而是怂，什么时候能很自然地说出来呢（这是可以写的吗（怎么不能呢x</p>
<h1 id="月11日">5月11日</h1>
<p>前阵子买了个披肩，本来是想用来搭一件没有袖子的裙子，后来发现它可以让所有的裙子都变好看，彻底离不开了。感觉可以算是今年（至少上半年）买得最成功的一样东西（</p>
<blockquote>
<!--今年求真是被禁止报名英华学者的-->
</blockquote>
<!--you know who，你真的好抽象-->
<!--讲道理最近好崩溃，当然我好像也没有什么不崩溃的时候（，退了多元统计和实分析，实在不知道之后的路往哪里走。学收敛定理学的也好崩溃，每一个做起来感觉困难的概率问题都像在狠狠给我一拳，催我赶紧爬回统计去。每个在线性回归课上理解不能的模型诊断问题也都狠狠给我一拳。每天就是搁这左挨一拳右挨一拳，实在是不知道应该怎么办，还能怎么办，没路走了呀。-->
<!--自己搁这破大防可能也没什么意义，先把期末熬过去，然后约几个老师聊聊天吧。-->
<!--写完这些话之后我去写了测量学的作业，更崩溃了，这种毫无意义的事情还要做很多，还有几十个学分这种莫名其妙的课，有意义的事情我却做不完，没补起来的基础也有那么那么多，真的很难不怀疑自己。~~说到底当年为什么不退学重新高考（？），又堆沉没成本了（（胡言乱语x~~-->
<!--算了，这种时候就想一想，挣扎到现在说不定就只是为了遇到欧老师，那也非常值得了（#每日羞耻play（草-->
<p>感觉没什么可写的，学啥的进度都非常缓慢，想想下个月的今天就概率论期末了，非常恐怖。</p>
<h1 id="月12日">5月12日</h1>
<p>半夜发现车钥匙好像落在车筐里了，下楼去找的时候想着就算把我车带着车钥匙一起偷了也无所谓，但是上面还有寝室门的钥匙和衣柜锁的钥匙，最重要的是我得开衣柜啊（。还好拿回来了。两点半下楼还看到楼下有情侣在贴贴，太辛苦了，respect（</p>
<p>早晨起来看到答疑坊小程序里有社友在提问，互相真名爆破了一手（，中午又正好在清芬遇到了，#每日脑内社聚成真。但我一眼并没有很确认是本人，感觉非常脸盲，换个发型就认不出人来。上次和社友见面的时候还没把头发扎起来<!--（指路 4.4 的日记，是在线性回归课上遇到了调课过来的蜂蜜和奶老师（。这么说来还是因为那次遇到了他才想到可以调课去看铃芽之旅，蜂蜜和奶老师真的助攻了好多次（x-->，这次居然能被认出来，好强（</p>
<p>天气好热<del>还没空调</del>，贴贴也好热（，晚上答疑坊<del>值班</del>写作业还有蚊子，绷不住了，<del>早知道穿条裤子</del>（<del>一直说要穿条裤子但又一直不穿的屑</del>。中间原因不明地离开了二十来分钟，回来发现来了好多人，<del>工时输麻了</del>，我的座位都被来答疑的人占掉了，草（</p>
<!--btw LagrangeKMnO4 今天穿的 T 恤上有“风驰雨骤”四个字，他就坐我对面，从我的视角看过去正好看到一个“驰雨”，吓得我（（-->
<h1 id="月13日">5月13日</h1>
<p>看到生统概论的分组名单了，我居然是唯一一个大二的，剩下都是零字班和九字班。那还不开摆？（</p>
<p>绷不住了，之前一直觉得自己太菜了甚至都不好意思写出来，今年报名了丘赛，概统和计算数学两场。今天下午出发去考概统的时候，到理科楼门口了其实都还在犹豫要不要走进去，还在想反正也不可能有成绩，弃赛<del>然后躲回去贴贴</del>又怎么样，<del>甚至有在想我又有什么资格，要以什么身份走进去这种中二问题</del>。磨蹭了一会之后戴上口罩进去了，明知道生活从来没有观众但总是不由自主地想别人会怎么看这样的事情，说真的连考场都有点不敢进的话输麻了也是非常正常的吧。</p>
<p>所以说，顺利走进 A112
并且完赛了，而且甚至还没爆零（，对我来说就已经赢麻了，剩下的事情明年再说。其实双面的卷子对我来说也约等于只有一面，前三道题说到底看都没看太久，也没什么想法，考完出来听说有题目需要用鞅论，有的是高级结论，确实都没学过。一上来觉得第四题可以做结果发现确实是按定义推就可以了，后面就一直在算最后的统计题，概率好寄，还好学过统计（</p>
<p><del>之前课上有同学问 lzx
今年想考概率丘赛的话要做哪些准备，他说除了上这门课之外自己再去学一下
Markov Chain 就够用了。他瞎说（，Markov Chain
没考，课上讲的也完全不够（（</del></p>
<p>监考老师（看着像数学系教务）还来改了一个<del>我完全没怎么看的</del>题，一上来把改第二题说成了改第五题，写在黑板上的公式还是
<span class="math inline">\(U_{-n}\)</span> 什么什么的，题目里是 <span class="math inline">\(U_n\)</span>
才对。我看了半天才明白，大概是组委会微信通知她的时候写的是
U_n，她误以为是 <span class="math inline">\(U_{-n}\)</span>
了，绷不住了（</p>
<p>前段时间想买本 Durrett
看，电子书不方便写写画画的话实在有点看不下去，似乎不再出版了也很难买到新书，干脆在某宝上找打印店印了一本。当时选的是需要装订还多花了两块钱，拿到手才意识到低估了把
400 多页 A4
纸装订在一起的重量，还是很难带出门，于是又手动拆掉了（。今天带了鞅论的一部分内容去教室看，感觉比
lzx
那几本教材不知道高到哪去了，真的新手友好，他甚至还有好多衔接初概的东西，<del>好温柔，我哭死</del>。</p>
<p>感觉这样也挺好的，把书拆掉之后每天带几页出去读，回来换一部分下次要读的内容，真的会有一种每天进步一点点的感觉（？）。想起来
Bowen L 之前和我说过的话：</p>
<blockquote>
<p>另外一件事是，在学数学的时候你真的能碰到非常非常非常多厉害的人，比你厉害无数倍的人，这可能会击碎你的信心，可这又有什么关系呢？做好自己就好了！进一寸有一寸的欢喜，能比昨天的自己多会一些东西我认为就已经非常不错了。如果真的是想学数学，那就是一辈子的事情，早学一些晚学一些也没有什么大不了的。</p>
</blockquote>
<p>太对了（<del>自我安慰.jpg</del></p>
<h1 id="月14日">5月14日</h1>
<p>今天走进理科楼的过程就比昨天顺利了很多（，虽然计算这一场有点坐牢了，卷子居然有三页纸。</p>
<p>学得还是太少了，PDE 数值解完全不懂，ODE
数值解本来应该是数值分析的内容，但是上学期课时紧张就没讲，真正知道是在干什么的就三道题，回忆起来也很费劲，写完不想继续坐牢就提前交卷了。总之是彻底完赛了，今年纯纯陪跑，当然再过两年应该也还是在<del>更多的赛道上</del>陪跑（</p>
<p>说起来，就算这样实际上也比主赛道概统做得多（悲）<del>干脆转计算好了（x</del></p>
<p>明年再考会怎么样呢。这么说来一年一次丘赛也挺好的，反正拿不了奖，就看看一年来到底进步了多少。然而我又比去年这时候的自己多学了多少东西呢，学了个<del>没啥用的</del>抽代，学了数值分析也忘得差不多了，实分析云了一些，统计入了门但是又有些纠结要不要就这样丢掉，概率水平大约介于（lzx
版本的）概率论 1 和概率论 2 之间，不知道能不能达到 wh 的概率论 1
水平，希望明年春天有机会去上求真的概率论 3（x</p>
<p>不管了，考完就好，该准备期末了捏（x</p>
<p>香槟开早了，概率论期末怎么后延了一周到 6.18
去了，测量学期末又是怎么会安排在 6.23 这种时间的，我 6.22 还要去打第三针
hpv 疫苗，很难说第二天会是什么身体状态，希望人没事。</p>
<h1 id="月15日">5月15日</h1>
<p>这两天读 Durrett
读得非常乐，<del>线性回归要寄了，大作业要寄了</del>，差不多是一天一小节的速度在读，概率论期末前有望读完（。并没有按照顺序看，先挑了一些课堂在讲的
topic 自救。Durrett 的体验比较好可能是因为习题没有 Kai Lai Chung
那么难吧（，内容倒是多一些，比如说终于搞明白随机变量和 Borel field
以及相互排列组合出来的独立关系究竟是怎么一回事了（，明明在最开头说清楚也就是几句话的事，lzx
那几本书里面只有科大的教材提到了这个内容，我不大爱看那本书，也没讲明白（（</p>
<p>唉我学得好慢。每天能学到新东西的确非常开心，但还是很为进度忧虑。<del>比别人开始得晚，天赋比别人差，学东西也更慢，基础还更拉胯，好破防（</del></p>
<p>好热，但是教室终于有空调了，贴贴体验大幅提升（</p>
<h1 id="月16日">5月16日</h1>
<p>感觉毽球也好别的也好，打直球效率确实是高啊。会打直球的话站在左半区就能把球发进左半区，站在右半区就能把球发进右半区，完全就不需要考虑换区但不换惯用脚会打歪的问题。但是也真的好难（#发球考试有感。不过还是不太一样的，毽球练多了有球感就能稳定直球不会歪了，别的事情我练都不敢练（</p>
<p>来点我最喜欢的环友发言环节：</p>
<blockquote>
<p>A：</p>
<p>为什么不考虑一下 z-lib（）</p>
<p>B：</p>
<p>纸质书比电子书爽x</p>
<p>C：</p>
<p>纸质书有质感 而且方便批注</p>
<p>有个神秘的好处是以后你要是想查个结论</p>
<p>你大概能记得这个结论在这本书“多厚”的位置</p>
<p>这个电子书做不到</p>
</blockquote>
<blockquote>
<p>D：</p>
<p>那天 E 告诉我国内教材有的把鞅翻译成马丁格尔</p>
<p>我人直接炸了</p>
<p>F：</p>
<p>和常凯申有的一拼</p>
<p>C：</p>
<p>一切都是从条件期望和鞅开始有意思的！</p>
</blockquote>
<p>下学期课表创烂了，应随和拓扑撞，拓扑和数分 3 撞，求真概率论 2
和统推撞（不知道数学系统推和统计中心统推差别多大，本来还想去摸一下的）还不知道能不能选上，这样的话只能再去选统计中心的高统了。统辅课倒总是很神奇，能做到和谁都不撞，然而我也不打算再上了。</p>
<p>事实上和我的专业课也完全创烂了，我选择暂时继续忘记自己不是数学系的。必修几乎没有一门是能上的，只能去水大四秋季的课，搞不懂为什么大四这些课全都是后八周，合着前八周先好好学数学，后八周每周突然多出来
5 个课时，真离谱。</p>
<p>女生也有台球课了，还有这种好事，感觉会很难选上（</p>
<!--今天翻相册又看到 Bowen L 当时在我抽代作业上的批语，我当时 Zariski Topology 的附加题写不出来，说感觉很酷但可惜我不懂，他在旁边批注说你迟早能看清这些美丽的数学的，我相信你。这大概也算是我下学期宁可放掉数分 3 也真的很想去把拓扑上完的理由之一吧，很多时候回想起来会真的很感谢他。-->
<p>大概从这里开始也就要确定延毕了，这样下去显然是不能按时走人的。虽然我每天都一副很乐的样子但其实是相当迷茫的（。<!--今天闲来无事（真的闲吗）打开朋友圈看了一眼，其实是看到了 LagrangeKMnO4 的转系心路发在了闻刀日肥上，突然想打开朋友圈看看认识的转系的同学都是什么情况。翻了翻发现最近班级同学不是在吐槽数理方程作业太难，就是在说基物期中太晚没来得及退课，还有人在北大强基的高中同学降转成功了。一下子觉得真的好遥远，感觉自己存在感好低，不是通行的那个意思，其实我想说的是，我好像不存在在这个世界上。我到底在做什么呢，我做的事情真的对吗。不是说转数学这个决定对不对，毋须怀疑已经是我的最优解了，然而又是上课上不动被迫退课，又是突发延毕，我不过是在按照自己的理解跌跌撞撞地爬着学数学吧，这真的没问题吗。读 Durrett 是很乐，也似乎学到了很多，但分析基础什么水平我自己心里有数，不习惯用的记号有那么那么多，这学期答疑坊微积分 A2 的题目都经常算不动，是吧。--></p>
<h1 id="月17日">5月17日</h1>
<p>这个月的日记明显没意思。往前翻了一下发现，不是在因为数学学不会或者肉身不在数学系而破防，就是在贴贴，贴贴的细节也不能细说（bushi，要么就是在摆烂。</p>
<p>测量实验做麻了，下午下着大雨搁那儿在室外测角，两个人扛别的组四个人扛的仪器又做了四个人的活，运动量堪比一小节体育课。上次全班还是奇数个人，这次变成
mod 4 余 2 了，怪事，不过总比一个人要好（叹气</p>
<p>又一次被概率论助教给的作业分气晕，不想批作业可以不批，我这几周扣掉的作业分都快要在总成绩上面明显地显示出来了。本来今天想把最近在讲的收敛定理看一看的，气得我往后推<del>马丁格尔</del>鞅论去了，这周作业明明好多但完全不想写，<del>迟交算了，迟交都比正常交的分数高（</del></p>
<!--在评教里评价助教的时候说了很多（。课咨委之前一直在考虑怎么改评教才能让大家认真评，事实上我感觉只有遇到非常好/非常差的体验才会认真夸/骂，怎么改都没用（-->
<!--虽然也不能要求每个助教都像 Bowen L 一样 supportive（，但是这样我也实在有点难以接受。算了往好处想，我上的第一门数学系专业课遇到的助教是 Bowen L，已经是莫大的幸运了。不过他比较 supportive 的原因或许是 hx 那个课上的人实在太少了吧（，大概也不是，感觉他性格就很好，期中考试的时候还给每个人发了巧克力（-->
<!--说起来数学系的博士生应该是每学期都要做助教才对，不知道毕业之前还会不会再遇到他。但他是代数方向的，我大概也不会再修什么代数的课了，有点难呢。-->
<!--说到底为什么要为了一两次的作业成绩这么破防，上次拿作业的时候明明看到 8.5 的有一大摞，可能整体给分就很不行。我感觉可能还是转数人的原因总之我格外地需要很多的正反馈，大到数学课绩点如何（这大吗），小到每一次作业的成绩怎么样，然而在这门课上几乎从来都没有过，而且我还想主修概率的。-->
<p>果然今天也是在不停地破大防（</p>
<h1 id="月18日">5月18日</h1>
<p>今天体验了：因为痛经没胃口不想去吃饭 <span class="math inline">\(\to\)</span> 不吃饭就不能空腹吃药 <span class="math inline">\(\to\)</span> 不吃药就会继续痛 <span class="math inline">\(\to\)</span> 太痛了不想去吃饭（</p>
<p>待会还会体验：上午太难受了睡了两个多小时 <span class="math inline">\(\to\)</span> 晚上睡不着了 <span class="math inline">\(\to\)</span>
明天要早（？）起，睡眠不足可能还会更难受（</p>
<p>UPD：早起倒是没事，结果中午淋了点雨又疼了好久，绷不住了，怎么这么菜（。<!--站在西阶门口等雨停，甚至开始思考这个午饭还吃不吃的时候突然想起来，我初三下学期到高二上学期的两年时间里还真是从来不吃午饭。高中的前一年半是只吃晚饭，中午吃早晨剩下的面包。初三的那半年倒也不只是不吃午饭，是瘫在家里哪一顿都不怎么吃（。不过真·ex 出现之后还是让我高中的后一年半每天都吃上了三餐的，从那之后整个人大概也变得正常点了，甚至后来每顿饭还能蹭到他的拌饭酱吃，还不错，乐（--></p>
<!--这就是之前从来没提过的另一个故事了，不说了（-->
<p>感觉好几天没学数学了，实际上今天才看了 survival analysis，昨天才学了
martingale，咋回事呢。大概是因为还在咕咕收敛定理吧（</p>
<p>做实验发现溴钨灯还挺好看的。</p>
<p>怎么没头没尾的（（</p>
<h1 id="月19日">5月19日</h1>
<p>早晨习概快下课了才发现坐在我旁边的是一个高中同学，他旁边还有我另一个高中同学，都是当时的同班同学。如果不是我瞟到他校园卡上的名字的话都没认出来，当然也没打招呼，估计他们也不认识我了，乐（</p>
<p>今早在盒马订了一束玫瑰，修了叶子和根插进水里醒花之后才出门上课，晚上回来看到花瓣都展开了。本来是想今天拿来处理好之后明天去送给欧老师，但是我好急（，晚上一个冲动就端过去（？）送掉了。反正离
5.20
也不差几个小时了，鲜花这种东西不是越早拿到越好吗（x<del>（希望室友没事，骑车过去的路上感觉回头率也好高（</del></p>
<p><img src="https://s2.loli.net/2023/05/19/Xf1mAgi4dQjaLYB.jpg" alt="rose.jpg"></p>
<p>想起来中学的时候写的两句话：</p>
<blockquote>
<p>我哪一刻不是含苞待放</p>
<p><del>（这个大概是在被 ex 各种欺负和无视的时候自暴自弃说的（</del></p>
<p>我小时候也会期待窗纱外小鹿衔枝花送给我，长大后能不能学会剪窗花赠与人</p>
<p><del>（当时说的剪窗花不是剪纸的意思，大概想表达的是剪窗边的花（</del></p>
</blockquote>
<p>其实从上周末就在想这件事情，送之前还担心了好久会不会被当成不是很实用的礼物或者不会被喜欢什么的，怂到还提前写了封信说了一堆车轱辘话，送完差点拔腿就跑（。<del>我对于送礼物之类的事情是很怂很怂的，还是以前被
ex PUA
得太严重了。当时断断续续给他用心准备过不少礼物，他要么装死不回应，要么是批评我礼物不实用/太女孩子气了/或者别的什么理由总之说我不好，感觉就是故意欺负人罢了。现在真的很难想象当时怎么还能越挫越勇（，纠缠了一年多。总以为再真诚一点就会好了，但这种人果然是改变不了的，还好我当初也没在他身上浪费过鲜花就是了，太屑了（怎么又骂了这么长一段</del></p>
<p>谢谢室友从早晨看到我处理花开始一直帮忙保守秘密到现在，为了这点惊喜/仪式感（？）大概也憋坏了，辛苦了（</p>
<!--实际上我留了三枝在寝室里，今天回来看感觉比昨天状态还好。是否可以做个生存分析（-->
<h1 id="月20日">5月20日</h1>
<p>前天给数理方程的老师发了封邮件，问能不能用数学系的 ODE + PDE
替代这门课。实际上 ODE + PDE 都 8 学分了，数理方程才 3
学分，想不出来有什么理由拒绝（，但是被已读不回了，悲。<!--~~不会忘了吧，这么逆天的替代方案应该很少见才对，不应该印象深刻吗（~~--></p>
<p>中厅装修之后我其实体感变好了很多，虽然室友都觉得越改越烂。改造之前没有储物空间，大家都把大件的东西堆在地上，出于洁癖
/
不想和别人把东西堆在一起我从来没在中厅放过东西，前两天清空的时候就也没我的事，很乐。现在装了新柜子之后我倒也打算把不用的东西放到柜子里了，但是柜子是细长的构造，室友的大件收纳箱放不进去。<del>另外之前中厅还有个大桌子，动不动有人把同学拉进来团建，现在没桌子也没有能给好几个人站或者坐的空间了估计也能安静很多（，</del>总之我是觉得改了比不改好，虽然大家都不这么觉得（（</p>
<blockquote>
<p>别在这意难平了 该冲选就毫不犹豫冲选</p>
</blockquote>
<p>好几天没看环里的聊天记录了，往前翻看到一句这个，学到许多。</p>
<!--今天看到社友在讨论《春江花月夜》，想起来很多事情。这是我家还在嘉兴的时候我妈教我背的倒数第二首长诗，当时她教我说这首诗的上下句之间有很多重合的字词，这个叫互文，找规律会比较好背。长大一些之后我才知道其实是顶真，等我长大时她也对诗文不再感兴趣了，一直也没有告诉她。在嘉兴背的最后一首诗是《琵琶行》，截成 6 段，每两天背一段，最难的是有“呕哑嘲哳难为听”的那一段，这几个字就有一种明明都认识（也不是都认识）但是读出来好难的感觉。来到上海之后她开始教我背《长恨歌》，然而我还没背完父母就开始折腾离异的事情，过了一年多母亲重病一场，此后她再也没教过我什么了，最终我也没有背完《长恨歌》。童年大约到《琵琶行》就结束了，此后的人生都是凛冽的冬，一年三百六十日，风刀霜剑严相逼，那时的自己是不会知道的。-->
<!--我后来突然明白不存在什么平稳的童年的，现在觉得平稳是因为没有记忆，是因为风刀霜剑都有人替我挡下来了。不是一出生就因为性别被厌弃了吗？既然根本不存在，那也就不用再想了。-->
<!--注释和正文画风差别好大（-->
<!--光搁这破防去了，该写的没写完（-->
<p>热导实验是这学期速通得最快的一个，一个半小时就做完了，每隔一分钟测一次电压好麻烦，试了试一边看泡面番（马娘摇曳）一边做，手忙脚乱（。还有二十分钟在帮旁边<del>不认识</del>的同班同学改电路。想在别人搭的电路上找问题也太难了，还不如把线全拔了重新搭，<del>虽然好像有那么点伤人（</del></p>
<p>这辈子还剩下两个基物实验，还都要写报告，急了。</p>
<p>最近在戒断咖啡，果然还是不行，每天都好困，明天开始还得喝。</p>
<h1 id="月21日">5月21日</h1>
<p>表面波澜不惊，实际非常慌。如果不是群友在课程群里提问我都不知道故宫学的报告是第
16 周现场交，还以为可以考试周摸掉；16
周要考两门统辅期末，线性回归我还一片混沌，要把之前的录屏补一补；大作业进度缓慢，有一个
15 周要做 pre，17
周要交另一个；概率论这周作业到现在没写完，今天压根没写，看了一天 Durrett
倒是学到很多，说实话 lzx 讲得其实比 Durrett
简单太多了啊，实在不想没学透就嗯做，大概要迟交一次了，怎么会这样（说到底还是这周身体各种不舒服的原因罢（<del>（也不好说，今晚说不定通个宵就做完了（</del></p>
<p>其实我来华子到现在还从来没有迟交过作业，甚至连踩着 ddl
交作业都没有过，<del>想想还挺强的</del>。这个学期纯纯是被两门基物实验和两门上到后来痛苦不堪的统辅课给毁了（</p>
<p>晚上在三教出门接水，遇到一个穿着书院院衫值日的同学，看了我好几眼还尝试挥手和我打招呼，虽然摸不着头脑但还是尴尬地微笑点头.jpg
回应了一下。<del>虽然摸不着头脑但我还自恋了一会美女果然是有魅力（不是</del>，后来在教室里又遇到才发现他穿的是
EFZ 的校裤（左侧口袋的地方有一个 EFZ
的标志），看颜色是二字班。看来是单向认识我，<del>可能还以为我也认识他</del>，说不定甚至是微信好友但我完全不认识（。<del>我说你们这一届怎么就这么爱穿这个校服，认识我的人还这么多，比同班同学认识我的都多（</del></p>
<p>偶然发现了个<a href="https://www.hsefz.icu/">这个</a>，好怪，才发现高中的校园邮箱到现在都还保留着，在里面找到了很多当时化学老师发的试卷答案，全都是未读，<del>难怪化学拖我后腿没进新雅现在搁这受罪呢</del>（</p>
<h1 id="月22日">5月22日</h1>
<p>这学期第一次通宵，写概率论作业写到了早晨七点半（，然后睡到了下午一点。实际上原来没想这样的，但是在床上翻来覆去到两点半一直睡不着，还是下来写完了。本来想着迟交也无所谓的，不迟交甚至可能分数还更低（，通宵写完的作业再拿个
8.5
的话也太抽象了吧，但还是睡不着。是因为最近一直就很焦虑经常很难过吗，感觉这个状态还没到期末周就要把自己送进北医三院/六院（<!--想了想应该主要还是三院吧，这点程度已经不至于把我送进六院了（（（--></p>
<p>这才知道四点半天就已经变成蓝色了，五点多就完全天亮了，是夏天了。感觉也多亏了桌上还有三枝玫瑰在陪我，虽然稍微有点蔫了，鲜切花的花期真的好短暂。下午出门上课感觉整个人都很虚浮（，不是在走路，而是在飘（</p>
<p>队友感染新冠了，晚上在教学楼楼道里开腾讯会议讨论大作业，听到对面教室里值日的两个人在暴论：</p>
<blockquote>
<p>A：你知道 lzx 概率论今天刚交的这份作业多少个题吗，38 个</p>
<p>（但是我上次数的时候是 31
个，刚刚数了一下发现他是把上面标出来要习题课讲的题重复计数了（</p>
<p>B：你知道 wxq 今天布置了几道题吗？三道题</p>
<p>A：卧槽你知道吗我上周就一直在写概率论，连抄带做写了一个星期，别的作业几乎没看</p>
<p>B：叫你不选 wxq 吧哈哈哈哈哈哈哈</p>
<p>A：但我们期末考透题</p>
<p>B：爬</p>
</blockquote>
<p>刚通宵写了这玩意的本人也绷不住了（</p>
<!--看到丘赛出获奖/总决赛名单了，我到底为什么还去看了名单，是抱有什么期待吗（。认出来好几个以前就认识的你沪 MOer，还有认识的书院转数人进决赛的，羡慕，呜呜，明年再来（-->
<!--仔细看了下 fym 分析和概统都是第一，太猛了（-->
<p>今天突然在想暑假回家要不要去学车，总觉得有可以使用载具的技能的话会很有安全感（，虽然自行车和公共交通基本暂时能满足在城市里生活的需要了。大家好像大多都是高考完的暑假考的驾照，当时本来也想去学，但是忙着家教攒钱去了。去年暑假也稍微干了点活，另外天气太热了，大多数时间还是在家摆烂，也没去学。今年应该不会再做了，一来在学校每个月都有答疑坊的补贴拿，前两年也攒得差不多了，二来高中那些东西我也实在是看着就想吐，不想再浪费生命了（<del>其实是也已经不会了</del></p>
<p>当然现在突然想这件事也未必会去做，行动力实在是不行（</p>
<p>理了下中厅的柜子，把暂时不看/已经学完了的数学书塞进去了，附带屯的两盒咖啡，这个格局看起来也太幸福了，我也想钻进去。如果都读完了大概更幸福罢（</p>
<p><img src="https://s2.loli.net/2023/05/22/xGwAUcdr7YXVmJn.jpg" alt="math_books.jpg"></p>
<p>看着好不整齐啊（，昨天怎么忍住没重新按高度/大小排一下的（</p>
<p>北大出版社的那几本都是从 runzhi
那里通过隔壁数院的共享计划嫖来的，之后他还要嫖回去（。Stein
的两本分析是女生节预算 200
自选礼物的时候我选的，还被吐槽了（，其实当时一共买了四本，Munkres
的拓扑和 M.Ross
现在都放在床上当睡前读物（但也好久没读了，我沾床就睡（。想学的东西还有好多但是我啃书真的好慢
qwq</p>
<h1 id="月23日">5月23日</h1>
<!--和家人联系，之前一直以为我已经原谅了，原谅是因为还是非常感恩在幼小的时候没有遭到抛弃，知道她也为了我吃了很多苦，但其实也是因为如果不原谅就实在不知道要怎么继续生活下去。以为已经原谅了，然而真的遇到事情感觉自己还是有点冷漠，怎么办才好呢。-->
<!--想这些事情发呆的时候突然想起来，生日的时候蜂蜜和奶老师送给我过一份礼物，在里面附了一些圣经的摘抄，翻出来读了一下，还是平静了一点。那天他还给我私信留言说：-->
<blockquote>
<!--早上有些忙忘记说了，便利贴后面有一段我特别喜欢的圣经，“凡事包容，凡事相信，凡事盼望，凡事忍耐”也一直是我的微信签名。希望能在你需要的时候给你一些帮助。-->
</blockquote>
<!--“希望能在你需要的时候给你一些帮助”，是有这种力量的，总之非常感谢。~~以后去信个教算了（不是~~-->
<!--在写什么东西（-->
<p>两天加起来睡了十个小时，体育课毽球比赛还打得有来有回，终结了对面的三连胜（<del>米浴：不中嘞</del>（。截止现在我们赢过第一名，也输过最后一名，是否说明
<span class="math inline">\(\lim \sup \leq \lim
\inf\)</span>，每个队水平都差不多输赢全看运气（，实在有点抽象。<del>赢了是好事，就算输了反正我们队名是北京大学毽球队，丢的也是隔壁的脸（</del></p>
<p>毽球好好玩，不那么消耗体力也不直接对抗的竞技还挺有意思的，下个学期有点想再来<del>薄纱大家（不太可能，但是运气好的话可以趁大家没学会抢到前几场比赛的胜利）</del>了，选不上台球课的话就来（</p>
<blockquote>
<p>我：（困倦地打出一个发球）（得分）（打算捡回来发下一个）</p>
<p>队友：（开始欢呼）</p>
<p>我：（疑惑）<del>（她们在鬼叫什么）</del></p>
<p>裁判：比赛结束</p>
<p>我：啊原来规则是这样的，刚刚那个是决胜球啊（还好不知道，知道的话大概就紧张失误了（</p>
<p><del>队友赛后补充视角：驰雨老师沉着冷静从容满脸写着一定会赢的骄傲（应该是太困了所以面无表情）地在比分几度追平的情况下稳稳打出了一记直球，太帅了捏（草</del></p>
</blockquote>
<p>无线耳机还是好文明，可以一边听<a href="https://music.163.com/#/song?id=1981787077">马儿跳</a>一边打比赛，或许也是一种
buff（？）。<del>下学期要不要买件帝皇的痛衣穿着跑最后一次 1500
呢（</del></p>
<p><del>刚刚在想跑 1500
似乎应该买件麦昆的痛衣才合适，毕竟是长距离。不过好像对我来说是超长距（，但对赛马来说只能算是中距离，那还得是帝皇啊（。不管了，买一件帝皇和麦昆贴贴的好了！（草</del></p>
<p>线性回归改成大作业和考试二选一了，那我必选考试，这数据分析是一秒钟也不想再做了（</p>
<h1 id="月24日">5月24日</h1>
<p><img src="https://s2.loli.net/2023/05/24/hbEU2QdJupHX4Dv.png" alt="questionnaire.png"></p>
<p>既然你诚心诚意地发问了，那我就大发慈悲地告诉你.jpg</p>
<p>填了这么一串还真不是单纯在发泄情绪，每一个“非常不同意”都是我的真实情况，就很草。<del>不过把书院骂一顿还能领
15 块钱也太爽了吧（x</del></p>
<p>最近三天的平均入睡时间大概是早晨五点半，日均睡不到五个半小时，还次次都是自然醒。我感觉我每天都是在飘而不是在走路（，下午甚至还把装着全副身家性命（拆开的
Durrett，没写完的概率论作业，物理实验讲义和表格，乱涂乱画但是写着有用的东西的草稿纸）的文件袋落在了测量学的教室里，平常都不太会落东西的，还开始冒痘了，好崩溃（</p>
<p>还没到月底，结果随手查了下账发现严重超支，草。本来最后四周想摆烂不干答疑坊了，今晚还是紧急做了几道微积分和高代（</p>
<h1 id="月25日">5月25日</h1>
<p>（夜间）睡眠不到 6 小时的第四天，犯蠢次数显著增加（</p>
<p>《室友的暧昧对象把下次的实验报告发给她之后》<!--~~这个剧情是否在哪见过~~--></p>
<p><img src="https://s2.loli.net/2023/05/26/lVmxsF4wIPy6CW3.jpg" alt="cross-validation.jpg"></p>
<p>结果她的“很多份”就是三份而已，怎么这样，连 5-fold cross validation
都做不了（</p>
<h1 id="月26日">5月26日</h1>
<p>本来还想看看夏季学期有什么课可以上，去年印象里致理有一堆什么基础学科交叉课程，查了一下今年数学就只有左怀青，我又不做代数，不想花三周时间学他那玩意了。逻辑学专题不知道今年的两个主题会是什么，虽然挺有意思的但反正和军训撞了也选不了，说到底同一课序号的课也不能选两遍吧（。去年上的时候虽然好玩，但其实选了个偏
CS
的专题甚至连离散基础都没有，写作业就好痛苦（，选的时候没细看还以为会比较数理逻辑的，<del>结果当时欧老师说也要选我才仔细一看发现不是那么回事但这下也跑不掉了（什么，中途好几次绷不住想退掉跑路但是一想到欧老师在上就也还是努力绷住了，喜提了个
A 但实际上还是被薄纱了（（好久远的赛博单向贴贴（</del></p>
<p>然后想了想怎么到现在<del>一把年纪了</del>还是天天想着用上课解决问题，虽然数学壬基础学习时长确实长一点，但是不能就一直这个思路下去了啊。期末考完直接去找老师进入一个磕盐入门的节奏，暑假里<del>一边贴贴一边</del>读书就好了，老惦记华子那些个上得那么烂的课干什么啊（</p>
<p>学 LLN
学得有点崩溃，不过好歹是把作业写完了，昨晚看错一个题白痛苦了一个小时，<del>还是得多睡觉</del>。我感觉
lzx 的作业对我学概率稍微有点反作用，不写完作业就也没心思去读
Durrett，但也只有读 Durrett 学习效果最好。学得还不咋地就在这里硬写 Kai
Lai Chung 的习题，只能说多谢 MSE 的帮助了。</p>
<p>之前环友说本科不在数学系也能学得好数学的，那也确实，这玩意是不怎么吃资源。但是我现在觉得人不在数学系，学数学需要的专注就很难有，动不动这里插进来一个物理实验然后写一天报告，那里一个测量实验扛一堆仪器累到下午睡一觉，更离谱的是这学期还被统辅带进了沟里，那个线性回归学到最后我都不知道是在干什么了，你校统辅改名数据科学辅修算了（暴论），实在是和数学没啥关系（</p>
<p>下学期乱七八糟的 2
学分专业课好多，稍微选了一点，多少有点担心五年也毕不了业。数学课也不少，我还在想要不要冲选应随，冲选的话连见老师一面的机会都没有（xs，看暑假里学的情况好了。期中后退课还没有了，希望人没事（</p>
<p>虽然马上就要离开了，但还是要感谢统辅的，再次想起转数学这件事情也还是在知道了统辅项目之后决定试试看，不然我现在还搁那儿不知道干嘛呢。<del>另外，之前一直没说过不想做代数但是大二上学期突发恶疾选了个抽代的理由，其实不仅是因为抽代不需要什么前置，选一下属于是在试探能不能转数，也是想着可不可以就像暑假上逻辑学专题一样能遇到欧老师呢（，遇不到的话有点共同话题也不错。虽然也没选到
zmx
的课，结果上来看是没遇到的，后来有课余量了也没折腾手选第二次换过去。从那之后在课上认识了新的转数的朋友，慢慢地爬回数学，都是很好的事情捏（好久远的单向贴贴（二度</del></p>
<p><del>之前有私下里说过，其实刚认识的时候也是有点被欧老师的强度和热情打击到（）所以不想转码了，当然这些选择都有很多很多理由，转数的最大理由当然是因为喜欢，但是突发恶疾选抽代也是个很不错的契机。突然就想起来《勾指起誓》里那一句，“你是分割我人生的线，又将它们相连”，还挺合适的呢。</del></p>
<p><del>怎么唐突发糖（这是糖吗，这纯纯是羞耻 play 罢！</del></p>
<h1 id="月27日">5月27日</h1>
<p>今天在答疑坊居然接到了一个非常基础的群论问题，来问的同学说是他的离散数学作业，越发好奇离散
2 到底是在干什么。自闭写实验报告的时候听到旁边两个答疑 CS
类的志愿者在讨论 Borel-Cantelli lemma
和一些在概率问题里的应用，太恐怖了。<!--突然想起来这学期第一节概率论课的时候，TA 突然给我发微信，说他正在读陶哲轩的一篇博客，问了我一些大数定律的问题，于是那节课我一边和基物实验 2 的负责老师交涉和故宫学冲突了能不能换时间，一边用所剩无几的初概记忆磕磕绊绊地回复 TA，好忙，从第一节课开始就完全没有在听 lzx 讲课（-->今晚用的插座也不是很行，双孔插座需要把插头翘起来一个角度才能充上电，调了半天直接把无线耳机的耳机仓塞在了两个插头中间，效果很好，又找到了一个无线耳机优于有线耳机的场景（（</p>
<p><img src="https://s2.loli.net/2023/05/27/q2IUnPuN7DhCz1V.jpg" alt="mysterious-socket.jpg"></p>
<p>下雨明明室外很凉快，教学楼走廊里也很凉快，怎么教室里这么热，好像还就我觉得热（，甚至不是很敢去开空调，绷不住了。<del>搁以前我就拎包跑路去找舒服的教室了，反正我也不用插座，坐哪都一样（x。</del>答疑坊也很凉快，怎么会事（</p>
<p>又一整天没有握笔，基物实验报告是怎样毁掉我的人生的.jpg（，虽然已经摆烂不用
R
画图了但值班结束都差点没写完，真绷不住了。<!--实际上偏振实验我拿到了六份往年报告，真的用其中的两份 train 了自己的实验报告然后用剩下的做了 test，虽然并不标准但也算是 cross validation（毕竟 train 用的数据比 test 还多）。结果它们互相之间连基本的结论都有矛盾，把我整的越发迷惑，绷不住了，cross validation 是怎样毁掉我的人生的.jpg（不--></p>
<p>跟室友当了一回 bcl
单推人，这两天还有人在各种群里问数值分析的我也都激推了，<del>说到底未央为什么会要求上这个</del>，听说他被选爆了，感觉至少也有我一份功劳。然而我上这门课的时候几乎没去过早八，晚课会去听但也一般就是自己看
PPT
和教材，现在反而开始激推了，怎么回事，<del>是不是失去了才懂得珍惜（</del></p>
<!--还在群里看到有未央的同学问微分几何相比数值分析怎么样，因为也是数理课组里的，感觉这门课上未央的人会少一点，选微分几何的话就会不那么卷。我的评价是别太荒谬了啊（，未央物理是很强~~因为落榜物竞生多~~，院内的课是也都很卷，但怎么会有自信能在数学课上卷过数学系的，或者说，怎么会觉得数学专业课的主要困难是卷不过自己人的呢（-->
<p>和认识八年的朋友（我姐）之间的对话抽象水平：</p>
<p><img src="https://s2.loli.net/2023/05/27/N2AH35zSx9qGbnt.jpg" alt="gossip.jpg"></p>
<h1 id="月28日">5月28日</h1>
<blockquote>
<p>室友：有点纠结这几门课选哪个</p>
<p>我：姐姐选我（突发恶疾</p>
<p>室友：你不在我的培养方案里</p>
<p>我：但你有我的优先志愿</p>
</blockquote>
<p>开完理发店突然在想真的有不在培养方案里但是有优先志愿的情况吗，还真有，所有的统辅课都对工工的同学开放优先志愿<del>（但是未央工工没有优先志愿（#每日乳未央</del>，但是不在培养方案里（</p>
<p>这学期的必修课就选了两门，大四上学期的必修课也不知道现在没有必修志愿到底能不能选上，求真概率论
2
和统计中心高等数理统计都要等下学期手选，非常急不知道万一选满了（虽然目前来看不会）又不扩容怎么办，五年真能毕业吗？我到底在干什么呢。</p>
<p>一旦开始思考“我到底在干什么”这种问题就说明该去码头整点薯条了，于是今天整了点精神薯条——久违地读了一天（半天）Durrett
的 LLN
部分，非常的爽。上次觉得自己还是该继续补补数分的时候就在想，不会到了明年这时候我还在因为数分没学过分析太烂而破防吧，不会后年还这样吧，我这辈子不会就永远这样了吧！现在觉得除去为了之后上
ODE 和 PDE 需要系统地拯救一下岌岌可危的多元微积分或者说数分
2，还有实分析最好重学一下级数、函数列以及要刷一下周民强之外，其他东西遇到了就现学甚至参考
<em>Young man, in mathematics you don't understand things. You just get
used to them.</em> 通过学高阶来补基础也不是不行！</p>
<p>下次如果能一边吃实物薯条一边啃精神薯条应该会更爽（什</p>
<p>零字班的环友还有下学期也要选概率论 2
的，害怕，不知道是会被吊打，还是大家都会开摆保护低年级同学的绩点（bushi。没选过不知道求真课劲有多大，这甚至主要还是门研究生课，感觉绩点很危。另外听说
PIN
的抽代选爆了，甚至还有贵系人慕名而来，乐死我了。现在抽代没有选课限制了，羡慕，不过拓扑和
ODE
也都没有，现在来看也都能任选三志愿正常选上，倒是省了不少心，<del>终于不婆罗门了</del></p>
<blockquote>
<p>我觉得 pin 讲的应该是具体代数</p>
<p>而不是抽象代数</p>
<p>实际上这个名字很不好</p>
<p>我感觉抽象代数不应该叫抽象代数（bushi</p>
</blockquote>
<!--写完日记去洗澡，在浴室里听到两个人在谈论其中一个的单恋小故事，努力记住了一些对话的大意，笑死了（感觉放出来不是很好，万一开盒了，还是记在注释里好了-->
<blockquote>
<!--A: 唉我跟你说，我最近有点想放弃（追喜欢的人）了-->
<!--B: 怎么了，我给你话疗一下-->
<!--A: 就是我约他周六一起出去玩的，结果他周六早上突然就生病不能去了，下午突然又好了，就没有去成，我突然感觉就不是很有缘分，怎么办呢-->
<!--而且我们约的是去雍和宫，感觉更不妙了，虽然他没去但我还是和室友一起去了的-->
<!--B: 你确定不是他找理由不去的吗-->
<!--A: 他才不是那种人呢呜呜呜-->
<!--话说到底怎么判断对方喜不喜欢自己啊-->
<!--B: 我觉得你可以试试看最近先不要那么主动，以退为进，看他会不会追上来-->
<!--（什么恋爱带师，好强（（-->
<!--A: 那他要是也不主动怎么办啊，我觉得他就是那种木头，不行，就算我不和他恋爱我也得在相处的过程里努力教会他怎么对待女孩子，这样下去是不行的！-->
<!--B: 放下助人情结尊重他人命运（-->
<!--A: 说起来我真的好想谈恋爱啊现在，想了想如果和那种很会谈的人谈恋爱的话体验也会很好的吧-->
<!--B: 那种一般都是海王诶-->
<!--A: 海不海的没关系啦，我就是想体验恋爱嘛，会照顾人的海王相处一下试试不也挺好的，不是比他强多了-->
<!--（刚刚还以为是纯爱战士来着.jpg-->
<!--B: 你让我想起来我一个海王同学，找的 npy 也是海王，结果俩人在一起一周没官宣，都在各自处理之前的遗留问题，非常的默契-->
<!--A: 笑死了那不也挺好的，海王和海王锁死-->
</blockquote>
<!--在没有隔间的浴室里说这个真不拿我当外人啊！全程想笑又不敢笑，最大的感受是我确实已经过期 jk 了，根本不可能和人谈论这些，哪怕是之前感觉在单向（虽然实际是双向）喜欢欧老师的时候也完全没有这么多心理活动（-->
<!--想听后续，不知道有没有机会了（有机不会（什-->
<h1 id="月29日">5月29日</h1>
<p>熬夜在一边看<del>卫宫巨侠一穿六</del>雪下的誓言<del>（这年头怎么还有人看
fate 系列啊）</del>一边写线性回归，要中二还得看
fate，我还挺期待七月的<del>命运/好怪 很假</del> Fate/strange Fake
-Whispers of Dawn-
的。四点半合上电脑去洗衣服然后洗漱睡觉，发现天已经大亮了，不是我睡得晚，是天亮得太早了（</p>
<p>躺下想起来高三的时候有一次精神状态堪忧，通宵看完了《太阳照常升起》（指的是姜文那部电影，不是海明威的书x），大受震撼，睡觉的时候也是正好天亮了。后来高考前最后一次心理课似乎是带着大家一起喊楼什么的，就想起来片尾的情节，于是在喊高考加油之类的话的大家中间就我在搁那复刻“阿廖沙，别害怕，火车在上面停下了，他一笑天就亮了”，现在想想好中二好社死（，还好也没人注意我在干什么<!--除了那一位以为我生日是 4.15 的高中同学（，上次他还提到这件事了用来例证说觉得我挺有意思一个人，草，那当然了（-->。那大概也是我这几年来说话声音最大的一次了，到现在还记得当时刚张开嘴想发声音的时候嗓子里黏糊糊的感觉，声音很哑，声带振动不起来，才意识到在学校已经好多好多天都没有说过话了。</p>
<p>今天吃饭的时候读到了<a href="https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&amp;__biz=MjM5MTMzOTg4Mw==&amp;scene=1&amp;album_id=2280665283558293508&amp;count=3#wechat_redirect">一些上海文学</a>，一口气看完了五篇，太乐了，然后开始和友人发癫（喜</p>
<p><img src="https://s2.loli.net/2023/05/29/T73Shztpjleyb1x.jpg" alt="shanghai-literature.jpg"></p>
<p>交通工程和房地产啥啥的一个大四的必修课用任选志愿肯定选不上，删掉换了点别的保底，能手选上再说。又数了一下培养方案里除去毕设、夏季学期、可以替代掉的数学物理方程之外还有
38
学分的课没选，突然觉得五年毕业也没那么难，<del>就连四年毕业都还有理论上的可能</del>。然后想到其中有七门物理课，对不起我轻敌了，五年毕业也还是挺难的（（。这种时候就想想求真的研究生（似乎）也要修四大力学，还是安慰下自己也没有那么冤（（</p>
<p>发邮件给数学物理方程的老师复读了一遍我想用 8 个学分替代 3
个学分的事情，又被已读不回了，啥意思（。想起来这门课两个学期是两个不同的老师分别开课，就又给另一个老师发了邮件，说是只要
PDE 一门课就可以替代，草，不要给我下个学期 ODE
学到破防跑路的退路啊（x</p>
<blockquote>
<p>lzx: 我觉得这个数学最好学了</p>
</blockquote>
<p>（震撼</p>
<h1 id="月30日">5月30日</h1>
<p>数学物理方程的另一个老师终于回邮件了，说是按基科的惯例是可以用 PDE
替代的，然后提醒我：</p>
<blockquote>
<p>但是必须说明：从内容看，这门课是针对数学系的。数学系之外的一般学生会可能会觉得抽象程度较高。你要根据自己的兴趣倾向来考虑。如果你觉得自己不习惯数学系专业课程的风格，请慎重选择。</p>
</blockquote>
<p>嘿嘿我就喜欢搞抽象的不喜欢搞具体的（什</p>
<p>毽球最后一场比赛不仅输了还成功被队友铲倒（，之前觉得帝皇训练摔倒第三次骨折的演出有点夸张，今天体验了一下还真是那么回事，<del>不知道导演和分镜有没有去摔过试试</del>。眼前的景象突然静止，视线再一次清楚已经是<a href="https://www.bilibili.com/bangumi/play/ep29859">陌生的、天花板</a>了（草</p>
<p>还好是仰面摔而不是往前摔，也没摔到头，除了给我本就不大健康的腰雪上加霜之外没太大影响，往前摔万一下意识用胳膊甚至手掌撑地的话说不定真骨折了，<del>期末周的数学壬最宝贵的不就是手了吗</del>。这下虽然也用手扶了一下但是冲击挺小的，不过手肘和手掌还是都撞到了，有点淤青。铲倒我的不愧是个医学院的姐姐，直接从包里拿了两片贴膏给我（室友锐评：她不会经常铲倒人所以随身准备这个吧（害怕</p>
<p>贴了一天晚上撕下来去洗手，结果这个药剂沾到手上怎么洗不掉啊，救命，<del>我这辈子右手手掌不会就是黄色的了吧</del>（（</p>
<p>夏季学期就选了两门必修，急死我了，今年逻辑学专题课看起来很数理，甚至还有博弈论，急死我了急死我了急死我了为什么是今年军训而不是去年，<del>这课能旁听吗，给个
zoom 会议号也好啊</del></p>
<p>今天 Nice Nature 去世了，素质女士，我的素质女士呜呜（</p>
<h1 id="月31日">5月31日</h1>
<p>昨天还以为摔得不重，睡了一觉感觉腰和尾椎骨越来越痛了，起床都花了好久，每走一步路都好痛（。手受伤之后就不是很想仔细扎头发了，<del>什么先把头发分成两部分扎上双马尾再编成两边麻花辫，别为难我了</del>。非常难得的把头发随便一捆夹一个抓夹出门，但说实话这个发型是最舒服的，感觉头发不存在一样，就是不好看罢了。</p>
<p>生统大作业 pre 终于结束了，更坚定了我不搞应统的决心，被成熟的 data
analyst
们带飞（。实在是好痛苦，代码写过十遍也写不熟，读模型抓不住重点，数据特征被别人提出来才觉得我超好有道理，我存在的意义纯纯是干杂活以及通过尬吹给队友提供一些情绪价值（。今晚闲着没事看统计中心的推送，看合影发现队友里面有一位<del>帅哥</del>周末刚参加了统计中心夏令营，还有一个在概率论和实分析课上都见过的某双学位书院的姐姐也参加了，世界真小。</p>
<p>后面就是两个统辅课期末考了，线性回归的回放还差一节没刷完，cheatsheet
也都没做，周末要做实验还要把故宫学报告写了，身体状况欠佳，到这份上了我还是只想读
Durrett
写概率论，怎么办啊急死了（。但至少关于统辅的痛苦大概到下周三就结束了，然后就是长达十天可以全部用来学概率的考试周，虽然需要穿插预习一个测量学但怎么说也都太幸福了，感觉放暑假了一样。</p>
<p>测量实验的时候就在想，在不擅长的事情上找不到自己存在的意义也是很正常的事情吧（。实在测不准的话就主动提出来当那个站桩调平棱镜和保护定位仪器<del>顺便摸鱼看马娘摇曳</del>的人算了，至少不添麻烦，在什么都不会做的场合有需要这种角色的存在也已经不错了（</p>
<p>至少我定点和调水平都做得还可以嘛，虽然这两个谁都会就是啦（</p>
<p><img src="https://s2.loli.net/2023/05/31/CUTx4uRGeqDgsEV.jpg" alt="surveying-experiment.jpg"></p>
<p>五月的最后一天，在觉得自己各方面都是废物中度过（</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇十·23年6月</title>
    <url>/2023/06/01/Diary-2023-06/</url>
    <content><![CDATA[<p>西郊有密林，助君出重围</p>
<span id="more"></span>
<h1 id="月1日">6月1日</h1>
<p>之前老姐说她在听万青的时候我还在乐，说你这也太青春了，然后最近我开始循环冀西南林路行（</p>
<p>睡一觉起来又觉得腰更疼了，草，怎么会这样，早知道越睡越疼的话还不如通宵不睡了（？。早八太困了，想起来好久没看
Lofter 了，刷了会赛马娘
tag，本来以为能看到大量帝宝，结果怎么全都是船啊，创死我了（（</p>
<blockquote>
<p>lzx: 我三天不看论文就急得慌，觉得生活不一样了</p>
</blockquote>
<p>本来以为今天可以先写完后两周概率论作业再刷完最后一节线性回归课，后来觉得回归课来不及了能写完概率论也不错，结果晚上吃晚饭突然被
SRT
导师叫去开会说材料还要改，甚至他稍微有点不想结题了想继续优化（，草。最后就只写了这周的概率论，也只是写了还没去读
Durrett，可能又要塞进考试周了，非常的绷不住。</p>
<p>选课最后俩小时看到一个博弈论与政治啥的社科课组的课，虽然和高等数理统计冲突了但私心还想着万一选上了就去，结果也没抢上，<del>好似</del>，乖乖学高统去了（</p>
<p>晚上在教学楼外面贴贴，从我的方向正好可以靠在欧老师的肩头看到满月。但愿人长久，千里共婵娟，下意识地伸出一只手用食指和大拇指圈住月亮的时候，是很真诚地在这么希望的。</p>
<h1 id="月2日">6月2日</h1>
<p>上周五在盒马订了一束<del>特价的</del>蝴蝶康乃馨<!--，甚至咕掉了早十的习概在寝室里等送货（绷不住了，还搁这毛概呢-->，虽然有点摸不着头脑这是康乃馨的什么远房亲戚，长得也不像。主要还是觉得这一周会很辛苦要经常熬大夜，桌上如果能有花大概会提振一下精神。这次的花买来的时候都还是没开的花苞，插水养了两天才真正绽开，花期也长很多，一周过去了仍然很鲜活的样子。我原本是这么想的，结果翻出来一周之前的照片才发现当时的花瓣是接近于紫色的颜色，茎叶也都是翠绿的，现在明显褪色了。</p>
<p><img src="https://s2.loli.net/2023/06/02/ta42vrhHN9wZykD.jpg" alt="carnation.jpg"></p>
<p>突然发现概率论作业从期中之后就再也没拿过
10/10，乐了但又乐不出来，无所谓了。第一次读 Durrett
的时候就是在读条件期望那一部分，当时完全不明白 Kai Lai Chung
上面突发恶疾把条件期望写成一个 Radon-Nikodym Thm
导出的微分形式是在发什么癫，也就只是接受了，读了 Durrett
才知道很自然，一下子觉得这书真不错，迅速换了教材。最后一次 bonus
就是要证明这个然后和条件期望联系起来，下周正好研究一下顺便弥补作业扣掉的分数好了。今天写第
16 周作业的一道题，本来非常摸不着头脑，把 Kai Lai Chung
上面稀奇古怪的定义翻译过来才发现就是 CLT + Feller <span class="math inline">\(\iff\)</span> Lindeberg
那个定理罢了，这书真看不下去了。</p>
<p>突然想起来一个有意思的事：在博客右下角放了一只黑色猫猫最开始的原因是因为左上角有黑色的色块，这样比较对称。不过赛博猫猫后来替博客里的很多内容背了锅就是了（怎么了嘛，确实是赛博猫猫写的呀（</p>
<p>（昨天）睡前突然意识到实分析期中那个来自 Stein
的改编题，直接迁移到概率就是对于在 <span class="math inline">\([0,+\infty)\)</span> 上取值的随机变量 <span class="math inline">\(X\)</span>，<span class="math inline">\(\mathbb
EX^p = \int_0 ^\infty (1-F(x))px^{p-1} dx\)</span>
这个经典公式。<del>很难想象睡前一般都在想什么，睡眠质量真的会好吗</del>。现在说起来实分析都感觉是很久远的事情，想想前半学期真是做了很多尝试，现如今我也并没有很好地履行退课之后仍然认真上完这门课的约定，作业都还有一些没写完，抽象测度也没看，时间都花到
Durrett 以及补前半学期扔下的线性回归去了。</p>
<p>之前在数学笔记里面完结撒花的时候用过“证明完毕”那一张 FGO 章节
CG，结果新章剧情给我来了个这个（<del>这年头怎么真的有人还在玩这破游戏啊</del>，谢谢很实用，太贴心了：</p>
<p><img src="https://s2.loli.net/2023/06/02/zAXgkpBsuhy4OUW.jpg" alt="EFQ.jpg"></p>
<h1 id="月3日">6月3日</h1>
<p>走在路上脚踝创到了路边一辆电动车的脚蹬，不锈钢的，好痛。结果我还没来得及检查创得怎么样，它先开始报警了，凭什么（，好想再给它一拳（<del>喊什么喊，你喊破喉咙也不会有人来救你的（车主：？</del></p>
<p>骑车出门的时候想着哼两句歌，今天脱口而出的是《如果有来生》里面“我们去大草原的湖边，等候鸟飞回来”和《南国的孩子》里“血里流窜着远在古老的故事，手心刻画上帝的仁慈与未知相似”。这种时候想起来的都是初中时候爱听的歌，当时品位真不错<del>，不像现在就一天天搁那听马儿跳的二次元</del></p>
<p>微调了一下课表就等手选了，下学期还有个必修的生物课要上，你院到底怎么会想到让大家都必修
2
学分生物的啊，我高中都没学过这玩意（。虽然一直偏文也喜欢地理，但真正放弃选生物还是学减数分裂的时候，完全看不懂（</p>
<!--翻出来一条四舍五入两年没穿的裙子，至少入学的时候带到学校然后再也没穿过，总觉得比印象里变短了一些，是不是说明我又长高了（？-->
<h1 id="月4日">6月4日</h1>
<blockquote>
<!--時代遍地磚瓦 卻欠這種優雅-->
<!--誠心祝福你 捱得到 新天地-->
</blockquote>
<p>试图用区间套定理抢救两门统辅课的一天，说失败好像也没多失败，一天大致写完了故宫学报告，复习完了生统概论一学期的内容写完了
cheatsheet，但是也完全谈不上成功，线性回归后天晚上就考了现在 cheatsheet
还没做。</p>
<p>急了，通宵去了（</p>
<h1 id="月5日">6月5日</h1>
<p>通宵把线性回归 cheatsheet
摸了三分之二，白天又写了几个小时终于写完了，有点极限。怎么说呢，生统概论的
cheatsheet
无非是把讲过的东西都塞上去，然而线性回归讲的东西肯定不可能塞到一张 A4
纸上去，所以复制了一份笔记一边删一边抄，反而没写那么多，把接近三万字的笔记删没的感觉还蛮爽的（？</p>
<blockquote>
<p>早上好，午饭估计又无了，我睡了，晚安（？</p>
</blockquote>
<p>早晨六点半躺下的时候给欧老师发的，一个错误的同时用到“早”“午”“晚”三个字的造句示例（</p>
<p>已经很多天没读 Durrett
了，明后天考试，大后天要精修一下故宫学报告，周五还有个基物实验报告，最早也要周末再开始学概率论和写
bonus，急了，好想发疯（</p>
<blockquote>
<p>Durrett！Durrett！Durrett！</p>
<p>啊啊啊啊啊啊啊啊啊啊啊！！！！！</p>
<p>DurrettDurrettDurrettDurrettDurrettDurrettDurrettDurrett</p>
<p>啊啊啊啊啊啊啊啊啊啊啊！！！！！prprprprprprprprprpr！！！！！味道真棒啊！prpr！！</p>
<p>啊啊啊！好想 prpr Durrett 影印本的封面啊！！！prpr！！！！啊~！</p>
<p>诶 稍等一下 不对 是好想摸摸啊！！！摸摸~ 摸摸~ 摸摸它的封面~
！摸摸它的封面~！</p>
<p>教会了我条件期望的 Durrett 好可爱啊！！</p>
<p>啊~ 啊~ 啊啊啊啊啊啊~！！！！！</p>
<p>附录里有好几个大定理的证明真是太棒了 Durrett！！！</p>
<p>啊~真可爱啊！！！真是太可爱啦！！！！</p>
<p>啊~ 啊~！！！！！！</p>
<p>之后复习的时候还可以读完 LLN 和 CLT 章节真是太高兴了</p>
<p>呀~ ！！！！喵~ ！！！！！嘎~！！！！！！</p>
<p>咕啊！！！！！！！！！！！！</p>
<p>概率理论什么的根本就不是现实？！啊，仔细想想代数和分析也是……</p>
<p><span class="math inline">\(\mathbb R^2\)</span> 上的东西推广到 <span class="math inline">\(\mathbb R^3\)</span> 里不存在？喵 ~
！！！！！呜哇~ ！！！！！！！怎么会这样！不要啊！！！！！！</p>
<p>哈啊啊啊！！！！！！可恶！狗屎！我要跟这个狗屎的世界说再见了……</p>
<p>诶 Durrett 在看着我？</p>
<p>书架上的 Durrett 它在看着我？</p>
<p>书架上的 Durrett 它在看着我啊！</p>
<p>它在看着我啊！</p>
<p>书架上的 Durrett 它在看着我啊！</p>
<p>太好了！看来这个世界还是没有抛弃我呢！！！呀吼！！！！！！</p>
</blockquote>
<p>感觉发疯还是搞个折叠块比较好（心虚（<del>明明忙不完了怎么还有空整活（</del></p>
<h1 id="月6日">6月6日</h1>
<!--闲着没事爬了爬答疑坊志愿者群的楼，感觉这是第二个贵系大群（-->
<blockquote>
<p>我姐：昨天我妈看到我在一边聊天一边乐</p>
<p>她以为我终于交男朋友了</p>
<p>凑过来一看是你 她很失望</p>
</blockquote>
<p>乐死（</p>
<blockquote>
<!--还是她：说真的你妈妈我很难评 我不大了解但是按照我知道的来看 你能长成现在这样确实很不容易-->
<!--我：那当然了（蜜汁骄傲-->
<!--她：你读初中高中的时候我真怕你有一天绷不住就（-->
<!--她：宝宝还是很好地长大了-->
<!--我：？你怎么像个男妈妈-->
<!--她：？-->
<!--我：其实也没有，我长大之后也还是乱七八糟的-->
<!--她：没关系 你还记得那句诗吗 我身体里的火车从来不会错轨 所以允许大雪 风暴 泥石流 和荒谬-->
</blockquote>
<p>前两天真的印了件帝皇麦昆贴贴的痛衣，今天穿着去跑了
50m，穿上出门才发现是双倍的羞耻，<!--虽然有照片但是完全不敢放出来，一方面这种东西自己印了穿是没什么问题但是发出来似乎不太好，说到底官方要是出周边就好了（，而且码数买大了显得好胖（。是按体重选的码数，充分说明了我上半身和下半身不属于同一个体重（-->不过真比我预想的成绩要好很多，很神奇，<del>可能主要还是老师掐表没掐准</del>。虽然这两位没有一个能跑短距离<del>（帝皇短距离适性
F，麦昆是 G）</del>，但果然还是比普通人强得多，下次体测和 1500m
还穿（</p>
<p>上周也是在体育课上摔伤了腰背，到这周本来以为好得差不多了，一跑步才感觉到还是很痛，有点迈不开步子。只不过也没机会重新测了，就算周四可以去别的班上测也不见得这两天就能好，现在成绩也还算满意，就这样了。</p>
<p>线性回归本来是想考试考得好的话就把大作业咕掉了，现在考完感觉也不知道考得好不好（，<del>虽然等收卷的时候瞟了半天前排一个哥们的填选题答案感觉自己做得还挺好的（</del>，估计也还行但后一周有空的话还是写一下好了。感觉这个考试复习的要义就是考前两周把所有的雨课堂回放二倍速听一遍，把老师说的每一句让人感觉摸不着头脑的话记下来抄到
cheatsheet
上，<del>都到这时候了别再搁那算你那个线性代数推导了</del>，考试的时候再抄到卷子上就可以了（。本来没觉得可以这么复习，我是前半个学期基本没学所以这两周一直在听回放抢救，没想到确实考了一堆课堂上说的原话，很难绷得住。</p>
<p>前两天做 cheatsheet 的时候看到笔记里有若干个 typo
但是太急了没改，现在虽然还记得是什么内容，但是打开文件才发现要在三万字里面再一次找到它们实在是有点困难（，追悔莫及。下午睡了一觉今晚估计又通半个宵，生统那边复习得顺利的话大概可以改完，<del>然后我死后管他洪水滔天</del>。</p>
<p>又一次晚上在户外靠在欧老师肩头贴贴的时候看到了北斗七星，除了天权之外都看得很清楚。<del>突然就想起来高中的时候有一次逃晚自习坐在操场上破大防，哭完之后发现秋天的夜空其实很澄澈，透过没擦干的泪水看到的星星比平时更闪。于是躺下举起手机用
Stellarium（还是星图来着）对准天空一颗一颗认星星，一边哭一边笑。过了一会打开
FGO 开始抽卡（，好疯啊（</del></p>
<p>6.10 UPD:
因为太草了所以当天根本没写进来，今天想想还是补个档。当时考完试出来还沉浸在这个题怎么又难又简单的疑惑中的时候看到欧老师在门口等我，我第一反应居然是，这哥们怎么考完试还来找我啊，他不会也喜欢我吧（（。我超，走了几步我都还沉浸在这不会也算是双向吧.jpg
的喜悦里（，直到走出教学楼看到欧老师一脸“今天为什么不牵手”的疑惑然后对我伸出手的时候才反应过来，我超，好像一个月之前就在一起了来着啊（（，草。</p>
<p>线性回归把人变成鬼（</p>
<h1 id="月7日">6月7日</h1>
<p>出门前花了十分钟蹲在楼下看两只猫猫吵架，真好，我也想当小猫（</p>
<p>群友上次说测量学实际上作业和实验都不占成绩，只是不参加/不交的话要倒扣分，实际上是
all in 期末的，人均 3.0
上下这样子。<del>急了，怎么不早说，早知道后八周退课就退掉了</del>。无所谓了，就当多上一门体育课，<del>某种意义上来说测量实验确实就是体育课（</del></p>
<p>这个生统概论的期末比我想象中的逆天很多（，反正上课作业考试都不是一个难度，无所谓了，统辅到这里就真的结束了<del>醒醒是不是还有个大作业没写</del>。数学课考得不好我会觉得是我的问题<del>然后开始为自己的菜而反复破防</del>，这种东西我就不会再往自己身上找原因了，一定是课的问题（。</p>
<p>不过至少可以算进外文课，虽然并没有外文认证但是攒够两门去办一个替代也可以代掉一门听说，赚了（。只不过我现在也还是想不明白为什么入学的时候笔试四级但口试没过，虽然更想不明白我这个英语水平怎么就免修了，<del>真正有在学英语的时间就退役到春考前的三个月</del>。只能说考试水平大概还是远高于实际的应用水平罢，拟合能力比较强（</p>
<!--一边绩点焦虑一边又觉得，其实申请之前控住 3.8 以上就差不多了，容错率还是很高的。但是看土水学院这个给分，看数学系那个给分，又觉得真不好说能不能控制住（-->
<blockquote>
<!--A: -->
<!--今年推研第一批录取形势怎么样呀-->
<!--B: -->
<!--不知道，我身边没什么人去数学系-->
<!--数学系报名本系的好像也不多-->
<!--A: -->
<!--啊这，难道都涌向求真了-->
<!--B: -->
<!--难道大家不都转战光华/五金/高金/泛海/安泰/汇丰了吗？-->
</blockquote>
<!--你环太乐了（-->
<h1 id="月8日">6月8日</h1>
<p>昨天刚给水卡充了 19.98<del>（我除了前两次充卡之外一直都是充 19.98
来保持余额是 3
的倍数，而且这样不会收到微信消息）</del>，今晚一回寝室就拿到了新校园卡，我急了我急了我急了（</p>
<!--新卡为什么不能换照片呢（，现在用的证件照还是高考完的暑假去天真蓝化了妆拍的，说实话我感觉还没有另一张素颜在家附近随便一个店里拍的证件照好看（。但当时拍完有一种不用一下可惜了的感觉（（，就放到校园卡上了，追悔莫及（-->
<p>今天写完了人生中最后一个基物实验报告。室友之前评价说这个东西要抱着把它当做打字小游戏的心态来写，但实验讲义里几乎每一句话都有我完全没听过的概念，好多因果关系也完全看不懂，连读顺溜了都难（，就算当做打字小游戏也属实不是很好玩。总之终于免费了，乐得我晚上刷了好多答疑坊的单子，跟没别的事了似的，答疑答到九点半才想起来概率论最后一次
bonus 还没写，抢救了一个小时连 Lebesgue's decomposition
都还没读完，太失败了（</p>
<p>不过也确实，期末对我来说压力最大的一阵子已经过去了，虽然还没到期末周（</p>
<!--因为一个小时里遇到了三个非常乐的事情于是临时加更一手（（-->
<!--之前熬大夜的时候经常凌晨两三点去洗漱，经常会遇到对门的一个学姐也没睡，之前大概就知道她们寝室是致理零字班的，还以为是生物所以非常肝（什么刻板印象）。今天正好洗澡的时候遇到她在和她室友吐槽 PDE 和泛函，才知道她是致理数的（，绷不住了，难怪睡这么晚（（不是-->
<!--我平时不看朋友圈，但是时不时会去翻一下 Bowen L 的朋友圈给他点点赞，~~知遇之恩是你这么报的吗~~。之前一直以为数学系的这些助教里面就他还单身了，~~脱单率怎么这么高，不太符合我对数学壬的刻板印象（其实是符合刻板印象的那些人确实都单着但是也不熟罢了~~。之前还在想他还蛮可爱的怎么还单身（？），最近看到他朋友圈的照片里有 npy 出现了，感到非常的欣慰（？）。-->
<!--晚上和友人聊天，她告诉我前段时间我 ex 从化院降转到信科了，原来隔壁强基是真的可以转专业啊。听说他们信科是很大一个院系，电子什么的也都在里面，随口问了友人一句转的哪个专业，结果她告诉我，是信息与计算科学（（（（-->
<!--去看了眼[培养方案](https://eecs.pku.edu.cn/info/1083/5225.htm)，还真是学计算机的而不是学数学的，非常符合我对这个专业应该长什么样子的想象。虽然这个专业在隔壁强基里面叫数学 2（数学 1 就是数学），草（（（-->
<h1 id="月9日">6月9日</h1>
<p>今天突然被室友问了为什么要用院系发的文件袋，<del>说好和院系割席的来着</del>。但其实我多少有点是故意的，上学期上抽代的时候突然想整个活，<del>在这之前用的是另一个交大的文件袋（怎么听起来整活整的更大</del>，本意是觉得在这种课上掏出一个未央的文件袋放在桌上效果会很炸裂<del>（醒醒根本不会有人注意</del>，乐（</p>
<p>社恐归社恐，我一个人整烂活自娱自乐的时候好像一点也不社恐（</p>
<p>好久没看实分析了，晚上答疑坊值班的时候为了答一个一直没人理的实分析单子，接着上次的进度往后学了好多，答完正好下班。今晚本来是想写习概论文的，结果莫名其妙把时间都花在这上面了，<del>学会了证出来才去接单，结果人家还以为我秒题，工时就给了
15 分钟（（</del></p>
<!--不装了，说点阴暗的。提问的是我高中隔壁班的一个女同学，以前也是数竞组的但是一直在水，当时大概是因为高考成绩和校测加起来比较高所以被录进了致理数学。我很难评，虽然这完全是强基招生的问题，但在她面前我真的很难放下莫名其妙的好胜心，后半学期在答疑坊答了好多单她问的概率论和实分析，麻了（（。很多时候我都觉得自己有点毛病，想说明什么，说明我哪怕人在奇怪的院系、少学一年也能在同样的课上学得比她好，所以就比她更适合读这个专业吗，那又怎样呢（（-->
<!--算了，论迹不论心（迫真，至少教人做题了（（-->
<p>智齿又开始发炎了，比上次痛一点点但也还好，暑假回家真得给它拔了。<del>还好不影响贴贴</del></p>
<h1 id="月10日">6月10日</h1>
<p>思政课的课程总结能不能用 250
个“谢谢老师”凑一千字啊，全是感情没有技巧，真写不出来（。<del>晚上一边跟友人吃高中同学的瓜一边写，非常的乐，勉强活下来了（</del></p>
<p>前天读证明读到了 Hahn's
decomposition，昨天自己成功把引理和定理证明都复现出来了，然后把另两个分解和原定理证明也读了，今天也基本都顺利复现出来然后交掉了。一杯茶一包烟五页证明看三天，第二天是还能写出来，过一周说不定连定理在讲什么都记不得，就记个名字。<del>这个时候要安慰自己，无所谓，我大概知道它在这本书多厚的地方（</del></p>
<p>寒假回来之前给电脑外壳贴了个二号机的镭射贴<del>但是已经蹭掉一部分了（别问，问就是香厨</del>，键盘旁边贴了个
SEELE 的标志。今天突然想再买个 NERV
贴在另一侧，找了两家店都卖完了，可恶（</p>
<p>室友的基物实验报告里抄讲义的一部分被判抄袭了，另一个无辜被判和她互相抄袭的是她们班一个同学，助教的逻辑大概是“你们两个是一个班的所以互相抄袭也说得过去”，虽然他俩连微信都没加过（。在寝室吹水的时候说，这种感觉就像“两个不太熟的人在路上偶遇对视了一眼，围观路人瞬间通过他们曾经一起上过同一节马原这件事情判断出来肯定有问题，然后当场表示磕到了”，草，<del>我太会形容了</del>。希望申诉没事（</p>
<h1 id="月11日">6月11日</h1>
<!--#每日吃瓜 #每日暴论-->
<!--室友生理期不舒服，一个追她的男生给她送了暖宝宝和姜茶-->
<!--我：30 多度的天送暖宝宝是怎么想的，送姜茶感觉不如送两片布洛芬来，这男的不行你别上头（暴论-->
<!--室友：嘿嘿他好关心我-->
<!--fine（-->
<p>半夜（大概算昨天晚上）很难过，下楼想买瓶甜一点的饮料喝。自动售货机上支付宝只能刷脸支付，我一直到现在都很固执地没有开通这个，就选了微信付；微信没零钱了，想着用学校发的那张中行卡付，结果
23:00-3:00
在维护不能支付；真的真的很想喝点甜的，就从支付宝往另一张卡上转了钱，等了一会到账才终于可以付款了。结果付了钱之后售货机故障饮料没掉出来，只好更加难过地回寝室了。白天申请退款还被商家拒绝了，超绝难过（（</p>
<p>上次平白无故被华子（？）骗走钱还是给老姐寄礼物的时候，在支付宝小程序下了单之后现场扫了快递员的二维码付邮费，结果莫名其妙又在小程序上被扣了一份钱。投诉、要求退款以及和客服扯皮好几次也没结果，委屈地去答疑坊接了两单当做弥补（</p>
<!--感觉消费观有点问题，不知道是不是因为完全是自己花自己挣的钱所以这种时候肉痛的不行还花了不少时间，还是说单纯觉得这件事情是有问题的所以一定想要掰扯清楚。说到延毕的第一反应也是思考要多交一次 5000+900，但是平时几十几百的消费一笔也没落下而且其实也没什么感觉，一超支就去薅答疑坊的羊毛（。用于生活的钱花得很少完全是因为物欲低而不是真的在刻意节省，总觉得还是有哪里不大对劲（-->
<p>晚上在教室被热麻了，1h
什么都没干光觉得好热好热好难受好难受，明明室外那么凉快，搬到走廊里才好一点。经常有一种夏天不会就我觉得很热吧不会吧不会吧不会吧，为什么别人都不需要开空调的感觉。<del>冬天的暖气就不能关甚至不能调小一点，然而空调大家只要脸皮厚（不是）就都可以随意控制，有一个室友夏天不开空调，冬天在暖气的基础上还要开暖空调，对怕热的人来说好不公平啊（。</del>困惑地思考去年夏天怎么没觉得在教室自习很热，然后想起来，去年因为疫情有一阵子教室里不允许开空调，逻辑好像是病毒会随中央空调管道传播，乐。寝室里室友白天也经常不让开，我觉得太难受了，六月初上海一解封就回家了（<del>但好像我回家之后过了几天就能开了，可恶</del></p>
<!--这两天接了一些答疑坊的概率论 (1) 的问题，我现在明白了，我不是单独对那个同学有好胜心，凡是看到有人在问我学过的数学专业课就都这样，~~虽然对那个同学尤甚~~（-->
<p>今年参加高考的小朋友里面只认识一个，是高中时候同校的 FGO
同好，<del>另一位曾经比较熟的同好还是（）</del>。这两天有在找我聊天，我也不知道为什么突然想起来我这么个人，然后他今天问我：</p>
<blockquote>
<p>你去过 taca 或者 tda 吗</p>
</blockquote>
<p>我都不知道是什么，唐突被提问还以为是什么 FGO
的展子的缩写（，搜了才知道华子还有这种考试啊。突然就想起来高二暑假的时候，我前两年的课内成绩甚至拿不到一个华子暑期学校的名额，印象里全年级有超过一半人数的暑校名额，班里没拿到名额的就个位数。<del>后来差点裸分考上华子，感觉很黄金船行为，大漏闸出迟，但是末脚.jpg</del></p>
<h1 id="月12日">6月12日</h1>
<p>身体状况有点糟糕，每天都非常疲惫，白天补觉也睡不着，做不了太多事情，晚上又熬大夜赶进度，然后循环。去年期末周顶着不知道哪一天会感染甚至室友还先我一步发烧的情况，第一周重学
Galois
理论加复习整本书，第二周完整学了一遍数值分析，今年总有种忙东忙西但还是不知道在干什么的感觉，很累很累。</p>
<p>时常因为不太懂赌博是怎么赌的而感觉有点难以理解概率论（，虽然看了赛马娘之后去补了不少赛马原型故事，但到现在也不太懂赌马的赔率是怎么按照投注来算的。看
martingale
更觉得绕了，别的章节举例子都是有助于理解，这一章举的例子我反而看不太懂是在赌什么，怎么就
unfavorable game
了，数学家从现实抽象的能力真强啊，但我只能看懂抽象出来的那一部分（</p>
<blockquote>
<p>lzx:
我们概率学科的出身不太好，不像代数分析那些，概率是从赌博出身的（笑</p>
</blockquote>
<p>为了防止期末再发生概率论期中忘记带手表破大防的惨案，最近一直都戴着试图养成习惯，热上加热（</p>
<p>吃饭的时候回忆了一下，发现还记得用来证明 Radon-Nikodym Thm
的三个分解和它们的证明，挺好的，不知道是不是经常回忆就不容易忘记了。<del>可是期末又不考这个（</del>。每次读这种大定理的证明都觉得真是精巧，<del>我未来又能做出什么样的工作呢。</del></p>
<blockquote>
<p>花费数十载光阴，证明一个浅显的定理，为后世某个天才节约几个下午的时间</p>
<p>—— <a href="https://www.zhihu.com/question/442130053/answer/1707345709">平庸的数学家能为数学的发展做什么贡献？</a></p>
</blockquote>
<h1 id="月13日">6月13日</h1>
<p>现在是 6 月 13 号，晚上的 8 点 36，星期二。18 号，概率论
1，一章没看。23
号测量学，还行，还剩三节课的内容，主要是导线测量一大章没看。前面的看了，题也不会做。25
号，线性回归大作业，等到 23 号再写。22 号还有九价疫苗的第三针，我 nm 18
周还打疫苗我超，这怎么上个大学这么多事儿，后面忘了，这个口味的冰红茶还挺好喝的，热带风味（</p>
<p>骑车出门遇到两个路人在用沪语聊天，<del>能不能带我一个</del></p>
<p>没歌听了之后又回到了 One Last
Kiss，哥们又来逛卢浮宫了，<del>截止现在已经逛了 4459
次，不知道考试周结束会不会逛到 5000+（（</del></p>
<p>昨天答疑坊小程序蹲了一天没看到微积分的问题，到晚上才意识到是已经考完了。室友今天考概统，昨天在寝室一边整理东西一边帮她抢救了一会，考完她告诉我“我感觉这个你昨天跟我说过，但是没记住你说的什么”，乐（</p>
<p>突然想起来初中的时候有个学长，高中去了上中，<del>我还在知乎膜过他（#每日黑历史
#每日开盒</del>。第一年高考<del>据他自述是谈恋爱谈昏头了所以</del>寄了<del>但他当时的
npy
裸分考上华子了不过好像入学之后很快就分手了（这是可以说的吗这</del>，又复读一年去了复旦数学。说起来还蛮有意思的，听说他后来也一直在当时的高复机构当助教，昨天才在知乎看到他发了今年高考数学复卷点评什么的，他本人说去复旦读数学也是因为以后想当高中数学老师。又想起来一节概率论早八的时候昏昏欲睡，<del>除了透的期末题之外</del>就听进去一句话，下课的时候
lzx
在和前排的同学说好多学校的数学系现在要变成师专了。<del>旦不至于，没有乳旦的意思</del></p>
<p><del>所以为什么突然想起来这个呢，是因为觉得教室友好难所以想感叹能当高中老师太强了吗（</del></p>
<p>逐渐觉得晚上回寝室一路沿着校河走其实非常爽，比走学堂路舒适。下坡比较分散可以全程都不怎么费劲蹬车，校河旁边有风，<del>路上没什么人所以可以唱歌（其实这个才是关键</del></p>
<h1 id="月14日">6月14日</h1>
<p>Durrett
前三章读完了，第四章读了一半，感觉后几天的任务好像就是背证明和回看作业题了（。理顺了确实能自己写出来，但是新的问题是这些定理都恁大<!--（今天才发现，怎么唐突开始讲山东话（乐-->，两个小时来得及写完吗，哪怕只是写完其中五道题？（</p>
<p>虽然把书拆了没办法拥有“知道某个定理在多厚的地方”这样的技能，但还是知道在哪个章节的多厚的地方，甚至感觉最主要的是知道它在左边一页还是右边一页，证明占了多长的地方，是在纸的上半部分还是中间还是下面（</p>
<p>一直在用大一的时候微积分的习题卷反面当草稿纸，大二都快过完了也还是没用完。越想越气，当时就知道搁那儿大力拟合，A1
啥也没学到但至少拟合出来绩点了，A2 overfit
出了截止现在数学课最低成绩<del>虽然下个学期过完就不一定最低了</del>，大二暑假了还要补分析，丢人（</p>
<p>书后习题没有答案又没有一个或许可以讨论，或者说，至少大家都在学的氛围，就实在有点难受，大概也是读不动
PIN 和 Kai Lai Chung 的一大原因，在考虑可以换点什么参考书，baby rudin
吗，<del>还是直接去听 647 的网课</del>（</p>
<p>从故纸堆里找可以用的草稿纸的时候还翻到了去年工艺美术史的
cheatsheet，这玩意怎么进去的，我还挺喜欢这门课的<del>但也只有
A，虽然一分不调按分数严格映射到等第的情况下 A
也不错了，听说这课也因此评教爆炸了，但还是经典内恰三着驰雨拿
A</del>，赶紧抢救了出来。当时是老师会给一个大致总结好的 cheatsheet
但不保证覆盖所有的考试内容，然后我期末周还花了一天在上面补充细节，室友锐评看起来跟要考研似的（<!--不知道 neruko 老师考研有没有考这个，听说工艺美术史还真是美院的一门考研科目（--></p>
<p>刷课程攻略共享计划玩儿，<!--前两天在答疑坊看到有人提问去年微积分的期末题，感觉那个同学打印出来的卷子像我考完之后截图拼在一起发在上面的，有点乐。-->看了一眼贵系数值分析的期中卷，我直接愣住，这是在干什么（，别惦记你那矩阵要存多少个字节了，果然和数学系根本不是一门课（我们无法互相理解.jpg<!--但我数学系那门课是觉得自己学得真不错考得也挺好，最后还是 A，内恰竟是我自己（--></p>
<p>还找到了以前发在上面的一些东西，打开大学化学 B
的总结笔记一看，大一上期末周在法图复习到晚上十点然后绝望地回寝室的那个夜晚扑面而来。这破课还要求背元素周期表，歪日，我直到高考结束都只会前
20
号元素，当时还真背下来了，进考场第一件事开始在草稿纸上画格子，把临时印在脑子里的东西吐到纸面上。当然也没用，这课是真的“老师说题不难不用复习的太深，结果考场上计算器都没按完”（。不知道下学期生物课会不会也这么逆天（</p>
<p>又到了令人安心的补货环节，这咖啡不怎么好喝<del>但我也不是很在乎，醒着就行</del>，包装是真的设计得不错，空盒子全让我拿去当收纳盒了。转念一想快暑假了，真的需要存这么多咖啡吗，暑假没必要这么肝了吧（</p>
<p><img src="https://s2.loli.net/2023/06/14/5yBdvrFqlLw32cZ.jpg" alt="onebox.jpg"></p>
<h1 id="月15日">6月15日</h1>
<!--怎么又到这个点了（，更新一下概率论题目方便白天看，顺便偷跑一点这几个小时里写的日记好了。半夜看什么 feiyue.online 啊，本来没什么失学焦虑也整焦虑了x。还没拉到底就感觉看着像是 V1ncent19 一手操办的，难怪他一直在咕 stat wiki（-->
<p>去年期末周我调整作息的方式是每天把睡眠时间往后推一点，然后转了一圈就恢复正常了。突然觉得概率论考前一晚是不是也没必要睡太多，前一天晚上早点睡，<del>甚至可以六点起床早读背诵定理</del></p>
<blockquote>
<p>昨天早上的我：今天就睡了不到 6
个小时，感觉晚上可以早点睡，调整作息！</p>
<p>昨晚八点半的我在教室：把 Durrett 前三章刷完了，腰有点疼先趴一会</p>
<p>九点多醒来：？刚刚发生什么了怎么会睡着的，睡得好难受，头好晕（</p>
<p>今天凌晨四点的我：啊...或许可以再试试调整作息？（</p>
</blockquote>
<p>半夜<del>直接跳过两门期末考</del>开始挑军训用的防晒霜，挑麻了最后直接按照高中军训用的又买了一瓶，其实如果不是防晒喷雾带不上高铁的话寒假回来的时候就把家里那瓶带上了。不装了，我不仅不化妆而且也完全不护肤，冬天大宝拍脸，夏天洗完脸就出门（。躺在床上给老姐挑生日礼物挑了一个多小时，绷不住了，一年断断续续都没挑出来怎么可能一晚上就能挑到有意思的东西，还是照例买书
+ 按照聊天里的一些线索（？）买了点东西（</p>
<p>逛着逛着给购物车里加了一堆没用的东西但也没打算真的买（，不过有在考虑买一套工具入坑手冲咖啡（<del>因为看到
onebox
的咖啡豆好像不错的样子</del>，虽然上闲鱼一看就又觉得还是算了，买了大概也会闲置。上次在学堂路上还看到一个手冲咖啡大赛（？）的海报，<del>感觉比丘赛更吸引人</del>，很心动（</p>
<!--因为从初升高的时候就认识最近探微期末考作弊的其中一位同学（，所以这两天完整地吃完了这个瓜，~~学不完了~~，大受震撼。观察了一下感觉现在在树洞里沪爷已经在鄙视链底端了，到处都是 AOE 攻击，草（-->
<p>今晚有环友问有无 lzx 期末题整理，发了一份 PDF
顺便在里面署了名<del>（并不是真名）</del>。我现在很好奇它能够传播到多远的地方，会不会发生什么世界真小事件，蜜汁期待（？</p>
<h1 id="月16日">6月16日</h1>
<p>Happy lowiro day！虽然我已经退坑 Arcaea 很久了（</p>
<p>（昨晚）睡前试图通过回忆下 Radon-Nikodym Thm
的证明思路帮助睡眠（？），以为会想到某个地方脑力不济就睡着了。结果到
Lebesgue decomposition 的时候突然意识到，所谓的 singular continuous
distribution function 实际上就是它对应的 probability measure is singular
w.r.t. Lebesgue
measure<del>（我实在是不知道这句话用中文要怎么说（</del>。所以前几周在实分析里学的和在分布函数那里学的
Lebesgue decomposition
跟后面这个更一般的结论其实是一回事，又是一个低维投影。</p>
<p>这很 trivial，搜了一下发现这甚至是一个定义 singular continuous
的版本<del>（这句话听起来也很奇怪，但我现在一说版本满脑子都是 a version
of conditional
expectation，不知道怎么表达比较好）</del>，所以完全没什么值得说的，但躺在床上想到这件事之后还是<del>感觉自己要长脑子了</del>，就彻底睡不着了（</p>
<p>卢浮宫逛到 4900
遍了，真的很恐怖（<!--每天一边听 One Last Kiss 一边 one more kiss（草--></p>
<!--看到 V1ncent19 主页上的统辅笔记修订得差不多了，真不错，难怪他咕 stat-wiki（x。他是真的给过我很多帮助和鼓励，从刚开始修统辅，到寒假里问他要了几门课的 PPT 想预习，申请季观察了整个过程跟着失学焦虑（x，甚至最后退出统辅项目之前也和他聊过，他倒是很理解我希望做扎实严谨的理论而不只是 data analysis 这样的工作这种想法，还帮我问了问数学系几个概统的朋友，真的很感谢（那为什么要写注释里不写正文，绷不住了）。现在要毕业了，一直也没有线下见过面，以后恐怕更难有机会了。-->
<!--突然就想起来八字班社友毕业之前也没有能克服社恐五一社聚去见一见大家，刚来到贵社的时候还和其中一位（id 太抽象了我不知道怎么形容他，是 @xiaobao，但其实我刚来的时候他的 id 还很正常，叫 Xrepus，后来不知道为什么突然开始整抽象活儿）碰巧也是基科的社友聊过很久，接受了他的很多帮助，甚至还聊过他是从水利转过去的，他有一个同学保研去了统计中心现在在未央当辅导员，什么的。最早接触到统辅项目虽然不是在和他的谈话中了解到，但也差不多是在这个时候，后来又简短地聊过一点润学（，他毕业去了隔壁之后就也没什么联系了。人生到处知何似，应似飞鸿踏雪泥。-->
<p>终于熬大夜熬到熬不动了，今晚大概能早睡，太好了（</p>
<h1 id="月17日">6月17日</h1>
<!--#每日偷跑-->
<p>还以为鼠标坏了，反复纠结既然平时也懒得带着去教室就晚上在寝室用一下是不是也没必要再买一个了但是最近
618 要不还是买一个之后，才发现电池装反了，白做三学期物理实验（（</p>
<p>说到 618，每年 618
都是我买东西最多的购物节，基本上都要给老姐挑生日礼物，今年还买了两瓶防晒，本来还想试着买点别的咖啡但<del>预算不够了（并不）</del>担心保质期就也没买。今年挑到最后买的礼物（之一）是茶颜悦色的茶叶，<!--第一次喝到是真 · ex 高二的时候从长沙一中集训回来给我带的（，他说集训的时候一天两杯，顺便给我带点，草。死去的记忆开始攻击我.jpg-->想想她既然既喜欢喝茶又喜欢奶茶（，那还真挺合适的。</p>
<p>所以茶颜悦色到底什么时候才能开到北京上海来，感觉希望不大，急死了，别老惦记你那长沙武汉重庆南京了（</p>
<p>今天一天不知道在干嘛，好像就是在反复确认定理背完了没有，早点洗洗睡了。学数学哪都好就是考试真折磨人.jpg</p>
<h1 id="月18日">6月18日</h1>
<blockquote>
<p>但是新的问题是这些定理都恁大<del>（怎么唐突沙东话</del>，两个小时来得及写完吗，哪怕只是写完其中五道题？（</p>
</blockquote>
<p>我就是带预言家，今天两个小时笔就没停下过，勉强写了五道题，脑子是一秒也没动过，动脑子也没用。上来打眼一看<del>（怎么又在唐突沙东话</del>，哟这个是往年题，那个是期中考题又拿来出了一遍，这个考前透过，那个读
Durrett
的时候感觉很好玩就顺便记住了，还有哪个好像手搓出来过，总之感觉每个题都会证，就钩了五个最有把握能写好的，结果上来第一题四个又水又麻烦的小问写了半小时，心态爆炸了（，早知道选五个能写得最快的。最后还剩
15 分钟想再算一道题提高容错率但也没来得及算出来，还不如去写个 Kolmogorov
inequality 的证明玩玩，不过也差不多得了。考完想起来 CLT
的证明里有一步放缩可能写得有点问题，感觉满分无了（，唯一一个在数学课上拿
A+ 的机会大概也无了（差不多得了</p>
<p>强大数定律一开始没看到题目里可积的条件，考试中间问了助教一句结果她告诉我正部减负部可以得到
<span class="math inline">\(\mathbb EX_1 = 0\)</span> 蕴含 <span class="math inline">\(\mathbb E|X_1| &lt; +
\infty\)</span>，我人都傻了。后来一看卷子上好像有说是 i.i.d.
可积随机变量，考完还想找她确认一下她那个逻辑不对，举了个反例感觉还是鸡同鸭讲（，lzx
就跟我说卷子上有可积性但我想说的不是这个啊（，算了无所谓了。</p>
<p>考前咖啡杯的防水圈松了漏在了包里，血压爆了，幸亏电脑和杯子之间隔了个文件袋，<del>谢谢未央</del>。想起来有一次毛概课上室友装着咖啡的玻璃杯碎在了包里，作业寄了，她拿着包往垃圾桶里倒玻璃渣子的时候还把无线耳机一起倒进去了，损失惨重（</p>
<p>考完数学好空虚（，线性回归大作业不会写，测量学明明都是中文但嗯是看不懂，现在是一个学期里少有的除了学土水学院这些破课之外没别的事情干也不太应该干别的事情的时间，好崩溃。下午手搓了个大作业的可能<del>正确</del>有用的模型，读了读老师给的参考文献，感叹中文期刊真水啊，这不我上我也行（。然而按照设想的来做的话代码写起来估计很费劲，这几天晚上争取肝出来，不过不如先写报告编故事吧（</p>
<p>急了，测量这些东西我真的背不下来，也不知道要考什么，不会要比体育课还拉胯吧（。<!--这么说的话就算生病退一万步测量缓考也无所谓反正现在也不会（，主要是我 22 号那一针疫苗怎么办，后面军训又没空去打，急急急，希望人别有事（--></p>
<!--答疑坊志愿者大群里今晚不是在破防习概写不完，就是在骂数电，果然是贵系大群 2.0（-->
<h1 id="月19日">6月19日</h1>
<p>在食堂听到有人说，不是数学选择它的追随者吗，现在为什么是由这个 sb
强基招生办来选择的，草，<del>你们数学壬怎么无处不在（</del>。很好奇这哥们是被强基坑了没进数学，还是高考生分数高结果一无所知地被放进了致理数学，<del>还是信计的</del>（</p>
<p>我想通了，大作业又不需要交代码，数据都在 Excel 里，那为什么要用
R（。今天筛了筛数据然后把 EDA
做完了，按照预想的手搓模型试了一下感觉问题很大（，那就再简化一下然后在报告里编一个很牛逼的故事掩盖过去吧！大作业怎么样都不可能分数比考试更高，只不过两个都做可以拿加分罢了（</p>
<p>昨晚开始喉咙痛，今天痛了一天然而也没什么别的症状，希望明天没事。借着不舒服和下雨的借口在寝室摆烂了一天，<del>没有贴贴，悲（</del>，还啥也不想干，除了写大作业就是在打桥牌。补了赛马娘第一季后面的
OVA <del>评价是虽然成田大进和 road to the top
里的织姬一样看起来像在突发恶疾，但也比第一季正片好看</del>。想起来当时第一季最后一话也没给我留下什么很深刻的印象，就回看了一遍，<del>果然是比第二季最后一话不知道差到哪去了</del>。怎么说呢，为什么特别周高光的日本杯冲线之前还是要靠看到了观众席上的铃鹿才发力呢，嗯要做成马娘贴贴反而弱化了竞技和取胜的决心，但是这话说得也多少有点
#每日在虚构的故事当中寻求真实感 #每日脑袋一定有问题（</p>
<p><del>第一季的 winning live
也好敷衍，可能主要还是小特不会跳舞，看完去刷了一下第二季和 road to the
top 的最终
live，太烧经费了（。</del>急了，第三季啥时候出，<del>想看悸动战士（</del>。只不过前段时间看一周年纪念短片的时候感觉很不适应北黑和钻哥长大的形态（，可能第二季两小只看多了觉得应该就是那个体型（</p>
<p>绷不住了，今晚不会要通宵学测量吧（</p>
<h1 id="月20日">6月20日</h1>
<p>昨晚真通宵学测量了，还是发着烧通宵，草。没学完，今晚可能还得继续。测了两次抗原也没测出来阳性，<del>再测不出来都要退烧了</del>，都这时候了我还没能拥有一支属于自己的两条杠抗原，急了（这是在急什么（。吃完午饭想冲一杯感冒冲剂喝，脑子完全不在线最后把挂滤包扔掉的时候才意识到冲出来了一杯咖啡，反正看着也差不多，就这样喝吧（（</p>
<p>晚上下楼拿外卖，遇到一个姐姐一直盯着我看，然后她跟我打招呼说一直都觉得我很眼熟（害怕），问我是不是
efz
的，还精准说出了我的班级，这下校友相认了（。高中的时候有一年教室是和她们班在同一条走廊里，我当时确实也脸熟她，但是今天属实是一眼没认出来，感觉变化很大。然而她说我看起来没什么变化，明明今天因为生病披头散发还戴了口罩，怎么会这样（</p>
<p>前天 One Last Kiss 就听到 5000+ 了，只是一直忘记写。今天想起来去
bangumi 上把我的第一个 10
分给了这张专辑，肉眼可见的未来里我不会给任何一部番打 10
分，如果真香了那更值得庆贺。<del>实际上 EVA 全系列我给的都是 9
分，其他的 9 分好像也就是 Fate/Zero 和赛马娘第二季，但是 One Last Kiss
给了 10，然而喜欢 One Last Kiss 非常大程度上是有 EVA
加成的（，怎么会是呢。</del>所以啥时候入一张实体专辑呢（</p>
<blockquote>
<p>我评分的颗粒度还挺大的，还行是 7 分，不错是 8 分，很能打动我是 9
分，One Last Kiss 是 10 分（</p>
</blockquote>
<p>本来想给 Pop Virus 也打 10 分，最后还是给了 9，如果能给 2019 Tokyo
Dome live 评分的话当然会是 10 分，专辑反而不太能给，Gen
桑你好神奇（。想在 bangumi
上评分（或者说展示在主页上）的音乐大概也就这俩了，这两张也是截至目前仅有的想买实体的专辑，当然
Pop Virus 的话实际上想买的是演唱会的 BD（</p>
<blockquote>
<p>群友：你不是学过 measure theory 了吗，怎么会学不会测量学呢（</p>
</blockquote>
<p>measure 和 surveying 还是有很大差别啊x</p>
<p>回看了一下 road to the
top，之前光盯着织姬和成田路看了，二刷才发现制作组表面让成田路当主角，实际上是好歌剧厨，好多镜头都太帅了（。之前读过好歌剧的原型故事，感觉在赛马娘里面有点弱化了，第一第二季当背景板，第三季既然是北黑主角那更不可能有，road
to the top 里截取的也是好歌剧刚出道的时期，真想看到歌剧王的时代啊（x</p>
<h1 id="月21日">6月21日</h1>
<p>土木这专业怎么还不撤销啊？昨晚看测量学仪器校准的部分，完全不理解，上
b 站找了个不知名学校的辅导视频看懂了，在华子学这玩意大专都不如。</p>
<p><del>两天没贴贴了，今天贴了个爽（啥。</del>前两天以为是身体不舒服和没有贴贴的原因学不下去，今天才知道没啥关系，这玩意学不会就是学不会（</p>
<p>比起这个，今天看了一点点 local
CLT，之前因为课上不讲又是打星号的就先跳过了，深刻地感觉到几天没看数学人都变笨了。在想军训不知道强度怎么样，强度不大的话晚上回来在床上读读
Munkres 也好，读不动的话水一水 M.Ross
也好，这两本在我床上放了好久了也没怎么看过偶尔还当枕头（，能稍微动动脑子就挺好了。实在不行这两天刚买了本金阁寺，早就想看但是一直没看，能读读也不错（（</p>
<h1 id="月22日">6月22日</h1>
<p>打完了最后一针 hpv
疫苗，胳膊好痛，但总算结束了一个漫长的破事（。不知道是不是今天端午节的原因，明明第二针的时候有好多人排队，今天除了我就两个人来打，成功速通了（什么这也要速通</p>
<p>是和友人一起去的，顺便看到了北大的军训安排，太水了吧，<del>当初怎么没去隔壁（</del>。说到这个其实是高一的时候教练把我推到了华子数学系的飞测而不是隔壁数院的飞测<del>（废话自己什么水平还没数吗</del>，很意外地笔试面试全过拿了个约
<del>然而也没进队没能兑现，强基时代之后好像也直接作废了</del>，从那之后就死磕华子了，不然我肯定会选隔壁
<del>然后考败去交</del>。甚至填强基志愿的时候，当年北大的笔试改成了只考语文数学而华子数理化都要考，显然我更擅长前一个，要不是华子给了
A+
评定就真把志愿改成北大了。<!--草，其实也因为 ex CCHO 之后签的是北大的约，报的也是北大，绷不住了--></p>
<p>谢谢唐老师，虽然我高一的比赛除了联赛之外都丢大人<del>（联赛也只是没那么丢人而已，高二比高一还丢人）</del>但他还是把我推上了飞测，<del>不然就遇不到欧老师了（x</del></p>
<!--真去隔壁了的话说不定就不会和 ex 分手了（，也不好说，一个人的命运当然要靠自我的奋斗，但也要考虑历史的进程.jpg。然而在你沪没牌的话强基进北大和进华子根本不是一个难度，我感觉我是不太行，搞不好真考败去交然后和 eex 大眼瞪小眼了（，听起来都不是什么好事，谢谢唐老师（二度-->
<p>这百京怎么会这么热的，打完疫苗回来的路上胳膊又疼又热得一身汗，<del>贴着友人睡了一路还是好累</del>，真绷不住了，回来先睡个觉然后起来通宵抢救明天的
<del>记忆力大赛</del>
测量期末。我军训必表演一个全连第一个倒下（<del>全连？什么全连（音游人并感</del></p>
<blockquote>
<p>挂不至于</p>
<p>lz 上次非常自豪的和我说 如果你作业每次都交了认真写了的话
考试没及格他会把你调到 1.3 所以“完全不用担心”！</p>
</blockquote>
<p>说实在的这课我真就是以不想挂科为目标，背书的时候每一个脑细胞都在抗拒真的去记住这些东西，听到这话反而是真的不担心了。我土水学院的课到现在加起来均绩可能也就
3 刚出头，之前大家说水利系养老均绩 3.5
什么的我还很惊讶，现在感觉大家未必是真在养老，而是这破地方给分就这样。</p>
<p>随机到<a href="https://music.163.com/#/song?id=537854741">心拍数#0822</a>的时候听到开头的几声鼓点，第一反应下一句应该是“There
once was a ship that put to sea, the name of the ship was the Billy of
Tea”（出自 <a href="https://music.163.com/#/song?id=1813960297">Wellerman</a>），脑内都已经唱出来了，结果出来的是鹿乃的声音被吓了一跳，草（</p>
<h1 id="月23日">6月23日</h1>
<p>测量学考完了，感觉大概能和体育课差不多水平，别无所求（。下午把线性回归大作业报告也水掉了，这个从后半段开始就痛苦无比（指学业和气温）的学期总算结束了，<del>可以毫无负担地贴贴真好啊
qwq</del>。然而气温的痛苦远没有结束，能休息的也就一天半，后天晚上军训动员会大概就是新的噩梦的开始（。考测量学之前那么痛苦也有一想到之后要军训就破大防的原因，真的能活下来吗（</p>
<p>晚上补了补觉，<del>其实是不知道为什么就睡着了（</del>，想接着往后读鞅论，军训之前能不能把这一章看完<del>（做梦</del>。怎么说呢，不知道为什么这个东西我学一遍忘一遍，每次都要从这一章最开头看起才行，感觉是例子见得不够多<del>简称就看了概念和定理，习题没做完（</del>，分析味也没前几章那么重，总之确实比较独立一点（</p>
<h1 id="月24日">6月24日</h1>
<p>四教三楼有个神奇的沙发，每次路过想稍微坐一会都会莫名其妙地睡着，醒来发现
1h
过去了（。主要它真的很舒服，坐在最边上睡的话可以把头靠在侧边或者后面（<del>是不是平时趴着睡太多次了所以偶尔换个姿势就觉得不错</del></p>
<p>晚饭的时候突然流鼻血，第一反应是怎么没在军训站队的时候流，那才节目效果拉满（。太热了这个百京，这几天看到路上穿学士服的学长学姐感觉真的好强，是我的话这个天气大概根本就不参加了（<del>等等我还有三年才毕业为什么会想这个</del></p>
<p>感觉今天是真正的暑假，一边学一边贴贴（，给 Durrett CLT
那一章收了尾，没想到 Poisson convergence 和 Poisson process
会放在这里一起讲，尤其 Poisson process
那里还挺绕的，<del>随机过程也没我想得容易嘛</del>（草（#每日举例帮助理解但例子比理论更难理解，不过还是学到许多。<del>鞅论，什么鞅论，我没说过军训之前要看完这种话</del></p>
<p>寒假刚回来的时候就说要去换身份证，但一直懒癌发作拖到了现在，也是因为中间有几次需要用身份证的时候（去国博和打疫苗什么的），而且也并没有立刻到期。顺便还想重新拍个照片可能需要剪下刘海什么的<del>（为什么刘海不能过眉啊，我这几年从来没有过这种时候（</del>，就一直拖着。周五在答疑坊志愿者群里看到有群友问才想起来这件事，又突然克服拖延症想暑假回家之前办好（。本来想着既然周末户籍办不上班那就要军训结束再去了，后来想起来明天是端午调休补班，也稍微降点温了，运气不错，这样明天去了大概下周就能拿到（</p>
<h1 id="月25日">6月25日</h1>
<p>来回骑车十公里去换了身份证，在北四环中路差点被一排靠边的公交车夹在了自行车道上，感觉上还蛮恐怖的，早知道在没什么人的人行道上骑了（？）。然后拍出了人生中最丑的一张照片当证件照，真绷不住了。昨晚特地下了个小红书看有没有拍身份证证件照的时候保留刘海的，看人家都是既可以披肩发又有刘海，带着一丝侥幸去了中关村派出所，结果我照的时候连双马尾都不让扎，让我必须把头发盘起来放后面（</p>
<p>最要命的还不是刘海必须夹上去，而是工作人员跟我说平时留刘海的话最好夹一半上去留一半，露出眉毛就可以，最后拍出来一张很逆天的日本古早电视剧式空气刘海，好崩溃（</p>
<p>还是想保留原来的身份证，就直接说了挂失补办而不是续期，多交了 20
块钱（。新的身份证上户籍地址就是清华园 1
号而不是济南市中区了，毕业后大概会按华子本科毕业生的绿色通道直接把户口迁去上海，拿到二十年来从来没拥有过也险些因此没能在上海高考的户籍<!--，其实初三的时候连镇海中学都已经联系好了，差点就要去宁波读书，还是因为蹭到了我爸当时是博士后流动站在站人员，子女可以在沪高考这个奇怪的政策。我迄今为止的人生就是一个 Markov chain 引向的结果，中间哪怕一个环节有变化都会天翻地覆-->。感觉上是永久地和家乡切割了，只不过哪怕是想回去也早就没有可以去的地方，身份证号也是浙江的，户口在入学的时候就已经迁到了学校里，身份证上这个地址也只是最后一丝联系，如今也不会再有了。</p>
<p>办个身份证和邮寄加起来花了
55，太恐怖了，这个月从买军训的衣服开始就彻底超支到了一个从来没到过的水平（</p>
<p>收拾了一下午寝室，其实早就想收拾但是没军训这个由头实在懒得动（，大概东西实在太多了，收拾一下反而找到了很多神奇的东西（<!--包括但不限于，买来想着去北大新生舞会的时候戴的配饰结果舞会前突然被 ex 甩了所以完全没用过就塞起来了（（，前两学期的排名成绩单，虽然去年评奖学金大失败之后我就懒得关心排名了，出国也不看，就没打上学期的排名，但是今天找到了之后出门还顺便去 C 楼打了上学期的，仍然在 50% 左右晃悠，这院系真离谱啊（--></p>
<h1 id="月26日">6月26日</h1>
<p>军训第一天，读完了《金阁寺》（</p>
<p>上午为了对抗困意读了几章，最后还是绷不住想睡了，搁那儿努力揉眼睛结果把防晒霜揉到眼睛里去了，好痛（。昨天就收拾了寝室所以下午没啥事，配着
Mili 的《Dandelion Girls, Dandelion
Boys》读完了<del>然后大睡一觉</del>，还挺合适的。</p>
<!--来点忘记写的滑梯：-->
<!--某志愿者群：-->
<!--A：我还以为让致理数学这哥们上去讲是要说他想研究纯数搞基础学科报国，结果他的家国情怀是数学辅修经济（-->
<!--B：你说领导会不会一开始也这么想结果没嘱咐他就说歪了（-->
<!--综体是没有网吗（打开 wifi）《___上有狗叫》-->
<p>之后可能没这么闲但是感觉藏书还够（</p>
<p>教官挺佛的，隔壁班教官明明是华子的退伍军人还训得巨狠，乐（。感觉军训就没啥写的，洗洗睡了（</p>
<!--好像也没强调一定要穿深色袜子但我也没有白色以外的袜子（，我们教官似乎管的也不严但是隔壁班一直在强调这个，哪天非要穿的话我只能在里面套黑丝了（？？？-->
<h1 id="月27日">6月27日</h1>
<blockquote>
<p>好消息，数值模式对京津冀本周后期的高温预报有所调弱，调弱到42度。——<a href="https://weibo.com/1763864272/N730E8yMS">中气爱</a></p>
</blockquote>
<p>本来想放 b 站链接的，结果发现中气爱有些条目在空间发但是不在 b
站发，只好放了个微博，怎么会事呢（</p>
<p>早训感觉莫名的轻松，结果齐步走走到树荫外面才意识到是因为一直站在树荫里没有被晒到，还好教官比较善良，带大家光速退回了（。<del>早训完还有贴贴，真好啊</del></p>
<p>用课程替代查完成绩之后顺便想着用一下它原来的功能（，就试着提交了一下用概率论
1
替代培养方案里的工科概率论。理论上来说这课上学期不明不白地就被（非疫情原因）PF
掉的初概替代了（看成绩单里初概是限选），结果审批通过了。这是否有点问题，教务你在干什么啊教务（<del>也可能是我院教务的正常水平吧</del></p>
<p>开始读点集拓扑，说到底这些东西应该数分里都学过了才对，是在预习，但是没在预习（。下学期不知道数学课能不能顶得住，感觉一学期四门还要加一个运筹的话属实很难说<del>（绷不住了，第一次接触
OR
居然是建管交通方向的必修）</del>，顶不住的话最先被退掉的肯定是拓扑学，最优先被保护的大概是概率论
2 吧（</p>
<p>看着看着点集拓扑就打开了芦毛灰姑娘，怎么会事呢，期末周结束了也还是凉性循环吗（</p>
<!--我还以为皇帝的人设就是慈爱老父亲，没想到在漫画里还凶小栗帽和训练员，看来只有对帝皇是慈父形象（（确实是父子啊x-->
<h1 id="月28日">6月28日</h1>
<p>逆天，上午下雨所以训练到一半把大家带进北体育馆拉歌然后开演唱会，把我们教官给整社恐了，全程在后面摸鱼（</p>
<p>坐在北体的时候我左边的哥们是 CCHO Au，后面的哥们 CPHO
Au，斜后面的姐们 NOI Ag，这里就我最菜了.jpg <del>但是经过提醒 CGMO
的牌也是牌，于是愉快加入了谈话（心虚</del>，一起聊了半个小时竞赛的一些滑梯。都要大三了还在回忆竞赛生涯，看来确实是无聊到了一种程度（</p>
<p>所以这里是致理还是未央，哦我们四个是一个班的啊，那看来是未央（（</p>
<p>来点全寝室睡了一下午之后室友锐评军训：</p>
<blockquote>
<p>军训的作息应该 12
小时为一个单位，一次睡五到六个小时，然后吃一顿饭起来训练一次，回来洗个澡再吃点东西</p>
</blockquote>
<!--在想要不要参加定向越野，手册里说有心脑血管疾病的话不要参加，我血压高，心率也有问题，如果不算进成绩的话真的不想参加。但算进军训成绩的话又觉得很亏，完全不参加没有这一部分成绩，那还不如直接申请半训，成绩估计也差不多还轻松很多，感觉有点清人鬼。-->
<h1 id="月29日">6月29日</h1>
<p>摆烂，看芦毛灰姑娘（</p>
<!--之前没怎么认真看过漫画，主要是觉得黑白漫有点伤眼睛，唯一一部看过的是~~被 ex 甩了之后看的~~《恋如雨止》。芦毛灰姑娘的优势大概是篇幅长，看起来是要把小栗帽的所有比赛都画出来，隔壁帝皇就因为篇幅和剧情安排原因舍弃了日本杯复出夺冠，惨惨。只不过看小栗帽从笠松到制霸中央比赛的过程多少也是看到了点从郊县初中升学到 efz 的自己（（什么东西-->
<!--15 话神回（-->
<!--汉化组厨力溢出了（-->
<!--但是跑步开领域特效属实是有点尬（（-->
<p>军训的场地就在快递柜旁边，然而有一个快递到了三天都不记得去领，每次解散就开始往回跑，乐了。</p>
<p>新的身份证到了，感觉彩色的照片倒也没那么丑了<del>甚至还有一点可爱（，只不过发型轻微有点奇怪而已</del>，上次在派出所看到的是黑白的所以稍微有点崩溃。只不过黑白的看不出黑眼圈，彩色的就挺明显的，很难绷（</p>
<p>和几年前拍的身份证照片对比了一下就显得更好看了（，看起来胖了不少，总之脸变圆了，闻道日肥（</p>
<p>拍给友人看之后她的锐评是，拿到北京的 F-1 签证了啊（。草，就要个 F-1
签<del>留作纪念</del>就行，百京的 H1B 就算了（x</p>
<!--一个挺有意思的事情：户籍地址是清华园 1 号，后面还有一串神秘的六位数字，恰好是我高中的班号加学号（-->
<h1 id="月30日">6月30日</h1>
<p>单人定向越野的时候悟到了莫名其妙的东西，一边走一边用手机在备忘录里敲了下来：</p>
<blockquote>
<p>我的人生就是军训定向越野的一些证据：</p>
<ul>
<li><p>和五分之一的人拿着一样的地图</p></li>
<li><p>拒绝了一些组队邀请之后就不再有人找我组队了</p></li>
<li><p>一个人走全程（不至于，不至于x</p></li>
<li><p>没怎么思考所以没有规划，到处绕路</p></li>
<li><p>反复走回头路</p></li>
<li><p>不想走人多的地方，但是能得分的点都人很多，每次还是只能靠过去</p></li>
<li><p>拿了个差不多的分就开始摆烂</p></li>
<li><p>很困很累</p></li>
</ul>
</blockquote>
<p>建议搭配一些 neruko 老师投喂的<a href="https://mp.weixin.qq.com/s/ylB_RwcXnaJRZmb1jLuBNg">定向越野鸡汤</a>（？）使用（</p>
<p>本来这个月月底都不敢看账单了，结果今天课咨委的补贴终于到账了，直接收支平衡，太好了。<del>攒钱要开源节流，节不住流的时候只要入账够多也不是问题（（</del></p>
<p>上次在文艺晚会之类的场合看到大型的悬臂式摄像机（实在不知道这玩意应该叫什么）还是在
CGMO
的开幕式，而且似乎只有树德中学有过，<!--绷不住了，我想了半天第一次参加这比赛到底是在成都的哪个学校，肯定不是成外，似乎也不是成都七中，查了一下才想起来是这个。这啥学校（-->现在想想不到两百个人参加的场合有必要吗（。灯光师高兴的时候就打光让我看两眼拓扑，不高兴就直接目害，手机还差点没电，感觉是军训到现在为止最痛苦的一天（</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇十一·23年7月</title>
    <url>/2023/07/01/Diary-2023-07/</url>
    <content><![CDATA[<p>恭喜日记篇数进入两位数时代（</p>
<span id="more"></span>
<h1 id="月1日">7月1日</h1>
<!--草，昨天忘记发癫了，线性回归居然给了我 A-，我超，太知足了，大作业才 80 分（。这课是真的上不动，时间安排在上学期最缺少贴贴的周二（，上到后来也和我的期望偏离得越来越远。之前还在想我数学课除了微积分 A2 之外还没有不是 4.0 的，别被这破课给背刺了，后来又想万一被背刺了的话我只要不承认它是数学课就好了（，感觉也确实很难说是（（-->
<p>上午晒了 3h 感觉真有点中暑，上次中暑还是 2019 CGMO
的时候，<del>当时好菜（</del>。睡了一下午，今天训练结束之后寝室里每时每刻都有至少两个人在睡觉（（</p>
<p>待会拉练，希望人没事。实在不想带自己的被子，找了个不用的被罩里面裹了个枕头蒙混过关，别散了啊（</p>
<p>来点室友名言：你别去按照那个教程学是怎么打的，看一遍就行了，然后自己凭感觉打三横加两竖，肯定能打出来（</p>
<p>她是对的（</p>
<h1 id="月2日">7月2日</h1>
<p>拉练，然后摆烂（，拉练出发之前和结束之后都有短暂的贴贴，满足了（</p>
<p>从我高中军训的时候就在听我那位华子毕业的总之好像是什么状元的班主任满怀自豪地反复讲述他们当年背着被子走了
20 km
的事迹，那个时候就已经开始为拉练这件事情烦躁。虽然也不是保证能考到华子但是反正上交也有拉练（，入学之后军训又推迟了两年，整整为此烦躁了五年。</p>
<p>前一个小时还能和何老板以及班里那位 CCHO Au
的哥们吹水，顺便听二位讲了讲投行实习做的事情<del>以及他们的感情状况，学到很多</del>，最后一个小时的时候开始逐渐和何老板掉队到后一排排尾，虽然还是在吹水但是频率和音量都低了很多（。毕竟是整个营的末端了，我在哪队尾就在哪，不妨碍后面的人行进，所以也没急着追。队尾的几个老哥大概也都是这个心态，一起摆烂了，还遇到了从上一个连掉队到我旁边的室友，蚌（</p>
<p>起来之后在楼道里听到有人打电话，说“哎呀人哪能要求十全十美呢，找对象看中对方身上的一些优点就可以忽略别的一些缺点了（大意）”。纯爱战士在心里默默点头正准备满意离场，结果听到她的下一句是“但是对我来说对方长得帅是最重要的，如果很帅的话哪怕有其他的一些问题我觉得也可以原谅<del>（因为被震撼到了所以完整地记住了原文）</del>”，草，怎么会是呢（</p>
<!--想了想还是不如何老板抽象（，拉练全程印象最深刻的一句话大概就是他说“这是我的第三次初恋”了吧（（（-->
<p>下午和晚上终于看完了 Munkres
上每本数学书都有的但我好像从来没学扎实过的集合论和逻辑（，跑步进入大家已经在数分里学完了（不太确定）的点集拓扑。给我的感觉就是贵校数学系在数分里面把什么都学完了，听说宗学的点拓只上七周，大概还是得自己赶一赶，没学过数分的我只能度过一个相对失败的人生（。在教学楼关门之前终于写出来第一节最后一个定理证明跑路了，虽然还是比预期的时间晚了
20 min，但总之是好的（</p>
<p><del>命运/好怪 很假</del> <a href="https://bgm.tv/subject/402128">Fate/strange Fake -Whispers of
Dawn-</a>
终于放送了，<del>急急急，我已经迫不及待想看宝具对轰辣（</del></p>
<h1 id="月3日">7月3日</h1>
<p>好困，感觉没啥可记的（</p>
<p>两门上次没出成绩的课到现在也还是没出，真就拖到 ddl
再给我一拳是吧（</p>
<!--也懒得算了，这两门加上军训可能绩点还得掉个零点零几，无所谓，掉不下 3.8 就还好（-->
<p>下午贴了 1.5 h
回来之后发现三个室友都还在睡觉，明明是差不多时间上床的，草（。晚训完也贴到了，只不过能不能只贴不军训啊（（</p>
<!--原来 Bowen L 的 npy 是隔壁的啊，看他发了毕业照，到底是本科刚毕业还是硕博呢，这关乎这是年下还是什么还是延毕了的问题（x-->
<!--开始给吴昊和杨朋昆写邮件，感觉好难写，要不要附个成绩单呢，但是上的课实在太少了，数分高代也都没学过（，虽然数学几乎都是 4.0 吧但是一门分析都没有，蚌（。急急急，社恐了（-->
<h1 id="月4日">7月4日</h1>
<p>给老师发邮件之前单独列了个数学课的成绩单出来，虽然单算这些的话均绩远高于我自己的
GPA
但还是给我整绷不住了，怎么都是水课，然后才发现我好像是真的没怎么上过非常困难的课（。急了，怎么办，还要不要单列，单列了反而显得很菜（<del>然而还是可以薄纱大部分去统计中心的人，所以先给那边的老师发了（</del></p>
<p>一杯茶一包烟一页 Munkres 看一天（，好绕。</p>
<p>射击搞到晚上九点多，等了两个小时不到两分钟就打完了，麻了。我其实一直有点做不到闭左眼睁右眼，所以打靶的时候左手没扶枪，用来按眼睛了。还是打了
90
多环，虽然也没意义，毕竟不脱靶就有分，所以确实有（一只）手就行（。好像端枪的姿势不太对，后坐力震得锁骨疼（</p>
<p>这个困扰其实物理实验的时候也有，感觉有的时候对焦或者读数看不清，只能左手按住左眼勉强看，不过军训射击怎么就不算一种物理实验了呢（。这里是不是该有个物理实验九宫格（</p>
<p>懒得骂武装部了，累了。</p>
<h1 id="月5日">7月5日</h1>
<p>早训摆烂的时候我甚至躺在树荫下面睡着了，怎么会是呢。只记得有点无聊，然后就躺下了，哼了一会我贫瘠的华语歌歌单，班里一个同学问我在唱什么，我说是《南国的孩子》，给她发了一个我最喜欢的版本。然后迷迷糊糊地就闭上了眼睛，再次有意识就是醒来看到蓝天的时候吓了一跳，好像是第一次躺在地上睡着（</p>
<p>后面又睡着了一次。咋说呢，后两天能不能也继续摆烂，最好还是有时间睡觉（</p>
<p>体验了一天 wake up with no
email（。只不过这个暑假开始磕盐根本不现实，延毕的话确实是一点都不急，找两个老师留个印象，能有点别的指导（？）的话更好。</p>
<p>急了，七月能把点集拓扑读完吗（</p>
<!--习概终于出了，短暂地体验一下 3.88（（-->
<p>所以到今天已经贴了两个月了<del>（虽然今天并没有贴到</del>，不知道为什么给我的感觉是，原来才两个月吗（，<del>是不是每次想起来的时候脑内自动从三月就开始算了</del>（</p>
<h1 id="月6日">7月6日</h1>
<p>听说人在隔壁化院的高中同学已经跟着导师发 Nature
了，而我昨天才刚收到和两个老师约时间聊天的邮件，怎么会是呢（<del>大家都有光明的未来（x</del></p>
<p>到底要怎么样才能把这个 <del>行列式</del> 分列式的 bgm
从脑子里赶出去，循环一天 One Last Kiss 和 Idol
了，晚训还是又灌了回来，急急急（</p>
<p>室友锐评：你这个发型，是不是根本就没打算晚训，想贴到晚上的来着（</p>
<p>还是室友锐评：急了，分列式和现男友以及前男友都站在同一列里，逆天（</p>
<p>来点今晚东操的天空，但是玩闪耀！优骏少女玩得：</p>
<p><img src="https://s2.loli.net/2023/07/06/7t3gPDkaHeMKLBi.jpg" alt="玩闪耀优骏少女玩得.jpg"></p>
<p>你还别说，左边阴影里这个云的分布真挺像的（</p>
<h1 id="月7日">7月7日</h1>
<p>这个 b 军训（，终于要结束了（</p>
<p>没啥写的，今晚就打算开始把之前为了内务检查塞起来的东西摆回原位了。</p>
<!--本来觉得这个月既然要买回家的车票那肯定支出再次爆炸，结果我说下周日回去我妈直接给我订好票了，时隔两年又一次花到了她的钱（，好不熟悉的感觉（（。她大概确实每次都是很急着让我回去，但是能不能回去之后在家里对我稍微好点呢（（-->
<h1 id="月8日">7月8日</h1>
<p>众所周知未央书院只有 14
连（，但这个军训还是从我们被取消评优资格开始乐起来的，好事（</p>
<p>拉练回来那天就觉得四教教室的地面不是很平坦，当时还以为是脚太痛了感受异常（，后面这几天在教室里走的时候感觉确实是不太平，不知道是我的幻觉还是设计师你在干什么啊设计师.jpg（</p>
<p>今天突然看懂了 Munkres
上一个两天前卡住了的反例，然后被自己蠢到。下午课后题卡住想得脑袋疼，结果去吃饭的路上想明白了，再一次被蠢到。军训完第一天的阅读进度大约和之前一周的进度差不多吧（</p>
<p>这书是女生节礼物额度报销的，当时还比较笨蛋，没直接影印电子版<del>（版权意识薄弱.jpg）</del>，原版贵好几倍感觉不太值<del>不如多报销两本书</del>，就买了中译。现在感觉翻译质量也还可以，至少
Hausdorff space 被翻译成了 Hausdorff 空间而不是豪斯多夫空间，点名批评
Stein 中译本的博雷尔集（</p>
<p>最后一次去东操（？）的时候在路灯下面看到个这玩意，我直接一个测量学
PTSD，想起来暑假里有测量实习和地质实习更崩溃了，那不就是军训 2.0
吗。今早还在想防晒霜用不完了，急，现在也没必要急了，实习还得用（</p>
<p><img src="https://s2.loli.net/2023/07/07/jVBOdTR8t7owSGh.jpg" alt="水准尺.jpg"></p>
<p>（这个东西叫四等水准尺，确定地面高程用的（（说不定测量实习的时候会在学校里用到它，绷不住了</p>
<!--手机之前为了一些用途设了拍照 5 秒倒计时（（，拍这个的时候快要集合了结果还等了个倒计时，急急急（，上次拍刺猬的时候也等了五秒，还好它爬得慢（-->
<p>第一次大概也是最后一次用宿舍楼里的洗衣机是今天把军训的东西全部扔进去洗。本来还觉得问题有点大，这身衣服坐完东操坐北操，万一楼里有别的年级的人洗自己的衣服岂不是（，结果室友表示没啥问题，可以我先洗她再洗然后加消毒液空转一圈，让我不用有压力（。既然你们天天用洗衣机的人都这么说了那就
ok fine（</p>
<h1 id="月9日">7月9日</h1>
<p>没有学期中间乱七八糟的作业，Munkres 的 solution manual
不如直接在手机上用 solverer 平替，解脱了，不用天天带电脑了。</p>
<p>睡得很晚但醒得很早，早晨突然有个高中有一阵子聊得很多的群友给我发消息，说最近看了天之杯之后想入坑
FGO，太恐怖了，我光速劝回（。Fate 系列的动画也好，FGO
也好，如果到现在完全没接触过的话还是别入坑了（只不过 FZ
还是值得一看的），但是如果都坚持看/玩到现在了的话就有一种必须要继续下去的感觉（。柯南剧场版好像也是这个道理，这些东西怎么都除了画质之外越做越烂（</p>
<p>看了眼今天上海最高温 29
度，本来觉得没啥，又看了一眼早晨下过雨之后空气湿度 100%，那体感不得 40
度，草。下周回家估计就已经出梅了，一时不知道是湿热好还是干热好，虽然出梅了也肯定比北京湿，急了。</p>
<p>中午骑车路过地质大学的时候看到一堆人扛着三脚架和全站仪往里面走，急了急了急了急了别提醒我暑假末尾还有个测量实习这回事了。旁边一条路的围墙上写了各种高中自然地理小知识，如果我还是个高中生的话会很感兴趣，但我现在在读这个
b 专业所以看了只觉得好崩溃（，这下又过期 jk 了。</p>
<p>荷清路比学堂路好走一万倍，没有意义不明的上下坡</p>
<h1 id="月10日">7月10日</h1>
<p>军训第一周在北操被不知名虫子（首先排除蚊子）在手臂上咬了几个包，后来不知道是过敏还是又多次被咬了，逐渐蔓延到了两条手臂上都有好多，抓起来的时候看着还挺吓人的。本来还觉得应该排除点别的原因，但是室友和她们班的一个同学都是和我一样的症状，大概就是军训的问题。要不要去校医院看一下呢，要么直接回家去华山医院看吧（</p>
<p>认识硕哥还是四月底的那个推研转系讲座，当时就跟他说期末考完去找吴昊，他还劝我越早越好<!--，还在闭社把我的盒开了（-->，五月的时候还给我推了吴昊组里一个学姐的微信。说起来这一通操作下来多少有点不去也得去了（，我清楚地记得是一节测量学的课，旧水的空调开了和没开一样，课也不想听，然后他突然来和我说吴昊组里有个想要学妹微信的学姐（）的时候真有点社恐地狱。总之我一直把这事咕到军训之后，今天才去。</p>
<blockquote>
<p>数理基科是学物理的吗，你是致理书院的吗？</p>
<p>哦哦，啊这，未央是什么（</p>
<p>数分没学过问题不大吧，你概率论 1
不也撑下来了，后面的课程里遇到不会的随时补就行。其实按这个来说你已经提前体验到科研的状态了！</p>
</blockquote>
<p>难绷（</p>
<p>下个学期可能有必要把概率论 2 和 3 一并上完，据说是必要的基础（，而且
3 只有秋季开课，错过等一年，2
是两学期都开然后进度上有一个章节的区别。<!--其实和 cm 说的不太一样就是了，无所谓了。吴昊的意思是要出国的话功利上讲最好别跟她科研，要么去统计中心，要么跟顾陈琳，她这里方向太基础了不可能有文章。只不过现在概统都这么卷了吗，急急急，我就想有个学上罢了。-->那就要退掉
ODE
和拓扑之一，感觉大概率是后者，<del>宗学年年都有，而台湾腔不常见（</del>，这样的话最近把
Munkres 第二章看完当做补习数分，然后就可以停下来换回 Durrett
了。今天顺便还偷跑到了吴昊概率论 1 和 2 的纸质版讲义，概率论 1
的部分好像是她下学期要用的，虽然我翻了一下感觉就是 Durrett
的精简换序版，然后把习题都换成了丘赛题，<del>双厨狂喜（你都厨了些什么东西（</del>。</p>
<p>下午到得比较早，在静斋转了两圈，看到二楼走廊尽头有一个开着门的巨大的办公室，里面还有小隔间，还以为是研讨间之类的，想着如果没人的话可以先进去坐一会<!--，总比站在走廊里好，如果今天不是躲得快的话，我和吴昊的初见就不是在她办公室而是在三楼的女厕所里了，真绷不住了-->。结果凑近一看门口的名牌是
Shing-Tung Yau，绷不住了（</p>
<p>顺便还看到了刁晗生的名牌，高中的时候就经常听教练念叨他，<del>怎么不算师出同门了呢（（别丢人了</del>。之前环友发过李思门口的抽象画，今天看到了真迹，很生草，虽然但是到底为什么要贴在门上，我还是更能理解王浩然把《达拉崩吧》的歌词贴门口（</p>
<p>说到推研转系讲座就想起来，军训动员会的时候梁曦东说“大家入学的时候专业是限定的，大二结束选导师的院系/专业范围就会扩大很多，等到推研和做研究几乎全校范围内都可以选，范围是越来越广的（大意）”。我就不明白了，这个宽窄的顺序完全反了罢（</p>
<p>开始玩 Disco
Elysium。暑假回家的一个月除了去拔智齿之外其实就三件事，监工家里的装修顺便跑几趟宜家搞软装，稍微学点数学，精神损伤的时候
Disco Elysium 启动然后加重损伤（。本来是想 Death Stranding 和 Disco
Elysium 二选一的，后者比较便宜/夏促力度更大/更感兴趣就先买了。</p>
<p><del>（Death Stranding 在愿望单里主要是有 Pop Virus
的加成，是的我是来听歌的（</del></p>
<h1 id="月11日">7月11日</h1>
<!--今天突然想起来，我怎么连把遮阳伞都没有。然后死去的记忆开始攻击我（，以前买过一把[凛的周边伞](https://mall.bilibili.com/detail.html?#itemsId=10053664)，21 年暑假借给 ex 用了一阵子，但不知道为什么他一直没还我，直到突然被分手都没还，我还一直都把这件事忘了，莫名其妙过了两年没遮阳伞的生活。急急急，现在去要回来还来得及吗（悲（Rin 我的 Rin，这伞真的好看，急急急急急急-->
<!--7.12 UPD: 怎么会是呢，今天手里这把雨伞真的坏了，伞柄掉了（。最崩溃的是这发生在 ypk 和我一起下楼吃饭的时候，我撑开伞结果把伞柄拔掉了，好社死。也勉强还能打，再凑合两天，回家拿一把晴雨两用的来吧（-->
<p>吴昊讲义上的 P 和 E 全都是 mathbb，舒服了（</p>
<p>Munkres 第二章结束了，把吴昊讲义的概率论 1
部分走马观花复习了一下，好崩溃，这才过了不到一个月有些东西印象就有点模糊了。这个时候就要安慰自己，<del>没事，抽代我更是忘完了，</del>概率论
2 也不是很分析，别管那么多接着往后看就是了（</p>
<p>晚上回寝室开答疑坊，给正在被小学期暴打的室友讲了会傅里叶变换和卷积。实际上傅里叶变换我真的已经忘完了，上次接触还是求特征函数，感觉也不太涉及什么分析性质，今晚一边看讲义一边现学现讲的（。看了看大作业要求给我整绷不住了，这真的是能用
MATLAB 写出来的东西吗，希望人没事（</p>
<p>开完答疑坊就开始开理发店：</p>
<blockquote>
<p>室友：哟你这个戒指挺好看的</p>
<p>我：（中二发作）其实这是爱因兹贝伦家主的证明，圣杯战争就要来辣<del>（室友也是月厨所以发癫也没问题</del></p>
<p>室友：别中二了，这是个对戒吧</p>
<p>我：（</p>
</blockquote>
<h1 id="月12日">7月12日</h1>
<p>猫超的老酸奶真好吃，<del>请年轻酸奶在老酸奶陪同下观看（</del></p>
<p>今天去和 ypk
聊了个天<!--，是不是华子的年轻 AP 们大多照片和实际不符，我看他统计中心官网的照片还蛮帅的（，现实里要胖一圈（（-->，聊到饭点还一起去玉树吃了个饭（，稍微有点社恐地狱，不过算是个好的开局。然后被丢了一个
linear regression 的问题和一篇 paper
读，可能是数学书看多了吧，我反正觉得 90
页是一个，非常非常庞大的数字，不知道要读多久。下午简单翻了一下感觉
notation 都不是很熟悉，不知道要额外多看多少 paper 才能看懂，急急急（</p>
<p>虽然我感觉一上来聊天的环节里他像个留学中介一样（，还问我有无 dream
school，我随口说了个感觉 UMich
这样的就挺好的了，他问我为啥，我说因为我喜欢比较冷的地方，给他整不会了（</p>
<p>来点乐子：</p>
<blockquote>
<p>吴昊我认识，她的方向好基础好难（</p>
<p>既然要延毕的话可以再课业为主一个学期，下学期把随机过程和随机分析学了是好事，听吴昊的，不急（</p>
<p>所以未央书院是学什么的（<del>太经典了，每个老师都要问一遍</del></p>
<p>那你们书院的同学是不是有好多想转 CS 的（</p>
<p>我发现学数学的同学好多都不喜欢统辅课</p>
<p>“找不到喜欢什么的话可以先排除不喜欢什么”“我不想写很多代码”“你们学数学的同学怎么都这么说”（</p>
<p>那你当初为啥不去北大数院呢？（</p>
<p>一到暑假清芬三楼停伙我就不知道该吃点啥了，你有什么推荐吗（<del>清芬战士喜加一</del></p>
</blockquote>
<h1 id="月13日">7月13日</h1>
<p>有个高中同学毕业之后把我 QQ
好友删了，后来又给我发了几次好友申请，每次我都直接无视，今天又来一次。不知道为什么这么执着，我又不欠他钱（，也不是很想加回来，但还是担心万一是有什么事情，就回了一句如果有事情可以加我微信说，然后给了微信号。结果他也没加，我不理解（</p>
<p>后来一想应该是删好友的时候自动拉黑所以也收不到消息了，<del>那太好了正好我其实也不大想加他微信</del>（</p>
<p>中午雨正大的时候在双清路上被一个逆行的外卖骑手创了，没摔倒的代价是把车和伞扔了出去（？），人往另一边撤然后就顺利站住了，现在想想也有点想象不出来这个动作，不过没摔就好。然后发现右手大拇指指甲盖里在流血，也不太懂是为什么，不过也是小事。又骑上车之后觉得雨天单手打伞骑车还挺危险的，在学校里倒还好反正整条路都是自行车道（，在外面尤其是右手还一边扶车把一边拿着手机看路线，遇到突发情况刹车都很难，路又很滑。</p>
<p>好像问题在于我不想用导航模式，每次都是自己看着地图走，不然其实可以直接听语音导航，也不用一直拿着手机还时不时要看两眼。说实话自己看地图还经常不慎走错和绕路，也没什么好的，但就是不想换（</p>
<p>最近在大力 Disco Elysium，现在进度终于到 Day 3
了，不知道啥时候才能完成一周目，但是感觉
<del>相比于刚开始玩的时候开个灯就能把自己整去世来说</del>
还算顺利。也有幸（？）在 Day 2 就看到了这一段名场面
<del>然后就昏了过去</del>，吸引我入坑的 Dora's letter:</p>
<blockquote>
<p>Harry, I wanted to write you a letter, so you can read it when you
wake up. Maybe it will make you happy.</p>
<p>Every morning when I step out and you're asleep behind me, I find a
little piece of sadness in me. I carry it in my chest down Voyager
Road... Every step I take, it grows. By the time I reach the fuel
station it has filled me entirely. I step on the light rail and look
back, sparks fall from the bow collector.</p>
<p>I know it will be like this until late afternoon, when I get off the
42 -- and walk back to you... You, you... Every step I take will get
lighter. It almost makes me run! Sometimes I do.</p>
<p>I can't believe I met you. I can't believe the happiness I feel with
you. You have a vast, vast soul and I will always, always, always come
back to it. Kisses, kisses, kisses.</p>
</blockquote>
<p>不知道为什么（？）好困，感觉能早睡（</p>
<h1 id="月14日">7月14日</h1>
<p>早上双人成行，晚上去情人坡看星星，回寝室极乐迪斯科启动，如果不是中间在学概率论的话真有暑假那味了（</p>
<p>越学概率论越急，之前一直看不太懂
upcrossing，今天发现后面有个提示说看成和买股票一样，规定小于 <span class="math inline">\(a\)</span> 金额时买入，大于 <span class="math inline">\(b\)</span> 金额时卖出，只要存在 upcrossing
就一定能赚到 <span class="math inline">\((b-a)\)</span>
的钱。联想到一些，高考完赚了点小钱之后买的已经砸在手里的基金<del>（也不至于，总体还是赚的，全靠纳斯达克撑着（</del>，完全理解了，<del>是不是因为我一直犯懒只设定投然后就变成了现在这个样子</del>（</p>
<p>观测到了夏季大三角，在 Stellarium 上看织女星的时候第一反应是 Admire
Vega，玩闪耀！优俊少女玩得（</p>
<h1 id="月15日">7月15日</h1>
<p>在寝室收拾行李和打扫卫生，明天就回家了。事实上今天快到中午才起床，一个室友比我还晚起来至少
2h，怕收拾东西吵到她而且不能开灯，干脆极乐迪斯科启动（。之前大概看了一下游戏内容有
10
天，结果第四天下午到处跑着做任务突然被卷进帮派斗争，草，我的警枪都还没来得及找回来（，中弹后直到第六天上午才
<del>在 Kim 的照顾下</del>
醒过来。感觉明天高铁上再玩玩就真快要速通了（</p>
<p>刚把床上的东西收完就被另一个在接受小学期暴打的室友叫去帮忙，从教她装
Pytorch 和 CUDA
开始<!--（装 Pytorch 踩过很多坑了，今天一上来就给她把梯子关了（，但带上 CUDA 其实还是第一次，因为我的电脑是 A 卡（（草-->一直到把
lab
写完，就差不多到晚饭时间了，绷不住了，今天到底在干什么。<del>不是自己的作业而且只有这一回，就觉得一边查一边写还挺好玩的，但如果这是我的小学期那肯定会觉得很烦（</del></p>
<p>填答疑坊工时的时候她说半天找不到我的名字，结果一看是在计算机类答疑里面找我（，绷不住了。才发现单次工时上限是
150 min，还填了两次。感觉填个数学也不好 <del>毕竟这又不是 learning
theory</del>，临时在答疑学科偏好里面加了一下 Python
程设（？），填完工时赶紧撤销了，我不行。然后突然想到，为什么不直接去答疑坊找个真正的贵系志愿者帮忙呢（（</p>
<p>这门课不是叫集成电路实验吗，为啥里面还会有个图像二分类的作业（。文档也非常逆天，感觉完全没接触过的话单看文档不可能理解是要做什么，比贵系暑培都差远了。页眉写的还是“2021
小学期”，最逆天的是正文里面还出现了“使用命令 <code>import pytorch</code>
和 <code>pytorch.__version__</code> 检查安装结果”这种
typo，绷不住了，万一真有人信了怎么办（（</p>
<p>今天才发现网易云终于有 <a href="https://music.163.com/#/song?id=2063500980">Life is PIANO</a> 和
<a href="https://music.163.com/#/song?id=2019022000">R.I.P.</a>
这两首我最喜欢的 G2R2018
参赛曲了（虽然都不是冠军，顺带一提这一年的曲子还有 <a href="https://music.163.com/#/song?id=1446245131">MARENOL</a>，冠军是 <a href="https://music.163.com/#/song?id=1403449766">Destr0yer</a>），一开始都是在音游里听到的，以前都是在播客里面听，不沉迷音游之后没有听播客的习惯了所以也听得少了。R.I.P.
里那句“おはよう、朝だよ”也曾经被我用在了很多地方的个人简介里。</p>
<p>喜欢看纸质书最大的弊端就是不方便搬运，颠了颠箱子稍微有点担忧。<del>而且费老大劲搬回家要是没看多少又带回来就更蚌了（</del></p>
<h1 id="月16日">7月16日</h1>
<p>在高铁上猝不及防地就把 Disco Elysium 通关了，一周目游戏时长 18.2
h<del>（能不能用这个时间去学学数学.jpg</del></p>
<p>虽然看起来大家都没玩过，但是这点吐槽大概也不会导致什么剧透（。<del>其实如果是我的话看番或者打游戏一般都会先去看一眼剧透再开始，比较有掌控感（？）</del></p>
<blockquote>
<ul>
<li><p>直到破案和抓到犯人，游戏结束，我都没能找回自己的警枪，怎么会是呢（</p>
<p>因为找枪需要晚上十点之后去和某个 NPC
对线，第四天中午接了这个任务，回来的路上就遇到了帮派斗争，被枪击之后第六天上午才醒，但是第六天下午就把案子破了（悲</p>
<p>从和 Titus
对峙开始我就一共开了两个世界线，其中一个接任务比较早但是掷骰子运气不好导致很难玩，后续就没继续下去。而且貌似晚上九点之后
Kim 会离队，我不敢一个人去找手里有把枪的 NPC
所以就搁置了这件事（挠头</p></li>
<li><p>怎么突然就结束了，感觉这个结局多少有点烂尾，不过现实中被踢出制作团队的主创们已经给出了
Disco Elysium 的最佳结局（（</p>
<p>我看到 Kim
开始总结说我是他见过最好的警督的时候就觉得不对劲，但是后面还提到要去拜访
Lena、她就住在我家附近的时候还以为可以开新地图，去看看和前妻曾经生活过的房子。结果还是突然就结束了，然后开始放演职员表，甚至都没来得及截到
Kim 的评价（</p></li>
<li><p>金*真心*相信你。虽然我的对话选项都是在他面前发疯，但他真的好宽容（（</p></li>
<li><p>信息量太大了，只有任务提示没有对话回档和小地图确实有点困难，不停地迷路，不知道下一步要干什么所以只能胡乱和
NPC 聊天，总的来说游戏性还是不太行，但这些问题之外也可以给 9
分。<del>可以给发行商扣大分吗（</del></p>
<p><del>不是因为只想给 One Last Kiss 10 分才故意不给的</del></p></li>
<li><p>如果按我的习惯<del>（xp？）</del>来说开局人格会直接选
Intellect，可惜体质太差很快就被嘲讽寄了。最后尝试的是给智力和精神平均匀了点数，Inland
Empire 发疯的体验非常好。如果有二周目<del>（还玩？）</del>我会选
Psyche。</p></li>
<li><p>用我破碎的法语读懂了 <del>自己的名字 Du Bois 和</del>
写在雪地上的那一句“UN JOUR JE SERAI DE RETOUR PRES DE
TOI”，总有一天我会回到你身边。</p></li>
</ul>
</blockquote>
<p>我爱它晦涩的文字和时常的疯狂，时而让我悲伤，时而让我充满希望。</p>
<blockquote>
<p><strong>YOU:</strong> No, you're special. You had glowing lungs.</p>
<p><strong>DOLORES DEI:</strong> “My lungs do not *glow*, Harry. I am
just like all the others. None of us have glowing lungs—stop making me
into some kind of…”</p>
<p><strong>INLAND EMPIRE:</strong> [Legendary: Success] Then it's you.
*You* will make her lungs glow. Your pain is NOT meaningless.</p>
</blockquote>
<blockquote>
<p><strong>Suggestion:</strong> [Medium: Success] "I know you still love
me."(Kiss her.)</p>
<p><strong>ARIST:</strong> No…</p>
<p><strong>DOLORES DEI:</strong> No answer. The arches of her brows
quiver as she looks you in the eye and backs away from you...</p>
<p><strong>EMPATHY</strong> [Medium: Success]: You won't do any of that.
You can barely make her cry.</p>
<p><strong>SHIVERS</strong> [Medium: Success]: All the roads will miss
her footsteps when she's gone from here.</p>
<p><strong>INLAND EMPIRE</strong> [Easy: Success]: A completely
different world.</p>
<p><strong>SUGGESTION</strong> [Medium: Success]: With your feet
trembling from the steps you took -- tepid and fearful -- you stand
against her; her body close to you, radiating warmth. With your eyes
closed, you move your lips on her mouth.</p>
<p><strong>DOLORES DEI:</strong> She is not kissing you back.</p>
<p><strong>YOU:</strong> I feel her breath...</p>
<p><strong>DOLORES DEI:</strong> Her chest rising like a pillow, warm
exhalations against the side of your mouth—her tender soul moving
through her lungs.</p>
</blockquote>
<blockquote>
<p><strong>DOLORES DEI:</strong> “Oh, yes. This is real darkness. It’s
not death, or war, or child molestation. Real darkness has love for a
face. The first death is in the heart, Harry.”</p>
<p><strong>DOLORES DEI:</strong> “See you tomorrow.”</p>
</blockquote>
<p>别的没干啥了，每次一到虹桥站感受到的最大不同都是南方潮湿的空气。今天上海在下暴雨，但是我一如既往地不记得带伞（，还好一直到下地铁都在室内，出地铁之后雨也停了。<!--相比北京我真是觉得上海要好一万倍，每次看到上海虹桥的站牌都有一种高呼到达世界最高城的冲动（，哪怕连这个地铁规划和地铁站的装修都比北京好一万倍（坏了，要是写在正文里会不会被骂沪爷 x--></p>
<!--之前放假回家一般都是我爸开车来接我，等回去的时候再开车送我去虹桥站，久而久之就成了父母双全体验卡（。只不过这次他也没来，不知道人在不在上海，但至少属于是不装了，20 th 的当头一棒（？-->
<!--我曾经在他生日和父亲节的时候说想给他买礼物寄过去，实际上也是想要个地址，但都还是被拒绝了，后来就直接发红包了。-->
<h1 id="月17日">7月17日</h1>
<!--昨天在高铁上想起来 3.29 写的这两段话：-->
<!--上晚课之前浅睡了十几分钟，居然梦到了一段记忆，完全就是把记忆呈现出来，没有什么来自梦境的加工。四年前的清明假期去镇海集训了一次，好像持续了五六天，可能学校原因不明地多放了几天假。最后一天从镇海回来的时候没有回家，带着行李箱直接去了学校寝室，然后去教室取了些东西，在桌上看到了 ex （7.17 注：实际上是 eex）提前给我的生日礼物，是一条项链，回寝室之后趴在阳台栏杆上一边把玩一边傻乐了很久（。-->
<!--感觉是最近清明、生日之类的话题都有提过，以及老姐送我的生日礼物也是项链，所以才想起来这件事。当时拍了一张从吊坠的透明部分里倒映出红色的教学楼的照片，今晚回来扒拉了好久各种相册，就是找不到了，也许在旧手机的相册里没有迁移过来，罢了。然后又想了想也不知道这条项链放哪去了，肯定没被我丢掉，至于实物在哪里，完全想不起来，对我来说真的很奇怪。-->
<!--回家之后找到高中用过的旧手机，每次都是我想找一些和 eex 有关的东西才会打开它，2023 年了居然还能用（，它不如早点坏掉（（。翻遍了相册也没找到那张照片，非常怪，也可能是那一年精神状态太不稳定，后来删掉了。说实话拍得真不错，一点痕迹都没留下真有点可惜，甚至让我怀疑是不是当时精神状态太差了，整件事都是脑补出来安慰自己的（（不至于，毕竟项链盒找到了，后来拿去装杂物了。-->
<!--至于项链的下落我倒是想起来了，分手一段时间之后吊坠被我摘下来改装成了生日贺卡上的挂饰送给了老姐，那条链子应该是拿去给我妈当项链的替换链了，还是什么都没留下。-->
<!--顺带去翻了一下旧手机上的短信记录，一开始的两个月还是互发，后面一年就全是我在发疯（，怎么说呢，几乎可以说是，祈求他能够看我一眼，但是没有任何的回复，太惨了，不能再看了，光速关机放回去。-->
<p>今天去看了看装修进度，热麻了。家里有个地方寒假里漏水掉了墙皮，内部也有点泡坏了，拿墙纸临时糊了一下，今天顺便还去和包工头请教了一下补墙的技巧（，下次顺一点腻子粉和油漆（其实不知道这个方不方便带）回去自己补一下好了。</p>
<p>出门之前拿了一张平面图走，在地铁上看了看，工程计算机制图的 DNA
动了。坏了，离成为土木老哥越来越近了（</p>
<h1 id="月18日">7月18日</h1>
<p>洗完头感觉头发闻起来很香，想着回学校买家里的同款洗发水的时候才想起来前段时间刚买了一大瓶，急了。</p>
<p>之前一直想要不要搞个学术点的主页，和这个<del>充满青春疼痛文学、贴贴实况和发疯的</del>博客分开，至少要能拿得出来给老师看，但我也实在没什么可以往上放的东西，课程笔记之类的看起来非常没必要，等真的开始读
paper 再说？上次 ypk 还跟我说读完论文可以给他看我写的阅读笔记，手写和
tex 都可以，我寻思着不如直接挂 homepage 上然后丢个链接给他（？</p>
<p>又去看了一眼友人的 academic
page，原来还要放大头照啊，那还是算了（</p>
<p>早晨出门看到楼下堆了不少建筑垃圾，才知道楼上有一户在装修，鼓起勇气敲门借了油漆和腻子粉。正好工头也在，先是问我要这些东西干什么，听说我要自己在家补墙之后非常震惊，说要是自己搞不定还可以找他们来弄一下<del>但实际上我想自己补就是因为不想请工人到家里来</del>，还借了我刷子、刮板和一副
maimai
手套，啊不是，劳保手套（。回家补好看起来还可以，满意出门。完全干掉之后也还有一点色差，果然是五彩斑斓的白（，但反正是在角落里一般也看不到，总之没啥用而且也不想再用第二次了的新技能增加了（</p>
<p>昨晚拿 AutoCAD
画了一张新家的平面图打印了好多份，方便确认家具摆放位置之类的问题的时候在上面写写画画，什么嘛工程计算机制图也还是有点用的（。画的时候对照当时的几张
PPT
才发现中介给的图不标准，承重墙的标注大小、尺寸标注之类的都有点问题，听说房产证还是购房合同上有更正式的图，不过也懒得拿出来对了，<del>我觉得该怎么画就怎么画</del>。</p>
<p>今天去宜家看软装的时候除了挑样板间，其实主要是做了一些家具的尺寸测量，坐在休息区舔着一块钱的甜筒埋头对着照片和平面图算能不能把需要的东西都塞进去，CPU
烧了，早知道带个电脑。随便复盘一点今天看到的东西。</p>
<p>逛样板间的时候看到一个所谓的情侣电竞房，这个配色真挺刻板印象的（，路过一些儿童房样板间的时候也是一样的感觉，只不过样板间是不是就确实是需要往
mode
靠近所以也不得不做成这样。虽然但是为什么一起打游戏要分两张桌子还几乎背对着（，而且左边这样看起来给我的感觉更像女主播的工位（（</p>
<p>7.22
UPD：现在再看感觉这个墙两边能做成没啥违和感的渐变色也挺强的（</p>
<p><img src="https://s2.loli.net/2023/07/18/kszU5LC4KSaFvWh.jpg" alt="电竞房（？.jpg"></p>
<p>感觉老破小的独卧做成下面这种装潢还算是比较好的
solution，用一个柜子把床和桌子隔开，之前还一直在考虑要怎么才能减少两边的互相打扰，算了一下除了沙发和茶几之外基本都能保留只是稍微局促，实在不行就把床尾的衣柜挪到侧面去。只不过装修好之后我也几乎没有机会去住，但还是先设计了再说。</p>
<p><img src="https://s2.loli.net/2023/07/18/HLt7Z5wMqSR3JzX.jpg" alt="一种卧室.jpg"></p>
<p>后面随便逛的时候看到一个梦中情单人间，储物空间和墙上的小黑板都戳中我了，这个灯球很
disco，我好喜欢。<del>只不过别到了能装修一个自己的住处的时候又是自己一个人住单人间吧（，毕竟这个床加宽一点、多加个椅子看起来也问题不大的样子（？（暴论</del></p>
<p><img src="https://s2.loli.net/2023/07/18/Iw7fA1MdtyY5pEW.jpg" alt="单人间.jpg"></p>
<p>这个厨房其实整体很好看，配色我还挺喜欢的。但是不知道为什么是开放式的设计，看到墙上这些乱七八糟的摆件和吊饰，我都能想象到用了两三年之后它们油腻的表面（，有点中看不中用。不过毕竟是展示效果，图一乐。</p>
<p><img src="https://s2.loli.net/2023/07/18/iuUBIfWorvwTg8a.jpg" alt="厨房.jpg"></p>
<p>宜家大鲨鱼，还是没能抱一只回家（</p>
<p><img src="https://s2.loli.net/2023/07/18/nRD1VuGxKEWsCNg.jpg" alt="大哈鱼.jpg"></p>
<h1 id="月19日">7月19日</h1>
<p>试了下视频通话，赛博贴贴好耶（</p>
<p>前面几天都好累，今天直接摆烂加起来睡了
13h，但还是困，待会大概还是正常时间睡觉，怎么会是呢（</p>
<p>啥事没干，在凉性循环地看 AMP algorithm 的论文和
Durrett，啥时候才能进入 Markov chain
啊，丘赛之前就说想把这个学了<del>但其实也没考但是考的我也不会</del>，一直咕到现在。之前
lzx
一直说丘赛概统题和平时考试作业差不多，我还真信了，考场直接破大防，后来翻吴昊讲义的课后题发现几年前的丘赛题难度是和考试作业差不多，最近是什么东西（</p>
<h1 id="月20日">7月20日</h1>
<p>试了试线上双人成行，卡关的时候用语音瞎比划好难（（，不过<del>金工实习</del>第二关还是过了（</p>
<p>开始凉性循环 ODE 和 Durrett，云一云 ODE
感觉我又行了（，难怪这课大二上学期就能上（？（x。虽然看到曲线积分又麻了，微积分
A2 遗毒无穷，还要读一下 PIN。</p>
<h1 id="月21日">7月21日</h1>
<p>昨天看雷达图强对流全国范围随机点名，还搁那儿乐，都这样了我家这里还一滴没下。结果今天晚高峰时间下了差不多
0.6 郑（郑州 720 暴雨最大小时雨量大约是一小时 202mm，今天下午是一小时约
120mm），内涝到需要消防车来抽水，草（</p>
<p>我之前以为内涝只会在我小时候住的郊县边缘那种地方发生，小学的时候有一次九月份下暴雨，路上的积水到膝盖，蹚着水去上学<del>（天哪小时候真的好爱上学，现在华子里要是变成这个样子我必然翘课，就算是高中也肯定直接请假了x）</del>，很害怕路上的井盖漂起来又看不到，几百米的路走了快一个小时。今天才知道中环以内的市区也这样（</p>
<p>最近日均睡 9h
以上但还是好困，本来以为睡得多会导致时区慢慢往西移动，但实际上也没有，还是不到两点就很困。是因为从期末周结束之后就没喝过咖啡了吗，虽然带了一盒咖啡回家但也不大想喝，何况家里没有牛奶可以兑，直接冲清咖感觉还是，别折磨自己了（。<del>既然这样的话就睡罢！是不是说明九小时精致睡眠是最符合生理需求的</del>（</p>
<p>今天还基本啥也没干，效率还没军训的时候高。最近就云完了 ODE
的一些特殊形式的初等积分解法，一半是在复习微积分
A1，顺便还意识到了对多元微积分的理解很薄弱，麻了。AMP algorithm
的论文也没啥进展，notation 还得一个一个查，更麻了（</p>
<p>顺便看到一个相当不错的 <a href="https://www.bilibili.com/video/BV1Yh4y1f7t3/">PV</a>，可以说是很长一段时间里看到的最喜欢的（</p>
<h1 id="月22日">7月22日</h1>
<p>在家睡觉不定闹钟，今天睡了接近 10
h，怎么会是呢。醒来之前梦到的是测量学出成绩了，喜提
D+，大受震撼就醒了。其实也不是因为梦到 D+
才醒，而是梦到查到之后绷不住了，光速开始贴贴回血，然后在梦里想起来我不是回上海了吗哪来的贴贴，就醒了（（</p>
<p>所以这测量学怎么还不出分啊，是不是卷子已经弄丢了（</p>
<p>电脑支架在寝室里架一格，回家还是架一格但感觉怎么都不舒服，突然意识到可能要往上再抬一格才合适。看来家里的桌子比寝室里矮，不过寝室的又比教室的矮（也不好说，大概主要是我懒得带支架去教室（</p>
<p>今天速通了一会 PIN 的数分 2，我大一学的个什么玩意，但是 PIN
这个笔误好多（，一边看一边在 banana space
上大海捞针一样地改，<del>只不过这么久了都没人改是不是因为根本没人在看</del>。顺便把
Terry Tao 的 <a href="https://terrytao.wordpress.com/career-advice/">career advice</a>
系列看完了（翻译：在摸鱼</p>
<p>早晨起来看到个<a href="https://weibo.com/1763864272/Nb0gwxhV4#comment">中气爱投稿</a>，乐了，顺便往社友的评论区转了一下：</p>
<blockquote>
<p>#北京暴雨#
今天早上局部暴雨再度来到北京。有多局部呢，清华东北44毫米，到了北大西南只有1.7毫米。来自frp</p>
</blockquote>
<p>原博的评论区也很乐：</p>
<blockquote>
<p>毕竟下20多毫米雨也会淹死人的地方，大家理解一下。</p>
</blockquote>
<p>想起来昨天青浦国展中心下了 0.6
郑导致内涝还有人喷排水系统不行（不过昨天正好
BW，人尤其多，太惨了），实际上你沪的排水估计已经是全国数一数二的水平了，一般来说小时雨量超过
100 mm
的话就是会怎么都排不掉。还是先看看远处只要下雨紫荆区就会积水的华子吧（</p>
<p>友人今天才给我发她昨天在 BW
积水现场拍的照片，说还好带的是高中毕业的时候班里一起定制当纪念品的那把大伞，勉强罩住一起去的三个人。我懵了，我说等一下这是什么伞，她说你是笨蛋吗
<del>什么明日香（香厨狂喜</del>
定制纪念品的时候全班就你坚决不肯要。回忆了一下还真是，当时班级订的纪念品似乎是一个书包一个杯子一把伞一个印章，每个上面都有印的校徽和某届某班毕业纪念之类的字样，<del>想起来这些东西加起来要
700
块钱也挺逆天的，当时的我就已经是性价比战士辣（</del>。当时班主任还反复和我确认是不是都不要，哪怕只要其中的某几样也可以，我说我真的全都不想要。</p>
<p>草，对高三唯一不需要认真回忆也能想起来的记忆竟然是，五月中旬有一次吃完饭回来，发现大家在教室里一起看<a href="https://www.bilibili.com/video/BV1cf4y1W771/">方舟圣经</a>，当时还有一搭没一搭地玩方舟但一直没来得及看这个视频，就没有直接收拾东西去自习教室，而是坐下看完了。还难得和班里的几个舟舟人说了几句话一起乐了一会儿，<del>属于是难得被人群接纳的时刻</del>（</p>
<p>不好说，我其实还是相信大多数时候并不是自己不被人群接纳，而是我不愿意靠近人群，不过也无所谓了（</p>
<h1 id="月23日">7月23日</h1>
<!--赛博贴贴发展出了奇怪的新形式（（-->
<p>绷不住了，来个今日二次元笑话：</p>
<blockquote>
<p>（一个还是 MO
时期认识的当时有一阵子还挺熟的今年高中毕业的）学弟：顺带问一下，有没有什么毕业主题的歌曲推荐，我们班要做个毕业视频</p>
<p><del>（今天在空间看到他去南开了，随口问了一句伯苓班的情况然后莫名其妙聊起来了但是怎么会聊到这个的）</del></p>
<p>我：那当然是这个啦（掏出 <a href="https://music.163.com/#/song?id=414118123">バイバイ
YESTERDAY</a></p>
<p>学弟：啊，我是说，中文的（</p>
<p>我：（沉默）</p>
<p>我：啊这，我没怎么听过，要不你问问别人（</p>
</blockquote>
<p>但是 bye bye yesterday
真的很经典啊！暗杀教室还是我初中开始看过的第一部番，印象挺深的（</p>
<p>昨晚没睡好，没几个小时就醒了，下午开始头有点疼，<del>看 Durrett
看得</del>。好几天没出门了，入伏之后室外逐渐变得很难说和 40
度的百京相比来说谁更难受，一出门就感觉空气里的水全贴到了身上，下雨也是倒开水<del>（沪语真是博大精深</del>，地铁和商场里的空调总觉得也不是很管用的样子。明天要陪家人去医院，每次都说腰椎智齿过敏之类的问题想等到回家再去医院看，然后就从寒假拖到了暑假然后大概还要再拖回寒假，从入学体检发现各种问题之后一直说每年要做的全套体检也从来没去过，没什么行动力，<del>但是陪家人去医院这种类似于看热闹不嫌事大的事情从挂号开始就完全不会拖</del>，暂且希望（自己）没事（</p>
<h1 id="月24日">7月24日</h1>
<p>回家就瘫着不想动了，晚上随便看了两三个 PIN
的法式大题，我认为夏天还是不要出门的好（</p>
<p>（就这一句吗）（真没得写了）（</p>
<h1 id="月25日">7月25日</h1>
<p>在家里真的是没啥生产力，感觉能不受打扰专心看看书的时间就是个零测集，没办法。要不要把工作时间移到凌晨，但现实是我天天很早就困（</p>
<p>在和家人聊天的缝隙里一口气看完了几个月的<a href="https://cosx.org/2023/07/monthly/">统计月读</a>，玩了几个看起来挺有意思的东西。然后感觉，比如说，现在我拥有了一个
GPT 附魔的 R
Studio，但是并不减少每次打开它想到“沃日又来搞数据了”的时候的痛苦程度（</p>
<p>是不是应该 focus 一点，感觉每天都在做不一样的事情。但是在零测集里怎么
focus（</p>
<p>晚上写 Durrett
习题的时候少见地加了页而不是直接塞在页眉页脚里（，发现家里还有 2019
金秋营的时候 runzhi
从北大带给我的两本作业纸，绷不住了，就用了一下。突然在想要是在课上交作业用隔壁的作业纸算不算节目效果，又觉得应该是个不少人已经整过的烂活，况且我现在想要隔壁的作业纸都有点难，算了。</p>
<!--说“是个不少人已经整过的烂活”是因为，刚入学的时候 ex 还真问我要过几本华子的作业纸说要在高数课上交作业用，不知道把我甩了又无缝衔接（每次想起来还是咬牙切齿.jpg（？）了一位自己学校里的 npy 之后，这哥们的作业纸是不是断供了。当时还是三天两头封校的时代，现在进出华子没那么难了的话感觉整这么个活的难度又降低了很多，那更是烂活了。-->
<p>开了个新坑写一些 trivial
的事实，发现我表达能力好差（。一开始以为会写出一些正确的显然的废话，真的落笔写了两个之后发现是正常人看不懂的<del>也不知道正不</del>正确的废话。<del>退而求其次，回想一下长脑子的感觉还是挺快乐的（</del></p>
<p>写到一半感觉越来越不对劲，一量发烧了，每学期回家都要生病这件事情总之是逃不掉的（</p>
<p>中间一醒来看到个<a href="https://weibo.com/1763864272/Nby4SwAm7">这个</a>，绷不住了。这两天还在围观群友猜到底闽南登陆还是粤东登陆，怕是要穿透福建省了，真挺恐怖的。</p>
<h1 id="月26日">7月26日</h1>
<p>躺了一天，感觉可能是前天去医院的时候院内交叉感染了。</p>
<p>头不那么沉的时候稍微翻了一些以前写到 Durrett
上的批注，许多长脑子时刻如果不是再回头看的话都要忘掉了，记一笔不亏。摆烂刷
b 站猝不及防地学习了一个<a href="https://www.bilibili.com/video/BV1RP41167t5/">张祖德教你正十二面体和正二十面体的画法</a>，<del>体会到了什么叫有时候一个人上网真挺无助的</del>，然后被正在旅游中的友人随手教育了足球烯的画法，<del>你们物化双修选手真恐怖</del>（</p>
<!--严格来说她不是物化双修，是物理 Ag 之后高三闲着没事去学了学化学（草-->
<h1 id="月27日">7月27日</h1>
<p>本来以为满血复活，实际上还是头疼得睡不着，不会真要长脑子了吧。多写了一些
miscellaneous topics 才打算睡，大多数是在骂 Stein
那本书（，下次想挑一本从 Carathéodory condition
开始构造可测集而不是从开覆盖一路具体地冲下来的实分析教材<del>（是的还会有下一次（悲</del></p>
<p>原来 Disco Elysium
还有硬核模式，<del>既然已经一周目了那还能有多硬核（</del>，有点跃跃欲试（（</p>
<p>下午开着视频通话双人成行了
3h，<del>二阶赛博贴贴好耶</del>，第三章好长啊，还没打完（（<del>被自己菜死</del></p>
<!--今天被转数环/答疑坊（其实感觉转数环活跃元素基本都属于答疑坊）/之前转系推研讲座上/实分析群里认识的一个哥们加了好友（虽然不知道为什么加完啥也没说（，实际上我之前看丘赛获奖名单的时候就发现他今年计算与应用进了总决赛，在心里暗暗地膜过了（？），只不过今天才知道他在探微学的是生物和化学（。把这俩凑成一个双学位真的学得完吗（-->
<!--本来以为可能是未知原因流落到探微的 MO 炸鱼佬，随便一开盒，这哥们以前怎么是学 OI 的，什么缝合怪（（-->
<!--之前那次转系讲座之后就一起聊过天，知道他好像是计算数学的，这么一说也很合理。~~虽然但是怎么不是数学物理呢，这样的话就彻底缝合了（~~-->
<h1 id="月28日">7月28日</h1>
<p>在家瘫了一周多了，肉眼可见在长胖（。今天又去看了眼装修，然后被催着去订了墙面漆，刷完漆硬装就完成了，<del>软装还停留在纸上画图记家具编号的状态</del>。订完货被闲聊（）的时候店主问我是不是北方人<del>（为什么会这么问，我寻思着我也妹口音啊，说话有点倒装吧也就是（草</del>，我想想也没什么问题就点头说是，之前忘记啥时候被问是不是南方人的时候我也说是，真方便（</p>
<p>没啥可写的，但是今天还翻到一个古早年间的 <a href="https://tieba.baidu.com/p/2245824015">EFZ
成就系统</a>和我毕业的时候填的表，复习了一遍太乐了（</p>
<p>收集进度
64/100，还挺多的，不知道的还以为是什么现充（。感觉只是比较擅长自闭的时候自娱自乐（，顺带通过违纪生活得舒服一点。不如说校规里规定不能做<del>但是做了会很爽</del>的事情我基本都做过（<del>啥叫不能带手机，谁说不能坐电梯的，我怎么不知道
etc.</del>，感觉也几乎没有真的被惩罚过（（。以及高一高二的时候成绩很差高三竞赛退役之后猛补回来的，正常人关于成绩的两极分化的成就一般就收集一半，但我基本能集齐（（</p>
<p>这个图有点目害，不过我也懒得再整一份了，将就看吧（</p>
<p><img src="https://s2.loli.net/2023/07/28/DUOPqNJbSuLAY4E.jpg" alt="efz-100.jpg"></p>
<h1 id="月29日">7月29日</h1>
<p>写点啥呢（</p>
<p>晚上出门买东西回来没赶上公交，于是骑自行车跑赢了走同一段路的公交车（</p>
<p>然而公交车一块钱，共享单车 18 min
两块五，上海的车比北京还贵，略输。</p>
<p>但是很爽，又赢麻了（</p>
<p><del>追车的时候挺有信念感的，感觉又是赛马娘后遗症（。当然跑赢了不是因为我快，主要还是托其中一个红灯的福，我过去了公交车没过去（</del></p>
<h1 id="月30日">7月30日</h1>
<p>写点啥呢（（</p>
<p><del>二阶赛博贴贴</del>双人成行<del>总算</del>终于把树屋通了，这一章全程用键鼠瞄准其实都感觉有点坐牢（<del>也可能是在为菜找借口，但我体感是真不太好控制，总不会是通关了都还没找对正确的玩法吧（</del></p>
<p>读一章 Durrett 再过一遍吴昊的讲义体验还挺好的，她真的就是在给 Durrett
做
summary（<del>刚刚还在想为什么要这样说话，然后想起来源头是上海英语高考有个题型是给短文写
summary，听老师说多了刻进 DNA
了（</del>。只不过这种并没有学到什么新东西但是又好像做了很多事情的状态是不是有点不妙（</p>
<p>今天看到个 <a href="https://b23.tv/ds10160106">EVA
伞</a>，本来觉得也没啥，为什么还卖这么贵，看到沾水后的心之壁特效我坐不住了（，它甚至还是八边形（。可恶啊前两天刚买了把平平无奇（？）的猫猫伞，早知道别这么急了（</p>
<h1 id="月31日">7月31日</h1>
<p>早晨醒来看到友人给我骂骂咧咧了十几条语音，吐槽暴雨天在贵北暑期学校打工引导学生入住；下午听室友吐槽没报到暑校志愿者的名，于是今天在招生办接了无数个逆天电话（</p>
<p>与此同时的我：最近有两个台风但都不经过你沪，风和日丽但是有点热，在家里躺着好爽，所以暑期学校到底是干啥的，<del>虽然我们高中至少有超过总人数
50% 的名额但</del>我也没参加过（</p>
<p>然后被吐槽竟然是强基一类考生（<del>这就是竞赛也菜高考也菜罢（</del></p>
<p>七月怎么感觉过得迷迷糊糊的，开了好几本书的坑但是进度都一般，一事无成了属于是。</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇十二·23年8月</title>
    <url>/2023/08/01/Diary-2023-08/</url>
    <content><![CDATA[<p>别来无恙</p>
<span id="more"></span>
<h1 id="月1日">8月1日</h1>
<!--早就想吃火锅了，今天的父母双全体验卡是一起吃了海底捞（-->
<!--最好的情况下的体验卡是我单独见我爸，比如他偶尔会开车送我回家。最糟糕的情况当然就是吃饭围观吵架，小的时候很害怕这种场合最后都会哭着回家还要挨骂，长大了之后变得比较现实，觉得既然有饭吃我就也没亏。-->
<!--今天发现他到现在都没把希罗多德历史的下册给我，残念。-->
<!--不知道说什么好了，别来无恙。-->
<p>摆烂，本来想去看硬装的情况，合同上签的是七月底完工，但是到今天还没结束。然后学到了新知识：刮腻子要三遍，每一遍之后都要晾干，晾干之后刷墙漆之前还要磨平，所以真正刷漆要到明天了。</p>
<p>在宜家下单了一部分家具，要说贵也不至于多贵，但是加起来就不便宜，怎么会是呢。在新家老破小里硬是装了个小吧台，放了两张高脚凳，<del>越矮越喜欢爬高处的椅子</del>。虽然也不知道有什么用，培养点喝酒的爱好吗（</p>
<p>突然想起来一个乐子，去年五月封校的时候时不时就一堆人去猫超排队屯食物和水。有一次和室友（点名
wafarinliu
老师）一起去买东西，发现矿泉水又被搬得差不多了，开始思考我们要不要也做点什么准备，于是站在货架前面商量要不要提半打青啤回寝室（，怎么不算是水了呢。回去和另一个室友说这件事情，被锐评不愧是山东人和新疆人（</p>
<p>之前不知道在哪里看到一个说法，国内软装家具质保最有保障的还是宜家，别的店不管做什么的都有可能家具还没坏就倒闭了，真到坏了也没地方修（</p>
<h1 id="月2日">8月2日</h1>
<p>验收了硬装，终于完事了。然而明天开始宜家就要送货和安装了，我也不知道是送一堆木板到家里还是拼好的送上门还是有人负责安装，说不定还要自己动手（<del>狂喜（拼家具很好玩的（</del></p>
<p>中午起晚了出门之前没来得及吃午饭，就拿了片面包走，<del>还在地铁上脑补要是去晚了就叼着面包冲进门装作很忙不是故意迟到的（</del>。傍晚饿昏了冲进开封菜才意识到今天不是星期四，吃了点东西，路过麦麦又补了一个甜筒，再路过奈雪又补了一杯奶茶。<del>胖什么胖，都是冰的，没有热量的（</del></p>
<p>晚上闲着没事又赛博占星了一次图一乐，为什么我的 N 也变成 S
了，以前只有 J 和 P 会横跳的来着，<del>快点变回来</del>（</p>
<p><del>在家里的第 17
天，感觉已经过了一年了一样漫长，各种原因地想回学校（</del></p>
<h1 id="月3日">8月3日</h1>
<p>写点啥呢（</p>
<p>是不是昨天甜食吃多了，今天开始爆痘，可能这是必要的牺牲吧（</p>
<p>昨天说拼家具好玩，今天真就是直接送了零件来，还是稍微有点难绷。有点虚，不太确定需要多少工具，32
头的螺丝刀和一套梅花扳手都放学校里了（<del>所以为什么要放在学校里</del>，是不是要寄希望于有手就行，或者买家具送工具（</p>
<p>说起来当初还是室友（仍然是 wafarinliu 老师）小学期参加<a href="https://eesast.com/home/contests">硬件设计大赛</a>（<del>虽然但是这有什么必要加个链接呢（</del>）的时候多领了一盒
32 头螺丝刀，结果还不回去了，然后给我的。但是真的很好用（</p>
<p>最近摆烂的时候时不时去看看物理系那个 3 学分的基础拓扑学的讲义，72
页的小册子罢了，<del>一个学期就只学点拓还能拿 3
学分（不然难道让物理系的同学先学个抽代然后学代拓吗（，看起来好爽，我要不学完拓扑之后也去水个绩点</del>。以前以为学点工科数学是洒洒水的事情，但是初概和微积分
2
接连给了我两拳，就不敢这么想了<del>然后就只敢去上数学系的课了（什么</del>。现在觉得可能只是我计算水平太差了，<del>多少受不了这种水题看错一个条件算错一个数直接扣没的考试（有人又在为菜找借口</del>，至少
ywb 这个讲义看着好舒适啊（</p>
<h1 id="月4日">8月4日</h1>
<p>闲着没事看了下 <a href="https://tianyingw.github.io/">wty
老师的主页</a>（<del>感觉可以说是闲着没事想欣赏下美女姐姐有没有发新照片（（</del>，发现她疑似（？这还有啥好疑似的呢）从华子跑路了，看了一眼今年六月才刚升了副教授，怎么会是呢。上学期居然上到了她在华子教的最后一门课，希望生统概论这课没事<del>，有事也没关系，没啥可学的（</del></p>
<p><del>突然开始莫名其妙地慌了起来！沃日，ypk
不会跑路吧，别过几个月我论文磕磕绊绊读完了结果他人不见了啊（（。还有这课如果以后停开了或者由哪个老师转成中文授课，我今年上过的话还能不能计入外文课啊（</del></p>
<p>满地乱爬，今天又什么都没干，不会真要把工作量全留到八月底和实习期间吧，这段时间别的安排还挺多的，急（（</p>
<h1 id="月5日">8月5日</h1>
<!--今天发现 Gamma Pie 虽然没删号但是也实质上跑路了，原因是我觉得好像很久没看到他发自己做的海派美食（？姑且这么叫吧）了，怎么会是呢，以前还以为润了之后自己做饭可以作为参考的来着。-->
<!--然后给他简单写了封邮件，虽然事后感觉其实有点打扰（只不过如果是我的话知道还有人发现自己消失了会挺开心的（，看自己写的几句话核心思想似乎是“你做的饭看起来好好吃，我也想做饭做得和你一样好”（（，还收到了回信（。虽然但是，好耶（（-->
<!--8.17 UPD: 怎么会是呢，不过回来了总是好的（（-->
<!--以及昨天在 LagrangeKMnO4 的日记里看到 lq 和 ypk 下学期要办面向清北本科生的 learning theory 的论文 seminar 但是碍于这个定语又不好公开宣传（如果有人看到这段注释而且也想参加的话也可以找这两位老师发发邮件，人太少开不起来（打广告.jpg，看来回学校之后还得闪击一下 lq 顺便 argue 一下虽然我不是数学系的但是也学过这些课没那么菜之类的事（（-->
<!--说来我其实一直并没有很想 learning theory，这玩意的风评/看起来其实没什么用而且申请还要和茶园竞争（（，但似乎各种意义上（校内没有其他方向更合适的老师/实际上和概统很密切/甚至还有认识的人一起/理论和应用的定位目测比较合适（我不懂口胡的）/目测资源丰富一点）来说（在目前入门环节）是挺好的选择了（-->
<!--想起来一个友人之前的锐评（x）：我一直不想 AI 但现在也 NLP 了，人总是会活成自己讨厌的样子的（点烟-->
<p>因为一些计划有变（两个橱柜的定制价太贵，打算直接在宜家买合适的成品），所以今天去新家拼家具的时候重新量了一些细部的尺寸，本来这一部分工作是想直接交给定制那边的。不量不拍照都不知道还存在很多问题。</p>
<p>（我试着比划一下，但是感觉正常人听不懂（，其实有什么必要说出来呢（（</p>
<ul>
<li><p>其中一个橱柜下面直接是水泥地，上一位业主住在这里的时候一直都没有给这一块铺木地板，直接放了柜子。把旧的橱柜拆掉之后这里就是一个深
7cm 的坑，买成品家具放进去的话很可能最下面的柜门被挡住打不开。</p>
<p>之前一直没有管过这个问题是因为打算定制一个高脚/厚底的柜子严丝合缝地放进去，然而昨天拿到的报价实在逆天，宜家如果能挑到合适的成品可以省一半钱。</p>
<p>解决方案是找包工头重新给这一块铺木地板，实际上也就一平方米<!--（价值八万（草（被骂沪爷警告x-->，然后学到一个新（也不是很新，可能是复习）知识，木地板下面要先铺地龙（就是一个木架子），他们做出来不一定平，希望人没事（希望柜子没事</p></li>
<li><p>量好另一个橱柜的尺寸，甚至都在宜家小程序初步挑了几个之后才发现柜子后面要走空调管道，扣掉这
12cm 之后选择面就窄了很多，急。</p>
<p>顶上有一个走水管的位置卡掉了很多层高，如果硬要保留层高就要卡掉宽度，为此多测了很多数据，趴地上画了个图感觉本质是个规划问题，如果考虑测量误差的话是不是个数值分析问题（</p>
<p>旁边是不能动的承重墙（当然装修装到这个份上能动也不可能再动了），还要预留窗帘和门的位置，说到底房间隔断处是装个门还是厚窗帘本来都打算之后再想，然而为了买这个柜子就导致一定要提前决策，我还得先去挑窗帘（</p>
<p>考虑所有限制以及最大化空间利用效率的话，最合适的几个柜子的分层高又有问题，很可能挂不下最长的衣服，还得回去量量衣服有多长，然后再跑一趟宜家量分层高（</p></li>
</ul>
<p>逆天，<del>翻新市区老破小的确比郊区新房装修困难</del>（</p>
<p>在屋里烦躁地转来转去的时候又发现一些，截止主体验收的时候没处理完的问题：</p>
<ul>
<li>刷漆的时候把踢脚线铲了还没装新的</li>
<li>木地板和瓷砖交界处还没做大理石的隔断（是这么叫吗）但是合同里有，怎么会是呢，这不得铲了重来吗</li>
<li>淋浴间还有一道挡水石没做</li>
<li>一些开关之类的安装杂项</li>
</ul>
<p>反正工程款还没结，还能在包工头面前当一阵子大爷（，催着一个一个改就好了，小问题。只不过快要回百京了，还挺急的，远程监工也挺麻烦。</p>
<p>量第二个橱柜的边边角角的尺寸，以及想这些问题的时候，很难不想起来一些测量学
DNA：</p>
<blockquote>
<p>测量工作应遵循的原则是由整体到局部，由控制到碎部，步步检核</p>
</blockquote>
<p>这么一说确实还挺对的，<del>不过工程不应该都是这个步骤吗（我不懂啊我学不来工科，瞎说的（（</del></p>
<h1 id="月6日">8月6日</h1>
<p>挑窗帘，顺便把一直被催的灯具也挑了，周末估计宜家人很多所以没去，能吐槽的事情不多懒得写了，也可能是装修半个月我现在忍受能力已经大幅提升了，总之下略（</p>
<p>晚饭吃麻辣香锅，点完单犹豫两秒把微辣改成了中辣，吃了个爽（。吃完还剩半盆辣椒，你们这儿辣椒不要钱的吗（</p>
<p>想起来上学期在寝室一起点外卖的时候室友（还是 wafarinliu
老师）被中辣背刺，还没尝过，等回百京了有空再一起比划比划（<del>感觉最近日记里
wafarinliu 老师含量过高，怎么会是呢（（</del></p>
<h1 id="月7日">8月7日</h1>
<p>翻到高中的照片发现来华子这两年头发其实变浓密了，真好（（</p>
<p>军训期间所有的 DNA
都早就洗掉了，只有某天在北体开演唱会的时候大家一起唱的《成都》洗不掉。其实在这之前我也没听过这歌，但是它一个月以来就是时不时地会在脑内开始放，今天干脆去循环了一会，怎么会是呢（</p>
<p>进行一个发语音.amr</p>
<blockquote>
<p>和我在成都的街头走一走</p>
<p>直到所有的灯都熄灭了也不停留</p>
<p>你会挽着我的衣袖 我会把手揣进裤兜</p>
<p>走到玉林路的尽头 坐在小酒馆的门口</p>
</blockquote>
<!--开演唱会的时候就对“走到玉林路的尽头”这句话印象非常深，想了半天为什么，哦原来是因为我爸叫这个（（。从我记事起父母就在不停地吵架，直到现在只要不在我爸面前，我妈就会对我用“他”来称呼他，一个带着重音的“他”就是特指他，我总是一遍又一遍地忘记又想起“他”叫什么名字。哦对，我其实到现在也不知道爷爷奶奶叫什么名字，但也无所谓，他们可能也不知道“老二那个死丫头片子”叫什么名字（-->
<!--我很难评，其实这才是我所见的真实的家乡，不完全是丘陵上连绵不绝的青山。-->
<p>虽然今天没出门搞装修，但在家用很暴力的方式修了一些坏掉的东西。淋浴的三角阀之前家人说一直转不动，调不了出水口但也勉强用着，报修的话光是上门费就要
150，今天福至心灵双手用力一拧，立省
150（。浴霸的灯罩是个嵌在天花板里的长方形盖子，之前掉下来两个角，掉的两个角装不回去，没掉的两个角又拆不下来，只好一直悬空着。今天找了片合适的
<del>流麻废材</del>
亚克力板卡在缝隙里固定住了，不确定在挤压下强度怎么样，但是又找不到其他密度低而且不锋利所以掉下来也没关系/不会被水汽影响的材料，不太放心又在天花板里面用绳子简单做了个支撑。</p>
<p>固定的时候突然想起来《牯岭街少年杀人事件》里小四的朋友在天花板上找到一把匕首的情节，在天花板里捣鼓半天不整点活属实和我气质不太符合，然而画不来镇宅符（，最后就在板子上写了个日期塑封了一下塞上去。</p>
<p>还剩一个特定条件下会触发拧不紧的水龙头拆开发现不会修，又装回去了，<del>至少学会拆水龙头了</del>，可能是想说明有些钱还是要让别人赚。虽然不大贴切但还是想起来
Disco Elysium 剧情里给我印象很深的一段，（我认为是在）暗示人的有限性的
<a href="https://discoelysium.fandom.com/wiki/One_More_Door">One More
Door</a>：</p>
<blockquote>
<p>There is no way to open the supply depot door. Accept it. You cannot
open *all the doors*. You have to integrate this into your character.
Some doors will forever remain closed. Even if every single other door
will open at one time or another, maybe to a key, or maybe to some sort
of tool meant for opening doors... But this one will never accede to
such commands. A realization crucial to personal growth. Crucial.</p>
</blockquote>
<p><del>人生是旷野，或者是 CRPG（</del></p>
<h1 id="月8日">8月8日</h1>
<p>之前学鞅论的时候对 Durrett 上那个 Dubin's Inequality
的习题感到非常困惑，官方的 solution manual
上那个步骤我一眼完全没懂（应该主要是缺上下标，所以一遍看不懂它的设计），另一份两个韩国人写的答案直接把这题空过去了，然后我也跳了。</p>
<p>今天（凌晨）又回来看的时候用最笨的办法把序列完整地写出来，才终于明白了归纳是个什么意思，然后也是直接在摘出的序列上动手做的又手动把每一段序列拼到一起证出来的，写完感觉真要长脑子了。结果看了眼
<a href="https://math.stackexchange.com/questions/4281820/how-to-prove-dubins-inequality">MSE
上有人提问</a>，原来完全用特征函数写然后很直观地用一下 switching
principle 的话就两行，这才是真 ·
归纳，知道这个意思之后再回头看官方解答就明白上下标缺在哪里了，好崩溃（</p>
<p>不过我还是觉得这个题目关于 <span class="math inline">\(Y_0\)</span>
以及 <span class="math inline">\(N_0\)</span> 和 <span class="math inline">\(0\)</span>
的关系表达得也稍微有问题，之后想稍微在长脑子篇里讲一讲正确的做法，还是说其实是我英语太拉了所以误解了（（</p>
<p>顺带悟到了遇事不决可以把 <span class="math inline">\(X_{N_k \wedge
n}\)</span> 这种逆天东西想成 <span class="math inline">\(X_{N_k(\omega)
\wedge n} (\omega)\)</span> 的形式（可是为什么现在才悟到呢（，虽然很
trivial
而且一般没必要，但是这种想问题想到神经损伤的时刻确实还是换一换比较清楚，本来就被答案绕进去，险些又因为
stopping time 的概念开始怀疑自己这阵子都在学什么东西，真挺崩溃的（（</p>
<p>我平时会直接把 supermartingale 简写成 super-mart，submartingale
同理。托这道题的福睡前满脑子就都是 super-mart，梦里也是
super-mart，今天出门在外面进超市买水的时候还在想 mart
不是商场来着吗，所以超市的英文是 super-mart
吧，但为什么总觉得怪怪的呢（。走在路上还在想杜宾犬的英文难道是 Dubin
吗，总觉得也怪怪的，<del>想到方舟的杜宾教官才想起来是
Dobermann</del>（</p>
<p>说起来舟用的居然是 Dobermann 而不是
Doberman，可能本意是作为姓氏，只不过教官本人确实是狗狗就是了（</p>
<p>今天还去吃到了小杨生煎的 <del>双肩包</del>
生煎包（是个沪语梗），虽然也没有非常喜欢，但还是比清芬生煎好太多了。想起来刚入学的时候
wafarinliu
老师激动地拉着我去清芬吃生煎说这个超好吃，但我觉得相比上海的真不咋地。后来有一次我激动地告诉她清芬的羊肉泡馍好吃，很适合当冬天的
comfort
food，她跟我说同生煎的理很可能比陕西的差远了，只是我吃不出来而已（（</p>
<p>来点今天在外面拍的东西（</p>
<p><img src="https://s2.loli.net/2023/08/08/j1huNKDEi2gxpJq.jpg" alt="muji.jpg"></p>
<p>嘿，听好了，最近东部城市会举办一个超大的
party，所有的风云人物都会参加，但你猜谁收不到邀请？</p>
<p>（退后一步）（尬舞）</p>
<p>是你！北京！</p>
<p><img src="https://s2.loli.net/2023/08/08/RlMCTLcIOaQo84f.jpg" alt="art-life-books.jpg"></p>
<p>五角场的上海书城分店装修之后绝大部分区域都划给童书和教辅了，今天走累了进去摆烂的时候想找本书读，看到这个艺术生活读物的幕墙还以为终于有书看了，结果怎么会是呢（（</p>
<p><img src="https://s2.loli.net/2023/08/08/6mqswyL3rcQMb8T.jpg" alt="Shirasu-Masako.jpg"></p>
<p>所以最后跑去 MUJI 读随笔了，巴掌大的 150
页的小书有一半是插图和语录，另一半是八篇散文，但是竖版书而且阅读顺序从右往左感觉不太习惯，读了大概
2h
当做休息然后就回家了。感觉是那种很刻板印象的日本人写的（，读完右边这段话我的第一反应是，这个作者自己悟出了影子价格的概念（（</p>
<p>有的时候感觉读这个破双学位也算杂学旁收，如果不是工程经济学强制给我喂了一点经济学知识应该不会知道这个（</p>
<p>装帧挺不错的，非常无印良品，只不过要 28
块钱我还是觉得有点逆天，当然无印良品里绝大多数东西的要价我都觉得逆天（，<del>白嫖下样书得了，下次还来</del>（</p>
<h1 id="月9日">8月9日</h1>
<p>因为啥都没干所以险些忘记写了，还好到现在还没收到类似于寒假时候“怎么没写日记你还活着吗”的邮件问候（</p>
<p>还活着，而且</p>
<blockquote>
<p>INSULINDIAN PHASMID - I exist.</p>
</blockquote>
<p><img src="https://s2.loli.net/2023/08/09/ex1uk29vod3OsmE.jpg" alt="I_exist.jpg"></p>
<p>（？（什么发疯实录（</p>
<h1 id="月10日">8月10日</h1>
<p>又到了装修血压时刻，本来说了一大堆发出来之前还是删了，没必要以后回来看的时候再暴击一下本就脆弱的心血管（</p>
<p>看到个<a href="https://mp.weixin.qq.com/s/-c0I46YpMLkcplfBl8FTxA">这个</a>，好乐，上海中学都能举办西部赛了，乌鲁木齐一中啥时候举办东南赛，<del>中国啥时候举办欧洲杯</del>（（</p>
<h1 id="月11日">8月11日</h1>
<p>继上学期在体育课上摔倒之后，今天又用同样的姿势在浴室里摔倒了，还好是在家里而不是在学校，眼前闪回的仍然是帝宝训练摔倒的演出，怎么会是呢（</p>
<p>《What Remains of Edith Finch》终于降价了，光速进行一个买，据说 2h
就能通，打算高铁上玩。试了下键鼠控制和视角很有双人成行那味，<del>包括找不着路和不能手动存档也是（</del>，但有点晕
3D（</p>
<p><del>其实是看群友吹它是最强第九艺术，非常为 Disco Elysium
感到不服遂打算玩一下试试</del></p>
<h1 id="月12日">8月12日</h1>
<p>收行李，把 Durrett 装箱的时候想起来第四章的 examples
赶进度的时候跳过没看，翻出来以为摆烂间隙能速通，结果被一个没写清楚的
Kakutani dichotomy
的证明整破防了。众所周知（？）这种美式教材讲究一个保姆级教学生怕读者看不懂，但是从进入第四章开始就逐渐透露出来一种“都看到这儿了不至于水平那么拉吧”的气息，会突发恶疾地在
non-trivial
的地方敷衍，看不懂步骤的时候就会深刻怀疑自己是不是脑子有点问题，然后破大防（</p>
<p>不太舒服所以间断地睡了好几觉，没干啥事，下略（</p>
<h1 id="月13日">8月13日</h1>
<p>后天回学校，今天把装修的事情交代了一下。之前有一个 to-do list
专门记录没解决完的问题和指数增长的新问题，今天把宜家还需要买的东西/具体的步骤和各种想到想不到的注意事项写成了一个新的文档，两个一起留给家人（。<del>虽然我相信我妈根本不会细看，到时候还是一个电话打给我问怎么办</del>。不知道为什么总有一种离职跑路但跑不掉的感觉（</p>
<p>读<a href="https://www.ikea.com/ca/fr/assembly_instructions/songesand-armoire-penderie-blanc__AA-2030694-3-1.pdf">其中一个橱柜的安装手册</a>（来判断难度，到底是留到寒假回去我自己拼着玩还是干脆买个安装服务）的时候看到个抽象插图：</p>
<p><img src="https://s2.loli.net/2023/08/13/fijycgEBQ73FYb5.jpg" alt="ikea-songesand.jpg"></p>
<p>啥意思，一个人不能安装吗（<del>，为什么只有右边的人有耳朵，多一个有耳朵和铅笔的人参与安装就可以了吗，那我为啥不能自己长出耳朵或者拿着铅笔（，还是说贴贴可以提高效率（，我也想贴贴（（</del></p>
<p>仍然不舒服，下略（</p>
<h1 id="月14日">8月14日</h1>
<p>把三周的地质和测量实习改成了两周的纯测量，不知道工作量多大。想多留一周时间贴贴<del>和学完全没学完的随机过程</del>，而且一想到地质实习会遇到一堆同专业但又几乎可以说是不认识的同学（，自己没上过工程地质啥都不会，还有组队
pre 写报告之类的烂事，完全 carry
不了甚至还需要靠抱大腿的话还是算了吧。纯测量那边有两个军训期间比较聊得来的同学<del>（是班里的两位
CPHO/CCHO Au
选手，多少有点同是天涯沦落人的喜剧感）</del>，组队体验可能稍好一点（啥</p>
<p>这样成绩单上会莫名其妙多出来两个
W，明明是完全没开始上就退掉的课，挺逆天的，下学期去课咨委提一嘴（</p>
<p>收完东西感觉箱子比来的时候重好多（，希望人没事。明天回百京了，现在还是好急（</p>
<p>还是不舒服，下略（（</p>
<h1 id="月15日">8月15日</h1>
<blockquote>
<p>从潮湿的地方来，到温暖干燥的你身边。</p>
</blockquote>
<p>印象里是沉迷方舟时候看过的一篇同人标题，说人话就是：回学校了，大贴特贴（</p>
<p>残念，晕 3D 而且高铁上环境不太好没能打游戏，看了半天 <a href="https://raps-with-r.dev/">Building reproducible analytical
pipelines with R</a>
催眠，速睡。本来想在旁边小朋友的家长面前表演一个玩物丧志，希望没那个加深华子的刻板印象（</p>
<h1 id="月16日">8月16日</h1>
<p>一边贴一边看一些看不懂的东西，虽然还是看不懂但至少在看了，所以说贴贴真好（啥</p>
<h1 id="月17日">8月17日</h1>
<p>之前吴昊给我她的概率论讲义的时候跟我说 Markov Chain 和 Brownian
Motion 这几章《非常简单，工科生也要学的》，昨天被 Durrett
整破防之后带了她的讲义去教室看，感觉，感觉这两本书在讲的明明是同一个东西但根本不是同一个东西（，怎么会这样呢（</p>
<p>总的来说我这两天真挺怀疑自己脑子是不是有点问题的，希望人没事（</p>
<p>看到 hx
在一个啥的“青年教师教学能力进阶项目”拿了一等奖，给我整绷不住了，和他同组的是我当年的写沟老师（在生命学院本博，后来去了教研院），世界真小，不过这两个人怎么能做到在同一组的（</p>
<p>吃饭刷北大猫协公众号，瞟到果壳发了个<a href="https://mp.weixin.qq.com/s/SpJ9o3LnMpSnpOlZzEWZBQ">天气越热，数学成绩越差</a>，我觉得合理，而且不只是数学成绩会受气温影响（。还好秋季学期要来了，秋天到初冬开暖气之前这段时间是最舒服的（（</p>
<p>晚上突发装修后遗症，盯了一会四教三楼一个嵌得角度挺刁钻的灯带，想的是这要是坏了会很难修吧（</p>
<h1 id="月19日">8月19日</h1>
<p>昨天难得太累了咕了日记，老姐来北京陪她出去玩，晚上回来贴贴了一下，回寝室和
wafarinliu 老师扯皮，谢谢大家盘活我（啥</p>
<p>远程验收了装修，也不知道还有没有什么问题但总之是交房了，可喜可贺，就算有也差不多得了。到最后了包工头还在跟我扯皮我买的柜子可能有什么问题总之不如定制，扯皮的时候把尺寸抄在草稿纸上打算问他到底哪里不合适，后来发现长宽高三个常数在乱七八糟全是符号的草稿纸上真的很格格不入，好久没见过这么多具体的数字了（</p>
<p>吃饭的时候看到一个<a href="https://mp.weixin.qq.com/s/jtW0cjrvWR0r-Fhr9vEl3g">这玩意</a>，以前看到竞赛生小作文都会默默划过去<del>所以为什么不取关质心这个公众号</del>，今天扫了一眼封面发现
efz
的录取通知书被拍进去了，内容和事情本身也挺逆天（，加上有一些熟悉的元素，还真的读完了。<del>总的来说很符合我对你校竞赛生的刻板印象，以及华子还是一如既往地不当人（</del></p>
<blockquote>
<p>我一个数竞cmo银牌同学，综合成绩常年年级前五，综合营优秀评定，我校卓越毕业生，最后因为报的是热门的信计，也没有录取……校测只给到13分（招办说如果改成数学可以录取）</p>
</blockquote>
<p><del>笑麻了，傻孩子们，快跑啊（</del></p>
<h1 id="月20日">8月20日</h1>
<p>逛街的时候看到有个七夕写许愿牌的活动，一些真诚的祝福：</p>
<p><img src="https://s2.loli.net/2023/08/20/rsonUadWj1mMFRJ.jpg" alt="Ito-Yokado.jpg"></p>
<p>毕竟我偶尔想起来那些没上的物理课，会觉得五年毕业也很困难（。考公的考一开始还写错了，残念（</p>
<p>被暴雨困在商场里走不了的时候去玩了一下自助拍照的机器，和老姐《初检合格》（（</p>
<p><img src="https://s2.loli.net/2023/08/20/C91pHvlOfzDBIky.jpg" alt="wedding-photo.jpg"></p>
<p>贴图的表情包还挺精髓的（（x</p>
<h1 id="月21日">8月21日</h1>
<p>右手大拇指根好痛，有刚入坑音游的时候当拇指党结果玩太多玩出腱鞘炎那感觉了。怎么偏偏是这个手指，写题就讲究一个冥想，<del>吃饭也好想把筷子扔掉（，</del>下略（</p>
<h1 id="月22日">8月22日</h1>
<p>早晨收到了玫瑰，去社聚还收到了 neruko
老师的小卡片，回来才发现卡背是透光的，好用心 qwq</p>
<p><img src="https://s2.loli.net/2023/08/23/qE63QgbufHKMPxN.jpg" alt="23_08_22.jpg"></p>
<p>以及</p>
<blockquote>
<p>今天是乞巧节，希望织女赐我巧手，让我写证明少写点伪证，写代码少出点bug</p>
</blockquote>
<h1 id="月23日">8月23日</h1>
<p>十月终于要有赛马娘第三季看了，急急急急急（</p>
<p>今天送老姐去北京西坐高铁，才知道这边不允许送站，买票进站的话最多提前大约六个小时，逆天。在这之前我还真以为所有的车站都是允许送站的，至少上海虹桥和北京南都是，然而以前也只有在这两个地方送站/被送站的经验（。等寒假回去测试一下上海站，上海西站和上海南站能不能送站，<del>可以的话其实也想测测什么松江南金山北南翔北安亭西芦潮港站（开玩笑的，芦潮港站不办理客运</del>，<del>可以送就说明百京不行，不能送就买个从上海站到上海西站的票假装在运转好了（（x</del></p>
<p>然后发现其实芦潮港站和清华园站（这个东西还挺冷知识的）这种早就已经停止办理客运的站点在
12306 上也还可以选择，多少有点时代的眼泪了（x</p>
<p>去年秋季学期在统计推断课上学 C-R Inequality 的时候老师还提了一句 C.
R. Rao 目前仍然在世，后来网上冲浪的时候还在<a href="https://cosx.org/">统计之都</a>读到了《<a href="https://cosx.org/2021/08/a-century-in-statistical-science/">C.
Radhakrishna Rao: A Century in Statistical Science</a>》，R.I.P.</p>
<p><del>对不起但如果不是去翻了一下的话我已经全然忘记 C-R Inequality
的形式了（（</del></p>
<h1 id="月24日">8月24日</h1>
<p>晚饭和 Triang-jyed-driung
面了个基，虽然他看起来对欧老师更感兴趣，怎么会是呢（（x</p>
<p>新生好可怕（？，晚上听人在楼道里吹了半个多小时长笛，<del>而且听起来好像不太会的样子</del>（（</p>
<p>测量实习组队好艰难，<del>每到实践课组队都觉得和自己专业的同学大多都不是很熟还是挺麻烦的</del>。找的第一组四缺一但是他们在何老板和我之间选择了何老板（，去问
OscarZs
一开始也是四缺一被拒，后来又可以了（，过了一阵第一组又润掉一个人，问我还能不能来，<del>这次轮到我拒绝你们辣</del>，总的来说好崩溃（（</p>
<h1 id="月26日">8月26日</h1>
<p>虽然昨天没写但其实是挺重要（？）的一天，但是没写（？</p>
<p>从去年就在看《<a href="https://cosx.org/2022/10/causality-statistical-method/">因果推断的统计方法</a>》了，这两天终于<del>在手机上</del>看完了，学到许多但其实也没学到啥（。最开始看到统辅课里面有一门因果推断导论（不知道是不是叫这个名）的时候还在疑惑这也是统吗，一头雾水（x）地读完发现确实挺统的（</p>
<p>形式化定义真难，一开始疑惑 Casual Inference
到底是个什么东西的时候主要就觉得很难形式化定义，像 confounding
这样的东西在线性回归课上也只是举个例子说明，真看定义还是蛮绕的。</p>
<p>后天要开始测量了，难绷。</p>
<h1 id="月27日">8月27日</h1>
<p>明天早八就要测量了，总感觉今天是十天内最后一次学数学，很崩溃，就郑重地往前给一些打星号的章节收了尾（，然后回去终于放心地把第四章的一整沓纸放进了影印书的那个壳儿里（。以前不知道是出于什么精神状态没看，如果看过的话读后面的东西应该会顺畅很多，#每日追悔莫及（</p>
<p>然而测量的课前准备从申请 CASS 试用资格和现在 AutoCAD 都已经出到 2024
版了但还是要求用 2014
这一步开始我就觉得难绷了，上次感觉到相似的难绷应该还是<del>上次</del>领军训服装的时候。看这个测量实习的指导书感觉也挺军训的，尤其要穿两周长裤，本来想着如果只是规定穿的话那我就不穿顶多扣点分而已，后来看了看学长的工作日志感觉可能是外业测量的时候蚊子太多不得不穿（，工作环境好像还不如军训，好崩溃（</p>
<p>看到 ypk 今天给我发邮件说明早有个 talk
可以来听一下的时候崩溃感达到了顶峰（（<del>有人需要吗在这里写一下好了</del></p>
<blockquote>
<p>8/28. 10-11am. 三教 1205</p>
<p><strong>Speaker 1</strong>: Yaqi Duan</p>
<p><strong>Title</strong>: Optimal policy evaluation using kernel-based
temporal difference methods</p>
<p><strong>Abstract</strong>: We study methods based on reproducing
kernel Hilbert spaces for estimating the value function of an
infinite-horizon discounted Markov reward process (MRP). We study a
regularized form of the kernel least-squares temporal difference (LSTD)
estimate. We analyze the error of this estimate in the L2(μ)-norm, where
μ denotes the stationary distribution of the underlying Markov chain. We
use empirical process theory techniques to derive a non-asymptotic upper
bound on the error with explicit dependence on the eigenvalues of the
associated kernel operator, as well as the instance-dependent variance
of the Bellman residual error. In addition, we prove minimax lower
bounds over sub-classes of MRPs, which shows that our rate is optimal in
terms of the sample size n and the effective horizon H=1/(1−γ). Whereas
existing worst-case theory predicts cubic scaling (H^3) in the effective
horizon, our theory reveals that there is in fact a much wider range of
scalings, depending on the kernel, the stationary distribution, and the
variance of the Bellman residual error. Notably, it is only parametric
and near-parametric problems that can ever achieve the worst-case cubic
scaling.</p>
<p><strong>Bio</strong>: Yaqi Duan is an Assistant Professor of
Technology, Operations and Statistics at New York University Stern
School of Business. Prior to joining NYU, she worked as a postdoctoral
researcher at Massachusetts Institute of Technology for one year. She
received her PhD from Princeton University and BS from Peking
University.</p>
<p><strong>Speaker 2</strong>: Kaizheng Wang</p>
<p><strong>Title</strong>: Pseudo-Labeling for Kernel Ridge Regression
under Covariate Shift</p>
<p><strong>Abstract</strong>: We develop and analyze a principled
approach to kernel ridge regression under covariate shift. The goal is
to learn a regression function with small mean squared error over a
target distribution, based on unlabeled data from there and labeled data
that may have a different feature distribution. We propose to split the
labeled data into two subsets and conduct kernel ridge regression on
them separately to obtain a collection of candidate models and an
imputation model. We use the latter to fill the missing labels and then
select the best candidate model accordingly. Our non-asymptotic excess
risk bounds show that in quite general scenarios, our estimator adapts
to the structure of the target distribution and the covariate shift. It
achieves the minimax optimal error rate up to a logarithmic factor. The
use of pseudo-labels in model selection does not have major negative
impacts.</p>
<p><strong>Short bio</strong>: Kaizheng Wang is an assistant professor
of Industrial Engineering and Operations Research, and a member of the
Data Science Institute at Columbia University. He works at the
intersection of machine learning, statistics, and optimization. He
received his PhD from Princeton University in 2020.</p>
</blockquote>
<p>前段时间在家里闲着没事的时候整了一个计算闭合导线参数的小<del>（不如说非常非常小）</del>工具，看实习指导书上还有一个可选提交项目是使用的程序，确实可以<del>卷</del>交一下，前提是我最好对这个测量步骤没有什么理解性错误，闭合导线测量占比要是比支导线还少那就大寄特寄（。然而这一步难道是重点吗，重点难道不是我连全站仪都不是非常的会用、工程计算机制图或许就是
2.3
的水平所以也不会画图、然而测量学到现在都没有出分我甚至不知道它和工程计算机制图相比哪个更烂，<del>而且这段时间看起来非常的缺少贴贴</del>，吗（，那要不还是先希望队友没事吧（（</p>
<p>不行，现在压力好大，又想起来组队的时候还是我主动去问能不能加组的，<del>如果不是我的话他们本来明明有机会拥有一个啥都会的组员而不是我这样的
five</del>，别真坑队友了吧（（</p>
<h1 id="月28日">8月28日</h1>
<p>测量实习就是军训的一些证据：</p>
<ul>
<li><p>都是 2 学分的小学期课程</p></li>
<li><p>和同班/同专业的同学待在一起（</p></li>
<li><p>（理论上来说是）早晨，下午和晚上干活，早晨起得很早，太热太晒的时间休息</p></li>
<li><p>戴帽子，穿长袖长裤</p></li>
<li><p>在学校里定向越野</p></li>
<li><p>缺少贴贴</p></li>
</ul>
<p>晚上回来疲惫地走进猫超买了盒酸奶，里面挤满了刚结束晚训的新生，对着楼梯口的镜子照了照自己，我的评价是穿得好奇怪一女的（。想起来下午在东主楼附近找合适的控制点的时候也是穿着这身奇奇怪怪的衣服，还遇到了
TA，世界真小，不过我觉得 TA
新（？）发型还挺好看的，为啥上次社聚的时候大家都在乐（（x</p>
<p>白天实在不想听课，看了很久地理等级考之后就没再看过了的星球研究所，他们制图水平真的好高（</p>
<h1 id="月29日">8月29日</h1>
<p>早晨踏勘选点涂油漆之后其实就累了，中午爆睡俩小时。吃饭的时候看微信步数是
7k 多一点，下午跑尺，晚上回来也就
10k，<del>然而地质实习的同学中午就人均破万了，好（</del></p>
<!--早上把伞借给没戴帽子的队友遮阳，她还给我的时候才发现上面多了好几道油漆（。下午伤心地（？）坐在马路牙子上用湿巾擦了半天，伞面和边上的是擦不掉了，我上个月刚买的伞自己都还没怎么舍得打（不是）啊（。别人的东西也稍微爱护一下啊（悲-->
<p>怎么能写的东西还不如工作日志多，<del>下次要不直接把工作日志搬上来吧（谁要看啊</del></p>
<h1 id="月30日">8月30日</h1>
<p>昨天跑尺的时候坐在马路牙子上思考 regular conditional expectation
和那个我有点看不懂的 transition probability 的 general definition
有啥关系，至少长得挺像的，某种程度上是把随机变量的定义修改成了映射到可测空间而不限制在
<span class="math inline">\((R, \mathcal B^1 (R))\)</span>
上，想到这里就感觉有点困了<!--，然后开始伤心地擦我的伞（，又看了一点相合之物，其实我一直都不太喜欢日常番，但是很适合在这种无所事事又烦躁的时候打发时间（-->（。</p>
<p>昨晚才发现之前看不懂主要是 notation
在前几章的角落里出现过但是又没有再提过多少有点你谁啊真不熟了，要是有索引就好了（。查
MSE 看到一个关于为什么需要一个 general definition 的讨论，有个评论说</p>
<blockquote>
<p>"a random variable gives out a real number" Not necessarily, for
example, to model DNA sequences by Markov chains, one could choose
S={A,C,G,T}.</p>
</blockquote>
<p>才想起来生统概论课上也举过类似的例子（单指用随机变量表示基因型）但我给忘了，老师当时还说了一句虽然随机变量定义上是取实数值但也可以换（大意），当时以为她在说废话<del>于是记住了这件事</del>，现在想想不知道是不是有别的深意（<del>其实应该没有吧</del></p>
<p>昨晚查这玩意查上头了睡了还不到六个小时，最近实习有超长午休，本来以为今天可以先睡个觉然后学点数学来治疗精神损伤，结果剥蒜三小时闭合导线参数还没算出来，晚上继续剥蒜，还算了一些高程和支导线，早晨的角度闭合也是当场画图算的，计算器要按冒烟了，高考数学打计算器强度都没这么高（<del>是的你沪高考数学是可以用计算器的，虽然不知道现在还能不能，至少以前会因此有很逆天的剥蒜</del>。下午记水准测量读数的时候也一直在打计算器，<del>数学壬不是这么用的，我最不会的就是剥蒜</del>，<del>但是还写错一个数，还好刚重测了存疑的两站就发现了，没返太多工</del>（</p>
<p>明早四等水准测量，今晚看了几个例子大致知道是要干什么了。说起来今天得知水准测量的两把尺一定要是不同规格的时候
CPU
都烧了，但实际操作也没那么难，还能预判读数在不在值域里，希望明天高程能闭合，再闭合不了/误报闭合失败我真要给队友谢罪了（。下午大概要测碎部，然而我对于怎么测碎部点甚至怎么记读数这件事尚且没有任何概念（</p>
<p>下午看到老师说明天最好是六点到九点测四等水准，大家商量说往后推到七点半到十点半也不是不行，差点脱口而出“毕竟
Lebesgue 测度有平移不变性”然后硬给憋回去了自己开始乐，<del>并且默念这是
surveying 不是 measure theory（</del></p>
<h1 id="月31日">8月31日</h1>
<p>这两天我一直以为中午收工之后仪器是送到测量老师办公室保管的，今天才听清楚是送到其中一个队友的工位，碰巧也在新土木馆。连你院本科生都有工位，<del>而某些系和某些书院到现在博士生工位都不够，博后工位还十人一间（</del></p>
<p>晚上看到个<a href="https://mp.weixin.qq.com/s/iI2e3QCcDbGllojJwV3omA">这个</a>，光速克服拖延去下单了
GTM274 的影印（（这是可以说的吗（（对不起但真买不起（。之前本来想读完
Durrett 之后看 Markov Chains and Mixing
Times，但好像太专了，优先级不应该那么高（</p>
<p>早上的四等水准太折磨了，作为一个对于最终成图没有任何帮助的支线任务，四个半小时测了整整
28
站还不得不用一些物理实验手段处理了一下（，好崩溃。最逆天的是这玩意的转点没法保存，只能一口气测完全程（</p>
<p>测量实习中期要交的东西都做完了，下午站在东配楼门口测试了下碎部测量，然后聊了会天就收工了。聊天的时候无意中发现
OscarZs
会把“什么什么东西看起来很糊”的“糊”读成四声，想起来之前欧老师也是，还以为是什么湖北特供口音，然后另一个家在河北的队友说他们那边也是这么读的（。稍微有点怀疑读成二声是什么江浙沪和山东莫名其妙统一起来了的口音了（</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇十三·23年9月</title>
    <url>/2023/09/01/Diary-2023-09/</url>
    <content><![CDATA[<p>公开写了一年日记了，从抽代算起的话学数学也一年了</p>
<p>但还是啥也不会（</p>
<span id="more"></span>
<h1 id="月1日">9月1日</h1>
<p>感觉一年没学数学了，之前说感觉午休可以学，但是这两天要么午休也在忙着测算，要么太累直接大睡俩小时，一直没怎么看过。昨晚收工早倒是看了一下，之前没懂的地方稍微有进展了，但是不多（。今天继续往后看，有一种朦朦胧胧感觉要看懂了但又还差一点的感觉，解决的细节越来越多，仍然是稍微有进展，但是不多（，学得好慢。</p>
<p>打开上个月的日记发现 8.1 在装修，8.31
在测量，某种程度上来说整个八月都是在专业实践（，好崩溃。总觉得忙活装修已经是很久远的事情了，最近的进度因为太忙也没有再跟进，和宜家打电话沟通好像也是挺久之前了。</p>
<p>前两天外业一直在做水准测量的记录，内业也做了不少计算，尤其四等水准测量是一边走一边记一边把计算器打到冒烟，到今天开始测碎部实在绷不住不想再记数据了，就选了画草图。脑子一抽打算把各个地方的草图画成边缘可以拼在一起的样式，到最后不仅有
AutoCAD
的成图，各部分草图也可以拿透明胶粘在一起组成一张完整的手绘地图。除了强迫症发作之外这样或许对内业绘图的队友也更友好一点，于是就在大家面前夸下了海口（，结果今天画了两张
A4
纸，刚把美院周边测完就觉得实在太难了（，只能自我安慰图纸效果似乎还挺清楚的，对队友友好而且答辩也能吹一波（</p>
<p>估计总共要画六到八张，希望人没事。这样的话之后几天草图就只能我来画了，轮不到换班跑尺或者读数养老了，寄（。还是原来那样，如果我还是原来那个喜欢地理的高中生的话应该会觉得画地图这种事情很有意思，但它现在是不得不上的专业课就觉得好痛苦，随便把一般的兴趣变成主业是完全行不通的事情，不过也可能只是
jk 过期了（</p>
<p><img src="https://s2.loli.net/2023/09/01/WekEdzHYrlZyvCT.jpg" alt="surveying_9_1.jpg"></p>
<p>虽然已经不负责读数和计算了，但是到晚上所有的数据表还是会莫名其妙都回到我手里，这是怎么会是呢（</p>
<p>今天交中期的九样东西，<del>这几天一直在劝诱（？）组长用 LaTeX
写但成品还是 word 了，虽然很没必要但是好急（？</del></p>
<h1 id="月2日">9月2日</h1>
<p>早晨出门正好看到大量研究生新生在往综体走，大概是开学典礼，一路上在心里默默锐评了一些院衫。</p>
<ul>
<li>物理系是我看到唯一一个集合之后举着牌子排着队在学堂路上走的，其他院系大概都是自行前往（</li>
<li>怎么有个院系的院衫就是一件印了字的大红色的纯色 polo
衫？原来是求真啊，那正常（</li>
<li>核研院的 T 恤背面写着“缘起 200 号，逐梦核研人”，在路上想有没有“缘起
600 号，宛平南路精神病人”（</li>
<li>看了一路感觉材料学院的院衫是最好看的</li>
<li><del>看到水利系院衫，默默嫌弃地扭头骑车走了</del></li>
<li>为什么分散地看到好几次网研院的但是一直没看到贵系的，<del>概率论不存在了</del></li>
</ul>
<p>终于把《相合之物》看完了（，是不是日常番集中补的话就会有点没意思，而且我是来看日式点心的，对主线也没啥兴趣。到最后已经是二倍速在看了，看完感觉终于解脱了（，怎么会这样呢。</p>
<p>看到 bangumi 上第 12 话下面有一条评论：</p>
<blockquote>
<p>感谢在我备考的这段时间陪着我</p>
</blockquote>
<p>突然就有点理解日常番的精髓了（。想起来 20 年的时候在追《<a href="https://bgm.tv/subject/280678">放学后海堤日记</a>》，大约是高三最后一次联赛之前的一两天发烧了在家休息，迷迷糊糊睡醒看到钓鱼番更新了，本来赛前生病心情很不好很担忧状态，躺在床上看完最新一话还是开心了很多，然后爬起来洗了个澡。这番好像一直到确认退役的时候才完结，感觉考完联赛知道进队没戏，在家切换状态到高考和补作业的那两天似乎也看了最新一话，出上海赛区初步名单的那段时间也有看，所以说虽然现在完全不记得是在干啥了，说不定还不如《相合之物》好看，但印象还挺好的（</p>
<p>今天主要在测建馆附近的楼，草图加了一张 A4
纸，比例越发崩坏，这个建馆报告厅看起来和光华路一样宽。</p>
<p><img src="https://s2.loli.net/2023/09/02/UwO5syJIHhmYSVp.jpg" alt="surveying_9_2.jpg"></p>
<p>早上测到建馆报告厅的时候感觉台阶设计得实在太抽象，就和组长商量了我中午先回去仔细想想怎么处理，下午带着画好的草图来测就会快很多。拍了一些靠近美院这一侧的照片就回去画大图了，下午也在下雨之前测完了东面和南面，本来应该
flag
顺利回收快乐提前下班，结果绕到西面和北面一看才知道早晨把我整破防的东面和南面还算简单的，又回去画图，成品长得也挺抽象的。</p>
<p><img src="https://s2.loli.net/2023/09/02/TatJYDghSzy8lfA.jpg" alt="建馆报告厅.jpg"></p>
<p>它还和继续教育学院有一座桥连在一起，往后绕了绕感觉继续教育学院和建馆咖啡厅也有点抽象，等测到这边的时候估计还要甚至要给这个详图再加纸再画大图，下次再说吧。</p>
<p>上午只走了 5k 步，之前几天都是早上就快到 10k
了，但是感觉今天比以往都累。到教学楼放下东西之后几乎是跌跌撞撞走到四教三楼的神奇沙发（什么东西）上坐下开始休息，不知道是不是因为湿度大气压低所以即使气温不高也很不舒服，还是说这几天的疲惫其实在累积。晚上下班早，画完建馆报告厅的图之后应该可以看看数学的，但是总感觉很累甚至很焦躁也没看多少，就稍微多处理了一点点细节，一直没理解的问题到现在也还是不理解，有点麻烦了。</p>
<h1 id="月3日">9月3日</h1>
<p>早晨刷牙的时候想清楚之前 Durrett
上一直卡着的问题了，很乐，但是被自己蠢死（</p>
<p>今天把草图基本画完了，南边勉强是测量的时候一边测一边画的，到建馆报告厅和门口的小树林就彻底现场画不出来了，中午照着地图画完下午对着草图选点测点，爽死。</p>
<p>感觉明天能收工，后天肝图和 PPT，希望不是人生十大错觉（</p>
<p>比例已经彻底崩坏了，这个清华路和光华路看起来都比建馆报告厅还宽，东配楼看着有建馆报告厅四倍大，但说实话主要是西南部分画太小了，东配楼和美院的比例还真就这样。</p>
<p><img src="https://s2.loli.net/2023/09/03/s4lY3LfqXyECuKm.jpg" alt="surveying_9_3.jpg"></p>
<p>已经拍不清了（</p>
<h1 id="月4日">9月4日</h1>
<p>下午测东主楼的时候在路上遇到了一个疑似邱宝（<del>坏了现在说到邱宝我第一反应为什么是
Yau</del>）的大叔，说疑似是因为这儿离工字厅有点远，而且他为啥会一个人在路上（x。过了一会有人来问路，问伟清楼怎么走，这我熟毕竟统计中心就在伟清楼，顺手指了一下。只不过他对我的称呼一直是“老师”，我们穿着工作服怎么看都更像修路工人而不是学校的老师（，稍微有点怀疑是不是遇到济南老乡了（x）。说起来确实快到
<del>全体济南人的节日</del> 教师节了（</p>
<p>测东主楼东配楼之间的天桥的时候看到下面的路灯类似白玉兰的形状，一下子有点愣住，上海街头（或者可能只是我住的郊区是这样的
x）有相当多这样形状的灯，因为上海市花是白玉兰。</p>
<p>想回家了，可能也不是想回家，而是想回你沪了，我也不知道为什么（</p>
<p><img src="https://s2.loli.net/2023/09/04/H9pvZixy8QmjATR.jpg" alt="magnolia.jpg"></p>
<p>今天是彻底收工了，晚上在做内业的工作，明天可能看成图的情况还要去补测（<del>但愿不是大批量重测</del>）一些东西，不好说。之前发现用发的卷尺量我的身高量出来一米七（，后来我们都管它叫自欺欺人尺了，但也还是在用这把尺测。今天发现棱镜高也会在戳地面的时候自己偷偷地变（，合着它也是自欺欺人棱镜，那这高程岂不是全是误差，看那个评图
<del>统计量</del>
标准里有一项还是高程和点位坐标的标准差，有点虚。最后大家讨论得到的结果是，总能及格的吧（（</p>
<p>趴在地上把地图贴好了，画出来居然真的长宽近似相等，和正方形的测区基本符合，说明我瞎画的水平也还蛮高的嘛（。建馆报告厅的详图也画好了，打算后天拿到
pre 现场展开 <del>燕国地图</del> 给大家一点小小的未央震撼（（x</p>
<p>人家以为我很卷，实际上我只是怕拖队友后腿<!--，尤其是和四个队友都不大熟，而他们互相之间很熟-->。</p>
<p><img src="https://s2.loli.net/2023/09/04/AD65LMpwTgixPWs.jpg" alt="surveying_9_4.jpg"></p>
<p><img src="https://s2.loli.net/2023/09/04/vSopzrL9tRKwnac.jpg" alt="建馆报告厅_2.0.jpg"></p>
<p>四等水准测量那天从早晨七点半开始，测到综体前面最后一站的时候已经是暴晒的正午，组长在旁边调平水准仪，我蹲在一边按计算器盘算着这一站大约测出多少高程才能闭合。第一遍测的读数出来之后我心算了一下感觉非常的不闭合，就告诉旁边的组长再看看读对了没有，但一直找不到问题。</p>
<p>从 A 到 B 的测量非常完美，但是从 B 到 A
的过程中的确出了一点小问题。我们完全可以相信去程的数据，但是回程的问题在最后一站才会暴露出来，整个过程的转点都是自选的没有办法保存，连回去检查的机会都没有。为什么要用这种原始的方法测紫荆网球场的高程，这一定是既有的数据。当然后来的画地图更是没有意义的事情，没有哪个机构会采用我们的地图，是卫星地图不好用吗，我们是很业余地在用老旧过时的仪器重复做几十年前的人就已经做过的事情，精度可能还更低。</p>
<p>于是我忍不住问旁边的组长，我们做这个事情有什么意义？他没有回答我，也可能只是没听清，说中午太晒了视野有点晃，然后又报了一组数据，让我再看看这下闭合了没有。</p>
<!--虽然但是，这几天其实非常崩溃（，我直到测量实习第一天到现场才知道另外四个人实际上本来就很熟，其中三个是同班同学也（大概）曾经是一起工作的班委，另一个目测是其中一个人的室友，只是他们拉第五个熟人的时候失败了，然后被我横插一脚。然而在我的视角里组长是自己专业的同学里面相对非常熟的人了（，但本质上还是非常不熟。-->
<!--整个实习过程都很焦虑，不知道是跟着他们四个人好还是自己待的距离远一点好，最后不知道为什么就变成了拼命揽活做，从踏勘开始所有的规划就都是我和组长一起完成的，最困难的两次数据记录也是我在做，所有的计算都是我做完的，不夸张地说测碎部这几天画这两张草图和现场指挥的工作量感觉已经大于其他人加起来的工作量了，所有人午休都是真休息，我每次都说午休可以看数学，但还是在焦虑地干活。唯一摸鱼的一次是第一天控制测量，我实在不知道是应该跟着大家一起还是默默蹲在远一点的地方，就选了跑尺，离所有人都很远，只要在 n 时刻站到他们 n-1 时刻的点位就可以了，非常的 predictable。回去之后很害怕他们觉得我拖后腿，也不知道到底要怎么参与到他们中间，后来解决这个问题的答案是由我来 carry 所有的工作，就不会社恐了。-->
<!--人家以为我测量学 A+ 水平，结果我每天晚上躺在床上睡不着害怕第二天的工作不会做，怎么会是呢。-->
<!--还好都结束了。-->
<h1 id="月5日">9月5日</h1>
<p>上次看数学还是上次（，距离一点点推出所有的细节直到早晨刷牙的时候彻底想清楚
Durrett
上卡住很久的那个问题已经有两天了，今早起来才抽出空自己重写又复盘了一遍，后面的进展就自然了很多。</p>
<p>写完之后把它夹进 Durrett 里面准备出门去系馆，突然就想起来这个：</p>
<blockquote>
<p>This is actually quite a triumph, even if it is hard to explain to
your friends and family members exactly what you have achieved.</p>
<p>——《<a href="https://mashplant.online/2022-spring-summary/">研一下总结</a>》</p>
</blockquote>
<p>这两天没有来由的（<del>真的吗？明明有很多来源</del>）难过，想回家，也并不是想回家，想回上海了，然而秋季学期甚至还没有开始，这咋办。今天交了学费然后准备晚上回去的路上去注册，之前总觉得六千块钱是我的可支配财产里不小的一部分了，所以想一直捂到开学之前再交的（，只是再拖下去按我这个记性说不定开学就失学了。最重要的一点可能是从九月份开始每月多了一笔固定的入账（<del>真的吗？说不定下个月就没有了吧</del>），尽管并不多，它的来源让我有点难受，也不想在这里细讲，但当然要收下。</p>
<p><del>怎么听起来这么奇怪啊，可不是什么见不得人的事</del></p>
<!--说出来也无妨，我父亲现在在西南地区/的一所二本高校工作，算当地的高收入人群。当初我妈为了给我争取一个在上海高考的资格和他复婚，如今我 20 岁他 48 岁，他正打算在当地相个农村的年轻女孩结婚，想生个儿子。他坦诚说这些，跟我说既然我生活辛苦就不必再给他转钱，他今后每个月会打一点给我。-->
<!--我从前多少次认为他多少还是对我好的，。在我妈不许我有零花钱和用手机的时候还是他偷偷给了我一些这样的自由，他送了我很多他自己做研究的时候读过的，还有他挑选的觉得我会看的文史哲专著，即便我到现在也没有看完，我妈就不会做这些事情。我前两天把这些话跟友人说，她说你怎么又双叒叕被男人骗啦，我说我没有完全被骗，我又不是就不要这个钱了，我还问他能不能再多给点、顺便把今年的学费也给我交了来着。-->
<!--我有的时候会想起来小时候看情深深雨濛濛的时候，印象最深的还是依萍冒着大雨去爸爸家要钱的那个片段，当时我就想如果是我挨了这么大一顿打之后一定会攥着钱跑路，不会像她一样就不要了。还真是（-->
<p>才 5
号就已经写了四千多字了，真能水，八月总共才写了一万字出头。测量实习可能是今年对我来说最后一次大规模（？）社交了，毕竟数学课又不用组队。</p>
<h1 id="月6日">9月6日</h1>
<p>测量实习，彻底下班！感觉比地质 +
测量赚多了，就是不知道最后给的成绩赚不赚，<del>不过总能及格吧</del>（</p>
<p>早上买了瓶西柚味茶 <span class="math inline">\(\pi\)</span>
带去教室就早饭吃，虽然身为糖水爱好者初二的时候就看到过同学从便利店买这个，但今天还真是第一次喝。感觉就是有一点点茶味儿和西柚味的比较清甜的糖水，说人话就是三到五分糖加香精，尤其这个茶味儿就像北京菜里面放的辣椒一样是摆着看的，但我确实比较喜欢喝糖水。</p>
<p>高三的时候吃完饭时不时会拉上友人在零食窗口买奶茶回教室喝，看着像是学校自制的，质量很不稳定，时而齁甜时而这白开水怎么没味儿啊，小贵而且去晚了还买不到。感觉上好像就是需要一点糖刺激奖励机制，不然混不下去。<del>我的体重会不会就是当时涨起来的呢（</del>
<!--开玩笑的，是初三吃药的时候涨起来的，虽然以前也不瘦（--></p>
<p>没吃晚饭，本来想吃桃李夜宵的烤冷面再加串冰糖葫芦（前情提要：2023.02.19），最后买了碗小馄饨就饱了，最近口腔溃疡也吃不动冰糖葫芦，吃辣都得吸溜一阵，但是不能一天不吃带辣椒的菜。感觉整体不如玉树的夜宵但也确实便宜，而且不知道玉树夜宵暑假开没开，吃过最好吃的一顿玉树夜宵是一二九分声部那天晚上翘掉了活动和何老板去吃夜宵，两个人买了一份烤冷面一份馄饨拿小碗分着吃顺带吐槽院系这些没用的破事，可能是我没吃晚饭的原因，真贵但是真好吃啊，下次开学了去吃。<del>下下次为了冰糖葫芦还不吃晚饭（</del></p>
<p>好喜欢汤带着鲜味的小馄饨（就是味精放的多），如果是小馄饨的话就是纯肉馅最好吃，饺子馅我最喜欢的是玉米猪肉，湾仔码头的煮着好吃但是有点贵，自己包的就不太好吃。而且我捏的饺子煮了之后一部分会破或者整个散开，买的速冻水饺看起来个个都有开口，煮了之后也只会漏油不会散开，很神奇。大概毕竟吃饭就是吃调料吧，我还是不太会配料，就只是能把东西做熟。不过众所周知上海宁过年不吃饺子吃汤圆，上个学期在桃李二楼吃饭的时候偶尔也买小碗汤圆当主食，好像十个四块钱而且还有一小碗汤，记不清了。汤圆馅就没有什么花头，都是黑芝麻，花生的我也不爱吃，但是都不如搬家之前在家附近超市里买的冷冻汤圆，煮熟之后咬一口糯米皮可以扯得很长。说到你沪特色碳水还得是
<del>双肩包</del>
生煎，小杨生煎那种纯肉馅最好吃，灵魂还是那口汤，大壶春的个头大就显得比较糙，我也吃不下。上次路过清芬的生煎窗口虽然不屑一顾但看到旁边有
<del>你好谢谢</del> 小笼包
<del>再见</del>，长得很像小时候在城隍庙吃到的那种，<!--我一辈子都记得小时候刚来上海不久，大约是 2010 年第一次去城隍庙，午饭在小吃店吃的是一盘 32 块钱 4 个的鸡翅，现在想想都是我轻易负担不来的东西。当时家里穷得揭不开锅，看我想吃我妈还是给我买了，我还记得她当时打开那个亮黄色的小钱包的样子，以及她自己没吃饭。-->只不过我还是不太相信北方卖的小笼包，如果买了之后发现没有那口汤、皮很厚的话我会很难过。但还是想下次试试，就是不知道在清芬一楼单买一笼小笼包的话应该配点什么才能吃饱而且不碳水过量。主食的话米粉也很好吃啦，但我喜欢汤粉多于炒粉和拌粉，在上海火车站附近吃过一家据说很正宗的桂林米粉，高中学校旁边那个传奇广场有个店做的也很好吃但稍微咸了点，除了长泰广场松鹤楼的鸡汤面和某个炸鸡店的炸杏鲍菇之外，高三的时候我也会晚饭时间偷溜出去吃这家然后回来上课，就是太烫了每次要晾很久才能凉，时间充裕才能吃。两家店酸豆角都给得相当多而且好便宜，一碗肯定不到
20
块钱，米粉很滑很弹，前者的笋尖尤其好吃。后来再吃到这么好吃的笋是今年暑假在紫燕鸡挑卤味的时候一时兴起买了些拌笋，是用小米辣加别的调料拌的，和米粉里面的笋尖不是一个味道，但脆爽和鲜嫩多汁是一样的。</p>
<p>这是在干什么，用嘴炒菜吗（</p>
<!--最近看到 Akid 的事情，就想到小时候曾体验过的那种长期的饥饿感，也不是说饥饿，没有真正饿到过，但是小孩子自己在家做的吃的真的很寡淡，学校的饭是教育局的配餐，重油重盐、原料估计不太好总之也很难吃，一对比哪个都不好吃，也不是很想多吃，小学的时候我是班里最瘦最小的，现在还是矮但是往胖了长了。上高中之后第一感觉是学校食堂真的太好吃了，可能是我和我妈都不太会做饭的原因吧，毕竟同学都说不如家里做的好吃，他们好多都有一个全职在家的妈妈。走读的同学有几个经常在空间晒在长泰广场或者家里吃的晚餐，印象很深的是一个当时物理竞赛现在在茶园的同学经常发吃的煎饺，好馋。很长一段时间里我不敢吃午饭，于是就趁晚饭人少一点热泪盈眶地咔咔刷那张橙色的饭卡，拿蚂蚁上树（就是粉条儿）拌米饭，吃看起来像是模具里压出来的鸡块，到了周五发现这周的钱没花完，就点份十块钱的肉酱面多加一个虎皮鸡蛋，在师傅舀汤浇上去之前赶紧说不要汤。后来 ex 去长沙集训了一次，带回来当地一种很好吃的辣酱，每次在盛免费汤的地方多要一个勺子挖着拌饭吃，一天能吃一小盒。他带回来的吃完之后我在某宝上买了一些同款，结果好像是产区不一样，味道明显变了，就没怎么再吃。-->
<!--我是在混乱博物馆刚刚停更、回形针 PaperClip 才创立只有几千粉丝的时候就在看了，在回形针的视频末尾看到过大象公会的联名。早上看了 Akid 的微博和推，到现在还记得那只形销骨立的手举着菜叶子、青梅和漫画书的样子，和反复说想吃烧鹅和玉米炖排骨。在饥饿上共情之后还是很难不同情，想着想着含泪（不是）多吃了一大口。-->
<h1 id="月7日">9月7日</h1>
<!--昨天想到高中食堂的蚂蚁上树馋的睡不着，今天在桃李二楼还真看到了，不过酱料加的不够多，粉条太长太粘稠了，拌饭不好吃。之前看大家都在说今年十一期间是 efz 65 周年校庆，好多同学都要回去，我是不可能，只不过 60 周年校庆的时候我刚上高一，还在和 eex 一起当校庆志愿者，草。突然想到这样的话今年也是贵系 65 周年系庆，草（-->
<p>早晨起来 wafarinliu
老师问我要不要一起点外卖，本来今天打算洗洗衣服再出门所以想答应的来着，结果查了一下上个月的账单给我整精神了，怎么明明是假期还一个月花了两个月的钱（，这个月当然更夸张毕竟刚交了学费。虽然都是正常的特殊开销（？）但还是立刻决定去桃李吃午饭了（。在猫超买东西的时候看到了之前一直想尝尝的三得利茉莉乌龙，虽然它写着无糖完全不符合我对糖水的期待，但毕竟是茶尝尝也不亏，当咖啡的平替喝也是我赚了。</p>
<p>测量实习结束之后走在路上还是忍不住去看井盖上的字是正常现象吗（</p>
<p>今天把芦毛灰姑娘看完（？）了，睡前看到有马纪念入场前会长和小栗帽的击掌就燃得不行但实在是困了（，早晨起来一口气看完了第二部就想打
9
分（不好说是不是冲动评分，可能是动画第二季的印象好导致对芦毛灰姑娘一上来就很有好感），晚上就看到目前连载的位置了。后面逐渐在变成
<del>Cygames 非常擅长的</del>
群像剧，<del>小栗帽痛失主角位（</del>，不知道啥时候才能画到有马纪念有终之美，急。</p>
<p>其实感觉应该标搁置才对，后面没打算追更，攒一阵子再看，那不就是搁置而不是看过（。也没必要分这么清（</p>
<p><img src="https://s2.loli.net/2023/09/07/kN3owLArh4HRI1J.jpg" alt="Arima-Kinen.jpg"></p>
<p>急了，啥时候能看到芦毛灰姑娘动画化（。看第二季的时候最喜欢帝皇，但看了漫画感觉还是更喜欢小栗帽。要类比的话可以说从笠松到中央的经历是戳到我了，和好歌剧都不是血统优良的名马（9.8
upd：是我记错了，这下乳好歌剧了，虽然也都说好歌剧血统一般但果然比起小栗帽还是强太多太多太多了）但也不是后者那样开挂的天才反而更加励志，还有“跑步是因为能跑，从站都站不住到能够跑起来已经很好了”总算是摆脱了两季动画的友情设定，第一季多少就有点因此走向废萌变得很无聊
<del>但其实也有人爱看废萌吧只是我不喜欢</del>，帽门永存（</p>
<h1 id="月8日">9月8日</h1>
<p>看到了《<a href="https://mp.weixin.qq.com/s/5yRCOj57YOrnQuNb7Rv8Xg">院友代表于品在北大数院2023年开学典礼上的发言</a>》，里面每一句话都在骂我（，边读边再一次捶胸顿足为什么是去年上了抽代而不是今年上。晚上又看到《<a href="https://mp.weixin.qq.com/s/791SeziTBxYbrhHqsPTm8A">师说新语 |
“小米教授”薛金鑫：终结百年潘勒韦猜想，保持与学生共情的能力</a>》，又一次捶胸顿足上个学期为什么只上了实分析（？）和概率论而没有上复分析（</p>
<p>晚上看到一个</p>
<blockquote>
<p>What doesn't kill you makes you stranger</p>
</blockquote>
<p>笑晕（</p>
<h1 id="月9日">9月9日</h1>
<p>学会了一些用 Markov property 证明的结论之后逐渐不会用 Bayes' Theorem
了（</p>
<p>横贯测量实习这些天到现在终于是看完 Recurrence and Transience
了，之前还是不熟悉长得奇形怪状的
notation，熟悉了就好很多，但不会每一章都要这么痛苦一回吧（，感觉最近实在是有点迟钝。Hoil
Lee 的那份答案这一章到这里就没有了，下一道题就是 Ergodic
Theorems，只能去看 Durrett 自己写的老版本答案，和 5th edition
稍微有点对不上但也没再更新了，也问题不大。</p>
<p>之前只能把 transient
和暂态的意思对起来，今天随手查了下才知道还有候鸟的意思，感觉非常有道理，再一想这个好像高中的时候讲过（，对不起我高三的英语老师了。<del>倒也没有非常对不起她，高三我真的有在努力学英语了，对不起的是高一高二的那位英语老师（（</del>。再想想其实有点没道理，单从字面上来看候鸟明明就是常返的，哪怕真的套
Markov chain 的 recurrence 定义也能对得上，所以 Transient is
Recurrent!（<del>哲起来了（学数学学得</del></p>
<p>被没有口袋的女装 PUA
惯了，今天穿了条有口袋的裙子还是习惯性在没有手的时候把东西用胳膊夹住。说起来我本来以为下雨天会很冷所以穿了长裙的，结果中午去骑车拿了趟快递下摆就湿透了，崩溃。</p>
<h1 id="月10日">9月10日</h1>
<p>今天又是全体济南人的节日！（</p>
<p>现在每天晚上去挑第二天喝什么茶已经成了一种固定的快乐了，甚至正在写一个
<del>茶饮料替代咖啡从口味价格和效果方面评价的可行性分析</del>
测评（，等我把所有猫超能买到的品牌和口味尝完就发（（</p>
<p>昨天拿到了之前影印的书，翻了下感觉排版有点丑（。今天闲来无事打开 <a href="https://hastie.su.domains/Papers/ESLII.pdf">ESL</a>
看了一眼<del>又舒服了</del>，不过总不会这种七百多页看起来就一堆废话的书我都要打印出来看吧，差不多得了。<del>读这个（相对来说）真轻松啊，跟看小说似的（</del></p>
<p>闲着没事的时候看到一份 lty 的讲义把 sub/supermartingale
分别标成红色和绿色来代表看涨和看跌，笑麻了。正好今天做题 <del>终于</del>
做到了 superharmonic function，才知道之前早就见到 harmonic function
了只是不认识这种形式。回头看了下<a href="https://math.stackexchange.com/questions/858817/why-are-stochastic-processes-with-decreasing-expected-value-called-supermartinga">这个回答</a>明白是在干啥了，<del>只不过我还是更喜欢
superman 的解释（</del></p>
<h1 id="月11日">9月11日</h1>
<p>今晚回来难得还干了会活，把 Durrett 的 Markov chain
章节通了，<del>当然是把打星号的部分先跳了</del>。以前还担心跳章节会有什么问题，结果每次看不懂下一章的时候就会回来把上一章跳过的部分读了，虽然对往下推进度也没有帮助，但是当时看起来很难的东西这时候反而成了舒适区，就有点草，然后竟然也都读完了。</p>
<p>往后翻了翻感觉读完 Ergodic Theorem 就可以换 GTM274 从 Brownian Motion
开始往下看了，但总觉得也没必要，现在 Durrett
这本成我的舒适区了，草。其实也不太清楚是不是把后面的东西留到概率论 2
后半学期再学，现在先去读点高统甚至去挑着读点 PIN
比较好，更搞的是下学期数学系那两门课我是一门都不想上了，现在看着课表又陷入了沉思然后开始重新排课，某些人有（至少）两个培养方案是会哪个都修不完的（</p>
<p>时不时会把 summing 看成
summoning，颇有一种把求和项都召唤过来加在一起的感觉，好像也没错（（</p>
<p>突然想到以后是不是可以把 solution manual
打印出来带去教室，就不用带电脑了（，<del>所以相比用电脑来说哪个更环保呢</del></p>
<h1 id="月12日">9月12日</h1>
<p>下学期课表又要变成不认识的样子了，已经连着三个学期了，补退选 II
要选的课比正选和补退选 I
加起来还多，后验上来看也都挺没效率的，只能说水平就这样知道吧.jpg</p>
<!--还是不知道泛函和 ODE 应该选哪个，从少花力气就能学得会~~和贴贴~~的角度来说当然是选 ODE，环友说 fyw 给分不错，但好像真没用。不过作为概统人要不要先买本祖师爷 Kolmogorov 的 Elements of the Theory of Functions and Functional Analysis 镇宅呢（x（看是不可能看，打字机风格的书看起来太难受了-->
<p>数学史的限选范围里居然有未央，好离谱<!--，要不要选了然后 PF 掉去面圣呢（他不会给我挂掉吧草-->（</p>
<p>Durrett 单推人今天才发现他还有写《<a href="https://services.math.duke.edu/~rtd/EOSP/EOSP2E.pdf">Essentials of
Stochastic Process</a>》，最新一版还是 2021
年，虽然我不一定看、目测这本很入门、和 PTE（坏了以后不能把它简称为
Durrett 了）有大量重合而且目测也不如 PTE 难，<del>但它排版比 GTM274
好多了</del>，还是想印一份留着。有可能 continuous time Markov chain
会用他的读，Poisson process 之前也只是在 Poisson convergence
里简单读过可以顺带梳理一下，听说这一本的 Martingale 和 Markov chain
顺序反过来有深意读起来很爽，最后一章那个 mathematical finance
看着也挺好玩的，摸鱼的时候把模型当 examples
看看。不过这书怎么这么多课后题（</p>
<!--说到 mathematical finance，我和我爸最后一次正常的对话是八月的一次闲聊，他问我在学哪个方向，我说概统，他说他在上财的时候知道的几个做计量经济学水平很高的教授数理基础非常恐怖，都是从概统转来薄纱的。然后感叹他自己因为高考选了文科，后来又荒废了数学只能做经哲方面的工作，以及告诉我学数学也很可能有走不下去的一天，到时转行离开也没什么大不了的。-->
<!--好平淡，还给我一种从小真的成长在高知家庭的错觉呢，已经和今时今日彻底决裂了。-->
<p>晚上翻了翻发现《天浴》一直想看但是又一直没看，带着电脑躺到床上开摆，结果一个半小时的电影我看了两个半小时才看完，中间每次崩溃了就按暂停先缓一缓再说，看完又崩溃了半个小时（。这种东西我都会看一眼摘要甚至更细的剧评再看，本来以为没什么的，然而镜头表现出的冲击力还是远远超出预期。</p>
<h1 id="月13日">9月13日</h1>
<p>下午和友人吃到了 69
折的海底捞，本来以为会想说的话也都没有说，吃饭要紧<del>（帽门.jpg</del>，眼泪最后还是从嘴角流出来的。<!--我和她在一起的时候还是会不止一次地想，和你们这种从小家境优渥一切顺遂的小孩还是好难互相理解，也不只是她，还有高中的时候被数竞组的同学嘲讽两年来没有一点进步的时候，被 ex 指责的时候，太多太多了。-->第一次吃四宫格的火锅，虽然大多数东西还是都下了辣锅，但是猪肚鸡汤好香，煮出来的面条也好香（<del>主要是味精加得多吧</del></p>
<p>逛了下那边的超市发现猫超的东方树叶种类还不是很齐，背了一瓶绿茶一瓶乌龙茶回来。</p>
<p>是第一次骑车去上地那边，走着走着感觉不太对劲，这不就是拉练的时候走过的其中一段路吗，好崩溃。沿着自行车道一直走结果被高德提示偏航，按照它的路线拐过去发现厢白旗桥下面非机动车不能通行，好崩溃（二度），勉强从人行道上过的，问就是全地形共享单车。回来的时候探索了一下才发现我原来走的是对的，干脆直接把导航关了，结果本来想从北门进校，骑到西北门才发现怎么过了，<del>好崩溃（三度（什么<a href="https://zh.moegirl.org.cn/zh-hans/%E5%B0%BC%E7%A6%84%C2%B7%E5%85%8B%E5%8A%B3%E7%8B%84%E4%B9%8C%E6%96%AF(Fate)#.E6.8C.81.E6.9C.89.E6.8A.80.E8.83.BD">纵使三度迎来</a>崩溃</del></p>
<p>最后在四教后面 30 分 28 秒极限锁车，以前以为只要超过 30 分钟就按 3
块钱算，实际上是超过 30 分 30
秒才算，<del>赚死（</del>。北京至少共享单车价格是比上海便宜一半的，在家的时候这种路程绝对不可能骑车，当然上海的公共交通建设其实就很少会让我骑这么老远，一般也就是解决下最后一公里的问题才会骑车<del>（没有拉踩的意思（所以北京这个共享单车价格不会是在弥补稀碎的公交吧</del></p>
<h1 id="月14日">9月14日</h1>
<p>试了试友人新提的公路车，差点把我腰撅断，座位往前调了调就变舒适了，差点忘记她比我高
5cm
这件事了（悲），但还是稍微有点够不到刹车。骑起来确实快，就是全地形适应力不太行，要换车的话还是得换山地车。</p>
<p>凌晨两点多看到新民路上有人在跑步，后面一群人骑着车一边追一边喊你这三千米不得跑个满分，其中一个还指着路边对同伴说我们每天早晨都是在这边集合然后带去东操训练，走这么远还不让骑车。原来是还在军训的新生，太猛了（</p>
<p>身体不舒服，晚上去猫超发现有临期饭团买一送一，就着本来打算明天喝的茶吃掉感觉稍微好点了，这个搭配还挺日式校园午餐的，但是是夜宵（</p>
<h1 id="月15日">9月15日</h1>
<p>这个学是一定要上吗.jpg</p>
<h1 id="月16日">9月16日</h1>
<p>最近遇到很多很伤神的事情，今天身体又不舒服躺了一天，几乎已经一周没有学什么新东西了。这么多年了，就是在无数这样的时刻慢慢变得迟钝的吧。</p>
<p>我也好想跑起来啊</p>
<p><del>（玩闪耀优俊少女玩得（收收味</del></p>
<h1 id="月17日">9月17日</h1>
<p>又到了该拿出这张图的时间：</p>
<p><img src="https://s2.loli.net/2023/02/02/pCU1j65TyFtKa8m.jpg" alt="holiday.jpg"></p>
<p>不好说，说不定我过两周又放暑假了，上学主打一个体验（</p>
<h1 id="月18日">9月18日</h1>
<p>今天好闲啊（，早上去偷袭了一下吴昊（女）的概率论
1，然后又去上了杨帆（男）的概率论
2，<del>总感觉求真书院的本科生课比研究生课难一点</del>。概率论 2 教材是
Durrett
PTE，作业基本从上面出，讲的四章我已经看过两章多一点了，梦幻开局。然后听老师念了一遍又在黑板上抄了一遍
conditional expectation
那一节，像回到去年何翔的抽代了一样，啊不是至少这课教材和讲课用的都是英文（，就，感觉以后周日晚上可以晚点睡了（（x</p>
<p>坐我旁边的是一个俄罗斯姐姐，似乎是求真的研究生新生，一开始没注意还想问她能不能加个微信把作业发给我一份，她转过头来我才开始切换语言系统（，有一种毫无防备突然开始
TOEFL Speaking 的感觉，很难绷（</p>
<p>发自我的手机</p>
<hr>
<p>（草</p>
<p>说起来下课还拿到了学生会发的开学加油小饼干，我寻思着恁大一个盒子不会是月饼吧，打开一看才知道是饼干。吃了才知道饼干里面居然是空心的还夹了字条（，很担心学生会的精神状态，不过居然拿了个数学相关，好评（。想起来上一个用优化问题类比的还是《<a href="https://mp.weixin.qq.com/s?__biz=MzU3NzA0OTA5Mg==&amp;mid=2247496244&amp;idx=1&amp;sn=f9e70244d2f20cae18b35db7ad3cf25b&amp;chksm=fd08355fca7fbc49ef82cfa95c7f0dd4d1b4db340d34794405c9782a20a69d69ef73916e0e46&amp;scene=27">求好人生的“优化问题”
| 毕业生代表吴清玉在北京大学2022年本科生毕业典礼上的发言</a>》（</p>
<p><img src="https://s2.loli.net/2023/09/18/JwOqntZ2aUBx6V8.jpg" alt="optimization.jpg"></p>
<p><del>但是我一个三维空间里的碳基生物为什么要做矩阵，我不能做点不抽象的东西吗</del></p>
<p>又联想到一个 random walk in <span class="math inline">\(\mathbb
R^d\)</span> 笑话：</p>
<blockquote>
<p>A drunk man will find his way home eventually, but a drunk bird may
get lost forever.</p>
</blockquote>
<p>（大概就是说 <span class="math inline">\(\mathbb R^2\)</span> 上的
random walk 是常返的，但 <span class="math inline">\(\mathbb
R^3\)</span> 上的 random walk
状态都是暂态，<del>实在不知道要翻译成什么样</del></p>
<p>睡前还是没忍住去看了芦毛灰姑娘最新一话，甚至有幼年帝皇客串，awsl（</p>
<p><img src="https://s2.loli.net/2023/09/18/fSaX3D492BO6Cix.jpg" alt="帝宝贴贴.jpg"></p>
<p><del>不准在中央面前无礼.jpg</del></p>
<p>有点难绷，然后特地翻到 20 话左右的地方去截了经典名场面（</p>
<p><img src="https://s2.loli.net/2023/09/18/NTY39UcXLw8751z.jpg" alt="不准在中央面前无礼.jpg"></p>
<p><del>帽门！</del></p>
<p>才发现这里帽的耳朵是往后翻的。最近赛马娘系列有<a href="https://bgm.tv/subject/407353">新漫画</a>了，看了第一卷感觉画风不如芦灰，又去看了看樱花桂冠的生平，有点子好奇大器晚成的故事要怎么做才能比较精彩。这个月到现在为止发了三张芦灰的漫画截图，并不是每张都有帽，但是居然每张都有皇帝。<del>这个世界上哪有什么鲁铎黑，只有鲁铎厨和扭曲的鲁铎厨罢了（（</del></p>
<h1 id="月19日">9月19日</h1>
<p>选课的时候说想听台湾腔今天还真听到了，本来还以为会是英文授课的，这下如愿以偿了（</p>
<p>上了两节数学课但还莫名挺休闲的，ODE
就是在扯闲篇，讲到最后成泛函了，怎么回事。期中考试似乎是随堂，不知道
1.5h
能考点什么，这下真梦回何宝的抽代了。讲义印了但还没到，急急急。写完昨天概率论
2 的作业发现 due 是
10.2，就，我知道大三了还这样真不是很好但我就是停不下来地焦虑（</p>
<p>掐指一算今天还真是从 jk 毕业之后第一次穿
jk（，<del>白丝真不耐脏啊</del>。<!--中午在食堂还人生中第一次被路人要微信了，不知道有没有因果关系，然而遇到这种情况是真有点害怕，一下子也反应不过来，拒绝了之后老担心这哥们折回来给我一拳（，晚上去食堂都还莫名有点害怕（（--></p>
<h1 id="月20日">9月20日</h1>
<p>今天最难的好像是现代生物学导论（，真不太会。高统在挂机以及听旁边两个哥们讲求真笑话（，运筹也挺休闲的。是不是我的选课有什么问题，现在总有一种学了概率论然后就可以到处嘎嘎乱杀应数课了的幻觉（暴论</p>
<p>这运筹课好没意思，<del>不过也是，建管系开的能有啥含金量，主人的任务罢了</del>，不如下学期去上个数学规划
<del>贴贴</del> 玩玩（</p>
<p>本来十一假期（如果还在北京的话）想去龙头牧场看看目白阿尔丹的墓碑，还想带束花带点胡萝卜（，今天一时兴起看了几个圣地巡礼视频又简单查了下，好像现在不开放了，牧场经营也出了点问题，残念。</p>
<h1 id="月21日">9月21日</h1>
<p>之前本来还想着如果压力太大的话就把优化理论换成非参导论水一下，今早做梦梦回上个学期在
zzy
课上坐大牢直接惊醒了，我脑子一定有问题才会想要再选她的课（叠甲：我不知道是她的问题还是我的问题，反正线性回归我坐大牢了，但也有同学说她讲得很好，所以可能只是我和她不合适）。退掉退掉，选优化理论
<del>去和 JasonL 老师面基</del>（（</p>
<p>昨晚本来不困，结果这个运筹课非要关着灯上，黑灯瞎火的给我整困了，就一边喝带的小瓶美式一边写高统作业。本来以为没什么问题结果晚上根本睡不着，好崩溃（，一边清醒着一边默念美式的美式的来安慰自己早八会没事的，最后还是有事了（（</p>
<p>感觉这学期的课程群几乎就没有，尤其数学课是真的一个都没有，哦原来是有
10
个学分的课我都还没选上啊（，哈哈，等我选上课网络学堂公告里的群二维码都过期了，怎么办呢（（</p>
<p>第一周就是在不停地发邮件问能不能冲选能不能手选，还有课后线下偷袭老师不停重复同一套话术：</p>
<blockquote>
<p>老师好，我不是数学系的/我是本科生所以要特殊原因选这门课，现在还看不到网络学堂不知道第一周作业是哪些，能不能邮件发我一份，谢谢谢谢，谢谢老师。哦哦不用担心虽然我不是数学系的但我学过前置知识不会听不懂的，对我一直有在上数学课，也知道我选这课是在干什么。啊还有我要第二周周中才能选上课，能不能把第一次作业的
ddl
延后一点或者给我个助教的邮箱我交过去，谢谢谢谢，谢谢老师，老师再见。</p>
</blockquote>
<p>想想应该再问老师加个微信群的，抽代的时候我就是从何宝那里直接扫码加的群，现在居然给忘了，残念。遇到好奇心强的老师还要解释一下未央是什么东西（，我一个学物理和交通的同学怎么就来学数学了呢，还有为什么不转系难道是不想吗（，好崩溃。优化理论应该是最后一遍了（，但是下周可能还要给各个院系的教务发邮件打电话催手选审批，秦清的微信我上学期就加了，这学期真不想再找她了（</p>
<p><del>说到抽代，又到秋季学期了，还能不能遇到像 Bowen L
那么可爱的助教呢</del></p>
<h1 id="月22日">9月22日</h1>
<p>第一周感觉就像体验上学，所有的课都像开盲盒
<del>而且也基本都不必修</del>，还就那个充满期待（</p>
<p><del>这周最大的感想是原来不是每个老师英语口语都像 wty
一样好，然而她已经润了，急</del></p>
<p>优化理论体感还挺良好，半听半摸的就过了，印象比较深的是讲 linear
programming 有人问为什么 cost function 里面有 <span class="math inline">\(|x_i|\)</span>
也还算是线性函数，我当时想到的是把它拆成 <span class="math inline">\(x_i\)</span> 正负部的和再多在 constraints
里面加两条不就变成线性的了嘛，结果老师说是把 <span class="math inline">\(|x_i|\)</span> 换成 <span class="math inline">\(y_i\)</span> 然后在 constraints 里加上 <span class="math inline">\(y_i \geq x_i ,y_i \geq - x_i\)</span>
就可以，虽然也是等价的但是突然感觉有点不爽（，也觉得好像没学过分析就不太会从正负部考虑。后来翻了下教材发现上面这两种形式都给出来了，舒服（</p>
<p>其实不算是严格的正负部，严格正负部的话 <span class="math inline">\(x_i ^+,x_i ^-\)</span> 之中必有一个是 <span class="math inline">\(0\)</span>，在优化里就把两个直接都当成非负数也没关系，<del>不要在意这些细节，警惕学魔怔了（</del></p>
<p>作业还没写完，但是在读 <a href="https://services.math.duke.edu/~rtd/EOSP/EOSP2021.pdf">Durrett
ESP</a> 的 continuous time Markov chains，写得比 PTE
友好而且入门一点，比如说这本上 Chapman-Kolmogorov Equation
的证明就直接用了 Bayesian Thm，PTE 当时用的是 Markov
property，初学直接给我干懵了（，但其实也是学到了很有用的技巧。然而令人悲伤的是
PTE 的 Brownian motion 我也已经有点子看不懂了（。</p>
<p>但其实 ESP
也还是有看不太懂的地方，虽然我有点怀疑可能是因为是直接从第四章开始看的，说不定有些东西在前面已经说过了但我没看到。之前打印凑页数满减的时候翻到了当年分系讲座的时候推荐的一份
<a href="https://www.dpmms.cam.ac.uk/~ps422/notes-new.pdf">lecture
notes</a>，这次正好拿出来对着看，就感觉稍好一点。</p>
<p>另外之前觉得这书习题太多了，现在再看感觉其实有点少（，几十道题全都堆在章节最后看起来很恐怖，然而
PTE 分散在每一部分的习题加起来可能比这个还多，不也都做下来了嘛。</p>
<p><del>然而哥们也还是做不动了，挑着写点吧</del>
<del>都在学概率论了，不如每次 random 一下选择做哪几道好了（x</del></p>
<h1 id="月23日">9月23日</h1>
<p>周末睡大觉.jpg</p>
<p>ODE
作业看起来很水但想写严谨的话还真有点烦，这课不会就这样吧不会吧不会吧.jpg，算了就当
<del>预习</del>
复习数分了吧（。我的确时常感觉到没学数分有点头大，但是又没有那个心力再回去学了，选点这种课随便复习点（</p>
<p>这个学期竟然有 11 学分的必修，太辛苦了。本来有 13
学分，但又担心万一剩的太少被按时结业就寄了，又退了一门。</p>
<p>晚上在答疑坊值班甚至没来得及填完奖学金申请表，经过去年入账 0
元之后我就知道我申自己院系的奖学金是自取其辱，<del>但万一今年甩给我两千块钱来加倍羞辱我呢</del>。去年必限/必限任在班级/年级里的排名这四个指标中的任何一个都可以拿来填学业奖学金，今年任何一个都到不了，甚至必限
GPA 在班级里已经是后 50% 了，我说你们也太可怕了罢.jpg</p>
<p>然而就算这样去年也没有拿到一分钱，今年不更是纯纯的自取其辱，随便糊完然后看乐子.jpg</p>
<h1 id="月24日">9月24日</h1>
<p>今早去偷袭了下隔壁，想起来明天是 runzhi
的生日就把他叫上一起吃饭了，出门之前翻了翻把我那本世图出版的 Functional
Analysis by Stein 当礼物送了<del>，写完 ODE
作业之后把剩的一小摞作业纸也塞给他了，怎么会是呢</del>。<del>数学壬真方便，送纸质数学书当礼物就一定没问题（</del></p>
<p>本来没什么事，突然跑过去是因为听说理教四楼的椅子很舒服（，于是去坐了一下（#每日坐椅子<del>（所以这个
tag 到底是什么梗（</del>。在那边半个小时写了三道 ODE
作业，昨天在三教一下午写了两道，高下立判（不<del>（当然是因为昨天下午先读了
Walter 又写的作业，而且前两道更麻烦一点</del></p>
<p>非常好北大，爱来自隔壁，下周末还去（</p>
<h1 id="月25日">9月25日</h1>
<p>来点手选笑话：</p>
<p>好消息是我下午一点多提交了所有的申请，三点就选上了优化理论；</p>
<p>坏消息是到现在还没选上另三门；</p>
<p>好消息是之前本来以为三门课要找三个不同院系的教务催审批，但现在来看不用了；</p>
<p>坏消息是不需要找教务是因为审批目前还卡在老师那里，还没轮到教务批（</p>
<p>报了个答疑坊小班辅导讲师的面试，其实招募是一周前的事了，不知道现在还缺不缺人。我也只能讲讲概/统/概统，不想再回去复习线代什么的，所以感觉就算面试也不是很需要准备，只是薪酬相比日常答疑来说还是比较可观的，有高中毕业之后带家教那味了（</p>
<h1 id="月26日">9月26日</h1>
<p>才第二周刚开始我就已经觉得这学期有点难顶了，现在最大的压力来源居然是，优化理论的作业必须
LaTeX
不能交手写（，还以为这学期终于摆脱基物实验报告了，结果来了个每周一次的纯英文实验报告（。</p>
<p>一下午一晚上没写完
HW1，当然也有教材后面一小部分还没看完的原因。还是感觉如果手写的话晚上总还能干点别的，难怪
zjz 在作业文件里写</p>
<blockquote>
<p>Please start early!</p>
</blockquote>
<p>（</p>
<p>晚上骑车的时候听到两个路人聊天：</p>
<blockquote>
<p>A: 那个算法导论的 ddl 是今晚吗</p>
<p>B: 是的，但是我网络学堂上还没这门课呢</p>
</blockquote>
<h1 id="月27日">9月27日</h1>
<p>今早在路上遇到一位好歌剧（，骑车从我和旁边一辆车的缝隙里穿了过去，虽然吓我一跳但完全没发生事故，好强（</p>
<p>（是在 neta 这个（（</p>
<blockquote>
<p>2000
年有马纪念，在和田自己选位不佳、加上其他优秀赛马的紧盯之下，好歌剧从起跑起被其他马死死围在马群核心。和田龙二多次起身观察脱出路线未果，直到最后
300
米直道，由于名将怒涛冲刺、成田路失速的机缘巧合，马群让出了一闪即逝、仅可供一马通过的包围网缺口，好歌剧立即从这一缺口切出并凭借强劲的末脚一路冲刺，反超名将怒涛以鼻差夺冠。（这也是游戏中好歌剧固有技能发动条件要求被团团包围的由来）赛后和田龙二称，他当时已经对比赛绝望，路是好歌剧自己选的。（<a href="https://zh.moegirl.org.cn/%E5%A5%BD%E6%AD%8C%E5%89%A7">出处</a>）</p>
</blockquote>
<p><del>玩闪耀优俊少女玩得（</del></p>
<p>这运筹学怎么天天关着灯上课，还在低速复读优化理论第一节课的一个零测度子集（，之前我问老师他还理直气壮地说这课不能替代，明明就是门水课。之前还想着下次带个台灯去上课，又感觉会被针对，麻了（</p>
<h1 id="月28日">9月28日</h1>
<p>在建筑材料课上困得睁不开眼睛，遂写现代生物学导论作业：</p>
<blockquote>
<p>我：</p>
<p>在建筑材料课上听老师讲化学</p>
<p>与此同时在写生物作业</p>
<p>这两门课我高中一门没考 一门 B+ 全班倒一</p>
<p>一个都不会 好崩溃</p>
<p>友：</p>
<p>草</p>
<p>远离数学寸步难行</p>
<p>我：</p>
<p>是的 但我现在数学也学得寸步难行</p>
</blockquote>
<p>放假前一晚 4-6 的自带 PF
的通识水课课前说有小测把所有人骗去，结束的时候又说没有，素质极差（</p>
<p>感觉这学期课也没有很多（挠头）但是为什么现在一天到晚都在学数学，不然连作业都写不完（</p>
<p>再来段传世经典（x）对话：</p>
<blockquote>
<p>友：球队有个学弟大一就开始数分高代几何 励志转数</p>
<p>我：要转的话不就该这样吗 我是失败例子</p>
<p>友：也是 还有个学弟写了三周代码就想转码 还想卷 AI</p>
<p>我：能理解 我写了三周的时候也想转 第四周好像讲到类了
然后就不太想转了</p>
</blockquote>
<h1 id="月29日">9月29日</h1>
<p>为了报 seminar 写了个 CV，然后轻微破防，我怎么除了 GPA 和并不完整的
core course 之外啥也没有（</p>
<p><del>如果报上了是不是就可以两周出入北大一次了</del>
不知道能不能去北大，但那样的话这个 ODE 大概真是留不得了（</p>
<p>这学期选了几门研究生课，现在看到 8 和 9
开头的近邻宝取件码都感觉有点像课程号，有点难绷。</p>
<h1 id="月30日">9月30日</h1>
<p>最近在听《<a href="https://www.bilibili.com/video/BV1FG411o7ui/">她似了，又活了。她没似，他似了，所以她也似了。她又活了，可他们似了，所以她又似了。</a>》，好美丽的精神状态，好喜欢（</p>
<p>给 lq 的博士生发了报名 seminar 的邮件，然后：</p>
<blockquote>
<p>收到，后续会通知申请结果以及具体信息。</p>
<p>祝好！</p>
</blockquote>
<p>这个东西难道还有筛选还会过不了吗，<del>你最好快点通知，要是过了第六周我就来不及退
ODE 了（（</del></p>
<p>假期为什么只开六教 A 区和清华学堂（，六教的蚊子太恐怖了，翻了翻
2022.09.21
的日记，一年过去了六教不知道第多少茬的新蚊子也还是和当时一样，只喜欢盯着我咬（。晚上鼓起勇气（？）探索了下清华学堂，在二楼看到数学学堂班专用的教室还是羡慕了（</p>
<p>之前一直觉得头发太长了不太舒服，今早起来终于克服懒癌把理发剪刀找出来剪短了，结果克服得太过了给剪太短了（，现在显得脸好大肩也好宽，本来就稀疏的头发显得更没几根了。本来还在安慰自己过两个月到冬天需要头发来保暖的时候就又长出来了，然后想起来过两天有社聚，看了眼鸽鸽鸽还有之前没面基过的社友来，好崩溃（（x</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇十四·23年10月</title>
    <url>/2023/10/01/Diary-2023-10/</url>
    <content><![CDATA[<p>好热又好冷，然而这已经算是北京比较舒服的天气了，受不了一点。</p>
<span id="more"></span>
<p>虽然其实每年的十月好像都发生点惊吓，或者一些事后看来也不是什么好事的惊喜（</p>
<h1 id="月1日">10月1日</h1>
<p>北大一日游，顺了一盒茶叶几本书一个挂件回来，还有公路车一周体验卡，我到底是去干啥的（（</p>
<p>晚上骑公路车沿着周边的几条大路 <del>描边</del>
飙车，不慎从路边一个下水口压过去的时候感觉车轮还没有下水道的缝隙宽，就挺危险的，全地形适应力实在是不太行。起步不太容易，速度太快了刹车也不好刹，需要提前好远就开始摁，有的时候最后还得脚刹，甚至我胳膊太短了如果不趴下去的话会有点够不到刹车。但是它快啊，骑着爽啊（</p>
<p>背单肩包实在不太适合飙这么远，中间累了的时候就不由自主地降低重心往车架上面趴，大概也能降低点风阻，<del>而且这样好像很专业很帅的样子（</del>。<del>有点联想到小栗帽的跑步姿势了，离地面很近几乎会平行什么的（玩（）玩得</del></p>
<h1 id="月2日">10月2日</h1>
<p>昨晚飙了一个小时车，今天成功发烧了，国庆假期 -1（。</p>
<p>但是下床吃饼干当晚饭的时候把还没布置的运筹学作业水完了，写完开始乐，顶点是什么松弛系数又是什么，这教材是一点看不懂，反正我是英文写的，总不会判错吧（x）。先观察下作业批改情况看看这课到底多逆天，实在不行第五周退了（</p>
<p>躺在床上水群的时候看到有人问搞数学怎么样算 taste
好，我也不知道，但反正我的 taste
就停留在教材至少要满足是用英文写的和是用 LaTeX 排的这二者之一（</p>
<h1 id="月3日">10月3日</h1>
<p>这个烧退了吗，好像退过，但是又没退，如退（</p>
<p>今天勉强往后看了点 LP，还以为可以把 ODE
写掉的。不是我说这个假期不会就要在生病中迷迷糊糊地过去了吧（</p>
<h1 id="月4日">10月4日</h1>
<p>清华学堂这个桌椅还挺舒服的，有很多可以踩的横杠，<del>腿短人在椅子上也可以缩成一团（</del></p>
<p>看了一天 <del>泛函分析</del> ODE（，还挺有意思的，只是把它用到 ODE
里就没啥意思，这几个核心定理的条件看着就有点丑（。之前还在幻想一上来就概统了岂不是失去了在很多方向上探索下的体验，现在简单探索了两周觉得确实还是概统比较有意思（</p>
<p>说起来感觉至今都没有认识的做动力系统的数学壬，别的方向多多少少都知道几个，除了概统之外认识最多的应该是代数壬
<del>虽然都是赛博人</del>，怎么会是呢。</p>
<p>晚上才知道大鸣大放居然也成为马娘了，之前还一直想着拿不到许可，第三季里怕是要直接删减
<del>看不到北黑吃瘪</del> 或者是用路人马娘代替了，Cygames 太强力（</p>
<h1 id="月5日">10月5日</h1>
<p><del>这赛马娘第三季一股浓浓的第一季的味儿（</del></p>
<p><del>大鸣大放好帅</del></p>
<blockquote>
<p>有特别篇珠玉在前，对跑步的演出有点无感。不过我跟巴普洛夫的狗一样，看到帝皇就开始头皮发麻，眼眶湿润，不知道怎么回事捏。</p>
</blockquote>
<p>说起来感觉看到了很多 neta，但是字幕没标注所以也不确定是不是在
neta（，<del>看芦灰的尾注看得（</del></p>
<p>终于还是下了个闪耀优俊少女开始养马（，逃不过这一天（。<del>能看到会动的小栗帽真好啊，帽门</del></p>
<h1 id="月6日">10月6日</h1>
<p>简单给 Intro to LP 前三章收了个尾，看 zjz 主页上的课程大纲似乎讲完
duality 之后就要开始 convex optimization
了，但有本书我还没印，<del>就非得印出来看吗</del>，虽然不急但甚至有点急。说起来我每次说
Jingzhao Zhang 的时候脑子里想的都是 Jingzhang Zhao，还有救吗（</p>
<p>本来今晚要去面试小班辅导讲师，结果嗯是到晚上六点左右才通知十点钟面试，这么晚而且看起来又很不靠谱（，干脆就咕掉了，进行了一个全程参加社聚。<del>想买副塔罗牌遇事不决玩一玩了</del></p>
<p><del>这么一说我感觉最不靠谱的好像是我</del></p>
<p>明天开始练习在一些 <del>不得不去又信息密度极低而且全是无效信息</del>
的土水学院的课上绣十字绣（</p>
<p>谋勇兼备退役了，之前还说是唯一一个在现役时代就进入赛马娘企划的马娘来着的。<del>铁鸟翱天和杏目什么时候能来，急（</del></p>
<h1 id="月7日">10月7日</h1>
<p>本来想打印下
Boyd，翻了一下什么原来有七百多页啊，那用纸质感觉还不如看电子版了（。Jun
Shao
那本数理统计也是太厚了就没打出来看，<del>不会真有人把查阅用的书打印出来看吧</del>，高统的话感觉听课看
PPT 也就差不多了，希望吧（</p>
<blockquote>
<p><span class="citation" data-cites="所有人">@所有人</span> 如果两位同学负责同一次 scribe
note，两位同学仅需要提交一份 note
即可，请两位同学私下自行沟通，并且相互检查最终提交的版本，谢谢！</p>
</blockquote>
<p>好可怕，为什么不能一人交一份（（</p>
<p>同一个概率论问题我给室友写过一遍，国庆前就在小程序里答了两遍了，今天在志愿者群里又答了一遍，晚上值班又答了一遍，有三个是看不懂
<span class="math inline">\(P_C(\cdot ) = P(\cdot | C)\)</span>
这个定义形式里面的点是什么意思（，一个是在纠结是不是要用概率的条件概率来算
<del>某种程度上来说水平很高</del>，还有一个没说哪里不懂。绷不住了，你们这作业
ddl 还挺长啊（</p>
<p>值班被问数值分析还给问挂黑板了，紧急临场打开教材 pdf
开始回忆矩阵条件数是什么以及若干
bound（，丢人（（<del>不丢人，我又不搞计算（（x</del></p>
<p>今天是周一，明天是周五，后天是周一，再过几天又是周五，1！5！（</p>
<h1 id="月8日">10月8日</h1>
<p>今天是袁洋给张景昭代课，但是（（</p>
<blockquote>
<p>张老师出去玩了，我给大家代课（</p>
<p>我虽然是搞优化的，但是这些我都没学过，simplex method
之前没怎么接触过（</p>
<p>十年前在 Cornell
的时候在同学强烈建议下我去旁听了一门优化课，但是没参加考试所以还是不会（</p>
<p>为了给大家上课我花了两个晚上学了这些，如果错了那是 zjz 的 PPT
有问题，不是我的错（</p>
<p>Farka's lemma 是个很核心的定理，我在 Cornell
读书的时候老师讲了四五节课，但是我只能讲十分钟，因为我也不懂更深刻的东西（</p>
</blockquote>
<p>我大震撼（x</p>
<p>总的来说这节课槽点实在太多了，偏偏是<del>（还不是自己选的吗）</del>今天在做
scribing，不过既然不是 zjz 本人讲的而且又有
PPT（问题是也还没发诶（，那岂不是自由度还挺大（x</p>
<p>申请奖学金的时候就说感觉是在自取其辱，还真是（，今年综奖是差额答辩但也没进，我估计单项更没什么希望。放在去年我还百思不解，难过了一阵子，今年就变成了：</p>
<blockquote>
<p>我好喜欢被未央书院羞辱啊！</p>
</blockquote>
<p>无所谓，毕竟早就想到答疑坊志愿工时兑换成津贴所得的收入期望比拿去评奖学金更高了来着。室友给我看了几个综奖入围的公示材料，有的按我对一些事情的
<del>吃瓜</del> 了解来说感觉挺虚浮的，换到我身上的话我觉得自己做的最
concrete
的事情还是学了几门数学，不过这放在评奖学金这件事里毕竟是扣分项。</p>
<p><del>某种程度上来说这个破地方也有优点，让我在一事无成的时候仍然充满自信，并且坚定相信是书院的问题（</del></p>
<p><del>既然要延毕那好像就有四次申奖学金的机会，这么说来可以又双叒叕被未央书院羞辱，好兴奋啊（</del></p>
<h1 id="月9日">10月9日</h1>
<p>因为隔壁今天才开学的原因所以我的假期其实也跟着续了两天（，该好好学习了（（</p>
<p>虽然杨帆上课是 Durrett PTE
reader，但其实属于是听他念书也学到许多。今天发现上节课的其实都差不多忘完了（，但记住了一个挺有用的反例，就想起来还在学概率论
1
的时候甚至学完之后一段时间都时不时在几乎处处收敛和依概率收敛还有对应的期望上迷糊，每次都是仔细想想
lzx 期末默写的那个刻进 DNA 里的反例就明白了。</p>
<p>今天在讲 optional stopping theorem，有个定理觉得很熟悉，遍寻 Durrett
而不得，再一想是 lzx
当时的期末题。期末前最后一节课他就讲了半个小时鞅论，当时说要考这个的时候我还在心里吐槽是谁搞出来一个这么无聊的结论，从来没想到其实是在一个很重要的问题框架下的
lemma，就挺深刻的。再看一眼其实两个月前做习题的时候就做到过，只是放在习题里的时候
stopping time 的符号是 M 和 N 就没有认出来，今天课上用的是 S 和 T
才发现，绷不住了（</p>
<p>来一句九月份我最喜欢的摘录（x</p>
<blockquote>
<p>在华子通过上课来获取知识算是获取知识的鄙视链底端，但我必须要说数学这玩意自己学跟上课还是两码事（</p>
</blockquote>
<p><del>如果不是统辅课的话（</del> <del>统辅课算数学课吗</del></p>
<p>发自我的手机</p>
<hr>
<p>你院又在配对学业导师，大三终于可以填不需要导师了，<!--也不用去面对和我同一个导师的那几个逆天人了，-->赢！这么说来军训期间我前两年水利系的那个学业导师那次约饭其实是和她的最后一顿了，但我没去，怎么还有点子残念（并没有</p>
<p>去年秋季学期的第四周左右我约了一次 dwl 的 OOH，和她浅聊了 20
min，我也不记得在说什么了，现在印象最深的是她好像不是很会画眉毛，手机壁纸是她一家四口的合影<del>（对不起我不是故意看到的）</del>，以及她当时说自己在北大读本科的时候因为感觉女生不适合学基础数学所以选了统计，给我整不会了。倒也是我第一次去找老师聊天，<del>后来还聊了好几个老师，干啥的都有</del>。她讲的每门课我都学得很烂，初概直接绷不住
PF
了，在她那儿学的那些个初等高等夹心知识遗害无穷（，多元统计期中爆炸也就退了，打算下学期去上数学系那门同名研究生课。</p>
<p>为什么会想起来呢，因为今天听说有人想邀请她当自己的学业导师（。另外那个上学期评教结果里全校第一名的课是她这个多元统计，第二名是
zzy 的线性回归，反正这两门课我都大坐牢，太难绷了，感觉不如 lzx（。</p>
<hr>
<p>答疑坊小程序现在不仅新订单提醒消失了，连回复提醒都不好用了。有个单子以为早就结束了，没收到对方的追问回复提醒就给鸽了，然后查了下答疑订单统计里的平均分，哥们似乎被送了个一星差评，再接
300 单就可以把它稀释回原来的水平了，虽然也没啥用但还是有点难绷（（</p>
<h1 id="月10日">10月10日</h1>
<p>终于跳出了
1！5！的循环，但是有没有一种可能其实只是在一个比较大的循环的中途（</p>
<p>#闲的程度，今天发现优化理论一个助教在网络学堂填的邮箱是
tsinghu.edu.cn（</p>
<p>但其实一点都不闲吧，这课怎么作业这么多（，昨晚才刚把 scribing
交了，今天从吃完午饭开始写 HW2，卡着教室关门的点写完。印象里 HW1
我周二断断续续写了一晚上，周三在高统课上继续写，到晚上运筹学还在写，实在不知道什么时候写完的，所以说相比之下
HW2 还是很快的（错乱</p>
<p>Geogebra + tikz
画图真好看啊真好看（点头<del>（如果把格线去掉的话</del></p>
<p>感觉学得不大扎实，也不是说不扎实，课上讲得好少把进度拉得好快，作业又似乎会布置一点
reading
的部分。这书是写得又细又好，说到底也没啥本质难度，但信息密度太大了，三周上大几百页的内容哥们是真有点看不完（，您们茶园是这样的吗（</p>
<p>今早躺在床上看到一个<a href="https://www.zhihu.com/question/615184782/answer/3154343306">知乎回答</a>，乐到垂死梦中惊坐起：</p>
<blockquote>
<p>他或许没有多么光彩的过去，但他可以埋葬许多光明的未来</p>
<p>——写给我的班主任</p>
</blockquote>
<p>也写给我的高中班主任（</p>
<h1 id="月11日">10月11日</h1>
<blockquote>
<p>你好，你的申请已通过，方便加一下我的微信，之后可能会拉微信群。且需要提供一下身份证号码和电话，用于申请北大的入校预约。</p>
</blockquote>
<p>看来 CV 还是有点言过其实（x</p>
<blockquote>
<p>简历上的干货有一页吗？</p>
</blockquote>
<p>复习下 hx
的（前）微信签名，看了一下现在已经是“不好！含猫量要超标了”，头像也换成猫猫而不是柴犬了（。<del>可是我的
CV 还不到一页，说明有用的东西确实严格小于一页（x</del></p>
<p>好好好（指下周六就可以去北大了<del>（你这统计中心又没地方开讨论班，以后会不会全放在北大，看看人家数院新楼</del></p>
<p><del>太好了 ODE 不用太认真学了反正也不必修（速速 PF！</del></p>
<p>摸鱼玩赛马娘的时候感觉波旁跑步好让人放心，毕竟是跑逃的，从头开始就是前几名，不像某些跑差和追的（</p>
<p>今天是 Yau
发表如此成績如何招生讲话三周年！说起来周末我就要去求真招生考核现场当考务
<del>顺便一边感叹小朋友们的强度一边感叹怎么进了这么个大坑</del>
了，应该招生招得还蛮好的（</p>
<h1 id="月12日">10月12日</h1>
<p>建筑材料课上讲化学，梦游中听到老师在夸一个在积极互动的同学“你提的问题全都是我这节课要讲的答案”，醒了，整不会了。这是什么，dual
的 dual 是 primal，function 的 function 是 functional 吗（（</p>
<p>看完赛马娘第二集感觉又好又怪，激情吐槽剧透一波（。</p>
<p>内恰对话那段第二季的味上来了，<del>小北黑和小光钻比赛疑似 neta
血统（还是说是 neta 竞拍价呢
x）差距也挺不错的</del>，但演出还是好尬（。帝皇开始学老父亲装冷酷了，好不习惯
<del>但总感觉大概私下去安慰过大鸣大放了罢，也管管北黑啊</del>，看到曾经的第一季主角特别周仅有的台词又是胡萝卜特饮感觉一如既往的胃疼（。在马路上看新闻放送的时候北黑的耳朵都快扭断了后面还要在和内恰的对话里再说一遍是因为感觉大鸣大放不参赛自己可能会赢而羞耻，勉强当做引出对话而不是这点事情都要掰开揉碎喂给观众的话还稍微好一点（<del>是否有点婆罗门发言了</del>。比赛做得就（，咋这么急啊，<del>怎么不先表演个跑一次坂道三本再来比（</del></p>
<p>ED 的麦昆每一帧都好可爱，我开始非常理解帝皇（</p>
<p>这都两话了，大鸣大放你说句话啊大鸣大放（，<del>再不说话跑完宝冢纪念就要退役了</del></p>
<p><del>小北的爸爸是在 neta 马主吗，笑裂了</del></p>
<p>晚上水群的时候聊起来周末去求真招生考试当考务的事情，然后和 <del>2019
年华二复附丘班考核联合小队队长</del> ycj
单独聊了几句，话题最后还是又拐到了赛马娘，<del>啊不是，闪耀优俊少女的神奇翻译（（</del></p>
<blockquote>
<p>我： 说起来日服的有马纪念是叫有马纪念吗
国服我目测改成中山大奖赛了</p>
<p>ycj：</p>
<p>是的</p>
<p>草 懂了 反正就是不能有马</p>
<p>我：</p>
<p>草 没马了（确信）</p>
<p>ycj：</p>
<p>还真是 怎么不叫有人纪念</p>
<p>我：</p>
<p>有优俊纪念</p>
</blockquote>
<h1 id="月13日">10月13日</h1>
<p>虽然不管怎么样都不会这么选，但细细一想我确实已经完全失去大四在华子推研的可能性了（主要是因为前三学年必限差好多没修完（，甚至感觉到一丝淡淡的惆怅（x</p>
<p>看了眼数学系推研分享的讲座，认识的几个人都润到北大去了，急了，强基连外推这个选项都没有（<del>但我也不保研啊</del></p>
<p>每到秋冬都很理解冷静这个词里面为什么会有冷这个字，下午在三教差点给我热到昏迷，然而教室里所有人穿得都比我多看起来好像也没有觉得热的，好恐怖。吃完饭换了个教室坐到窗边才好一点，紧急呼吸一口
17 度的空气.jpg</p>
<p>在教室写笔记的时候突发奇想拿手里的东西整了个小活，想必这里是复旦罢（<del>十字绣至今没动工别骂了别骂了</del></p>
<p><img src="https://s2.loli.net/2023/10/14/Jhue2dEy3BXq4xn.jpg" alt="FDU.jpg"></p>
<h1 id="月14日">10月14日</h1>
<p>现在已经到了错过饭点连外卖都懒得点的程度，去猫超买瓶乌龙茶买个饭团，结完账用那边的微波炉热好拿到
C
楼一层站在窗边吃掉就糊弄掉一顿饭了，没喝完的茶下午继续（。虽然还是会有点饿，但是糊弄糊弄就很省事（</p>
<p>该写现代生物学导论的思考题了，正好明天很早就要起，今晚干脆去答疑坊值了次班，<del>这样是不是期中周就不用值了</del>。6A014
实在是个很冷静的地方，可能是我坐在窗边的原因，但是赚了两个十月中旬的蚊子包，还是隔着丝袜咬的，实在有点难绷。</p>
<p>无论是怕热还是非常吸引蚊子，种种证据或许都支持我现在实在太胖了，至少体脂率有点高这件事（不愿面对.jpg</p>
<p>上次学生物还是高一下学期会考之前紧急翻书
<del>然后考前就扔进了北二楼的垃圾桶</del>，已经过去四年了，不管是上课还是看思考题每次都体验语言恐怖谷效应（</p>
<blockquote>
<ol type="1">
<li><p>什么证据支持“蛋白激酶必须要和周期素结合才能被激活”？</p></li>
<li><p>为什么一种特殊的生长因子如神经生长因子（NGF）只能促进神经元的生长，而不能促进其他种类细胞如红细胞前体的生长？</p></li>
</ol>
</blockquote>
<p>你到底在说什么啊（（</p>
<!--晚上出门之前突然接了个支线任务，去逸夫馆帮友人借了两本 CV 的书。这次找书找得非常顺利，我以前每次去借统计相关的书都要找好久，后来直接变成自己打印出来看了，毕竟图书馆借的书也不能随便乱涂乱画做批注。-->
<!--然后想起来这学期那两本没打印出来的书怎么没想着去图书馆借，查了一下也都没有，算了。然后又长出一口气（，万一真有的话借来了还挺负担的，大概只能放书架上镇宅了，我也并不喜欢背着很重的书跑来跑去，要么就看电子版要么就打印出来然后拆成一页一页地读了。-->
<blockquote>
<!--友：这两本是清华大学出版社的 我们图书馆的被借掉了-->
<!--我：我查了一下西馆还有八本 你要吗-->
<!--友：爹-->
<!--我：好（-->
<!--我：但是这看起来像是那种翻译得依托的中译本 为啥不直接打印原版书看呢-->
<!--友：求你了别骂了帮我借借吧-->
<!--我：好（-->
</blockquote>
<!--抱着两本计算机的书出门感觉怪心虚的，还好回寝室把电脑之外的东西都放下了，塞进包里迅速逃跑了。-->
<h1 id="月15日">10月15日</h1>
<p>今天好多事别的就啥也没干，早晨监考，中午去北大送了下书然后又回来取答疑坊优秀志愿者的奖品，结果还没拿到奖状，本来还想着这是我在华子收到的第一份实物奖状来着，诚惶诚恐。硬说类似物的话可能也只有去年逻辑学暑期学校的证书了，我还以为开学之后可以去领纸质版的，结果就只有个电子版。</p>
<p>下午被一个来送考丘班 <del>顺便回母校转转</del>
的老师叫去和以前认识的几个同学吃了个下午茶，<del>听了很多求真笑话和数学系笑话，你要是问我我只能说无可奉告</del>。我
2019 年考金秋营的时候这哥们还在质心，当时他有个几何题（本质是 Japanese
Theorem，不知道为什么叫这个<del>，日本没别的定理了吗</del>）的解答不会写还问我怎么做的，我告诉他我归纳硬算的，给他整不会了，这哥们现在已经润去重庆某中学带竞赛了。本来还约了
runzhi
一起结果他临时鸽了，看来一个月里见到这哥们两次只存在于我高二的时候和他的教室只隔着一道墙的情况。</p>
<p>晚上一起吃了个饭，等位的时候有点 social
不来所以把优化的笔记写完了，来自隔壁的群友在旁边看数算
PPT。我也不知道自己在发什么病把华子的校园卡反过来扣在了他电脑屏幕上，结果进去的时候哥们把电脑一合直接带走了，晚上我骑到学校门口才发现，草。待会半夜还得去东门取一下，绷不住了（</p>
<p>我超我腰要痛断了，怎么会这样（</p>
<h1 id="月16日">10月16日</h1>
<p>我超，我的腰怎么又双叒叕痛成这样了，绝不调（</p>
<!--因为痛苦就是无边无际-->
<p>早上概率论 yf
突然说目测这门课上的外国人都退课了，这节课开始就用中文讲课英文板书了，<del>这确实是最方便的一种做法，然而我担心的是外文认证课还差一门才能免修听说，急了（10.17
upd：等一下我是不是把优化理论给忘了，加上上学期的生统概论其实也就够了</del>。讲了五分钟之后俄罗斯小姐姐走了进来又换回了英文（，<del>求你了别退课好吗</del>（草（</p>
<p>今早把 PTE 4.8~5.2 塞包里出门，还以为他要把 application to random
walk 讲掉然后向 Markov chain 奔去（草，结果讲的是 4.7 backwards
martingale 和 4.3.4. branching process，<del>这下真
backwards了（</del>。Markov chain 就讲了最初等的一点，急了
<del>但是摸鱼也挺好的</del>。说起来这哥们好喜欢用 random graph
讲课啊，感觉学多，查了一下他确实搞这个。</p>
<p>看到 ODE HW1
被扣了分还以为哪里写的不严格，打开一看原来是算错了啊，那很正常，长舒一口气（</p>
<p>昨天下午和杨不亚老师聊天的时候他说自己算不了一点，当年在质心上课的时候每次都是提前算好一个过程和答案对起来，然后上课的时候假装在当场算实际上在往黑板上抄。<del>也因此分析都学得一般，尤其
PDE 坐牢，跑去搞代数了</del>。另外这哥们 2019 年
<del>作为最后一届数学中心的非应用统计</del>
硕士毕业<del>（非常神秘，他是做自守形式的，居然拿了硕士学位毕业了）</del>，和我相差九届，<del>学号后六位差
500（</del>，但都上过 lzx 的概率论和 dg
的毽球课，还干过答疑坊，讲了不少破事（</p>
<!--（有个关于 lzx 的乐子就是说，在 2015 年之前 lzx 的概率论都非常初等，结果那年 wh 来华子开了概率论的平行班讲高等的内容，一个月冲完 lzx 的教学进度然后往后塞爆什么的。第二年开始几乎所有人都选 lzx 不选 wh 水过去，导致 wh 要求 lzx 一定要上强度，草。然后我才意识到 lzx 上课动不动说 wh 要求他怎么怎么讲原来确有其事，当时去找 wh 的时候她也和我强调 lzx 的概率论和求真的那个系列大有不同，草）-->
<p>然而我之前没有开过他的盒，今天上网一搜看到他还写过一份 Hartshorne 的
solution manual，开头是这样一段：</p>
<blockquote>
<p>(2019.6.9.)</p>
<p>Sorry for my decision to stop updating the amendments. I think I will
not update this pdf of solutions anymore. I got no offer for a Ph.D.
program this year. Maybe that’s because I have no talent and luck to
study mathematics. So, that’s it. I give up. Best wishes for everyone.
Thanks to my friends who helped me correct my answers, and some guys on
Internet who sent me e‑mails and encouraged me. But, bye‑bye!</p>
</blockquote>
<p><del>相比这哥们我肯定 less talented，背后一凉</del></p>
<h1 id="月17日">10月17日</h1>
<p>打开概率论 2 这周作业：</p>
<blockquote>
<ol start="7" type="1">
<li>An ant randomly travels along the edges of a unit cube. Each step,
it travels from one vertex to an adjacent vertex. Starting from a
vertex, what is the expected number of steps the ant is to travel to
first reach the diagonal vertex?</li>
</ol>
</blockquote>
<p>什么 vertex，什么 adjacent，<del>为什么不说 basic feasible
solution</del>，我穿越到隔壁优化了？（</p>
<p>这作业的 ddl 是 10.31
还把这件事写在了作业标题里，大写加粗地告诉我这个月要过完了（迫真），然后就要考四门数学期中（草）了，急急急急急急急（</p>
<p>感觉这课的作业变难了（并不是说上面这道题（，也可能是我变菜了，感觉
optional stopping time 那里不知道为啥就是不太会证明 <span class="math inline">\(X_{n \wedge N}\)</span>
的那些个性质。之前自己看书做习题的时候就不太会做的几个问题也全被挑出来当作业了，有一个
optional stopping time 的题光是证明收敛就想了好久，最后一小问问了点
intuition 但我显然是不知道，当初在两份 solution manual
上都没找到就放掉了，今天居然在 <a href="https://services.math.duke.edu/~rtd/EOSP/EOSP2E.pdf">EOSP</a>
上找到了这题，去查了下 Durrett 的 solution manual：</p>
<blockquote>
<p>..., using the optional stopping theorem at time <span class="math inline">\(V_0\)</span>, noticing <span class="math inline">\(S_{V0} = 0\)</span>, (and not worrying about the
details) we have ...</p>
</blockquote>
<p>草（，你知道你 not worrying about 的 detail
我证了多久吗（，这书果然比 PTE 简单点（x</p>
<hr>
<p>啊痛痛痛</p>
<h1 id="月18日">10月18日</h1>
<p>第五周高等数理统计终于开始讲统计了（，虽然也就讲了一个 delta
method，<del>但高维的之前还真不会</del>。只是复习概率论的这几节课也时不时膝盖中箭，今天复习弱收敛然后每个定理看着都这个妹妹我曾见过（，你要是问我
<del>妹妹叫什么名字</del> 定理怎么证我就只能干一碗饭（</p>
<p><del>但是这么多妹妹真的需要知道她们每个都叫什么名字吗，难道不是记得长什么样自己比较喜欢哪个，需要的时候再问名字不就好了（什么渣男发言</del></p>
<p>但好消息是我还会证明 CLT，甚至是 Lindeberg &amp; Feller 的 CLT（</p>
<hr>
<p>啊痛痛痛痛痛痛痛</p>
<h1 id="月19日">10月19日</h1>
<p>写运筹学作业写破防了，四道计算算了一下午一晚上，<del>往好处想是弥补了优化理论天天搁那证明从来没算过一个具体的算例</del>，确实也<del>学到一点</del>
复习了一点 full
tableau。但哥们现在非常害怕运筹学期中出问题，就是说我至少知道 simplex
method 中文叫单纯形法，但你要是告诉我求 basic feasible solution
那个公式叫做典式，把 reduced cost 取个负的就叫检验数然后 optimal
情况下检验数是非正的，还有那个什么单纯形表和 full tableau
之间存在一个我也记不住的初等变换关系（，那我可真的不能再多记这么一套莞莞类卿的体系了（</p>
<p>反正我作业都是用优化课学的那一套语言和方法做的，要是那个建管系的助教看不懂还嗯说不能这样按最标准通行的方法做（<del>不知道是不是刻板印象但我总觉得这种事情在土水学院的课上很常见</del>）的话我可就要退课走人了！</p>
<hr>
<p>最近在小程序答疑收获的一些称呼：</p>
<blockquote>
<p>谢谢学长</p>
<p>太厉害了哥</p>
<p>谢谢哥哥（啊？</p>
<p>师兄太强了（刚开完组会？</p>
<p>大哥辛苦了</p>
</blockquote>
<p>怎么会是呢（，除了线下面对面的几次答疑之外还从来没有人正确地叫过我学姐/学妹（？（</p>
<p>我的名字看起来真这么中性吗（挠头），不确定的话为啥不直接叫学长（，哥们（？）有点绷不住（</p>
<h1 id="月20日">10月20日</h1>
<p>昨天说害怕运筹学期中出问题，今天直接收到助教邮件，大概意思说我用英文写作业是在和另一个同学互相抄袭，通过中英互翻来掩盖，我真绷不住了（（</p>
<p>稍微 argue
了一下，把优化的课程大纲和教材发了过去，<del>差点想说运筹这课开学到现在我就没听过你可别瞎说了，第一次作业我闭着眼都能写何苦去抄别人的还翻成英文，</del>最后还是忍住了，好佩服我自己（。不知道他还能整出什么活来，<del>大不了退课</del>（</p>
<p>明天去北大听讨论班
<del>但估计第一次就是团建性质的，主打一个旅游</del>，急急急急急急急急急急（。这么说来讨论班和答疑坊正好都是单周周六，还就那个每两周大休息一天（</p>
<!--这周终于过完了（，每天（尤其上周末）都在好艰难地降低自己的存在感（（-->
<h1 id="月21日">10月21日</h1>
<!--在友人寝室的床上（不然手肘很痛）和她掰手腕，我是不是太抽象了点（。然后才知道我一直觉得自己手劲不小，但十多年来掰手腕胜率极低是因为我一直以为要通过手臂发力，潜意识里觉得手腕发力会容易受伤，但实际上大家都是手腕发力所以自己不用力反而更容易受伤。每次对方在对着自己的手腕用力的时候就感觉手腕要被折断了，手臂力量掰不过，为了防止受伤就速速放弃用力认输了。-->
<!--果然是物理学得不好啊（-->
<!--学到了正确的玩法之后她两只手都掰不过我一只手，我是不是太抽象了点（-->
<p>讨论班，但是隔壁数院 110 年院庆（</p>
<p>拍了一点游客照，拍完就尴尬地逃跑了（，如果哪天我有学术主页了真的很想拿这个当照片（
（</p>
<p><img src="https://s2.loli.net/2023/10/21/KAFBEDomyTJihlC.jpg" alt="pkusms110.jpg"></p>
<p>说起来还在签名墙看到单芃老师的签名了，不知道是不是 YMSC
那个单芃，查了下她是清华毕业的，怎么会是呢（</p>
<hr>
<p>想想还是再说几句，第一次 seminar
是林乾的博士生讲了他最近做完的一个有关 kernel ridge regression
的问题，也没讲什么具体的推导所以就听个框架，四舍五入就只有组织讨论班的几个老师和他在聊，我就听个乐呵了。而且说实话也听不太懂，属于是一边听一边查，什么是
reproducing kernel Hilbert space，我只能说 kernel 和 Hilbert space
我上学期最后自己读 Stein 的时候是学过了，连起来是什么东西（，reproducing
又是啥意思，查了一下算是泛函内容，感觉也不可能真在泛函的课上学到这个东西。</p>
<p>这学期上完五门课，之后还有个概率论 3
和复分析<del>（四舍五入是留数定理）</del>属于必要的基础，就真的算是在科研之前把该学的都学完了，然而暑假读个论文读了俩月每个
notation
都不知道是啥的场景还历历在目，我相信也不可能在哪一门课上真的学到这些。什么时候能迈出学的舒适圈，而这个由自己圈定的舒适圈似乎又无边无际，我仍然一无所知。</p>
<blockquote>
<p>如果提前了解了你所要面对的结局，你是否还会有勇气前来</p>
</blockquote>
<hr>
<p>下面是突然想起来这周的赛马娘还没看，于是来点第三话激情吐槽（</p>
<p>赛马娘的时间线本来就是乱的，我还以为北黑第一次有马纪念同时作为船的退役战是不会把这两个人放在一起做了，毕竟这动画前两季总给人一种船和帝皇麦昆同期，比特别周小一点，但又比北黑大好多届的感觉（。另外之前也不太知道赛马娘退役要什么整，原来还有个梦之杯当复活甲啊（，原来第一季末尾那个做了不如没做的
18 人同时冲线的比赛就是这个啊，难怪还能看到鲁铎亲自上场跑步（（</p>
<p>大胆暴论一手，特地做个退役感觉是要等到男子汉的谢幕之际的时候照应一下。最后丢魔方也很有意思，你现在是
G1 一胜，我有六胜，希望你能达到七胜.jpg，<del>但是想代表 G1
五胜的话难道能转到有且仅有五面同色吗（（</del></p>
<p>现在已经不指望小栗帽能作为背景板吃饭了，这一集还能在路人的台词里出现就太感动了（</p>
<p>观众席上笑着看船跑完最后一场的大叔，你一定是今浪老爷子吧.jpg</p>
<p><del>大家围着小北鼓掌和 omedeto 的时候很难不联想到 EVA（</del></p>
<p><del>然而船跑完开始喊要在梦之杯击败巨匠和贵妇人，很难不怀疑梦之杯指的是配种（</del></p>
<p><del>制作组你太懂我想看什么了，我就想看船的颜艺，她不管突然发出什么奇怪的声音都很合理（</del></p>
<p>感觉到这里已经图穷匕见了，第三季就是粉丝向作品，<del>幸亏是在第二季入的坑，</del>希望评分没事。</p>
<h1 id="月22日">10月22日</h1>
<p>教室友写概率论作业，证明题我看一眼就 chua chua chua
写，<del>小学奥数</del>
计算题我除了枚举没任何思路，算了两遍每次离散分布的概率和加起来都不是
1，一次比 1 大一次比 1 小，好崩溃，<del>有没有 1，好想要 1（</del></p>
<p>#闲的程度
给昨天的照片植了个发，看起来顺眼多了（，<del>属于是摄影师没有提醒导致的拍照失误而不是我本来就没头发所以修图修出来不算是照骗</del>，在一些需要用自己照片的场合就打算用右边那张了（喜</p>
<p>周五那节优化被我大休息过去了（，今天读完了 duality
那章剩下没讲的内容，感觉学到很多，学到的比讲过的还多（，你甚至能在优化里面看到实分析和点拓（其实就一点点）。刚看完
separating hyperplane theorem 再去读 Bubeck
那一本的第一章发现怎么又是这个（，有一种开上帝视角学习的美感，然而凸优化围绕
black box model 展开还是给了我一点小小的 TCS 震撼（。再看第二章怎么又是
center of gravity method 和 ellipsoid method，原来上周五那节优化讲的不是
Bertsimas 的 Chapter 8 而是已经开始讲凸优化了啊，学到许多（（</p>
<p>这两本书关于 ellipsoid method 的一个 bound 还略有不同，一个是 <span class="math inline">\(\exp(-\frac{1}{2n})\)</span>，另一个是 <span class="math inline">\(\exp(-\frac{1}{2(n+1)})\)</span>，放缩的细致程度有非常细微的差别。哥们以后周四晚上还是早点睡吧，这课真没边没沿的，handout
又很咕，scribing
更是不知道咕到哪里去了，不仔细听一下的话直接就变成那个自学三本加起来一千多页的书。说起来哥们国庆之前写完的
HW1 到现在还没批呢，有一种助教和老师上课时间外完全失踪的美感（</p>
<h1 id="月23日">10月23日</h1>
<p>我以前一直以为 strong Markov property <span class="math inline">\(E_\mu(Y_N \circ \theta_N \mid \mathcal F_N) =
E_{X_N}Y_N\)</span> 右边式子展开写是要写成 <span class="math inline">\(E_{X_{N(\omega)}(\omega)}
Y_{N(\omega)}(\omega)\)</span>（救命，实际上今天课上 yf 一说才注意到
<span class="math inline">\(Y\)</span> 本身所在的 <span class="math inline">\(\omega\)</span> 和 <span class="math inline">\(N\)</span>
所在的并不是同一个，原因很简单就是因为这里的 <span class="math inline">\(Y\)</span> 从 <span class="math inline">\(X_N\)</span> 开始，而 <span class="math inline">\(X_N\)</span> 这条 chain 是从 <span class="math inline">\(x_0\)</span> 开始的。所以应该是 <span class="math inline">\(E_{X_{N(\omega)}(\omega)}
Y_{N(\omega)}(\omega^\prime)\)</span>。只不过这个其实不写也无所谓（，只是不能乱写，考虑
<span class="math inline">\(\varphi(x,n) = E_{x}Y_n\)</span>
的话实际上右边就是 <span class="math inline">\(E_{X_N}Y_N =
\varphi(X_N,N)\)</span>，<span class="math inline">\(Y\)</span>
本身的取值不重要，只是取它在初态是 <span class="math inline">\(X_N\)</span> 下的期望而已。</p>
<p>感觉学到很多，Markov property construction
初学的时候我看了很久很久，然而今天听了课发现还是有一点误解。虽然 yf
说了好几遍今天讲的东西都是 abstract and useless junk, but let us stand
on solid ground（，真的假的（</p>
<!--令人后悔的是第二个课间我点开了真故计划今天的更新(指路 https://mp.weixin.qq.com/s/7j2MXAgWP37wwTWwra8J0Q)，然后第三小节就没怎么听，一直在忍着不要掉眼泪，麻了（（ -->
<p>高统是周三的课，不知道为什么总是喜欢在周一布置作业，然后把 ddl
放在七天后（。wwc
讲课属实有点折磨了，主要是他这课真没什么逻辑，就是在堆定理，堆了五周了。也可能就是在给没学过高概的同学补习概率论所以也没什么逻辑可言，看看后面这课上得怎么样吧。</p>
<p>ODE PF 了，感觉现在已经不是因为讨论班花时间所以要把它 PF
掉了，而是哥们如果不 PF
或者直接退掉一门数学课，而且又想认真学概率论高统和优化这三门的话真的很难活到
2024 年（，思来想去唯一的口子就是这门课罢了。</p>
<blockquote>
<p>慢报：求真和生命学院等签署（博士）联合培养计划</p>
<p>和求真联合培养的院系有：经管，自动化，生命学院</p>
<p>BIMSA 刚发了一篇大的，用同调方法处理疾病数据</p>
</blockquote>
<p>啊？（</p>
<h1 id="月24日">10月24日</h1>
<p>优化终于发上节课手稿了，然后发现阴差阳错都被我周末看的东西覆盖了，好好好好好。这周临时加了一次
scribe
<!--主要是看到 LagrangeKMnO4 的 partner 不知道为什么跑了要一个人做（友情训练发生（，而且看后面的报名情况和我期中后的死亡密度好像有点来不及做第二次了，不如加到这次里面-->所以醒一醒醒一醒醒一醒（。仔细研究了下课程安排，原来这课的期中是在第九周周五而不是第八周周五，好好好好好好好好好好不然我第八周五天要考四门数学（</p>
<p>说实话上这课最大的乐趣是能看到很多上世纪，甚至 1950s 之后的结论（</p>
<p>这 ODE
作业好温柔啊，第一次和第三次都是计算，第二次也就是一点点泛函（<del>我不管，我没学拓扑和数分，所以它就应该是泛函</del>，感觉劲不如优化大，不过哥们实在是卷不动了（</p>
<h1 id="月25日">10月25日</h1>
<p>半夜在优化作业里算了个通过证明 Hessian 矩阵 negative semi-definite
说明是 concave function 的题，正确使用了一个 Holder inequality
算对了一些东西把哥们激动得不行，高中竞赛的时候那些个不等式奇技淫巧忘得一干二净，现在能用个最基本的不等式一遍算对就已经特别开心了（（</p>
<p>这课真的压力好大啊（，反正到目前为止力压概率论 2 的工作量。zjz
在第一节课还说希望把这课设计得不 challenging 而是能让大家觉得
easy，反正我暂时是没觉得，估计以后也不会觉得（。作业也挺
push，尤其是每次看到作业文档开头那一句：</p>
<blockquote>
<p>Please start early!</p>
</blockquote>
<p>我到现在为止上过的课还没有这么说话的（（x</p>
<p>晚上把 ellipsoid method for convex optimization
那题写了，然后我完全理解一切（</p>
<p>今早骑车出门在路上摔了一跤，给大家表演了一个一位 jk
连人带车摔倒在马路中央（，后车能及时刹住没再创我一下感觉已经挺好的了，手掌和膝盖都擦伤不少。不过往左摔的为什么主要受伤的是右手和右腿膝盖呢（，有点不是很理解。虽然有点乐的是我摔了之后第一反应是想起来安倍遇刺的时候路边摔倒的
jk
妹子（，到教室之后还找出来那个动图又看了一眼，还是她摔得比较重，<del>这个姿势是怎么摔出来的，甘拜下风</del>，好担心自己的精神状态（（</p>
<p><del>放一个在这给大家品鉴下</del></p>
<p><img src="https://s2.loli.net/2023/10/26/lpEIDNA9jCP6Z2W.gif" alt="jk.gif"></p>
<p>晚上回寝室之后又在帮室友配环境（，配完她说太好了明天组会有东西可以讲了，<del>你们组会这么水的吗（</del>。暑假回家之前就在帮她配环境，现在还在配，<del>会不会到学期结束她做的科研都还在我的邻域里（不是</del></p>
<p>另外破案了，wwc
讲课就是这么拉，今天开始讲统计了也还是大堆特堆（。<del>为了去上这课我还在路上摔了，好不值（x</del></p>
<h1 id="月26日">10月26日</h1>
<p>昨晚有个未央二字班的小朋友加我微信问转数的事，大喜过望还以为后继有人（不是。今早和他唠了建筑材料两课时，转述了当初一位数学系的学长和我说过的一些一直让我印象深刻的实话，结果给人劝退回交通工程去了，怎么会是呢（（</p>
<p>去年的我确实也一样的迷茫，也只多上了一门抽代一门统推（还是统计中心的），最大的不同可能只是我跑路的决心一直很坚定（</p>
<p>昨天还觉得只是右手和右膝摔得比较严重，今早起来左边肩膀有点动不了了，果然是往左边摔的（。</p>
<p>现在的心情就是和第一次骨折的帝宝差不多（，本来还打算
<del>五个月后跑菊花赏的但现在就是一个跑不了</del>
周末去体测的但现在走路都有点难，尤其是下楼梯和下坡，跑步的话估计肩膀活动受限也会有影响。说起来我周二晚上还把上学期买的帝麦贴贴的那件
<del>决胜服</del> 痛 T 找出来打算周末体测跑 800
米的时候穿呢，果然周三腿就受伤了（，现在就是需要一个奇跡の復活（（</p>
<p><del>下次还是整件北黑或者船的痛 T 穿吧，就不会受伤了（（</del></p>
<p><del>这么说来穿船的痛 T
就可以肆无忌惮地跑最后一名和出迟了（（</del></p>
<p>为啥 Durrett
上第一遍不会做的题第二遍还是不会，甚至第二遍做还不如第一遍，给我整急了。</p>
<p>把运筹的作业看成优化的习题课之后心态就平衡了很多，你还别说这个 dual
simplex method 我之前还真不会算。</p>
<p>晚上去猫超想买副橡胶手套用来洗衣服，但是没找到，郁闷地买了瓶乌龙茶走。进楼之前看到外面车位上停着辆后座贴着大蝴蝶结的电动车，随手拍给何老板一问还真是他的，然后在烤冷面摊位前面又浅聊了一下，看了个金融数学里的小东西。走之前他还把买一送一的酸奶拆了一瓶给我，<del>感觉很熟悉（，问了下本来不是打算给
npy 的我就放心地接了（（</del></p>
<h1 id="月27日">10月27日</h1>
<p>已经一周没接答疑坊小程序的单了，现在全是私人问题（，给何老板推论文里的公式顺便也读点，然后感叹我要是真混不下去了就搞金数算了（<del>虽然简单一些但那不是更卷吗（</del>，这哥们还挺讲究
intuition，感觉也学到一点。回寝室偶尔给室友配环境或者秒一下概率论（</p>
<p><del>其实主要还是期中学不完了</del></p>
<p>时隔两周又做了一次优化的
scribe，好好好这学期的就做到这里了。<del>overleaf
的同时编辑好好玩（（</del></p>
<hr>
<p>在教室里看了赛马娘第三季第四话，好社死（，后面都是看完写的新鲜的周常钝评（</p>
<blockquote>
<p>比赛（注：菊花赏）做得就（，咋这么急啊，<del>怎么不先表演个跑一次坂道三本再来比（</del></p>
<p>——2023.10.12</p>
</blockquote>
<p>感觉第四话好像就是在做我当时的暴论，<del>预言家刀了（</del>。观感其实挺好的，<del>感觉在养马</del>，不是很重要的比赛做成
PPT 塞一下 ED 很可以接受而且还不尬，<del>总不能七个 G1
全是大制作吧</del>。只不过这次春天皇赏唯一一个有版权的同期赛马是高尚骏逸，应该是跑了第三名，还只在过弯的时候出现了，冲线的时候都没给个特写，急了。</p>
<p>不过没关系，高尚骏逸应该后面还有不少戏份
<del>还会在后期背刺北黑</del>，不用急（</p>
<p>现实的北黑一次训练跑三次坡道，动画里跑四次还要加一堆别的，好强（<del>怎么没有东商变革客串下</del></p>
<p><del>内恰怎么又是你啊内恰，制作组里一定有内恰厨吧</del></p>
<p>第三季至少比赛顺序的时间线很正常，所以大胆猜测一手下一话或者再过一话（<del>但如果再过一话的话中间该做点什么呢，总不能还是日常过渡</del>）是宝冢纪念，会做个大鸣大放主场，毕竟要退役了。<del>求你了说句话吧</del>。<del>然而这一场北黑还是没能跑过大鸣大放，虽然大鸣大放也不是第一。但第一名的赛马并没有版权，不知道是要魔改还是就像开头产经赏里一样用路人代替下了（</del></p>
<p><del>说起来如果比较还原的话宝冢纪念说不定还是能在路人里面看到高尚骏逸，但是第九</del></p>
<p><del>所以说如果大鸣大放有个人回的话，感觉后期应该还有机会看到高尚骏逸的个人回，这孩子也蛮惨的</del></p>
<p><del>不知道我的暴论能中几个，先说就是了，中了就是我预言家，没中是 KAI
社的问题</del></p>
<p>开头北黑产经赏输了之后还说希望能一直连胜下去结果还是输了感觉很可惜，怎么不算是铺垫了呢，<del>毕竟她出道之后就没连胜过</del>（。感觉确实越来越粉丝向了，当然选北黑做主角确实注定门槛不低，<del>希望评分没事（二度（（</del></p>
<p><del>“请大家记住，我的名字是里见光钻”，钻哥好 A（</del></p>
<p><del>怎么北黑 G1
二胜之后还真的把魔方转成两面了，不会到五胜的时候真要画个有且仅有五面还原的魔方吧</del></p>
<h1 id="月28日">10月28日</h1>
<p>半年给电脑不清一次灰充电的时候风扇的声音就贼大，拖了一周终于有空把螺丝刀套装找出来拆一手了。三月份的时候我拆完自己的还顺便教了室友一手，但今天她看到我在拆还是把电脑塞给了我让我顺便帮忙处理下（，<del>这能算答疑坊工时吗（x</del></p>
<p>膝盖还肿着但还是穿痛 T
去体测了，在路上还觉得没啥，到东操看到人群就开始社恐差点把外套拉练拉起来（。反正
50 米和仰卧起坐都能 <del>因子继承</del>
保留春季成绩，立定跳远感觉太伤膝盖了就没测，万一别的项目加起来没及格再补。跑
800 米后面甚至还有至少三个人，<del>最终直线上</del> 最后 100
米连超了两个，和前面一名大约有个颈差（，怎么不是一种奇跡の復活（（</p>
<p>初中的时候我还是跑先行的，高中就变成了差，现在是彻彻底底的追，还只能一穿二（。这下更要买件船的痛
T 了（</p>
<p>我的评价是看赛马娘看得（</p>
<p>手机不太好带，就拿手表用很原始的方法记了时间，提前拨到两点整然后让它停下来，开始跑了之后再按下去。目测是四分钟左右，<del>不过好像也不能排除跑了五分钟的可能毕竟这个表的精细程度真有点看不出来一分钟，记了个寂寞（</del></p>
<h1 id="月29日">10月29日</h1>
<p>写点啥呢</p>
<p>前两天发现 KFC 现在在和 JOJO 联名，就挺震撼的，虽然我不是 JO
厨但是今天去代吃了一下（，体感还蛮值的，这不比买谷便宜多了。想起来上次代吃是高中的时候
KFC 和明日方舟的联名，印象里出了个泡菜堡，就挺震撼的（</p>
<p><img src="https://s2.loli.net/2023/10/30/2jJaepvuVmB38PX.jpg" alt="jojo x kfc.jpg"></p>
<p>最近太摸了，一边代吃一边把生物课预习作业看了，虽然听不懂她在说什么但幻视一个<a href="https://zh.moegirl.org.cn/zh-hans/%E6%9C%97%E5%9F%BA%E5%8A%AA%E6%96%AF%E6%9E%AA#EVA.E4.B8.AD.E7.9A.84.E6.9C.97.E5.9F.BA.E5.8A.AA.E6.96.AF.E6.9E.AA">朗基努斯之枪</a>（（#每日EVA</p>
<p><del>这都说是复制叉了，那不就真是朗枪吗</del></p>
<p><img src="https://s2.loli.net/2023/10/30/5dNWOirPj8JXZ7B.jpg" alt="Lance of Longinus.jpg"></p>
<p>晚上在写 ODE 试图赶上进度，先把 handout 读完了。感觉课确实是好课，fyw
把重点把握得很好，虽然我对 ODE
理论感觉不是太有兴趣但是读起来也还是有点意思，就是可惜这课被我上水了。我觉得他考试肯定不会难，但哥们现在不仅算不了一点，也没时间和心力和真
· 大二的小朋友卷这个，PF 保平安了。</p>
<p>想起来社聚时候的占卜了，原来 ODE
就是那门学了图一乐但是不要学分的课，谢谢 neruko 老师的点拨（x</p>
<h1 id="月30日">10月30日</h1>
<p>昨天下午在睡大觉，所以 ODE
作业是晚上回寝室熬夜写完的，倒也不是很困。晚上离开教室的时候就在考虑
complex eigenvector 要怎么算才能方便一点
<del>是的没学过高代的人就这水平</del>，哪怕把其中一个分量（对不起我终于想起来这个中文应该叫什么了）归一也要算
<span class="math inline">\((2n-2)\)</span> 个参数，我这种 logarithmic
time complexity 的问题手算都算不清楚全靠 MATLAB
和各种小工具苟命的人哪承受得了这种计算量，就算只有三阶也不行。不过后来一想一对共轭的
complex eigenvalue 的 eigenvector
也是共轭的不需要算两遍，所以计算量并没有增加只不过要一次算完而已，<del>感觉要长脑子了</del></p>
<p>到处搜着玩的时候还找到个<a href="https://textbooks.math.gatech.edu/ila/complex-eigenvalues.html">这个</a>读了读，差点在作业写完之前把电脑电量耗完。不过后来又看了看上周的高统
PPT 直到把电脑看没电，这 PPT
就是在抄书，讲课也是在把英文翻译成中文然后念书，但是看书比听讲和看 PPT
效率高太多了，不是很懂为什么。讲课不太行可以理解（，另一个我只能理解成是这个
beamer
字太密了对比度又太高，而且就是在堆定理把中间的话全删掉了的问题（</p>
<p>在看 parametric family 这一节，突然想起来大多数朴素的微积分问题都能用
Radon-Nikodym Thm 来理解，<span class="math inline">\(\mathrm
dx\)</span> 不过是指 Lebesgue measure
而已。<del>这不是很显然吗</del></p>
<p>然后回去翻了翻 wjd 当时讲统计推断的时候那个很初等的关于 exponential
family 的定义，看到充分完备统计量啥啥的那一节笔记里有这么一句话：</p>
<blockquote>
<p>Data don't make any sense, we will have to resort to statistics.</p>
</blockquote>
<p>这是 wjd 当初这一讲 PPT
封面上的一句话，我当时甚至有些大受触动，第一次从直觉上觉得统计很美妙。然而接触了高等的内容之后有了更新的认识而不是再像当初在这课上从表面上看统计，就是后来的事情了。顺带一提在我短暂的统辅学习生涯里最喜欢的一位老师就是
wjd，甚至唯一一个没被我吐槽过的老师就是她，尽管大家都说她讲得不太好而格外推崇
dwl 和
zzy，我听过其他人对她最高的评价大约只是中规中矩，但我真挺喜欢她的课。</p>
<p><del>今天怎么全是数学，还都是大半夜写的（</del></p>
<hr>
<p>想了想这半年沉迷赛马娘本质上和小时候（初中吧，不算很小）沉迷看网球赛是一回事，起因是突然发现我微信还关注着
WTA 的公众号，<del>至于为什么没关注 ATP
就是个谜了</del>，虽然翻了一下历史推送发现现在活跃的选手基本都不认识了。<del>这么一想网球赛的分级制度和赛马也差不多，人类真无聊</del>（</p>
<p>好好好，今天又摔了而且是磕了脚踝，还好周末把体测测完了，不然这周真没法测。<del>还以为体测就是有马纪念了，没想到只是日本杯，后面还得受伤</del>
<del>已经挑好印到新痛衣上的图了，假装本来就是北黑厨（</del></p>
<p>你院奖学金难产了一个月终于公示了，不出意料的自取其辱，太棒力（喜</p>
<!--开玩笑的虽然本来就知道没戏但怎么可能真的无所谓（悲），这下托福报名的钱要友情（？）从老板工资里抠点，再在答疑坊多刮点了，毕竟 expectation 是考两次。之前看到有个院系的暑研补贴是 1w 左右，虽然觉得不错但感觉这种好事既然是从院系发那肯定是到不了我头上，大概也要自己补。-->
<blockquote>
<!--我：看看我的每年度自取其辱-->
<!--友：没事我今年也没奖学金-->
<!--但是我可以把刚到账的裁判费都打给你-->
<!--然后给你颁一个年度最佳小猫奖-->
<!--你要证书吗-->
<!--也可以印一个-->
</blockquote>
<!--笑死（-->
<p>从上学期以来就经常在浴室里捡到别人的卡，今天在清芬门口停车又捡到一张，发邮件果然没人理，很难绷得住（。半夜下楼散步的时候顺便送去紫一了，希望卡没事。</p>
<h1 id="月31日">10月31日</h1>
<p>闲着没事在优化课程群里扒拉，这学期不是和二字班一起上课就是和研究生一起上课，心态上是降转成功了。仔细一看这课上怎么还有九字班的，再仔细一看这位不是我高中<!--是当时的 IPhO Au，名字里有个字很特别所以记住了-->的学长吗（，世界真小，<del>教教怎么能保证顺利延毕（</del></p>
<p>挺久之前就想尝尝贝纳颂的生椰拿铁了，今天终于全款拿下一瓶（，好贵但确实好喝，在双十一开始前的下午加了一箱进购物车，我赚两次。</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇十五·23年11月</title>
    <url>/2023/11/01/Diary-2023-11/</url>
    <content><![CDATA[<p>别来暖气别来暖气别来暖气别来暖气别来暖气别来暖气（悲</p>
<span id="more"></span>
<h1 id="月1日">11月1日</h1>
<p>在通过双十一凑单练习优化（，这个月的答疑坊津贴还没到手但已经送出去了三分之一左右，好好好（</p>
<p><del>选衣服的时候看到备注的春秋款直接幻视一个春秋分，你怎么知道春秋分刚刚天皇赏秋夺冠（看赛马娘看得</del></p>
<blockquote>
<p>考试的话除了 normal 和 Poisson
之外的分布我都会给在卷子上，抄就是了，毕竟别的很多分布的参数很混乱，我估计你们每个人说出来的
Gamma 分布都不一样。</p>
<p>另外如果连 normal 和 Poisson
都记不住的话我想你们也坐不到这个课堂上（</p>
<p>搞应用的时候人家问你这个模型怎么不这样那样改，你就说 all models are
wrong but some are useful，我自己这个就是 useful 的；到搞 inference
的时候你又可以说自己的 model is exactly
correct，在什么场合就说什么话（</p>
<p>——wwc</p>
</blockquote>
<p>但我上课在写上周作业，没仔细听还有没有别的暴论，急了（</p>
<h1 id="月2日">11月2日</h1>
<p>本来感觉学不完了，但这个 ODE 居然有点速通的意思，<del>早知道不 PF
了</del>
开玩笑的，我的练习量只有三次作业十五道题，速通只是能把讲义看完的程度（<del>但这对我一个不搞
ODE
和动力系统只是学着玩顺便复习或者说预习分析的人来说已经足够了</del>，可不敢碰瓷二字班小朋友（<del>等等我不是马上就要变成二字班了吗</del></p>
<p>又到了虽然不用朋友圈但偶尔去看 Bowen L
最近在发啥如果间隔时间比较短就给他点个赞时间（，突然发现他的签名改成了</p>
<blockquote>
<p>以轻松愉快的心情面对就可以了</p>
</blockquote>
<p><del>可爱捏</del> <del>谢谢不焦虑了（并没有</del></p>
<hr>
<!--Saheto o 'adingo i hekalan, hatiraay aca, aca.-->
<!--我会一直记得-->
<!--12.19 upd: 今天 pad 到了，iCloud 同步了一下 20 年以前用的 iPhone 6 上的照片，把我创飞了。最上面一张是我四年前填的艺术节校外人员邀请函，然而那次他们学校不放人就没来，似乎就错过了唯一一次面基的机会，再不会有了。-->
<!--12.21: 尾七。-->
<!--我用什么将你留住？-->
<!--12.22: 唉，生日快乐啊。-->
<hr>
<p>下面是周常新鲜的赛马娘第三季第五话吐槽（</p>
<p>确实是宝冢纪念，但没做完，下一话应该还是大鸣大放。yysy
最后做出来的这个大鸣大放的性格真和我想的一模一样，四舍五入是狂化的帝宝（，只是没猜到秋奈的声线。</p>
<p>比赛演出还是不错的，大鸣大放骨折那一下确实给我整得心肺骤停了，第二季印象太深刻开始闪回帝宝的几次骨折。然而宝冢纪念还是在北黑视角下展开稍微有一小点失望，我以为会做出来大鸣大放骨折那一刻的心态，受伤的一瞬知道这是自己最后的末脚了，赛前对凯旋门赏的壮志已经化为泡影
<del>这下找到北黑参加凯旋门的执念源头了</del>，于是忍住巨大的痛苦拼尽一切从外侧赶超错失的上届菊花赏冠军。或者至少有北黑知道这是最后一次和大鸣大放比赛的机会（虽然我知道赛前和赛中不可能做出来，毕竟北黑领放看不到身后的情况，她如果跑追的话倒是有机会，应该是会等到下一话知道大鸣大放失去竞赛能力之后表现。但如果赛中能有的话该多精彩啊），带着全部的心意去决战的描写。</p>
<p>本来还在期待能有大鸣大放的内心戏在好好看比赛演出，结果胜之石超过的时候北黑大喊一声你谁啊给我破功了，这活整得又好又烂的，<del>真的不会得罪马主吗</del>（</p>
<p>但现在给我的感觉是大鸣大放好像并不知道这次受伤就再也不能跑了，下一话会做成啥样呢。<del>不管怎么样先期待一个上届骨折选手
&amp; 经典双冠马娘帝皇出面安慰大鸣大放（</del></p>
<p><del>大鸣大放的腿，斯哈斯哈（</del> <del>嘟啦酱我的嘟啦酱</del></p>
<p>Eyecatch
图的大鸣大放感觉有点小崩，头好大啊（<del>琵琶晨光：？</del></p>
<p>这一话小北和光钻双双被史实杀，好好好（，不过光钻菊花赏就要赢了，感觉不会下一话塞到一起吧（</p>
<p>胜之石你好惨胜之石（，明明赢了还被吐槽这谁啊完事在背景里一顿自嗨也太可怜了吧（<del>虽然挺可爱的</del></p>
<p>高尚骏逸有戏份了<del>（虽然只是举了几秒钟铁）</del>，决胜服总觉得很眼熟但就想不起来为什么，后来一想略像
ISLAND 的女主<del>（对不起<a href="https://bgm.tv/character/37703">凛音</a>我想了半天也没想起来你叫啥）</del>。观赛的两个看起来既路人又不太路人的
<del>有点像大拓太阳神的</del> 马娘在 OP
里也出现了，感觉可能是高尚骏逸的姐姐和妹妹。然而我都忘了这一场还有里见皇冠，其实发型真的蛮可爱的（。</p>
<p>说到 OP，ED 里面特别周腿上阴影的作画失误仍然没有改（</p>
<p>但有一说一如果我是刚入坑的话看到这一话北黑被路人马娘莫名其妙史实杀，都不是被大鸣大放背刺，真的会气到吐血弃番的吧（</p>
<h1 id="月3日">11月3日</h1>
<p>昨晚在 MSE
上提了个遍寻不得但事后看来蠢得想把自己脑袋摘下来的问题，居然有 6 upvotes
还迅速收到了两个回答，reputation 涨了
62，咋回事呢（。其实就是个突然在想又想不出来的反例，评论区还给多加了个条件，挺有意思的。</p>
<p>上次在 MSE 提问是因为不会做 Bowen L
出的附加题但是又搜不到就问了，后来被识别成了 duplicated
但我说实话没觉得重复，本来有个 upvote
但是这个问题本身过了一年被删掉了，就又没有了。好好好，下次还问（</p>
<p>凌晨的时候有环友问了个和 Durrett 上 recurrence
那一章的某几个习题长得十分甚至有九分相似的课后题，那几个题我本来就不会做而且答案上没有，也可能是处理收敛级数的水平不太行，但看到环友也都不会就放心了（</p>
<p>说到环友，有个之前好像知道我要延毕的环友今天来问我是不是真的要延，我说是，他说别延毕一年最后来求真了就行（，正确的。然而说实话不去求真我就只能统计中心/出国了，<del>总不能去投奔
lzx
吧</del>，去统计中心这件事几乎零测（，强基不能转专业什么的我都已经看开了，实在是不能理解不允许外推的规定，否则能去北大
<del>能让我学数学的话大不了复旦也行（x）</del>的话怎么不算兜底了呢。</p>
<p>我说如果不出意外（i.e.
学校不批准延毕之类的）肯定要延，他给了一些我意料之内的反应，比如说认为我能做出这个决定非常不容易什么的。其实并没有，我几乎毫不犹豫（，另外延毕这事儿我从大二上学期就开始口嗨了，属于是给自己做足了心理准备。</p>
<p>周三运筹在讲整数规划，虽然不可能难但毕竟 zjz
没提过这个我也没学过，估计就是个 linear programming
的小的延伸（暴论，搜了份讲义考完前两门期中回来看（（</p>
<p><del>双十一买了个帽子，戴上之后有种莫名的既视感，想了想是后面的蝴蝶结有一丝丝像诗歌剧，那没事了，诗宝可爱（</del></p>
<h1 id="月4日">11月4日</h1>
<p>本来还想着今天要去讨论班的，还想着上讨论班的时候可以写点
ODE，结果起床之后想了想反正论文也没读过干脆别听了，直接变成那个去隔壁复习概率论（。哥们是真有点急了，现在拟合题目拟合得想吐了已经（</p>
<p>Jianfa Lai 给了一个论文的
list，从下次开始似乎也能提前知道要讲什么论文了，打算自己先读一下，不然纯听故事也没什么意思。</p>
<p>紧赶慢赶把 optional stopping time 学完了。之前 variance of the
gambler's ruin time
那个题哪怕在作业里出了也一直不会，直接口胡了交上去的但也没扣我分，这课也不发作业答案，助教是个
23 级的博士生，我其实稍微有点疑惑如果这课真是用来准备 <del>脖子</del>
博资考的那他本人为什么不上（<del>当然我不懂求真的脖子考具体规则所以不乱说了（</del>，还是说他在自己
TA 自己（。PTE 2nd edition solution manual 没这道题，Hoil Lee
的答案感觉既看不懂又是错的，MSE
上没仔细搜但是搜到的两个回答更是透着一股浓浓的 not worrying about the
details（</p>
<p>今天福至心灵自己把它做出来了。然后心理压力瞬间减小了很多，optional
stopping time
那一章的习题也迅速过完了，<del>想了想闲得不行的话可以把这个题在 MSE
上写下来作为我的第一个回答</del>，顺便发现了另一个之前不知道的定理用法，学到很多（这是学到吗，好像是自己教会自己许多（（x</p>
<p>果然学数学就要去北大学（迫真，去了一趟感觉很缓解期中周精神状态（</p>
<h1 id="月5日">11月5日</h1>
<p>虽说昨天觉得不用慌了但果然考数学之前就是很难不慌（，希望能成功早睡（</p>
<p>膝盖本来好很多了，结果上次又摔了脚踝，今天又被车蹬子打到了膝盖上还有淤青的地方，真好不了了，<del>帝宝求你了放过我</del>（。说起来上周体测
800
米测出了上高中之后就再也没见过的成绩，跑的时候甚至感觉还有余力，帝宝特有的受伤之后能变强是吧（</p>
<p>上次在 MSE
问的问题已经周榜第三了，好崩溃，这周会不会收到一封能在里面看到自己的 MSE
Weekly Newsletter（</p>
<p>今天在教学楼洗手间里看到一个出水停不下来的水龙头，突然联想起大一的某个雨天骑车的时候一滴水打在我没锁屏的手机上然后连发了几十个表情包（，当时正好在旁边擦手，顺便拿纸擦了一下那个红外感应器（？我也不知道叫什么）上的水果然就不流了，学到许多（，而且日行一善（1/1）（（</p>
<p>这概率论 2
颇有一种奶酪越多，奶酪孔越多，奶酪孔越多，奶酪越少，所以奶酪越多，奶酪越少的感觉（，学得越多不会的越多，题目拟合的越多之前会做的后来再看也不会了（，随便吧反正明早就考了（（</p>
<h1 id="月6日">11月6日</h1>
<p>昨晚把时区猛往东调了六个（，果然入睡有点困难，吃了 1/3
粒室友的安眠药然后光速睡着了。</p>
<p>概率论大寄特寄，我是真没想到 yf
这么喜欢考计算，每道题都在算（还特别喜欢 random walk on graph，一个
binary tree
一上来给我看傻了），我做计算本来就又慢又菜，这次干脆剩了个题没算完。考完之后在路上一边走一边想，算一个有
<span class="math inline">\(n\)</span> 种取值的 discrete random variable
的期望需要 <span class="math inline">\(2n-1\)</span>
步，我也不知道算最后那个 triangular sequence
里每一个随机变量的期望花了多久，总觉得最后的 45min 转瞬即逝，看来确实
<span class="math inline">\(O(n)\)</span> 对我来说已经太难了（（</p>
<p>无所谓了，我现在越来越发现我考试发挥的水平就这样，之前已经复习挺好了，该掌握的也都熟练了，差不多得了。</p>
<p>晚上看答疑坊群里说线代爆单了，想想我暂时没什么要紧的考试了就去秒了十几单，然后把生物作业写了，好闲啊（。明天考完
ODE
要极限开始学整数规划然后写后天要交的作业，实在不行先把作业写了再学（</p>
<p>这周大概还得赶赶高统的进度，虽然不期中考但落的有点多，然后就是没边没沿的优化了，真不知道咋复习，<del>上周还休息了</del>（</p>
<h1 id="月7日">11月7日</h1>
<p>好崩溃，为什么要 PF
ODE，哥们就复习了两个下午，昨晚还在写生物作业，写完开始摸鱼抽卡摸到两点，躺床上看了一眼整理的笔记的照片一秒入睡（，早上六点半就<!--被呛-->醒了<!--，醒来感觉喉咙里有东西味道还很奇怪，猛地坐起来之后吐出来一口血，这个场景真是好久不见。怎么说呢，我要是再晚一点醒过来的话还有命考 ODE 吗（，别似好吗（）-->然后睡不着了。刚拿到卷子又开始流鼻血，怕时间来不及就一边捂着鼻子一边算，看起来还挺壮烈的。</p>
<p>铺垫了这么多（，实际上我想说的是 70min 就 AK
了（（，昨天概率论要是有这水平还愁啥（</p>
<p>上来一看怎么第一题全是字儿，再一看这个 enumerate
写了六行居然是在解释什么叫唯一解无解和多解，我还以为善良到把判定法则给出来了（。说到底这课就没什么难的，除了一些计算细节（比如说
(a) 的无穷多解几乎就和 Lecture 1
讲过的那个一模一样）之外核心定理就两三个，像 (c) 这种除了套
Picard-Lindelöf 之外也不太可能有什么别的办法，随便一放缩凑个 local
Lipshitz 就有了，问题是你这个 (b) 到底为什么压根不满足 initial value
condition 啊，我还给解出来了然后仔细一看逗哥们玩呢。</p>
<p>中间两个就是只要学了微积分 A1 就会做的计算
<del>可能也不会毕竟其中有一个是 Jordan decomposition</del>
<del>尽管我当初并不在乎唯一性乃至这么做的合理性之类的细节</del>，最后一题本来还想着说不定有点小难，再仔细一看兄啊你这导数
<span class="math inline">\(y^\prime = f\)</span>
怎么还是有界的，你这函数怎么还是在 <span class="math inline">\([-1,1]\)</span> 上的，那不写个 Arzelà-Ascoli
theorem 再用一下 <del>LagrangeKMnO4</del> Lagrange mean value
就直接带走了吗（悲</p>
<p><img src="https://s2.loli.net/2023/11/07/9ygiHQGDuWmwoRv.jpg" alt="ODE_midterm_2023.jpg"></p>
<p>卷子可以带走，所以发出来也没啥吧（？</p>
<p>我懂了，这学期主打一个学到就是赚到，别天天牵挂你那绩点了.jpg。下学期要去上
PDE 替代培养方案里的数理方程，虽然不知道和 ODE 有多大关系
<del>而且重点应该是我那稀碎的多元微积分水平不太行</del>，总之学一个先。</p>
<p>今天不知道是不是考完了的原因所有的课都开始哐哐布置作业，打开平时事不太多的高统发现布置了超过五个题，急死了，再打开优化作业一看真好啊竟然只有六道题（，再一看每道题平均三个小问，急死了（（</p>
<h1 id="月8日">11月8日</h1>
<p>现在笔芯好难买啊，我平时只用
0.38，本来就已经很难找了，这次缺的是蓝色笔芯，某宝都快翻烂了才找到以前一直用的那一款。不是墨蓝就是晶蓝，就想买支纯蓝色
<del>而且笔杆可爱一点不要纯透明的（草）</del>的笔咋这么难呢。</p>
<p>优化期中就有两张正反面 cheatsheet，高统期末也有一张正反面
cheatsheet，建筑材料直接那个开卷允许带书，感觉别说复习了光是塞
cheatsheet 就够我喝一壶。</p>
<p>今天突发恶疾看了一眼春季那个数学规划的大纲，这不就优化吗（。里面就非线性规划没学过，到明年去水一个工工的好了，考虑到数学系大三非泛函专业课的那个水平还是不去浪费时间了，好好学复分析吧（（</p>
<p>Shao Jun
这本数理统计越看越觉得也有点怪，感觉描述性的语言太多了，不能多列点公式吗（。像
the conditional distribution of <span class="math inline">\(X\)</span>
given <span class="math inline">\(T\)</span> is known
这种话（我觉得）写在 remark 里就可以了，为什么会在定义里，去 example
里找式子感觉有点小抽象。</p>
<p>喜提了第一个数学考试满分（，这是好事，但是
ODE（，明早去看看分位数是多少。虽然考试其实 AK
过很多次但是基本上都有被小扣分，去年抽代期末还以为能满分结果笔误了两个被浅扣了一点，数值分析也
AK 了但没公布成绩，看最后是 A 而不是 A+ 有点怀疑又笔误了（，说到底 ODE
可能也不是没有笔误只是批的松吧（</p>
<h1 id="月9日">11月9日</h1>
<p>睡大觉。</p>
<p>本来觉得优化是下周五不用慌，今天仔细一算我这周连作业都写不完，急死了。</p>
<p>今天写高统作业看到个好玩的：<span class="math inline">\(f_1f_2
I_{A}+g_1g_2I_{A^c}=(f_1I_A +
g_1I_{A^c})(f_2I_A+g_2I_{A^c})\)</span>，实际上是在拆 exponential family
的题目里看到的，但那个题我看了一眼感觉不能拆就直接开始说 subset 的
minimal sufficient 也是全集的 minimal sufficient 了（毕竟 subset 就是
exponential family），似乎有点粗暴。</p>
<p>赛马娘第六话钝评，端上来罢！</p>
<hr>
<p>前天还是昨天看了预告其实就给我整不会了（</p>
<p>上次宝冢纪念大鸣大放赛后明明骨折了还愣在北黑面前站起来了本来就有点给我整不会，我以为埋了个大瓜等这一话才知道再也不能跑了，开始掉小珍珠然后和北黑进行信念的传承，结果怎么是光钻？</p>
<p>我超，总算有小林历奇了，光钻小林东商皇冠俊逸和北黑的修罗场人总算到齐了，而北黑还在和内恰贴（</p>
<p>我有点评价不来这番的搞笑情节，感觉观感和第一季越来越像了，前半段真不是在水时长吗，后半段我其实看了预告就感觉应该会和麦昆谈心
<del>虽然里见家族和目白家族简直不是一个量级但反正目白牧场早就没了随便说呗</del>
但麦昆突然讲龟兔赛跑然后被打断还是给我气笑了，尴尬程度不亚于早已沦为胡萝卜特饮推销员的特别周在第一季
OVA
里面对着胜利奖券大声复述训练员怒斥早恋小情侣的那段话，<del>及川启对自己不合时宜的插科打诨的强烈执着依然毫无反思甚至可能都没有认识，你不是马黑谁是马黑（</del></p>
<p>麦昆：比赛中落铁和斜行都是很常见的事（指天皇赏春落铁，天皇赏秋斜行被降十八着，真的很在行（</p>
<p>总觉得这是麦昆第三季以来第一次说超过三句话（，<del>太亚撒西了，我永远喜欢大西沙织</del></p>
<p>光钻这场菊花赏应该是目前为止做的最长的比赛，虽然最后冲刺全靠和观众一起吼还是给我整绷不住了，但不得不说里见家的姐姐们出场看比赛、光钻赛后掉小珍珠还真算是这一季里面截至目前情绪渲染的高峰了。</p>
<p>现在魔咒破了，里见 <del>魅魔</del>
皇冠后面能说点别的了吗，这么可爱的妹子没戏份的话真的好可惜（</p>
<p>下一话按照时间线应该是北黑光钻第一次有马纪念对决
<del>今天的小北不是我的对手</del>，不知道北黑要怎么输。同场的又是万籁争鸣、高尚骏逸和<strong>胜之石</strong>（小北这次认识了吗？），但这三位都没能入着，其他马娘又是都没有版权（当然胜之石也没有），大鸣大放已经退役，很难想象这比赛会是什么抽象样子，大概只能搞女酮了（。估计是赛前
<del>修罗场</del>，续上宝冢纪念的大鸣大放受伤和未能参加有马、凯旋门就退役的遗憾，或者能有个会动的
winning live <del>和在 winning live 上和好贴贴的北黑光钻</del>
看看了。</p>
<p>啊所以真的还有人记得大鸣大放吗？还有人记得大鸣大放的凯旋门赏吗？</p>
<p>如果说光钻个人回结束了才开始写大鸣大放这才知道自己不能再参赛了我还是会有点小小的难以接受但勉强接受也不是不行（，也不是非常不合理，但感觉接受不了也是有点因为和预期不符，<del>宝冢纪念之后伤那么重早干啥去了</del>。只能说或许要把“不能再参赛了”阐述成“未能参与有马纪念就遗憾地面临退役”，然而但凡把第六话前半段的抽象演出压一压然后讲大鸣大放的情况也比这好啊。</p>
<p><del>帝宝救一下啊，麦昆都开始当知心姐姐了，你救一下大鸣大放也行啊</del></p>
<h1 id="月10日">11月10日</h1>
<p>昨晚把不考但是这周要交作业的三门课的作业写完了，<del>心情好了很多没那么破防了</del>，然后想了想我优化上周的内容还没仔细看呢，今天何必还要去教室，咕咕。</p>
<p>写运筹作业的时候还不知道昨晚讲的非线性优化是个啥东西，打开 PPT
一看哦原来就是凸优化的基本概念然后随便讲了几个数值算法，速通了。不过翻这
PPT
的时候还是给我气笑了，不会写数学公式可以板书，别惦记着你那关着灯上课了.jpg</p>
<p>好痛苦，选这么多数学课干啥。学新的东西掌握漂亮的技巧确实很开心，然而用选课来催促自己好好学的代价就是有一个在复习拟合中感到无比痛苦的超长考试月，在此期间就连去读一些写得很好的讲义和写作业都失去了应有的兴致，非考试科目的话甚至只想赶快掌握下表面的东西把作业写完然后就放下，省出时间复习，之后再来还债，好痛苦好痛苦。更痛的是哥们期末有八门课要考试，真能活下来吗（</p>
<p>今天一边读 Boyd Chapter 4,5
写作业（也没写完，急死了）一边辱骂优化这门课，要是按照上确界来准备的话就是五章
Boyd 四章 Intro to LP 再加一章 Bubeck，然后读读课堂笔记再加一个上课讲的
maxcut，两张双面 cheatsheet 我觉得少了，但是既然限定要 handwritten
我又觉得太多了（。这 Boyd Chapter 4
到底在干啥呢，好像就罗列了一堆不同类型的 convex optimization
problems，我还以为会有什么稍微统一点的方法结果课后题仍然相当依赖人类智慧，甚至可以说只是依赖线性代数水平（</p>
<p>想来想去只有一句锐评，这课比赛马娘第三季还能塞。</p>
<h1 id="月11日">11月11日</h1>
<p>写点啥呢（</p>
<p>收获了一个 <del>asuka 同款</del> 朗枪帆布袋
<del>感觉有点地狱</del>，找<a href="https://twitter.com/eva_store/status/1564953651134742528">出处</a>找了半天（</p>
<p><del>其实只是借用一周，骑车把之前用的帆布袋弄脏了（（</del></p>
<p>晚上回来之后吃了个朗姆酒冰激凌，感觉头晕晕的，怎么会是呢，好菜（。</p>
<h1 id="月12日">11月12日</h1>
<p>双十一买了个咖啡杯，还买了一箱瓶装咖啡，结果就是到现在瓶装都没喝完
<del>作为一个懒狗</del>
更不可能自己泡了，想想新杯子一直放着也有点可惜，拿出来喝水了。300 ml
的杯子有个奇效是走路的时候放在口袋里也不费劲，打一杯热水去吃饭来回路上当热水袋，回教室之后就正好可以喝了。</p>
<p>晚饭后饭困的频率越来越高，下次留一口咖啡吃完饭回来喝（...）或者饭后去骑会车好了。</p>
<p>周五考试，两张正反面 cheatsheet
仍然没有开工，但是不紧不慢.jpg，怎么会是呢。今天把 Boyd Chapter 1,2,3 和
Appendix
看了，总感觉线代水平似乎不太行，小急。为什么要在额外的纸上做笔记而不是直接抄在
cheatsheet
上，我也不是很懂。不过还好，后面四天没有要写的作业（...）所以还挺有时间的。</p>
<p>话说回来感觉与其微雕折磨自己不如随便找纸写大一点然后缩印到一张纸上（比划），明天去看看清芬打印水平行不行，实在不行去社友曾经推荐过的北馆（</p>
<h1 id="月13日">11月13日</h1>
<p>今天摸鱼的时候看到有个致理的同学在答疑坊小程序里问数分学不会怎么办要不要多刷题（，本来想话疗一下后来想想我也没学过数分还是另请高明吧，过了一会看这哥们又问了个离散，<del>成分已经很明确了这还学数分学那么认真干什么.jpg（</del></p>
<p>在读优化的 scribe notes，<del>读到 week 3 惊喜地发现还有人 LaTeX
写得比我还丑，满意离场</del></p>
<p>自从找到可以把水果酸奶送楼下的店之后就有了晚饭之后骑车遛弯顺便回去取的动力，每次下单都在默念我一个月挣两千买点吃的怎么了总不至于真没钱考托福了吧.jpg</p>
<p>晚上教室里另一个姐一直在乐，走的时候听到她 npy
和她说我求你别笑了然后两个人开始一起乐（。<del>除了当时在推一段推不出来的公式感觉有点小吵之外</del>，羡慕和疑惑参半，好美丽的精神状态（，我怎么一天天的就完全乐不起来，反正每周离已经过去的周六越远整个人越乐不起来（</p>
<p>走在路上突然好想吃玉米肉馅的饺子，感觉是不可能存在于北方食堂的东西，晚上就在清芬多买了一个生煎当代餐，尽管也知道它比在上海随便找个店能吃到的差得太远太远了。晚上拿到的昨天买的青提上不知道为什么沾了好多泥，和上周末买了带去隔壁的完全不一样，费劲地洗了好久最后尝起来也不甜，你这白开水怎么没味儿。不过买到的芋泥厚乳很好喝，本来差点突发恶疾就冰着喝了，放暖气上热了一下留到洗完澡喝的，好香好香。</p>
<p>乐不出来可能也是因为饭太难吃了，清芬一楼还就那个又贵又难吃。周六可以吃好点。</p>
<h1 id="月14日">11月14日</h1>
<p>昨天想吃玉米肉馅的饺子，在华子想必是不存在的，吃了个不好吃的生煎当代餐，完全和你沪的没得比。今天想吃汤圆，去桃李二楼的时候已经没有了，又没吃上。</p>
<p>北京初冬这个天气不刮风的话真的很舒服，今天下午在一教摸鱼，出去交作业的时候顺便在后面的小土坡（？）上溜达了几圈，把围巾摊开当披肩披在卫衣外面就出去了。所以说感觉现在真没必要穿得特别厚，有一件抗风的外套就足够了。当然我没有，冲锋衣暑假带回家洗了之后忘记带回来了，那就骑车骑快点吧（</p>
<p>晚上在教室看到前排一个男生在用香蕉空间看复微分形式的定义，大受震撼，又窥了下屏发现他旁边的女生在写复分析作业（，感觉求真爷实锤了，仔细一看哥们桌上的入党申请书写的求真
2 党支部（。再右边的另一个男生在看 GTM，别的没看清就觉得一个图长得很像
upcrossing inequality，看他翻了几页之后标题是
martingale，不知道是哪本。浓度好高（</p>
<p>这学期连期中周都还没活过去，看下学期的课表倒看得很乐呵，希望最后别变成在那嗯造两本
Stein（<del>其实我本来都不知道是造哪两本，但是看到下学期泛函是 xgy
开课之后就确定了是实复（</del>。春季的必修课我倒是上得差不多了，就几个很水的建管交通必修课随便摸摸就过去了。统计中心那边摸一个高统
II 和高维概率 <del>我觉得这两门总能命中 ypk</del>，看到求真那里开了一门
combinatorial
optimization，简单查了查感觉和这学期优化理论接上了可以去学学，主要是既然同一个老师的
deep learning theory
没考试的话这课也不会有考试的对吧对吧对吧对吧哥们是真的考不动了（（</p>
<p>下学期实分析是光叔和 lyx 但是看这个课容量我觉得我就是 lyx
的份了（，<del>本来不知道后面这哥们是谁，查了下以前学期都在开我不太关心的研究生课难怪不认识，但看了他在<a href="https://math.tsinghua.edu.cn/info/1125/1876.htm">官网上的照片</a>（右一）之后我觉得应该是个好人吧（迫真</del></p>
<p>PDE 没有 jhy，我只是想拿这课水
<del>看起来根本不可能学会因为不会转化物理模型的</del>
数理方程而已，那就不急着选了。</p>
<p>好想用上海话骂人哦，在华子没什么机会 gang <del>洋泾浜</del> sang hai
ei wu 真是失去了很多乐趣（</p>
<h1 id="月15日">11月15日</h1>
<p>早上突发恶疾看了会 Gaussian sequential
model，主要是周末讨论班讲这个，结果主讲人发的链接是一本 500
页的书实在给我整不会了（，看一点是一点能听懂多少是多少吧（</p>
<blockquote>
<p>提醒各位同学，本周五是优化理论课程期中考试，时间和地点和日常上课一致。</p>
<p>题目数量：6 道题目，包含证明题和解答题</p>
<p>题目难度：TA 用时约 1.5h 完成</p>
</blockquote>
<p><del>TA 好强（#每日TA</del></p>
<p>我寻思着 TA 用时约 1.5h
完成到底是个什么难度（，开了下盒发现这哥们是前几年的丘赛概统银奖，<del>那他怎么做了这么久，这考试是不是还挺难的（x</del></p>
<p>今天身体不舒服睡了好久，晚上感觉要小肝一下。<del>怎么以前做出来的作业题第二遍看都觉得自己当初像会魔法一样</del></p>
<h1 id="月16日">11月16日</h1>
<p>烦死了这优化快点考完吧，好想学点新的东西，ODE 和高统都是（</p>
<p>不过今天看了不少 SDP，也算是学了。不知道后半学期讲不讲，反正当初讲
max cut 的其中一个转换的时候 zjz 突然说了一句这就是个
SDP（大意），然后在场的茶园爷看起来全都懂了，只有我愣住了，SDP
是啥，讲过吗（</p>
<p>下午往 cheatsheet
的最后一块空白上随便塞了点东西，晚上写了运筹作业，又看了点高统，感觉神清气爽（。希望明天没事，但我感觉
bgm 都快换成 Komm süsser Tod 了（<del>不如放<a href="https://zh.moegirl.org.cn/%E6%AC%A2%E4%B9%90%E9%A2%82">欢乐颂</a>怎么样</del></p>
<p>赛马娘，钝评，端！</p>
<hr>
<p>又一次给我气笑了（</p>
<p>真没绷住，我想着这次日本杯第三是表现高尚骏逸一生一次的末脚之前的高光之一了，再没有的话只能等明年春天皇赏的第二了。万籁争鸣是最后一次拿到第二名，此后再也没有进过前三。所以我还以为这次有马纪念可以像第二季的帝麦对决那样先铺垫个一集，结果又莫名其妙，比赛之前高尚骏逸又说一定要赢，然后又输了输完很不甘心，光钻日本杯的时候看着北黑赢了还就那个面无表情，有马纪念早上起来还想着给北黑留小纸条说自己先走了，到赛场上就甩脸子
<del>离婚</del>
不认人。要是说这就算描写了光钻比北黑对待竞技的心态更成熟的话我可要绷不住了，赢了之后也是北黑先向光钻搭话不然头也不回一个，那这场比赛光钻要是输了的话岂不是更要翻脸不认人了
<del>反正你这输赢也莫名其妙的除了按史实写之外啥也没有</del>，性格还没有北黑成绩起起落落也没看到大的起伏、无论输赢都在笑来得讨喜。赛中莫名其妙地追上了超越了，两个人吼着吼着北黑不知道为什么就输了，我看了个啥（</p>
<p>跑步就跑步别吼了啊啊啊啊啊冲线那一段我直接把声音关了（黄金伶人/巨星俳优：那我呢？</p>
<p><del>cy
你还是搞女酮吧，之前的预期是第三季能和第一季差不多就行了，现在感觉好像还没第一季好看（</del></p>
<p>winning live
冒了个尖我还想看北黑望着光钻的背影一边忍着不掉小珍珠一边跳舞（，之后直接转
ED 也没绷住，<del>想做搞笑番可以再单开一个四格别霍霍第三季</del></p>
<p><del>你还别说这 ED 相比正片来说还挺好看的，麦昆可爱捏</del></p>
<p>睡前想起来这回事躺床上拿手机直接在 b
站看的，看到标题把“我们的有马纪念”翻译成“我们的中山大奖赛”就已经开始绷不住了，第一季和第二季的时候不是还可以翻成有马纪念的吗，看了下吐槽似乎有些马名（大鸣大放？）都没按照香港竞马会的翻译来翻而是自己重新译了一个，乐（</p>
<p>里见皇冠你怎么还惦记着你那魔咒（，不过和光钻的性格反差做的还不错，在没有破咒的时候皇冠是稍微相信魔咒每次失利都更加畏缩，光钻是始终不相信魔咒的存在一直在努力，光钻破咒了之后皇冠也受到鼓舞赢下了
G1。只是香港瓶没版权做不了也有点小急（</p>
<p><del>皇冠好涩，远景里高尚骏逸的小肉腿也好涩，怎么会是呢（</del></p>
<p>所以说真的没有人记得大鸣大放了是吗？cy
你要这版权有啥用啊，不就一背景板工具人吗，你看黄金伶人的替身（巨星俳优）不也演得好好的吗（</p>
<p>帝皇谈心 <del>怎么就这</del>
说了点啥啊（，还以为能类比一手帝麦对决，感觉在努力类比了又没类比，看在第三季这么塞的份上算了吧不吐槽了（</p>
<p>一集一比赛确实观感就不好人设也立不起来，不过看起来是要把北黑七冠至少菜名都报全，隔壁帝宝四个
G1 还跳过了日本杯没提也是做了 13
集，放平心态放平心态（。说难听点北黑和同世代马大多甚至都还没从种马退役，要端水照顾好
<del>马主的心情</del> 也正常
<del>虽然除了把比赛塞完之外我也没看出来这是在激怒所有人还是在干啥</del>，第二季播出的时候帝宝都竟走快十年了（，麦昆家目白牧场都寄了，随便魔改控制节奏也没啥，放平心态放平心态.jpg</p>
<h1 id="月17日">11月17日</h1>
<p>昨晚睡不着吃了点安眠药，早上起来就感觉 <del>dokidoki 的</del>
心悸，一直到下午才好一点，整个考试期间也挺不舒服的。我还想着周一考概率论之前也吃了药所以感觉考试状态不太好是错觉，是我太慌了所以不舒服，现在看来感觉确实和吃药有关系，下次
<del>直接把大晚上还搁那闹腾的室友打晕</del> 不吃了（。</p>
<p>本来觉得没什么问题的，在医院开的药，禁忌症也没有高血压心脏病，但还是不舒服。</p>
<p>这优化考试准备了真的有用吗（，斜前面一个哥们考着考着看起来嫌
cheatsheet 碍事直接给扔旁边座位上了，笑死。zjz 怎么还一边考一边发
hint，<del>这是什么赛制</del>，他要是不提醒 <span class="math inline">\(\log \det (X)\)</span> 是 concave 的话我都快把
duality 搓出来了，他一说这不约等于提示直接用 KKT
了吗（。虽然造出来之后还因为不记得 Sherman-Morrison
长啥样了小破防了一下，但再一想 hint
里面甚至有逆矩阵的形式，乘起来不就好了，草。另外一个 hint
发布（？）的时候是写在白板上的但我那个位置正好看不见，然后就出现了考试中途把其中一个助教叫住让他在我的草稿纸上写一下具体形式的梦幻场景（</p>
<p>当然这都不算什么，最重量级的还是今天在卷子上证明了一个 finite state
Markov chain 一定有 recurrent state 因此它有 stationary
measure，从而对于一个 stochastic matrix <span class="math inline">\(P\)</span>，<span class="math inline">\(p^TP=p^T\)</span> 一定有非负解 <span class="math inline">\(p \succeq 0\)</span>。这题让用 duality
做，但我说实话连动手尝试一下怎么造一个奇形怪状的 primal-dual pair
的兴趣都没有，而且它出个题还要在 remark 里提到 Markov chain，zjz
也说不是非要用 duality
可以用微积分线代知识，那我可就要表演一点小小的概统震撼了。<del>希望能有分（</del></p>
<p><del>虽然本来还感觉了一下不知道能不能用 Brouwer fixed-point theorem
但是又忍住了因为更不会证</del></p>
<p>一切都是虚张声势的线性代数，可惜我线代太菜了，只能徒手建造数学大厦了捏（</p>
<p>但其实考试期间一直在 <del>dokidoki</del>
心慌，搞得人很难受脑子也不清楚。同一个式子焦躁的时候写两三遍都写不对，椭圆不相交那个题的
if 我明明拿 seperating hyperplane theorem 证完 only if
之后一眼就出来了，还嗯是因为写不清楚正负号在那里多折腾了二十分钟，别的地方也不停地笔误，状态蛮糟糕的，几乎是到最后一刻才写完。<del>但反正
ak 了</del></p>
<hr>
<p>晚上写了高统，好难，云了一点 Gaussian sequence model，<del>看着像个
toy model
但是不会</del>，不知道明天能听懂多少。暂且以坚持十分钟为目标（嗯？</p>
<!--明早去听友人讲计概辅导（不是）早点去在教室里等她下课，最好能顺便把建筑材料实验报告写了，反正就是把老师课上说的话全都写下来罢了。感觉无论是早去还是写实验报告都很 flag，还是写注释里吧（-->
<p>又收到 BBO 的广告了，差不多考完了就好想打桥牌哦（</p>
<h1 id="月18日">11月18日</h1>
<p>今天 Gaussian sequence model
坚持了半个小时才掉线，感觉算大成功了（。后面一个小时就继续在看之前找到的讲义，没什么听了。不过
slides
发群里了所以之后有心情的话感觉还能看看，这两天是不行了，期中耽误的 ddl
都赶不完（</p>
<p>上午写了一会建筑材料实验报告，感觉这个报告的要义在于把 20
张拍的照片全部塞进去（</p>
<p>这张图我愿称之为《再见了，所有的混凝土块》（</p>
<p><img src="https://s2.loli.net/2023/11/18/QOvWlYsgPUnrt4T.jpg" alt="sayonara.jpg"></p>
<p>右下角那个碎的那么厉害是我等实验的时候太无聊了把能手剥的碎屑都剥下来了（（</p>
<h1 id="月19日">11月19日</h1>
<p>建筑材料实验周五做了一个半小时，周末写实验报告写了一天半最后写了 16
页，导出来有 44 M（挠头</p>
<p>它还有个文献调研的问题，今天被迫看了俩小时有关混凝土裂纹的论文（恼</p>
<p>晚上去猫超买咖啡，发现纸盒装的 NEVER x COFFEE
回来了，虽然那个美式真的是我喝过最清醒的咖啡，但还是选了拿铁，那个味真的太（，只能说感觉是因为难喝所以清醒。</p>
<p>路过果切的地方被八折吸引过去了，虽然事后想想只便宜了不到一块钱但是我出超市的时候手上还是多了一盒哈密瓜，怎么会是呢。昨晚在海底捞吃到了放在料台上的特别好吃的哈密瓜，今天自己买的反而都没那么好吃，难道说这就是</p>
<blockquote>
<p>真的，一直到现在，我实在再没有吃到那夜似的好豆，——也不再看到那夜似的好戏了。</p>
</blockquote>
<h1 id="月20日">11月20日</h1>
<p>今天和 ODE 作业搏斗了很久，到处搜了很多东西，算了 114514
个级数，还挺有意思的。用解析函数逼近一个奇点邻域内的局部解，这种想法我甚至学微积分
A1
的时候就有，当时其实觉得自己什么都不会所以应该很不严谨吧，现在看到了完整的理论就很开心。不知道为什么
ODE
感觉期中后突然上强度了，可能是期中前的东西确实学过一点的原因，也可能是我函数项级数很菜，或者合并同类项水平不行。感觉他前半学期在泛函，后半学期在泛函且复分析，而且是以本废物可以理解的简明易懂的方式在讲，学一门课赚了两门，好好好。</p>
<p>周末听讨论班和看自己找的讲义的时候就感觉里面举的例子蛮熟悉的，哦这不就是数值分析的时候学过的那个
Legendre
基吗；昨天自闭搓衣服的时候一个在旁边洗漱的姐姐突然跟我搭话，说去年数值分析的时候就见过我，今年本来想上概率论
2
最后又没上但也看到我了（，<del>我寻思着数值分析这课我也没去过几节才对怎么还就记住我了</del>，还问我下学期要不要上
bcl 的凸优化 <del>可惜我已经在学了</del>；今天看 ODE 讲义又开始 analytic
function 了，乐死，一门课学完之后仅存的记忆用了一年半（</p>
<p>说到学微积分 A1 的时候，突然想起我大一也是和 OJ
搏斗了一整年，然而已经遥远得像在梦里发生的一样了，我现在就只记得大一好像啥也没学，然后微积分
A2
学得特别差，唯一有点意思的是学了一年法语。虽然现在也只学了不到一年半的数学，但感觉至少大二上学期学的东西现在还记得不少，甚至我第一次接触赋范空间什么的就是在数值分析，但你现在要是让我去写一点
C/C++ 我只能说我根本都没这个勇气再动手了，还是写 R 吧（</p>
<p>发现在和一个助教上同一门课，这算几代同堂（</p>
<blockquote>
<p>注：本次作业占分为平时2倍；3.6.24假设T是有界的随机变量；提交期限延长至12月4日，共14天。</p>
</blockquote>
<p>既然占分是两倍，ddl
也是其他作业的两倍时间，那为什么不拆成两次作业来布置呢（（</p>
<p>为什么概率论 2 期末是 15
周啊，这不是快了吗（（。本来想这学期能在这课上学到一点 continuous time
Markov chain 就赢了，结果看现在这个进度根本不可能，把 Brownian motion
讲完就不错了。所以就是复习一些我学过的东西然后把基础打扎实一点，然后估计还要拿个不太好的成绩，乐不出来。</p>
<p>上周作业有个 2017 年丘赛题（P2），反正我现在一看到 random walk on
binary tree 就头疼，想起来期中做不出来的那道题也是个类似的设定有点
PTSD。这一年的题也没公布答案，到处搜了半天也没有，可能等再动手试一试如果做不出来的话还是得自己在
MSE 上问。前两天还有个数 21
的哥们从环里加我问我这个题，我只能尴尬地说期中刚考完还没来得及做呢（的确如此），他说问了助教这题和
Markov chain
没关系就是硬算，<del>我寻思着这助教原来会提前看我们的作业题啊，那他为什么从来不公布作业答案呢，是因为他自己会所以就怕我们也都学会吗（不是</del>。昨晚翻了一下
wh 暑假里给我的那本讲义，在第七章的习题里有，但也没答案啊（挠头</p>
<p>昨晚熄灯之后就对着 ODE
的讲义和这道题枯坐，很困很累了也学不进去什么东西，但反正还是能感觉到这周
ODE
作业有点小难，然后丘赛题也没底，算了几项感觉找不到什么规律，就是很急。后来感觉很累了也没再继续动手做题，就开始枯坐，然后回忆期中的失败，别的课都好说没有特别离谱的，就概率论
2
开天窗一个大题还是给我整挺难受的，别的题加起来也扣了一点总之不是很好看，越想越难受了属于是。</p>
<p>压力好大，周三考运筹我到现在还没开始复习，虽然知道很水，大多数都在优化里学过了，但要人肉算一堆东西的话还是有点难说。我想把
Gaussian sequence model
在讨论班之前和之后读到学到的东西都整理出来，想去学一下相关的泛函基础，想动手写一写
Frobenius method
的笔记，高统作业都写完了但说到底也不是很扎实，想回头再看一看，怎么就是做什么都没空呢，每天都在忙什么呢。</p>
<h1 id="月21日">11月21日</h1>
<p>复习运筹的时候一边看他这个 duality 一边乐，太简单粗暴了，连
Lagrangian
都懒得提一下就把对偶形式怼出来，但说实话用影子价格解释还甚至有那么一点道理，又绷不住又乐。本来懒得多看了，然后刚刚一想不对啊优化是开卷，这课是闭卷，我甚至还得去仔细背一下
LP duality
那个形式，不然我本来计算就很慢还容易错，什么都现推感觉来不及。可恶啊，优化有什么可开卷的，该开卷的是运筹（</p>
<p>反正我明晚就要去运筹考场上使劲用英文写解答了，感觉助教批我作业的时候从来不看我写的啥，就直接找我划出来的答案看对不/对。如果全是计算的话这样似乎还挺危险的，算错一个全没了谁受得了啊（</p>
<p>今天把以前写的作业又重新算了一遍，反正还是算不对，而且发现以前也有步骤不严谨的但是并没有批出来（</p>
<p>看了下赛马娘下一话的预告，怎么又双叒叕是内恰，绷不住了，<del>第三季的第三是内恰的第三</del>（</p>
<h1 id="月22日">11月22日</h1>
<p>下学期高统是林乾，<del>似乎要大讲 decision theory 和
minimax（</del></p>
<p>高统课上随便听了点然后在补看前几节课的 PPT
写笔记（，听着听着怎么突然开始 loss function is convex，然后 take
optimal parameter，还有 inadmissible
了（。<del>何必把概统优化运筹分开呢，不都是通的吗（不是</del>
<del>换句话说其实感觉可能确实就得什么都会一点才行（</del></p>
<p>下午和室友聊天，我说我前两天读到了一些二三十年前的数学，特别感动，现在又退回一百年前了。结果她大受震撼，说她现在学的东西有很多二十年前都还不存在，还只是课上学的而不是磕盐做的，乐死了（</p>
<p>运筹期中做了 40 min
左右就水完了，本来想再浪费一会生命结果这教室实在太热了坐不下去了就跑了（，好好好，期中结束了，cheers（<del>开始满意地吃刚洗好的今晚买的草莓.jpg（好怪哦</del></p>
<h1 id="月23日">11月23日</h1>
<p>今天本来想补上上周至今没写的概率论作业，最后还是看了一天高统
<del>感觉既会了又没会</del>，难道是在复刻区间套赶 ddl 法（</p>
<p>赛马娘，评，端（</p>
<hr>
<p>这集好像没啥可说的，中段的文戏意外地还可以，帝宝的谈心反而让我越来越觉得第二季实在是强。<del>原来制作组也知道北黑没目标啊</del>。但不知道为什么评分非常低，比上一话还低（</p>
<p>说实话我看完几段谈心和商店街应援之后还感觉观感好多了，结果北黑大晚上跑下楼啊啊啊啊啊啊训练还是给我整崩溃了，包括一开屏又是上次比赛两个人啊啊啊啊啊啊真的是（（</p>
<p><del>谁说第三季没有 live 了，小北的爸爸不是开了两场 live
了吗，虽然是兼用卡（</del></p>
<p>大鸣大放终于出现了，只不过开口第一句是突然问北黑你的目标是什么实在是有点生硬（，帝宝谈心也谈了，如果这些放在宝冢纪念之后就好了。该说
better late than never 吗（</p>
<p>高尚骏逸这描写怪怪的，不过刚刚连跪了好几场心情不好很正常，反而是极峰给我感觉看似安慰实则嘲讽（，私服也不是特别好看
<del>cy
你的服装设计传统艺能呢</del>。想想高尚骏逸出场加起来应该不超过五分钟就还是释然了（，<del>人设立不起来是正常的，输了就在姐妹面前垮起个批脸也是正常的（，没看到在训练也是正常的，后面突然一生一次的末脚也是正常的（（</del>
反正没有剧情也没关系，后面等角色在游戏里实装了再补个人剧情也行，第三季还就是那个宣传片，开摆！</p>
<h1 id="月24日">11月24日</h1>
<p>下午在教室打开门看到门边坐的一个哥们在全屏玩原神，差点没绷住（</p>
<p>去新土木馆 <del>搅水泥</del>
建筑材料实验的时候那边正在消防演练，楼道里全是烟，<del>我昨天刚洗的头，我的鼻子</del>，这破专业怎么还折寿呢（</p>
<p>有时候有点怀疑是不是只有特定会触发任务的人能看到我（，搅水泥之前按组领表格的时候大家都在随便拿，我说前面有组号结果旁边的大哥还是没听到我的话就把我的拿走了（。直到他们发现不对在若干人之间传了很久之后另一个哥们把它放回去，我站他面前说能不能把第五组的给我，他还是没听到，绕过我放到讲台上就走了，草（（</p>
<p>然而今天搅水泥穿了一身白衣服，只蹭脏了一点已经是我赢了，晚饭吃香锅又快乐地往上面溅了三个油点（（。虽然经常吃清芬但其实还是第一次吃香锅，你这中辣怎么没味啊（</p>
<h1 id="月25日">11月25日</h1>
<p>开始做双十一买的纸模了，似乎小栗帽比麦昆的简单一些，但裁下来几块头发之后人就已经晕了，希望能做完（</p>
<p>今天写了一天概率论，主要就是在对着不会做的题发呆，还有睡大觉（，<del>相对</del>
非常失败。这期中周的后劲怎么还没顶完，马上都十一周了，爆了（</p>
<p>太乐了，来点最喜欢的一集（<del>这课显然不是我在上</del></p>
<p><img src="https://s2.loli.net/2023/11/25/V1FbaihJUuOTXwS.jpg" alt="hermite.jpg"></p>
<h1 id="月26日">11月26日</h1>
<p>最近答疑坊接的都是熟人的私活，值班也鸽了不知道多少了，干不动一点，津贴和
<del>最基本的别因为值班次数太少被踢出去了都</del>
有点寄。下周打算去补一次顺便写写这周的建筑材料实验报告，要是写不完就补两次反正我每次讨论班之后也都没心情去（，急急急。</p>
<p>晚上 <del>yoasobi 的时候</del> 突然感觉心口疼，<del>20
岁，一天到晚一副要寄了的样子，鉴定为老猫，喵喵</del></p>
<p>最近在校内找到了一家品控好价格正常送货上门的水果店，吃了很多在他家买的橘子
<del>主要是相比之下橘子是最方便吃的不怎么需要洗而且还不贵</del>。想起来《<a href="https://www.bilibili.com/video/BV1vq4y1t7YN">我去世了，然后...</a>》，感觉死前能吃够
100 个，问题不大（</p>
<h1 id="月27日">11月27日</h1>
<p>洗漱的时候听到两个致理数 0 的姐在聊天：</p>
<blockquote>
<p>A：你毕设导师找好了吗</p>
<p>B：找好了，是丘中心的 xx（没听清</p>
<p>A：我还没找呢，现在数学系是不是已经没有有名额的老师了，那咋办</p>
<p>B：丘中心和统计中心都可以，跨专业也可以，但是要申请</p>
<p>A：我还在犹豫做运筹还是统计，我之前学运筹那几门课完全学不明白，感觉和运筹相比还是统计简单点</p>
<p>B：丘中心做应数的老师就那几个，我怀疑现在可能已经没得选了（</p>
</blockquote>
<p>《还是统计简单点》，差点把这学期在上高统的我吓晕（，上周一直在补落下的进度，看
Jun Shao 每次都离昏过去只差一点，虽然也确实很有意思就是了 <del>抖 M
就直说</del>。<del>哦她学的是数学系概统的那几门限选课啊，那确实还好（</del></p>
<p><del>但相比之下运筹难在哪了（不是</del></p>
<p>今天把上次那个二合一的高统作业写完了，进度也赶得差不多了（，binomial
distribution 的二三四阶矩加权和算得我天昏地暗还没有答案，最后 <span class="math inline">\(Var T\)</span> 比 C-R lower bound
严格小而且完全看不出来哪儿错了（，希望期末没事（（</p>
<p><del>问题是 C-R lower bound 和 Delta method 算出来的 amse
一样大，应该就没问题啊，那错的还是 <span class="math inline">\(VarT\)</span>
呗，问题是我没觉得错啊，助教看着想扣几分扣几分吧（（</del></p>
<blockquote>
<p>Brownian Motion
的定义看起来非常简单，但其实还需要验证是不是给出这三个条件就能确定唯一的一个过程，还有三个条件是不是冗余。我读博士的时候有个老师讲过一个故事，系里曾经有个搞代数的研究生做了一个很复杂的东西出来，答辩的时候委员会问了个很简单的问题，就是这个东西存不存在，他当时没回答出来，回去想了想确实不存在，就延毕重做了（</p>
</blockquote>
<p>草（</p>
<p>连一刻都没有为概率论 2
写不完的作业和寄掉的期中哀悼，立刻赶到现场的是上周五的建筑材料实验报告，这周日要做的建筑材料课程实验，这周五要做的建筑材料实验，上周布置的生物作业，还有周四建筑材料研讨课要做的
pre！</p>
<p>晚上又遇到了两周前的周一在同一个位置上看 GTM
的男生，这次看到了封面，是 GTM 274，和我想的一样（</p>
<p>感觉应该世界很小，很可能是吴昊的学生，但反正也不敢问（</p>
<h1 id="月28日">11月28日</h1>
<p>睡前躺着看了下今年的日本杯，不用想也是春秋分的散步大胜（。不说秋三冠怎么样了，<del>求你了再跑一年吧别直接去当种马，我什么都会做的（</del></p>
<p>建筑材料研讨课的队友说 nature
上有一篇文章比较合适可以去看一下，我在心里默念：内恰上有一篇文章比较合适（</p>
<p>越想越气，我放着讨论班的论文没看，搁这读建筑材料研讨课的论文，建筑材料实验报告还得随便引几篇，建筑材料的实验还有个这课的老师的论文没看要学一下怎么处理数据，生物作业也是文献调研题，看又看不懂，还就那个离谱（</p>
<p>今天下午骑车的时候把电脑屏幕摔（？）碎了，在教室掏出来的时候大受震撼还以为寄没了，再仔细一看屏幕就碎了挺小一部分，看起来哈人只是因为顶盖变形比较严重。测了下主板键盘什么的都没啥问题，心情好了很多。修是不可能官方修的，只能自己买个盖买个屏幕换一换这样子，-300，本不富裕的家庭雪上加霜（</p>
<p><img src="https://s2.loli.net/2023/11/28/iBWmx5og6ULb8Py.jpg" alt="二号机.jpg"></p>
<p>它正好裂在 <del>已经战损的</del>
二号机贴纸这个地方，想想二号机的战损程度突然感觉好像就不应该贴这个（，遂下单初号机金属贴，<del>只要驾驶员自闭就很耐造（</del></p>
<p>说实话这个 A 盖翘起来之后反而方便拆下来了，我赢（，B
盖边缘有一点轻微的变形，感觉拼装的时候或许会有小问题，暂且拿钳子掰了一下感觉应该还好，不至于再花几十块钱重新买一个。</p>
<p>下单配件之后发现买屏幕的那家店在商品详情页写的是“不难，女学生，新手都能自己换好”，销量
2 万 +，现在真的是 2023
年吗？退货换了一家，点了个举报，虽然大概也没有什么用，除此之外能作为反抗的选项就是自证了吧，我拒绝。</p>
<p>出于好奇查了下官修的价钱，感觉自己动手的话还是赚麻了又不觉得 300
贵了（（。后来想起来还可以带着配件去科服修，但也有点想自己拆着玩（？），到货再说吧。</p>
<h1 id="月29日">11月29日</h1>
<p>上午和中午认真听了会生物课
<del>然后四道雨课堂题错了三道</del>，充分说明我是真的学不了这玩意，然后
<del>在队友完全失踪的状态下</del> 把建筑材料 pre PPT
做了，体育课前把建筑材料实验的实验报告写完了。<del>今天是认真学专业课的一天（迫真</del></p>
<p>晚上本来想学一下今天的高统，然后想想作业也不是很急还是算了，更急的是概率论（，但不知道为什么不是很想学这个东西，期中裂开之后心态上有点摆了
<del>这不行吧</del>。结果喉咙越来越痛直接睡了，原因不明但除了感冒了之外还能是什么呢，吃阿奇霉素.jpg</p>
<p>回寝室一看之前买的药都过期了，心态爆炸（</p>
<h1 id="月30日">11月30日</h1>
<p>喉咙还是好痛，现在是连带着头也好痛，人有事（。今天除了在睡就是在难受得睡不着，一天做了四道概率论，急死了（。这个月还只有
30 天，更急了（（</p>
<p>吃西瓜霜的时候看了眼成分表，辅料是蔗糖，<del>那你不标一下营养成分表告诉我每
100g 有多少糖我哪知道要吃多少啊</del></p>
<p>马娘，评，端（</p>
<hr>
<p>周一看了预告之后我还在想，看起来是日常贴贴回，这还能做烂了？</p>
<p>看完：到底是我有问题还是 KAI
社有问题，感觉有点理解不了制作组的精神状态（</p>
<p>早晨一起床突然说要去 <del>随机公交挑战</del>
旅游，<del>那光钻要是没被吵醒的话你就自己一个人去了呗</del>，思考了一下和朋友之前出游的情况感觉到处晃悠还挺能理解的，这随机公交挑战还给我看出几分亲切感（。然后这个复刻光钻突发放狠话的二度离婚是怎么回事呢（，镜头一转就开始比赛了又是怎么回事呢，<del>有一种比赛前的一回合选择了外出所以半个月都在摸回来突然比赛也能赢的错觉</del></p>
<p>上次北黑和光钻冲线的时候中间沉默而且没有特效的是黄金伶人（没版权）我还能理解，这次中间是高尚骏逸啊，怎么会是呢（。<del>但是远景过弯的时候高尚骏逸的腿真的好可爱啊，好像觉醒
xp 了</del></p>
<p>赛后为什么又是无视了第二名开始和第三的光钻贴呢，按理说第二名难道不是很重要吗，一边压制光钻一边逼迫北黑，换句话说光钻连高尚骏逸都跑不过还说没超过北黑什么的真的没问题吗。比赛中途也一直无视，很难想象之后要怎么刻画一生一次的末脚，<del>要么就别写了，不然骏逸还要惨遭拥有一个单人回</del></p>
<p><del>居然有樱花桂冠，好评，但我总感觉突然插宣传片莫名其妙的，难道是对第三季的刻板印象导致的（</del></p>
<p><del>你看看第二季帝宝麦昆贴都是抱在一起互相鼓励，为什么小北和光钻贴就只有握手，真不熟</del>（</p>
<p>其实我还是疑惑光钻冲线的时候这个闪回是什么意思呢，一直带着自己去看前方各种风景的是小北，ok
fine，但上次不是你赢了吗（。怎么不是想北黑这段时间以来相比自己进步了多少（然而我完全感觉不到！）而是在想这个（</p>
<p>感觉蜜汁演出好多，不知道慢动作入闸是在干啥，小北比赛中间突然开领域（确信）我还以为给安排了点不存在的骨折戏份（，结果就这（。念叨凯旋门赏念叨到现在终于给了大鸣大放三个镜头，求你了下集别又把人家给忘了（。高尚骏逸冲刺的时候终于有台词了，所以下一话会是日本杯吗，那我大鸣大放呢（（</p>
<p>不过贴贴确实好看，特别好。</p>
<p>这番真的还有必要继续追下去吗，真的有必要吗（</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇十六·23年12月</title>
    <url>/2023/12/01/Diary-2023-12/</url>
    <content><![CDATA[<p>喵喵喵喵喵喵喵喵喵（</p>
<p>二十岁老猫过冬.jpg</p>
<span id="more"></span>
<h1 id="月1日">12月1日</h1>
<p>喉咙好点了，头还是嗡嗡的，急（</p>
<p>做完非常后现代的建筑材料实验出来之后在文北楼旁边的垃圾桶看到个熟悉的东西，第一反应这不会是个混凝土块吧然后狠狠地嘲笑了自己做完实验看什么都像混凝土。走近一看怎么这个断面怎么这么标准的条状断裂（，怎么正面还有实验条件和批号的标注，还真是压碎的混凝土上岗再就业（</p>
<p><img src="https://s2.loli.net/2023/12/01/nuMGhDvU8oRB9jf.jpg" alt="cement.jpg"></p>
<h1 id="月2日">12月2日</h1>
<p>省流：今天修了一天电脑，好像学到许多（</p>
<p>中午把配件从快递点取回来之后就开始动手拆电脑了，我寻思着不就是换个屏换个盖能有多难，结果直接那个错过了讨论班（。拆
D
盖拔电源我轻车熟路，拆转轴拔屏线信号线重拳出击，拆转轴盖...诶怎么拆不下来，看了下发现是和
B 盖连在一起的不用拆，学多（。正好摔的时候 A 盖和 B
盖已经有一条缝了还不用努力抠，只是这个 B
盖用双面胶粘在屏幕上实在有点费手（，拆的时候把旧屏又压碎了一点还把手划了，倒也都不是问题。然后是喜闻乐见的撕易拉胶，把屏幕拿下来一看，怎么和我想象的不太一样，A
盖后面两根线粘的死死的，其中一根焊在下面的结构上然后贴在后盖上，扒拉了一下撕不下来，草（</p>
<p>仔细研究了下感觉不太清楚金属胶贴下面是只有胶还是有走线（但最后知道就只是胶，撕不下来的结构也不敢太大力，于是把四部分电脑收起来等晚上去科服问一下，打开旧
surface 开始用 Overleaf
写作业强装淡定.jpg，然后很疑惑五六年前为什么会买这么难用的电脑（</p>
<p>七点左右到 C
楼把四块电脑一块新屏一块新盖排成一排（，感觉对面的表情逐渐疑惑了起来（，就承认了是拆到一半感觉超过我能力了这样子（。最后是用热风枪把所有东西拆掉又贴到新盖上的，学到许多我也想买一个（不是</p>
<blockquote>
<p>A：我再研究一下你这个盖上的结构，旁边这块白的是啥啊</p>
<p>我：这是我没撕干净的易拉胶（</p>
</blockquote>
<blockquote>
<p>A：你这拆的还挺好，要不要试试我们的招新面试</p>
<p>我：我瞎拆的（，而且我还在答疑坊打着一份工呢（</p>
<p>B：那算了，我们时薪没答疑坊高，还累（举热风枪</p>
</blockquote>
<blockquote>
<p>A：所以为啥要单独买个屏买个壳呢，这样拆一遍壳很费劲的（</p>
<p>我：对不起（</p>
<p>B：所以咋不重买一个呢</p>
<p>我：对不起（，但我都用惠普战 66 了不就说明没钱吗（</p>
<p>C：别说人家啦，拆好带过来还没拆出啥问题挺好的了，不然还得拆一遍，费手</p>
<p>我：对不起（</p>
<p>A：他是在夸你</p>
<p>我：对不起（</p>
</blockquote>
<p>顺便见到了人手一套的电动螺丝刀，<del>寝室里 32
头的那一套瞬间就不香了</del></p>
<h1 id="月3日">12月3日</h1>
<p>这周的优化作业怎么这么抽象啊（，你谁（。<del>其实我的意思是这周的优化作业怎么这么具体，虽然它一直都很具体但这周有两道题写起来好困难</del></p>
<p>牛顿法数值分析的时候已经学了个大全套了，看 zjz
这个讲义感觉也太云了，<del>这学期为什么要上这课呢</del>。</p>
<p>今晚把周一晚上要交的作业写了，明天把周二下午要交的作业写了，后天把周三晚上要交的作业写了。我感觉我一天天的都挺忙的怎么还卡得这么紧呢（，原来是一直在看最近没布置作业的数理统计啊（</p>
<h1 id="月4日">12月4日</h1>
<p>初号机贴纸怎么还没到，急急急（。突然意识到之前的问题所在了，贴了二号机的电脑怎么能放在朗枪的包里（</p>
<p>上周被喉咙痛折磨得不轻，这周感觉右半边腰特别疼，稍微一动就感觉像闪着了一样，活着真累。<del>猫猫活到二十岁已经很不容易了，感觉快要不行了</del></p>
<p>下学期果然是林乾开高统
2，杨朋昆开高维概率，但我寻思着统计中心就没几门博士生课你俩为什么要都放在
4-2 开课，急了。再一看实分析也有一节
4-2，感觉要冲突选课。再再一看发现复分析和组合优化也创了，感觉还要冲突选课，<del>被冲突的当然是复分析就是了</del>。<del>往好处想下学期课表会显得比较空，因为都覆盖了</del></p>
<p>别的没有啥特别想上的课了，摸了个社科课组，再见了，所有的通识选修课（。体育打算选个壁球玩玩，这学期毽球没有上学期有意思，不想再踢了。必限就一两门，在考虑要不要上个基物
2
<del>防止被退学</del>，之后如果不每个学期浅浅学点物理的话我感觉我五年也毕不了业（</p>
<h1 id="月5日">12月5日</h1>
<p>算了下感觉下学期必修就一门基物 2
一门什么绿色交通系统就行，现在在考虑的是我大四春季有一些连着暑假一起春研暑研的宏伟计划（，所以为了不妨碍大五毕设开题，春季还是不能剩下太多课。大四上修量子力学和工程力学基础，大五上修工程力学
CE，结构力学和流体力学然后随便它们烂成什么样（，最后一学期把工程地质和基物
3 解决一下就行，还是能有条不紊地毕业捏（？？</p>
<p>我以前一直以为中厅是没有暖气的所以特别冷，今天发现就在饮水机旁边，摸了一下是冰凉的，有没有其他紫荆住户能告诉我这是不是正常现象（（。<del>说实话这真的合规吗，不是供暖室内低于
18 度都不行吗（</del></p>
<p>本来想给核动力笔记本贴个电力充足，想了想还是没电的初号机更强一些，就给它再加强了一下（</p>
<p><img src="https://s2.loli.net/2023/12/05/6Pm8c4VWNb9LHDw.jpg" alt="Evangelion01.jpg"></p>
<h1 id="月6日">12月6日</h1>
<p>今天穿北黑痛衣跑了 1500，英里距离适性 C
果然还是不够用，但立定跳远变强了非常多，感谢室友教我正确的姿势（</p>
<p>下略。</p>
<h1 id="月7日">12月7日</h1>
<p>昨天跑了
1500，今天就是一个人大困特困，腰背腿大痛特痛，于是大睡特睡，连高统 PPT
都没看完（</p>
<h1 id="月8日">12月8日</h1>
<p>北京的松鹤楼和上海的一样好吃，感觉稍微有点安慰（</p>
<p>晚上在看运筹的决策分析，看了几页感觉定义有点像 decision
theory，还看到了简化版的 Bayes
rule，结果画风一转变成需要按固定格式写的小学数学应用题，我到底在期待什么（</p>
<p>感觉有点小急，作业好多，但是又不是特别急，属于一个轻轻摸一下也能做完的情况（？</p>
<h1 id="月9日">12月9日</h1>
<p>处理了一些约等于在摸的作业<del>（真的吗写高统作业不是次次都在痛苦嚎叫吗）</del>，然后对着优化不会做的那两道题继续阴暗爬行，然后
yoasobi，然后睡觉（</p>
<p>听说 yyl
被非升即走了，这英文高代选这么有意思，我答疑还做了不少他们的作业题，以后就没了（悲</p>
<p>晚上在紫荆吃了好吃的鸭腿饭，<del>要不寒假回家试试复现（怎么这也能复现</del>，拿到了前两天买的好喝的酸奶，室友的品位还是高（</p>
<h1 id="月10日">12月10日</h1>
<p>学 Blumenthal's 0-1 law 的时候心里默念的是
Duramente（（，这听起来不是挺像的吗（</p>
<p>好消息：十六周周三不用连考三门期末了！</p>
<p>坏消息：因为高统提前到了前一天晚上考（</p>
<p>感觉考完高统之后要回去紧急背生物，考完生物回寝室睡觉，然后下午稍微看一眼运筹就可以去考了，都不是问题，复习这些还不如早点开始写优化的
cheatsheet（。但确实有个好消息是不用担心睡得不好影响考试了（（</p>
<p>晚上五分钟遇到了三只不同花色的猫猫，回去得稍晚了一点，骑车的时候感觉手比平时冷很多，然后就感觉到冷冷的冰粒子，啊不是，雪花拍在我脸上（</p>
<p>一些和交大转数群友（？但确实是）的暴论：</p>
<blockquote>
<p>H：</p>
<p>你猜猜看我的数分助教是做什么的</p>
<p>我：</p>
<p>他既然觉得 Lebesgue 积分和 Riemann 积分不一样</p>
<p>那先排除概率 再排除分析 我感觉统计也不至于（</p>
<p>是代数吗 是不是本科不必修实变或者忘完了</p>
<p>但我觉得这是个很基础很优美的结论 总应该知道的吧</p>
<p>总觉得代数都是聪明人（刻板印象.jpg 是不是也不至于啊（x</p>
<p>H：</p>
<p>不是</p>
<p>三个助教是同一个课题组的 做 PDE</p>
<p>我：</p>
<p>草 dbq 我想起来那句</p>
<p>PDE 养活了不知道多少无能的数学家</p>
<p>没有说他们的意思 只是无端联想（</p>
<p>H：</p>
<p>草</p>
<p>礼拜五我问我那个助教是不是做分析的的时候</p>
<p>感觉他稍微有点蚌埠住</p>
</blockquote>
<h1 id="月11日">12月11日</h1>
<p>半夜两点跑到楼下在雪地里用一次性筷子默写了《雪赋》的最后一段，精神状态非常的好啊。</p>
<p><img src="https://s2.loli.net/2023/12/12/L76rqIczoKRO51h.jpg" alt="23_12_11.jpg"></p>
<p><del>我相信这图上是看不清的但是说不定放上原文就能对起来了</del></p>
<blockquote>
<p>白羽虽白，质以轻兮，白玉虽白，空守贞兮。未若兹雪，因时兴灭。玄阴凝不昧其洁，太阳不固其节。节岂我名，洁岂我贞。凭云升降，从风飘零。值物赋象，任地班形。素因遇立，污随染成。纵心皓然，何虑何营？</p>
</blockquote>
<p>今晚在作业里写了一个</p>
<p><span class="math display">\[\{T_A \leq t\} = \cap_{n=1}^{\infty}
\cup _{s \in \mathbb Q \cap (0,t)} \cup_{i=1}^\infty \cup_{x \in \mathbb
Q^d \cap A_i} \{B(s) \in B_d(x,\frac{1}{n})\} \in \mathcal
F_t\]</span></p>
<p>其实我只是在证 Brownian motion 中一个 <span class="math inline">\(F_\sigma\)</span> set 的 hitting time 一定是
stopping time（。能把 trivial
的东西写得这么丑陋和唬人，似乎觉醒了一点点灌水的天赋（</p>
<h1 id="月12日">12月12日</h1>
<p>明天暴雪橙色预警，但是我有四节课（疑惑</p>
<p>下午写优化作业，因为认为 <span class="math inline">\(t(t+1)\)</span>
在 <span class="math inline">\(t=0\)</span> 时取值为 <span class="math inline">\(1\)</span>
而疑惑了至少二十分钟。晚上在答疑坊值班教室友写概率论作业，五道剥蒜题给了我到现在都没有恢复的心理阴影（</p>
<p>晚上回来又在赶之前在答疑坊接的一个这周要交的主人的任务，想了想这个月几乎就没多少津贴，还是干一下吧。</p>
<h1 id="月13日">12月13日</h1>
<p>下午在寝室和综体之间走了一个来回，晚上又在寝室和法图之间走了一个来回，还上了体育课，今天的运动量就到这了（。课好难，好冷，好困，好累，这学期怎么还不结束，这紫荆宿舍怎么还没塌掉，麻了（</p>
<p>晚上在看高统的讲义，感到深深的疑惑，wwc
平时都在抄书这次怎么把书扬了整这么难，想了想好像之前也很难但好像学会了之后就会变简单（，希望吧。但是优化学起来完全不是这个感觉，学一点忘一点，也不知道是这课的问题还是我的问题。</p>
<p>一到 asymptotic behavior
就开始大力分析了，感觉自己好菜，<del>以后谁再说统计简单我跟谁急</del></p>
<p>早上有点睡多了，晚上走回寝室的路上想了想在打烊之前拐去七港九买了杯奶茶，后来又来了几个人在纠结晚上再喝一杯会不会睡不着，要不要换成果茶。店员说已经没有奶茶了，我这杯是最后一杯，他们说太好了（。感觉我也赚了，大家都满意的世界达成了（</p>
<h1 id="月14日">12月14日</h1>
<p>今天研究了半个下午怎么配混凝土的各个组分（，感觉本质上是个有八个参数的非线性规划问题，虽然是有解的但是
feasible set
不是很大，解的可解释性（）也都不太好。但如果想得到解释性好的解的话，可以稍微牺牲其中一个
constraint，所以除了规划之外还可以整个 weighted cost function
把它变成优化问题，乐死了（<del>学数学学得</del></p>
<p>本来想参考下同学的（迫真，算着算着越来越不对劲，仔细一看他们公式代错了，草（</p>
<p>因为没法解释其实也不太敢（？）和队友解释我这些迷思（，再加上这个活拆成六个人的份本来就不合理，就一个人把六个人的活给干了，至于干得怎么样还得看明天做出来的结果（，就图一乐吧。这玩意
16 周有个 pre，到时候就心安理得地推掉给他们就好了，哥们 16
周考四门课，真没时间陪你们玩泥巴了（</p>
<p>今晚似乎是最后一个熄灯的晚上了，回去收拾一下直奔 C
楼把这个计算书敲完，这寝室真待不下去了，断电之后冻死（</p>
<p>昨晚梦到在上讨论班（为什么，一个同学在台上讲他论文里证的一个不等式，另一个同学问他你的
lower bound
既然可以达到那算什么不等式，不是可以相等的吗？还有一个同学问为什么常用的不等式里的符号都不是
<span class="math inline">\(\neq\)</span>，这算什么不等式（。然后吓醒了，发现自己在床上而不是在讨论班坐牢，非常开心（</p>
<p>所以这周六到底是考六级还是去讨论班呢，要不周六早上起床再说吧（</p>
<h1 id="月15日">12月15日</h1>
<p>探索了下 C 楼的刷夜，其实体感还挺好的，以后寝室太冷 / 太吵 /
太安静（？）可以经常来。但我这次居然是在刷夜写混凝土配合比计算书，乐（。一边写又一边抄文献，我知道做这个事情毫无意义，但昨天看到两个队友算错的数之后就稍微有点不舒服然后开始单干了（。其实我觉得我要求真的不高，能把公式都用对，满足所有的
constraints，在此之上可解释性的要求也只有一两条，结果长得和大多数文献或者专利里差不多就行了，这不都是很合理和基本的想法（？</p>
<p>然后今天做出来结果还挺好的，虽然是绝对的烂，但是相对的好，那就挺好的了（？</p>
<p>看选课，发现下学期要选的其实没啥课，高统复分析组合优化
<del>还有基物</del> 而已（。到处乱搜的时候看到求真有个计算概率，讲 MCMC
之类的东西，用的书以 applied 开头（，稍微有点心动。再一看作业 50% 上机
50%，更心动了，现在在我眼里写上机作业竟比考试更轻松（</p>
<p>茶园还有个因果推断前沿的 2
学分的课，但感觉在方向上有点太细分了不好说有多大用处。</p>
<p>早上起来看到 <a href="https://mp.weixin.qq.com/s/xmWPEcG9oMsyVUcVX_oCFQ">CoCo
和恋与的联名</a>，虽然早就不玩了但爷青结（，而且这好便宜，四舍五入一块亚克力两张拍立得两个杯套一个保温袋
<del>还送两杯糖水</del> 才三十，遂点。不过前夫哥的那款 <del>糖水</del>
奶茶不好喝，有一种玫瑰香精滞销于是捆了烫男人的谷子一起出售的感觉（</p>
<h1 id="月16日">12月16日</h1>
<p>前几天一直走路，昨晚才又开始骑车。其实唯一的原因就是我只有一件羽绒服还是浅色的，万一真摔在泥水里就没衣服穿了（（</p>
<p>今天还是选了讨论班，第一次有我能全程听懂的，真不错。但说实话最后几个老师的锐评以及中间的提问和讨论才是很精髓，不管从找了乐子还是学到许多的角度来说都感觉在这个天来回骑了八公里挺值的（（</p>
<p>晚上回来去答疑坊值班，给室友讲概率论，算得我天昏地暗，结束之后换个教室爆睡，睡得正暖和的时候教室关门了，走到外面真冻麻了（。来点暴论，零下十几度本质上也还行啊，感觉冷的来源主要还是室内外温差大切换不过来，还有这个北京风真的太大了，没风的话也不至于（</p>
<h1 id="月18日">12月18日</h1>
<p>昨天一天都不太舒服，晚上好点了去刷了个夜，今天还去了早十，感觉睡眠不足一整天人都有点降智，包括但不限于在食堂掉了耳机，出门打水忘记把杯子带走，刮坏手机膜还又把手机掉地上一次（。今天早上洗脸洗着洗着感觉有股奇怪的味道手感也很怪，睁开眼睛一看流鼻血了还被我抹了半个脸，实在有点难绷（</p>
<p>又该买手机膜了，<del>然而上次凑单的时候怎么不买</del>，<del>虽然但是我还是觉得水凝膜是最好的，不接受任何反驳</del></p>
<p>看了下选课除了基物 2
必掉之外其他都没事，<del>应该考虑的是选了这么多乱七八糟的下学期开学之后退哪个</del>。基物换个老师就行了
<del>然后就要换回我大一时的基物 1
老师了</del>，好但是又不太好，考试前要背好多题。上次上基物 1
还是两年前，而下次上基物 3 应该是大五的春季，也就是两年后（（</p>
<p>pad 到了，还就买前生产力买后 Arcaea，摸了一把 mili 的曲子，普通的 ftr
8 打了个 992，感觉又菜又不算太菜的。不能再摸了概率论真要寄了（</p>
<h1 id="月19日">12月19日</h1>
<p>有一说一这优化怎么还没赶上我上周二的进度（，这后半学期想学深一点的话算着还挺累的，不知道考试怎么考。</p>
<p>Bubeck
好书，然而这课涉及的还是太少了，寒假能不能多看点。说起来寒假如果有心情把
multi-dimensional Brownian motion 那一章看了的话就把 Durrett
从头到尾读完了，理论上来说这书看了半年多不应该变强吗可我怎么还这么菜呢（</p>
<p>问题是光搁这看书，我的科研到底什么时候才能开始，急死了（（。某种程度上来说就是换点没那么容易看的书啊不是
paper 看（，但不知道为什么就是开始不了一点，考完试去跟 ypk 谢罪吧（</p>
<p>今天才发现给 iPad 9 买了个二代 apple
pencil，也退不了了，笑晕。折了点价出掉，本来想拿这个钱再买个一代，想来想去还是买了支第三方的笔，一通优惠最后
75 拿下，傻乐了半天，消费降级.jpg（</p>
<p>快期末考试了还能学到新知识，好开心哦（（</p>
<h1 id="月20日">12月20日</h1>
<p>在手写笔到货之前果然是不可能用板子干正事的，复健了一下 Arcaea 和
Lanota（。今天下午去取了快递，在体育课见习的时候写了点作业。不过壳和贴膜还没到，还是不大方便带出门，今天带去体育课之前紧急付了
apple care（</p>
<!--之前找出来了以前给 surface 配的手写笔，是我高三的暑假第一次跑到奉贤做家教，赚了八百之后买的。后来用它上了很多网课，挣了不少钱。来华子之后换了电脑就不太用了，偶尔还拿来涂涂画画，以后恐怕也不怎么会用了，其实一个笔头都还没用坏，想想有点可惜的。-->
<p>用 EVA
终的海报定制了个壳儿，我理想中觉得会很好看，就是不知道到货会怎么样（，根据之前印手机壳儿和痛衣的经验来说应该会还好，但想了想既然是定制那不就说明不能退了吗，不好也得用吧（</p>
<p>晚上发烧了，我说这一年到底生病多少次了，受不了一点（</p>
<p>怎么算都是复习不完了，那怎么办呢，干脆好心态决定女人一生.jpg 吧（</p>
<h1 id="月21日">12月21日</h1>
<p>睡了一天，也不大有胃口吃东西，那么下周一的概率论期末怎么办呢，急急急急急急急急急急（</p>
<p>晚上稍好一点了开始想吃东西，迅速点了杯奶茶，把冰箱里存的一盒龙眼吃掉了，不知道待会还会不会大睡特睡，不睡的话干脆就多学点吧（</p>
<h1 id="月22日">12月22日</h1>
<p>一学期下来发现还是高统最有意思，概率论不知道是不是因为学了两遍有点想吐了所以不好玩，优化也一般，探索了一年半最后还是收敛到了选择转数时懵懂地说打算做统计的起点。听起来也很合理，毕竟一个
Brownian motion 会以概率 <span class="math inline">\(1\)</span>
经过原点不可数多次（（</p>
<p>这学期选的其他数学课多少都有点（，下学期也不打算到处玩了（<del>真的吗那你不妨说说都选了些什么课</del>。ODE
这课设计得是非常好但我不大用这玩意也没精力，给水过去了，唯一一次在别的地方见到
ODE 还是 Brownian motion 里有个和 heat equation
相关的结论（<del>曾经在一个夜晚把在 C
楼刷夜的我折磨的不轻</del>，其实非常优美但也只用一个壳子罢了。</p>
<p>现在我也不知道科研会往哪个方向跑了，初期还是得贴着 ypk
他让我看啥我看啥，沾着优化和统计的边跑
<del>前提是鸽了一个学期之后他别不理我了</del>。优化这课上下来觉得没啥意思
<del>刚刚说什么来着</del>，但感觉和数值分析一样思想和一些技术还是很泛用的，下学期去摸个求真的组合优化看看是不是茶园这课的问题罢（</p>
<p>虽然现在的下学期课表和真正的课表之间还差一个忒修斯之船，但可以预见到的形状是周二早八一节
<del>未必会去的</del> 培养方案内水课后去上三课时 wwc
的课，然后第三节午睡一会去体育课，回来洗澡洗衣服吃饭再去晚课，听起来就和这学期周三一模一样（（</p>
<p>这概率论 2 前半学期的东西随便看看复习下定理和结论差不多得了，yf
说不太会再考很精细的证明了哥们也不想再学第三遍，如果考到不会干脆那个认栽。后半学期又觉得没讲啥，虽然
Brownian motion 里面有很多涉及到 continuous time
的东西感觉思路还是挺不一样的但是这一章东西倒也并不多，还是不知道会考啥。麻了，学数学和学考试能一样吗，后面忘了，为什么要演奏春日影！然后把
Ito's formula 学了，反正不考，学了我赚。</p>
<p>这生物老师和助教怎么都这么喜欢空口鉴 ChatGPT，上课也经常说有人在用 AI
写作业，我唯一一次全程自己写的作业（只是一个思维导图整理）被她鉴成
ChatGPT 写的了，有没有一种可能就是我自己完全没理解这课在学什么所以抄 PPT
抄出来看着没啥逻辑呢（。随便了，又没打回来让我重做，我就当没看到评语算了（</p>
<p>今晚脑子一热把托福的 2100
交了，约了春季学期初的考位，这下不想学的时候想想交的钱应该就能学了（，给寒假找了个摸鱼的
upper
bound。在真正的春季考英语、一场考试两个小时、考前只有大约三个月时间可以从头开始学、听说读写都要考、写作包括
summary
和作文，原来我时隔三年又要考英语春考辣（，<del>你这上海英语春考怎么是在北京考啊（我也想约个上海的考位来着啊（</del></p>
<p>真正的原因是本来没有暑研计划的大三暑假现在被迫要找一个了，而我从大一下学期打算出国开始到现在连六级都一直拖着没考，唯一的语言成绩还是四级的分数，好丢人（（，再不逼自己考一个怕要等到真申请之前滑铲了（</p>
<h1 id="月23日">12月23日</h1>
<p>之前不知道为什么有个印象是高统 I 作业期末 3:7，今天看了一眼 syllabus
才发现是五五开，给哥们高兴坏了毕竟这作业分都是白送（x</p>
<p>之前读书上的定理的时候自然地形成了一个感觉，觉得 optional stopping
theorem 的题目要靠 uniformly integrable 拉 <span class="math inline">\(L^1\)</span> 收敛，以及我觉得 <span class="math inline">\(E|X_N|&lt;+\infty\)</span> &amp; <span class="math inline">\(X_n 1_{\{n&lt;N\}}\)</span> UI
这个条件是最好用的，因为前者非常好算，后者有的时候会 bounded by an
integrable r.v. <span class="math inline">\(Y\)</span>。今天又摸了一手习题才意识到其实很多都能先把
<span class="math inline">\(N\)</span> 换成 <span class="math inline">\(n \wedge N\)</span> 再用 MCT，DCT 和 Fatou's lemma
夹出可积，然后哪怕只能说明序列 a.s. 收敛也可以用 MCT 和 DCT
解决问题了，常看常新，但我果然毫无分析水平.jpg（</p>
<p>虽然周四上午就退烧了，但到现在食欲都不行，前两天都没怎么吃东西，白人饭为主，带油的都没怎么吃，<del>奶茶倒是喝了两杯</del>。其实周三晚饭就觉得没啥胃口，过了一会就开始不舒服，也或许生病本身就是肠胃不舒服导致的所以一直恢复不过来。今天起来处理了一下冰箱里的吃的，周二买的小番茄在室外放了几个钟头才取回来，还好当时就记得把冻裂的挑出来丢掉了，没发生裂了之后又放了好几天的惨案（。之前的一瓶鲜牛奶本来计划是这两天喝掉，现在过期了，急。橘子一向是放在之前留下的一个纸箱里，不知道为什么压坏了一个，丢掉之后把剩下的转移了。洗了杯子和之前没来得及洗的衣服，多少有点仪式感，感觉是我家那边有生病痊愈之后要清洗用过的物品的习惯，一般把这叫做去病气。</p>
<p>Arcaea 收录 felys final remix
了，紧急摸了一下，结果梯子都爬不动，随便开一把都能掉
980。难道是前两天小摸的几把 Lanota 导致的吗（</p>
<p>感觉以前认识的音游人现在基本都以打 maimai
为主了，为什么呢（。骑车去五道口就挺远的，早起排队等机子，线下运动，可能需要和陌生人交流，感觉去不了一点（（</p>
<h1 id="月24日">12月24日</h1>
<p>明天概率论怎么办，急，复习是早就复习完了晚上还看了会高统，但怎么感觉这课复习了也和考试没太大关系尤其是最后一章的习题也偏简单（</p>
<p>早点睡了，考完这门后面 12 天内还有四门呢，乐（</p>
<h1 id="月25日">12月25日</h1>
<p>概率论拿到卷子：第一题名词解释怎么只有 8
分了，第二题是个挺长的定理证明默写感觉还记得但最后中间还是糊了一点，好好好背刺我是吧，第三题就看楞了，为什么是一个群上的随机游走（虽然事后证明用到的群性质仅有有限群元素都有周期，方法仅有生成群元素的表示，但看到还是眼前一黑并花了很长时间细细思考我还记得的群性质（<del>以及我为什么抽代有
A（？</del>。第四题比较常规一个定理甩上去就行，第五题常规但我好像用了不是很常规的方法（我觉得正常应该是
Markov property
放缩，但我写了一手归纳也没觉得有什么问题），但是正常的题占分太少了完全不够用！第六题为什么要手搓一些
Laplace's equation 套着 heat equation
的根（虽然事后也证明想到了就没啥），第七题又是一个课上从未讲过的树上随机游走，它甚至还有
5 分 bonus
但显然和我没什么关系，这次不同于期中的是当时还认真想了想，这次最后一题基本没来得及看，加时的
15 分钟用 Galton's process 把第一问胡写一通但愿猜对答案骗到分了（乐</p>
<p>总之考这个试需要最多的可能是心态平和不要惊慌，还有就是感觉得自学一下树上随机游走的一些方法可惜我是一点不会，我也不想会（。<del>为什么要学抽代这个问题现在不就解决了吗，不学抽代我哪知道那个题在说什么呢（乐</del></p>
<p><del>那要是有人没学过抽代怎么办</del></p>
<p><del>连我都学过抽代难道还有人没学过吗</del></p>
<p>其实期末分数应该和期中差不多甚至可能稍好点（在做梦，他就算一分不调也能有个
B 吧（草。Anyway
反正这课就到这了，卷子又不是我改没必要多想，乐也乐完了，输也输麻了，PTE
差不多学完了。高统怎么办，优化怎么办，急（</p>
<h1 id="月26日">12月26日</h1>
<p>通宵干脏活，先写了点迫真数学作业然后这周有两个实验报告要交，这建筑材料实验怎么还要算数值积分，大半夜在那
debug
给我梦回大一，我不想再过这样的日子了啊啊啊啊啊啊啊（？（那下学期为什么还在考虑选计算概率（</p>
<p>今天看到社友发的梗图才明白昨天的树上随机游走是圣诞特供（x，这下<a href="https://www.bilibili.com/video/BV1xV4y1w7Kq/">圣诞有数学相伴</a>了（</p>
<p><img src="https://s2.loli.net/2023/12/27/gKwh6xkLYXOcQPU.jpg" alt="tree.jpg"></p>
<p>晚上摸音游随便开了一首新曲，初见接近 970
感觉还行就保存了，二见休息段瞟到曲名 Sakura Fubuki 吓了一跳以为是
Fubini，然后鲨了（指二见 980（</p>
<h1 id="月27日">12月27日</h1>
<p>这两天摸音游感觉到有个小问题是右手休息段接蛇的时候经常无意识地切换到无名指或者中指，然后需要继续打
note 的话如果没换回来就容易爆 far。简而言之就是不仅有摸鱼癖还菜（</p>
<p>晚上为了拿订的酸奶跑了一趟东北门，考虑到学校东边的乌鸦密度直接从东三门出校在荷清路飚了一段，路上没什么车的时候骑车兜风真的爽，尤其这两天也不大冷（我是这么觉得的）。这学期远超其他学期的强度下（至少我以前从来没有频繁去
C
楼刷夜过，没上过这么多研究生课）还能保持不崩溃的一大理由可能是找到了好吃的水果和酸奶，比如我敲这段话的时候就在吃很好吃的冰激凌酸奶，每周体育课后都能吃一小盒龙眼，基本每天都有橘子吃，偶尔还有葡萄青提草莓小番茄之类在北京算得上有点金贵的水果
<del>反正至少很难洗</del>。</p>
<p>昨天才发现我这个月答疑坊志愿者升特级了，然后看了看表格悲伤地发现其实没几个人不是特级（，而我摸鱼摸了近一年才升上。涨工资好.jpg，至少买水果酸奶都不用眨眼然后也能被这个津贴轻松覆盖就是说。</p>
<p>左手刹车线之前看着就不太对劲，至少它和另一边不对称，今天彻底掉下来了。不过反正还有右手刹能用，等我有时间研究这玩意怎么修了再说吧，感觉不难（大概</p>
<h1 id="月28日">12月28日</h1>
<p>原来 wwc 老师也是物转统（，等一下我为什么要说也，难道我也算吗（（</p>
<p>今天干了啥？早上写了建筑材料实验报告一直写到下午，中间去找建筑材料助教听了一下另一个实验的具体事项，然后睡了会，然后本来想学优化，结果优化还没学作业已经写完了，我寻思着你这作业需要用到任何课上学过的知识吗，这不都是微积分和线性代数的简单应用（（。晚上回来写另一个迫真数学作业，现在在看优化
Bubeck Chapter 4，待会上床之后把板子带上床争取看一两份生物
ppt，急急急高统怎么办明天再说吧但明早还要早起（</p>
<p>这周上了好多课，大多数都是考试前的最后一节所以也休息不了了（，好累（x</p>
<p>早上感觉右手手腕疼，左手手指指根也有点疼，不知道是不是打音游打得，晚上回来爬梯子打了三遍骨折光三遍病女（都是
prs，见笑了），感觉不疼了（？</p>
<blockquote>
<p>建筑材料老师：色谱光谱质谱这些里面的谱指的都是扫描</p>
<p>我：啥？谱？</p>
</blockquote>
<p>#每日学数学学得（</p>
<h1 id="月29日">12月29日</h1>
<p>本来今天打算的是学高统，结果写了一天优化的
cheatsheet，又在闭区间套法学习（。本来很急优化这个云得不行的课要看多少东西，现在感恩
Bubeck
思路挺清楚的，感觉等下次发了最后一课的讲义之后再看一个晚上就能弄完了。<del>那我在
Boyd 那一块 Newton method 缺的营养谁给我补啊？</del></p>
<p>早晨起来顿悟，除了之前写的那个优化作业之后还要用 LaTeX
誊写一遍，实验报告都写完了，那我还带着电脑干啥。所以对我来说电脑是一块必须竖着放但是可以写
LaTeX <del>（偶尔也可以写
R）</del>的屏幕兼搜索引擎，平板是一块可以平放在桌上当书看还可以写写画画的屏幕，而我
95%
以上的工作还是用纸笔完成的<del>（虽然是相当原始的生活状态但感觉真的已经够了</del>，甚至现在想想确实不需要
Apple pencil，平替的笔就算写字不好用能拿来圈画一下重点或者标记一下 PPT
上看过的部分就足够了（</p>
<p>那挺好的，后面一直到考试周结束非必要不带电脑出门了（草（#每日学数学学得（什么这也学数学学得（</p>
<p>后面几天也没啥别的事了，<del>什么那美好的仗我已经打过了，当行的路已经行尽了，所信的道也已经守住了，从此以后有公义的冠冕为我存留</del>，希望高统没事。不知道两个半小时考五道题一道
10 分直接计入总评是什么水平，那哥们至少得做个四道
<del>然后根据四舍五入没满分就是零分（草</del>，希望真能没事。优化更不知道怎么考，至于生物其实
PPT 已经当睡前读物溜了一圈了但啥都记不住啊（</p>
<h1 id="月30日">12月30日</h1>
<p>很急。</p>
<h1 id="月31日">12月31日</h1>
<p>前天买的阳光玫瑰不好吃，皮很厚，不过这个季节还想吃到好吃的青提是否是我在做梦（</p>
<p>今天早上八点多就起来了，打开很久没听的 One Last Kiss
开始复习高统，假装这一年我的生活都如此规律、尽在掌握，后来一想其实这个装模作样的过程才是精准概括了我的生活（</p>
<p>发一张我本年度最喜欢的猫图，尽管这是前几天才看到的，最近只要有人和我说话我都会发一张过去。不过
2021 年我最喜欢的一张自拍还是 12.31
拍的<!--，它还成功钓到了欧老师（？-->，感觉非常正常（</p>
<p><img src="https://s2.loli.net/2023/12/31/GT5znU82gSXuM7b.jpg" alt="cats.jpg"></p>
<blockquote>
<p>在我国气象观测中，每天 20
点是划分新旧两天气象数据的时间节点，所以对广大气象爱好者来说，气象意义上的
2024 年此刻已经到来。</p>
</blockquote>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇十七·24年1月</title>
    <url>/2024/01/01/Diary-2024-01/</url>
    <content><![CDATA[<p>日月不居，一误难再</p>
<span id="more"></span>
<p>摘要来自《游焦山小记》，是高中时候读的，很喜欢，是那种读完不自觉会勾起嘴角的小记。但居然一直记到现在。</p>
<blockquote>
<p>予自丁酉来游，未遑穷讨。人事参商，忽忽数年，始一续至。又以羁绁俗缘，卒卒便去，如传舍然，不知此行定复何急，良可浩叹，自今以往，日月不居，一误难再，赋归之后，纵心独往，尚于兹山不能无情。当择春秋佳日，买小艇，被宿松寥阁上十日夕，以偿夙负，滔滔江水，实闻此言。</p>
</blockquote>
<h1 id="月1日">1月1日</h1>
<p>高统看完了，现在只要把 cheatsheet
抄完就好了（迫真，乐观一点的话明天还有机会能看看优化，我不好说，有机不会（</p>
<p>奇怪的跨年方式增加了.jpg</p>
<h1 id="月3日">1月3日</h1>
<p>大学以来强度最大的一天结束了（，考了三门，期末一下子过半了（</p>
<p>早上生导评价为还好没复习毕竟复习也没用，不过早晨七点多去考场在马路上骑车骑得很爽，自从换车之后骑行体验大幅增长，有的时候还在想华子有没有什么相关的社团之类的可以玩玩。这考试一半感觉小有把握，三分之一感觉能选一个出来但不大确定，剩下六分之一的判断题看不懂在说什么但你既然这么说了只要听起来不太离谱我就当你是对的好了.jpg</p>
<p>然后一刻也没有为寄掉的生导而哀悼，立即赶到考场的是高统。拿到卷子半小时写了两道感觉稳了，再仔细一看怎么考
U-estimable，非参数的东西不是特别熟有点小慌，我知道他那个 hint
大概是想让我说明 U-estimable with order <span class="math inline">\(m\)</span> 会引出一个至多 <span class="math inline">\(m\)</span>
阶的多项式，然后证明开个方就寄了，线性的部分只要想到对 population
做一个线性变换然后积分就好，脑子还算清楚想到了是类似于证明 <span class="math inline">\(\sigma^2\)</span> 的 U-statistic
至少二阶那个定理的做法。但平方那里感觉写得不大行，似乎当时就已经很紧张了。还有个算
amse 的题想了半天 sample variance 的渐进分布是什么（，还要讨论 <span class="math inline">\(\max \{0 , \bar X^2 - S^2 /n \}\)</span>
的渐进分布，寄，没算出来，大致写了下我猜测的结论是 <span class="math inline">\(\mu \neq 0\)</span> 时和 <span class="math inline">\(\bar X^2\)</span> 以及 <span class="math inline">\(\bar X^2 - S^2/n\)</span> 的 amse 一样，如果 <span class="math inline">\(\mu =0\)</span> 的话这个怪东西会 asymptotically
more efficient，听起来蛮合理的因为这个题的目的是在 estimate <span class="math inline">\(\mu^2\)</span>，你要是让统计量都小于 <span class="math inline">\(0\)</span>
了那还估个啥。这个时候都快十二点了，然后突然想出来前面那个 optimal
decision rule 的题怎么构造了，拿出最大算力算完手抖着交了。</p>
<p>晚上就出分了，好快（，点进去发现好高还以为给我登错分了，看来我写的猜测的结论也给了点分，以及均分也没我想象的那么高，好好好特别好。前两天说感觉这课前十五周舒服得像在泡脚，课好作业好玩学到许多，第十六周写
cheatsheet 就感觉像在喝整整 15
周的洗脚水，今天考试发现之前喝的也没用（指 cheatsheet
几乎没用到，考前说要考定理证明哥们抄了满满两面结果完全没考，不讲武德）又被灌了一桶，但阅卷还是放过我了，真好。</p>
<p>晚上运筹一个手解 <span class="math inline">\(3 \times 4\)</span>
大小的线性规划没算完，评价为恶心人用的。不过这课期末占比 20% 所以考 50
分就够用了。</p>
<p>优化怎么办呢，感觉学的 Newton's method
已经是很久以前的事情了（，是不是应该感激他后半学期讲算法没讲梯度下降（</p>
<h1 id="月4日">1月4日</h1>
<blockquote>
<p>是不是应该感激他后半学期讲算法没讲梯度下降（</p>
</blockquote>
<p>我昨天在说什么（疑惑，其实我想说的是他没像数值分析那样讲梯度下降，毕竟这课的
iteration <span class="math inline">\(x_{t+1} = x_t - \eta
\Delta_t\)</span> 里面的 <span class="math inline">\(\eta\)</span>
全都不用求直接说是 backtracking
得到的就糊过去了，数值分析那个讲法考前一天才看的话真的会死人的（</p>
<p>今天凌晨试图在 C 楼刷夜，但我忽略了昨天早上是六点四十起的，把 scribe
notes 过了一遍直接倒在 C
楼隔间的懒人沙发上睡着了，睡得很暖和醒来之后又觉得好冷直接绝不调，看了会笔记然后回寝室一觉到中午。但是评价为睡沙发真挺舒服的，我还查了一下同款只要两百多，想买一个放家里（不</p>
<p>一天速通优化，晚上离开教室的时候看到还有课友在抄
cheatsheet，安心了一点（不</p>
<blockquote>
<p>我的 cheatsheet 除了 cheat 了我自己之外什么用都没有</p>
</blockquote>
<p>更棘手的是明天考完优化还要紧急重做组员今晚交上来的建筑材料实验的
pre，有一说一不想做可以早点告诉我让我有个心理准备自己解决，没必要到最后一刻交出来一个显然不是用手更别说带没带脑子做的东西然后确信有人会救场。</p>
<h1 id="月5日">1月5日</h1>
<p>这个 b
优化（，我被优化掉了（（。反正我承认这课我学得不咋地，但考拉了也没什么值得自裁的，就是不会，期中后一节不落地去上课也没用，什么算法设计，不会.jpg。</p>
<p>蹲个调分，不调也随便你（，以后还是只在数学系/求真/统计中心的范围内选课了（</p>
<p>反正我真有点 PTSD
不想整优化了，更不太想碰完全不沾统计的算法（。还是统计好，高统考完两天了我还时不时会去想没做出来的那个题，今天竟突然明白了，而这个
b 优化考完不到 12 小时后瞥到昨天的日记，backtracking
是怎么做的来着？</p>
<p>下学期真的还要选组合优化吗（，求真课会不会好一点呢，要不干脆还是去上计算概率吧（</p>
<p>中午基本没吃饭，感觉早饭午饭吃的面包加起来还不如喝的酸奶多（，考完试就去四教开始赶下午建材实验
pre 的 PPT，成功在新土木馆讲了一些凸优化和 loss function
凑时长（，不管最后结果怎么样至少我觉得节目效果不错（（。晚上大吃一斤香锅（？）结果吃太撑了，在猫超散步不知怎的看到买一送一就买了两瓶
costa
的燕麦摩卡，付了款才想起来我超它买一送一肯定是因为不好喝啊。到教室就开始那个睡，一直睡到教室关门，还有一个实验报告没写，优化作业还没有打成
LaTeX
结果还是在废纸堆里找到了上周写的纸质版，明天要赶一个五千字的结课论文，建筑材料一点没学下周二就考了，我急死（</p>
<h1 id="月6日">1月6日</h1>
<p>今天莫名其妙开始咳嗽了，晚上回来找上次咳嗽时候买的药找了好久，两个月里咳嗽两次发烧一次，20
岁老猫.jpg。</p>
<p>不过写了一天工程与法律（一个到了期末我才想起来它的存在的限选课）的大作业，搁那逆转裁判啊不是瞎判案子，好快乐（，给我整得寒假都有点想玩逆转裁判了（。我发现写这个东西和科研差不多，遇到一些不知道怎么判的情况加一个条件就会变得好判，那就编一个上去，看起来别太离谱就行（</p>
<p>下面是一些整活欣赏（x</p>
<p><img src="https://s2.loli.net/2024/01/07/6oNxX5GLgtdjr7b.png" alt="判决书-1.png"></p>
<p>你们都是谁.jpg</p>
<p><del>迟先生</del> 驰先生，混入！</p>
<p><img src="https://s2.loli.net/2024/01/07/4zVhZnBFRIKLiY2.png" alt="判决书-2.png"></p>
<p>为了说明被告已知和原告签的是挂靠合同直接调一个吃饭时候的监控真的没问题吗（（</p>
<p>这些个被告怎么对一些对自己不利的证据全都无异议，高 风 亮 节（</p>
<p><img src="https://s2.loli.net/2024/01/07/yTlaAmOp4UPkbJi.png" alt="判决书-3.png"></p>
<p>任 人 唯 亲（</p>
<h1 id="月7日">1月7日</h1>
<p>又发烧了，新年第一烧（啊？，上次是十四周周三，这次是十六周周日，二十天内烧了两次，这个
b 学校（（</p>
<p>但我不好说这次是什么情况，我觉得可能性最大的是室友为了缓考量统把自己冻感冒了，然后我这几天强度巨大又被她传染了，如果是的话真的难绷（</p>
<p>还是咳嗽，但是没有昨天严重，喉咙不疼，又有了鼻塞之类的感冒常见症状。白天取了几个体温的样本感觉方差很小，upper
bound 是 37.5，lower bound 应该就是 37
度，甚至有的时候按照标准来说不是发烧，但我体温一直有点偏低，而且感觉不舒服，就当做发烧好了。晚上感觉越来越不舒服，现在是到
37.8 了，乐。</p>
<p>看了一点建筑材料的 PPT，它周二就要考了，真的很急。</p>
<h1 id="月8日">1月8日</h1>
<p>昨晚开始往高了烧了，吃了退烧药之后感觉整个人烫烫烫完全睡不着，连带着喉咙痒咳嗽打喷嚏甚至右边智齿都在疼，很急，在床上把手机和
pad 全玩没电了到五点钟才睡着，甚至还看了点 PPT（</p>
<p>明天考建筑材料，很神奇的是我勉强算是复习完了。我的评价是随缘吧，然而这学期怎么有这么多考成啥样都随缘的课，感觉绩点危（。虽说出国壬
3.7+ 管够 3.8 挺好，<del>但 3.8
在某个书院好像有点活不下去甚至都该紫菜了（。（x</del></p>
<h1 id="月9日">1月9日</h1>
<p>昨晚一直挺好的，直到我去洗了个澡回来就开始不舒服了，一量
37.5，哈哈.jpg。今天白天也降下去过，到晚上又 38
度了，这绝望的轮回。为什么还在烧，我觉得这下大概率肺炎或者最近流行的什么甲流乙流了，寄。</p>
<p>不管怎么样作为一个正常人断断续续烧了三天总是不太正常，而且都是白天还算舒服从傍晚开始烧，挺肺炎的，明天该去医院了。</p>
<p>哦，今天还考建筑材料了啊，抄 PPT
水课，糊完跑了。附带我在后排全程咳嗽，咳到老师来问我要不要帮我打杯水，咳得我感觉脑浆都晃匀了反正现在头是震得挺疼的，对不起所有人.jpg</p>
<h1 id="月10日">1月10日</h1>
<p>昨晚又来了一轮
38.5，人都快烧傻了，今天爬起来去了趟校医院，颇有一种被塞进猫包带去看病的错觉，事乙流（</p>
<p>出门的时候都做好今晚彻夜在北医三院吊盐水的准备了，换洗的衣服都收拾了一个袋子只是没带上，还查了查车道沟附近有没有什么好点的酒店可以去休息的，结果在校医院开了盒奥司他韦被赶出来了，哈哈。事后想想可能再不去医院病都要好了（开玩笑的，不吃奥司他韦估计还是寄</p>
<p>所以前两天为什么不自己买个试纸测一测呢（，被自己蠢到了。光搁那发烧吃退烧药退烧吃一些没啥用的药发烧吃退烧药了，这绝望的轮回（</p>
<p>凌晨烫烫烫睡不着的时候看了点《繁花》，一个是因为我之前就特别喜欢辛芷蕾（虽然如懿传真的很难看吧但她真的很美），再一看似乎江浙一带练一练就能讲上海话的演员都到齐了
<del>甚至连 papi 酱都来了</del>（，半夜点开测试了一下来沪 14
年外地人的沪语水平，什么嘛不看字幕也是能听懂的嘛（x</p>
<p><del>不用看评论就知道肯定有吐槽演员洋泾浜的，我是听不太出来只觉得有一些语调比较怪，反正我讲起来更洋泾浜（</del></p>
<p>只不过这玩意怎么能拍出来 30 集的，<del>二次元当久了有点看不动 13
话以上的作品（</del></p>
<h1 id="月11日">1月11日</h1>
<!--敲下来这个日期觉得蛮熟悉的，结合今天在空间云看 eex 东京旅游，想起来是他的生日，眼馋了，我也想这么潇洒但我生日从来都是期中周，现在期末周人是蛮闲的但是只能在这里咳咳咳和看剧，繁花都看了 20 多集了，急死了（（-->
<p>昨晚又来了一轮
38.5，哈哈，已经懒得写了，反正今晚的也已经开始了，就是没那么高（</p>
<p>下学期一定摸一点不能这样上强度了我超，辛苦搞了一学期到期末歇了算什么事儿，崩溃（（</p>
<p>以前觉得能在床上躺着真是至福，现在一想到带着手机电脑 pad
温度计耳机水杯冷毛巾和药爬到床上，在漆黑一片里面烫烫烫然后等到退烧了才能睡着中间室友要是要睡了还得憋一阵子不能咳嗽，就觉得睡觉也好难受，要
ptsd 了（（</p>
<p>今天临时发了两封要课程推的邮件，虽然都还没回但突然得知要推荐信之后我开始思考该问谁要的心理活动就差点没把我尴尬死（。问就是我压根都不敢去找
lq/ypk，只能在统计中心找两个上过课成绩还好但除此之外完全不认得的老师要课推这样子（（，要是去数学系要推的话我恐怕只能找
lzx 了，其他重量级一点的老师的真数学课我都上得一塌糊涂，崩溃（（</p>
<h1 id="月12日">1月12日</h1>
<p>病中在床上摸了摸光叔下学期的讲义，不得不说虽然我实分析当初学得一般，但还是在概率里一边做一边学常读常新很久了，感觉还行。组合优化不玩了的话干脆开学手选一个这玩意好了，反正说是还能少量扩容。</p>
<p>为啥要个课推都这么难，闹麻了。如果 wty
还没走的话其实还可以找她问一下的，只不过她那个生统离我现在申的这玩意更是差得远了。目前手里只有一封，可以的话最好能找到
zzy
要一封，毕竟这个项目看起来就没有理论，我能理解的部分就全是在搞数据，但想一想总比打灰有意思。zzy
下周要来录课感觉可以当面问一下，正好录的是之前上的那个线性回归，这两天就算是跑一趟伟清楼我也跑不动，今天在楼下一摸自行车座都积灰了。</p>
<p>今天正好看到统计中心发了招聘通知，招一个 AP 一个讲师，毕竟 wjd
也要走了，要不要找她要个推荐信留作纪念呢，笑死。不知道她还会不会继续在高校，据我所知她是做咨询的。我看她下学期开了
11 学分的课，不知道是不是以前也这样但有点哈人的。</p>
<p>还是看看近处的 ODE 吧（</p>
<h1 id="月13日">1月13日</h1>
<p>病了一周把《繁花》看完了，还是不错的，就当回家之前做了 20
个小时沪语听力，那托福怎么办（。</p>
<p>突然发现这学期的笔记到最后都鸽掉了（心虚，高统后来转纸质了体验挺好，优化感觉不值得我每周花时间打字（。</p>
<p>zzy
答应给推荐信了，虽然她热情得让我有点怀疑到底谁是甲方（，<del>姐姐真好谢谢姐姐</del>。挺好的，现在就还有个
PS 没写了，写不出来 <del>但反正限定是固定字体大小的一页 A4
纸那似乎也不多</del>，感觉只能编一编统计和 IE
之间的关系毕竟我校的统计中心还就那个在工工。考完 ODE 再说吧（。</p>
<p>还有两周回家，考完试除了去找
ypk，摸实分析讲义和练托福之外还可以干点啥呢（还想干点啥呢（</p>
<h1 id="月14日">1月14日</h1>
<p>这一天天的就没有个身体舒服的时候.jpg，这下 ODE 有点小急了（</p>
<h1 id="月15日">1月15日</h1>
<p>这一天天的就没有个身体舒服的时候（复读</p>
<h1 id="月16日">1月16日</h1>
<p>考完了，这 ODE 不过如此，虽然谱性质我是一点不会放了个 15
分的题，正经学分析的时候再来吧（</p>
<p>推荐信还没交齐，急急急急急。PS
写不出来，这个倒是没那么急毕竟掌握在自己手里，这就打开 GPT
争取睡前写完.jpg</p>
<h1 id="月17日">1月17日</h1>
<p>开始学托福，但是上新东方 TPO
做了两篇阅读就觉得有点无聊了（，<del>感觉不如高中的时候考的校卷难（（</del>，啊不是，感觉随便看看了解下题型和流程就行了没必要做多少，还是练口语和写作吧。然而口语肯定是回家对着墙练或者等室友走了之后在寝室练，写作现在背了考前不会忘吗，那做听力吧，啊不是那还准备个啥闲着没事听听算了（（</p>
<p>所以既然也不难为什么到现在都没考托福呢，需要语言成绩的时候啥也没有就挺崩溃的。</p>
<p>最急的是到现在推荐信还没齐，马上 ddl 了，zzy
答应给推的时候特别热情但为什么咕了（，老师都好忙啊（。邮件催了一下但还未读，感觉要么今天要去加她微信问一下要么得早点去蹲伟清楼了，哪个都是社恐地狱，<del>能不能只交一封推荐信呢（</del>。要不再约一下
ypk 去一趟伟清楼全部解决好了（不是</p>
<!--今天出门逛街的时候看到个挺好看的手链，本来想买了带去雍和宫开个光再送给我姐，友人说应该是不能自带的，只能去雍和宫现买，我寻思着静安寺也没这么黑不愧是北京（，不过她看起来更懂一点所以就算了。回来问了下室友说可以，某宝找了找没看到更好看的，急了（x-->
<!--当时想到这里感觉有点难过，我姐考公如果能应届上岸当然是最好的，但是然后呢，她永远就不会离开南昌了吧，日子就这样一眼望到头吗。国考哪怕录不上也还有省考，市局去不了可以去分局，一定能找到工作，但并不会离开江西。她说她妈妈已经在给她找相亲对象了，她们那儿工作稳定之后一般来说下一步就是相亲了，没有太多自己的时间的。-->
<!--我想起她暑假来北京的时候还说想考研去江浙读书，但又觉得去一个普通的学校继续读文科出来迟早还是回家考公，都一样的。我说可是姐姐我觉得还是不一样的，她说你选择就是多很多，当然是不一样的，但对她来说已经没什么不一样的了，如果想要不一样的话，当初填志愿就应该去浙传吧。-->
<p>说起来这个霸王茶姬和茶话弄有啥本质区别吗，之前一直听人说好喝所以特别火，去万柳的店看起来也不怎么需要排队。所以说茶颜悦色难道会比霸王茶姬和茶话弄好喝很多吗（质疑，感觉不能抱太高期待（？</p>
<h1 id="月18日">1月18日</h1>
<p>UTokyo ESEP 2024 申请结束了，催推荐信一直催到 ddl
前半个小时，不仅急坏了而且催的时候实在忍不住脚趾抠地，但还好交上了，感觉申个没什么用的暑研身心都受到了不小的摧残
<del>所以说真的非润不可吗</del>（<!--那当然了（-->。<del>越发提醒我要开始贴
ypk
了不然找老师要个课推真的好困难（这和课推不课推有关系吗（</del>。<!--zzy 这次狠狠咕我这么多天，感觉之后再问她要推也没什么不行的，某种程度上来说我觉得越是这次被咕了下次越得问她要推，虽然仅限一些校级合作项目会找她要课推吧。-->不过今天去了一趟才知道
ypk
已经不在伟清楼了，统计中心只有他搬去了焊接馆，难怪有一次讨论班是在那边开的，我不理解但总不会是他也要润了吧那我怎么办（，<del>按理说
wty 走了之后伟清楼不应该更加宽敞了才对吗（？</del></p>
<p>上个秋季学期我就在申 UTokyo
的交换，院系二选一也没把名额给我，拿到名额的哥们也没真的去，麻。这学期又在申
UTokyo，这次都不好说整个华子能不能有名额，感觉就图一乐吧，还得继续找保底。<del>但我暑假真的好想去日本玩啊，我还在
PS 里写 I'm a big fan of Japanese anime 什么的现在想想好丢人</del></p>
<p>下午一只手拿电脑一只手推车走回寝室的路上突然推不动了，一看路上有一根类似丝带
<del>实际上更像衣服拉链侧边的布条（？）</del>的东西一头缠在了牙盘里，这是马路上该有的东西吗就算有它就应该缠在车上吗我真是摸不着头脑.jpg。进车棚把踏板轮胎牙盘裤子清理干净之后想想感觉得回去把它捡起来丢掉，在路上推着车走缠进来就算了也就是停在马路中央扯出来会尴尬一点，如果是骑车突然被缠感觉挺危险的。刚走回事故现场就发现了另一个正在和它左右互搏的路人，绷不住了（（</p>
<p><del>好困好累好饿但是又不饿清华大学你把我害死了（</del></p>
<h1 id="月19日">1月19日</h1>
<p>给导师发邮件，但已读不回了，我又急了，这是咕了一学期的代价吗（</p>
<p>很摸地听了一些托福听力，但是只听了 lecture 没听
conversation，<del>这有什么练的必要吗（二度）</del>。然而做的最烂的是一篇讲
cat domestication 的，所以为什么要驯化猫猫，猫猫又没用（（</p>
<h1 id="月20日">1月20日</h1>
<!--查了下成绩，其实也没出几门课，概率论 2 不出意料地 B+ 了，我现在有不是 4.0 的数学课了（大悲。建筑材料这课性价比真的高，反正我上课不是在写实验报告就是在困告，发着烧复习了两天又发着烧去考试还给了哥们 A-。高统反正也没有 A+，早就预料到的事情，然而我还借此要了封课推（-->
<p>发现五道口开了家万圣书园，虽然二楼还没开放，急急急。上次去还是大概这学期前几周的时候去华子南门那家店，至福。逛了一圈，看到几本想看但是没看的书，还有几本感觉有点意思的，但好贵，没买，回来看电子版（（</p>
<p>回来路上第一次发现西郊宾馆藏在王庄路旁边的一条小巷子里，里面自行车似乎不让进，走着进去探索了一下。<del>好破</del></p>
<p>所以说被取代的是哪家店呢，逛了一圈感觉没看到 <del>也没听到</del>
之前那个机厅，不会是寄了吧，滴——蜡——熊——</p>
<p>今天闲着没事在翻华清大学课程攻略共享计划，开了点盒（。看了眼计量经济学的卷子怎么有且仅有线性回归，还一股
zzy
那个课的味儿，<del>所以说数学万一学不下去的话可以转行的对吧（（</del></p>
<p>Wake up with no email everyday（</p>
<h1 id="月21日">1月21日</h1>
<p>有什么能比熬了个大夜读完一本书然后发现这书好烂更令人难过吗，躺在床上气得睡不着（。好不容易睡着了结果做了个梦，梦到一天要在北京上海之间来回，到了下午一点想买回上海的票结果发现全卖完了连动车票都没剩，想了想京沪高铁票岂有卖完的时候，肯定是假的，然后就醒了（</p>
<p>起床打扫卫生洗衣服，到晚饭把 <del>窖藏两个月</del>
买来放了俩月没喝的奶啤拿出来，本来想去食堂一边吃饭一边喝，后来还是社恐了吃完饭回来在寝室阴暗地喝的。意外地很不错，平时酒仅限于浅尝
<del>我算什么沙东人</del>，但这个除了闻起来有点酒味之外喝着更像益生菌饮料，还想着下学期一定多买点，<del>带去上课喝（不是</del>，结果过了一会劲上来了上床躺了两三个钟头，草（（</p>
<p>Wake up with no email
everyday（<!--，我现在都在想 ypk 要是不打算理我了那我还可以去找 wwc 毕竟已经是两学期长期粉丝了（（--></p>
<h1 id="月22日">1月22日</h1>
<p>每年一度的看《恋爱的犀牛》，去年是买了票去蜂巢剧场看蝴蝶组的演出，前年似乎是看了郝蕾段奕宏版，这次不知道为啥点了<a href="https://www.bilibili.com/video/BV1ct411k7Vj/">高中话剧社演出的版本</a>，<del>这男主还挺帅的我印象里好像当时知道他叫什么名字但现在忘记了</del>
现在再看还是觉得真的演得不错。当然这也是我第一次看这部话剧的版本，不过第一次也是在
b 站看的，社恐没去现场。这剧本太伟大了好想背下来啊（。</p>
<p>但我读剧本好像是在看话剧之前，读了才想去看的。后来看到过带孟京辉廖一梅的采访的剧本版本，才知道“黄昏是我一天当中视力最差的时候
blahblah”那句话是陈建斌说的，草，<del>四大爷还是有点浪漫在身上的</del>（</p>
<p>Wake up with no email everyday（，但我今天才知道 wwc
组里目前没有本科生，有点惊讶。所以说万一真没人要我了其实去他那里也可以吧
<del>看起来还有机会跑路 econ 的样子（然而我最近为什么老在想跑路 econ
呢，感觉也没有完全学不下去才对（</del>，<del>而且我是他两学期课程老粉了而且他认识我而且我还已经拿到过他的推荐信了</del>（（</p>
<h1 id="月23日">1月23日</h1>
<p>出去玩了一天，但 wake up with an email
today（。本来想今晚还收不到的话就去给 wwc
发邮件了，这下（暂时）是错过了，<del>也不好说之后会不会还是要跑过去</del>（（x</p>
<p>后面几天<del>（不出意外的话）</del>去天津玩，出发之前正好跟 ypk
约了个午饭（，<del>（不出意外的话应该算是）</del>稍微有点极限，急急急。电脑就不带了，日记先咕个几天，26
号再说。<del>给因为乙流导致本来就很短的一月日记雪上加霜</del></p>
<p>上个月被何老板拉着报了个美赛，今天发现 2.1
就要开始了，我还不知道我是去干啥的。看知识点只感觉理论嘎嘎清楚，Markov
chain 哥们能给你把 Durrett PTE
那一章空口讲一遍，但是咋用来解决问题呢，乐了。</p>
<h1 id="月26日">1月26日</h1>
<p>回北京了，收拾东西明天回家，累累累，急急急，明天高铁上慢慢补上前几天的（</p>
<p>UTokyo ESEP
项目的负责人发邮件跟我说不接受三月补交托福成绩单，寄。上次在 thos
上填申请的时候未央教务就问我为什么能参加考试周期间开始的项目，这次
UTokyo
又说清华本科生按理是不能按时到的让我解释一下，反正我都说考试周没啥安排能赶得上，先把饼画了再说，危。
但是用一下归纳法的话可以知道实复分析都是考试周一开始就考掉了，统计中心的课也都不进考试周，应该没啥问题吧。<del>至少感觉比起能不能申请得到来说不算很大的问题（</del></p>
<h1 id="月24日补">1月24日（补</h1>
<p>主要是，去找导师的过程有点震撼我了，所以写一个（</p>
<p>早晨醒来看到一个：</p>
<blockquote>
<p>“你会干什么啊？” “做证明。”</p>
<p>“除了证明呢？” “算 cohomology。”</p>
<p>“应用数学呢？统计？” “不会。那种东西有用么？”</p>
<p>“那数学的以外你还会什么？编程？” “LaTeX。”</p>
<p>“额。那你有没有什么爱好？” “看书呀。”</p>
<p>“一般看什么书？” “Springer GTM。”</p>
</blockquote>
<p>统计壬被骂了，但统计壬也别的什么都不会啊而且也不会算
cohomology，又作为假数学壬被骂了一遍（（</p>
<p>在清芬三楼蹭了 ypk
一顿饭，然后去参观（？）了他位于焊接馆的新办公室，<del>没有电梯，楼里还一股味儿，听说焊接馆还发生过实验事故，具体来说就是炸了</del>，才知道
lq
果然也搬过来了就在他隔壁，但统计中心官网上没更新，<del>哥俩好</del>。不知道伟清楼
209 现在改成啥样了，但有独立的办公室是好事（</p>
<blockquote>
<p>ypk：具体来说你对什么样的问题比较感兴趣呢</p>
<p>我：（疑惑）我不太会写代码，然后希望做更理论一点啊更准确来说是比较
rigorous 的研究（比划）就反正我学统辅学得很痛苦最后 quit
了，在数学系学分析和代数那些基础课倒觉得不错，应数各个方向都可以考虑吧</p>
<p>ypk：啊...再具体一点呢</p>
<p>我：（疑惑）（我寻思着我也不知道什么问题好做啊）（试图转移话题）老师您最近有什么关注的问题吗</p>
<p>ypk：我前两天和华为那帮人见了个面，讨论了一些 GPU
加速的问题，就比如怎么让矩阵乘法算的更快一点，要不你看看这个</p>
<p>ypk：这是我前两天看到 Zipei Nie
发的随机优化的一个方法反正挺复杂的也不用写代码全是推公式，你看这些玩意这么复杂应该比较满足你对理论的要求了（。工程一点的做法的话
Deepmind 用 AI
做了一个很不一样的，你回去顺着这两篇往前找找整个问题发展的脉络，开个
overleaf project
写一写然后把链接给我吧，这是不是能起到一个监督的作用（</p>
<p>ypk：你回去也可以读点 TCS
顶会别的文章看看还有没有感兴趣的话题，啊对就算是 TCS
也可以不写代码的（</p>
</blockquote>
<p>我吓晕了怎么世界的尽头又是 CS（，<del>现在投靠 wwc
还来得及吗我反而觉得他做的时间序列和 M-estimation
之类的东西变得靠谱起来了</del>。先看一点试试吧，希望人没事（</p>
<p>看的时候就觉得 Zipei Nie
这个名字有点熟悉，反正是上海某年的一个数学国家队，但不知道是华二的还是上中的。回去一查果然是上中的，确实，<del>你华二数学什么水平还来碰瓷</del></p>
<p>从焊接馆出来头嗡嗡的只知道这事儿听起来和统计离得有点远（，但反正还是数学就问题不大（迫真，之后要是觉得不行再说吧，wwc
那里又没人。回寝室寄了个快递洗了点衣服，然后很极限地去天津了。</p>
<h1 id="月27日">1月27日</h1>
<p>回家了，好累啊（</p>
<p>本来想在路上补一补前两天的日记，看了个电影就睡了，咕咕。今天把去年的柯南剧场版看了，虽然很烂就给了个
6
分但实在是乐得不行，很久没有看番笑得这么开心了（（。顺便把柯南系列的作品都补标了，发现除了若干烂得这么多年来都一直有印象的剧场版之外别的都不记得了，也没怎么打分（</p>
<h1 id="月28日">1月28日</h1>
<p>白天在陪家人逛街，从 1.23 到现在每天都在外面
<del>还一天一杯奶茶</del>，真有点摸了。晚上回来看美赛 O
奖论文，没啥头猪啊不是没啥头绪，方法也不是很会，最后变成了在玩一些没啥用的小工具，但愿最后论文能看起来漂亮一点。</p>
<h1 id="月29日">1月29日</h1>
<p>凌晨的时候在看美赛的论文，感觉 A
或许还是能做的但队友不一定爱看，去年的 A
似乎都不怎么需要数据直接编然后跑模拟就行了。BCD 我个人都不怎么想考虑，E
和 F
就很有一种老婆饼里没有老婆所以说数学建模和数学有什么关系的美感。看着看着给我都整婆罗门了，这简易的初等数学模型有什么学的必要吗，我知道它真的有用至少在这个比赛里比数分有用（，但我不大想仔细看。这比赛真值得我花四天时间打吗（</p>
<p>看不下去了，发癫的时候上豆瓣标记已读了 <a href="https://book.douban.com/subject/5326315/">PTE</a>。</p>
<p>一般来说到了寒假就需要重温一下明日方舟，简单看了眼最近的活动，怎么在种菜（。都不想下载了，机制这么复杂的游戏如同推导之前
assumption 堆了三页纸的定理，总之是丑的（胡言乱语</p>
<p>美赛也暂且不想看了，后天急了再说，开始读一点自己的论文。目前的进展是新建了一个
overleaf project，但还没勇气把链接发出去（</p>
<p>注册一亩三分地的时候发现我的 id 被用过了，没绷住（（</p>
<p>开学前大概要把托福口语和写作准备好，稍微读点论文，能排得上号的话在九院把智齿拔掉，投几所学校的暑研项目，还得打个美赛（。之前还想着感觉能学点别的，比如
PTE
没看的几节，先学点复分析啥的，现在看来似乎没什么时间，把前面这些事做好就不错了（</p>
<h1 id="月30日">1月30日</h1>
<!--还在读自己的论文，首先是仍然在基础的问题上就那个整不明白算法复杂度（，更别提优化的方法了。中间还去看了半天 the master theorem for divide-and-conquer recurrences，一边觉得这玩意还需要用个定理来描述吗一边又对着 cases 大受震撼，越来越绷不住了，我到底在干什么（-->
<!--我也不知道该不该跑路，首先我不知道能不能做出哪怕一点点东西来，其次这看起来已经是个很成体系的问题了要是弄出什么来恐怕不是伪了就是搞了个大新闻（，可能的思路大概是对着一些特殊矩阵形式做优化。诚实一点讲其实我没觉得这个问题有多吸引我，再看一阵子不行就开学约 wwc 吧（-->
<p>不知道为什么今天开始看时间序列了（<del>绝对不是想跑路
wwc</del>，下学期 mld 休假没开课所以直接发了
slides，<del>看了看感觉这不就是随机过程吗这我熟</del>，问题不大。翻着翻着我超怎么这么猛，他甚至还讲
ergodic theorems，<del>好喜欢啊不是</del> 有点逆天。回头看了眼 V1ncent19
的课程测评，<del>我的评价是在统辅大讲理论的都是好课，比那个线性回归不知道高到哪里去了</del>，看起来值得好评（x</p>
<p><del>然后又一想，wwc 那里没人是不是因为他去年休假了来着。</del></p>
<p>说起来我多元统计至今未修（去年春季退课了），虽说是统辅必修课但感觉也问题不大的样子。<del>我又不需要统辅学位</del></p>
<h1 id="月31日">1月31日</h1>
<p>累累累（</p>
<!--每次回家关于婚恋问题的架是一定会吵，都不用虽迟但到。起因是今天安装家具的时候弄伤了手，回家和宜家沟通调换家具的时候又涉及到一些自付运费、是不是需要自己搬下楼的问题。我妈一如既往地开始感叹如果家里有个男人想必这些事情都会好做一些，再次提醒我以后还是结婚好。-->
<!--我失落的点并不在于她至今没有完全接受我以后还是想一个人生活的想法，只是有点感叹，这么多年来我学着做了那么多事情，只为了向她证明“如果家里有男人就会很轻松解决的问题”并不存在，至少我也可以做到。-->
<!--当然这个话题每次都在我讲的笑话中结束。她向我抱怨如果家里有男人就能把衣柜搬下楼而不需要自付这一部分的服务费了，我说感觉至少要两个才能搬得动，不知道有什么合法的方法可以和两个男人结婚让他们负责干这些活，否则就不需要。把她在紧张严肃的氛围里整绷不住了乐出来了，就结束了，又活过了一天。-->
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇十八·24年2月</title>
    <url>/2024/02/01/Diary-2024-02/</url>
    <content><![CDATA[<p>感觉做什么都没有头猪啊不是头绪是怎么一回事呢</p>
<span id="more"></span>
<h1 id="月1日">2月1日</h1>
<p>过一会（？）就美赛了，我们仨（？）目前仍然是一个友谊第一比赛第二
<del>内恰第三</del> 的氛围（，还能吃到他们俩的糖，挺好的。</p>
<p>今天还是在时间序列，感觉还挺有意思的，只不过 Time Series Analysis
With Applications in R
这本书看了一下感觉有点水，可能是作业题会从里面出，又不是上课现在就只看看讲义好了，似乎下学期金统也会用到的样子。怎么又变成在学而不是在磕盐了呢，急急急（<del>，是不是等我把这个学了就可以换导师了</del></p>
<h1 id="月2日">2月2日</h1>
<p>美赛受难记（（</p>
<p>好消息：上午我在负责详细看 E 题，讨论下来最后决定就是做 E 题</p>
<p>坏消息：不大会做</p>
<p>好消息：我觉得要用 ARIMA 做一部分，前段时间正好就在学时间序列</p>
<p>坏消息：还没看到这里</p>
<p>（</p>
<p>下午洗数据的时候正好出成绩，这下我相信茶课调分的实力了（，然而概率论
2 这个喜提 B+ 还是有点难受的。我知道他要是不调分的话我大概就是 B 或 B-
了而且期中爆炸确实是自己的问题但调得还是不够用力啊（x，求真课初体验大失败。</p>
<p>其他的话，我生物甚至有 A（，另外这学期喜提了一个
A+，坏消息是这门课叫建筑材料实验（（</p>
<h1 id="月3日">2月3日</h1>
<p>美赛受难记，但是今天睡眠充足（，白天也没干啥。除了把论文里面不需要具体计算的部分写了之外，就是不停地在画图，流程图画了一个两个三个，其他
introduction 性质的地图柱状图啥的也画了几个。原来美赛是美工大赛（</p>
<p>虽然堆起来看着产出很多，但感觉还挺佛的，至少是没怎么动脑子，为后两天爆肝写论文打基础（迫真</p>
<p>翻译：我就一臭写论文的，既不知道模型建得怎么样了，也不知道我能帮上点啥忙，那就睡觉吧。</p>
<p>晚上感觉进度有点小慢，想了想也不是非要顺序推进毕竟最后一问和前面没啥关系，又找到了合适的论文，就先开始做了，减轻点压力。而且最后还要写个小作文，本来也算是我的活，那不如早点开始了。以此为理由把前面的模型的论文任务推回给了队友，让他们一边做一边写，听起来也蛮合理的，总比最后让我从头再开始学习模型
<del>还看不懂</del> 然后压 ddl 写论文靠谱（</p>
<p>说实话我今天在一篇 heritage protection 相关的<a href="https://www.sciencedirect.com/science/article/pii/S0264275123000860#da0005">论文</a>里终于明白了
univariate, bivariate, multivariate analysis
的真正意义和对应的三种从来没想过要放一起看的方法，是不是我这个统人当得实在有点太抽象（字面义）了，就是说，太不应用了（（</p>
<h1 id="月4日">2月4日</h1>
<p>美赛受难记，今天（我自己）刚磨蹭着做完最后一题，听起来非常光明，但是只做了这道题（</p>
<p>一边做一边把这部分的论文写好了，现在就有 15
页，也不知道后面要不要压字数。现在想帮忙做第二题但感觉也帮不上什么忙，又想到队友至多有一个会写
LaTeX，毛骨悚然（x（</p>
<p>肩颈都好痛，这破比赛打完之后得稍微休息一天，至少多在床上待一会（</p>
<p>事已至此，先写 Report on Use of AI 和其他有的没的东西吧，比如说 model
evaluation，sensitivity analysis，完全不存在的 assumption and
justification，草怎么还有这么多事。<del>这比赛没有 LLM
的话怎么打啊，以前的选手太强了吧（</del></p>
<p>之前说觉得 Mili
现在的歌没有以前好听了，歌词也没那么戳我，但又稍微有点疑惑是不是我的偏见导致的，或者单纯就是
Millennium Mother 这张专辑太强了。今天写论文的时候发现自己在哼 <a href="https://music.163.com/song?id=554242868">Extension of You</a>
的旋律，又回去听了一下，还是像第一次看到歌词的时候一样要流泪了。</p>
<h1 id="月5日">2月5日</h1>
<p>美赛受难记，后面忘了，总之已经到最危难的时刻了，逸一时，误一世，啊啊啊啊啊啊（？</p>
<h1 id="月6日">2月6日</h1>
<p>美赛受难记，但结束了，不 disqualified 就是赢！</p>
<p>万一今年有高于 S 的奖的话明年可以自己单刷一次，哦那样的话报名费要自付
100 刀没人一起摊，好贵，算了（x）。而且感觉也很危，这次其实除了当
regression monkey 之外就是在用嘴和 GPT 建模，不过 ICM
是不是就这样啊（。</p>
<h1 id="月7日">2月7日</h1>
<p>又活一天</p>
<p>看了 #457994 之后又破防了（x</p>
<h1 id="月8日">2月8日</h1>
<p>摆了，详见最新一篇。</p>
<!--这两天和家人说了很多话，今天在路上一边骑车也一边想了很多问题，最后的结论是我可能还是更需要（并不是更想）去搞钱，用来面对一个人生活会遇到的风险。相比于做学术，我目前是更倾向于转 econ（其实也早有这样的想法），或者直白一些说就是转 quant，但又还是放不下复杂优美的理论带给我的那种 thrilling 的感受。不过毕竟我出不起金融硕的钱，所以要润出去读 PhD 这件事还是确定的，但不知道毕业后是不是真的要转了。那么科研方向需要改一下吗，wwc 救救我（。-->
<!--然而我是因为做不了工程才来学数学的，现在又想倒回去，真的没问题吗。PhD 毕业又转行真的可行吗（-->
<h1 id="月9日">2月9日</h1>
<p>年夜饭是巡湘记，好哦，不过它和望湘园的本质差别到底是啥呢，剁椒鱼头里面加的主食是面条而不是米线吗（</p>
<p>提前一段时间订了座，今天去才知道全都订满了，坐得好挤，平时两个人还能坐四人桌，今天就被赶去角落的双人桌了。也挺合理，今晚还营业的餐厅本来就少，而且到底谁大过年的还想在家无偿做饭（。<!--比起坐飞机路过山东还要收起小桌板，是一种非常珍贵的自由。--></p>
<!--越到年关越感受到前所未有的一种痛苦和恐惧，想抓住这种来之不易的轻盈和自由，要如何选择，又得放弃什么，我到现在还是不明白。我许多次和我妈说我以后想要一个人生活，向她分析原因证明我也能过得很好，到现在她终于接受了我的想法，但是今天说完之后她问我，你说的这些我都明白了，但为什么要哭呢？-->
<p>晚上终于又开始推时间序列的进度了（</p>
<h1 id="月10日">2月10日</h1>
<p>今天在外环和中环之间搬东西，因为初一要吃素所以也没在外面吃东西，简单来说就是没吃啥，然后买了炸鸡回去等着零点之后当夜宵吃。我和我妈说等我润掉了年初一自己过的话就不吃素了，她说你别让我知道了就行。</p>
<p>晚上一出顾村公园地铁站，这边放鞭炮放得空气已经五米之外看不到人了，吓晕。烟花爆竹哪怕在外环外也买不到，想放还要跑去江浙买，到底有啥可放的，好强的信念感。扫了单车之后看到有个在等公交的孕妇用手捂着口鼻，出于对孕妇的敬佩（真的主要是敬佩）我把包里多的口罩送给了她，听了一些吉祥话。搁平时我觉得我来不及听，因为这个共享单车
16
分钟就要计两块五了，但我现在有单车卡，半路感觉车骑起来不舒服还能当场停下换一辆，大概就这么阔气。</p>
<p>不过还是不要这样就觉得我是什么好人（<del>没人在乎这个</del>，因为在路上骑车的时候我在想的是，这样的话昨天在巡湘记离店的时候多顺的一把薄荷糖就抵消了。顺带巡湘记的薄荷糖真的很好吃，比海底捞的好吃，而望湘园没有薄荷糖。</p>
<h1 id="月11日">2月11日</h1>
<p>好想去淀山湖玩啊！坏了，这个假期不是在外环和中环之间搬东西就是在玩，盐是一点没磕，就看了一咪咪时间序列，<del>开学真的，直接换导师算了，还能假装假期补习了前置知识</del>。</p>
<p>今天在外面抽空看完了一个二医大（交医）的姐姐写的垃圾话公众号，真的，欲罢不能，看得我早上去宜家的时候直接坐过了站，本来想出站骑个车哪怕只有两公里也能过过瘾，结果为了再多看一会又往回坐了一站地铁。晚上在回家的路上看完了所有的文章，一边爽的不行并为我那些不能见人的垃圾话感到难过，它们就不配在阳光下暴晒并获得好几百阅读量，一边又惋惜乃至憎恨，这么刻薄又这么有才华还更新得这么慢，我要到什么时候才能再一次性吃上这么多这么好的饭。</p>
<p>不行，我也要找个阴暗的角落大声说我的垃圾话，不是我和我姐天天讲的那种垃圾话，是我天天在心里大喊、晚上一大段一大段敲到电脑上又觉得万一发博客我的一切人际关系就都要毁掉了的那种垃圾话。</p>
<p>顺带，上次不明不白地被宜家送货的师傅骂了，是一款常见的爱指手画脚觉得自己最牛逼的呀苏，一到楼下就讲怎么是个小姑娘在家里接货也没法帮忙搬，我说搬货上楼本来就是你们的服务范围，伊刚上海人都蛮客气的呀你怎么这样子，我今天跑了多少单人家家里男主人都会得搭把手额呀。我让他小心点不要碰花了刚刷过的墙不要乱踩我家里的地板，他嫌我女小囡事体多，我问如果这个换过的床架还有问题的话能不能再换，他跟我讲阿姨啊哪能可能再出问题，跟你们女人家真是怎么讲道理也没用，我说我在复旦念数学（<del>是的我感觉这话在这里听起来甚至比说在华子念数学更有底气一些，还好伊嘟囔了一句高材生也这么没素质就走了，也没问我要学生证</del>，是我懂概率还是你懂概率（<del>抱歉其实我心里知道我懂的那些概率也没什么用</del>。后来跟客服投诉了服务态度差，获得了一张一百块的代金券，很想和客服说我的乳腺结节不止这些钱，又怕对面长结节，算了。今天用它买了一些没啥用的东西回来，本来想买个狗狗甚至大鲨鱼玩偶，但我妈让我买衣架和鞋刷子（叹气。</p>
<p>晚上吃了贵州菜，本着都没吃过但是哪家店排队最长应该就最好吃的心态去吃了山石榴，好吃，能把我辣得嘶溜嘶溜，就是歌单不太行。我也鉴不出来预制菜，只要端上来有热乎气我就当锅气了，但反正确实就挺好吃的，管它呢。</p>
<h1 id="月12日">2月12日</h1>
<p>累累累，摆摆摆，先别说科研和学习了，暑研怎么办托福怎么办（乐</p>
<h1 id="月13日">2月13日</h1>
<p>前面忘了，后面也忘了，总之今天要看<a href="https://mp.weixin.qq.com/s/X2uiBOo_ovRsB7T_V-WZWg">二月十三</a>（</p>
<p>用了四五年的 <del>我妈的同事随手送她于是她又随手送给我的</del>
星巴克联名款卡包裂开了，然而感觉在淘宝怎么挑都挑不到这么合适的，不是没有挂绳就是卡册类型的要么就超过二十块已经不在我的财力范围内了。搜了一下才知道原来这个七八十，难怪好用，感觉是我不配（（</p>
<h1 id="月14日">2月14日</h1>
<p>早晨起来洗完脸发现脸颊上红红的，还觉得要么是睡得太暖和了要么是气色好（，结果到晚上都没退下去还越来越肿，才发现久违地过敏了，吃氯雷他定然后昏睡.jpg</p>
<p>大冬天的到底是在对什么过敏啊，情人节吗，还是说今天 22
度所以我的身体以为这是上海的春天了然后就过敏了（</p>
<h1 id="月15日">2月15日</h1>
<!--终于是找到了概率论 2 期末之后复的题，这东西能弄丢本来就实属奇迹，但我现在也看不太懂了，罢了（-->
<p>时间序列好难，急，还有个暑研项目一周后截止但我什么都还没填，托福是什么，怎么能这么摆（乐</p>
<h1 id="月16日">2月16日</h1>
<p>前两天右边嘴角起了个痘，现在差不多好了，今天左边嘴角又起了一个，记之（</p>
<!--今晚在家又发表了一些学数学不如当家庭主妇的暴论，把我妈整的很疑惑。感觉只要让她习惯了我时不时发疯，以后就什么都能接受了（-->
<h1 id="月17日">2月17日</h1>
<p>昨晚登了一下高中的智学网账号，今天卸载之前又看了一眼当时的一些原卷，鄙人高考前英语作文甚至能有
22/25
这样的伟业，又和我这两天写的托福练习作文对比了一下，我恨不得回去让我高三的英语老师重造一个月。</p>
<p>于是今天又开始对着阅读划词组背句子了，背一点算一点，我总能把它们塞到毫不相干的作文主题的合适位置里的。然后不知道为什么就去补<a href="https://bgm.tv/subject/55770">巨人</a>了，后面忘了，心脏撒撒给哟（</p>
<h1 id="月18日">2月18日</h1>
<p>感觉托福听力的最大障碍是没法集中精力听完五段，听三个我就累了。之前一直以为
lecture 会比 conversation 难，结果现在发现还是 conversation
比较困难，急急急，语速太快了没跟上就寄了。不过应该换个思路，conversation
就别记笔记了，听懂了也没太多可记的，没听懂记了也没用。</p>
<p>省流：今天做了一些听力和写作，然而在家也没法练口语，就又去补巨人了。来点锐评：</p>
<blockquote>
<p>我：</p>
<p>这番里面的马真的都画的好好啊</p>
<p><img src="https://s2.loli.net/2024/02/18/V7c9fQsXALlgJ1b.jpg" alt="俺の愛馬が！.jpg"></p>
<p>俺の愛馬が！</p>
<p>要不要搞个自由之翼的披风穿 jk 外面</p>
<p>好便宜 才四五十 就是太中二了</p>
<p>只恨我初中的时候没看这个</p>
<p>友：</p>
<p>沃日 初中哪有这么多钱 (?)</p>
<p>我：</p>
<p>确实</p>
<p>但是如果初中的时候看这个 现在就不会想买了</p>
<p>还可以早点和谏山创和解</p>
<p>友：</p>
<p>那也不一定</p>
<p>我：</p>
<p>没事 我都能和市川春子和解</p>
<p>谏山创算什么</p>
<p>友：</p>
<p>创创</p>
<p>全部创了</p>
<p>我：</p>
<p>你看过宝石之国漫画吗 和解了吗</p>
<p>友：</p>
<p>没看漫画</p>
<p>我：</p>
<p>fine 那你可以去和解一下</p>
<p>友：</p>
<p>笑死 听说小绿最后变成人了</p>
<p>感觉难绷</p>
<p>我：</p>
<p>不是 这个结局我觉得可以预料到</p>
<p>但是它的过程实在是令人震撼</p>
<p>就看到动漫魂肉骨那个说法的时候我感觉就差不多了</p>
<p>但是后面这个过程我接受不了</p>
<p>不过我也和解了</p>
<p>友：</p>
<p>好好好 无所谓</p>
<p>都这个年纪了什么和解不了啊</p>
<p>我：</p>
<p>确实 又不是女高了</p>
<p>看这玩意看到现在我还是只关心马</p>
<p><img src="https://s2.loli.net/2024/02/18/EcpF4IjzQuCthDT.jpg" alt="赛马娘可能性微存.jpg"></p>
<p>这个体型真就是速度竞马，但好像比一般的赛马小一点（</p>
<p><img src="https://s2.loli.net/2024/02/18/aKvJL7WstgGEpx6.jpg" alt="蹄铁.jpg"></p>
<p>蹄铁背景没绷住</p>
<p>但是时速 75~80 km 还是太恐怖了吧</p>
<p>赛马一般 1km 跑 60 秒左右吧</p>
<p>查了下世界纪录是 53.7 s，所以是时速 67 km</p>
<p>怎么人全死了啊 就爱看这种</p>
<p>但撤退的时候根本没人关心他们的马怎么样了 急</p>
<p>我：</p>
<p>太典了</p>
<p>把 Ayanami 还回来 啊不是 把 Eren 还回来</p>
<p>我说这不就是换皮 EVA 吗 不话疗的那种 所以评分会比 EVA 低一点</p>
<p>友：</p>
<p>确实 但是三笠是面瘫</p>
<p>我：</p>
<p>不错啊 那就是 Ayanami 加强了 能要求把真嗣还回来了</p>
<p>可惜我最喜欢 Asuka 巨人没有这号角色</p>
<p>友：</p>
<p>是 傲娇在这个世界活不了一点</p>
<p>我：</p>
<p>别骂了 但 Asuka 强啊</p>
<p>所以 Misato 桑可以代兵长吗</p>
<p>不太能代 他太强了 而且不够涩</p>
<p>友：</p>
<p>兵长多色啊 战损了更色</p>
<p>Misato 至始至终都是完整的 (不是)</p>
<p>我：</p>
<p>我靠 你别引诱我的 xp</p>
</blockquote>
<p>（？</p>
<h1 id="月19日">2月19日</h1>
<p>进巨第一季看完了，真的，EVA 和 FZ 之后好久没吃到这么好的饭了（</p>
<p><del>那为什么打 8 分而不是 9 分呢（因为不够 EVA 或 FZ（x</del></p>
<p>明天去交大，摸一天，感觉也属于定番（</p>
<p>凌晨练了个口语比练别的加起来都精彩：</p>
<blockquote>
<p>题目：Talk about a famous person that you admire. Explain why you
respect this person.</p>
<p>我：Ummm（思考）（十五秒快过去了还想不出来能说什么）（急急急）</p>
<p>One of the famous person I admire is Shing-Tung Yau, a famous
mathematician who enjoys high reputation in the whole world (</p>
</blockquote>
<h1 id="月20日">2月20日</h1>
<p>今天去交大了，蛮累的，之后再写。前年这时候在后悔当初为什么拒了电院那个
IEEE
班（，去年这时候觉得没去交也没什么反正去了也学不会，今年发现去交或者去旦学数学其实都很爽，唉（x</p>
<p>和初中同学聊了聊天，她告诉我她考前三天才开始学口语和写作最后
102，小分也都够用，ok（，感觉确实每天要练但也不是非得特别紧张（（</p>
<p>因为路程比较远所以昨晚下好了进巨第二季还带了充电宝，在地铁上看完了，第三季也开了个头。虽然槽点也不少，但还是好久没吃到这么好的饭了（二度，看了这么多有的没的才发现，我果然还是喜欢这种啊（（</p>
<h1 id="月21日">2月21日</h1>
<p>进巨第三季前半看完了，王政篇给了 9
分。往后看看发现这玩意真的好长啊，最终季还分上下部分，还有若干
OVA，稍微有点看不动了，寒假能看到看海就差不多得了。不过我属于是不往后看剧透又不一口气补完就抓耳挠腮坐立不安，不同于第二季我和艾伦一样疑惑，王政篇之后看剧透和设定终于看得懂了。何况这个体量的作品如果不提前知道一些思路又不二刷的话真的会漏掉很多细节，失去的震撼感在丰富的内容面前是可以让位的。</p>
<p>晚上卡 ddl
交了一个暑研申请，主要是我太拖了，推荐信倒是今早我还在大睡的时候就收到了（。其实寒假除了几个校级的项目之外就压根没找，咋办呢，总不能真去实习吧，<del>实在不行能以
2025 年不毕业为理由直接不选课吗</del>（</p>
<p>想了想倒还是和小时候一样，我妈前脚出门上班我后脚打开电脑开始看动漫，然后在她回家之前加速补作业（交申请，给
wwc
写邮件），晚上在她眼皮子底下随便干点有的没的（练托福写作）。快要回学校了。</p>
<p>明天本来是想去滨江道骑车，<del>陆家嘴签证拿到了</del>，下暴雨的话恐怕就不行了，大不了明年冬天再说。总之要从静安寺换乘买
Lilian by the
way，不能骑车的话就去世纪大道走走好了，然后早点回家收拾东西。</p>
<h1 id="月22日">2月22日</h1>
<p>又该选课了（，课表再次变成了不认识的样子。好消息是一周三休了，坏消息是周二好像有五节课（（（</p>
<h1 id="月23日">2月23日</h1>
<p>最近光是安装的家具送来的时候工具包里多余的材料就攒下了这么多，轻轻地崩溃了：</p>
<p><img src="https://s2.loli.net/2024/02/23/6pGVxPjWh4eywBJ.jpg" alt="345C0214A5FAFCEB3955FBD265154895.jpg"></p>
<p>如果还有下次（？）的话我选全屋定制（</p>
<p>明天回学校了，希望高铁不要晚点太多（（</p>
<h1 id="月24日">2月24日</h1>
<p>喝到茶颜悦色了，虽然我的评价是，就这（x）。感觉还是得现买现喝，下次一定（</p>
<p>带回寝室拍了个照，怎么不算是一种谷子了呢：</p>
<p><img src="https://s2.loli.net/2024/02/26/RwYMGEQqCfib2Jd.jpg" alt="茶颜悦色.jpg"></p>
<p>在高铁上补了进巨最终季 part 1，看到第 15
话后半段的时候到站了，急急急急急（。马莱篇感觉确实没那么有趣，但单凭莎夏那几话都也还是
8 分的水平。其实到第三季结束发现 104
期配角三人组还是完整的的时候我就感觉要刀莎夏了（<del>主要是莎夏太单纯了，刀另两个人效果就没那么好（</del>，完全是死于谏山创的刀法（。很难评价谏山创和虚渊玄谁更爱的战士，单看
Fate/Zero 似乎还是谏山创更疯，感觉得去补一下魔圆再说（</p>
<p>题外话，感觉我最看重的还是单回质量，像 Fate/Extra Last Encore
即使作为粉丝向作品来看大约就是 7 分（<del>对路人来说还不到 6
分，实在绷不住</del>，然而因为童谣那两话我就愿意给个
8。后来聊了聊设定和一些问题（简称我要求被剧透（，感觉全系列除了完结篇有待考察之外应该能稳定在至少
8 分，但后面应该既有争议又很难像第三季一样有趣又震撼，给不出 9 了。</p>
<p>虽然但是，三笠你的脸到后期怎么画成这样了啊，我看得睡不着觉。就感觉，诶，很空虚，没有什么永垂不朽。</p>
<p>感觉最近实在是赛马和进巨都看太多了，加上下午还在吐槽既然想要保留王血何必安排希斯托莉娅怀孕，还不如让吉克在生命的最后一年猛猛当种马效率高（。结果傍晚睡觉梦到进巨的设定集里有九大巨人的配种费表，进巨和始祖最高要一亿日元左右，平均水平是四五千万，只有车力最低是两千万，实在没绷住（</p>
<p><del>其实北黑和春秋分今年的配种费都是两千万，已经是种马的最高价格了（</del></p>
<h1 id="月25日">2月25日</h1>
<p>前段时间在上海疑似因为天气太暖和，时隔好几年犯鼻炎了。昨天还好一点，今天收拾东西可能吃灰吃多了又开始打喷嚏了（</p>
<p>完全不想上学，于是今晚把进巨最终季 part 1 看了，待会上床写托福（</p>
<h1 id="月26日">2月26日</h1>
<p>难受的春季学期开始了，前半段气温还可以但暖气难受，后半段气温难受（</p>
<p>最终还是打算在课表里加可靠性数据与生存分析了，虽然是很细的生统方向跟我几乎就没关系，但其实完全出于我的一厢情愿（？），因为
wjd
这学期结束就要离开华子了。如果不算高统的话，她当年那门统推是让我印象最好的一门统辅课，可惜几乎全是线上上的。而且说实话和我完全没关系的课我也上了不少了（，大不了水水过，而且很可能没有期末考，另外很多东西生统概论的时候也学过了。</p>
<p>第一次点了瑞幸（<del>其实只是需要它的纸袋子</del>，发现券还蛮多的，后面可以多点几次。果然好多冰，这个不额外加糖的丝绒生椰拿铁怎么也这么甜（</p>
<p>来个很烂的谐音梗：</p>
<blockquote>
<p>室友：下午没课，我打算把冬天的衣服都拿去干洗店洗</p>
<p>我：今天是你大洗的日子啊！</p>
</blockquote>
<p>于是晚上我就把菜汤弄到衣服上回去洗了，寄（</p>
<h1 id="月27日">2月27日</h1>
<p>早八之前买了杯瑞幸，是 064
号，进店的时候看到咖啡师在赶早七，一排一排地做咖啡（，感觉很惨。早十课上坐我斜前面的同学的瑞幸是
429 号，感觉更惨了（（</p>
<p>有点子上瘾，这玩意比瓶装好喝多了啊（（</p>
<h1 id="月28日">2月28日</h1>
<p>现在总感觉喝咖啡能维持清醒的时间越来越短了，虽然一个寒假都几乎没喝但还是不行，一会就困。喝了两天瑞幸获得了两个袋子，其实是想折纸了（x</p>
<p><img src="https://s2.loli.net/2024/02/28/AZYdx8pjkF72BmC.jpg" alt="luckin coffee.jpg"></p>
<p>今天把进巨看完了，晚课坐在中间排用电脑看了完结篇后篇（，现在想想开始感到尴尬了（。不钝评了，虽然不喜欢未来视的设定（相比之下“这是由你亲手开始的故事啊！”这句真是我全系列最喜欢的台词）但好歹圆回来给了结局已经很好了，出彩的部分基本集中在前三季，表现力也一直很强，补完还是很值的。</p>
<p>刚在六教再见了所有的巨人（，下课出来就被树吓了一跳，好难绷（（</p>
<p><img src="https://s2.loli.net/2024/02/28/aZ8GUkyPsQmAB5H.jpg" alt="进巨后遗症.jpg"></p>
<h1 id="月29日">2月29日</h1>
<p>高统 II 讲
Bayesian、其他的一些估计方法和非参数统计，之前我还一直犹豫要不要去上 dwl
开的那门贝叶斯，感觉不上又不踏实，上了既然是她的课那我必吃
3.6（，又找不到明显的上位替代，这下没事了。不过毕竟是第二学期了，不像上学期开始的时候我还以为是个很摸的课（，一上来就在上强度，急。</p>
<p>lq
讲课还挺好的，<del>奶一口，单看第一节课我感觉他恐怕是统计中心最会讲课的老师了，甚至比
wwc 和 wjd
都好（，这俩在我心里已经是讲得最好的了，别人更是（（</del>。有 slides
和板书，除了读 PPT
之外还讲一些直观理解之类的东西，不然一上来还挺头大的，感觉 4-2 以后
<del>起得来床的话</del> 还是值得一去。</p>
<p>托福终于摆脱听力阅读越做越菜了。今晚突然意识到阅读是不是不应该先通读文章再做题，而是要直接对着题目一段一段读，但试了一下感觉也并没有省时间，还错得更多了，还是按自己的节奏来吧（</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇十九·24年3月</title>
    <url>/2024/03/01/Diary-2024-03/</url>
    <content><![CDATA[<p>春困困困困困色特了</p>
<span id="more"></span>
<h1 id="月1日">3月1日</h1>
<p>昨天喝了瑞幸的珞珈樱花拿铁，<del>为什么不是顾村公园樱花拿铁，是樱花节名气还不够大吗（确实是</del>。感觉第一次吃到和樱花沾边但是味道意外地不错的食物，可能主要是也没什么樱花味吧（。今天又来一杯，明天打算点个美式（</p>
<p>好像后面又有线条小狗和瑞幸的联名了，<del>点两杯才能有周边怎么办</del>
<del>太好了这回我堂堂正正喝两杯（</del></p>
<p>这个计算概率，我不好说，后半部分是一些 SDE
数值解法但哥们完全没学过这玩意，但好像会提一下背景知识，这课上也好多没上过概率论
3
的，希望人没事。老师下个学期就要离开华子了，又收集到一门绝版课程，<del>但愿这样的话给分能好点（</del>。<del>第一次作业在课上就写完了，体验绝佳（不</del></p>
<!--这两天和友人大吵一架，虽然也算不上割席，以后冬衣要靠自己慢慢搓了，上个月本就惨淡的评论区还出现一位 ghost，乐。稍微也有点乐不出来，又一次在别人的二选一里当了败犬，不是都说青梅竹马打不过天降吗，就不能让我赢一次嘛。-->
<h1 id="月2日">3月2日</h1>
<p>昨天早上九点二十起床，在去自取了一杯瑞幸的情况下在上课前顺利走进了六教二楼的教室，现在是越来越强了。今早就暴毙了，直接一个补觉（</p>
<p>你说得对，现在是第一周，但我已经急了，怎么实分析和基物 2
作业都这么多。实分析作业我寒假没写是我的问题我自裁，但基物 2
是从衍射学起哥们连干涉都压根没学（，现在处在一个回头看基础设定的状态，书上明明都是数学公式但我怎么看不懂一点捏（。学了一晚上，我痛死（</p>
<p>早知道当初报第一周周末的托福，乐了。</p>
<p>但唯一的好消息是我今天下午在 C
楼研讨间练口语的时候发现这玩意其实不是很难，至少我 independent speaking
不会没话说，果然瞎扯我还是有一手。但是后面三道题有概率说不完，还是得学习一个高速神言（</p>
<p>瑞幸冰美式可以加双份奶，有券于是五块钱到手了。我现在理解为什么说减脂期喝美式了，这玩意是真有点抑制食欲，不是那种通过饱腹感来抑制，而是通过在嘴里残留一些苦味来让人不想吃饭（</p>
<h1 id="月3日">3月3日</h1>
<p>今天的瑞幸可能是定位有问题，不知道为什么下单下到清华科技园店去了。我还寻思着清芬这边一直都没有茶咖系列，今天怎么突然有了，提示取餐的时候才发现。从四教过去其实也不远，感觉和从寝室到四教差不多，甚至还要近一些，而且清华路以南是家属区所以路修的比较好，比北边好走很多。</p>
<p>但是这玩意真的好难喝啊，我下单的时候就想，茉莉花香拿铁，这六个字没有一个听起来是难喝的，于是带着幻想乐颠颠地骑了好远的路。但是就是很难喝，不像营销说的是茶叶泡出来的，味道像茶粉。也是，十块钱难道还想喝真茶叶和真咖啡豆吗，醒醒。</p>
<p><del>所以清芬店没有茶咖是因为这玩意太难喝了所以让大家不要喝吗，它真的我哭死</del></p>
<p>天气不错，所以下错单出去骑车也没什么怨言，反而很开心。等考完托福找时间出去骑车吧——开玩笑的。</p>
<p>我突然理解了，学基物我还看它那个证明干啥，鉴定为数学学魔怔了。反正也看不懂，拟合一下题目拉倒（</p>
<p>写了一下午一晚上实分析作业还没写完，倒也不怎么难，但主要是在看讲义，反正都是这个妹妹我见过的那种感觉（。明天应该能写完了吧，我草，为什么第一周这么累，难道真是因为物理和实分析都布置了两周的作业的原因吗。</p>
<p>猛猛约下周早上的研讨间练口语，但愿作息能顺带变得健康点（。现在我也不知道问题到底会在哪一部分了，是口语自我感觉良好实际很菜还是别的不行，难不成会是阅读不行吗（，<del>这样的话好像不是很老中（（</del></p>
<h1 id="月4日">3月4日</h1>
<p>开学到现在光是把菜汤弄到身上跑回寝室洗都已经两次了，<del>感觉开学那天我对着室友说出“今天是你大洗的日子”这么烂的梗之后命运的齿轮就开始旋转了</del>，寄。</p>
<p>线条小狗和瑞幸的联名太可爱力，虽然今天起得稍微有点晚了，早晨赶着去练口语就没来得及买，但单杯的袋子也挺好的。明天从早八上到晚十，感觉可以整两杯
<del>来获得一张贴纸</del>。</p>
<p>下午上生存分析的时候发现从四教四楼可以看到 W
楼，视野是这样的。从远处看感觉这个层高很逼仄（在说什么废话</p>
<p><img src="https://s2.loli.net/2024/03/04/a9YhefUQCOA2MpZ.jpg" alt="W.jpg"></p>
<h1 id="月5日">3月5日</h1>
<!--几个月之前听说我姐考公过了笔试我还长吁短叹，这周她要去面试了，我：世界真是个巨大的草台班子，连你都要为人民服务了，太可怕了吧！-->
<!--非常的 mean，不过她说她也是这么想的，好哦（-->
<p>明天下午要和 wwc
聊，现在很急，首先我要跟他讲一遍我是未央的然后我要延毕
etc，现在我不知道为什么很担心他到底带不带本科生尤其是之后打算润的本科生了（虽然但是会有人不带吗（，希望人没事。</p>
<!--何老板正好今早问我对他现在打算做的一个题目有没有兴趣，如果想做的话可以一起，导师是经管的高峰（啊不是目白高峰吗（不是（。我对他有点印象，因为经管也有一门叫实分析的课但其实是数分 1，曾帮助很多统辅人当做靠谱的成绩拿出去润掉了，今年没开导致很多人来选测度与积分。-->
<!--多少有点破罐破摔了，万一 wwc 这里不行的话就和他一起吧。虽然我今天看了他给的那篇文章，发现 SDE 一点都不会，stopping time 倒是用得很浅。我现在都有点不知道他是怎么做到学了个皮毛就能用的，我总觉得不从最底层开始学一遍就很难上手应用学，学数学学得。如同只有搞清楚整个 R 的框架才能写出 Hello World（quoted from LagrangeKMnO4（。-->
<p>晚上回来吃了三个（中等大小的）番茄，尝了一个今天买的芒果。室友大受震撼问我不是减脂期吗我说对啊晚饭没吃饱而且这个加餐不是挺减脂的吗（（</p>
<p>唉，我说我减脂是因为 BMI
超了，而且总感觉精力不济，室友说你就是服美役。那我就要开始跟她暴论了，明明很多说别人在服美役的人要么是自己也在偷偷服，要么就是天生一副符合主流审美的好皮囊轮不到你来服啊！随时随地吃任何东西都不胖的人不许说别人为了健康减肥是服美役，就像我夏天都不打防晒冬天只擦保湿和素颜霜而你尽力护肤也只能达到一个亚健康的状态一样。最后这句话把她搞破防了，现在我在算热量她在拍脸，嘿嘿（</p>
<p>然后她小红书十分钟之后回来问我一杯瑞幸拿铁二百大卡怎么下得去嘴的，我破防了，明天喝美式（x</p>
<h1 id="月6日">3月6日</h1>
<p>今天和 wwc
聊了，回来一看我昨天在担心些什么（。今年他招的博士生正好是未央零字班的，<!--虽然我不认识这哥们但是他知道我延毕这是怎么一回事呢，好可怕（，-->不仅省略解释一堆这书院是什么玩意，他还先我一步锐评“你们这个培养方案真是不可理喻”，感觉来对地方了（。虽然预想的是搞时间序列，但他给我的问题是
network model &amp; graphon estimation
说是最近在看这个，而且概率会用得多一点，<!--然后跟我锐评未央那位哥们基础不太行，给他的还是应用的问题，希望我一上来看点理论的。还说上学期想让他去上吴昊的概率论 1，结果和未央的一门必修撞了还不允许冲选，你们未央真是不可理喻（二度（乐。-->也挺好，先看吧。</p>
<p>喝了一圈意外地发现还是厚乳拿铁最好喝，奶味很浓郁，也不怎么甜，<del>热量也还行</del>。其实瑞幸招牌的生椰拿铁我完全没喝出来哪里好喝了（，感觉还不如贝纳颂那一款，也不如丝绒生椰和冰吸生椰。下周开始有柚
C 美式了，好好好。</p>
<p>早上出门之前称了下体重，怎么现在 BMI
就已经正常了，好怪哦。感觉也不是最近有意识地减脂的结果毕竟也没几天（，而是寒假在家要自己做饭所以就瘦了（草（。晚上开心地吃了顿米粉（别骂了，辣汤又溅到了风衣上（，烂梗的惩罚没完没了。</p>
<p>然而这个清芬它有什么低热量的主食吗，每天这个米饭都吃得我相当纠结，人家桃李还有杂粮饭可以选（</p>
<h1 id="月7日">3月7日</h1>
<p>看了一下午论文，感觉头很大（，吃晚饭的时候在考虑能不能本科毕业直接去当高中老师（（x</p>
<p>虽然我感觉正文其实真没有什么非常困难的数学，很多地方为了贴合真实的处理甚至都没那么严谨了（挠头，但这个思路真的是看得我一愣一愣的（，顺着思路倒是结果都能随手推，但好累（。</p>
<p>yysy 这个 supplementary materials 需要读吗，我之前看 wwc
发给我的两篇都是 biometrika
上的文章，感觉都不长，还很乐，还觉得可能下周就可以汇报了，但这才发现证明全在
supplementary data 里面（，要读的话得到什么时候啊（x</p>
<p>今天把咖啡撒到身上了，我错了我以后真的不再玩烂梗了，饶了我吧（（</p>
<p>诶，我发现减肥能给自己带来一种错觉，就是别人给我拍的照片看起来也没那么魁梧了（。</p>
<!--今天下午洗完衣服回教室的路上想起来室友今天在校学生会的女生节活动那边，就顺路找她拍了张拍立得，诶，虽然从表情和在风里的发型管理一直到一个领子翻着一个领子没翻都很失败，但单看这个照片谁能想到我体重是现在这个水平呢（不-->
<!-- https://smms.app/image/DtWwPJZI7AcExsg -->
<!--好照骗哦！-->
<h1 id="月8日">3月8日</h1>
<p>早上起来看了一眼，今天计算概率复习简单的概率论，虽然看 logistic
感觉老师可能会讲一些求真笑话<del>（like
数学家至少要精通两个方向（我猜的）</del>但还是又躺下了（，有一种求真招生反诈宣传片的美感。</p>
<p>诶，昨天才和群友说起来还好高三春季的时候连去考一下求真的念头都没动，毕竟当时是第一届，风评还没有这么差，虽然我觉得既然要考物理的话我是考不上的，但万一考上了就太可怕了。然后我想了想为什么没考呢，好像单纯就是懒得准备了（，毕竟到当时高考也准备得还可以，春考看得过去，大概还有感觉高三的英语老师很可爱，<del>不如多和她贴贴（并不（谢谢她救我（</del></p>
<p>躺了一会起来练了下 TOEFL test ready 上剩的三篇写作，一个 integrated
和两个 independent 都给我判了
5/5，很怪，总不能真是字数多就行了吧（。其中有一个 independent writing
是讨论除了电子产品之外二百年内最伟大的科技成就，我：statistical
models！（</p>
<p>打了两遍 integrated writing 才把模板背下来，希望后天早上还记得（</p>
<p>它那个估分区间除了告诉我口语很烂之外就没啥用了，口语是 B2，听读写都是
C1，我本来觉得 advanced 听起来就挺好的了，后来才知道最高是 C2
proficiency（。就不练了，睡大觉（</p>
<h1 id="月10日">3月10日</h1>
<p>今天 <del>参加了一场贵族运动</del> 考完托福了。早上进汇佳考点之后在
ETS
考试中心大楼里等，听到一楼会议室里在吵架讨薪，有个领导一样的人说，我们不是没给发工资，是吧，工资的三个部分，blahblah
都结过了，blahblah
本来就已经降了，并不是拖欠，blahblah，然后被大家骂了（</p>
<p>考前是说台面上的两支笔只能带走一支，结果我走的时候监考老师让我都带上，好怪哦，她不会是在搞我吧（x</p>
<p><img src="https://s2.loli.net/2024/03/10/kpQW3DtPLf2xAHI.jpg" alt="toefl_pencil.jpg"></p>
<p>坐在我左边的是一个出生日期 2010.12.30
的小朋友，考试期间我感觉她不仅在不停乱动还时不时余光瞟我，可能是嫌我太老了<del>，但愿不是要带我一起
HOLD</del>。右边的小朋友是 2009.07 忘了几号出生的，没什么存在感。</p>
<p>总之考前就很有压力。我默默感叹，什么叫托福从娃娃抓起啊，感觉很上流，很京爷。所以左边的小朋友先我一步开始用
Chinglish
和很尖锐的娃娃音开始说口语的时候我就没绷住，一下子就很幻灭。我像她这么大的时候刚从上海的一所乡镇小学毕业进入一所乡镇初中，别说拿出两千块给我考试了，全家一个月都不一定吃这么多钱，然而那时的我都没这么
Chinglish。而且，我高中进入某个只刷题啥也不干的精英学校之后就基本没有开口说过英语了，我现在不算很
Chinglish 真得归功于我小学初中的乡村教师们，唉，果然不是我有
privilege，而是北京就是不行。（<del>我素质好差</del></p>
<p>但我乐了这一下之后听力最后一篇就开始掉线了，当然本来也有点听不懂，一下子没绷住之后更是开始豁边了，六个题目最后都有点乱选，活该。</p>
<p>客观题考完就立刻出分了，阅读 28 听力
26，虽然听力很豁边但是考虑到我最后一篇都是猜的，所以真的，给分不错（。阅读也没啥可说的，感觉比
TPO
难一点，两篇各有一道题不大确定（<del>说实话我觉得都是烂题，完全没在考逻辑，在考和出题人是不是同一个脑回路</del>），就当一篇错一个，28
也不亏。虽然考完刷刷小红书看到大家都 29
30（不是我今天这场，而是在小红书发分数的不是这个水平就是拉胯的不行求安慰，没有什么普通人），感觉还得拼一把写作和口语的运气，先不奶了。</p>
<p>写作一篇写了 300 字一篇写了 180
字，我也觉得很吓人，怎么会写这么多，平时似乎打字打不了这么快。独立写作是问
work 和 relationship
哪个更重要，看了三十秒题目就开始瞎掰了。口语的话，第二篇口语有一句话没说完，别的应该都还好。但愿没有高估自己（</p>
<p>诶，但是我考前就一直很担心一个问题，就是两个小时不能喝水的话怎么办，半个小时不让喝我都会有点头晕，不是真的因为干渴而头晕，而是不让我喝我就很有心理压力，就更快地失水。到现场发现问题比我想的更严重，不到八点钟就把柜子锁起来上楼了，三个多小时都没能喝到水，更糟糕的是我忘记带润唇膏了，都没法厚涂一下。还算聪明的是把水锁进柜子之前我把卫衣袖口整个打湿了，中间用它贴贴嘴唇或者碰一下脸降降温，权当一个心理安慰，勉强有效。</p>
<p>但是考完发现我没经验又社恐没问监考老师被摆了一道，水是可以带上二楼的，只是要放在考场外面的休息区，开考后就不能喝了。之前我就这个问题问过我认识的仅有的两个考过托福的人，只可惜二位都是八个小时不喝水也没关系的奇人，一个说不知道，另一个一开始说不知道后来又说不能带，而且我搜小红书也没搜到过类似的问题，就很奇怪，往往什么奇怪的问题都能在小红书找到同类，这个反而没有，大家都这么耐渴的吗，我可能还是不适合在地球生存。</p>
<p>唉，作业写不完了，paper 啥时候才能读完呢。</p>
<h1 id="月11日">3月11日</h1>
<p>实分析进入测度之后明显就有了一种这我熟（赞赏）的感觉（，毕竟概率论用了这么久，看来还是点拓水平不行。你还别说，ly
和 lxg
两个版本都学过一遍感觉挺好的，有很具体的例子和构造可以用来理解抽象的问题。只不过这课到底上到哪了，我好像到现在为止就去了一次，明天得去看看这周到底要交多少作业（（</p>
<p>高统不知道为什么刚开学就掉线了，感觉是很晚才选上课一直看不到课件的问题，急了，明天进行一个
Lec 2
和作业的补。他这个作业不仅有书后题还有自己出的习题，急急急，Bayesian
一点都没学过（</p>
<p>辅导员又发了个发展意向调查，为什么没有延毕的选项也不能自己填一个，为什么就连出国用的语言成绩都没有考完了还没出分这个选项，几个月之前我填的导师还是
ypk 这次就改成了
wwc（，蚌埠住了。最后两个问题是现在在跟哪个导师做什么课题，目前有哪些成果，我真觉得没必要告诉这哥们（，差点填了不方便透露/
I've signed an NDA（（x</p>
<p>昨晚回来还就那个摸，按照之前在小红书看到的教程改了瑞幸的单杯纸袋，今天我逢人就掏出来炫耀：</p>
<p><img src="https://s2.loli.net/2024/03/11/EGPxpNty9DdFCSH.jpg" alt="xiugou.jpg"></p>
<p>（其实是立体的但不知道为什么看起来不是很立体（可能堆高度用的是纳米胶而不是泡棉胶的问题（</p>
<p>今天拿到第二波联动的物料了，感觉之后还可以玩几次（别摸了（</p>
<h1 id="月12日">3月12日</h1>
<p>托福 checked in 了，不会真得等到周五吧（，急急急（</p>
<p>植树节在蚂蚁森林搞了个大的，发现三年前领的山杏还没种下去，蚌埠住了。</p>
<p>今天去听了下实分析，感觉很休闲，去年学的是实变函数与泛函分析，今年好像是真在学测度与积分（</p>
<h1 id="月13日">3月13日</h1>
<p>开学仅仅两周多三天就发烧了，这学校绝对有问题（</p>
<p>月初立了一个这个月不喝奶茶的
flag（<del>其实是我糖前了，令人感叹（别笑话我啊，很多人去查查也都有只是不知道罢了啊！</del>，饭点的时候烧的很高没吃晚饭，刚刚感觉饿了就点了点吃的，还是忍不住点了一杯茶话弄，我有罪（（</p>
<p>明晚有一个高统作业要交但我就写了一半，后天有个基物作业要交但是还没学，下午我跟可能会点名的
sb
必修课（它叫做绿色交通系统）的助教说我发烧了能不能开个雨课堂，他跟老师商量一通决定不开线上，并要求我过两天去校医院补个证明交给他，我蚌埠住了呀。又想起来它还有个据说很恶心的大作业，并且何老板这学期也没上这课所以就没人能帮忙一起水过去，我打算过一阵把这课退了。</p>
<p>急了呀，就有一种很想指着天空说这上面绝对有个人在搞我的感觉（</p>
<h1 id="月14日">3月14日</h1>
<p>昨晚写了高统作业，哪怕洗了个澡一直到睡前体温也是正常的（。今早是被自己热醒的，一量
37.5，我感觉我像一个在散发蒸汽的超大巨，<del>不知道阿尔敏每次变身超大巨之后难不难受，是不是也像发烧一样（</del></p>
<p>今天上半场在发烧，中间退烧之后稍微缓了一阵子，晚上痛经了（。所以就又是啥也没干的一天，莫名其妙放了两天假，很难想象这个周末要还多少债，科研到底怎么办急急急（。先别想这个了，明早能好好地活着就挺好的了（（</p>
<p>周五似乎是托福出分的 ddl
了，首考所以好像要等到下午，很急，想起我的两千一百块钱就睡不着了，但它至少不是早晨就出所以又睡得着了（？</p>
<h1 id="月15日">3月15日</h1>
<p>早上果然还是不行，生完病虚得很，躺了。从周三到今天我就上了一节课，还是个体育课，说是上课其实就是在边上坐着咳嗽了一个半小时，太寄了，周末要还多少债（</p>
<p>但好消息是基物作业是下周五交而不是这周五，我又舒服了。</p>
<p>托福果然首考出分慢，刷了半天小红书看到非首考的都是上午就出了，我一直到下午快六点才出。口语
22 写作
27，充分证明确实还是老中（。感觉这个口语小分应该是不太行，查了一下似乎
JHU 和 UCLA 的线都没过，印象里其他学校也有一些做 TA
需要口语小分更高的要求，恐怕之后还得考，虽然我也不知道这个东西到底有啥技巧。</p>
<p>但总之轻轻地过百了（103
倒也完全算不上高），一段时间内至少暑研可以放心用这个成绩，之后再刷一两次就好
<del>毕竟理论上来说这个成绩只有两年有效期挺不到我入学所以不管怎么样都要再考的</del>（</p>
<p>隔壁寝室的姐比我早一周在天津考了托福，今天我出分之后她勒着我的脖子喊果然上海宁就是基础好，我说停停有没有一种可能我小学初中都是念的乡镇学校，高中就竞赛结束后学了三个月英语，结果随机破防了隔壁另一位竞赛落榜生（x</p>
<p>哈哈，大三了，我终于也是有语言成绩的人了（</p>
<h1 id="月16日">3月16日</h1>
<p>早上本来打算去习题课交作业，醒来感受到了比昨晚强烈不知道多少倍的喉咙痛，一量又发烧了。求你了放过我吧，我感觉在某个地方绝对有个人在一边乐一边搞我啊（</p>
<p>先不说别的，我已经四天没喝咖啡了，不仅每天困色特了，瑞幸优惠券都过期好几张了（（</p>
<p>记得之前在转数环看到过有环友说刚发现自己几年来一直没拼对
continuous，结果我今天看 Cramer's theorem for large deviation
的时候突然意识到学统计学了快两年我好像一直把 standard deviation 写成
standard derivative（，当然其实也没怎么写过，一般都在公式里直接表示成
<span class="math inline">\(s^2\)</span> 或者 sd
而已，但就是，我有的时候自己在颅内读出来就是 standard
derivative，狠狠破防了（</p>
<p>下午不烧了，晚上从教室回来又烧了，我受不了了。</p>
<h1 id="月17日">3月17日</h1>
<p>头发好长，再留一留就能发动地鸣了。虽然很热但我暂时还不想剪，想搞一个很久之前就梦寐以求（？）的危险的发型，虽然也未必好看吧（</p>
<p>后感冒症状是不停地流鼻涕还鼻塞，有一种高中的时候过敏性鼻炎的感觉，擤鼻涕擤得我鼻子周围的皮都快破了。然后发现，诶，来北京之后哪怕所谓很严重的花粉季我也没再过敏了，不如上海的春天一根毛。</p>
<p>现在晚上回寝室纸笔都懒得往外掏了，以后争取每周用晚上的时间把计算概率和生存分析的作业写掉，然后平时就彻底不用带电脑了，<del>某种程度上来说</del>
以防在路上平地摔把电脑摔坏（。感觉平板没有那么多容易战损的点，而且我买
Apple Care 了，<del>随便造</del>（</p>
<p>前几天忘记在哪看到协和 4+4
那个培养计划今年的招生方案了，简单来说就是理工科读四年本科然后转去念医学，再过四年毕业也是医学博士，能考执业医师证。诶，我想起来很丢脸的一件事是高三的时候我妈讲如果裸分擦线的话干脆不要零志愿报协和了，不如直接走强基，我当时正苦于竞赛
PTSD 导致我不想学这个 b
数学了，我觉得这玩意既学不会又真的很没用（草，于是这时我感觉突然找到了一个我可以学的东西，我说我不，我就要学医，哪怕裸分过线好几分我也要填协和！然后和我妈关于裸分正好擦线这个八字没一撇的事情居然还吵架吵了很久，我还赌气去看了半天这个
4+4 是怎么回事，感觉哪怕真的强基了也还是有机会转进去的嘛！</p>
<p>直到后来群友问我这个化学和生物水平怎么学医，然后有一个正好比我大一届的群友对我谆谆教诲在华子要补习
35
学分的生物课代表着什么，fine，我就放下了这件事（，还把探微从强基那个志愿表上第三志愿的地方删掉了（。当时如果把服从调剂那个框也顺便反选掉，我现在就在
SJTU 不知道在干啥了，多是一件美事啊（悲</p>
<p>把这件事完整地回忆了一遍之后我比较震惊的是，我高三的时候就觉得学这个
b 数学没啥用（主要是竞赛 PTSD
感觉自己学不会，但也确实在质疑学这玩意干啥），感觉还不如学医有用，真的很超前，比我现在还超前，令人感叹。后来怎么把这个想法给忘了呢（<del>可能还是因为发现别的都学不会吧</del></p>
<h1 id="月18日">3月18日</h1>
<p>早上起来我又一次在寝室大喊大叫陷入崩溃，我问室友，我要怎么样才能让
wwc
相信我真的病了一周，我不是不想科研我是真的没时间，我作业都要写不完了。室友说，你现在这个鼻音的严重程度，去和他说句话他应该就能理解了。</p>
<p>我现在在我不想努力了我明天早十不去了要不干脆把金统也给退了吧，和，逃げちゃ駄目だ逃げちゃ駄目だ逃げちゃ駄目だ，之间反复纠结（</p>
<p>晚上回来我又开始跟室友嚷嚷，我说我之前想买平板就是觉得带个电脑只为了看
pdf
很麻烦，但现在又觉得哪怕只是为了水群打字快一点也最好买个配平板的键盘，还有就是我看论文要到处搜东西的，似乎又是电脑好一点，那不就又回去了吗。室友说，你白天不写代码吗？我说我不写啊，我写的代码都是
trivial 的，帮 GPT
润色一下就能用的，这种事情就不要白天做了，晚上回来摆烂的时候顺便搞搞好了，我写作业都是纸笔的。</p>
<p>室友扑哧一笑，说了一句很伤害我的话：哦哟，二十多岁了还在打数理基础啊。</p>
<p>她想了想又说了一句：你数理基础只打了一半，现在数学基础行了，总算开始学基物了，后面还要打两年物理基础。</p>
<p>我蚌埠住了（</p>
<p>晚上看邮件发现早已忘记这回事的 ESEP 出结果了，果然是：</p>
<blockquote>
<p>We regret to inform you</p>
</blockquote>
<p>搞得我又焦虑了（倒也没有，我真的已经身心俱疲，没有力气应付土木系诸如实习和上课这些破事了。<del>所以我明早桥梁工程要休息了（</del></p>
<h1 id="月19日">3月19日</h1>
<p>在实分析课上读 <del>已经两周没去的</del> 金统 PPT，一边听 Hausdorff
测度一边感叹 ARMA
这个东西真简单啊（。还记得我前几天吐槽为什么要把进击的巨人给格里沙而不是黛娜被锐评别合成大西瓜了，<del>我寻思着
ARMA，ARIMA，ARCH 和 GARCH 不更是合成大西瓜吗</del>（</p>
<p>我怎么感觉这个高统 II 比高统 I 劲大了这么多，早晨起来看助教给我批了个
80 分的作业直接宕机了，我错了我下次一定好好算最终答案（。上周的 slides
到现在还没发，急急急，那我周四去上个啥（。</p>
<p>写实分析作业，又遇到去年在 Stein 见过的
<del>感觉只能称之为是数学题也不知道具体是什么的</del>
题了，还是不会，<del>我蚌埠住了</del> 习惯就好。</p>
<p>晚上回来继续写生存分析的作业，我实在不明白这个助教为什么非要把作业布置在
word 里，就算真的喜欢 word 胜过 LaTeX（不理解但尊重祝福），也好歹把
Excel 的数据复制过来而不是截个图放里面吧（</p>
<p>定番之沙尘暴前一天洗了头，因为不想再洗一次所以戴了个帽子，晚上还是感觉头油油的，难道是戴帽子闷得（</p>
<p>今天在路上普通地走，一辆自行车倒在我面前，听到前面的路人说，纯爱战车应声倒地，我绷不住了（</p>
<h1 id="月20日">3月20日</h1>
<p>今天想打开桥梁工程作业附的 .dwg，想起来我早就把 AutoCAD
卸载了，哑然失笑。转 pdf
打开一看乐了，我有点看不懂他在画一个，呃，是什么情况的一个不知道什么地方。又想了想还是
<del>逃避</del> 先写基物比较着急，打开 PPT 就困了，我受不了了。</p>
<p>是的，清华大学土水学院（强调）以及未央书院（强调）就联合培养出了我这个水平的人（</p>
<p>凌晨手写了一个 life table
estimation，写得我火气色色桑就上来了，如果不是他让我 repeat the solution
with R 我直接把 Excel
做的截图放上去了（<del>抱歉但我其实是做不到的，我的强迫症实在不允许我模仿助教</del>（。我寻思着我那么大一堆
R package 怎么就找不到一个 censorship at the end of interval
的处理能调包一秒轻松解决问题，但确实是找不到，只有
<code>biostat3::lifetab</code> 是 middle of the interval
的做法，<del>是否说明实际上没人会纠结这种问题但这个真空中的球形鸡一般的作业就是把这个当做考点</del>（</p>
<p>这周生存分析的作业写了三个摸鱼的晚上，总算是交上了。今晚开始写基物，明天加急写基物，后天晚上开始写计算概率，<del>周末加急催何老板写一下桥梁工程（</del>，只要这些能在周一晚上之前写完，我就闭环了，以后白天就只要操心高统实分析和科研（草这也太多了吧）顺带还得听课和写写笔记就行了（。上学期何老板跟我说他白天上班晚上学习，我还觉得怎么这么猛，现在也（隔几天）体验一手（</p>
<p>下午读了一篇论文，读得我吱哇乱叫，大受震撼，总算读完（其实定理证明还没看，R
code 写日记之前才刚刚打开）之后打开另一篇，感觉好了很多（，果然
Biometrika 还是短，太温柔了。</p>
<p>骑车回去的路上想了想，后面要系统地学的数学课其实只有泛函，复分析和概率论
3 了（<del>PDE
这种为了替代数理方程而不得不上的除外</del>，其余就是随便选选课听个乐。别人实复概只学一个学期，我每年一门搞到最后学了三年（<del>其实复分析我真也没有很想上，只是感觉此前没学过工科的复变函数又不去上个复分析的话，很难说自己是学数学的</del>（。但这个进度完全是用这两年来在主修专业作为一具保持最低生命体征的尸体（i.e.
每学期只选 6
学分培养方案课程）换来的，一想到后面还得还这个债，有点崩溃了。</p>
<h1 id="月21日">3月21日</h1>
<p>wwc
把这个题目给我的时候还说可能会用到一些概率图模型和随机矩阵，还殷切关照我有没有把
Durrett
学完，结果看下来我感觉这个只和线性代数关系比较大，而我的掌握只能说是烂。</p>
<p>这个高统作业，它怎么就这么麻烦，我以为今天可以下午把 PPT
看完作业写完然后晚上把基物写掉，结果一直到教室关门都没把高统作业写完，fine，fine。</p>
<p>我昨天只是看了篇
paper，上周只是生病了，我没有杀人放火吧，怎么现在什么作业都交不上啊（</p>
<blockquote>
<p>室友：好多 1 啊</p>
<p>我：哪里哪里哪里哪里</p>
<p>室友：网络学堂的课程作业</p>
</blockquote>
<!--刷统计中心的公众号发现合影上面 wwc 穿了件泰迪熊卫衣，没绷住（，等我把总结交了就有脸去上课了，下周看看是不是还泰迪熊。-->
<h1 id="月22日">3月22日</h1>
<p>受不了了，昨晚熬夜写基物作业，今天通知基物第七周周三或者周六就要考期中，虽然这玩意能早点考掉也算一件好事，但我是真的学不会，除了把作业题全背下来，真的，别无他法（</p>
<blockquote>
<p>室友：你早点睡吧，明天的作业交得上今晚就别熬了</p>
<p>我：我每天晚上都在努力把一个网络学堂的 1 掰成 0 然后才能睡觉（</p>
</blockquote>
<p>从开学到现在掉了七八斤了，于是今天上完体育课点了杯茶话弄去教室一边崩溃一边赶作业，<del>在奶茶里面算是热量不怎么高的了所以放过我吧，今天又没喝咖啡，喝杯奶茶怎么了</del>（。感觉现在是一个不喝点什么就没法好好学习的状态，怎么会是呢（</p>
<p>为什么这个咳嗽和鼻塞还是不好，急了。</p>
<h1 id="月23日">3月23日</h1>
<p>今天读了另一篇 graphon
estimation，就，每个操作都在意料之外但又情理之中（，很难说。后天争取把总结写完，周二就有脸去上课了。但我觉得很悬，光是把我批注的问题搞清楚都不知道还需要查多少东西。</p>
<p>我只是又读了一个下午论文，晚上去答疑坊值班的时候我甚至在看基物 PPT
写物理作业，但我现在为什么有五个作业没交呢，就是说，这是一个什么原理呢。</p>
<p>我现在感觉可能计算概率得退掉了，一个只有作业没有考试的课记 PF
总觉得有点亏，但我真的扛不起生活的重担了。</p>
<h1 id="月24日">3月24日</h1>
<p>上次还在骂生存分析的代码作业，结果金统的 R code
写麻了，又写了三个晚上，我转不起来了，真要退计算概率了。</p>
<blockquote>
<p>我：绷不住了呀 作业拿 ARMA 预测后两周的上证指数</p>
<p>友：是桑海宁就给我直接写 5000</p>
<p>能预测准吗</p>
<p>我：哎呀 反正就是三千点多一点 也差不太多的</p>
</blockquote>
<p>下午满怀疑惑地把桥梁工程的作业做了，就，我要是第四周就已经会设计桥了，那我还上你这课是要干什么呢（</p>
<p>这个高统 II 怎么比 I
难这么多呢，明明只是换了个老师讲同一本书的后半部分。可能难度主要来自换了个助教（，他会认真出一些找不到答案的问题，还批的很严格，急急急（</p>
<p>感觉得纠结一下明天是学实分析还是开始写总结，不出意外的话周二还是没脸去上课，然而一切的前提是今晚真能把高统搞完（。想起来上学期上建筑材料的时候听到有个哥们在抱怨，说，我现在就觉得像不会游泳但是掉进河里了一样，时间一周一周地过去，就像一个一个浪打过来，我就只能勉强浮在水面上不沉下去，上岸是不可能的（</p>
<p>似乎还有点过敏了，本来昨天觉得咳嗽要好了，今天又重了很多，严重的时候感觉喘不上气来（</p>
<h1 id="月25日">3月25日</h1>
<p>之前听说厚乳拿铁里面也还是有白砂糖（主要是厚乳里面有），但毕竟很少，不过还是换澳白喝了几天。现实是喝了三次睡了两次（，口感也水水的，还是换回厚乳拿铁了，所以你这厚乳里面到底是加了什么（。听说澳白如果点热的味道会浓一点（或者说原教旨主义澳白就不能做冰的，但我实在不喜欢喝热饮，自己泡咖啡坚持不下来也主要是因为没条件冻冰块，再说就算有能冷冻的冰箱也远远比不上店里用制冰机做的冰，感觉不如买瓶装或者直接就瑞幸了。</p>
<p>熬夜把高统作业磨蹭完了，有个实在不会做的题到网上到处乱找，最后又是在
lty 的主页上找到的答案，<del>PKUnb</del>（。一看上来先把 prior 取成
inverse Gamma，这什么东西（，我还搁那用指数分布族一个个试，拿头做（</p>
<p>开始写（只有两篇 paper
的）总结了，发现之前还有理解错的地方，没懂的地方也在一个一个看。写了四页，刚把
background 和一些用到的背景知识（比如说我以前真的不知道什么是 spectral
clustering）记好（毕竟这个我也要看的所以记一下也不丢人罢（，graphon
linear estimation 还没有开始写 oracle-based analysis
的程度，已经四页了，什么时候是个头（</p>
<p>我感觉这学期非常不妙（各种意义上（</p>
<p>早上起来重新修了一下昨天造的桥，我抽象锐评，怎么看都总有一种艾伦的始祖巨人的既视感（，就是，把上拱当成肋骨，左边是垂下来的头，右边是腿（（</p>
<p><img src="https://s2.loli.net/2024/03/25/3AijYgwn45rOhXW.jpg" alt="Eren_Titan_.jpg"></p>
<p>诶，这个桥，缩小一点看感觉还不错的样子。</p>
<p>下午上生存分析的时候不知道为什么突然又焦虑延毕之后能不能顺利毕业了，于是重新排了一下后面两年的必修课课表，大概是秋季每学期要上五六门专业课的程度。春季倒是没什么课（如果明年春季要春研也能勉强安排得过来），要学的数学课也没剩多少了，主要就是多花时间磕盐。我感觉我像是
gap 了两年，马上要回去正经上学了。</p>
<!--晚上我又一次在寝室大喊大叫：-->
<blockquote>
<!--我：我现在真的没时间做科研啊！你们都在用什么时间做科研，我把睡觉的时间拿出来都来不及看论文，两篇 biometrika 加起来还不到 30 页，我搞了三周还没搞完，还遥遥无期，说出去真的好丢人啊！-->
<!--我：最搞的是什么，就是我到现在这个总结写了一半了，诶，我导师都还没有把我拉进他那个学生群里（我知道这个东西是存在的），我都还没有他的微信，我万一论文看不懂还得邮件问他，所以我都靠自己尽力看懂了。-->
<!--我：我感觉我像是在做小三，就是类似于那种微信上都不能正式联系，只能用一些非正常手段暗送秋波的小三！我什么时候能转正啊，还是说我要是不保研去他那边的话就要永远当小三了？我靠，他今年招的那个零字班的大哥都进他的群了，说明我的地位还是一个，垫底的状态，别说小三了，小四小五小六我都没当上，毕竟他在九字班招了俩博士生呢。-->
<!--室友：（关上门）你别开着门喊你在做小三！万一我们寝室连着门牌号被挂树洞了怎么办！-->
<!--我：（打开门）我今天就要丢这个脸！凭什么只有小三会丢脸，我导师让我做小三的，我一颗真心，我被骗了，丑恶的难道是我吗？凭什么骂小三啊！-->
<!--室友：啊啊啊啊啊你不要越描越黑啊，人家刚刚只听到你在做小三，现在变成你在给导师理直气壮地做小三了（锁门）至少你做小三不要害我被误伤！-->
</blockquote>
<h1 id="月26日">3月26日</h1>
<p>现在就是一个，诶，非常的疲倦。</p>
<p>把 graphon estimation 那一篇写了，还剩另一个 clustering
的，目前的进度是还在研究 k-means clustering 和 spectral clustering
各自是个什么情况的状态。有的时候真挺想打个电话问问作者，你们这样子做
approximation
真的没问题吗真的不害怕吗？我看着都害怕。还就真的没问题，bias 和 variance
都控住了，data analysis 结果也挺好（</p>
<h1 id="月27日">3月27日</h1>
<p>报了下丘赛，虽然未必去考（，不能带 cheatsheet 的话我是一个背 Delta
Method 都费劲的状态，大概就这个水平，也没空（</p>
<p>今天歇了一天，写实分析作业和基物作业，然后两个都没写完，麻了。</p>
<h1 id="月28日">3月28日</h1>
<p>又歇了一天，还是没写完。基物这个作业对着书倒也确实可以勉强做出来，但是考试没书也没
cheatsheet 怎么办呢（（</p>
<h1 id="月29日">3月29日</h1>
<p>又活了一周，真不错，这周末要是还写不完我那个总结的话感觉就很难活到下周了（</p>
<p>为什么这学期写了这么多码啊，虽然也挺好毕竟确实该练练了（。但这周开始的时候好像刚把金统的写完，写金统之前才刚写完上次生存分析的，今天上课把上周计算概率的写了（感觉强度并不大，大概还是不退课了），课上就一直在写，体育课上课之前在写，上完课回来又在狠狠调一个正负号，晚上写完实分析回来又写了计算概率这周的一道题，写了一半这次生存分析的作业。之前看论文感觉有必要去看一下他那个
Rmd 来看看我到底理解对了没有，看的时候感觉好疑惑，又开始调（（</p>
<p>从生病之后鸽了两次计算概率，今天一去：</p>
<blockquote>
<p>：今天是第五周，是单周，那按惯例辟谣一个小道消息，关于本科生申国自然的
blahblah</p>
<p>：我们早点下课，因为我下午就要去曲阜了，我现在是本科生事务主管所以得跟着（</p>
<p>：中央音乐学院还为这个活动贡献了一首歌，我们待会课间放一下！哦对了，我感觉下周应该可以给大家放一个现场的视频！</p>
</blockquote>
<p>今天看到一段对话：</p>
<blockquote>
<p>A: 求问基物 3 pyk 期中期末考的内容是和教材关系大还是和 ppt
关系大，感觉这俩差别好大</p>
<p>B：ppt 和作业</p>
<p>C：作业</p>
<p>D：其实跟往年题关系最大</p>
<p>B：还真是</p>
<p>C：确实</p>
</blockquote>
<p>我第一反应：有的人还在对着相关性找 dependent variable
和考虑要不要把它们放进模型做回归的阶段，有的人已经直接上 auto regression
了，感觉受到了启发！（指对于我的基物期中（虽然我是基物 2</p>
<p>晚上回来开幕雷击，东京工业大学暑研的邮件是 Congratulations
开头的（。本来这两天还在苦恼要怎么无痛延掉施工实习，都差点想去交钱申暑期短课了，好好好。不知道为什么我这次申暑研毫无动力，主要还是并不是真·暑研吧，就按华子的官方项目申了俩，录取率
50%（喜</p>
<h1 id="月30日">3月30日</h1>
<p>你还别说，我上次说觉得好像看论文看半天没理解对一个比较基本的问题，昨晚看了会
Rmd
感觉更不对了，今天又仔细读了读文章发现真不对，草。不过这样一来我终于理解他说的那个
strong consistency 是什么意思了，我之前一直百思不解的是，这和 statistic
sequence 的那个 consistency 到底能有什么关系，把自己蠢笑了（</p>
<p>明天一定把总结写完，再写不完真来不及了，真的，不知道为什么考了一个托福生了一个病，然后看了两篇论文了解了一个问题的框架之后就要期中考试了，我是大废物（</p>
<p>第七周周三基物期中，第八周周一生存分析，实分析不知道什么时候，但我感觉这玩意强度远低于去年，或者说习题和习题课强度远低于讲义正文，我在讲义看得晕头转向忍无可忍跳过证明的情况下还能随手鲨习题，就，不太好评价。</p>
<p>总之我受不了了（强装平静</p>
<h1 id="月31日">3月31日</h1>
<p>月底了，来欣赏一下这个月喝了点啥（去医院看糖尿病的时候记得带上你那破本子.jpg</p>
<p>这个本子是美赛的时候数学系发的纪念品，还一次给每个人发了四本 2024
年的计划本，摸不着头脑了。不过我发现贴咖啡标签正好，不如拿出来用一下。</p>
<p><img src="https://s2.loli.net/2024/03/31/8pIh6KlgGuw3bdA.jpg" alt="2024.03.jpg"></p>
<p>基本全勤了，3.13 到 3.16
在生病没喝咖啡，喝了三杯茶话弄当感冒药（，芊芊绿雪和云过处后来又回购了两次，便宜好喝，不加糖不是很好喝但比较有安慰感。周五一般都会有一杯茶话弄是因为体育课真的累，而且如果早课咕掉了的话也没必要再喝咖啡，不如整一杯奶茶。瑞幸的话，我一般不喝美式折磨自己，对生椰系列也没什么兴趣，就还是厚乳拿铁和澳白喝得最多，厚乳是很困的时候喝，澳白在不是很忙可以歇会或者睡得比较多的时候喝，不过理论上来说还是澳白更健康一点。</p>
<p>可以看出来撕瑞幸标签越来越娴熟了，一开始每次都撕坏，后来掌握了一个技巧是喝完之后把冰块倒掉，稍微用热水从里面浇一下杯壁，很容易就能撕下来。</p>
<p>我职业病犯了，统计了一下取餐号，还有点单时间，就是不知道怎么把这两个结合起来分析比较好。随便用
R 跑了一下，目前还没有重复的取餐号，但是有一对只相差 2，是 <span class="math inline">\((485,487)\)</span>，还有两对都只相差 4，是 <span class="math inline">\((613,617)\)</span> 和 <span class="math inline">\((485,481)\)</span>。虽然 <span class="math inline">\((481,485,487)\)</span>
非常接近，但点单时间可以说是毫无关系，只不过都是厚乳拿铁。考虑数字重新排列的话还有
<span class="math inline">\((617,167,761)\)</span> 和 <span class="math inline">\((841,481)\)</span>，到现在为止 481 和 617
出现频率谜一样的高。没有买到过取餐号是 3 开头的咖啡。</p>
<p>别搁这玩了，总结还差一个 statistical lower bound
的东西仍然存疑，周一上午总要用定时邮件发过去的，快去写罢（。明早还要去办护照，还得早起一点画个淡妆然后处理一下刘海和披发的问题。之前查了一下虽然申领流程可以在校内办，但校内没有邮寄的选项，之后还是要跑到阜成路取，受不了了。</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇廿二·24年6月</title>
    <url>/2024/06/01/Diary-2024-06/</url>
    <content><![CDATA[<p>我以后真的不选这么多课了，这学期期末怎么会变成这样。</p>
<span id="more"></span>
<h1 id="月1日">6月1日</h1>
<p>如题（</p>
<p>原汤化原食，开始用去年实分析作业的背面打草稿做今年的实分析作业（</p>
<p>晚上回来围观室友改简历，原来把课上做的项目写简历上是正常现象的吗（，想了想又觉得我好像连课上做的项目都没有（难不成金统这个能算？），这是怎么会是呢（（</p>
<blockquote>
<p>室友：我后来想了想还是把系里夏令营的报名撤了 因为我确实不想读博</p>
<p>首先我没什么学术追求，我的水平也没资格谈这个，其次钱对我来说真的很重要</p>
<p>我：我也是！</p>
<p>室友：是吧！我目前的烦恼都是钱不够导致的，暂时还没有什么用钱解决不了的问题</p>
<p>所以我去搞卓越工程师咯！</p>
</blockquote>
<h1 id="月2日">6月2日</h1>
<p>想来想去，期末这日子过成这样，基物可能需要负主要责任（。</p>
<h1 id="月3日">6月3日</h1>
<p>生存分析 pre，把高统 2
的东西搬过来狠狠装了一下，掩饰我根本没多读任何相关工作这件事（（</p>
<p>开始写金统
cheatsheet，有一种很快就能搞定然后去搞高统的感觉，又觉得现在不应该这么闲吧，难道不应该先开始复习实分析，至少往后写点作业吗（</p>
<h1 id="月4日">6月4日</h1>
<p>不是你这实分析这周要把第七章课后题写完是什么意思（。虽然说第八章不考（<del>但我总觉得完全不排除
lxg
第十六周心血来潮把它讲了然后考的可能性（</del>，但第八章本来就只有十来页啊（</p>
<p>金统 cheatsheet 写完了，这课又简单又难的，原理都水得很，但要全考实
<del>证</del>
分析的话恐怕有点（。下一个是高统，本来以为合同法是闭卷随便看两眼 PPT
差不多得了，结果这下可以带法条，蚌埠住了，又多一个 cheatsheet
要做（（。最需要 cheatsheet 的难道不是基物吗，凭什么就它没有（</p>
<p>感觉稍微可以喘口气了，但也完全不能摆，总之再熬两周就放假了（什么原来后两周要干这么多破事啊（（</p>
<p>昨天今天都没来得及在下午第一节课之前去买瑞幸，昨天在售货机上随手拿了一瓶星巴克美式，结果那个味儿实在是给我恶心到了（，为什么要演奏春日影，啊不是，为什么要在
0
蔗糖美式里面加赤藓糖醇？我真的一直郁闷到晚上，心情太差了就点了杯奶茶，惯性定律果然今晚又点了杯奶茶（。</p>
<p>最近每天晚上洗完澡一边吃东西一边看两话巨人然后才想干活，最速二刷了属于是。感觉可能是第一遍看的时候被唬到了，我承认第三季
part 2 很强，但 part 1 就这（，也就是个
8。反而之前以为单纯是个过渡回的第二季单看不屈的誓言就值得给个 9（</p>
<h1 id="月5日">6月5日</h1>
<p>真的要熬穿了，其实还是有点干不完，想到基物光学也要考心里就有点发毛，何况量子学得也不咋地。但如果只是背诵
PPT 的话应该就还好（？），或者说恐怕最后会变成只来得及背诵 PPT
上划的重点了吧。昨晚熬夜写实分析作业和金统 cheatsheet，白天又在写高统
cheatsheet，明明睡得不少还困得不行，看到以前会做的题目现在莫名其妙不会了，感觉到前所未有的疲惫。</p>
<p>我倒不会说是之前太摆了导致现在变成这个样子，我确实没觉得这学期什么时候真的很摆过，如果读论文不算在摆的话，可是论文也就读了三四篇。那么答案显而易见，大约并不是选了太多课导致的，而是能力不足。所以说如果这学期
GPA 没有很难看的话，下学期就不选高代 1 刷分了（</p>
<p>还好金统大作业延到 22 号了，等我 21 号晚上考完还能写 15
个小时（。代码基本上已经跑通了，感觉单纯是把剩下的废话说完的话这点时间能写得完，还就那个比美赛不知道轻松到哪里去了。或者说考完
19 号那两门之后其实也就可以开始搞了，无论如何现在压力稍微小了点。</p>
<h1 id="月6日">6月6日</h1>
<p>实在想不出来高统 2
要怎么考，是一个他要是考按定义计算和通过计算证明的话可能还好，但 MLE
那一坨东西我连模仿证明都做不出来的情况，学第二遍也不会。</p>
<p>有点小破防，然后摆起来了，这样不行吧（（</p>
<p>今晚摸鱼把进巨第三季 part 1
最后一话看了，王政篇除了政变之外的内容确实都是 8~9 分水平（，平均一下 8
分差不多。明晚开始玛利亚之墙夺回战，看看有没有可能真给 part 2（连同 EVA
TV，真心为你和猫鼠一起）调到 10 分去（（搓手（#<del>每日调分</del>
<del>这下 10 分要变水了，不如把赛马娘第二季也抬上去吧（x</del></p>
<h1 id="月7日">6月7日</h1>
<p>这高统 2
复习得我感觉自己还就那个好没能力，应该去读个硕然后直接找工作，就，学了两年数学还没这么崩溃过（，从来没有因为学数学半夜哭出来，上次这样可能还是大一搁那儿深夜和
OJ
左右互搏（。真不能再这么上课了，但又很难说集中精力科研会不会更崩溃，是否更应该少走弯路了（</p>
<p>好黑暗的日子，我真觉得我精神状态有点要出问题了，然而这个期末还有两周才熬完。后两个学期的学分都不算多，算了一下哪怕这学期爆炸
GPA 也还算
robust，只是不知道延期施工实习会不会导致给分出问题，还得留余地。最糟糕的情况下基物靠背题目混过去拿个低一点的成绩，尽力保护住数学课这样。</p>
<p>查了下网络学堂，上学期除去几门课公布成绩，一共交了 48
个作业，这学期到现在已经 64 个了，还活着就挺好的。</p>
<h1 id="月8日">6月8日</h1>
<p>我好没能力.jpg，不过看看实分析又觉得比较有能力了（？</p>
<p>很累，但晚上完全睡不着，在床上挣扎到五点钟起来把桥梁工程作业写了，写了两三道基物，然后倒头就睡（。天气也直白地热起来了，不过完全不如去年端午，痛苦回忆.jpg。中午出门感觉好虚，一热就更难受了，还是没自己去买咖啡，瑞幸外卖点不起，库迪
app
外卖竟能用美团到店券，好文明，虽然配送高了点但也还能接受，最近大概要依赖下咖啡外卖了。</p>
<p>我好像下雨的时候从来不记得带伞，但是太阳一晒就能记得带遮阳伞了（</p>
<h1 id="月9日">6月9日</h1>
<p>想来想去感觉下学期真得搬走了，反正延毕会导致至少要搬一次家，不如下学期就直接搬走，在这儿继续住我是真的天天都睡不着。当然，从大一上学期期末开始我就想换宿舍了，一直没动多半是懒且意志不坚定，所以为了坚定决心，我晚上回来跟隔壁寝室的一个姐在中厅里嚷嚷了半天，四舍五入大家已经都知道了，那就是必须得走了（。</p>
<p>一会感觉能复习完，一会又觉得不能，还是先看看周二考的两门课吧。金统的
cheatsheet 是周二做完的，周日的我：这课是干啥的来着（</p>
<h1 id="月10日">6月10日</h1>
<p>摆了（</p>
<h1 id="月11日">6月11日</h1>
<p>我是真的会因为夜里睡了半个小时醒来就睡不着了而哭出来（，好崩溃（</p>
<p>这金统在考啥（，我做 cheatsheet
的时候就在想把东西都塞上去是想考试的时候现学吗，结果真的现学了，<del>希望高统
2
也能来得及现学</del>。虽然怪没底的但反正也就这样了（，他但凡拿出上学期高统
1 薄纱大家的那个状态呢（x</p>
<p>合同法挺摆的，它到底是不是一个 PF
的课啊，怎么到结课了也不是很清楚这个问题（</p>
<p>你说得对，但是我高统 cheatsheet 还没弄完，怎么会是呢（（</p>
<h1 id="月12日">6月12日</h1>
<p>急，摆（</p>
<h1 id="月13日">6月13日</h1>
<p>现在是 6 月 13 号（</p>
<p>这高统折磨了一学期，期末竟是抄写和计算大赛（。虽然平时比较 push
能学到很多东西，加上考试不为难人确实是非常非常好的，但还是整得我又气又乐的，大概最近真的太焦虑了（</p>
<p>昨晚是一个月以来睡得最好的一晚，记之。不过下午还是因为早上抄写太累了睡了会，晚上没忍住在早晨喝过咖啡的情况下又点了个奶茶，唉（（</p>
<p>基物怎么办，急（</p>
<h1 id="月14日">6月14日</h1>
<p>好困，怎么会这样，这能复习完吗（</p>
<h1 id="月15日">6月15日</h1>
<p>一整天只学基物的话效率好低，但实分析其实也不是很想学（。它看起来一副只考期中后的样子，虽然考前提示里那个默证我一上来就没绷住（</p>
<p>唉，其实还有个大作业没写完，怎么会是呢（</p>
<h1 id="月16日">6月16日</h1>
<p>最近感觉整个腿脚都是水肿的，实在很难受。一个是休息得不好的体现，另外也真好久没怎么锻炼了，体力差了很多。没在减脂甚至也努力多吃饭了，体重还是一直掉，期末考完是否该去绕绕圈了（<del>但这个天气真别在户外锻炼吧</del></p>
<p>唉，我妈今天问我为什么没考阿赛（，还把入围名单里一些上海的年级相差不大的竞赛生都找出来了（。我不好说，但我确实对阿赛丘赛啥的都没太大兴趣，说好听点是精力有限，很多东西学完考完期末就不想二刷准备比赛了，投入大量时间学不到很新的东西，感觉不如读点文章有用，但可能本质上还是竞赛
PTSD 导致的（</p>
<h1 id="月17日">6月17日</h1>
<p>我现在感觉进巨最终季 part 1 也挺好的，马莱篇文戏是真那个有 9
分水平，至少比第二季和第三季 part 1 强（。但它评分只有 7.7，我理解是
MAPPA
画面相比霸权社实在不行，以及放送的时候漫画快出到结局了，这一季里还有谏山创手刃莎夏（，<del>所以说这下更不得不打
9 了</del>（</p>
<p>到底要不要调一波分呢，急（。说实话现在我打 9
的里面有几个如果再看一遍很可能就不会给 9
了，所以我打算不去二刷（，的这么一个情况（，另外也有再看一遍大约也不会动评分的。这样的话把其他真的很喜欢的拉到
10 区分出来大概也挺好的（</p>
<p>今天把光学看了，又拟合了一下原子物理的几个题。唉，这基物赶紧考了吧，多给一天也学不进去啥（</p>
<h1 id="月18日">6月18日</h1>
<p>如果我现在大一，明天要考两门四学分的课，大概已经昏过去了。但我现在大三下了，所以我今天玩了一整天，这怎么不算一种成熟呢（</p>
<h1 id="月19日">6月19日</h1>
<p>基物至少连着看了五天，喜提四学分
3.3，实分析就看了两个下午，一个小时做完了，唉（</p>
<p>想了想一年前还在选没人选的课选课法，主打一个不和数学系一起上课而是混在数辅里面，否则感觉考不过，现在已经如果我不是数学壬的话那这里大多数人也都不是.jpg
了（</p>
<p>虽然后半学期学得依托，Fourier
变换的题也不一定做得出来，好像也没有几个提前交卷的，但感觉考试的时候但凡把空调打开，也不至于做完六道题扔下附加题直接闭眼开睡（。可以交卷之后速速拎包跑路，还把水杯落在桌上了（（</p>
<h1 id="月20日">6月20日</h1>
<p>桥梁工程看了一天就差不多看完了，反正对我来说也就是复习一下之前看懂了的部分，不懂的也不太可能懂了（，随便考吧。这样的话有望提前一点把大作业写完，然后这学期就下班了，真是个漫长的噩梦。</p>
<p>这两天晚上稍微轻松点了，二刷进巨的速度变成了一晚上三话（。第一次看的时候觉得不咋地，现在感觉马莱篇质量是真的高，<del>突然有点想不通为什么第三季
part 1 比最终季分数高</del>（</p>
<h1 id="月21日">6月21日</h1>
<p>结束了，不用再战斗了（</p>
<p>昨晚熬了一下把金统大作业差不多写完了，待会稍微再改改就交，下班了。</p>
<h1 id="月22日">6月22日</h1>
<p>啥也没干，收拾了下寝室，晚上教（前）室友速通了一手假设检验和线性回归，本来以为会搞到很晚，结果离教室关门还留了
2h，遂开始手机 b
站看魔圆（。虽然比较担心看到了正版番剧（，但是急，而且也没啥事干，算了（</p>
<p>我评价：这玩意是 EVA，进巨和 FZ 三合一吗（</p>
<h1 id="月23日">6月23日</h1>
<p>一离开北京，整个人就好多了（喜</p>
<h1 id="月24日">6月24日</h1>
<p>14 周的时候虽然这个期末已经乱成一锅粥只能趁热喝了，但抽空听了一下
Weijing Tang 的报告，感觉这个 signed network model
看起来还蛮有意思的（。今天读了一些她引用的文章（</p>
<p>这么说来下次可以找机会把 14 周我咕掉的那节生存分析的课听一下（。</p>
<p>二刷了娜娜家，虽然还是很不错但总感觉没上次好吃了（？），难道这就是相见不如怀念（。上次的柠檬鸡和这次的烤翅味道都一般般，但咖喱很好吃，薯条分量很大，下次（如果还有下次的话）把肉换成土豆泥之类的小食或者干脆去楼下鲜芋仙吃个甜点吧（。</p>
<h1 id="月25日">6月25日</h1>
<p>到今天为止已经三天没喝咖啡了，每天都睡得很香，日均睡眠九小时以上，我觉得可能自然状态下就应该睡这么多（</p>
<p>大概也不是没喝咖啡的问题，昨晚晚饭后喝了杯奶茶一样睡得很香，主要还是没在寝室住了吧。</p>
<p>西塔老太太好吃，但最好吃的是免费的土豆泥（。虽然在天津一顿吃出了上海的人均稍微有点不满，但毕竟连锁店，口味也是熟悉的偏甜口，沪人狂喜。</p>
<h1 id="月26日">6月26日</h1>
<p>去了下天津博物馆，本来还想着心情好的话顺便去下旁边自然博物馆，结果一个是起得太晚来不及了，另外虽然没法苛责什么但天博确实是我去过最不行的省博（。）了。</p>
<p>而且旁边万象城那家九龙冰室，怎么能把菠萝咕咾肉做得那么难吃，不如文通冰室一根。那个双皮奶端上来尝了一口我就觉得有点不妙，这家店不像是很会做饭的样子（，果然是在天津踩到的唯一一个大雷。难道去吃粤菜就只能点烧鸭饭或者叉烧吗（</p>
<h1 id="月27日">6月27日</h1>
<p>回北京了，在城际铁路上就已经感觉到悲伤了（（</p>
<p>回寝室打扫卫生，收拾东西，看了点番（？），准备后天飞南昌了。</p>
<p>已经连续五天没喝咖啡但精神饱满了，原来日均九小时睡眠是最好的咖啡因（乐</p>
<h1 id="月28日">6月28日</h1>
<p>现在是 6 月 28 号晚上十一点十二分，航班不到 3/4
天之后就要起飞了，但我的行李箱目前还是空着的，更别提下楼试称重了，这是怎么一回事呢，我啥时候变成
P 人了（（x</p>
<h1 id="月29日">6月29日</h1>
<p>是的我是第一次坐飞机，某种程度上也是不想第一次坐飞机是在暑研的时候（为什么）所以这次飞了，当然北京到南昌的高铁本来就贵得离谱所以飞机确实省钱。</p>
<p>然而这个雨下得（，真的疲惫了，早上起来收到了延误 3 小时 20
分钟的通知，到机场之后首都机场这里开始雷阵雨，预定起飞时间的时候广播说飞不了先别排队了，过了十分钟开始登机（。登机之后又是漫长的飞不了，十点钟的时候广播说暂时飞不了先别急，于是我给我姐发了条消息说别出来接我了，我啥时候到了自己来就行，两分钟后突然起飞，等我反应过来的时候机头已经抬起来了，早已飞行模式但也不敢再打开流量了（</p>
<p>昨天还在想为什么要提前预定特殊飞机餐，订的还是低脂餐，就这么喜欢鸡胸肉吗。结果毫无胃口的晚上十一点拿到柠檬味的鸡胸肉，没什么味道的全麦包，以及沙拉和水果的时候，我还是感觉比旁边半夜吃宫保鸡丁饭的人要幸福一点（</p>
<p>一点钟到昌北机场，惴惴不安地打了个网约车，司机先让我从平台取消订单，我寻思着我平台打车不就是图个有监管吗，遂拒绝，同意把平台的抽成额外打给他；然后一看车牌号和高德上显示的也不一样，汗流浃背了，拍了发给我姐。行李放进后备箱之后司机突然说这一单要拼车，和一位提公文包的中年男子，我立即跳脚破口大骂，说要拼的话你拉他一个人走，我把行李拿下来，虽然骂完有点后悔怕挨打（，但可能我距离比较长能多赚点，司机真听我的了，就开走了。到我姐家之后还是觉得蛮汗流浃背的，就是，但愿以后别再遇到这种半夜打车的情况了（</p>
<h1 id="月30日">6月30日</h1>
<p>睡到中午，起来去了省博，布展真不太行，全混在一起没啥记忆点。下楼去文创店看了一圈，这都啥（。现在越来越觉得在河南省博钱花的还蛮值的（。</p>
<p>在江西省博转了一下午，感觉把今年能看到的小孩都看完了，反正你赣的生育率不怎么是问题（迫真</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇二十·24年4月</title>
    <url>/2024/04/01/Diary-2024-04/</url>
    <content><![CDATA[<p>我超怎么现在就有蚊子了啊啊啊啊啊啊啊啊啊</p>
<span id="more"></span>
<h1 id="月1日">4月1日</h1>
<p>终于把总结交了，凌晨两点钟已经是一个半梦半醒的状态了，越看越觉得我验证出来有点问题的一个矩阵计算真的有问题，于是把它写进了总结里面，白天也没想着再看一眼就给
wwc
发邮件了，想起来这件事的时候蚌埠住了。我现在都没有勇气再打开那篇文章和我写的总结研究一下到底是不是真的有问题，但其实问题不大，我只是觉得每个
extended covariate 前面那个系数并不是完全相同的，但改一下总之还是能做出
Cholesky 分解的形式 <del>而且还能体现 node
heterogeneity！</del>，就无所谓了（（</p>
<p>话是这么说，但是邮件被已读不回了，虽然这很正常毕竟它真的很长，但我现在真的是很难不害怕（x）。我明天又有点不敢去上课了，但又不敢不去（，大概就是这样的一个状态。</p>
<p>早上去办护照，照澜院的派出所倒是对发型很宽容，允许披发和刘海拍照（当然也没到盖住眉毛的程度。就是不知道为什么我早上起来化妆半小时，拍出来还像通缉犯捏（</p>
<p>悲报：清芬瑞幸关门了，我今天是骑车去清华科技园那家瑞幸取的咖啡，就是不知道有早课的话要怎么办比较好。现在是真的有点喝不得瓶装了，既没有冰又含很多糖还不是现做的价格也差不多，这怎么喝嘛（（</p>
<h1 id="月2日">4月2日</h1>
<p>昨天问教务才知道施工实习需要用学校官方的暑研项目（只有这种才有批件）申请延后，我歪打正着因为懒得自己找也没什么办法找暑研，就只投了两个官方项目，正好中了一个，暑假就可以歇了。</p>
<p>但现在的问题是，明年还有这么好的运气吗，那我是不是最好今年寒假去把它解决掉。但如果寒假补实习据说给分会比较糟糕，也不知道过年期间能不能给放假，虽然这些事情找零字班问问就好但我问的那个学长怎么不回我（。何老板在用暑期课程申请替代，倒也可以看看他的情况，如果成功了的话明年学一下就行，不成功的话，我真的不知道是今年暑假去实习好还是寒假补实习然后顶四学分低绩点好，比较缺乏信息的一个状态。</p>
<p>好累，好累，好累好累好累。科研感觉得暂时咕一下而且最近也没什么活（<del>如果我不去自己找活的话</del>，下周三就基物期中了，我还是一个你问我波长是啥我只能干两碗饭的程度（</p>
<p>尤其是昨天今天加起来写了 23
道实分析，梦回抽代（<del>但难度其实也差不多就梦回抽代</del>，我尸体真有点不舒服了。诶，但我周三近似于没课，所以说清明假期已经开始了，嘿嘿。</p>
<h1 id="月3日">4月3日</h1>
<p>感觉，打开一个搁置了三天以上的 overleaf project
需要非常大的勇气（（</p>
<p>节前把目前所有的作业写完了，<del>每个难缠的 1 终于都乖乖变成了
0</del>。我现在明白为什么周三效率最低了，因为这一天要写基物作业，一边呜啊呜啊一边写，写完之后都得缓好久。今晚在预习（x）基物，努力理解了一下偏振到底是在干什么，所以说，波长到底是什么来着（（x</p>
<p>晚上洗澡的时候旁边两个人在说：</p>
<blockquote>
<p>A: 我今天终于去做实验了，这是我第一次杀小鼠，我一次杀了八只！</p>
<p>B: 是不是你的师兄师姐杀不动了</p>
</blockquote>
<p>路人害怕.jpg</p>
<h1 id="月4日">4月4日</h1>
<p>学习偏振，在我完全理解一切和我啥也没明白之间反复横跳，感觉是学物理的一个正常状态（</p>
<p>我跟群友说学这玩意真的好痛苦，哪怕只是背答案，群友锐评基物 2
和实分析其实都是 4 学分，你看着办吧.jpg，好崩溃（（</p>
<h1 id="月5日">4月5日</h1>
<blockquote>
<p>A: zgy 会点名的你们也不去？</p>
<p>B: 哥 早八</p>
<p>别说点名</p>
<p>叫我起床出门捡人民币我都起不来啊</p>
</blockquote>
<p>分享一则环友发言（</p>
<h1 id="月6日">4月6日</h1>
<p>这清明莫名其妙就过完了，急急急，实分析怎么办基物怎么办（</p>
<p>今天 28
度，去清华科技园买咖啡突然就变得痛苦了起来，想起去年端午每天都要死在路上一样的状态，求求清芬瑞幸早日开业（</p>
<h1 id="月7日">4月7日</h1>
<p>最近越来越容易失眠了，是不是睡前最好还是别写题，写码和物理作业倒是经常写着写着就困了，写完数学不缓个一个小时感觉都有点睡不着，<del>哪怕只是光叔实分析作业这个水平</del>（？（。于是今早就没去计算概率，非常遗憾没看到求真祭孔现场视频，只不过运气不错的是今天讲
Markov chain 的理论，耳熟能详，而且还没讲到 MCMC，下次一定。</p>
<!--但这课上没别的女生，一次不去就好明显，上次去的时候感觉大家都带有一种“这人真没走错教室吗”的疑惑，碰巧这次又没去，急（（-->
<p>虽然实分析也耳熟能详了，而且光叔到现在还没到当年林勇大约第三周的进度，但我还是认真复习了一下他这个讲义
<del>但跳过了一些证明</del>。现在就是一点轻微的混乱，有的时候会稍微怀疑他俩是不是相容的而不敢乱写（。他这个期中到底会是个什么情况啊，感觉每周狠狠写一堆作业然后狠狠写一份习题课卷子，实际却也算是没怎么学，有点小急。</p>
<p>来点 <del>锐评</del> 批注（（</p>
<p><img src="https://s2.loli.net/2024/04/07/ZBDhLnQxS3JtTwd.jpg" alt="real-analysis-1.jpg"></p>
<p><img src="https://s2.loli.net/2024/04/07/LNtGljMan3uWwXH.jpg" alt="real-analysis-2.jpg"></p>
<h1 id="月8日">4月8日</h1>
<p>基物终于看完一遍，然而看完变换光学忘衍射，看完衍射忘偏振，看完偏振之后，屏函数是什么来着？希望
csm 守序善良一点，<del>我都两学期老粉了说不定基物 3
还要见面能不能捞捞</del>（</p>
<p>唯一的好事是找到了失踪半学期的计算器，然后 csm
在群里说这次用不着，全都是简单计算。我疑惑了呀，所以说不涉及乱七八糟的波长甚至不涉及
<span class="math inline">\(n_o, n_e\)</span>
之类的吗，那还能考什么（，难不成考证明或者直接用符号计算吗，我训练集里没这些啊（</p>
<h1 id="月9日">4月9日</h1>
<p>基物怎么办啊，算了，很快就会结束的（</p>
<p>原来托福成绩单还会邮寄一份，两千块钱听个响，啊不是，已经听了好几个响了（。出分的时候看到成绩单上有当天早上考前给拍的蓝底照片的时候已经崩溃了，结果还给我寄一份，受不了了（（</p>
<p>期中考完不知道有多少作业要补，还得讲组会
<del>的同构异形体</del>。为什么不开组会而是让大家一起听单人报告，太可怕了吧（</p>
<h1 id="月10日">4月10日</h1>
<p>基物期中不知道为什么这么多画图题，不会，差不多得了（。这个班成分还挺复杂的，但理论上这学期是给物理系开课，所以出现几个一小时就交卷的人应该也很正常吧，是吧（（</p>
<p>本来以为考完基物解决心腹大患之后可以狠狠学一天，但还是摆了，又困又累，明明晚上睡了七个半小时，午后又睡了将近一个小时，还灌了一杯拿铁，怎么会是呢。不知道实分析期中考到哪里，但考前总得把讲义再翻一遍吧。生存分析就随缘了，最后一年开课了，也没几个人，而且毕竟是
wjd，应该会比较善良，平时记的笔记删减一下打印出来当做 cheatsheet
就行了。</p>
<p>明早要去取护照，通缉犯.jpg。但凡拍照的时候稍微笑一下也好啊，相比之下我现在看身份证照片都觉得挺好看的了。</p>
<h1 id="月11日">4月11日</h1>
<p>高统不知道为什么又掉线了，上周放假，这周这个时间我正好要去取护照，已经没印象这课半个月前在干啥了。护照上打印出来的照片看起来比我当时照的还要白，不知道是不是又
p
过了，还是覆膜之后反光看起来就确实更白一点（？），于是黑眼圈也更深了，像一个潜逃期间三天没有合眼的通缉犯（</p>
<p>清芬瑞幸无了之后我就一直去清华科技园买，可能清明期间科技园的员工都真的放假了而我还在坚持点单（，导致我订单数进了他们门店前
20，然而清芬还在的时候似乎全勤都进不了（（。今天回来的路上在万柳吃的饭顺带点了咖啡带回来，于是现在就已经掉出榜了，加上明天是茶话弄日（？，感觉要无了（但是为什么要在榜上呢，为什么呢（（x</p>
<p>基物成绩很快的出，比我估的 baseline
还是高很多，虽然也就那样吧但挺好的挺好的，感觉比我高中时候强多了（（</p>
<p>感觉这周莫名其妙的就要过完了，上了六天课但也没觉得很漫长什么的，说明中间基物期中带来的压力已经超过了一切，于是它解脱了以后的幸福感能够抵消其余所有的痛苦（。剩下就写写作业，还有
all in 实分析了（生存分析：那我呢</p>
<h1 id="月12日">4月12日</h1>
<p>我麻了，痛苦的一天从看了匪夷所思的桥梁工程作业开始，我一直以为这是个水课，结果怎么还要求先修工程力学的？我是一个一学位物理二学位土水大类、在某书院中游
GPA
的大三（下学期）学生，你就默认我知道什么是弹性模量、截面应力和挠度，这合理吗（</p>
<p>稍微缓了一下，早上起来看到计算概率已经掉线了的讲义，我又麻了。不过这个好说，首先这周还是没布置作业，而且它无论如何都比桥梁工程好说，学一下就好了（</p>
<p>生存分析 cheatsheet
还没开始，倒也不是很急，而且一想到它没有期末就很开心，期中考完之后就等于不存在了。虽然期中之前也不太存在，就偶尔晚上要写写码。早上起来，上完体育课以及晚上回来写了写金统作业，倒是很平复焦虑，谢谢你
wwc，但如果能选一本在网上找得到答案的书布置作业就更好了（</p>
<p>最近买了两盒棉条想尝试一下，今晚突然想起来去认真查了一下
TSS，好可怕（。但我最担心的是，我感觉我在学校里感冒发烧真的非常频繁，发生在经期前后也很常见，TSS
的症状和流感也没啥区别，那怎么办，以后每次生病都要直奔医院吗（。我其实都有点怀疑跑去校医院跟医生说因为用了棉条然后最近生病了怀疑
TSS 人家会不会注意我在说啥（（</p>
<p>下午回来看到在布置校马设施，一阵头痛（，不知道明早要怎么闯出紫荆区去习题课交作业。去年校马的时候正好是实分析期中考试，还是在明理楼，就没绷住，今年怎么还在实分析（</p>
<h1 id="月13日">4月13日</h1>
<p>晚上本来就不太舒服，吃饭也晚，结果吃完饭收盘子的阿姨打翻一个面碗，被泼了一身油汤。只能说幸好除了外套之外都是今晚本来就要洗的衣服，食堂经理赔了干洗的费用，但有没有一种可能哪怕外衣我都是手洗，贴身的衣服更是不想干洗（除非真的洗不掉（衬衫上的油真有点洗不掉，再努力一下，实在不行真得干洗毕竟这衣服好贵（（，唉（</p>
<p>上次打算等到周日去问一下同学桥梁工程作业要怎么写，结果今晚他先发制人来问我怎么做，我绷不住了，哥你不是学过工程力学吗（。可能确实是这课逆天吧，我也不知道啊（</p>
<p>唉，生存分析，这就开始看（</p>
<h1 id="月14日">4月14日</h1>
<p>生存分析咋办（？</p>
<h1 id="月15日">4月15日</h1>
<p>生存分析赢麻了，昨晚 cheatsheet 上还有一块空的，就把 log rank 和
score test for cox model
等价的那个证明打印出来贴上去了。结果今天问这两个有什么区别，可以通过理论证明，或者用给定数据验证两个统计量相等的方式来说明，我寻思着让我算两个贼复杂的东西还要让它们相等，那我大概率算出来就不相等，就直接抄证明了。昨晚写桥梁工程作业，写的时候不知道里面有两个东西是相等的，算出来才发现真的相等，说明
priori 是非常重要的（什么</p>
<p>唉，wjd
的卷子一如既往出得真好，讲课也好，华子就是一个没有能力留住教学好的老师的状态，当然它可能也没啥兴趣留住。</p>
<p>考完之后 wjd 锐评：</p>
<blockquote>
<p>怎么大家考完试第一反应都是掏出手机来刷一会，然后露出满意的笑容</p>
<p>看来是考了两个半小时的试，中途一直摸不到手机，上面就发生了很多有意思的事情</p>
</blockquote>
<h1 id="月16日">4月16日</h1>
<p>这个 b 实分析（，真看不完了，现在又说 5.4
节也要考，但又来不及讲，虽然讲不讲也都无所谓但是，唉（x</p>
<h1 id="月17日">4月17日</h1>
<p>急急急，急中又夹杂着一丝不急，反正就是晚上回来先洗了个澡然后吃了一个小时水果（？</p>
<h1 id="月18日">4月18日</h1>
<p>天气热起来了，这种熟悉的黏腻的感觉又回来了，好烦（</p>
<p>继清芬瑞幸看起来彻底要无了之后，今天清华科技园店也没了。昨天没喝不知道什么情况，但今天下午一点打开点单发现店里除了点心之外全部缺货的时候，悬着的心真的死了（</p>
<p>想了想旁边还有个库迪，听说这两家打架打得厉害，还有人嫌瑞幸贵就拿库迪当平替，就去探索了一下，结论是替不了一点。我寻思着既然都当平替了那总得便宜点吧，我在美团买瑞幸券是每天九块九，库迪虽然全场九块九那不也还是九块九吗（。店面小很多，生椰拿铁都抄了瑞幸的怎么不顺手抄一下厚乳（，澳白只有热的（倒也正常，思来想去选了一个流云拿铁，主要是我没看出来这个是什么东西，于是我想总之是拿铁吧还能错到哪里去！结果提回去尝了一口怎么比奶茶还甜，冰也化得很快。之前还看大家吐槽瑞幸的冰太多化得太慢，然而在
30
度的天气下我真的就希望它多一点化得慢一点，既不要融到咖啡里面影响味道，还能在我热得很烦躁的时候贴贴脸安慰一下（</p>
<p>那怎么办，清华科技园这个是突发情况还是寄了啊（，难道以后去北大科技园买吗，下次干脆进北大买算了（</p>
<p>好累啊，怎么就这么累啊，这实分析快点考完吧（。学这个 b
数学平时就像泡脚一样细细欣赏优美的经典理论，到考试之前就得狠狠地喝洗脚水，管你每个结论怎么证明的，先把它记住再说（（</p>
<h1 id="月19日">4月19日</h1>
<p>累了，已经开始畅想考完去孚王府玩，吃必胜客 EVA 联名（</p>
<h1 id="月20日">4月20日</h1>
<p>终于考完了！休息！</p>
<p>下午拿到实分析卷子之后我有点，啊主要是，有很多的疑惑，这真是实分析？这不是数分，不是微积分吗，因为太水了所以我都怀疑到底有没有伪证的程度，只有附加题稍微有一丢丢难度，虽然这个怎么看都不可能正着证出来所以反证一枪秒了也没啥吧。不知道是出于想装个逼，还是最近复习得太痛苦了想赶快结束这一切（，还是晚上原定有出去吃饭的计划，写完附加题就跟在一个人后面提前
45 min 左右交了。</p>
<p>跟在别人后面交其实是因为，考完要在台上领后半学期讲义，他那个实在是太贵了（，而且我学期初就自己在某宝印好了（好孩子不要学），我又怕一个人上去被叫住，就只能挑个有人一起交卷的时机混过去。不过一出来走了两步就想起来第二题那个方体覆盖好像写拉了，边界上没完全盖住，虽然他真不一定仔细看或者心慈手软的话就当我笔误了放过或者扣不了几分，但是严格起来的话全扣也不是没道理。无所谓了，我附加题都写了，怎么样也不会出大问题。</p>
<p>只是感觉，早知这样的话何必痛苦地复习一周呢（。什么新的东西都没有学到，就单纯是在大口喝洗脚水，挺没意思的。不过也没什么可早知道的，somehow
这就是在不知道之后会发生什么的情况下做的无悔的选择了（看巨人看得（</p>
<p>所以 lxg
之后能不能开个泛函啊，我真的好想在他这里水过去，甚至他如果在我毕业之前还开下一轮数分的话我真的想去水一个，分析基础还是不咋地（</p>
<p>晚上去吃了 EVA
联名，本来想要明日香的吧唧，但店员说吧唧只剩三款的时候我就感觉有点不妙，领完的两款怎么想都是大烫门明日香和渚薰才对，果然一盒还剩下一个绫波丽，一群真希波和一大群真嗣（。想了想我那边有一个渚薰的吧唧，就拿了个真嗣凑了一对贴贴，看起来也还好嘛！只是左边像
mappa 的进巨画风右边像 WIT 而且还有个必胜客联名的标注罢了！</p>
<p><img src="https://s2.loli.net/2024/04/21/uz9tGV4ZAekBaIS.jpg" alt="eva.jpg"></p>
<p>所以为什么都不要真嗣，他不可爱吗（？</p>
<p>明天去世图读者开放日，不知道会冲动消费点啥，总不至于支持一手影印本
PTE 吧（？</p>
<h1 id="月21日">4月21日</h1>
<p>不知道为什么还是很累，而且这澳白我喝一次睡一次，网络学堂还有七个猛 1
在等我（，第九周要讲论文，急。</p>
<p>今晚回来把头发剪了，天气太热不地鸣了，love &amp; peace（。</p>
<h1 id="月22日">4月22日</h1>
<p>累麻了，论文证明看不动一点，我感觉它看起来就是单纯地算了 20 页（</p>
<p>今天的瑞幸取餐号是 001，但昨天是 032，前天是 031（</p>
<p>遇到了一个剪头发之后的常见问题，显得肩很宽，穿泡泡袖尤其灾难。算了凉快就好（</p>
<h1 id="月23日">4月23日</h1>
<p>实分析这期中成绩下来好令人幸福（，今天扫了眼写拉了的那个题（但其实助教放过了，谢谢助教）的答案，恍然大悟我为什么要重新给方体写一个
2
进方体的覆盖，它那个条件不就是个针对方体的不等式来着吗（。有一说一我能想到的解释只有，平时写作业写到
2
进方体的时候我都不知道怎么翻译才好，用到的时候就在英文里夹杂中文的这几个字，期中脑子一抽想用中文写答卷，一上来不知道为什么满脑子就都是
2 进方体 2 进方体 2 进方体了（</p>
<p>感觉比起做别的事情，现在更需要的是狠狠补充几天睡眠，尽快让这个疲惫的感觉消失，不然真的除了写作业啥都干不下去，效率蛮低的（</p>
<p>打算把讲论文挪到五一之后了，很累，看不太动，也确实还再需要点时间，另外又搞了篇新的。</p>
<p>高统 II 好难啊，虽然每个 slide 都比 wwc
当时短不少，但定理看起来复杂多了，抄笔记的时候总是很疑惑学这个东西干什么它真能有用吗，顺带稍微考虑一下是不是可以乱用这些估计方法做手里的问题，但也没有什么头绪。作业也写得很麻，wwc
之前布置的作业至少都是课后题也大多数都有答案，lq
搞一堆自己出的题目，磨蹭很久才能写完，这考试要怎么考（</p>
<h1 id="月24日">4月24日</h1>
<p>写了一天高统，还是没写完，蛮崩溃的。</p>
<p>晚上在户外停了五分钟，腿上被蚊子叮了三个包（</p>
<p>想起来前天和室友的一段对话：</p>
<blockquote>
<p>室友：你腿上的疤是被蚊子叮了吗（指）</p>
<p>我：应该是去年的，今年还没被叮过这么多</p>
<p>室友：啊这</p>
<p>室友：ok，我没有别的意思，很健康的两条腿（指）</p>
<p>我：所以对于健康的定义其实是，正常地遭受生活的磋磨的结果是吗？</p>
<p>室友：啊这</p>
<p>室友：你还别说</p>
</blockquote>
<h1 id="月25日">4月25日</h1>
<p>晚上在路上又被人撞了，令人感叹（，是非常常见的前车的哥们刷着手机就唐突左拐了，我一个急刹加按铃既没能拦住他也没能阻止后面的人撞我，唉（（</p>
<p>我说这学校的新生入学教育能不能整点实在的，至少拿半个小时讲讲骑行规范，比如说转向要减速，回头看或者至少打个手势（说实话我也不知道这两个到底哪个难，但回头看比打手势安全多了），车多的时候不要乱变道，etc（</p>
<p><del>唉，抱怨也没用，不如复读一些神腿们的教诲：有竞技的入门水平，平时就更应该有在路上调停事故的能力，自己不要不自觉地狠拉速度，至少还要能预判一些常见的问题，比别人更快地做出反应避免事故发生（（</del></p>
<p><del>别骂了别骂了（（</del></p>
<p>复盘一下，我被撞的时候刹住站稳了没摔，我感觉没摔这件事还算是给后车的哥们支撑了一下至少他人还狠狠扶了我一下（，只是衣服又脏了（。车应该没啥事，顺便狠狠教育了几句前车，我感觉已经赢了至少尽力了（（</p>
<p>我真的，我开学就是玩了个烂梗，结果衣服就不停地脏，以后真的不敢了饶了我吧（（</p>
<h1 id="月26日">4月26日</h1>
<p>我写量子力学
belike：叉乘是什么东西来着（。有的时候真觉得很丢人，都不太好意思说学过数学（这之间有关系吗</p>
<p>晚上勉强把高统作业交了，实在写不出来了，算了（。怎么就这么阴间啊，每个题长得都像
open problem
一样，用的定理也奇形怪状的，实在搞不定。然而从第一次的批改来看他这个作业给分还挺严格的，唉。我上得比较烂的课都是名字里带
2 的，比如概率论 2 和微积分 2（，感觉基物 2 也差不多可以算上了，高统 II
比高统 I 难巨多可能也是正常现象吧（</p>
<p>总之暂时下班了，感谢 wjd
送来的九天长假（指下周一的课她有事就放掉了。总之明天先去闪现一下郑州，后天回。</p>
<p>昨晚在答疑坊值班，想起来过两天有一个要交的期中论文可能只能在高铁上写了，在一晚上一单都没接到的情况下还花
120 购入了一个 ipad
键盘（。晚上回去何老板找我问问题，才终于又有了一点在答疑坊干活的实感，毕竟
5~8 周津贴统计里甚至没有我的名字，这是怎么一回事呢（（</p>
<p>今天取快递回来之后室友锐评：你确定这玩意 120 吗，我觉得把罗技的 logo
遮掉的话看起来顶多
30。可能是粉色就会显得廉价（，但选粉色绝对不是我自愿的，是粉色款比别的便宜
20
块，否则就买灰色或者卡其色了，我还真是第一次见到不仅不收粉红税还粉红免税的东西（（，大概是因为卖不出去或者确实是看着很廉价导致的吧（（</p>
<p>晚上回来试了一下，除了键位距离有点小一下子不习惯之外没什么毛病，稍微熟悉一下也就好了，我手比较小反而挺友好的。现在的问题是它和平板加起来都快和电脑一样重了（但如果把平板保护套拿掉就会轻很多），这一套还不能码代码，那为什么呢（。只能理解成上次电脑屏幕碎掉之后还是觉得带着
apple care 期限内的平板乱跑比较有安全感，以及平板看 PPT
确实比电脑爽很多这样子，键盘只是救急，只是救急（默念（</p>
<h1 id="月27日">4月27日</h1>
<p>现在这个发型虽然穿衣服要注意下不要显得肩太宽，但很适合戴耳环，以前头发很长的时候戴了也看不到，还会担心掉了都不知道（<del>虽然我的耳夹均价不超过十块而且都是淘宝常见款式，但也还是不想掉（</del>。不过我没有耳洞，也不打算打，一般都是戴耳夹，鉴于我不想承认是因为怕痛而不敢打，所以我一般都说是因为要防止改变自己的拓扑结构（</p>
<h1 id="月28日">4月28日</h1>
<p>闪现郑州，在街边吃碳水大餐（，这边好像真的很喜欢在路边放桌椅吃饭，虽然感觉胡辣汤和烩面都没有特别合胃口，有点太咸了。下午去郑州博物院，每到这个时候都感叹当初学工艺美术史的时候多么幸福。买回来一堆文创，多到我现在根本没有勇气去看这一趟花了多少钱（</p>
<p>高铁开出北京之后我皮都展开了，虽然去的时候坐和谐号没有插座是怎么一回事呢（，回来一开进北京就不舒服了（</p>
<p>在高铁上写完了合同法期中作业，还写了点别的<!--（今年社长选举的时间（被 neruko 拖得（x）挺凑巧的，如果 30 号之前没有人提名我就选一手了-->，现在开始急计算概率作业了（</p>
<h1 id="月29日">4月29日</h1>
<p>尝了下瑞幸新品青提味拿铁，蚌埠住了（，一边喝一边思考我到底为什么会对这个东西有期待，是为什么呢（</p>
<p>看了一天计算概率，补了一个月的内容（。晚上一直在研究 KFC 啊不是 KMC
和他之前说的那个加速方法到底要怎么样才能拼起来，最后才明白是证明里面要用到那个加速方法的结论，绷不住了。</p>
<p>现在处于一个刚搞明白要干啥的状态（也不好说是不是真的明白了），还没开始码，急急急（（</p>
<h1 id="月30日">4月30日</h1>
<p><img src="https://s2.loli.net/2024/05/05/q9zkyo2g7UPB4ha.jpg" alt="2024.04.jpg"></p>
<p>5.5 update: 总不会现在还有人想看这个吧？</p>
<p>总结：库迪好难喝，不要买。</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇廿一·24年5月</title>
    <url>/2024/05/05/Diary-2024-05/</url>
    <content><![CDATA[<!--我真的，困死我算了。-->
<p>五月的失败从 Yau contest 直接弃赛开始！</p>
<span id="more"></span>
<h1 id="月4日">5月4日</h1>
<p>突然闪现！前几天一直没写是五一华子游客太多了，也没有合适的教学楼可以去，<del>更没有工位和实验室</del>，于是躲去乡下（不是）瘫了四天，作业还越写越多，也没搞科研。</p>
<p>二月份打的美赛出奖项了，本来都做好拿蓝色证书的准备了，结果竟然是
honorable mention，今年 ICM
获奖率比以前高一些，运气还不错。开了下盒感觉华子 S
还是挺多的（，那我还蛮强的嘛！而且整体上看 ICM 这边 E 题选题比例高达
52%，华子倒是有 38 支队伍狠狠选 D，获奖情况并不如 E 的 12 个队伍，我们 E
人真是太厉害啦（（</p>
<p>最近还有很多事情搞不清头绪，比如暑期实习延期的问题似乎该去和教务沟通下了，再不沟通都该选课了，我也还是不知道要不要延期，可能还得和别的前辈聊聊。科研毫无进度，不是在期中考试就是写作业就是摆烂，你要是问我为什么四月论文阅读笔记消失了，我只能干两碗饭。瘫了四天回来上秤直接给我搞沉默了，晚上出去紧急骑车补救了一下。</p>
<p>事已至此，那怎么办，先睡觉吧（（</p>
<h1 id="月5日">5月5日</h1>
<p>看了一丢丢论文的证明，结果它真的就是狠狠地用泰勒展开和 OLS 算了 20
页，通篇难度不超过数分 1 高代 1 和概率论 1，我叹为观止。</p>
<p>还有一篇证明没看，之前自己找的一篇文章就看了个梗概，后天要见阔别两周的导，害怕（</p>
<h1 id="月6日">5月6日</h1>
<p>前两天在乡下（？）住的时候我发现证明看不下去的时候可以躺下看，缺点是整个人的状态比较的被动接受，另外因为没法用纸笔算所以一些细节只能随便脑一下，或者多攒几个等有精神了再坐起来验证，也可能会直接睡过去（。搞得我现在一看证明就想找个地方躺着。等暑假回家想买个
Luckysac
那样的懒人沙发，但家里又不是没有床（，寝室也不能放，更不能天天背着去教室（。所以最佳的论文阅读地点其实是
C 楼的双人研讨间（？（但不知道装修之后它还在吗</p>
<p>昨天看了好多泰勒展开，今天又看了十余个泰勒展开。说真的，它在证明上真没有本质的难度，但就算每个定理给到我面前让我去证，所有的技术（除了条件概率）在大一就都已经学会了，我怀疑我缺乏的还是一种在尖叫“这
tm 也能继续算吗”的情况下真的继续算下去并算出来的能力（</p>
<p>晚上一觉醒来看证明，看到这一句 <span class="math inline">\(\frac{2n}{n+1} - (u+v) &gt;0\)</span>
的时候我的小脑真的萎缩了。虽然后来反应过来他的意思是只要证这个条件下成立否则显然，但是，唉（（</p>
<p><img src="https://s2.loli.net/2024/05/07/GhZFVQe7KYgdo2H.png" alt="asab057.png"></p>
<h1 id="月7日">5月7日</h1>
<p>很久没有腰疼了，怎么最近突然又不行了（</p>
<p>又双叒叕身体不太舒服，本来想继续读论文，结果只好写了点作业，生存分析考完试之后只有两次作业了，难度骤降，速通了。金统这个大作业的要求和没要求有啥区别（，晚上上课的时候大概查了查，又去看了眼自己的
portfolio（，想起来之前一直说可以买点黄金但一直没买<del>（好像是在观望，问题是这是在观望什么，单纯是忘了吧）</del>，就搁那狠狠地投纳指和狠狠地捞一个亏了好多的医疗，最近金价暴涨只能看着易方达黄金总资产
0.67
元捶胸顿足。干脆做个金价的分析好了，多上几个时间序列模型拟合一手，然后做个资产配置，最后再因子分析这样子（yysy
我很好奇因子分析真能做吗，感觉只能宏观解释，要么就是找一点比较有
confounding
意味的因子来回归一下这样），后半学期他如果还讲点啥有意思的我就再给他缝上去（，反正这个大作业目的只是要把这学期讲过的内容串起来罢了（（<del>将要面对的现实：对着收集来的数据完全不会写码</del></p>
<p>之前订了一件 PKU SMS
的文化衫，是拓扑咖啡馆那款，周末就可以取了。下学期泛函看老师可能还是不太能上（我也不到啊），实在不行就去把拓扑和微分流形一锅端了，假装是基础人（<del>主要是数学系这概统和计算方向的课都实在没啥可上的啊</del></p>
<h1 id="月8日">5月8日</h1>
<p>好热，这教室里怎么还不开空调，完全那个没心情学，<del>这下真看论文看得汗流浃背了</del>（（</p>
<h1 id="月9日">5月9日</h1>
<p>教室终于开空调了，但是开空调之前好热没去买咖啡，于是今天睡得很死（（</p>
<p>这基物到底是在干什么呢，不是很理解，PPT
也不说人话，感觉浪费大半天看这玩意也没用，还得去看教材。虽然好像是会算的，但是换个皮可能又不会了这样子。我要求也不高，就希望它能
3.6 平安落地（</p>
<p>晚上直接摆了，想起来前段时间看的宫崎骏访谈，于是把痞子制作 EVA
终期间的纪录片看了（？，又补完了（</p>
<h1 id="月10日">5月10日</h1>
<p>今天看到求真夏令营的题，先疑惑了一下这是在招博士生还是本科生，想起来去年秋季已经招过本科生了，于是开始思考现在去考这个卷子的人是几字班，好像是一字班，诶等一下，那我是？（</p>
<p>体育课测仰卧起坐和 50 米，仰卧起坐定番先花 50 秒做 50 个然后躺下休息
10 秒（，躺完被老师拉起来示范怎么一秒一个，没绷住（。50
米这辈子第一次见到进 9
秒甚至及格了，减脂之后确实各种意义上来讲变强了一些（</p>
<p>不想刷乐动力了，感觉能及格（（</p>
<h1 id="月11日">5月11日</h1>
<p>今天填推研意向统计，又有点没绷住，虽然我还要延毕，但怎么已经轮到我这一届推研了？我毫无心理准备。我科研还是现在这个
beyonds，和啥都没有也妹区别。填了推迟推研之后又绷住了，反正我不推研，真推研的话去统计中心不太是问题，就算是求真看昨天那个卷子复习一下我上我也行，最大的问题其实是拿推研资格（，也即前三年课程中未完成的不超过三门，我觉得我明年也做不到。然后又没绷住，有没有一种可能我不推研是因为我要出国啊，那对科研的要求不是更高吗，真破防了（</p>
<p>但我感觉我室友也都和我一个状态，除了一个室友要去教研院读硕或者直接工作之外，另两位都完全没科研在等着强基
100%
推研给分配一个去处（，又不特别焦虑了（（。虽然我不知道数学系是什么情况，但真有未来一年里能发出来
paper
的吗，这种事情总感觉该发生在隔壁（。想了想得出结论还是别想了，去看了个证明，然后规划了一手暑假头上去江西和两湖找我姐
<del>同居</del> 玩一周多点，期间可能在她家潜心读论文两三天（（</p>
<p>之前看到过一篇推送说相比首都机场和大兴机场，天津滨海的机票会便宜一些。今天被北京到南昌七百多块的高铁票价吓晕了，又不想卧铺，除了夏天没办法洗澡以及洁癖地狱之外，16
个小时实在太长了，12
个小时的卧铺还要三百多接近四百，实在没啥必要。查了下大兴飞南昌的机票感觉早点买的话可以接受，又查了下天津飞南昌的机票感觉非常可以接受（，是一个从北京去天津待一天哪怕住一晚再飞南昌，加起来也比高铁便宜点的情况，还少坐三个多小时（。另外南昌回上海的高铁不算贵，中三省（对不起我其实也是今晚才知道有这么个称呼）转一圈加起来还没上次去郑州贵，冲了。</p>
<p>比起微分流形，今天看矩阵运算看麻了，下学年有点想去补票一个完整的高代了。我说真的，比起在读研之前就把研究生课全部上完（e.g.
我之前想去学概率论 3，现在觉得会一点实用的随机分析和 SDE
暂且够了）到时候还得再学一遍，这种越拖越不好意思甚至再也没办法补票的课去上一个会心里更踏实吧（</p>
<h1 id="月12日">5月12日</h1>
<p>看证明，越看越疑惑，我怎么感觉他这个里面这么多问题（，typo
不计其数就算了，第一页上来不等号就是反的吓我一跳（。最主要的是我真觉得算错了很多东西，有个
log-normal distribution 的期望就真的不对，虽然改改系数勉强可以 bound
住，但看他算出来那个值就很迷惑，<del>真不是故意写错的吗</del>。后面还有类似于“因为
<span class="math inline">\(a + b &gt; 2c\)</span> 所以 <span class="math inline">\(a &gt; 2c\)</span> 和 <span class="math inline">\(b &gt; 2c\)</span>
至少其中之一成立”的怪事，我猜他想说的是 <span class="math inline">\(a
&gt; c\)</span> 和 <span class="math inline">\(b &gt; c\)</span>
至少其中之一成立，虽然就差个系数改改也不是什么问题但是（。虽然还是有看了证明也没懂的点，但想了想先去重新验了一下正文里之前怀疑他搞错了的一个
Cholesky 分解，还是觉得不对，需要给每个点加
weight，<del>这下更有信心觉得是他错了而不是我错了</del>（</p>
<p>但有一说一，如果是真的需要加
weight，证明就有点出小问题，我没看出来怎么继续按这个看起来还算合理的全局假设来控误差（。如果要给假设改个大的的话，他后面那一堆
show that the signals under blahblah are strong enough to satisfy the
conditions in Theorems 1 and 2
怎么办（。所以，这时候我是该怀疑一下我自己吗（，感觉得整理一下然后问问导这样子。</p>
<p>先去看了看另一篇 graphon estimation 的文章，上次那个 local linear
regression
是真的算得很厉害，就是一种，假设并不复杂但结果挺好的，其他线性模型看起来也还有很多可以挖掘的点，还得学习一个。<del>五一在乡下休息的时候我其实还想了想怎么把
GLM 往上面塞，毕竟它也真有 covariates（sry</del></p>
<h1 id="月13日">5月13日</h1>
<p>今天把生存分析的论文看了，怎么不算是一种搞科研了？（</p>
<p>晚上重新算了昨天那一坨，又找了下发现 supplementary material
里面有一处改过来了，正文的确错了，但另一个地方没改，这啥意思（。给导发个邮件实话实说了，belike
现在出了点小问题，然后描述了一下这个小问题，如果真要尽快讲 pre
的话也可以先讲 graphon estimation，反正我也读了几篇别的可以说说
<del>而且我觉得这个问题会比较分析一点，就是说还稍微能算一点</del>，不急的话再等我算算另一个看能怎么救。另外我得狠狠写作业了所以这周不知道还有多少时间算，先别急
<del>急的话要么您自己来算，或者教教我量子力学罢</del>（（</p>
<!--今晚突然想起来 Mariana 申请之前还有一篇在投的 methodology 的文章，查了一下是 https://arxiv.org/pdf/2209.00170，一眼这个 co-auther 里面怎么还有 HM Zhao，就先没绷住。一看标题什么 Cyber Security，这几个人不都是统辅来着吗（，跳过几个从未想过会出现在统计的文章里的图之后，怎么变成 node classification 了，这也能缝起来的吗（（-->
<h1 id="月14日">5月14日</h1>
<p>最近睡眠实在是不行，感觉也体现在每天都在混沌做梦上，主打一个醒不过来或者睡了很久还是累。大概也和莫名其妙压力很大有关，一眼望到头的本科生活板上钉钉要续费一年，续费完了也没有留在国内读研的可能性，也完全看不到申请之前多这一年能搞出什么东西来，如果说大一大二好歹是探索了很多终于定下了方向，那大三这一年到底干了啥呢。<del>昨晚睡前焦虑得不行，狠狠地查了一些我知道的人的
pub，最后把知乎下载回来给 24 Fall
下面每个数学相关的点了个赞，然后沉沉睡去（</del></p>
<p>今天写了一天作业，补了补笔记，感觉稍好一点了，可能做这些不怎么费劲的事情到底可以麻痹一下。明后两天要把基物和高统仔细学一下，这俩都掉线挺久了。期末周结束得很早，虽然比较阴间的是
19 号早上基物晚上实分析，21 号桥梁工程，但到底就这三门课 <del>虽然 16
周生存分析要
pre，还有金统和高统的期末，什么某个通识课要考期末这难道还得复习吗（</del></p>
<p>时隔一周多终于拿到因公出国的批件了，明后天尽量去找土木系教务审批延期，总之要在夏季学期选课之前搞完。其实我也没什么别的考量，最重要的是夏天到乡下上工地实在太热了，我受不了，冠冕堂皇地讲就是会影响暑假的科研计划，所以我想延到寒假实习。</p>
<p>说到选课，今天看了下秋季学期的本科生课程，索然无味（，选个拓扑选个高代走人，统计计算也不太想上（<del>我真不是很想再上
zzy
的课了，虽然这个或许也是复习高代？我对算法的了解仅限于数值分析介绍的那些和计算概率讲的一点点，统计特化的计算完全不懂，也许学一下是有好处，但不是非得上课</del>），毕竟还有量子力学（<del>想开点，这个也是复习线代</del>）和工程力学基础这两门不得不品鉴的必修课，和大约三门比较水的必修，该把重心放到科研上了。</p>
<!--昨晚狠狠翻 arxiv 发现了个可能有点严重的问题是，我发现 wwc 的学生怎么普遍发不出论文来（至少和隔壁 zjy 相比，虽然 zjy 真的纯应用，这倒也没什么毛病）。他最近的几篇论文还都是和他上段博后的 mentor 合作的，我知道他真的很强，做的东西理论性很强，不像隔壁几个组天天往 cs 顶会上乱扔东西，但从功利的角度来说，我连在投都没有的话到底要怎么出国（，真就全凭 gender bias 吗（-->
<!--我真的不知道啊，我甚至不知道要不要现在趁最后的机会去海投一波暑研捡漏，tier 2 的学校也无所谓，主打一个寻找愿意可怜可怜我的清华校友。如果能找到，好处是凑出一封潜在的推荐信，坏处是一个暑假不在校内做的话，和 wwc 本就不怎么紧密的联系更要无了，另外我好不容易找到一个方向了解了一下，再换就能做出东西吗，三心二意确实不好，现在没投入很多时间也没得到多少指导也是真的，但我还是希望有能 hands-on 带我的老师，师兄也行（-->
<!--在华子数学这边保研真是个简单的选择，至少目前统计中心几乎点击就送，不需要本科任何的产出，我下一年只需要把必修课补齐拿到保研资格就可以，数学系也问题不大，求真不想去，去了也过不了脖子考。我不知道怎么形容我想出国这件事情，个中缘由我说不清楚，有的时候我会觉得我实在忍受不了这个大号的沙东，我想离开去其他某处，即使可能终于会失望，有的时候又觉得可能只是单纯地不想一直待在同一个地方，我想要自由。自私的时候会说我宁可就逃走，比起停留在大号沙东，宁可逃去一个暂且让我的性别竟能对个人的发展有利的地方，我也不过是想尽可能多搞钱留给我妈妈。无论如何，我想这样做，而作为一个白手起家的第一代移民，在经济上能负担得起（也不好说）的唯一方式，就只有去读一个 PhD 了。学术上的成就不敢说也不能说会有多少，大概率读完博就要离开学术界（非常好选择，这都无所谓，只是在这样的身份和野心之下，目前我还没有做到像我需要的那样勇敢、努力。-->
<h1 id="月15日">5月15日</h1>
<p>状态真不太行，怎么每个学期到后八周都过成这个 beyonds（</p>
<h1 id="月16日">5月16日</h1>
<p>草这实分析作业怎么这么多啊，前两天没意识到问题的严重性完全没看
<del>其实是物理更危急导致的</del>，今天边看边写搞了一天还没搞完，明天又没空写，真寄了。高统到现在还没开始，堆了三个没看的
slides 了。</p>
<p>算了无所谓（，周六早上反正我去中科院数学所公众科学日
<del>追星</del>，也不去交作业了，线上交还可以再迟一点，顺便也去那边看看世图新书展销。从寝室骑车两公里多就到了，压力不大，跟晨练似的，这总不至于再咕了（。前两天报了六月初的清北统计论坛
<del>去吃茶歇和追星</del>，总不至于过不了审不让我去吧（（</p>
<p>悲观一点说目测到期末之前没什么时间磕盐了，这学期绩点别爆炸就不错了，从下学期开始一定少选课。</p>
<h1 id="月17日">5月17日</h1>
<p>本来还在急这周实分析的作业，明天肯定交不上了，得找个理由交网络学堂，晚上在答疑坊小程序里看到一个问上周作业题的，什么叫松弛感啊（，这下不急了（</p>
<p>今晚在教室看到有人在看 Fate（目测是 HF 线），爷青回（</p>
<h1 id="月18日">5月18日</h1>
<p>今早去数学所了，虽然八点钟就开始了但我十点才到，听了三个报告，了解的话题再加上科普向就听得很乐，<del>来晚了于是没听到院士报告（</del>。中间摸鱼的时候顺便看了眼今年数学所的博士招生考试题，看在我没学复变不会做求真那个级数题的份上承认求真的题比数学所难，但数学所题量好大计算好多啊，感觉这么一说也有点难（。</p>
<p>但强基就算保研也不能离开华子，北大都去不了更不可能去数学所，又有什么关系呢（</p>
<p>中午结束之前和世图的一个编辑姐姐（群友）面基了一下，本来想买世图的新笔记本（前情提要：在摸鱼学导论和划水学原理之后又出了新系列的本子，详见<a href="https://mp.weixin.qq.com/s/mp4mT3STFPEeOja_AFhUMA">这里</a>），但是去太晚了，那个数学家用的量子理论笔记本没了，下次网上买吧（。没仔细逛展销，来晚了就光急着去计算实验室了，反正
GTM 也没上新，浅浅瞥的几眼里没看到
Durrett，不支持了（<del>看到应该也不会支持的</del>（。进校门了才想起来结束之前忘记回世图的摊位盖章了，枉费我还带了集章本，<del>算了反正世图的活动挺多的，而且就那几个章</del>（</p>
<p>现场中学生好多啊，羡慕，<del>搁我高中的时候学校旁边只有个上海硅酸盐研究所，完全没这个条件</del>（。遇到了一些认识的人，主要是隔壁
SMS
的几个，<del>不过完全没被认出来，标准结局了属于是</del>。遗憾的是今天没穿隔壁
SMS
那件院衫，正好还有个拓扑相关的报告，<del>不过还好没穿毕竟我完全是云的，下学期一定学</del>（</p>
<p><img src="https://s2.loli.net/2024/05/19/BAKreVmukItbWo1.jpg" alt="AMSS.jpg"></p>
<h1 id="月19日">5月19日</h1>
<p>退一万步讲，这学期变成这个 beyonds，这门高统 2
就没有任何责任吗（。它讲贝叶斯，一些深入的 MLE
和非参，我不知道怎么形容但我真的完全看不出来这些东西会在哪里有用，也可能比较
advanced
就是这样子的，每节课几个不知所云的主定理和看了也白看的证明，反复嘲笑我是大废物。作业也很逆天，五一前和
MLE asymptotic properties
那几个主定理搏斗还啥都没证出来犹在眼前，今天本来想补补笔记结果算了一天
one-step
MLE，他这个作业哥们连算都算不清桑，我实在很难想象考试要怎么考。</p>
<p>说实话从来没有上个课上得这么悲观过（？），它和高统 1
已经没啥关系了，倒是和搞科研看不懂论文的感觉比较像，可能研究生课就是这样的，问题是我好像过不了多久也要变成研究生了啊（大叫</p>
<h1 id="月20日">5月20日</h1>
<p>前天没买到的笔记本今天到货了，<del>我是自愿学习量子力学的</del>（</p>
<p>左边这本这学期基物量子部分稍微写写，下学期还有一门量子力学用来写写笔记。右边那个可能下学期写高代，<del>拓扑懒得写了反正有现成的</del>。好久没用笔记本写东西了，近一年来都是直接写纸上然后收集起来。</p>
<p><img src="https://s2.loli.net/2024/05/21/Wf8C9OYK4ksGH3L.jpg" alt="notebooks.jpg"></p>
<p>总之下学期就这两门数学课了，高代 1
大概比较挂机，我想补的东西应该大部分都在 2
吧。看了下研究生课果然还是索然无味，不多选了，学概率论 3
的意义可能并不如多花点时间读论文大，还得学量子力学，以及另外四门不得不品鉴的什么东西（，实在不行再找一两门课刷
GPA，虽然暂时感觉不太需要吧。</p>
<p>今天看到<a href="https://mp.weixin.qq.com/s/XlxLnxSy9zSSxaZojZxzbg">这个</a>，差点一个激动就买了明日香款，后来仔细一看不是两张卡
69，是一张卡正面明日香背面真希波卖
69。<del>我倒也不是不喜欢真希波，更不是没钱，我只是想要一个完整的明日香，所以我不买了</del>（。<del>另外第三新上海市的
EVA 联名是真不少，不急着买这一个（</del></p>
<p><del>另，今天在生存分析课上更新了平板上的 Arcaea，不知道是否构成
playing video games during lecture，记个 * 真书院的小过</del>（</p>
<h1 id="月21日">5月21日</h1>
<p>困困困，摆摆摆，我感觉我的睡眠问题也逐渐变得显著了，睡不着是真的难绷。</p>
<p>现在有六个作业和一个也不算很大的大作业要写，该用闭区间套法了（。日子一天一天过去，实在看不到什么希望（</p>
<p>今天收到了一个幻方猎头的好友申请，假如我这个本科要读六年的话，我可能暑假真的会去实习刮点钱，<!--况且我还是有不小的概率以后真的做这方面的工作吧，或者说，否则我也想不出来我还有什么能不饿死的工作可做（，-->可惜它只有五年（</p>
<h1 id="月22日">5月22日</h1>
<p>星野源<a href="https://twitter.com/tkzwgrs/status/1793262834597728390">似乎塌房</a>了，哥们上次在国内出名可能还是和新垣结衣结婚，上上次可能还是和新垣结衣搭戏（x）。不过自从我姐追
kinki kids
塌房以及见证过很多类似的事之后，我就觉得当日本男艺人的粉丝之前得做好这么个准备（？），所以倒觉得没啥（？？），而且毕竟没花过钱就更无所谓了（？）。话说回来
Tokyo Dome 的那场演出是真的很棒啊，唉（</p>
<p>相比之下今天更糟心的是买的水果和酸奶被偷了，可能是在这家消费过很多了的原因，店家还问我明早要不要送一份新的过来。明天还找不到的话就查监控去了，不是因为我正义感强，而是十来块钱对我来说就挺多的了所以我真的很需要让偷外卖的人赔钱（<del>来个
* 真书院的小过</del></p>
<p>晚上去开隔壁书院的年级大会（，正好看到唯一一个在华子的初中同学在斜后面，线上癫了一会，学了一天量子之后精神状态奇妙地变得好多了（但也不太好，进度还是慢一章（</p>
<h1 id="月23日">5月23日</h1>
<p>到底为什么要让我学量子力学啊！除了去求真可以少上一门课之外想不出来还有什么别的用处（</p>
<p>早上帮刚换了新寝室的室友搬了点东西，以后晚上回寝室就没人陪我说话了。我只是想永远身边能有人陪我闹着玩，三天之后就要失去一个，两年后要离开几乎所有人，想想还是有点难受的。<del>一般到这种时候就要想，按我现在这个情况其实也不好说能不能有学上，就不分离焦虑了，就申请焦虑了（</del></p>
<p>七点一刻到六教楼下才想起来下午待的教室晚上有课，但我忘了这回事，走之前扔了一堆东西在那里，又冲回四教拿。进门看到一楼在一年一度课间音乐会，扫了一眼没有
neruko 就跑了（？），结果冲上楼梯看到 neruko
就站在上面，在整个人卡住的状态下匆忙打了个招呼，事后一想怎么不算一种社长线下交接仪式了呢（（</p>
<p>这作业啥时候能写完啊，急着急着都不太急了。好几门课已经严重落后于进度了，真的，这是最后一个选这么多课的学期了，以后再也不敢了。</p>
<h1 id="月24日">5月24日</h1>
<p>好累啊，周五感觉一般就是混一天过去，上体育课导致的。</p>
<p>喉咙有点痛，开始紧急多喝水吃草珊瑚和西瓜霜含片了，希望明天能好。印象里小时候觉得草珊瑚含片很好吃，后来不知道为什么一直吃的是西瓜霜，上次感冒的时候两种都买了一些，发现西瓜霜显著比草珊瑚好吃，就纯甜，不像草珊瑚一样微甜中带着一股药味，不知道以前咋想的。大概是草珊瑚含片不含蔗糖的原因吧，所以虽然味道很怪但以后大概还是吃这个（？）</p>
<h1 id="月25日">5月25日</h1>
<p>金统大作业启动，然后突然想起来华子还欠着我一笔钱（，急了，周一问问（。钱难挣狗难当，这学期从答疑坊得到的收入越来越少，逐渐变成偶尔去看一眼小程序然后看眼缘答题
<del>简称不怎么干活也做题 PTSD
了</del>，到现在值班次数都不够，<del>我觉得暂且也别申请焦虑了，先申请费焦虑吧</del>（，怎么一天到晚的这么多事要操心。</p>
<p>室友搬完寝室了，虽然刚刚还在微信上和她讲垃圾话，但我真的希望能一直这样。<del>那种事不要啊！室友找了别的室友什么的……！我希望她一辈子都会想着我，我死了之后也暂时……至少持续十年吧！</del></p>
<h1 id="月26日">5月26日</h1>
<p>这个学期变成这个 beyonds，除了高统 2
需要承担责任之外，这个桥梁工程难道就是清白的吗（（</p>
<h1 id="月27日">5月27日</h1>
<p>鼻炎犯了，一直到早上七点都没睡着，九点多又被室友吵醒，然后又被楼长吵醒，过了一会又被上课回来的室友吵醒，兄弟非常恐怖（。下午实在撑不住就补觉了，两点才起来，错过了我能上到的
wjd 讲的最后一节课，有点小难受。</p>
<p>今天下午听了统计中心的两个报告，第一个是生统的听个乐呵，<del>申请 UNC
能不能给点好处啊哥</del>（x。另一个是 signed
network，把我认识的模型和聚类方法都捏到一起了，看到前段时间大折磨的正交矩阵乘逼近还是有点没绷住（。不过之前确实没从生成网络的这个角度考虑过为什么
graphon 和一系列的 model 能够 make sense，看到 one step estimation
想起不知道怎么办好的高统 2，背后一凉。</p>
<p>查了下 Weijing Tang
竟是华子数学系校友，<del>难怪会来统计中心作报告，这地方分明已经烂完了（暴论</del></p>
<h1 id="月28日">5月28日</h1>
<p>累累累困困困，下午走进六教感觉教室太热了，遂转身离开把课翘了（</p>
<p>睡眠质量真的不行，再这样下去真能活得过我那棵空气凤梨吗（。那 618
要不要买个手环（啥（<del>或者直接买个 apple watch 呢（我没事吧</del></p>
<h1 id="月29日">5月29日</h1>
<p>背了一本物理书一本笔记本去教室，一天都没拿出来，搁那嗯算高统，明天还得背着（</p>
<p>急急急，急急急，急急急。</p>
<h1 id="月30日">5月30日</h1>
<p>昨晚通了个宵，通完宵之后躺在床上想，后面 20
天要考六门课，还要交一个大作业，不知道还有多少小作业，就蚌埠住了，更睡不着了（。但是今天白天起来把基物第四章学会了，还赶上了进度，习题久违地会做，心情稍微好了一点。感觉别搁那儿看讲义和课本了，不如看雨课堂的视频总结挑不会的听，<del>然后在讲稿里搜索“考”查看会考的原题</del>（</p>
<p>下学期真要上量子力学吗，我不会数理方程诶。虽然大多数东西也不能说真不会，但我不想算（，要不上个流体力学吧，听说这个东西蛮水的（真
· 蛮水的）。但我现在 cx 的量子力学排在队列
1/51，感觉很有可能补选上，蚌埠住了（</p>
<p>这周实分析要交啥啊，怎么突然不发公告了，怪事。我都把 7.1
写完了，看习题课似乎才到 Fourier，<del>他啥时候这么慢了</del>（</p>
<h1 id="月31日">5月31日</h1>
<p>不是，你这实分析怎么一下把我写完的全交了（，现在已经变成周五上午布置作业，周五晚上/周六早上交了吗，有点恐怖（。好消息是今晚把前两周的习题课卷子都看完了，坏消息是明天的只能明天再说（</p>
<p>爆肝了两天之后感觉压力稍微轻一点了，周末一天往后写实分析，一天整理下基物，晚上回寝室继续赶金统的大作业，再准备下生存分析的
pre 就差不多了，还有多出来的时间的话（不太可能的样子）该开始准备
cheatsheet 了。</p>
<p>然后是定番：</p>
<p><img src="https://s2.loli.net/2024/06/01/hSaMXRbImjiqz1E.jpg" alt="2024.05.jpg"></p>
<p>这个月已经出现了两次重复的数字，一个是 776（可惜 5.5
那天的标签我忘记撕了），另一个是 819，第一次出现 819
是三月份，正好是我第一次去清华科技园店买咖啡的时候。奶茶喝得越来越多了，感觉说明真的压力很大（</p>
<p>虽然五月份有读了一点文章，但 work log 是纸质版的（，下次再说吧。</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇廿三·24年7月</title>
    <url>/2024/07/01/Diary-2024-07/</url>
    <content><![CDATA[<p>歇了（</p>
<span id="more"></span>
<h1 id="月1日">7月1日</h1>
<p>本来今天要早晨六点多起来去海昏侯博物馆，但起来一看外面下暴雨，遂在家补觉，摆烂，读论文（。说是读论文，我感觉和抄书甚至做手账差不多水平，就是平时在纸面上不会这样干，用平板反而比较（，但毕竟这儿也没桌子（</p>
<p>长沙感觉去不了了，现在还在不停下雨，到处淹着，遂退票。在考虑是早两天回家还是在这边多读两天论文（（</p>
<h1 id="月2日">7月2日</h1>
<p>下暴雨，仍然在读论文，然后就是晚上雨停之后出去吃吃饭，很摸的一个状态。</p>
<p>仍然在读一些 signed network
相关的文章，离我导一开始让我看的东西越来越远了（。这两天读的几篇主要是一些不那么统的会议的文章，有点水（，算了能看进去点也行吧。</p>
<p>之前听 hst 说 hd 在和 ypk 一起做概率图模型，最近发了篇
ICML，我还想着这又是什么方向，今天搜了一下发现哈哈不就是我这玩意吗！只不过我和我导一直管它叫网络数据或者
social network，好吧以后不这么叫了，听着有点不像统（</p>
<p>下午六点被告知明早七点去武汉的高铁被取消了，看了下这车也不往湖南开，可能是路过九江导致的。紧急改了后天的票，改订的酒店倒是还便宜了点，就明天去海昏侯博物馆看看金子这样子。感觉以后还是不要在七月初在南方玩这样，当然北京也在下暴雨（吧），反正变数很大。当然也没有几个以后了，寒假要补实习，暑假就暑研了，除了延毕那一年可能会松弛一点之外，就只可能学期中间出去摸一摸这样子。</p>
<h1 id="月3日">7月3日</h1>
<p>还是下雨，海昏侯又咕了，这下得等到从武汉回来再说了（</p>
<p>上午看了 TCL model
的那篇文章，看到它的初衷是想把朋友的朋友（很大概率）还是朋友这种传递关系的概率表示出来，最后证明了还是符合
FCL 的，感觉听起来很可以推广到另一种类型的 balanced triangle，在 random
insertion / wedge closing
的步骤里多加一步控制正负号，再多估计一个参数就好。然后随手一查发现这件事六年前（在这篇发表的六年后）就有人做过了，文章和这篇长得不能说完全一样只能说也没差太多，遗憾离场（x</p>
<p>下午傍晚出去逛了逛，这南昌已经待了四天了，回来还得待两天，每天都在愁吃点什么（（x</p>
<h1 id="月4日">7月4日</h1>
<p>二刷完进巨最终季 part 2，抬到了 9
分，比第一遍的观感更好。之前一直没注意到，最后一话在帐篷里喝酒的时候艾伦看着三笠和阿尔敏那个眷恋的眼神，抛开二刷注意到文戏改编得很优秀，也真的理解了人物动机之后，哪怕只看这一段都感觉已经有
9 的理由了（。</p>
<p>前两天在谷子店没忍住买了一对艾笠的色纸，虽然 MAPPA
出品真有点丑，但看完最终季我已经和画风和解了（。但是回来的路上我姐问我这是一对男酮
cp 吗的时候真的还是有点没绷住（（</p>
<h1 id="月7日">7月7日</h1>
<p>回南昌了，前面几天的在写了在写了（</p>
<h1 id="月8日">7月8日</h1>
<p>昨天说在写了之后就真的开始写了，狠狠吐了一万字，虽然我今晚就想发出来让所有人嫉妒我的才华（嫉妒我的手腕力量），但还是过几天再发吧。写完其中几个在高铁上就在构思的段落之后，我感觉自己文思泉涌无所不能，但把它补完成一篇有逻辑字句通顺的文章的过程中，我只能反复默念：完成比完美更重要。</p>
<h1 id="月9日">7月9日</h1>
<p>一整天了，没有人来找我偷跑我的一万字，封笔了（不是</p>
<p>明天回上海，现在已经是看到上海地铁屏蔽门会觉得很陌生的状态（</p>
<h1 id="月10日">7月10日</h1>
<p>回家了，终于可以开包看一眼就能从安检员身边大摇大摆走过去，抱歉但是各个方面来说第一次觉得上海这么好（（</p>
<p>早上去南昌西站的时候，虽然我拖了个箱子还背了两个包，但显然安检员对我箱子里有什么毫无兴趣，她只让我打开帆布袋把水拿出来喝一口（</p>
<p>另，今天在高铁上成功自己把箱子举起来放到了行李架上，还得继续练。</p>
<h1 id="月11日">7月11日</h1>
<p>在我姐家里的时候就没有网，三台设备全靠手机开热点，现在回家还是没网，好崩溃（（</p>
<p>我妈对茶颜悦色小零食大加赞赏，又买了一堆（。我蹭免邮又买了点茶包，上次那个比普通冷萃茶贵五块钱多一个票据收纳盒的茶礼盒里面还送了个纸徽章，茶包的包装也特别有意思，真的值了。感觉下次想喝茶颜悦色可以去南京或者无锡，至少我对南京的印象还是很好的，可以坐京沪高铁回家/去学校的路上在南京南站中途下个车这样子（</p>
<p>五一的时候我在一边写高统作业一边骂，顺便在口嗨怎么把 GLM
塞到当时在看的论文里，后来高统 II 奇迹般地摸到一个 A-，打破了每门课的 2
都会很拉胯的魔咒（微积分，基物和概率论，但数学课 A-
确实好像也算有点拉胯（啥）。现在我好像真遇到了一个塞 GLM
的机会（，啥时候和 wwc 约着聊一下（</p>
<p>之前觉得看论文看麻了之后读一下光叔的数分讲义还挺好的，现在觉得其实某些论文比数分讲义简单不少（（x</p>
<h1 id="月12日">7月12日</h1>
<p>179 的 EVA
展早鸟特典票我说买就买（，哈哈，但它是国内首展诶，特典看起来确实很值。感觉总不至于八月份没空去看吧，冲了，<del>可免税代购周边</del>（啥</p>
<p>最近都好能睡啊，这样不行吧（</p>
<h1 id="月13日">7月13日</h1>
<p>不太舒服，几乎就是躺了一天，中间起来狂暴做家务（</p>
<p>什么科研，啥都整不出来，急急急（x</p>
<h1 id="月14日">7月14日</h1>
<p>读论文，睡觉，睡醒做饭，做完饭洗碗洗锅，洗完就累了，睡觉（</p>
<p>洗锅的时候感觉我的生活差不多就和做饭一样，不知道在忙些什么东西，但是就是一天到晚都很忙，还糊了满脸油烟这样子。刚坐下来打开平板开始回忆我平时是干什么的来着哦好像是学数学的，我妈神神秘秘跑到我身边说我给你买了两个小礼物，打开淘宝一看是两盆花。我感觉她已经在想象家里鸟语（指我每天不知道在说什么鸟话）花香生机勃勃的这样一个场景，但我只觉得眼前一黑，我一地鸡毛的生活里，真的，再塞不进两个需要我照顾的东西了（</p>
<p>今天在厨房里发现了九个插座。不是，它到底是想起到一个什么样的作用啊（挠头</p>
<h1 id="月15日">7月15日</h1>
<p>摸了（，终于把这个 tutorial 看完了（（</p>
<h1 id="月16日">7月16日</h1>
<p>今天看一个 signed Laplacian，完全没看懂，一上来开始说可以用振子理解
eigenvalue（可能我也没理解对）blahblah，遗憾退场（</p>
<p>这 Umich 好喜欢研究 signed network 啊，搞物理的也在发 signed
network，<del>是因为 Harary 是 Umich 的吗</del>，怎么不算是歪打正着地离
dream school 近了一点捏（并没有</p>
<p>不是，这情况怎么急转直下，变成了我现在就已经有点想回学校了，但是我
EVA 展的票要 8.2 之后才能去看所以回不去啊我超（</p>
<h1 id="月17日">7月17日</h1>
<p>睡前在想为啥没有人在 adjacent matrix 里放 <span class="math inline">\(\pm
i\)</span>（暴论），思考了一下这得有多少种三角形然后就迅速睡着了（</p>
<p>这九院口外挂号挂了一周了还没挂上，想了想感觉还是下学期或者暑假末尾直接北医三院吧，体验下公费医疗（。上次拔左边的智齿前前后后拔出了一次托福的价钱，虽然确实弄得挺好的但还是（</p>
<h1 id="月18日">7月18日</h1>
<p>开始 <del>读 Stein（多大的人了还在读 Stein（</del> 补石头门，看
bangumi
评价好像前期节奏很慢，大概正好每天一边吃饭一边看。初中的时候好像就想看了，但是在游戏和动画之间犹豫不决，结果
neither 了（</p>
<p>今天想把蒸锅拿出来洗一洗，结果在橱柜里找到了厨房的第十个插座（，它到底是想起到一个什么样的作用啊（二度</p>
<h1 id="月19日">7月19日</h1>
<p>今天外出，回了一趟宝山，顺路去宜家 <del>零元购</del>
把积分兑成了一个靠垫和一堆小垃圾（。气温 38
度我在户外健步如飞，感觉比（声称）36 度的南昌和武汉舒服多了（（</p>
<p>所以我（看完 EVA
展之后）到底啥时候回学校（，之前担心的一些事情现在好像都不需要我了（？），现在都有点疑惑为啥这个暑假没去施工实习，真的就单纯因为怕热吗（。现在每天就是在家里不务正业地乱看文章（但我的正业到底是啥），已经从
signed network 看着看着不知道顺着哪条线被带到 matrix estimation
去了。正好下周一统计中心（现在改口叫统计系我都还不大适应）有个报告讲这个，顺便听一下。为什么要在日记里写这个捏，因为我怕我忘了（。</p>
<p>导针对我想跟他聊聊 signed network
的邮件向我提问：上学期让你看的那两篇怎么样了，啥时候讲一下？我哈哈大笑，什么
stochastic block
model，它真的太丑了所以定义都忘记了捏！这就再去看一眼（。</p>
<p>而且我的智齿好痛，今年已经肿了无数次了，虽然北医三院挂号看起来也很难，但想回去拔牙（。</p>
<h1 id="月20日">7月20日</h1>
<p>回去看学期中间看的那篇 adjusted
covariates，发现它和我前段时间看的一个 signed network 都引了同一篇 2020
年的文章，<del>考虑到 balanced theory，出现 co-citation
就不得不去读一下了</del>（x</p>
<p>但说实话这样一读我完全理解之前那个 signed network 了，就是给 2020
年那篇套上了一个选择符号的步骤，这和六年后在 TCL
里加正负号不就是一样的思路捏（，不过他多做了一个优化所以多推了若干
bound，用了一些 <del>花里胡哨的</del>
MLE。但是这篇把故事讲得很好，我的理解是造了一个也比较符合直觉的
population level balance 的概念，然后成功从这里引过去了。本质上是 inner
product model 在 signed network 里的推广，但故事讲的是 balance
这样子，<del>也顺利吸引到了我这种因为对 balance 和 signed network
感兴趣而来的人结果最后怎么吃了一大口 ERGM（x</del></p>
<p><del>来都来了，不如去看下 Terry Tao 那篇 matrix completion
吧！反正之前 low-rank method for signed network 也用到了来着！</del>
<del>那我的汇报到底要说点啥捏（</del></p>
<p>很久没追番了，最近竟然在以追番的状态看 7
月那部擅长逃跑的殿下（，我也不想的，<del>但是很久没有这么命中我好球区的男主了</del>
但是作画转场真的顶级，单纯欣赏画面也值了（</p>
<h1 id="月21日">7月21日</h1>
<p>这石头门好几天没看现在有点不大想看了（，前期节奏好慢，但也还是再坚持一下罢（。然后今天去把辉夜姬物语看了，我之前一直以为这是宫崎骏的作品，但我不太喜欢宫崎骏（这是可以说的吗？）所以一直没看，今天才发现不是，遂补（</p>
<p>最终还是去把 bangumi 评分调了，给进巨第三季 part 2 和 EVA
TV、<del>真心喂你</del> 真心为你拉到了 10 分，大概确实 9 和 10
之间还是有一些必须区分开的差距，别的 9
看了半天感觉实在动不了了，只有想往下打到 8
的（。但也没往下调，毕竟当时打 9 也一定有我的道理（？</p>
<p>看了一天 error bound，晚上盯着不等式里的 <span class="math inline">\(e^{M_1}\)</span> 陷入困惑，k-th iteration 的 error
metric 是 <span class="math inline">\(e_k\)</span>，个么 <span class="math inline">\(e\)</span> 是啥？再一想，<span class="math inline">\(e\)</span> 就是 <span class="math inline">\(e\)</span> 啊（（</p>
<p>一直担心（并没有）的事情终于发生了。很久没说过话的高中校友唐突开聊，我对他的了解止于他大一的时候从
FDU 数院转出了，然后：</p>
<blockquote>
<p>友：你现在在搞啥科研吗？数学哪个方向捏？</p>
<p>（我内心：直接说统计是不是有点太宽泛了，social network
听起来像人文社科的，要说 random graph
也不是不行，但我当时听到概率图模型这个名字的时候都没意识到就是我在搞的这个东西，说英文会比较容易理解吗？但是已经犹豫很久了还没回是不是会显得有点没礼貌啊，就
network model 吧！）</p>
<p>我：network model</p>
<p>友：哦哦</p>
<p>友：那你是本科学数学，研究生转码？</p>
<p>友：是看开了吗</p>
</blockquote>
<p>（挠头</p>
<h1 id="月22日">7月22日</h1>
<p>成功听到了报告，甚至下午三点半就打开了腾讯会议（但前面这第一个报告是在说啥），对我来说很厉害了（？</p>
<p>之前只看过一篇关于 Kronecker product 的文章，讲的是怎么用一个 <span class="math inline">\(2 \times 2\)</span> 的矩阵反复做 Kronecker product
得到一个 <span class="math inline">\(2^N \times 2^N\)</span> 的矩阵作为
adjacent matrix，然后它和 Chung-Lu model
在一定条件下是等价的。今天听的这个我一开始以为也是差不多的目的，结果怎么唐突推广到
time series（，但作为 SVD 的推广，把维数也加进 penalty
还是蛮有意思的。</p>
<p>有的时候觉得我不会是个废物吧？一时兴起开始学
RKHS，找了个讲义结果从早看到晚，一天啥都没干刚看明白（。</p>
<p>感觉很多时候还是这个阅读次序不对（后来看 norm 的花式 bound
也出现了一些阅读次序的问题），一开始随便找了个 notes，发现它努力地讲得
heuristic，但我看不懂（。后来去看 V1ncent19
的笔记，没直接看他标出来那本书，也有点疑惑。最后才去看 wiki，一说 Riesz
Representation theorem 我就完全理解了（，在 RKHS 里考虑一个泛函 <span class="math inline">\(L_xf := f(x)\)</span>，由 Riesz 和 RKHS
的定义知存在 <span class="math inline">\(K_x \in \mathcal H\)</span>
s.t. <span class="math inline">\(f(x) = \langle f, K_x \rangle =
\sum_{i=1}^{N_0} f_i K_{x,i}\)</span>，再定义 kernel <span class="math inline">\(K(x,y) = \langle K_x, K_y \rangle\)</span>
就能满足所谓的 reproducibility property 了，一般可以直接从 kernel
的形式看出来 <span class="math inline">\(K_x\)</span>
是个啥。整那些乱七八糟的干啥捏（不是</p>
<p>感觉，感觉可能还是我有问题，这个也许是最不好懂的，但我真的很依赖严谨的符号表达（</p>
<h1 id="月23日">7月23日</h1>
<p>约到了上海书展 8.15
的票，虽然是普通的年度固定节目，但一想到明年暑研好像没啥机会去了，后年八月中旬人可能都已经跑特了，买了（。不过至少还能退，之后万一要早回学校的话就退掉，反正其实也去过好多次了。想想去年六月初上影节还上了
EVA
终，也是国内（至今）唯一一次上映，期末周在学校天天大喊我也想去补完（。这个可能以后是真的没机会去了，以前也没去过（</p>
<p>上博那个古埃及特展整个暑假期间的票都没约到，不过反正展期有一整年，寒假可能还能再来（。今天才知道上博东馆终于开了，过段时间打算进行一个去，大概可以和
EVA
展同一天刷完（说实话大悦城五楼就那点地方，不买一堆谷的话估计也逛不了太久，就拍拍照看看原画稿这样子），看情况（</p>
<p>有的时候真挺无奈的，今天（凌晨）看 kernel PCA，发现其实让我说
classical PCA 的基本想法我是说不上来的，虽然这玩意我在 dwl
那里学过，也知道就是算
eigenvector，但好像基本没懂到底是怎么个降维法，今天一看就明白了。不知道为什么我对她的
PPT
实在是有一些阅读障碍（，上课也听不动。春季学期没啥压力的话补一个数学系的多元统计好了，大概就
PDE + 多元 +
泛函这样子，再补几门专业课（。听起来压力不大，难道我真在上大四（？</p>
<p>今天突然怀疑，难道我是学期中间甚至加上期末周过得太舒服了才会产生放假就快点回家的想法（？</p>
<h1 id="月24日">7月24日</h1>
<p>摸了一天（</p>
<h1 id="月25日">7月25日</h1>
<p>时隔一个学期又生病了，再摸一天（。你还别说，春季学期虽然各方面来说都不如秋季学期过得舒服，但没那么容易生病，看来我的话秋冬还是得好好戴口罩（</p>
<h1 id="月26日">7月26日</h1>
<p>活过来了，但一周（指工作日）又过完了（，那我的报告要怎么做捏，下周复下周，下周何其多（</p>
<p>每次读一些严肃的统计期刊（确信）就不可避免地要看几十页推
bound，读完就迫不及待地告诉导我可是把这个看完了（？）然后找出之前搁置的出自一些
cs 顶会的方法看起来很新颖但其实推导也没几页还从不跳步的 network science
相关文章调理一下（</p>
<p>问题是这个推 bound
的过程有啥必要在报告上讲吗，<del>反正都是初等的魔法</del>，另一个推广他这个模型的文章也就是在模仿并推广这个魔法，那他这个魔法是从哪来的捏（，可能还是读得太少了（</p>
<p>火星了，刚知道四号线浦电路站要改名 <del>八竿子打不着的</del>
向城路站了，爷青结，下次去上博东馆的时候顺便去看一下。这么说来要不浦东美术馆也顺便去一下吧（但不要抱太大期待就是了，之前还被中华艺术宫吓晕了一次（</p>
<h1 id="月27日">7月27日</h1>
<p>已经为 EVA
展要带什么无料去交换愁了半个月了，凌晨一个十年没正经画画的人突然爬起来画了丽香大头准备印名片大小的小卡（，虽然上色之后有点灾难，还考虑了一下要不直接线稿发出去当填色小游戏，这样正好卡面也不用做工艺了还能省几块钱，但反正！免费送的东西没人会嫌弃的吧（？</p>
<p>卡背印的都是展览名称/2024
上海之类的内容，但我下单了才后知后觉一下子印了 200 张（200
张起印）一次肯定发不完，之后可能还会带去别的地方乱撒（，卡背过期了应该也没啥问题吧（？</p>
<p>最近追番都没啥干劲（？，魔圆异闻带和石头门都看了一点就不想继续了，只有逃殿是真的在追番，难道一周看一话才是正常的频率（</p>
<h1 id="月28日">7月28日</h1>
<p>出门一天，明天又是周一，7
月要过完了，这么长时间我干什么了，这现在一个月真还有 31 天吗一分钟还有
60 秒吗（（</p>
<h1 id="月29日">7月29日</h1>
<p>昨天时隔 18
天喝了回家之后第二杯奶茶（，待在家里确实有助于控糖，今天喝了一个多月以来第一杯咖啡，然后也已经一周没锻炼了，很坏。还好家里没有秤（<del>倒也用不着秤，我现在已经不需要考虑体重了，单纯是想要肌肉（</del></p>
<p>苏州也要开茶颜悦色了，那岂不是骑到上海西站跳上 11 号线去花桥转苏州 11
号线就能喝到（？）<del>但是上海西站有直通苏州的高铁，才三十块钱，半个小时就到，为什么要坐
11 号线（</del></p>
<p>终究会迎来这么一天啊！我现在每天都觉得，为什么要延毕捏？关键中间这两年好像也没学到什么东西！科研还是全堆到申请前一年了，大概率也啥都整不出来，那我带着延毕一年的这个情况申请是不是还不如不延毕直接申哪？</p>
<p>虽然平时都是延毕嘿嘿嘿延毕哈哈哈哈哈哈我要延毕啦的状态，但是果然还是会有怀疑自己的这一天（。不过现在内耗也没意义了，都这时候了，已经没有不延毕的选项了，没什么好害怕的了，硬着头皮上吧！塔塔开！实在不行去个
QS 200+ 的学校也能拿个 PhD title
回家当高中老师，大不了教语文英语什么的（<del>真的可以吗？我高三那年的五月，十几个复旦中文系的研究生在我校抢一个语文老师的职位，英语应该一样卷吧，个么我高中数学竞赛也没啥拿得出手的奖项，实在不行去我那个乡镇初中上班吧！</del>），那我下学期抽点时间把教资考出来好了！（</p>
<h1 id="月30日">7月30日</h1>
<p>又到了七月底喜闻乐见的年度理相册环节，凌晨一边翻相册，一边二倍速把魔圆外传第一季看完了，并锐评：</p>
<blockquote>
<p>本作（主线（？））人气很高，第一季 6.6
分第二季扑街，如果不是连着看都很难记得上一话在讲啥，有中国元素，有女酮，勉强发色认人，会突然出现新角色，之前戏份不少的连着摸鱼好几话，所以这是星团（？？//
看看特异点</p>
</blockquote>
<p>然后才发现我竟然没给星点抛弃（</p>
<p>另，今天才知道浦东美术馆门票 80 块（是学生票，原价
100），之前还以为免费的，沉默了。上一次花这个价钱看展还是 2020
年上海浮世绘大展，包含富岳三十六景（部分）尤其神奈川冲浪里，今时不同往日，毕竟当时还是一年自费不了几百块的高中生，也就算了。再一看线上也能买文创，再再一看也不咋地，再再再一看浦美近期的展览，就觉得单纯是想买点东西送人的话，我自己就没必要进去了（。</p>
<p>感觉这样出去溜两天的行程排不满，正好今晚看到猫未未的上海签售场开始预约了，滑铲下单了两本漫画打算签了送人（，<del>虽然其实应该是我看完之后再送这样子（x</del></p>
<p>另外，今天收到打印的无料了，效果挺不错的，尤其是巴掌大的小卡拿远点看就没那么丑了（。考虑到发无料的时候至少都会保持着那么一个社交距离，好好好（。</p>
<h1 id="月31日">7月31日</h1>
<p>今天陪我妈去医院，早上六点多爬起来挤 11
号线感觉人生都没有希望了，还好至少不是从嘉定那边上车。到医院还就那个，等叫号一小时进诊室挨骂五分钟，不出意料地被两个科室互相踢皮球这样子，过两天换个我们高贵的交医系医院去看（</p>
<p>然后去逛了下 Costco 浦东店，在店门口滑铲开了 299 块的年会员
<del>准备过一段时间全款退掉</del>，进去一眼挑了一大袋 Ritter
Sport，主要如果不是在这家店里看到的话，已经完全忘记这个牌子了。以前在网上可以买到很多其他口味的，好像还有夹心是饼干的款式（巧克力夹饼干，不是饼干夹巧克力（比划）），但印象最深刻的还是红色包装的那款（查了一下是扁桃仁酱馅的黑巧，就，听起来就有点地狱），真的很难吃，不要买。店里只有五种口味的什锦装，但还是买了，相比网店真很便宜。后来逛到生鲜区，他们这边的试吃真已经
next level
了，卖鸡肉的柜台旁边专门有人炖鸡汤盛给路人试喝，很震撼。但生鲜都真的不错，同等价位来说分量远超盒马品质远超永辉，挑了两只童子鸡回去后面几天一只炖汤一只炒肉吃，其实牛羊肉和肋排也想买点回去（更想直接买一只羊腿），但也是和山姆一样的问题，份量太大了，家里只有两个人根本吃不完。相比之下
<del>穷鬼天堂</del> ALDI
就很会走社区超市的路线，宣传反对会员制和大分量，现在不知道吃啥就趁周末打折在小程序上拣便宜的买，一周的菜和半成品肉就有了。许愿
Costco 开到市区来（感觉不可能的啦！）或者至少把配送距离开远点（。</p>
<p>下午回家累得不行，打开空调没换外衣就直接躺在地板上睡着了，太自由了（，让我想起来那句“当碎鸡蛋只能在垃圾桶里度过它最后的时光时，它自由”（</p>
<p>个么这个月结束了，到底在干啥捏（在做饭（</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>日记·篇廿四·24年8月</title>
    <url>/2024/08/01/Diary-2024-08/</url>
    <content><![CDATA[<p>怎么这么摸啊（</p>
<span id="more"></span>
<h1 id="月1日">8月1日</h1>
<p>摸了，我现在感觉我这个科研是跑得越来越偏了，什么时候开始看 phase
retrieval 的捏？<del>难不成真就看到 Candes 之后 chua
的一下就点进去了吗</del>（，之前不是不在 network modelling 至少也在
matrix estimation 的吗（。</p>
<p><del>但你要说的话，linear regression 是不是也算一种广义的 matrix
estimation（？</del></p>
<p>导怎么又不理我了捏（，感觉好像还是不太熟（x</p>
<h1 id="月2日">8月2日</h1>
<p>收到了托福七折券邮件之后纠结半天，感觉明年九月就算真的暑研回来会变强（感觉也不会），申请季滑铲考这玩意也有点恐怖（，临时报了一次九月的，希望这次能再见了所有的标化考试（。最近是真有点低迷了，导也不怎么想理我的样子，再准备一次托福也算是合理利用时间了罢（，毕竟事实证明也只有口语还有点问题了。</p>
<p>最近在看一些 computing
的话题，主要是之前看到的几个不等式来自一些分散的话题（。今晚又开始
network 了，看了一个 multi-layer 的感觉有点意思，一眼 Biometrika 2024
还有一篇，再一看 J Zhu，等下是我想的那个 J Zhu 吗，还真是（</p>
<h1 id="月3日">8月3日</h1>
<p>今天外出，主要是去猫未未的签售会，龙华那边去哪里也都不大方便，也不知道签售走不走得开，所以就只安排这一件事情了。睡到十一点才起，之前看到武康路开了个霸王茶姬新店，买一杯就能抽限定徽章，精准捕捉我这种目标群体，遂去，遂抽到，满意离场。当然如果抽不到徽章的话说明抽到了更好的东西，但反正我就只想要这（</p>
<p>然后去签售会，互动环节没能进内场，但屏风后面也可以听到看到，一边听一边拿了本书店的漫画样书读，是藤本树的《蓦然回首》，赢两次。合影的时候有几张可以看到屏风后面伸出来一只拿手机的手，那个就是我（。排签绘的时候听到有人说网上买两本书还不到
60，现场买每本送一个透卡，但按原价
59/本卖，感觉赚了。是这样没错，但如果不是有这个活动的话，我前两天是不会在网上买两本的，确实是售了（</p>
<p>等签绘叫号的时候在书店里到处溜着找样书看，拿了一本《被寄生的家庭——尼崎连续离奇死亡事件的真相》，但实在记不住人名和人物关系，读了几十页知难而退放了回去。后来摸了一本博尔赫斯的《恶棍列传》，一百来页的小书比较好读，看完又找了本一直想看又一直没看的《长安的荔枝》，翻了没几页就叫到号了，签完回家。唯一失策的是出门的时候把平板放进包里，嫌沉又拿了出来，不然也不至于电量焦虑这么严重，而且今天其实莫名有点看不进书，中间还换了几本，翻了几页就没看下去，<del>感觉是刷
TPO
的好时机啊！</del>大概该给手机换个电池了，当然其实暑研之前也该换个手机了（</p>
<p>你还别说，这 39 度且下了场大雨补充湿度的上海，终于有那个 36
度的武汉的感觉了（乐</p>
<p>虽然我这个人看起来每天都挺乐的，但情况其实真的很被动（，我时不时真的会想去找个班上算了，虽然说出来也没啥意义，还是瘫在家里一动不动。不过也许人还是要开朗一点，实在不行还有港新，哈哈（</p>
<h1 id="月4日">8月4日</h1>
<p>之前一直想理解但是没理解的一个（一些个）事情是，balanced signed
network
在理论上等价于正负二分，虽然你可以每个点遍历一遍把它们扔进两堆，但应该怎么快速地二分；按照
statistician 的思路就要考虑 noise（也就是不那么 balance 但是比较接近
balance 的网络）的二分性了，能不能按照 cut
来做一个优化，最好能做到什么样子；signed Laplacian 之所以还叫做
Laplacian，那它有没有做一个 generalized spectral clustering
的可能。今天去看了一个 tutorial，我完全理解一切（。之前看 spectral
clustering
tutorial，因为它的确从很多角度论证了这个思路是正确的，倒也没有特别关注
cut，现在只能说果然世界的尽头是优化（乐</p>
<p>感觉现在关于 signed network clustering/modelling
的工作的确不算多，unsigned network 都已经在玩 adjusted covariates
了，可以理解，因为真的不知道要怎么办（。</p>
<p>我测，上周思来想去悄咪咪地把纳指抛到半仓了，这下怎么还真寄了（。无论如何还是留下一半，就，要有信心（</p>
<h1 id="月5日">8月5日</h1>
<p>确定了下周去南京的行程，其实也很久没和我妈一起出去旅游了，南京的话还算熟悉，体验应该不会差。但其实我除了南京博物院
<del>和库库喝茶颜悦色</del>
之外没什么很想去的地方了，可能先锋书店之类的独立书店算一个，高一的时候学校带着去过绝大多数景区了，反正这个天气人不能至少不应该再爬一次中山陵吧（</p>
<h1 id="月6日">8月6日</h1>
<p>现在大家对于到底什么是 signed stochastic block model
怎么还没有统一的定义捏（</p>
<p>看了篇文章，我真的抓耳挠腮：他在说什么疯话，是我疯了还是这个世界疯了？为什么要给
norm 套绝对值捏（</p>
<h1 id="月7日">8月7日</h1>
<p>去了 EVA
展和上博东馆，二者体验都挺不错的，最大的问题是上午逛到一半突然来生理期了，布洛芬吃晚了导致一下午都痛得几乎无法行动，在上博的大多数时间一直蜷缩在座位上，下午四点多才缓过来，已经快闭馆了。虽然我在
EVA 展没出 cos，只是在发无料和满场找 coser 集邮，但这不就完全是在 cos
明日香名场面吗（（</p>
<p>比较乐的是今天用 EVA 的无料换到了巨人的无料，赢麻了（</p>
<p>之前一直嫌弃今年夏天限电，商场和地铁里面空调都开得很弱，没太大作用。结果今天我捂着肚子走上二号线冻得一激灵，怎么就它这么冷啊（，上博东馆冷气也很足，不像之前江西/湖北省博（<del>到底到什么时候才能不再鞭尸这两个地方捏</del>）空调就和静安大悦城差不多水平。本来就难受，早上没想到会来生理期还吃了冰的，还带了个胶囊咖啡就着地铁站取的瓶装水当美式灌下去了，偏偏就今天遇到空调开得冷的这俩地方。其实也不好说是不是生理期这个身体的温度感受会发生变化，以前也经常会觉得本来正好舒适的环境在生理期变得有点冷。蜷缩在座位上还行，起来走两步就痛苦面具，青铜器馆人又多得要命（我理解都是来看大克鼎的），基本上没怎么仔细看就出去了，只能安慰自己初中的时候就看过上博的青铜器，现在只是再仔细逛逛而已。</p>
<p>但说实话最喜欢的还是陶瓷馆那个展厅，布展水平真的很高，这里就要鞭尸某个叫做瓷都的地方的省博了（<del>到底什么时候才能不要再鞭尸江西</del>），明明有一整层都拿来展示陶瓷和现代瓷器艺术，结果一圈看下来给人印象最深的是现代瓷器艺术展厅里专家们做出来的那些丑东西，真正珍贵的文物反而完全留不下记忆点。上博布展都是按照时间顺序和瓷窑归属来没错，但也会稍微打乱和融合，我看下来感觉最突出的一点是，同一个展柜里的东西色调和纹样互相配合得相当舒服，能让人感觉在这个环境里每一件物件都是独特的美的，并不是直接按官窑汝窑钧窑这样分成若干堆东西旁边写个介绍而已。<del>也可能是展品本身确实都品质很高，我实在不舒服确实也就看了个大概，不太清楚</del></p>
<p>另外四楼可以透过玻璃看到工作人员修复文物的现场，还有修复方法的大概介绍，确实都是在别的省博没看到过的。上次逛博物馆觉得耳目一新的还是湖北省博（<del>看吧这次没再鞭尸了</del>），史料考证的展厅布置得很有条理，另外曾侯乙墓的出土确实都太强了，<del>没办法谁叫他就葬在这块地方呢</del>（。上博展出的确实大多数都不是本地的东西
<del>但如果把江浙也叫本地的话就没事了</del>，另外也有不少依赖捐献得到的藏品，整体作为艺术博物馆展出确实已经符合主题也超出期待了，<del>总感觉背后凉飕飕的，总担心不这么叠个甲的话会被蛐蛐沪爷您吉祥</del>（。体验挺好的，就是身体不太好（（</p>
<h1 id="月8日">8月8日</h1>
<p>很久没看到这么单纯的论文了，才四个 lemma，<del>果然 signed graph
还是一片蓝海</del>（乐</p>
<p>之前春季学期有一个幻方的 HR
加我微信问我要不要去实习，一看实际上是搞大模型就以科研为理由推掉了，目前面前又有一个九坤的机会，待遇很不错，冲着这个日薪也有点想去。虽然感觉一周四天
onsite
还是有点多了，不考虑转正的话应该能摸一点，不知道能不能工位摆烂写作业。</p>
<p>下个学期应该要换海外导来自救了，把能找到的海外 network
方向华人都过了一遍（非华裔也有一些，看命吧），其实临时接触新话题（某种程度上来说也算是多接触点别的方向）我也愿意，既是有好处的又不是很难的事情，但无论从哪个方面来讲，最佳人选不过那么一两个，他们真的愿意指导这么长一段时间吗。只能说是很艰难的求变，此番动荡，究竟为何，又将去何？</p>
<h1 id="月9日">8月9日</h1>
<p>第一次知道 time series clustering 是把数据先用 correlation 变成
signed graph 再 cluster，那这个思路岂不是非常通用（</p>
<p>狠狠刷了半天托福，相比春季水平已经大退步了，但不管怎么样我的水平也就是高考那点底子，听力磨一磨耳朵总还能回到原来的程度。<del>要让早上起来做一个
test ready 像喝水一样自然</del>（</p>
<h1 id="月10日">8月10日</h1>
<p>今天在对着 QS ranking 拉表，找可以套 research intern
的老师，结果被这个榜给幽默到了，联想到上海某 QS top 50
人才引进落户政策，原来 CMU 还不符合要求啊！</p>
<p>对时间的流逝在读论文这件事上有了新的体会，读一个 2020
年提出的方法，发现作者在 2023 年又 regularize 了一下，再一想 2020
其实也过去挺久的了，也不是很新，之前还觉得 2018 挺新的（</p>
<h1 id="月11日">8月11日</h1>
<p>感觉在 test ready 官网上做题正确率比做 TPO 高得多，难道是因为它的 UI
比较好看吗（（</p>
<p>这个表每天看几个学校，一周不就搞完了吗？最大的问题是数学系统计系数据科学系甚至
EECS 都得找，稍微有点麻烦，以及 network
这个词的语义实在太多了（。意外的收获是找到了 <del>偷窥到了</del>
若干未央零字班申请者，看起来结果是不错的，倒也对找 remote intern
有信心一点了。做 network
的说多也不多说少也不少，<del>目前已经功成名就的比较多，华人 AP
比较少</del>，但主要是不管遇到啥样的 graph 还是 network
都得点进去仔细看看，到底是 neural network 还是 biostat network 还是
network analysis 还是 graphical neural network（（</p>
<h1 id="月12日">8月12日</h1>
<p>摸鱼拉表（<del>感觉这个行为确实和拉表差不多，我为我从未涉足饭圈却又这么了解饭圈而感到羞耻</del>，看
<del>王子屯</del> Princeton 的统计中心，看到 Danqi Chen
吓了我一跳，我说我来对地方了吗？一看网址 csml，好像确实不对，不过你们 ML
现在难道已经被开除 CS 籍所以要单独拿出来写了吗？再仔细一看 Center for
Statistics and Machine Learning，怎么又对了（</p>
<p>仔细一想，再过两周左右就得回北京了，差不多回去之后这个时间就可以开始套
intern，在这之前总能把表拉完。这个暑假做的事情确实比以前的暑假都多，但到底在干什么，研究了很多东西但仍然毫无头绪，导已经不回我邮件快两周了（乐</p>
<p>找了个 signed network
的综述，后面两天高铁上随便看看。<del>天知道为什么这么长时间过去了我突然开始看
signed network
的综述？难道是为了确定自己知道其中百分之多少的东西吗</del>（（</p>
<h1 id="月15日">8月15日</h1>
<p>再去一趟南京还是觉得不错，也可能只是因为它比较像沪，像回到家了一样（。回来写日记，打开发现走之前我说我要看综述，羞愧难当。最大的问题是这两天都没睡好觉，我寻思着我这个睡眠质量，怎么放假了还是这样，能活到毕业吗（。</p>
<p>今天摸鱼的时候刷到一个 <a href="https://www.bilibili.com/video/BV11MYLebEuc/">手刹</a>，我本来寻思着不就是有人鲨了个自制谱，看完大受震撼（。想了想高中毕业之后就没怎么打过音游了
<del>最后的印象是物理等级考前晚在刷
Vindication，很松弛</del>，也没有什么特别的原因，就是在寝室里打的话怕室友觉得吵，那更不可能去教室打
<del>其实没人的话也不是不行</del>，好像就只有压力大的时候会敲一敲，每次简单摸两下也都会因为水平不如从前了而很快放弃。</p>
<p>但其实高中的时候因为我的华为吃音，背面还有个凸出来的摄像头，在桌上完全放不平，还把早就不用了的
iPhone 6
拿出来打了一年音游，当时最期待的就是攒钱买个平板打歌，但去年买板子的时候想的是方便看
slides 和
paper，完全不记得当时这个需求了。今天看完这个谱饶有兴致地回去刷了几把
Quon，<del>我多指无力，双指不精，交互松散，读谱迟钝，没一个动作像样，就我还想打音游吗，做什么美梦</del>，假期倒是可以在家里玩玩。</p>
<p>再一想，大家解决没地方打音游这个问题的方法好像是出去打
maimai，那没事了，那还是有点太可怕了（</p>
<h1 id="月16日">8月16日</h1>
<p>前天在南京先锋书店其实体验也不是特别好，主要是我的问题，拖着两天睡了八个小时的身体骑车过去就已经累得不行了，店里人太多空调温度也不够低，就去挂了个明信片拍了拍照。看书这个环节今天去上海书展补回来了，其实单看薅回来的无料（？）也完全值回票价（十块钱），一趟还把我的盖章本盖满了。</p>
<p>很喜欢那个钱从四面八方来的猫猫（是一个亚克力小立牌），磨铁的胶片卡，上财出版社送的集章册（不然我的本子满了之后根本没地方盖了（，还有广西师大出版社送的诗集。本来还认不出来这是哪位，翻开第二篇就是《一个工人阅读时的疑问》，原来是你（。</p>
<p><img src="https://s2.loli.net/2024/08/16/ocpqX9li5MbZdwz.jpg" alt=".jpg"></p>
<p>去的时候想着只看不买，可以现场读一读回来网上买，不然无论是背回家还是带去北京都很累赘。但其实有些优惠力度还可以，整体价格是大于等于网上，像华师大出版社这样的大厂（？）折扣力度会比较小，小型出版社和独立书店相对实惠一点，买了三本。为了不暴露我鄙薄的品位，就不说是什么了。</p>
<p>书展三分之一是无料展，三分之一是盖章展，剩下的大约才是书。明天好像
<del>汪小姐</del>
唐嫣和《繁花》的其他一部分演员会去现场，票都提前抢完了，书还能占到六分之一就挺好的。确实盖到了很多有意思的章。</p>
<p><img src="https://s2.loli.net/2024/08/16/4YMxy6vocCnGmbd.jpg" alt=".jpg"></p>
<p>天津人美出版社和江西教育出版社这两个章，已经比我去这两个地方旅游盖到的还好看了。我一直很喜欢广西师大出版社的书，这个肥啾是今天盖到最可爱的一个了。精神
SJTU 人当然要盖一个，不过里面卖的大多是教辅，没仔细看，对面 FDU
出版社的章要排队，没盖。看到北大出版社的时候真乐出来了，但没有华子，华子不行。华师大出版社的摊位是高校出版社里最大的一个，大多也是教辅，只能说在你沪上学的话从小到大谁没做过华师大出版社的教辅，但看到全套小蓝本的时候倒是真的
PTSD 了一下。浦江教育出版社这个也挺漂亮的，但绘本为主，没仔细看。</p>
<p><img src="https://s2.loli.net/2024/08/16/zgFitPmWpcl7ZG8.jpg" alt=".jpg"></p>
<p>看到岳麓书社的时候还是乐了一下，我有一本岳麓书社出版的《古文观止》，初中的时候练字作业可以自由选择抄写的内容，我就从头到尾抄古文观止，倒也顺便读了一些，虽然一开始的出发点只是希望能自我感觉好得不得了。前两天挤早班地铁的时候看到一个哥们腿上摊着一本古文观止睡着了，书页翻在郑伯克段于鄢和周郑交质之间（差不多就是背单词背到
absolute
的这个位置吧），我扑哧一下笑了出来，读了一堆古文观止这么多年来还是第一次直观地用上，看来知识的尽头还得是攻击。</p>
<p>这个霉霉不知道是在哪儿盖到的，可能是阅文集团那里，一看到霉霉就想起青春期干的一些破事，虽然初中的时候我表面上一直说我不喜欢霉霉，我喜欢实验音乐，喜欢电音，问就是爱听
Marshmello 和 Diablo，认为 techno 虽好但还是 trance
更动人，实际上晚上回去会缩在被子里循环整张《1989》。其实只是因为当时大家都喜欢霉霉，说自己也喜欢会显得不够酷，也仅仅是因为我是个装逼犯。当然后来也逐渐不怎么关注了（去搞二次元了导致的），前段时间去听
Fearless (Taylor's
Version)，只觉得她不再明亮的嗓音让班卓琴都显得迟滞了。说起来阅文这个出版商也蛮有意思的，挂着
good stories never end 的牌子，我进去想看看你们出版了什么 good stories
啊，竟然是庆余年和全职高手，没绷住。</p>
<p>旁边那个“日记大王就是我”是在某个绘本的摊位盖到的，这边其他的章我都没盖，就盖了这一个，毕竟是我本人。左下角那个
PAPER PLEASE 我也不知道它本来是想表达一个什么意思，但反正我们这种需要
paper 的人，盖就是了（当然我还停留在需要读 paper
的程度，别人是需要发）。</p>
<p>写完又不理解了，我怎么这么能讲垃圾话捏（</p>
<h1 id="月18日">8月18日</h1>
<p>定好了回北京的日期，暑假就这么匆匆忙忙地快要过完了。要说没怎么学也不完全是，对
network
确实比较完整地入了个门，也有信心秋季直接找海外导，只是我还不知道怎么接受“如果找不到应该怎么办”这样的结果。其实我早也有想到，在我导这边的话他本人已经
Associate Prof
所以没什么压力，何况我是要出国，搞数学也没得打杂，不管怎么 push
大概毕业之前我也发不出论文来，对我不上心也是正常的。之前一直对延毕是一个很乐的状态，临近了就笑不出来了，时常有失群落伍的惶恐，何况我这个科研进度，就算当我降转也实在有点落后，你统的学科特点摆在这里，当即只能想办法凑推荐信，也是希望能有人给我一点方向上的指点，自己整活儿还是太逆天了点。</p>
<p>但无论怎么样，暑假走过了很多以前想去或者想再去一次的地方（<del>但我恨武汉，真的</del>），参加了不少活动，即使离出国还比较遥远，也和朋友认认真真做了一次见面和告别（暑假开头在南昌的时候我和我姐戏称：这是我们一生仅一次的超长见面了。现在想想也许真的是吧，日暮途远，人间何世？），确认了我妈的状态，即使牺牲了很多搞学术的时间，也和她说了很多话，<del>现在我已经没有什么好害怕的了</del>。精神上来说，真的已经非常满足了。前两天有群友看完日记说我：</p>
<blockquote>
<p>您这最近还这么划啊</p>
<p>就 我指的是 各处游览（）</p>
</blockquote>
<p>我回复：那咋了</p>
<p>所以说现在甚至都有点变得很平常的一个心态了，我不知道未来是什么样子，我其实也觉得很恐惧，但它就是要来了。</p>
<h1 id="月19日">8月19日</h1>
<p>四刷 SJTU，也是第一次在夏天刷（，去面基了群友
<del>明明是高中音游群的学弟为什么要叫群友</del>，哥们弃明投暗降转了数学或许也有我的责任（悲。讨论了一些“为什么在校园里把一张交大地图铺在地上，会导致地图和地面有且仅有一相同点重合”（基于比例尺的压缩变换，考虑不动点。二维点直接算坐标线性变换也可）之类的问题，获得了一些数分高代的补习建议（，这就
GTM 135
启动（下午看了一下感觉是一本不强调有限维的线性代数，四舍五入还看了个泛函）。说真的是第一次觉得有人一起聊着天学数学是这么有趣的事情，以前没体验过，之后也不知道能不能再有机会了。</p>
<p>买到了玉兰苑的菠萝包，又幸福了，然而骑车去地铁站的路上摔了一跤压坏了一个有馅儿的，含泪吃掉。之前一直觉得玉兰面包房的奶黄可颂很好吃，馅料很实，可惜今天没买到，老板说是还没开学所以品种不全。下次还来。</p>
<p>今天第一次喝
Manner，瑞幸的确没得比，但是它真的好贵（，<del>早说我自己带个杯子来</del>（x</p>
<h1 id="月20日">8月20日</h1>
<p>你交这个蚊子真毒啊，昨天叮的包今天还又痒又痛，还有一个正好叮在手腕上，肿好大一片，不对称了（</p>
<p>连着好长时间没能睡个真正意义上的好觉了，今天睡了一下午，晚上还一直处在一个搞不清状况的状态（。</p>
<h1 id="月21日">8月21日</h1>
<p>最近经常感觉脖子像被掐了一样痛，尤其是只有几个点位很痛，可以轻松地用手指对准这几个点做出掐脖子的动作（，附带吞咽的时候喉咙痛，以及经常觉得大脑缺氧晕晕乎乎。虽然大概率就是坐姿问题导致颈椎出了点小毛病，小概率是睡多了，但还是挺怪的。</p>
<p>导今天，时隔 19
天，突然想起我来了（，只不过为什么想起我的方式是今天突然扔了两篇文章给我然后说明天可以聊一聊（，<del>是要让我见到周四的日出吗</del>，大致读一下算了。看了看他说的去浅搜了一下，<del>其实我首先怀疑他这话不靠谱，至少之前一直观察到先做
cluster 再 estimation 这件事的远不如先 estimation 再 cluster
的多，我以前读 low-rank 那篇的时候有想过对 signed network 先 cluster
再做
completion，虽然二者看起来只是目标不同，但确实不清楚效率如何。我的理解是更大的困难在于不知道要怎么量化
k-means 分块的结果，在此基础上做 estimation
听起来有些太超越了，所以第一步至少不能做非常精细的
cluster。如果是先估计再 cluster 然后算 recovery rate
的话，只要比较两个矩阵就可以了，成熟的工具很多，Davis-Kahn
启动！</del>找到一篇，怎么又 Ji
Zhu了，这个领域真只有您一个组在做吗（（x</p>
<p>今天突然发现 Cytus II
确实挺好玩的，虽然读谱不能。这个就是说啊，学得越多，摸得越多，摸得越多，学得越少，所以学得越多，学得越少（</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>初等概率论与挣扎</title>
    <url>/2022/09/24/Elementary-probability-theory/</url>
    <content><![CDATA[<p>虽然 dwl
老师确实很好，但是我感觉初概这课有点儿稀碎（个人意见，个人意见）。</p>
<span id="more"></span>
<p>先前把统辅当做很有趣的数学分支，被转数环的学长泼了冷水说“统计中心的风格可能会不大适应”，另一位学长也说“统辅不是你期待的样子”，目前看中心开课的意思也好像有点当工科的辅助来学。我到底多大程度上能接受严谨的数学推导？又能走多远？统辅还是数辅<del>还是我全都要</del>，这是一个问题。</p>
<p>初概这玩意儿前八周上完，约等于梦回高中月考，我定义呢我证明呢啊怎么直接拿来用了？在考虑下学期去数学系重新上概（1），甚至考虑跟实复分析，但是数分的空缺真的没问题吗。当然，没有退初概还是为了跟上统辅的进度，毕竟后八周还有统计推断，我也没完全放弃统辅，目前或许是我目光短浅了。</p>
<p>这门课和教材也没什么映射关系（而且看老师的意思是也没有教材，草），直接按照
Lecture n
的顺序写吧。本来想放进茴香豆篇，但概率论这边举例比较多，放在一起又很冗长，还是算了。</p>
<h1 id="lecture-1">Lecture 1</h1>
<ul>
<li>概率模型：概率模型由样本空间和概率构成。每一个概率模型都关联着一个试验。
<ul>
<li>样本空间是一个集合，概率模型对应的试验产生的所有可能结果形成样本空间，记作
<span class="math inline">\(\Omega\)</span>。比如说，概率模型为抛硬币，样本空间即为
<span class="math inline">\(\lbrace head,tail
\rbrace\)</span>。样本空间可以是离散的，也可以是连续的。</li>
<li>事件 <span class="math inline">\(A\)</span>
是样本空间的子集，也就是某些试验结果的集合。概率 <span class="math inline">\(P(A)\)</span> 分配到事件 <span class="math inline">\(A\)</span> 上。</li>
</ul></li>
<li>概率公理：非负性，归一化，可加性。</li>
<li>概率的性质：两个技巧，归纳法和取补集。</li>
</ul>
<h1 id="lecture-2">Lecture 2</h1>
<ul>
<li><p>事件域（或称为 <span class="math inline">\(\sigma-\)</span>域，<span class="math inline">\(\sigma-\)</span>代数）：对于样本空间 <span class="math inline">\(\Omega\)</span>，<span class="math inline">\(F\)</span> 表示 <span class="math inline">\(\Omega\)</span> 的某些子集构成的集合，如果 <span class="math inline">\(F\)</span> 满足以下三个条件：</p>
<ul>
<li><span class="math inline">\(\Omega \in F\)</span> ；</li>
<li>对于任意的 <span class="math inline">\(A\in F\)</span>，有 <span class="math inline">\(A^c \in F\)</span>；</li>
<li>如果 <span class="math inline">\(A_n \in F\)</span>，<span class="math inline">\(n=1,2,...\)</span>，则 <span class="math inline">\(\cup_{n=1}^\infty A_n \in F\)</span>。</li>
</ul>
<p>那么称 <span class="math inline">\(F\)</span> 为 <span class="math inline">\(\Omega\)</span> 上的事件域，称 <span class="math inline">\(F\)</span> 中的元素为事件，称 <span class="math inline">\((\Omega,F)\)</span> 为可测空间。</p>
<p>从而，有且只有 <span class="math inline">\(F\)</span>
中的每个事件都能分配概率，这就圈定了我们所关心的事件的范围。</p>
<p>事件域的一些性质如下：</p>
<ul>
<li>两个事件域的并集不一定是事件域，但交集一定是。（Trivial）</li>
<li>事件域对集合的任何计算都是封闭的，包括事件列的极限运算。</li>
</ul></li>
<li><p>概率，也称为概率测度：设 <span class="math inline">\((\Omega,F)\)</span>
为<strong>可测空间</strong>，<span class="math inline">\(P\)</span>
是定义在 <span class="math inline">\(F\)</span> 上的函数，如果 <span class="math inline">\(P\)</span> 满足以下三个条件：</p>
<ul>
<li>非负性，完全性（Trivial）</li>
<li>可列可加性（<span class="math inline">\(\sigma-additivity\)</span>）：对于 <span class="math inline">\(F\)</span> 中互不相交的事件 <span class="math inline">\(A_1,A_2,...\)</span> ，有 <span class="math inline">\(P(\cup _{n=1} ^\infty A_n) = \Sigma _{n=1} ^\infty
P(A_n)\)</span>。</li>
</ul>
<p>那么称 <span class="math inline">\(P\)</span> 为 <span class="math inline">\(F\)</span> 上的概率测度，简称概率。</p></li>
<li><p>对于上述定义的样本空间，事件域和概率测度，我们称 <span class="math inline">\((\Omega,F,P)\)</span> 为概率空间。</p>
<p>简单举个例子，在掷硬币的概率模型中，样本空间是 <span class="math inline">\(\lbrace Head,Tail \rbrace\)</span>，事件域是 <span class="math inline">\(\lbrace \lbrace Head,Tail \rbrace, \lbrace Head
\rbrace, \lbrace Tail \rbrace, \emptyset
\rbrace\)</span>，此时样本空间和事件域构成可测空间。事件域中的每一个元素都是事件，概率测度为
<span class="math inline">\(P(\lbrace Head \rbrace) = p\)</span>, <span class="math inline">\(P(\lbrace Tail \rbrace)=1-p\)</span>。（这是考虑了
<span class="math inline">\(biased\)</span> <span class="math inline">\(coin\)</span> 的情况）</p></li>
<li><p>概率测度的一些性质：</p>
<ul>
<li>对于单调增序列，有 <span class="math inline">\(\lim_{n \to \infty}
A_n = \cup_{i=1} ^\infty A_i\)</span>， <span class="math inline">\(P(\lim_{n \to \infty}A_n) = \lim_{x \to
\infty}P(A_n)\)</span>。</li>
<li>单调减序列同理。</li>
</ul></li>
<li><p>条件概率（定义略）的若干性质：</p>
<ul>
<li><p>对互不相容的事件列 $B_i $，有 <span class="math inline">\(P(\cup
_{i=1}^\infty B_i|A) = \Sigma _{i=1} ^\infty P(B_i
|A)\)</span>。</p></li>
<li><p>用 <span class="math inline">\(P_A(·)=P(·|A)\)</span> 表示在事件
<span class="math inline">\(A\)</span>
发生条件下的条件概率，这仍然是一个概率测度，<span class="math inline">\((\Omega,F,P_A)\)</span> 仍然是一个概率空间。</p>
<p>当然，此时我们可以把 <span class="math inline">\(A\)</span>
之外的结果排除掉，记作 <span class="math inline">\((A,A\cap
F,P_A)\)</span>。</p></li>
</ul></li>
<li><p>乘法公式：设 <span class="math inline">\((\Omega, F,P)\)</span>
是概率空间，<span class="math inline">\(A_i \in F\)</span>，<span class="math inline">\(i = 1,2,...,n\)</span>，且 <span class="math inline">\(P(A_1 \cap A_2 \cap ... \cap
A_{n-1})&gt;0\)</span>，于是有<span class="math inline">\(P(\cap_{i=1}^n
A_i) = P(A_1) \Pi_{i=2}^n P(A_i|A_1\cap A_2 \cap ... \cap
A_{i-1})\)</span>。</p>
<p>举个例子：某人写了 <span class="math inline">\(n\)</span>
封信，将其装入 <span class="math inline">\(n\)</span>
个写有地址的信封，全部装错的概率 <span class="math inline">\(q_0\)</span> 为？恰有 <span class="math inline">\(r\)</span> 个信封装对的概率 <span class="math inline">\(q_r\)</span> 为？</p>
<ul>
<li>在第一个问题下面，我们考虑记事件 <span class="math inline">\(A_i\)</span> 为第 <span class="math inline">\(i\)</span>
个信封装对的事件，利用容斥原理即可。</li>
<li>在第二个问题下面，其实问题主要在于怎么考虑是哪 <span class="math inline">\(r\)</span> 个信封放对了的问题。“指定的某 <span class="math inline">\(r\)</span> 个信封放对了”这一事件的概率等于“从
<span class="math inline">\(n\)</span> 个信封里无放回地取出 <span class="math inline">\(r\)</span> 个正好是前 <span class="math inline">\(r\)</span> 号”的概率。又因为从 <span class="math inline">\(n\)</span> 个信封里指定 <span class="math inline">\(r\)</span> 个有 <span class="math inline">\(C_n
^r\)</span> 种方式，于是这一部分的概率为 <span class="math inline">\(\frac{1}{r!}\)</span>。</li>
</ul></li>
<li><p>全概率公式：将 <span class="math inline">\(\Omega\)</span>
分割成事件 <span class="math inline">\(A_1,A_2,...,A_n\)</span>
的并，另有其中的事件 <span class="math inline">\(B\)</span>，可以对每个
<span class="math inline">\(i\)</span> 得到 <span class="math inline">\(P(B|A_i)\)</span>，于是 <span class="math inline">\(P(B) = \Sigma_{i=1}^n P(A_i)P(B|Ai) =
\Sigma_{i=1}^n P(B \cap A_i)\)</span>。</p>
<p>这个时候，我们称 <span class="math inline">\(\lbrace A_i
\rbrace\)</span> 是 <span class="math inline">\(\Omega\)</span>
的一个分割。同时，式中的 <span class="math inline">\(n\)</span> 可以用
<span class="math inline">\(\infty\)</span> 代替。</p>
<p>举个例子：一个袋子里有 <span class="math inline">\(n\)</span>
个白球和 <span class="math inline">\(m\)</span> 个黑球，从中无放回地取出
<span class="math inline">\(k\)</span> 个球，求第 <span class="math inline">\(k\)</span> 次取得黑球的概率。</p>
<ul>
<li>递归：第一次取黑球的概率影响第二次，第二次影响第三次...简单列个数列可以看出来取黑球的概率是定值，即为
<span class="math inline">\(\frac{m}{m+n}\)</span>。</li>
<li>排队：把 <span class="math inline">\(m+n\)</span> 个球排成一列，算第
<span class="math inline">\(k\)</span> 个恰为黑球的概率即可。</li>
</ul></li>
<li><p><span class="math inline">\(Bayes\)</span> 准则：设 <span class="math inline">\((\Omega,F,P)\)</span> 是概率空间，<span class="math inline">\(B,A_i \in F\)</span>，<span class="math inline">\(i=1,2,...,n\)</span>，<span class="math inline">\(\lbrace A_i \rbrace\)</span> 是 <span class="math inline">\(\Omega\)</span> 的一个分割。我们要用 <span class="math inline">\(P(B|A_i)\)</span> 算 <span class="math inline">\(P(A_i|B)\)</span>，就可以使用 <span class="math inline">\(Bayes\)</span> 准则：<span class="math inline">\(P(A_i|B)=\frac{P(A_i)P(B|A_i)}{\Sigma_{j=1}^n
P(A_j)P(B|A_j)}\)</span> 。</p></li>
</ul>
<h1 id="lecture-3">Lecture 3</h1>
<ul>
<li><p>（两两）独立性，条件独立性和一组事件的相互独立性</p>
<ul>
<li><p>对于概率空间 <span class="math inline">\((\Omega,F,P)\)</span>，<span class="math inline">\(A,B,C \in F\)</span>，独立性指的是 <span class="math inline">\(P(A\cap B) = P(A)P(B)\)</span>，条件独立性指的是
<span class="math inline">\(P(A\cap B|C)=P(A|C)P(B|C)\)</span>。</p>
<p>那么这二者有什么关系呢？答案是没有关系（</p>
<p>简单举个反例：抛掷两次均匀的硬币，令 <span class="math inline">\(H_1=\lbrace\)</span>第一枚正面朝上<span class="math inline">\(\rbrace\)</span>，<span class="math inline">\(H_2=\lbrace\)</span>第二枚正面朝上<span class="math inline">\(\rbrace\)</span>，<span class="math inline">\(D=\lbrace\)</span>两枚硬币结果相反<span class="math inline">\(\rbrace\)</span>。于是有 <span class="math inline">\(P(H_1 \cap H_2) = P(H_1)P(H_2)\)</span>，但是
<span class="math inline">\(P(H_1 \cap H_2 |D) = 0,P(H_1|D) =
\frac{1}{2}，P(H_2|D) =
\frac{1}{2}\)</span>。也就是说，独立性不能推出条件独立性。</p></li>
<li><p>一组事件的相互独立性涉及到概率空间 <span class="math inline">\((\Omega,F,P)\)</span> 中的一组事件 <span class="math inline">\(A_1,A_2,...,A_n\)</span>，如果对于任意非空子集
<span class="math inline">\(S\subset \lbrace 1,2,...,n
\rbrace\)</span>，都有<span class="math inline">\(P(\cap_{i \in S}
A_i)=\Pi_{i\in S} P(A_i)\)</span>，那么称这一组事件是相互独立的。</p>
<p>根据 <span class="math inline">\(S\)</span>
的完备性可以知道，两两独立性也不能推出一组事件的相互独立性。</p></li>
<li><p>TODO：记得复习一下赌徒破产模型。</p></li>
</ul></li>
<li><p>随机变量何种情况下是良定义的？</p>
<ul>
<li>设 <span class="math inline">\((\Omega,F)\)</span> 为可测空间，如果
<span class="math inline">\(\Omega\)</span> 上的函数 <span class="math inline">\(X(\omega)\)</span> 满足：对 <span class="math inline">\(\forall x \in R\)</span>，<span class="math inline">\(\lbrace \omega | X(\omega) \leq x\rbrace \in
F\)</span>，则称 <span class="math inline">\(X(\omega)\)</span> 为 <span class="math inline">\((\Omega,F)\)</span> 上的随机变量。</li>
</ul></li>
</ul>
<h1 id="lecture-4">Lecture 4</h1>
<ul>
<li><p>对于离散型随机变量 <span class="math inline">\(X\)</span>，称
<span class="math inline">\(P(X=x_k) = p_k\)</span> 为 <span class="math inline">\(X\)</span> 的概率分布，称 <span class="math inline">\(\lbrace p_k \rbrace\)</span> 为概率分布列，简称为
<span class="math inline">\(PMF\)</span>。当其规律不够明显时可以写成表格形式。</p>
<ul>
<li><p>两点（<span class="math inline">\(Bernoulli\)</span>）分布：掷硬币或正或反，<span class="math inline">\(P(X=0)=p,P(X=1)=1-p\)</span>。</p></li>
<li><p>二项（<span class="math inline">\(Binomial\)</span>）分布：试验成功的概率为 <span class="math inline">\(p\)</span>，重复 <span class="math inline">\(n\)</span> 次试验成功 <span class="math inline">\(k\)</span> 次的概率，<span class="math inline">\(P(X=k) = C_n ^k p^k
(1-p)^{n-k}\)</span>。它是二项式展开的其中一项，故名二项分布。</p>
<p>二项分布的最大可能值（即中心项）的推断：考虑二项式展开。</p></li>
<li><p>......这里空间不够大，别的写不下了（其实是不需要记忆离散型分布的名字，会讲故事就行。</p></li>
<li><p>泊松（<span class="math inline">\(Poission\)</span>）分布：<span class="math inline">\(P(X=k)=\frac{\lambda ^k}{k!}
e^{-\lambda}\)</span>。一般来说，记随机变量 <span class="math inline">\(Y\sim P(\lambda)\)</span> 表示 <span class="math inline">\(Y\)</span> 服从参数为 <span class="math inline">\(\lambda\)</span> 的泊松分布。</p>
<p>放射粒子模型揭示了二项分布可以用泊松分布近似的事实。</p>
<p>TODO：复习粒子模型，做书上习题 <span class="math inline">\(2.2\)</span>。</p></li>
</ul></li>
<li><p>对于连续型随机变量的定义如下：设随机变量 <span class="math inline">\(X\)</span>，如果存在非负函数 <span class="math inline">\(f(x)\)</span> 满足对任意的 <span class="math inline">\(a&lt;b\)</span>，<span class="math inline">\(P(a&lt;X\leq b)=\int _a ^b f(x) dx\)</span>，则称
<span class="math inline">\(X\)</span> 为连续型随机变量。称 <span class="math inline">\(f(x)\)</span> 为 <span class="math inline">\(X\)</span>
的概率密度函数，简称概率密度或者密度（<span class="math inline">\(PDF\)</span>）。</p>
<p>这并不意味着 <span class="math inline">\(X(\omega)\)</span>
是连续函数，因为样本空间可能没有任何的拓扑结构，谈不上连续性。</p>
<ul>
<li><p>均匀（<span class="math inline">\(Uniform\)</span>）分布：<span class="math inline">\(f(x) = \frac{1}{b-a},x \in (a,b)\)</span>，此时记
<span class="math inline">\(X \sim U(a,b)\)</span>。</p></li>
<li><p>指数（<span class="math inline">\(Exponential\)</span>）分布：<span class="math inline">\(f(x) = \lambda e^{-\lambda x},x\geq
0\)</span>，此时记 <span class="math inline">\(X\sim
\epsilon(\lambda)\)</span>。</p>
<p>如果 <span class="math inline">\(X\)</span> 是连续型非负随机变量，则
<span class="math inline">\(X\)</span> 服从指数分布的充要条件是 <span class="math inline">\(X\)</span> 没有记忆性，也就是说 <span class="math inline">\(P(X&gt;s+t|X&gt;s) =
P(X&gt;t)\)</span>。（可以由条件概率公式证出，Trivial.）</p>
<p><span class="math inline">\(X\)</span>
的失效率就是单位长度时间内失效的概率，可推知即为 <span class="math inline">\(\lambda\)</span>。也称其为尺度参数（rate
parameter）。</p>
<p>TODO：再推一遍 <span class="math inline">\(X\sim
\epsilon(\lambda)\)</span> 时，<span class="math inline">\(Y=\lambda
X\)</span>，则 <span class="math inline">\(Y\sim \epsilon
(1)\)</span>。</p></li>
<li><p>正态分布（<span class="math inline">\(Normal\)</span> <span class="math inline">\(Distribution\)</span>）：<span class="math inline">\(f(x)=\frac{1}{\sigma \sqrt{2 \pi}}
exp(-\frac{(x-\mu)^2}{2\sigma ^2}),x \in R\)</span>，此时记 <span class="math inline">\(X\sim N(\mu ,\sigma^2)\)</span>。</p>
<p>正态分布的函数图像关于 <span class="math inline">\(x=\mu\)</span>
对称，在此处取最大值 <span class="math inline">\(f(\mu) = (\sigma
\sqrt{2\pi})^{-1}\)</span>。关于 <span class="math inline">\(x=\mu \pm
\sigma\)</span> 处有拐点。</p></li>
</ul></li>
</ul>
<h1 id="lecture-5">Lecture 5</h1>
<ul>
<li><p>概率分布函数（<span class="math inline">\(CDF\)</span>）：对随机变量 <span class="math inline">\(X\)</span>，称 <span class="math inline">\(x\)</span> 的函数 <span class="math inline">\(F(x)
= P(X\leq x),x \in R\)</span> 为 <span class="math inline">\(X\)</span>
的概率分布函数，也称为累积分布函数，分布函数。</p>
<ul>
<li><p>对一个 <span class="math inline">\(PMF\)</span> 书写 <span class="math inline">\(CDF\)</span>，它一般是一个分段函数。</p></li>
<li><p>对一个 <span class="math inline">\(PDF\)</span> 书写 <span class="math inline">\(CDF\)</span>，记随机变量 <span class="math inline">\(X\)</span> 的概率密度为 <span class="math inline">\(f(x)\)</span>，则其分布函数为 <span class="math inline">\(F(x) = \int_{-\infty}^x f(t) dt,x \in R\)</span>。
对于一个已知的 <span class="math inline">\(F(x)\)</span>，只能确定连续点
<span class="math inline">\(x\)</span> 处的概率密度为 <span class="math inline">\(f(x) =
F&#39;(x)\)</span>，显然在不连续点处是无法确定的。</p>
<ul>
<li>注：连续型随机变量的概率密度不必为连续函数，允许可列个单点断开。那它为什么叫连续型呢？这与
<span class="math inline">\(F(x)\)</span>
的形式有关。同时离散型这一形容也与 <span class="math inline">\(F(x)\)</span> 有关。</li>
</ul></li>
<li><p>举个例子：标准正态分布的概率密度为 <span class="math inline">\(\phi(x)=\frac{1}{\sqrt{2 \pi}}
exp(-\frac{x^2}{2}),x \in R\)</span>。其分布函数记为 <span class="math inline">\(\Phi(x)\)</span>，其值需要查表，当然也可以丢进
MATLAB 算，但是不要求（</p>
<p><img src="https://s2.loli.net/2022/09/29/lAWLBo8TXMfaQCK.png" alt="image-20220928155241878.png"></p></li>
<li><p>再举个例子：正态分布函数的概率密度计算中，可以对 <span class="math inline">\(\frac{x-\mu}{\sigma}\)</span>
进行换元，从而变为标准正态分布的情况。</p></li>
<li><p>再再举个例子：指数分布的分布函数要注意分段，考虑 <span class="math inline">\(x&lt;0\)</span> 的情况。</p>
<p>TODO：去看一下几何随机变量和指数随机变量的分布函数的逼近，这是利用
<span class="math inline">\(CDF\)</span> 寻找 <span class="math inline">\(PMF,PDF\)</span> 之间关系的例子。</p></li>
<li><p>分布函数对一切随机变量都适用，这是它相对 <span class="math inline">\(PMF,PDF\)</span> 的优势。</p></li>
</ul></li>
<li><p>对于一个随机变量 <span class="math inline">\(X\)</span> 的函数
<span class="math inline">\(g(X)\)</span>，怎么去寻找 <span class="math inline">\(g(X)\)</span>
的概率分布？（这一部分其实是做题方法）</p>
<ul>
<li><p>最简单的情形：<span class="math inline">\(X\)</span>
是离散型随机变量，对每一个 <span class="math inline">\(X\)</span> 的取值
<span class="math inline">\(x\)</span>，确定 <span class="math inline">\(Y=g(x)\)</span>
时的概率分布列即可。有需要的话还可以化成 <span class="math inline">\(CDF\)</span>。</p></li>
<li><p>曲线救国：考察 <span class="math inline">\(Y=g(X)\)</span>
的分布，若 <span class="math inline">\(g(x)\)</span>
是<strong>连续函数</strong>，那么可以先得到 <span class="math inline">\(Y\)</span> 的 <span class="math inline">\(CDF\)</span> 为 <span class="math inline">\(F_Y(y)=P(Y\leq y)\)</span>，再求导得到 <span class="math inline">\(f_Y(y)=F_Y&#39;(y)\)</span>。</p></li>
<li><p>特殊情况 1：线性的 <span class="math inline">\(g(X)\)</span>
可以直接从 <span class="math inline">\(f_X(x)\)</span> 得到 <span class="math inline">\(f_Y(y)\)</span> 而无需计算 <span class="math inline">\(CDF\)</span>。</p>
<p>形如 <span class="math inline">\(Y=aX+b\)</span> ，有 <span class="math inline">\(f_Y(y)=\frac{1}{|a|}
f_X(\frac{y-b}{a})\)</span>。（其实还是用 <span class="math inline">\(CDF\)</span> 证明的）</p></li>
<li><p>特殊情况 2：对于严格单调的 <span class="math inline">\(g(x)\)</span>，考虑 <span class="math inline">\(Y=g(X)\)</span>。记 <span class="math inline">\(h(y)\)</span> 是 <span class="math inline">\(g(x)\)</span> 的逆映射，于是 <span class="math inline">\(f_Y(y)=f_X(h(y))|h&#39;(y)|\)</span>，这可以通过考虑事件
<span class="math inline">\(\lbrace x&lt;X&lt;x+\delta \rbrace\)</span>
来证明。</p></li>
<li><p>特殊情况
3：像正态分布这样的特殊分布，遇到的时候建议先考虑能不能在 <span class="math inline">\(\Phi(x)\)</span>
的尺度先行利用对称性化简。</p></li>
</ul></li>
</ul>
<h1 id="lecture-6">Lecture 6</h1>
<ul>
<li><p><span class="math inline">\(n\)</span> 维随机向量：如果 <span class="math inline">\(X_1,X_2,...,X_n\)</span> 都是概率空间 <span class="math inline">\((\Omega,F,P)\)</span> 上的随机变量，那么称 <span class="math inline">\(X=(X_1,X_2,...,X_n)\)</span> 为概率空间 <span class="math inline">\((\Omega,F,P)\)</span> 上的 <span class="math inline">\(n\)</span> 维随机向量。</p>
<p>那么怎么从随机变量上迁移来诸多的概念呢？</p>
<ul>
<li><p>联合概率分布函数：设 <span class="math inline">\(X=(X_1,X_2,...,X_n)\)</span> 为随机向量，称 <span class="math inline">\(R^n\)</span> 上的 <span class="math inline">\(n\)</span> 元函数 <span class="math inline">\(F(x_1,x_2,...,x_n)=P(X_1&lt;x_1,...,X_n&lt;x_n)\)</span>
为 <span class="math inline">\(X=(X_1,X_2,...,X_n)\)</span>
的联合概率分布函数，简称为联合分布或者分布函数。</p></li>
<li><p>有关离散型随机向量：如果 <span class="math inline">\(X_1,X_2,...,X_n\)</span> 都是离散型随机变量，则称
<span class="math inline">\(X=(X_1,X_2,...,X_n)\)</span>
为离散型随机向量。如果所有 <span class="math inline">\(X_i\)</span>
的不同取值为 <span class="math inline">\(x(j_1,j_2,...,j_n)=(x_1(j_1),x_2(j_2),...,x_n(j_n))\)</span>，则称
<span class="math inline">\(p_{j_1 j_2 ...
j_n}=P(X=x(j_1,j_2,...,j_n))\)</span> 是 <span class="math inline">\(X\)</span> 的联合分布列。</p>
<ul>
<li><p>举个例子：设 <span class="math inline">\(F(x,y)\)</span> 是 <span class="math inline">\((X,Y)\)</span> 的联合分布，则 <span class="math inline">\(X,Y\)</span> 有概率分布：</p>
<p><span class="math inline">\(F_X(x) = P(X \leq x,Y \leq \infty) =
F(x,\infty)\)</span>，</p>
<p><span class="math inline">\(F_Y(y) = P(X \leq \infty,Y \leq y) =
F(\infty ,y)\)</span>。</p>
<p>于是，对于矩形 <span class="math inline">\(D=\lbrace a&lt;X \leq b,c
&lt; Y \leq d \rbrace\)</span>，有 <span class="math inline">\(P((X,Y)\in D) =
F(b,d)-F(b,c)-F(a,d)+F(a,c)\)</span>。</p></li>
</ul></li>
<li><p>有关连续型随机向量：简单来说，考虑二维的情形，如果 <span class="math inline">\((X,Y)\)</span> 有联合密度 <span class="math inline">\(f(x,y)\)</span>，则 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span> 分别有概率密度 <span class="math inline">\(f_X(x)=\int_{-\infty} ^{\infty}
f(x,y)dy\)</span>，<span class="math inline">\(f_Y(y)=\int_{-\infty}^{\infty}
f(x,y)dx\)</span>。</p>
<p>延拓到 <span class="math inline">\(n\)</span> 维的情况，被积函数
<span class="math inline">\(f_k(x_1,x_2,...,x_k)=\int_{R^{n-k}}
f(x_1,x_2,...,x_k) dx_{k+1}...dx_n\)</span> 是为 <span class="math inline">\((X_1,...,X_n)\)</span>
的联合密度，称之为边缘密度（Marginal PDF）。</p></li>
<li><p>连续型随机向量的独立性：对每个 <span class="math inline">\(i(1\leq i \leq n)\)</span>，随机变量 <span class="math inline">\(X_i\)</span> 有概率密度 <span class="math inline">\(f_i(x_i)\)</span>，则 <span class="math inline">\(X_1,X_2,...,X_n\)</span>
相互独立的充分必要条件为随机向量 <span class="math inline">\(X=(X_1,X_2,...,X_n)\)</span> 有联合密度 <span class="math inline">\(f_1(x_1)f_2(x_2)...f_n(x_n),(x_1,x_2,...,x_n)\in
R^n\)</span>。</p></li>
<li><p>经典连续型随机向量例：二元正态分布</p>
<p>设 <span class="math inline">\(\mu_1,\mu_2\)</span> 为常数，<span class="math inline">\(\sigma_1,\sigma_2\)</span> 为正常数，<span class="math inline">\(\rho \in (-1,1)\)</span> 中的常数。如果随机向量
<span class="math inline">\((X,Y)\)</span> 有概率密度</p>
<p><span class="math inline">\(f(x,y)=\frac{1}{2\pi \sigma_1 \sigma_2
\sqrt{1-\rho^2}}exp(-\frac{1} {2(1-\rho^2)} [\frac{(x-\mu_1)^2}{\sigma_1
^2} + \frac{(y-\mu_2)^2}{\sigma_2 ^2} - \frac{2\rho
(x-\mu_1)(y-\mu_2)}{\sigma_1 \sigma_2}])\)</span>，</p>
<p>那么称 <span class="math inline">\((X,Y)\)</span>
服从二元正态分布，记为 <span class="math inline">\((X,Y)\sim
N(\mu_1,\mu_2,\sigma_1^2, \sigma_2^2, \rho)\)</span>。</p>
<ul>
<li>一些性质：<span class="math inline">\(X,Y\)</span> 独立的充要条件是
<span class="math inline">\(\rho=0\)</span>。（Trivial）</li>
</ul></li>
<li><p>联合分布（Joint CDF）与联合密度（Joint PDF）：已知联合密度 <span class="math inline">\(f(x,y)\)</span>，于是有联合分布 <span class="math inline">\(F(x,y) = \int _{-\infty} ^x \int _{-\infty} ^y
f(u,v)dudv\)</span>。</p>
<p>当 <span class="math inline">\(f(x,y)\)</span> 连续时，有 <span class="math inline">\(f(x,y) = \frac{\partial^2 F(x,y)}{\partial x
\partial y}\)</span>。更一般地，如果该混合偏导数不存在，那么 <span class="math inline">\(f(x,y)=0\)</span>。</p></li>
<li><p>连续型条件概率分布：设随机向量 <span class="math inline">\((X,Y)\)</span> 有联合密度 <span class="math inline">\(f(x,y)\)</span>，<span class="math inline">\(Y\)</span> 有边缘密度 <span class="math inline">\(f_Y(y)\)</span>。若在确定的 <span class="math inline">\(y_0\)</span> 处 <span class="math inline">\(f_Y(y_0)&gt;0\)</span>，则称 <span class="math inline">\(P(X \leq x | Y=y_0) = \frac{\int_{-\infty} ^x
f(s,y_0) ds}{f_Y(y_0)}\)</span> 为给定条件 <span class="math inline">\(Y=y_0\)</span> 下，<span class="math inline">\(X\)</span> 的条件分布函数（conditional CDF），记为
<span class="math inline">\(F_{X|Y}(x|y_0)\)</span>。</p>
<p>于是条件分布密度为 <span class="math inline">\(f_{X|Y}(x|y_0) =
\frac{f(x,y_0)}{f_Y(y_0)}\)</span>。（conditional PDF）</p>
<ul>
<li><p>一些性质：</p>
<p>$F_{X|Y}(x|y)=P(Xx|Y=y)=<em>{-} ^x f</em>{X|Y}(s|y)ds, x R $。</p>
<p>如果 <span class="math inline">\(F_{X|Y}(x|y)\)</span> 关于 <span class="math inline">\(x\)</span>
连续，且除去至少可列个点后有连续的导数，则在偏导数存在时，<span class="math inline">\(f_{X|Y}(x|y_0)=\frac{\partial
F_{X|Y}(x|y)}{\partial x}\)</span>，否则为 <span class="math inline">\(0\)</span>。</p></li>
</ul></li>
</ul></li>
</ul>
<h1 id="期中插播提示">期中插播提示</h1>
<ul>
<li><p>关于连续型概率分布之前的误解：连续型的随机变量不能随便取单点的概率，因为单点处的概率就是
<span class="math inline">\(0\)</span>，这就是为什么要定义一个概率密度的原因。概率密度的大小可以是任意的，不一定要小于
<span class="math inline">\(1\)</span>，只要它的积分能够表示某一段（区域）的概率即可，这个在联合分布中有比较多的体现。</p>
<p>总之，虽然 <span class="math inline">\(F(x,y) = \int_{-\infty}^x
\int_{-\infty}^y f(u,v)dudv\)</span>，但是 <span class="math inline">\(f(u,v)\)</span> 不等同于 <span class="math inline">\(P(X=u,Y=v)\)</span>。同理，如果要算条件概率的话，可以用
<span class="math inline">\(F_{X|Y}(x|y)=P(x_1\leq X\leq
x_2|Y=y)=\int_{x_1}^{x_2} f_{X|Y} (s|y)ds\)</span>，也就是对 cond PDF
来积分求解。</p>
<p>（但是，出于记忆公式的方便考虑，我还是会把它当成单点处的概率来列写公式（</p></li>
<li><p>关于随机变量的独立性，定义如下：设 <span class="math inline">\(X_1,X_2,...,X_n\)</span> 是 <span class="math inline">\((\Omega,F)\)</span> 上的随机变量，如果对任意的实数
<span class="math inline">\(x_1,x_2,...,x_n\)</span> 有 <span class="math inline">\(P(X_1\leq x_1,X_2 \leq x_2,...,X_n \leq
x_n)=P(X_1\leq x_1)...P(X_n\leq x_n)\)</span> 成立，则称随机变量 <span class="math inline">\(X_1,X_2,...,X_n\)</span> 相互独立。</p>
<p>同时，设随机变量 <span class="math inline">\(X_1,X_2,...,X_n\)</span>
相互独立，<span class="math inline">\(g_1(x),g_2(x),...,g_n(x)\)</span>
是一元实可测函数，<span class="math inline">\(\phi(x_1,x_2,...,x_k)\)</span> 是 <span class="math inline">\(k\)</span> 元实可测函数，则：</p>
<ul>
<li>随机变量 <span class="math inline">\(g_1(X_1),...,g_n(X_n)\)</span>
相互独立；</li>
<li>随机变量 <span class="math inline">\(\phi(X_1,...,X_k),X_{k+1},...,X_n\)</span>
相互独立。</li>
</ul>
<p>这在样题的某个判断题中，以离散型随机变量的形式出现了，于是我自己证明了一下。实际上是一个更一般的结论。</p></li>
<li><p>单调事件列的概率极限问题：以单调增序列 <span class="math inline">\(\lbrace A_i\rbrace\)</span> 为例，有结论 <span class="math inline">\(lim_{n\to \infty} A_n=\cup _{i=1}^{\infty}
A_i\)</span>，于是极限概率为：</p>
<p><span class="math inline">\(P(\cup _{i=1}^{\infty} A_i) = P( lim
_{n\to \infty} A_n) = lim _{n \to \infty} P(A_n)\)</span>。</p>
<p>对于一些不单调的事件序列，可以用交并补构造一个单调序列，使得可以使用上述规律。</p></li>
<li><p>事件列的上下极限的通俗说法：设 <span class="math inline">\(\lbrace A_i \rbrace\)</span> 是 <span class="math inline">\(\Omega\)</span>
中的一个事件列，定义上下极限为：</p>
<p><span class="math inline">\(lim_{n\to \infty} sup A _n = \cap
_{n=1}^{\infty} \cup _{k=n}^{\infty} A_k =\lbrace \omega \in \Omega:
\omega\)</span> 属于无穷多个 <span class="math inline">\(A_i\rbrace\)</span>。</p>
<p><span class="math inline">\(lim_{n\to \infty} inf A _n = \cup
_{n=1}^{\infty} \cap _{k=n}^{\infty} A_k =\lbrace \omega \in \Omega:
\omega\)</span> 属于所有的 <span class="math inline">\(A_i\)</span>
除去有限个<span class="math inline">\(\rbrace\)</span>。</p>
<p>当上下极限相等时称 <span class="math inline">\(\lbrace A_i
\rbrace\)</span> 的极限存在。</p></li>
<li><p>条件概率中会忘记的常识：对互不相容的事件列 <span class="math inline">\(\lbrace B_i \rbrace\)</span>，有 <span class="math inline">\(P(\cup _{i=1}^{\infty} B_i | A) = \Sigma
_{i=1}^{\infty} P(B_i | A)\)</span>。</p>
<p>一个 insight：求条件概率时我们可以把 <span class="math inline">\(A\)</span> 之外的结果排除掉，记作 <span class="math inline">\((A,A\cap
F,P_A)\)</span>，这个事件域上完全可以有概率分布，因此不必为折棒太郎题惊讶。</p></li>
<li><p>注意一组事件“相互独立”所要求的完备性。</p></li>
<li><p>复习指南：</p>
<ul>
<li><p>以上全部 TODO</p></li>
<li><p>去看一下习题课中《一个有助于理解独立性的题目》和 Polya
坛子问题第二问。</p></li>
<li><p>Poisoner's Dilemma</p></li>
<li><p>A family has two girls while at least one names Lilia</p></li>
<li><p>记一下几个重要分布，以及二元正态</p></li>
<li><p>过一遍离散型、连续型随机向量的独立性证明，二元正态分布的独立性证明。</p></li>
<li><p><del>折棒太郎</del>折木棍问题的随机向量表述，Buffon 问题</p></li>
</ul></li>
<li><p>最后是一个我比较个人向的整理，根据考试重点和过往习题。<a href="https://cloud.tsinghua.edu.cn/f/4a371e0b38d64e178bc8/">Click
Here</a></p></li>
<li><p>记得多用归纳！</p></li>
</ul>
<h1 id="lecture-7">Lecture 7</h1>
<p>又是全新的一门课辣（自我洗脑）</p>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>刷书</tag>
      </tags>
  </entry>
  <entry>
    <title>别惦记你那 pivot statistic 了</title>
    <url>/2023/12/06/Hypothesis_Testing_and_Statistical_Decision_Theory/</url>
    <content><![CDATA[<p>去年秋季学期的最后四分之一学假设检验的时候我就很疑惑，人类要怎么才能记住这些规则，这有什么道理吗（</p>
<p>于是最后在作业期中期末占比约各三分之一、期中考了 94、wjd
老师海底捞调分的情况下考了个 A-（，就挺耻辱的。</p>
<p>时隔一年学了 statistical decision theory 之后我逐渐理解一切（</p>
<span id="more"></span>
<p>非常短的一集，我随便喵两句。</p>
<p>12.8 upd: 我超，我给学杂了，pivot rule 是 linear programming
里的，这玩意叫 pivot statistic，翻译过来叫枢轴量（</p>
<h1 id="statistical-decision-theory">Statistical Decision Theory</h1>
<p>多快好省的 decision theory 复习。</p>
<h2 id="nonrandomized-decision">Nonrandomized Decision</h2>
<ul>
<li><p>Let <span class="math inline">\(X\)</span> be a sample from a
population <span class="math inline">\(P \in \mathcal P\)</span>. A
statistical decision theory is an action that we take after observing
<span class="math inline">\(X\)</span>, for example, a conclusion about
<span class="math inline">\(P\)</span> or a characteristic about <span class="math inline">\(P\)</span> according to the observation. We use
<span class="math inline">\(\mathbb A\)</span> to denote the set of
allowable actions, and let <span class="math inline">\(\mathcal
F_{\mathbb A}\)</span> be a <span class="math inline">\(\sigma\)</span>-field on <span class="math inline">\(\mathbb A\)</span>. Then the measurable space
<span class="math inline">\((\mathbb A, \mathcal F_{\mathbb A})\)</span>
is called the action space.</p></li>
<li><p>Let <span class="math inline">\(\mathcal X\)</span> be the range
of <span class="math inline">\(X\)</span> and <span class="math inline">\(\mathcal F_{\mathcal X}\)</span> be a <span class="math inline">\(\sigma\)</span>-field on <span class="math inline">\(\mathcal X\)</span>. A decision rule is a
measurable function (actually a statistic) <span class="math inline">\(T\)</span> from <span class="math inline">\((\mathcal X, \mathcal F_{\mathcal X})\)</span> to
<span class="math inline">\((\mathbb A, \mathcal F_{\mathbb
A})\)</span>. If a decision rule <span class="math inline">\(T\)</span>
is chosen, then we take the action <span class="math inline">\(T(X)\)</span> whence <span class="math inline">\(X\)</span> is observed. That's where the name
"decision rule" comes from.</p></li>
<li><p>In statistical decision theory, we set a criterion using a loss
function <span class="math inline">\(L\)</span>, which is a function
from <span class="math inline">\(\mathcal P \times \mathbb A\)</span> to
<span class="math inline">\([0, +\infty)\)</span>, and is Borel on <span class="math inline">\((\mathbb A, \mathcal F_{\mathbb A})\)</span> for
each fixed <span class="math inline">\(P \in \mathcal P\)</span>. If
<span class="math inline">\(X=x\)</span> is observed and our decision
rule is <span class="math inline">\(T(X)\)</span>, then our "loss" in
making the decision <span class="math inline">\(T(X)\)</span> is <span class="math inline">\(L(P, T(x))\)</span>, which is still random
according to <span class="math inline">\(P\)</span>.</p></li>
<li><p>The average loss for the decision rule <span class="math inline">\(T\)</span>, which is called the risk of <span class="math inline">\(T\)</span>, is defined to be</p>
<p><span class="math display">\[R_T(P) = E[L(P,T(X))] = \int_{\mathcal
X} L(P, T(x)) dP_X(x).\]</span></p>
<p>If the family <span class="math inline">\(\mathcal P\)</span> is a
parameter family then the loss function and the risk can also be denoted
as <span class="math inline">\(L(\theta, T(X))\)</span> and <span class="math inline">\(R_T(\theta)\)</span>.</p></li>
</ul>
<h2 id="randomized-decision">Randomized Decision</h2>
<ul>
<li><p>Sometimes it is more useful to consider the randomized decision
rules. A randomized decision rule is a function <span class="math inline">\(\delta\)</span> on <span class="math inline">\(\mathcal X \times \mathcal F_{\mathbb A}\)</span>
such that, for every <span class="math inline">\(A \in \mathcal
F_{\mathbb A}\)</span>, <span class="math inline">\(\delta(\cdot,
A)\)</span> is a Borel function and, for every <span class="math inline">\(x \in \mathcal X\)</span>, <span class="math inline">\(\delta(x, \cdot)\)</span> is a probability measure
on <span class="math inline">\((\mathbb A, \mathcal F_{\mathbb
A})\)</span>.</p>
<p>The nonrandomized decision rule <span class="math inline">\(T\)</span> previously discussed can be viewed as a
special randomized decision rule with <span class="math inline">\(\delta
(x, \{a\}) = I_{\{a\}}(T(x)), a \in \mathbb A, x \in \mathcal
X\)</span>.</p>
<p>The loss function for a randomized rule <span class="math inline">\(\delta\)</span> is defined as <span class="math inline">\(L(P,\delta,x) = \int_{\mathbb A} L(P,a) d\delta
(x,a)\)</span>, and the risk is then</p>
<p><span class="math display">\[R_\delta(P) = E[L(P,\delta,X)] =
\int_{\mathcal X} \int_{\mathbb A} L(P,a) d\delta (x,a)
dP_X(x).\]</span></p></li>
</ul>
<h2 id="test-evaluation">Test Evaluation</h2>
<ul>
<li><p>A rule <span class="math inline">\(T_1(X)\)</span> is as good as
<span class="math inline">\(T_2(X)\)</span> if and only if <span class="math inline">\(R_{T_1}(P) \leq R_{T_2}(P)\)</span> for any <span class="math inline">\(P \in \mathcal P\)</span>.</p>
<p>A rule <span class="math inline">\(T_1(X)\)</span> is better than
<span class="math inline">\(T_2(X)\)</span> if and only if <span class="math inline">\(R_{T_2}(P)\)</span> if and only if <span class="math inline">\(R_{T_1}(P) \leq R_{T_2}(P)\)</span> for any <span class="math inline">\(P \in \mathcal P\)</span>, and there exists at
least one <span class="math inline">\(P \in \mathcal P\)</span> s.t.
<span class="math inline">\(R_{T_1} (P) &lt; R_{T_2}(P)\)</span>.</p>
<p>Two decision rules are equivalent if and only if <span class="math inline">\(R_{T_1}(P) = R_{T_2}(P)\)</span> holds for any
<span class="math inline">\(P\in \mathcal P\)</span>.</p>
<p>If there is a decision rule <span class="math inline">\(T^*\)</span>
that is as good as any other rule in <span class="math inline">\(\mathfrak F\)</span>, a class of allowable
decision rules, then <span class="math inline">\(T^*\)</span> is said to
be <span class="math inline">\(\mathfrak F\)</span>-optimal (or optimal
if <span class="math inline">\(\mathfrak F\)</span> contains all
possible rules).</p></li>
</ul>
<h1 id="hypothesis-testing">Hypothesis Testing</h1>
<h2 id="fundamental-settings-of-nonrandomized-testing">Fundamental
Settings of Nonrandomized Testing</h2>
<p>都见过但陌生又熟悉.jpg</p>
<h3 id="hypothesis-testing-problem">Hypothesis Testing Problem</h3>
<ul>
<li><p>Let <span class="math inline">\(\mathcal P\)</span> be a family
of distributions, <span class="math inline">\(\mathcal P_0 \subset
P\)</span> and <span class="math inline">\(\mathcal P_1 = \mathcal P
\setminus \mathcal P_0\)</span>. A hypothesis testing problem can be
formulated as that of deciding which of the following two statements are
true:</p>
<p><span class="math display">\[H_0 : P \in  \mathcal P_1 \quad
\text{versus} \quad H_1 : P \in \mathcal P_1\]</span></p></li>
<li><p>The action space for this problem contains only two elements,
i.e., <span class="math inline">\(\mathbb A = \{0,1\}\)</span>, where
<span class="math inline">\(0\)</span> is the action of accepting <span class="math inline">\(H_0\)</span> and <span class="math inline">\(1\)</span> is the action of accepting <span class="math inline">\(H_1\)</span>. A decision rule is called a test,
and must has the form <span class="math inline">\(T(X) =
I_C(X)\)</span>, in which <span class="math inline">\(C \in \mathcal
F_{\mathcal X}\)</span> is called the rejection region (because if <span class="math inline">\(X\in C\)</span> we take <span class="math inline">\(T(X) = 1\)</span>, i.e. reject <span class="math inline">\(H_0\)</span>).</p></li>
</ul>
<h3 id="loss-and-risk">Loss and Risk</h3>
<ul>
<li><p>A simple loss function for the problem is the <span class="math inline">\(0-1\)</span> loss: <span class="math inline">\(L(P,a)=0\)</span> if a correct decision is made
and <span class="math inline">\(L(P,a)=1\)</span> otherwise. Under this
loss, the risk is</p>
<p><span class="math display">\[R_T(P) = \begin{cases}  P(T(X)=1) =
P(X\in C)&amp; \quad P \in \mathcal P_0 \\ P(T(X)=0) = P(X \in C^c)
&amp;\quad P \in \mathcal P_1 \end{cases} = P(X \in C) I_{\mathcal
P_0}(P) + P(X \notin C)I_{\mathcal P_1}(P).\]</span></p></li>
<li><p>There are two types of statistical errors we may commit:
rejecting <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_0\)</span> is true (called the type I error) and
accepting <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_0\)</span> is wrong (called the type II
error).</p>
<p>In statistical inference, a test <span class="math inline">\(T\)</span>, which is a statistic from <span class="math inline">\(\mathcal X\)</span> to <span class="math inline">\(\{0,1\}\)</span>, is assessed by the probabilities
of making two types of errors (w.r.t. the <span class="math inline">\(0-1\)</span> loss function):</p>
<p><span class="math display">\[\alpha_T(P) = P(T(X)=1) = P(X\in C)
\quad P\in P_0\]</span></p>
<p><span class="math display">\[1-\alpha_T(P) = P(T(X)=0) = P(X \notin
C) \quad P \in \mathcal P_1\]</span></p>
<p>These two error probabilities cannot be minimized or even bounded by
a fixed <span class="math inline">\(\alpha \in (0,1)\)</span>
simultaneouly when we have a fixed sample size.</p></li>
</ul>
<h3 id="how-to-reach-the-optimal-test">How to Reach the Optimal
Test</h3>
<ul>
<li><p>A common approach to finding an optimal test is to assign a small
bound <span class="math inline">\(\alpha\)</span> to one of the error
probabilities (which will also leads to a small rejection region/), say,
<span class="math inline">\(\alpha_T(P), P \in \mathcal P_0\)</span>,
and then attempt to minimize the other one subject to</p>
<p><span class="math display">\[\sup_{P \in \mathcal P_0} \alpha_T(P)
\leq \alpha.\]</span></p>
<p>The small bound <span class="math inline">\(\alpha\)</span> is called
the level of significance, and the left side is called the size of the
test <span class="math inline">\(T\)</span>.</p>
<p>Actually we're using the minimax rule w.r.t. the type II error, i.e.
to minimize <span class="math inline">\(\sup_{P \in \mathcal P_1} 1-
\alpha_T(P)\)</span> under the constraint <span class="math inline">\(\sup_{P\in \mathcal P_0} \alpha_T(P) \leq
\alpha\)</span>, which will give a minimax rule <span class="math inline">\(T_\alpha^*(X)\)</span> as the test at level of
significance <span class="math inline">\(\alpha\)</span>.</p></li>
</ul>
<h3 id="the-famous-p-value">The Famous P-value</h3>
<ul>
<li><p>It's a good practice to assess the smallest possible level of
significance at which <span class="math inline">\(H_0\)</span> would be
rejected for the computed <span class="math inline">\(T_\alpha^*(x)\)</span> after observing <span class="math inline">\(x\)</span>, i.e. <span class="math inline">\(\hat
\alpha(x) = \inf \{\alpha \in (0,1) : T_\alpha^*(x)=1 \}\)</span>. Such
<span class="math inline">\(\hat \alpha (x)\)</span> is also a statistic
depending on observed <span class="math inline">\(x\)</span>, and is
called the p-value for the test <span class="math inline">\(T_\alpha
^*\)</span>.</p>
<p>The test can also be interpreted as <span class="math inline">\(T_\alpha^* (x) = I_{(0,\alpha)} (\hat
\alpha(x))\)</span>, thus we can find the p-value here.</p></li>
</ul>
<h2 id="example-of-nonrandomized-parameter-test">Example of
Nonrandomized Parameter Test</h2>
<p>举个例子来结束这些神神叨叨。</p>
<p><strong>Example 1</strong>: Let <span class="math inline">\(X_1,X_2,
\cdots, X_n\)</span> be i.i.d. from the <span class="math inline">\(N(\mu,\sigma^2)\)</span> distribution with an
unknown <span class="math inline">\(\mu \in \mathbb R\)</span> and a
known <span class="math inline">\(\sigma^2 &gt;0\)</span>. Consider the
hypothesis <span class="math inline">\(H_0 : \mu \leq \mu_0 \quad
\text{versus} \quad H_1 : \mu &gt; \mu_0\)</span>, where <span class="math inline">\(\mu_0\)</span> is a fixed constant. Since the
sample mean <span class="math inline">\(\bar X\)</span> is sufficient
for <span class="math inline">\(\mu \in \mathbb R\)</span>, it is
reasonable to consider the following class of tests: <span class="math inline">\(T_c(X) = I_{(c,\infty)}(\bar X)\)</span>.</p>
<p>By the property of normal distributions, <span class="math inline">\(\alpha_{T_c}(\mu) = P(T_c(X)=1) = 1-\Phi
\left(\frac{\sqrt n (c - \mu)}{\sigma} \right)\)</span>, and for some
level of significance <span class="math inline">\(\alpha\)</span> we
consider the type I error constraint <span class="math inline">\(\sup
_{\mu \leq \mu_0} \alpha_{T_c}(\mu) = 1-\Phi \left(\frac{\sqrt n
(c-\mu_0)}{\sigma} \right) \leq \alpha\)</span>, then the optimal test
should satisfy <span class="math inline">\(c_\alpha \geq \sigma
z_{1-\alpha} / \sqrt n + \mu_0\)</span>.</p>
<p>The next step is to minimize <span class="math inline">\(1-\alpha_{T_c}(\mu)=\Phi \left(\frac{\sqrt n (c -
\mu)}{\sigma} \right)\)</span> under the constraints <span class="math inline">\(c_\alpha \geq \sigma z_{1-\alpha} / \sqrt n +
\mu_0\)</span> and <span class="math inline">\(\mu &gt; \mu_0\)</span>,
the optimal test is <span class="math inline">\(c_\alpha ^*= \sigma
z_{1-\alpha} / \sqrt n + \mu_0\)</span>, and <span class="math inline">\(T_{c_\alpha ^*} (X) = I_{(c_\alpha ^*,
\infty)}(\bar X)\)</span>.</p>
<p>According to the definition of p-value <span class="math inline">\(\hat \alpha(x) = \inf\{\alpha \in (0,1):
T_{c_\alpha ^*} (x) =1\}\)</span>, we can obtain <span class="math inline">\(\sigma z_{1-\hat \alpha(x)} / \sqrt n + \mu_0=
\bar x\)</span> for any observed <span class="math inline">\(x\)</span>.
Thus <span class="math inline">\(\hat \alpha(x) =1-\Phi(\frac{\sqrt
n}{\sigma} \left(\bar x - \mu_0 \right))\)</span> as a function of the
observed data.</p>
<h2 id="randomized-test">Randomized Test</h2>
<p>In Example 1, the equality in <span class="math inline">\(\sup_{P \in
\mathcal P_0} \alpha_T(P) \leq \alpha\)</span> can always be achieved by
a suitable choice of <span class="math inline">\(c\)</span>. This is not
true in general. In such cases where the equality can't be attained, we
may consider randomized tests.</p>
<ul>
<li><p>A randomized decision rule is a probability measure <span class="math inline">\(\delta(x,\cdot)\)</span> on the action space for
any fixed <span class="math inline">\(x\)</span>. Since the action space
<span class="math inline">\((\mathbb A, \mathcal F_{\mathbb A}
)\)</span> contains only two points <span class="math inline">\(\mathbb
A = \{0,1 \}\)</span>, then any randomized test of a hypothesis testing
problem is equivalent to a statistic <span class="math inline">\(T(X)
\in [0,1]\)</span>, with <span class="math inline">\(T(x) =
\delta(x,\{1\})\)</span> and <span class="math inline">\(1-T(x) = \delta
(x,\{0\})\)</span>. In other words the expectation of <span class="math inline">\(T(X)I_{(0,1)}\)</span> must be <span class="math inline">\(0\)</span>.</p>
<p>In contrast, a nonrandomized test is a special case of randomized
test, where <span class="math inline">\(T(X)\)</span> doesn't take value
in <span class="math inline">\((0,1)\)</span>.</p></li>
<li><p>For any randomized test <span class="math inline">\(T(X)\)</span>, we define the type I error
probability to be <span class="math inline">\(\alpha_T(P) = ET(X), P \in
\mathcal P_0\)</span>, and the type II error probability to be <span class="math inline">\(1-\alpha_T(P) = 1-ET(X), P \in \mathcal
P_1\)</span>. The optimization rules are the same as the nonrandomized
case.</p></li>
</ul>
<p><strong>Example 2</strong>: Assume that the sample <span class="math inline">\(X\)</span> from a binomial distribution <span class="math inline">\(B(\theta,n)\)</span> with an unknown <span class="math inline">\(\theta \in (0,1)\)</span> and a fixed integer
<span class="math inline">\(n &gt;1\)</span>. Consider the hypothesis
<span class="math inline">\(H_0 : \theta \in (0, \theta_0] \quad
\text{versus} \quad H_1 : \theta \in (\theta_0 ,1)\)</span> and the
following class of randomized tests:</p>
<p><span class="math display">\[T_{j,q}(X) = \begin{cases} 1 \quad &amp;
X&gt;j \\ q \quad &amp; X=j \\ 0 \quad &amp; X &lt;j
\end{cases}\]</span></p>
<p>where <span class="math inline">\(j=0,1,\cdots,n-1\)</span> and <span class="math inline">\(q \in [0,1]\)</span>. Then</p>
<p><span class="math display">\[\alpha_{T_{j,q}}(\theta) = P(X&gt;j) +
qP(X=j), \; 0 &lt; \theta \leq \theta_0.\]</span></p>
<p>For any <span class="math inline">\(\alpha \in (0,1)\)</span> there
exists an integer <span class="math inline">\(j\)</span> and <span class="math inline">\(q \in (0,1)\)</span> such that the size of <span class="math inline">\(T_{j,q}\)</span> is exactly <span class="math inline">\(\alpha\)</span>, i.e. the upper bound is attained
through randomized test.</p>
<h1 id="confidence-sets">Confidence Sets</h1>
<p>Let <span class="math inline">\(\theta\)</span> be a <span class="math inline">\(k\)</span>-vector of unknown parameters related to
the unknown population <span class="math inline">\(P \in \mathcal
P\)</span>, <span class="math inline">\(C(X)\)</span> in the range of
<span class="math inline">\(\theta\)</span> and only depends on the
sample <span class="math inline">\(X\)</span>. If <span class="math inline">\(\inf_{P \in \mathcal P} P(\theta \in C(X)) \geq
1-\alpha\)</span>, then <span class="math inline">\(C(X)\)</span> is
called a confidence set for <span class="math inline">\(\theta\)</span>
with level of significance <span class="math inline">\(1-\alpha\)</span>.</p>
<p>Actually if the constraint above holds, the coverage probability of
<span class="math inline">\(C(X)\)</span> is at least <span class="math inline">\(1-\alpha\)</span>, though <span class="math inline">\(C(x)\)</span> either covers or doesn't cover <span class="math inline">\(\theta\)</span> whence we observe <span class="math inline">\(X=x\)</span>. To be more , the coverage
probability implies that when we make <span class="math inline">\(n\)</span> random observations of <span class="math inline">\(X=x\)</span> from the population and <span class="math inline">\(n\)</span> confidence regions correspondingly,
then there are about <span class="math inline">\(n (1-\alpha)\)</span>
among them covers <span class="math inline">\(\theta\)</span>.</p>
<h1 id="comments">Comments</h1>
<p>一些不负责任的暴论/吐槽（</p>
<ul>
<li><p>上统推的时候 wjd 说“一般情况下倾向于拒绝 <span class="math inline">\(H_0\)</span>”的时候就给我整震撼了，那我把 <span class="math inline">\(H_0\)</span> 和 <span class="math inline">\(H_1\)</span> 换一下不行吗（。你早说 decision rule
就是个示性函数，<span class="math inline">\(0\)</span> 对应 <span class="math inline">\(H_0\)</span>，<span class="math inline">\(1\)</span> 对应 <span class="math inline">\(H_1\)</span> 的话我还至于一年来都没记清楚 type I
error 和 type II error 分别是什么吗（x</p></li>
<li><p>另一个不能理解的点是 randomized
test，看她举的例子还以为这个东西就是用来做 <span class="math inline">\(H_0: \theta = \theta _0 \; \text{versus} \; H_1 :
\theta \neq \theta_0\)</span> 这种检验的，然后给 <span class="math inline">\(\theta = \theta_0\)</span> 一个 <span class="math inline">\(q \in (0,1)\)</span>
的值。感觉没怎么说过是因为达不到 upper bound
有点浪费所以用单点处来补足的这个想法，<del>可能也不排除当时已经是网课了所以是我听课不认真</del>（</p>
<p>但也不可能先把 randomized rule 讲一遍，再把 minimax rule
讲一下说明为什么是缩小 <span class="math inline">\(\sup
\alpha_T(P)\)</span>，在这之前总得把 measure
是啥说清楚，我说实话很怀疑很多人修统辅到最后连概率空间和 <span class="math inline">\(\sigma\)</span>-field
都没完全搞清楚，<del>一直在安慰大家这个不考那个不考的 dwl
全责</del>。但有的时候也很佩服统辅这些课能把故事完全限制在初等上还能讲明白<del>（大概吧，我经常是听不明白，但看起来大家都很明白）</del>的功力（</p></li>
<li><p>感觉就是之前一直没学本质，当时前四周的 statistics
看起来有点难但学会了 exponential family
的算法之后就薄纱一切了，反正大家也不会条件期望 <del>dwl 全责</del>
不可能真拿定义算 sufficient statistics 和
UMVUE；后半学期我就在疑惑这统计真的和数学有关系吗（，讲完基本概念之后就开始讲那些个
normal distribution family
上假设检验的例子，最后还要像八股文一样地考，可能确实是限制在初等上的话实在没什么可学的（</p></li>
<li><p>总之虽然吐槽了很多，我还是很认可去年统计推断这门课的，但只能说真想学点数学
<del>而不只是薄纱大家来愉悦身心（有的时候可能只会被反杀罢）</del>
的话还是别修统辅课了，调性不合（。</p>
<p><del>所以说去年这时候确实是对自己很没信心啊（</del></p>
<p><del>今年也没有啊（</del></p></li>
</ul>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>统计</tag>
      </tags>
  </entry>
  <entry>
    <title>整整整整个活儿啊不是整数规划</title>
    <url>/2023/11/07/Integer-Programming/</url>
    <content><![CDATA[<p>我觉得我写草稿纸上的笔记肯定过两天就不见了，存个档用来复习运筹期中，以及止增笑耳。</p>
<p>这什么破标题（</p>
<p>参考了《<a href="https://web.mit.edu/15.053/www/AMP.htm">Applied
Mathematical Programming</a>》Chapter 9,10 和一份相应的 <a href="https://www.math.clemson.edu/~mjs/courses/mthsc.440/integer.pdf">notes</a>。</p>
<span id="more"></span>
<p>为什么要做 integer programming？一般来说 linear programming
也可以得到一个答案，把它 round
一下不就好了？但其实有一些很实际的理由导致 integer programming
是必须的，就像线性回归中 dummy variable 也是必须的一样（啥</p>
<p>一般来说把 integer programming 的 integer condition 移除后的 linear
programming problem 称为其相应的 relaxed problem，integer programming 的
feasible set 一定是其 relax problem feasible set 的子集，其 optimal cost
也不会超过 relaxed problem 的 optimal
cost。这很好理解，就是取了个限定更强的形式。</p>
<ul>
<li><p>round 得到的结果未必还是最优的。比如：</p>
<p><span class="math display">\[\begin{aligned}\textbf{maximize} \quad
&amp; 8x_1+11x_2+ 6x_3 +4x_4 \\ \textbf{subject to} \quad
&amp;  5x_1+7x_2+4x_3+3x_4 \leq 14 \\ \quad &amp;x_j \in \{0,1\}, \quad
j=1,2,3,4 \end{aligned}\]</span></p>
<p>如果用 linear programming 会得到 optimal solution 是 <span class="math inline">\((1,1,0.5,0)^T\)</span>，round 一下得到 <span class="math inline">\((1,1,1,0)\)</span> 并不在 feasible set
中。与此同时实际上的 optimal solution 是 <span class="math inline">\((0,1,1,1)^T\)</span>，哪怕反向 round
也得不到精确的结果。</p>
<p>但是每个通过 round 得到的结果都比真正的 integer programming 的
optimal cost 要小，某种程度上来说给出了一个估计。</p></li>
<li><p>integer programming
可以反映许多很难描述的条件。例如两个条件至多成立一个，用某个 integer
variable 表示选择与否，等等。</p></li>
<li><p>哪怕真的可以用 round 的方法得到解，也不知道反向/正向 round
的结果是不是最好的，而在一些实际问题里哪怕只是相差 <span class="math inline">\(1\)</span> 也会造成成本/效益的巨大差异。</p></li>
</ul>
<p>另外 integer programming 的困难在于 optimal solution
不再一定在顶点处取到，而且 feasible set
是离散的点集，其数量远大于顶点数量，不太可能用枚举得到答案。</p>
<h1 id="standard-settings">Standard Settings</h1>
<p>Interger programming 的标准形式一般来说相对简单，但和 linear
programming 稍有不同：</p>
<p><span class="math display">\[\begin{aligned} \textbf{maximize} \quad
&amp; c^Tx \\ \textbf{subject to} \quad &amp; Ax \leq b  \\ \quad &amp;
x_j \in \mathbb N \end{aligned}\]</span></p>
<p>其中要求 <span class="math inline">\(c \geq 0, A \geq 0, b \geq
0\)</span>（指的是 <span class="math inline">\(A\)</span> 的每个分量
<span class="math inline">\(a_{ij}\)</span> 都要是非负的
<del>而不是正定什么的要求</del>）。</p>
<p>这样写相对粗糙。事实上，如果 <span class="math inline">\(A\)</span>
只表示一个一维的 constraint 则称为 knapsack problem，否则是
multidimensional knapsack problem；如果所有的 <span class="math inline">\(x_j\)</span> 均在 <span class="math inline">\(0,1\)</span> 上取值则称为 pure integer
programming，否则是 mixed linear programming。</p>
<p>对应的 pure integer programming 的标准形式是：</p>
<p><span class="math display">\[\begin{aligned} \textbf{maximize} \quad
&amp; c^Tx \\ \textbf{subject to} \quad &amp; Ax \leq b  \\ \quad &amp;
x_j \in \{0,1\} \end{aligned}\]</span></p>
<p>同样要求 <span class="math inline">\(c \geq 0, A \geq 0, b \geq
0\)</span>。</p>
<h2 id="standardize-to-0-1-knapsack-problem">Standardize to 0-1 Knapsack
Problem</h2>
<p>最明显的一些要求是 <span class="math inline">\(c\geq 0,A\geq
0\)</span>，至于 <span class="math inline">\(b\)</span>
谋事在人成事在天（。</p>
<p>对于 1-dimension 来说一般来说如果有看到 <span class="math inline">\(c_i \geq 0, a_i \leq 0\)</span> 的话直接把 <span class="math inline">\(x_i\)</span> 取为 <span class="math inline">\(1\)</span>，因为这变相的扩容了 constraint
的上限；如果 <span class="math inline">\(c_i \leq 0 ,a_i \geq 0\)</span>
则置为 <span class="math inline">\(0\)</span>，显然它的存在既会占用资源又减小上限。如果
<span class="math inline">\(c_i ,a_i \leq 0\)</span> 同时成立就用 <span class="math inline">\(y_i = 1-x_i\)</span>
代替原变量即可，从而得到标准形式。</p>
<p><del>Multidimension 咋办，他也没说啊（挠头（</del></p>
<p>感觉可能就不用动了，反正后面的求解里面都还是考虑 relaxed LP
问题，直接按照 LP 的 standardized form 来化简就可以。当然如果有一溜
<span class="math inline">\(\{a_{ij}\}_{i=1}^m \leq 0, c_i \geq
0\)</span> 这种情况的话直接把 <span class="math inline">\(x_{i}\)</span>
置 <span class="math inline">\(1\)</span>
即可，少一个变量是一个。或者也可能是用 <span class="math inline">\(x_1\)</span> 和 <span class="math inline">\(1-x_i\)</span> 替换来保证所有的 <span class="math inline">\(c_i\)</span> 为正。</p>
<h1 id="solutions-to-integer-programming">Solutions to Integer
Programming</h1>
<h2 id="relaxed-linear-programming">Relaxed Linear Programming</h2>
<p>比较符合直觉的一种方案就是把它和对应的 linear programming problem
结合起来看，它们之间的确存在一定的关系，甚至在某一些情况下可以得到对于
integer programming 的估计（未必是精确值）。</p>
<p><span class="math display">\[\begin{aligned} \textbf{maximize} \quad
&amp; c^Tx \\ \textbf{subject to} \quad &amp; Ax \leq b  \\ \quad &amp;
x_j \in \mathbb N \end{aligned} \quad \quad \quad \begin{aligned}
\textbf{maximize} \quad &amp; c^Tx \\ \textbf{subject to} \quad &amp; Ax
\leq b  \\ \quad &amp; x_j \geq 0 \end{aligned}\]</span></p>
<p>（暂且先不考虑 0-1 knapsack）</p>
<p>注意在实际计算中想要解出（比如用 simplex method）relaxed problem
还需要再做一步 standardize，此处略去。</p>
<p>此时有：</p>
<ul>
<li>如果 LP 的 optimal solution 恰好是个 integer solution 那么也一定是
IP 的 optimal solution；</li>
<li>LP 的 optimal cost 一定比 IP 的 optimal cost 更大；</li>
<li>如果 <span class="math inline">\(c\)</span> 的所有分量也是整数，则将
LP 的 optimal solution 向下取整得到的解也在 feasible set 里，而且至少比
IP 的 optimal cost 更大（因为 round 之后的结果未必是 <span class="math inline">\(0,1\)</span> 取值的，不一定是 IP 的解）。</li>
</ul>
<h2 id="bound-and-branch">Bound and Branch</h2>
<h3 id="pure-integer-programming">Pure Integer Programming</h3>
<p>本质上就是，利用 relaxed linear programming 来寻找一组 optimal
solution（一般用 simplex method）<span class="math inline">\(x=
(x_1,x_2,\cdots,x_n)\)</span>，其中会有若干个是非整数解，记为 <span class="math inline">\(x_{m1},x_{m2},\cdots,x_{mk}\)</span>。此时可以对每个
<span class="math inline">\(x_{mi}\)</span> 是向上 round 还是向下 round
做一个分割，就回到了 seperating hyperplane theorem。这样就得到了一个
tree，它的每一组分叉都多加了一个条件，解出所有分叉上点的解即可。</p>
<p>来个示意图，我也不知道为什么这个图在书上就是颈椎病图，凑合看吧（</p>
<p><img src="https://s2.loli.net/2023/11/07/s3LfDpAbhGFmCj8.png" alt="tree.png"></p>
<p>某种程度上来说和 ellipsoid method
非常相似，都是在原条件的基础上继续用 cutting plane
加条件然后继续往下解。所以说需要考虑的问题也是相似的，也即算法何时终止、time
usage 如何、这棵树上的 optimal solution 是否就是真正的 optimal
solution（只是在对每个非整数变量做
round，听起来不是特别靠谱）。特别地，还有树上所有的分支应该以什么样的顺序求解才最优、能否中途去掉一些
inactive 的分支来保证计算量最小。</p>
<ul>
<li><p>首先观察到所有的 <span class="math inline">\(c_i\)</span>
都是正的（如果不是正的请把 <span class="math inline">\(x_i\)</span> 换成
<span class="math inline">\((1-y_i)\)</span>），所以可以用 dual problem
来解 <del>但总觉得没啥必要</del></p></li>
<li><p>计算得到的最初的 <span class="math inline">\(L_0\)</span> 的
optimal cost 记为 <span class="math inline">\(\bar
z\)</span>，这样这棵树上的每一个 optimal cost 都不会大于 <span class="math inline">\(\bar z\)</span>。</p></li>
<li><p>在计算的过程中，如果已经有某个 subproblem 得到了 integer solution
和相应的 optimal cost <span class="math inline">\(z^*\)</span>，则如果在其他 active subproblem with
fractional solution 中得到了更小的 optimal cost <span class="math inline">\(z \leq z^*\)</span>，则说明无论如何分划，这一
active subproblem 所对应的平面区域上都不可能找到 optimal
cost，直接将其置为 inactive 即可。</p>
<p>换言之，在找到一个 optimal cost 为 <span class="math inline">\(z^*\)</span> 之后，只需要再寻找一个 optimal cost
为 <span class="math inline">\(z\)</span>，满足 <span class="math inline">\(z^* \leq z \leq \bar z\)</span> 的整数解。这就是
bound and branch 中 bound 的来源。</p></li>
<li><p>Infeasible subproblem 也不需要再分划下去。</p></li>
</ul>
<p>最后得到的 algorithm 大致是：</p>
<ol type="1">
<li>Solve the linear relaxation of the problem. If the solution is
integer, then we are done. Otherwise create two new subproblems by
branching on a fractional variable.</li>
<li>A subproblem is not active when any of the following occurs:
<ul>
<li>You used the subproblem to branch on</li>
<li>All variables in the solution are integer</li>
<li>The subproblem is infeasible</li>
<li>You can fathom the subproblem by a bounding argument</li>
</ul></li>
<li>Choose an active subproblem and branch on a fractional variable.
Repeat until there are no active subproblems.</li>
</ol>
<h3 id="mixed-integer-programming">Mixed Integer Programming</h3>
<p>Mixed integer programming 的 bound and branch
方法和上述几乎并无不同，只是每一次加条件做分枝的时候只对 integer
variable 加条件，计算量会隐性地小一点。</p>
<h2 id="cutting-plane-method">Cutting Plane Method</h2>
<p><del>我个人认为课件上说这个条件在二维条件下用比 bound and branch
简单这件事非常逆天，就，我用 bound and branch 来解 integer programming
的时候也是用画图来做的啊，谁真的拿 simplex method 解 <span class="math inline">\(2^k\)</span> 个 linear programming
啊（（</del></p>
<p>用一个例子来解释：</p>
<p><span class="math display">\[\begin{aligned}\textbf{maximize}
&amp;\quad 7x_1+ 9x_2 \\ \textbf{subject to}&amp; \quad -x_1+3x_2 \leq 6
\\ &amp; \quad 7x_1+x_2 \leq 35 \\ &amp; \quad x_1,x_2 \in \mathbb
N  \end{aligned}\]</span></p>
<p>类似于化成 linear programming 的方法，但是相应的 slack variable
也是正整数：</p>
<p><span class="math display">\[\begin{aligned}\textbf{minimize}
&amp;\quad -7x_1- 9x_2 \\ \textbf{subject to}&amp; \quad -x_1+3x_2+s_1=6
\\ &amp; \quad 7x_1+x_2 +s_2= 35 \\ &amp; \quad x_1,x_2,s_1,s_2 \in
\mathbb N  \end{aligned}\]</span></p>
<p>用 simplex method 得到一个最终的 full tableau（也就是无视掉上述
linear programming 的整数条件进行一个优化的做，得到 LP 对应的 optimal
solution），此时的 tableau 如下所示：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th><span class="math inline">\(x_1\)</span></th>
<th><span class="math inline">\(x_2\)</span></th>
<th><span class="math inline">\(s_1\)</span></th>
<th><span class="math inline">\(s_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td><span class="math inline">\(63\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(28/11\)</span></td>
<td><span class="math inline">\(15/11\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(x_2\)</span></td>
<td><span class="math inline">\(7/2\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(7/22\)</span></td>
<td><span class="math inline">\(1/22\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(x_1\)</span></td>
<td><span class="math inline">\(9/2\)</span></td>
<td><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(-1/22\)</span></td>
<td><span class="math inline">\(3/22\)</span></td>
</tr>
</tbody>
</table>
<p>也就是说在计算中最后得到的 constraints 为：</p>
<p><span class="math display">\[\begin{aligned} &amp; x_2+7/22 s_1+
1/22s_2=7/2 \\ &amp; x_1 - 1/22 s_1+ 3/22 s_2= 9/2
\end{aligned}\]</span></p>
<p>把所有的整数部分放在左边，分数 round 到最小放在右边（注意要让右边所有
variable 的系数为负，且绝对值小于 <span class="math inline">\(1\)</span>，这样才能往后加 constraints）：</p>
<p><span class="math display">\[\begin{aligned} &amp; x_2-3 =
1/2-7/22s_1-1/22s_2 \\ &amp;x_1 - s_1-4 =1/2-21/22s_1-3/22s_2
\end{aligned}\]</span></p>
<p>这给出了新的 constraints ：</p>
<p><span class="math display">\[\begin{aligned}&amp; 1/2-7/22s_1-1/22s_2
\leq 0 \\  &amp; 1/2 - 21/22s_1-3/22s_2 \leq 0
\end{aligned}\]</span></p>
<h2 id="solution-to-0-1-knapsack-problem">Solution to 0-1 Knapsack
Problem</h2>
<p>这 PPT 上怎么说是一个一个试啊（挠头</p>
<p>举个例子先：</p>
<p><span class="math display">\[\begin{aligned} \textbf{maximize} \quad
&amp; z=3x_1-2x_2+5x_3 \\ \textbf{subject to} \quad &amp; x_1+2x_2-x_3
\leq 2 \\ &amp; x_2+4x_2+x_3 \leq 4 \\&amp; x_2+x_3 \leq 3 \\
&amp;4x_2+x_3 \leq 6 \\ &amp; x_1,x_2,x_3 \in \{0,1\}
\end{aligned}\]</span></p>
<p>当然可以把 <span class="math inline">\((x_1,x_2,x_3)\)</span> 按照
<span class="math inline">\(000,001,010,011,100,101,110,111\)</span>
来逐个尝试，稍微简化一下的话可以考虑</p>
<p><span class="math display">\[\begin{aligned} \textbf{maximize} \quad
&amp; z=5x_3 +3x_1-2x_2\\ \textbf{subject to} \quad &amp; x_1+2x_2-x_3
\leq 2 \\ &amp; x_2+4x_2+x_3 \leq 4 \\&amp; x_2+x_3 \leq 3  \\
&amp;4x_2+x_3 \leq 6 \\ &amp; x_1,x_2,x_3 \in
\{0,1\}   \end{aligned}\]</span></p>
<p>把 cost function 中系数最大的 <span class="math inline">\(5x_3\)</span> 提到最前面，如果能够达到最大则 <span class="math inline">\(x_3=1\)</span> 的情况较为有利。我们发现 <span class="math inline">\((x_1,x_2,x_3) = (0,0,1)\)</span> 能够符合
constraints 而且 cost 为 <span class="math inline">\(5\)</span>，因此其后讨论其他取值时 cost 小于 <span class="math inline">\(5\)</span> 的可以无需带入检查
constraints，直接舍去。</p>
]]></content>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>详论生物统计学概论</title>
    <url>/2023/03/20/Introduction-to-Biostatistics/</url>
    <content><![CDATA[<p><del>我都给统辅课笔记起了些什么破标题</del></p>
<p>选课的时候我还侥幸以为生统概论可以放松心情，来随便听听简单了解一下那种。可能是前置没学完的原因，倒也没那么水，ANOVA
还是花了不少时间看的。</p>
<p>wty 老师的英语口语真不错，可惜我听力一般，一走神就寄了。还是要感谢 <a href="https://v1ncent19.github.io/SummaryNotes/">V1ncent19
的统辅笔记</a>救我，不过他看起来是前置都学完了来上的这个，写的有点抽象，我想写个<del>废话多一点</del>具体点的。</p>
<span id="more"></span>
<h1 id="analysis-of-variance">Analysis of Variance</h1>
<h2 id="示例treatment-of-lead-exposed-children-trial">示例——Treatment of
Lead-Exposed Children Trial</h2>
<p>100 名被试被分成两组分别使用安慰剂和药剂，在实验开始前、实验第 1, 4,
6 周分别检验了血液铅含量水平。第 i 名被试的实验开始前水平为 <span class="math inline">\(y_{i1}\)</span>，实验结束后水平为 <span class="math inline">\(y_{i2}\)</span>，变化水平为 <span class="math inline">\(d_i =
y_{i2}-y_{i1}\)</span>，希望利用这些数据观察药剂的有效程度。</p>
<p>假设线性回归模型为 <span class="math inline">\(d_i = \beta_0 +
\beta_1 x_i +e_i\)</span>，注意此处的 <span class="math inline">\(x_i\)</span>
是一个分类统计量，也就是说被试使用安慰剂时取 <span class="math inline">\(x_i = 0\)</span>，被试使用试验药剂时 <span class="math inline">\(x_i =1\)</span>。做一些假设检验：</p>
<ul>
<li><span class="math inline">\(H_0: \beta_0 =0\)</span>
检验了安慰剂组的平均变化是否为 <span class="math inline">\(0\)</span></li>
<li><span class="math inline">\(H_0:\beta_1 = 0\)</span>
检验了安慰剂组和药剂组之间的平均差异是否为 <span class="math inline">\(0\)</span>，也即药剂是否对治疗有作用</li>
</ul>
<p>这一模型也可以写作 <span class="math inline">\(y_{i2} = y_{i1} +
\beta_0 +\beta_1 x_i + e_i\)</span>，但实际上 <span class="math inline">\(y_{i1}\)</span> 对于 <span class="math inline">\(y_{i2}\)</span> 的影响也有待商榷，未必在 <span class="math inline">\(y_{i1}\)</span> 变化一个单位时，<span class="math inline">\(y_{i2}\)</span>
也随之变化一个单位，所以模型可以修正为 <span class="math inline">\(y_{i2} = \beta_0 + \beta_1 x_i +\beta_2 y_{i1}
+e_i\)</span>。这样又多出来一个假设检验：</p>
<ul>
<li><span class="math inline">\(H_0 :\beta _2 = 0\)</span>
检验了初始状态对末态是否有影响</li>
</ul>
<p>不同的检验模型会得到一些不同的结果。类似的场景是我们的出发点。</p>
<h2 id="one-factor-anova">One Factor ANOVA</h2>
<p>首先给出一个希望做检验的场景：<span class="math inline">\(n_T\)</span> 个实验对象被分成 <span class="math inline">\(r\)</span> 组，每组有 <span class="math inline">\(n_i\)</span> 个实验对象，有 <span class="math inline">\(n_T = \Sigma_{i=1} ^r n_i\)</span>。由此我们得到
<span class="math inline">\(n_T\)</span> 个数据 <span class="math inline">\(Y_{ij}\)</span>，<span class="math inline">\(i\)</span> 表示组别，<span class="math inline">\(1\leq i \leq r\)</span>，<span class="math inline">\(j\)</span> 表示在某一组内的编号，<span class="math inline">\(1 \leq j \leq n_i\)</span>。</p>
<h3 id="cell-means-model">Cell means model</h3>
<p>模型假设是 <span class="math inline">\(Y_{ij} = \mu_i +
\varepsilon_{ij}\)</span>。</p>
<p>其中，<span class="math inline">\(\mu_i\)</span> 是第 <span class="math inline">\(i\)</span> 组的理论均值，<span class="math inline">\(\varepsilon _{ij}\)</span> i.i.d. <span class="math inline">\(\sim
N(0,\sigma^2)\)</span>。注意到在这一模型假设中有 <span class="math inline">\(r+1\)</span> 个参数，分别是 <span class="math inline">\(\mu_1,\mu_2,...,\mu_r,\sigma^2\)</span>，我们需要用得到的数据来对这些未知参数进行估计。考虑一些统计量作为参数的估计量：</p>
<p><span class="math display">\[\bar{Y}_{i.} = \frac{1}{n_i} \Sigma_{j=1
}^{n_i} Y_{ij}  = \hat \mu _i\]</span></p>
<p><span class="math display">\[\bar{Y}_{..} = \frac{1}{n_T}
\Sigma_{i=1}^r \Sigma_{j=1} ^{n_i} Y_{ij} = \frac{1}{n_T} \Sigma_{i=1}^r
n_i \bar{Y}_{i.}\]</span></p>
<p><span class="math display">\[s_i ^2 = \Sigma(Y_{ij} - \bar Y_{i.})^2
/ (n_i -1) \]</span></p>
<p><span class="math display">\[s^2 = \frac{1}{n_T- r} \Sigma_{i=1}^r
(n_i -1) s_i ^2 = \hat \sigma^2\]</span></p>
<p>在这一模型中，我们关注的假设检验是 <span class="math inline">\(i\)</span> 组实验之间是否存在差异，假设检验表示为
<span class="math inline">\(H_0 : \mu_1= \mu_2 = ... = \mu_r =
\mu\)</span>，对应的备择假设即为 <span class="math inline">\(\{ \mu_i
\}_{i=1} ^r\)</span> 中存在不同的项。检验最经典的方法即为
ANOVA，analysis of variance。核心是以下的分解：</p>
<p><span class="math display">\[\begin{aligned} SSTO = \Sigma_i
\Sigma_j(Y_{ij} - \bar Y_{..})^2 &amp;= \Sigma_i \Sigma_j (Y_{ij} - \bar
Y_{i.} +\bar Y_{i.} - \bar Y_{..})^2 \\&amp; = \Sigma_i n_i (\bar Y_{i.}
- \bar Y_{..})^2 + \Sigma_i \Sigma_j (Y_{ij} - \bar Y_{i.})^2 \\
&amp;=SSTR + SSE \end{aligned}\]</span></p>
<p>可以观察到，<span class="math inline">\(SSTR\)</span>
是组间差距，体现了不同组别之间的差别，<span class="math inline">\(SSE\)</span>
是组内差距，体现了同一组内各数据的偏差。注意 <span class="math inline">\(SSTR\)</span> 的自由度是 <span class="math inline">\(r-1\)</span>，<span class="math inline">\(SSE\)</span> 的自由度是 <span class="math inline">\(n_T - r\)</span>，<span class="math inline">\(SSTO\)</span> 的自由度是 <span class="math inline">\(n_T - 1\)</span>。由此可以求出 <span class="math inline">\(MSE= \frac{SSE}{n_T -r}\)</span>，<span class="math inline">\(MSTR =
\frac{SSTR}{r-1}\)</span>。作业里证明了两个统计量的期望，<span class="math inline">\(\mathbb E(MSE) = \sigma^2\)</span>，<span class="math inline">\(\mathbb E(MSTR) = \sigma^2 +\frac{\Sigma_i n_i
(\mu _i -\mu_.)^2}{r-1}\)</span>，其中 <span class="math inline">\(\mu_.
= \frac{\Sigma_i n_i \mu_i}{n_T}\)</span>。</p>
<p>在 <span class="math inline">\(H_0\)</span> 成立时，<span class="math inline">\(\frac{SSE}{\sigma^2} \sim \chi^2 _{n_T -
r}\)</span>，<span class="math inline">\(\frac{SSTR}{\sigma^2} \sim
\chi^2_{r-1}\)</span>。因此 <span class="math inline">\(F=\frac{MSTR}{MSE} \sim F_{r-1,n_T -r}\)</span>
作为最终的检验统计量。</p>
<p>当 <span class="math inline">\(F^* &gt; F(1-\alpha , r-1 , n_T
-r)\)</span> 时拒绝原假设，否则接受；<span class="math inline">\(Power =
P(F^* &gt; F(1-\alpha , r-1,n_T -r)| \delta)\)</span>，其中 <span class="math inline">\(\delta\)</span> 是一个非中心偏移量，<span class="math inline">\(\delta = \frac{1}{\sigma} \sqrt{\frac 1 r \Sigma_i
n_i (\mu_i - \mu_.)^2}\)</span>。</p>
<h3 id="factor-effects-model">Factor Effects Model</h3>
<p>Factor Effects Model 是 Cell Means Model
的一个重新参数化的结果。模型假设是 <span class="math inline">\(Y_{ij} =
\mu + \tau_i + \varepsilon_{ij}\)</span>。</p>
<p>其中，<span class="math inline">\(\mu_i\)</span>
是整体的理论均值，<span class="math inline">\(\varepsilon _{ij} i.i.d.
\sim N(0,\sigma^2)\)</span>。它的参数比 cell mean model 多一个，分别是
<span class="math inline">\(\mu , \tau_1 , ..., \tau_r ,
\sigma^2\)</span>，但是自由度是相同的，因为 <span class="math inline">\(\{ \tau _i \}_{i=1}^r\)</span> 存在一个约束 <span class="math inline">\(\Sigma_{i=1}^r \tau_i =
0\)</span>，如果没有这个约束会导致存在多组解。考虑一些统计量作为参数的估计量：</p>
<p><span class="math display">\[\bar{Y}_{i.} = \frac{1}{n_i} \Sigma_{j=1
}^{n_i} Y_{ij}  = \hat \tau _i + \hat \mu\]</span></p>
<p><span class="math display">\[\bar{Y}_{..} = \frac{1}{n_T}
\Sigma_{i=1}^r \Sigma_{j=1} ^{n_i} Y_{ij} = \frac{1}{n_T} \Sigma_{i=1}^r
n_i \bar{Y}_{i.} = \hat{\mu}\]</span></p>
<p><span class="math display">\[s_i ^2 = \Sigma(Y_{ij} - \bar Y_{i.})^2
/ (n_i -1) \]</span></p>
<p><span class="math display">\[s^2 = \frac{1}{n_T- r} \Sigma_{i=1}^r
(n_i -1) s_i ^2 = \hat \sigma^2\]</span></p>
<p>在这一模型中，我们关注的假设检验仍然是 <span class="math inline">\(i\)</span> 组实验之间是否存在差异，假设检验表示为
<span class="math inline">\(H_0 : \tau_1= \tau_2 = ... = \tau_r =
0\)</span>，对应的备择假设即为 <span class="math inline">\(\{ \mu_i
\}_{i=1} ^r\)</span> 中存在不同的项。factor effects model
在参数的含义上比 cell mean model 更清晰。</p>
<h2 id="two-factors-anova">Two Factors ANOVA</h2>
<p>首先给出一个希望做检验的场景：<span class="math inline">\(nab\)</span> 个实验对象被分成 <span class="math inline">\(a\times b\)</span> 组，每组有 <span class="math inline">\(n\)</span> 个实验对象。第 <span class="math inline">\(ij\)</span> 组的实验条件是 <span class="math inline">\(A\)</span> 因素的等级为 <span class="math inline">\(i\)</span>，<span class="math inline">\(B\)</span>
因素的等级为 <span class="math inline">\(j\)</span>，其中有 <span class="math inline">\(1 \leq i \leq a, 1\leq j \leq
b\)</span>。由此我们得到 <span class="math inline">\(nab\)</span> 个数据
<span class="math inline">\(Y_{ijk}\)</span>，<span class="math inline">\(i\)</span> 表示以 <span class="math inline">\(A\)</span> 因素分类的组别，<span class="math inline">\(j\)</span> 表示以 <span class="math inline">\(B\)</span> 因素分类的组别，<span class="math inline">\(k\)</span> 表示在某一组内的编号，<span class="math inline">\(1 \leq k \leq n\)</span>。</p>
<p>每一组都是 <span class="math inline">\(n\)</span> 个人，这是一个
balanced design。</p>
<h3 id="factor-effects-model-1">Factor Effects Model</h3>
<p>模型假设是 <span class="math inline">\(Y_{ijk} = \mu +\alpha_i +
\beta_j +(\alpha \beta)_{ij} + \varepsilon_{ijk}\)</span>。</p>
<p>其中，<span class="math inline">\(\mu\)</span> 是整体的均值，<span class="math inline">\(\alpha_i\)</span> 代表只和等级为 <span class="math inline">\(i\)</span> 的因素 <span class="math inline">\(A\)</span> 有关的变化，<span class="math inline">\(\beta_j\)</span> 表示只和等级为 <span class="math inline">\(j\)</span> 的因素 <span class="math inline">\(B\)</span> 有关的变化，<span class="math inline">\((\alpha \beta)_{ij}\)</span>
表示和两个因素同时相关的变化，相当于一个交叉项。</p>
<p>这里面有 <span class="math inline">\((a+1)(b+1)\)</span>
个参数，对其也有一定的约束：<span class="math inline">\(\Sigma_i
\alpha_i = \Sigma_j \beta_j = \Sigma_i (\alpha \beta)_{ij} = \Sigma_j
(\alpha \beta)_{ij}
=0\)</span>。做一些其他的参数假设，让参数含义更清晰：</p>
<p><span class="math display">\[\mu_{i.} = \alpha_i
+\mu_{..}\]</span></p>
<p><span class="math display">\[\mu_{.j} = \beta _j +
\mu_{..}\]</span></p>
<p><span class="math display">\[\mu_{ij} = \mu_{..} +\alpha_i + \beta_j
+(\alpha \beta)_{ij}\]</span></p>
<p>如果 <span class="math inline">\((\alpha \beta)_{ij}=0\)</span>
则说明因素 <span class="math inline">\(A,B\)</span>
之间不存在相互作用的关系，这样的模型称为 additive model。</p>
<p>考虑一些统计量作为参数的估计量：</p>
<p><span class="math display">\[\bar{Y}_{ij.} = \frac{1}{n} \Sigma_{k=1
}^{n} Y_{ijk}  = \hat \mu_{ij} = \hat \mu + \hat \alpha _i + \hat
\beta_j + \hat{(\alpha \beta)}_{ij}\]</span></p>
<p><span class="math display">\[\bar{Y}_{i..} = \frac{1}{bn}
\Sigma_{j=1}^b \Sigma_{k=1} ^{n} Y_{ijk} = \hat{\mu} +\hat \alpha_i =
\hat \mu_{i.}\]</span></p>
<p><span class="math display">\[\bar{Y}_{.j.} = \frac{1}{an}
\Sigma_{i=1}^a \Sigma_{k=1} ^{n} Y_{ijk} = \hat{\mu} +\hat \beta_j =
\hat \mu_{.j}\]</span></p>
<p><span class="math display">\[\bar{Y}_{...} =
\frac{1}{abn}\Sigma_{i=1}^a \Sigma_{j=1}^b \Sigma_{k=1} ^{n} Y_{ijk} =
\hat{\mu} \]</span></p>
<p>Two factors ANOVA 的方差分解更复杂一些：</p>
<p><span class="math display">\[\begin{aligned} SSTO &amp;= \Sigma_i
\Sigma_j \Sigma_k (Y_{ijk} - \bar Y_{...})^2   \\ &amp;=  \Sigma_i
\Sigma_j \Sigma_k ((\bar Y_{i..} - \bar Y_{...})+(\bar{Y}_{.j.} - \bar
Y_{...}) +(\bar{Y}_{ij.} - \bar Y_{i..} -\bar Y_{.j.} +\bar Y_{...})
+(Y_{ijk} - \bar Y_{ij.}))^2 \\&amp;=bn\Sigma_i (\bar Y_{i..} - \bar
Y_{...})^2+an\Sigma_j (\bar{Y}_{.j.} - \bar Y_{...})^2+n\Sigma_i
\Sigma_j (\bar{Y}_{ij.} - \bar Y_{i..} -\bar Y_{.j.} +\bar Y_{...})^2+
\Sigma_{i}\Sigma_j \Sigma_k (Y_{ijk} - \bar Y_{ij.})^2  \\&amp;=SSA
+SSB+SSAB+SSE  \end{aligned}\]</span></p>
<p>其中，<span class="math inline">\(SSA\)</span> 的自由度是 <span class="math inline">\(a-1\)</span>，<span class="math inline">\(SSB\)</span> 的自由度是 <span class="math inline">\(b-1\)</span>，<span class="math inline">\(SSAB\)</span> 的自由度是 <span class="math inline">\((a-1)(b-1)\)</span>，<span class="math inline">\(SSE\)</span> 的自由度是 <span class="math inline">\(ab(n-1)\)</span>。在这一个复杂问题中我们关心不同的问题，可以做出三种不同的假设检验，有对应的检验统计量。</p>
<ul>
<li><span class="math inline">\(A\)</span> 因素是否会导致差异？<span class="math inline">\(H_0: \alpha_1 =\alpha_2=...=\alpha_a\)</span>，在
<span class="math inline">\(H_0\)</span> 下有 <span class="math inline">\(F^* = \frac{SSA/(a-1)}{SSE/(ab(n-1))} \sim
F_{a-1,ab(n-1)}\)</span></li>
<li><span class="math inline">\(B\)</span> 因素是否会导致差异？<span class="math inline">\(H_0: \beta_1 =\beta_2=...=\beta_b\)</span>，在
<span class="math inline">\(H_0\)</span> 下有 <span class="math inline">\(F^* = \frac{SSB/(b-1)}{SSE/(ab(n-1))} \sim
F_{b-1,ab(n-1)}\)</span></li>
<li><span class="math inline">\(A,B\)</span> 是否联合作用？<span class="math inline">\(H_0:(\alpha \beta)_{ij}=0, \forall 1 \leq i \leq
a,1\leq j \leq b\)</span>，在 <span class="math inline">\(H_0\)</span>
下有 <span class="math inline">\(F^*=\frac{SSAB/(a-1)(b-1)}{SSE/(ab(n-1))} \sim
F_{(a-1)(b-1),ab(n-1)}\)</span></li>
</ul>
<h2 id="random-effect-test">Random Effect Test</h2>
<h3 id="why-random-effects">Why random effects?</h3>
<p>事实上，有的时候对于一个 cell means model 或者 factor effects
model，我们并不是很关心每个 <span class="math inline">\(\mu_i\)</span>
的检验，而是关心整体的 <span class="math inline">\(\mu_.\)</span>
的情况；这种情况下一般 level of factor
也是随机从一个总体里取出的。所以需要改变一些模型假设，进行 random effect
的检验。</p>
<h3 id="cell-means-model-for-random-effect">Cell means model for random
effect</h3>
<p>回顾一下 cell means model：</p>
<blockquote>
<p>模型假设是 <span class="math inline">\(Y_{ij} = \mu_i +
\varepsilon_{ij}\)</span>。</p>
<p>其中，<span class="math inline">\(\mu_i\)</span> 是第 <span class="math inline">\(i\)</span> 组的理论均值，<span class="math inline">\(\varepsilon _{ij}\)</span> i.i.d. <span class="math inline">\(\sim
N(0,\sigma^2)\)</span>。注意到在这一模型假设中有 <span class="math inline">\(r+1\)</span> 个参数，分别是 <span class="math inline">\(\mu_1,\mu_2,...,\mu_r,\sigma^2\)</span>，我们需要用得到的数据来对这些未知参数进行估计。</p>
</blockquote>
<p>对于 cell means model for random effect，需要把 <span class="math inline">\(\mu_i\)</span> 视作一组随机变量而非参数：</p>
<blockquote>
<p>模型假设是 <span class="math inline">\(Y_{ij} = \mu_i +
\varepsilon_{ij}\)</span>。其中有 <span class="math inline">\(i =
1,2,...,r\)</span>，<span class="math inline">\(j
=1,2,...,n\)</span>，暂时设定为一个 balanced test。</p>
<p>其中，<span class="math inline">\(\mu_i \sim N(\mu_., \sigma_\mu
^2)\)</span> 不要求相互独立，<span class="math inline">\(\varepsilon_{ij}\)</span> i.i.d. <span class="math inline">\(\sim N(0,\sigma^2)\)</span>，且 <span class="math inline">\(\mu_i\)</span> 和 <span class="math inline">\(\varepsilon_{ij}\)</span> 之间是相互独立的。
因此，这一模型中共有 <span class="math inline">\(3\)</span>
个参数，分别是 <span class="math inline">\(\mu_., \sigma_\mu,
\sigma\)</span>，而且 <span class="math inline">\(Y_{ij}\)</span>
不相互独立。</p>
<p>事实上，我们不要求关于特定的 <span class="math inline">\(\mu_i\)</span> 的结论，而是关心在 population <span class="math inline">\(\lbrace \mu_i \rbrace_{i=1} ^r\)</span>
上的推断，以推断 <span class="math inline">\(\mu\)</span> 和 <span class="math inline">\(\sigma_\mu^2\)</span> 为主。</p>
</blockquote>
<p>简单推导可以得到以下结论：</p>
<ul>
<li><span class="math inline">\(\mathbb E(Y_{ij}) = \mu_.\)</span></li>
<li><span class="math inline">\(Var(Y_{ij}) = \sigma^2 +\sigma_\mu
^2\)</span></li>
<li><span class="math inline">\(Cov(Y_{ij} , Y_{ij&#39;}) = \sigma_\mu
^2, j \neq j&#39;\)</span></li>
<li><span class="math inline">\(Cov(Y_{ij},Y_{i&#39;j&#39;}) = 0, i \neq
i&#39;, j \neq j&#39;\)</span></li>
<li><span class="math inline">\(\mathbb E(MSE) = \sigma^2\)</span></li>
<li><span class="math inline">\(\mathbb E(MSTR) = \sigma^2 + n\sigma_\mu
^2\)</span></li>
</ul>
<p>记 <span class="math inline">\(\sigma_Y^2 = \sigma_\mu^2 +
\sigma^2\)</span>，有一个在推断中有意义的参数是 <span class="math inline">\(\frac{\sigma_\mu ^2}{\sigma_Y ^2} =
\frac{\sigma_\mu ^2}{\sigma_\mu ^2 +
\sigma^2}\)</span>。这表征了在整体方差中，由 <span class="math inline">\(Y_{ij}\)</span> 的随机性产生的比例。</p>
<p>对此我们常做的一个检验是 <span class="math inline">\(H_0 :\sigma_\mu
^2 = 0; H_a: \sigma_\mu ^2 &gt;0\)</span>，原假设的含义在于说明 <span class="math inline">\(\mu_i\)</span>​ 是相等的，事实上这和 fixed effect
下的 cell means model 所做的检验是相同的。在 <span class="math inline">\(H_0\)</span> 成立时，<span class="math inline">\(\frac{SSE}{\sigma^2} \sim \chi^2
_{r(n-1)}\)</span>，<span class="math inline">\(\frac{SSTR}{\sigma^2}
\sim \chi^2_{r-1}\)</span>。因此 <span class="math inline">\(F=\frac{MSTR}{MSE} \sim F_{r-1,r(n-1)}\)</span>
作为最终的检验统计量。</p>
<p>当 <span class="math inline">\(F^* &gt; F(1-\alpha , r-1 ,
r(n-1))\)</span> 时拒绝原假设，否则接受；<span class="math inline">\(Power = P(F^* &gt; F(1-\alpha , r-1,r(n-1))|
\delta)\)</span>，其中 <span class="math inline">\(\delta\)</span>
是一个非中心偏移量，<span class="math inline">\(\delta =
\frac{1}{\sigma} \sqrt{\frac 1 r \Sigma_i n_i (\mu_i -
\mu_.)^2}\)</span>。这里是暂时认为做的是 balanced test。</p>
<p>如果实验并不是一个 balanced test，每一组的数据量为 <span class="math inline">\(n_1,n_2,...,n_r\)</span> 且有 <span class="math inline">\(n_T = \Sigma_{i=1} ^r n_i\)</span>，于是有：</p>
<p><span class="math display">\[\mathbb E(MSTR) = \sigma^2 + n&#39;
\sigma_\mu ^2, \quad n&#39; = \frac{1}{r-1} [n_T - \frac{\Sigma_{i=1}^r
n_i ^2}{n_T}]\]</span></p>
<p>对这一模型的参数做一些估计，上文中提到 cell means model for random
effect 有三个参数 $_., ^2 $ 和 <span class="math inline">\(\sigma_\mu
^2\)</span>，事实上对于后两个参数我们也关心 <span class="math inline">\(\frac{\sigma_\mu ^2}{\sigma_\mu ^2 +
\sigma^2}\)</span> 的估计，以下还是在 balanced test
的前提下分点来阐述技术细节：</p>
<ul>
<li><p><span class="math inline">\(\mu_.\)</span> 的一个无偏估计即为
<span class="math inline">\(Y_{..} = \frac{\Sigma_{i=1}^r \Sigma_{j=1}^n
Y_{ij} }{rn}\)</span>，它的方差是 <span class="math inline">\(Var(Y_{..}) = \frac{\sigma^2}{rn} +
\frac{\sigma_\mu ^2}{r}\)</span>。</p>
<p>因此 <span class="math inline">\(s^2(\bar{Y}_{..}) =
\frac{MSTR}{rn}\)</span> 是 <span class="math inline">\(Y_{..}\)</span>
的方差的无偏估计，<span class="math inline">\(\mu_.\)</span>
的置信区间是 <span class="math inline">\(\bar{Y}_{..} \pm
t(1-\alpha/2;r-1)s(\bar{Y}_{.. } )\)</span>。</p></li>
<li><p>由于 <span class="math inline">\(\frac{MSTR/(n\sigma_\mu ^2 +
\sigma^2)}{MSE/ \sigma^2} \sim F_{r-1,r(n-1)}\)</span>，因此有：</p>
<p><span class="math display">\[L = \frac 1n [\frac{MSTR}{MSE}
(\frac{1}{F[1-\alpha/2;r-1;r(n-1)]})-1]\]</span></p>
<p><span class="math display">\[R = \frac 1n [\frac{MSTR}{MSE}
(\frac{1}{F[\alpha/2; r-1,r(n-1)]})-1]\]</span></p>
<p>此时 <span class="math inline">\(\frac{\sigma_\mu ^2}{\sigma_\mu ^2 +
\sigma^2}\)</span> 的 <span class="math inline">\(100(1-\alpha)
\%\)</span> 置信区间是 <span class="math inline">\([\frac{L}{1+L} ,
\frac{R}{1+R}]\)</span>。</p></li>
<li><p><span class="math inline">\(\sigma^2\)</span> 的无偏估计是 <span class="math inline">\(MSE = \frac{\Sigma_{i=1} ^r \Sigma_{j=1}^n (Y_{ij}
- \bar Y_{i.})}{r(n-1)}\)</span>，置信区间的估计可以建立在 <span class="math inline">\(\frac{r(n-1)MSE}{\sigma^2} \sim
\chi^2[r(n-1)]\)</span> 的基础上，于是有 <span class="math inline">\(\sigma^2\)</span> 的 <span class="math inline">\(100(1-\alpha) \%\)</span> 置信区间是 <span class="math inline">\([\frac{r(n-1)MSE}{\chi^2[1-\alpha /2; r(n-1)]},
\frac{r(n-1)MSE}{\chi^2 [\alpha/2;r(n-1)]}]\)</span></p></li>
<li><p><span class="math inline">\(\sigma_\mu^2\)</span> 的无偏估计是
<span class="math inline">\(s_\mu ^2 = \frac{MSTR -
MSE}{n}\)</span>，但有时数据点决定此处点估计值是负的，此时就用 <span class="math inline">\(0\)</span> 来代替 <span class="math inline">\(\sigma_\mu ^2\)</span> 的估计值。</p></li>
</ul>
<h3 id="random-factor-effects-model">Random factor effects model</h3>
<p>相应地可以对 cell means model for random effect 做一些改进。回顾一下
factor effects model：</p>
<blockquote>
<p>Factor Effects Model 是 Cell Means Model
的一个重新参数化的结果。模型假设是 <span class="math inline">\(Y_{ij} =
\mu + \tau_i + \varepsilon_{ij}\)</span>。</p>
<p>其中，<span class="math inline">\(\mu_i\)</span>
是整体的理论均值，<span class="math inline">\(\varepsilon _{ij}\)</span>
i.i.d. <span class="math inline">\(\sim
N(0,\sigma^2)\)</span>。它的参数比 cell mean model 多一个，分别是 <span class="math inline">\(\mu , \tau_1 , ..., \tau_r ,
\sigma^2\)</span>，但是自由度是相同的，因为 <span class="math inline">\(\{ \tau _i \}_{i=1}^r\)</span> 存在一个约束 <span class="math inline">\(\Sigma_{i=1}^r \tau_i =
0\)</span>，如果没有这个约束会导致存在多组解。</p>
</blockquote>
<p>Random factor effects model 也是 cell means model for random effects
的一个重新参数化的结果。</p>
<blockquote>
<p>模型假设是 <span class="math inline">\(Y_{ij} = \mu + \tau_i
+\varepsilon_{ij}\)</span>，其中 <span class="math inline">\(i =
1,2,...,a,j=1,2,...,n_i\)</span>。相对于 cell means model for random
effect，这里将 <span class="math inline">\(\tau_i\)</span>
都视作随机变量，满足 <span class="math inline">\(\tau_i \sim
N(0,\sigma_\tau ^2)\)</span> 不要求相互独立，<span class="math inline">\(\varepsilon_{ij}\)</span> i.i.d. <span class="math inline">\(\sim N(0,\sigma^2)\)</span>，且 <span class="math inline">\(\tau_i\)</span> 和 <span class="math inline">\(\varepsilon_{ij}\)</span>
之间是相互独立的。这一模型中也是三个参数，分别是 <span class="math inline">\(\mu_., \sigma_\mu, \sigma\)</span>，而且 <span class="math inline">\(Y_{ij}\)</span> 不相互独立。</p>
<p>由于是随机变量，自然不再要求满足 <span class="math inline">\(\Sigma_{i=1}^a \tau_i =0\)</span> 的限制。</p>
</blockquote>
<p>实际上可以看到，在 random effect 意义下，factor effects model 和 cell
means model
的关系更紧密了，只是相差一个常数。因此所有的检验和推断可以类似的进行。</p>
<h3 id="mixed-factors-effects-model">Mixed factors effects model</h3>
<p>回顾一下 two factors effects model：</p>
<blockquote>
<p>模型假设是 <span class="math inline">\(Y_{ijk} = \mu +\alpha_i +
\beta_j +(\alpha \beta)_{ij} + \varepsilon_{ijk}\)</span>。</p>
<p>其中，<span class="math inline">\(\mu\)</span> 是整体的均值，<span class="math inline">\(\alpha_i\)</span> 代表只和等级为 <span class="math inline">\(i\)</span> 的因素 <span class="math inline">\(A\)</span> 有关的变化，<span class="math inline">\(\beta_j\)</span> 表示只和等级为 <span class="math inline">\(j\)</span> 的因素 <span class="math inline">\(B\)</span> 有关的变化，<span class="math inline">\((\alpha \beta)_{ij}\)</span>
表示和两个因素同时相关的变化，相当于一个交叉项。</p>
<p>这里面有 <span class="math inline">\((a+1)(b+1)\)</span>
个参数，对其也有一定的约束：<span class="math inline">\(\Sigma_i
\alpha_i = \Sigma_j \beta_j = \Sigma_i (\alpha \beta)_{ij} = \Sigma_j
(\alpha \beta)_{ij} =0\)</span>。</p>
</blockquote>
<p>类似地，mixed factors effects model 也是把模型假设进行了一些修改，将
<span class="math inline">\(\alpha_i\)</span> 从参数改成了随机变量。注意
<span class="math inline">\(\alpha_i , \beta_j\)</span> 中只要有一个改为
random effect，其联合作用 <span class="math inline">\((\alpha
\beta)_{ij}\)</span> 也变为随机变量而非参数。</p>
<blockquote>
<p>模型假设是 <span class="math inline">\(Y_{ijk} = \mu +\alpha_i +
\beta_j +(\alpha \beta)_{ij} + \varepsilon_{ijk}\)</span>。</p>
<p>其中，<span class="math inline">\(\mu\)</span> 是整体的均值，<span class="math inline">\(\alpha_i\)</span> 代表只和等级为 <span class="math inline">\(i\)</span> 的因素 <span class="math inline">\(A\)</span> 有关的变化，<span class="math inline">\(\beta_j\)</span> 表示只和等级为 <span class="math inline">\(j\)</span> 的因素 <span class="math inline">\(B\)</span> 有关的变化，<span class="math inline">\((\alpha \beta)_{ij}\)</span>
表示和两个因素同时相关的变化，相当于一个交叉项。</p>
<p>需要满足一定的约束：</p>
<ul>
<li><span class="math inline">\(\Sigma_{i=1} ^ a \alpha _i
=0\)</span></li>
<li><span class="math inline">\(\beta_j \sim N(0,\sigma_\beta
^2)\)</span></li>
<li><span class="math inline">\((\alpha \beta)_{ij} \sim
N(0,\sigma_{\alpha \beta}^2)\)</span></li>
</ul>
</blockquote>
<p>检验方式和统计量见 ANOVA table construction 环节。</p>
<h2 id="anova-table-construction">ANOVA table construction</h2>
<p>e.g: three factors model</p>
<p><span class="math display">\[Y_{ijkl} = \mu + \alpha_i + \beta_j +
\gamma _k +(\alpha \beta)_{ij} + (\alpha \gamma)_{ik} + (\beta
\gamma)_{jk} + (\alpha \beta \gamma)_{ijk} +
\varepsilon_{ijkl}\]</span></p>
<p><span class="math display">\[i = 1,2,...,a\]</span></p>
<p><span class="math display">\[j = 1,2,...,b\]</span></p>
<p><span class="math display">\[k = 1,2,...,c\]</span></p>
<p><span class="math display">\[l = 1,2,...,n\]</span></p>
<p>其中 <span class="math inline">\(a\)</span> 是 fixed effect，而 <span class="math inline">\(b,c\)</span> 是 random effect。于是模型参数是
<span class="math inline">\(\theta = \lbrace \mu ,
\alpha_i^{i=1,2,...,a} , \sigma_\beta^2 , \sigma_\gamma ^2 ,
\sigma_{\alpha \beta}^2 , \sigma_{\beta \gamma }^2 ,
\sigma_{\alpha,\gamma}^2, \sigma_{\alpha,\beta,\gamma}^2,\sigma^2
\rbrace\)</span></p>
<p>ANOVA table construction 的过程详见 <a href="https://v1ncent19.github.io/SummaryNotes/">Statistics Note</a> by
<a href="https://v1ncent19.github.io/">V1ncent19</a>，P212-215，这里仅给出结果：</p>
<table style="width:100%;">
<colgroup>
<col style="width: 27%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 57%">
</colgroup>
<thead>
<tr class="header">
<th>Random/Fix</th>
<th>F</th>
<th>R</th>
<th>R</th>
<th>R</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td># level</td>
<td>a</td>
<td>b</td>
<td>c</td>
<td>n</td>
<td></td>
</tr>
<tr class="even">
<td>Index</td>
<td>i</td>
<td>j</td>
<td>k</td>
<td>l</td>
<td><span class="math inline">\(\mathbb E(MS)\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\alpha_i\)</span></td>
<td>0</td>
<td>b</td>
<td>c</td>
<td>n</td>
<td><span class="math inline">\(\sigma^2 + cn \sigma_{\alpha \beta}^2 +
bn \sigma_{\alpha \gamma}^2 + n \sigma_{\alpha \beta \gamma}^2 + bcn
\frac{\Sigma \alpha_i ^2}{a-1}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\beta_j\)</span></td>
<td>a</td>
<td>1</td>
<td>c</td>
<td>n</td>
<td><span class="math inline">\(\sigma^2 + an \sigma_{\beta \gamma}^2 +
acn \sigma_{\beta}^2\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\gamma_k\)</span></td>
<td>a</td>
<td>b</td>
<td>1</td>
<td>n</td>
<td><span class="math inline">\(\sigma^2 + an \sigma_{\beta \gamma}^2 +
abn \sigma_{\gamma}^2\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\((\alpha \beta)_{ij}\)</span></td>
<td>0</td>
<td>1</td>
<td>c</td>
<td>n</td>
<td><span class="math inline">\(\sigma^2 + cn \sigma_{\alpha \beta}^2 +
n \sigma_{\alpha \beta \gamma}^2\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\((\alpha \gamma)_{ik}\)</span></td>
<td>0</td>
<td>b</td>
<td>1</td>
<td>n</td>
<td><span class="math inline">\(\sigma ^2 + bn \sigma_{\alpha \gamma}^2
+ n \sigma_{\alpha \beta \gamma}^2\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\((\beta \gamma)_{jk}\)</span></td>
<td>a</td>
<td>1</td>
<td>1</td>
<td>n</td>
<td><span class="math inline">\(\sigma^2 + an\sigma_{\beta
\gamma}^2\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\((\alpha \beta
\gamma)_{ijk}\)</span></td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>n</td>
<td><span class="math inline">\(\sigma^2 + n \sigma_{\alpha \beta
\gamma}^2\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\varepsilon_{ijkl}\)</span></td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td><span class="math inline">\(\sigma^2\)</span></td>
</tr>
</tbody>
</table>
<p>于是可以利用上述期望进行检验：</p>
<ul>
<li><span class="math inline">\(H_0 : \alpha_1 = \alpha_2 =
...=\alpha_a\)</span>，检验 <span class="math inline">\(F_{\alpha_i} ^*
= \frac{MS_\alpha + MS_{\alpha ]beta \gamma}}{MS_{\alpha \beta} +
MS_{\alpha \gamma}} \sim ^{H_0} F_{(a-1)+(a-1)(b-1)(c-1),
(a-1)(b-1)+(a-1)(c-1)}\)</span></li>
<li><span class="math inline">\(H_0 : \sigma^2 =0\)</span></li>
<li><span class="math inline">\(H_0 : \sigma_{\beta}^2 =0\)</span></li>
<li>......</li>
</ul>
<h2 id="r-code-for-anova">R code for ANOVA</h2>
<p>详见 <a href="https://www.datanovia.com/en/lessons/mixed-anova-in-r/">Mixed
ANOVA in R</a>，和课上讲的是同一个东西但是更精细一点（</p>
<p>期末考前又去看我第二次作业的那个
project，绷不住了，我怎么做了个不合理的 mixed effect model
还拿了满分（</p>
<h1 id="实验设计方法">实验设计方法</h1>
<p>不如说是实验设计小知识（</p>
<p>Designed experiment 的主要目标是研究若干 explanatory factor 和
response variable 之间的因果关系。在实验中变量控制情况（也就是所谓的
treatments）和被试者的匹配之间是完全随机的，例如在试药时安慰剂和特效药是随机分发的，甚至会将实验条件对被试者保密。</p>
<h2 id="observational-experimental-study">Observational &amp;
Experimental Study</h2>
<ul>
<li><p>Observational study: The investigator use the data observed in
the population to make inference on the relationship between the
variables</p></li>
<li><p>Experimental study: The investigator intervene in the natural
history by actively alternating one of the variables and then making
inference on the relationship between the variables based on the
outcomes</p></li>
</ul>
<p>简单来说，直接研究通过观察收集来的数据就是 observational
study，数据只来自于自然的观察，收集者对事物发生不作任何干涉；experimental
study 则需要实验者自行控制变量，在所需条件下收集数据，再进行研究。</p>
<h2 id="crossed-and-nested-factors">Crossed and Nested Factors</h2>
<p>这是多因素分析中的一个概念。</p>
<ul>
<li><p>Crossed factors: all combinations of the levels of the two
factors are included in the study. e.g.</p>
<table>
<thead>
<tr class="header">
<th>Factor Combination</th>
<th>Temperature</th>
<th>Solvent Concentration</th>
<th>Outcome</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Low</td>
<td>Low</td>
<td>/</td>
</tr>
<tr class="even">
<td>2</td>
<td>Low</td>
<td>High</td>
<td>/</td>
</tr>
<tr class="odd">
<td>3</td>
<td>High</td>
<td>Low</td>
<td>/</td>
</tr>
<tr class="even">
<td>4</td>
<td>High</td>
<td>High</td>
<td>/</td>
</tr>
</tbody>
</table></li>
<li><p>Nested factors: the level of one factor are unique to a
particular level of another factor. e.g.</p>
<table>
<thead>
<tr class="header">
<th>Factor Combination</th>
<th>Temperature</th>
<th>Solvent Concentration</th>
<th>Outcome</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Low</td>
<td>Low</td>
<td>/</td>
</tr>
<tr class="even">
<td>2</td>
<td>High</td>
<td>High</td>
<td>/</td>
</tr>
</tbody>
</table></li>
</ul>
<h2 id="completely-randomized-design">Completely randomized design</h2>
<ul>
<li><p>对于一个有三个因素的 designed
experiment，建立的模型包括三个部分：</p>
<p><span class="math inline">\(Y=\)</span> overall constant + treatment
effect + experimental error</p>
<p>如果采用线性回归模型，以三个因素为例，全体被试者被分为 <span class="math inline">\(8\)</span> 组，使得</p>
<p><span class="math display">\[Y_{ij} = \beta_0 + \beta_1 X_{ij1} +
\beta_2 X_{ij2} + \beta_3 X_{ij3} + \varepsilon_{ij}\]</span></p>
<p>可以轻松地将其和上述的三个模型组成部分对应起来。其中 <span class="math inline">\(X_1,X_2,X_3\)</span> 类似于示性函数，此处是一种
categorical variable，$X_i = 1 $ if treatment <span class="math inline">\(i\)</span>，otherwise <span class="math inline">\(0\)</span>。</p>
<p>也可以用因子效应模型来考虑这个问题，表示起来会比较容易；另外要注意的是，regression
model 关心平均响应的预测，但 factor effect model
更关心平均响应的差别。</p></li>
<li><p>仍然以上一部分中的 Treatment of Lead-Exposed Children Trial
为例。</p>
<p><span class="math inline">\(100\)</span>
名被试被分成两组分别使用安慰剂和药剂，在实验开始前、实验第 <span class="math inline">\(1, 4, 6\)</span> 周分别检验了血液铅含量水平。第 i
名被试的实验开始前水平为 <span class="math inline">\(y_{i1}\)</span>，实验结束后水平为 <span class="math inline">\(y_{i2}\)</span>，变化水平为 <span class="math inline">\(d_i =
y_{i2}-y_{i1}\)</span>，希望利用这些数据观察药剂的有效程度。</p>
<p>我们在这一实验中设定三个不同的 explanatory factor，分别是 treatment
type (succimer or placebo)，children's ID (from <span class="math inline">\(1\)</span> to <span class="math inline">\(100\)</span>，用于展示个体间的差别)，time point
(week <span class="math inline">\(0,1,4,6\)</span>)。其中，treatment
type 和 time point 可能会协同作用。Outcome，也即 response variable
设定为血铅浓度 <span class="math inline">\(Y\)</span>。</p>
<p>模型为：</p>
<p><span class="math display">\[Y_{ijt} = \mu + \alpha_i + \beta_{j(i)}
+ \gamma_t + (\alpha \gamma)_{it} + \varepsilon_{ijt}\]</span></p>
<p>参数假设为：</p>
<p><span class="math display">\[\beta_{j(i)} \sim N(0,\sigma_\beta
^2)\]</span></p>
<p><span class="math display">\[\varepsilon_{ijk} \sim
N(0,\sigma^2)\]</span></p>
<p>自由度和方差分解为：</p>
<p><span class="math display">\[Y_{ijt} - Y_{...} = (\bar Y_{i..} - \bar
Y_{...}) +(\bar Y_{..t} - \bar Y_{...}) +(\bar Y_{i.t} - \bar Y_{i..} -
\bar Y_{..t} + \bar Y_{...}) + (\bar Y_{ij.} - \bar Y_{i..}) + (Y_{ijt}
- \bar Y_{ij.} - \bar Y_{i.t} + \bar Y_{i..})\]</span></p>
<p><span class="math display">\[df: Nn-1 =
(a-1)+(n-1)+(a-1)(n-1)+(N-a)+(N-a)(n-1)\]</span></p>
<p>可以提出并进行检验的问题有：</p>
<ul>
<li><p>安慰剂和药剂之间有无明显的区别？在第 <span class="math inline">\(0,1,4,6\)</span>
周时，两组之间的血铅值是否有明显差异？</p>
<p><span class="math inline">\(H_0: \mu_t(S) = \mu_t(P), \forall t=
1,2,3,4\)</span>，其中 <span class="math inline">\(\mu_t = \mu +
\gamma_t + (\alpha
\gamma)_{it}\)</span>，也即取出全体和时间有关的项。</p></li>
<li><p>也可以换一种表示方法：安慰剂和药剂是否在降低血铅方面有同等的效果？</p>
<p><span class="math inline">\(H_0 : \mu_t(S) - \mu_1 (S) = \mu_t(P) -
\mu_1(P),\forall t =2,3,4\)</span></p>
<p>可以推出这等价于 <span class="math inline">\(H_0: (\alpha
\gamma)_{it} = 0,\forall i = 1,2,
t=1,2,3,4\)</span>，这是因为参数假设中认为 <span class="math inline">\(\Sigma (\alpha \gamma)_{it}=0\)</span>。</p></li>
</ul></li>
</ul>
<h2 id="clinical-trials">Clinical Trials</h2>
<p>临床试验最准确的定义是 the evaluation of intervention (treatment) on
disease in a controlled experimental
setting（绷不住了，感觉看原文比翻译过来要靠谱的多），有不同的类型。</p>
<h3 id="randomized-clinical-trial">Randomized clinical trial</h3>
<p>RCT
的目的一般是在不存在因素的互相干扰情况下做对比，目的往往有找出最好的治疗方案，测试药剂相对于安慰剂的效果，等等。因此，实验组必须在各个方面和初始量化指标上都是一致的，在此基础上接受不同的治疗方案，才能控制变量找出方案对于效果的影响。</p>
<p>RCT
是最有力的临床试验方案，因为是对几乎相同的组别随机分配治疗方案，得到的结果是普适性的。</p>
<h3 id="non-randomized-clinical-trial">Non-randomized clinical
trial</h3>
<p>不随机的点有很多，比如被试者可以自行选择想参加实验的组，自由选择使用的是药剂还是安慰剂，或者这一分组是被实验组织者人为设定而不是随机分配的。</p>
<h2 id="contingency-table-in-clinical-trials">Contingency Table in
Clinical Trials</h2>
<p>Clinical trial 里面也会用到一些 contingency table
和相应的检验。在这里先给出我们关注的问题和一些相应的定义。</p>
<p>此处我们主要关心的情境是，两组被试者分别使用 medicine 和
placebo，可能会出现 adverse reaction
也可能不会出现，统计全体被试者的反应得到以下表格：</p>
<table>
<colgroup>
<col style="width: 20%">
<col style="width: 30%">
<col style="width: 37%">
<col style="width: 11%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Adverse Reaction (<span class="math inline">\(D\)</span>)</th>
<th>No Adverse Reaction (<span class="math inline">\(D^C\)</span>)</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Medicine (<span class="math inline">\(E\)</span>)</td>
<td><span class="math inline">\(n_{11}\)</span></td>
<td><span class="math inline">\(n_{12}\)</span></td>
<td><span class="math inline">\(n_{1+}\)</span></td>
</tr>
<tr class="even">
<td>Placebo (<span class="math inline">\(E^C\)</span>)</td>
<td><span class="math inline">\(n_{21}\)</span></td>
<td><span class="math inline">\(n_{22}\)</span></td>
<td><span class="math inline">\(n_{2+}\)</span></td>
</tr>
<tr class="odd">
<td>Total</td>
<td><span class="math inline">\(n_{+1}\)</span></td>
<td><span class="math inline">\(n_{+2}\)</span></td>
<td><span class="math inline">\(n_{++}\)</span></td>
</tr>
</tbody>
</table>
<p>相应地定义 <span class="math inline">\(p_1\)</span> 是 medicine
组发生不良反应的概率，<span class="math inline">\(p_2\)</span> 是
placebo 组发生不良反应的概率。于是有：</p>
<p><span class="math display">\[p_1 = \mathbb P(D | E) , p_2 = \mathbb
P(D |E^C)\]</span></p>
<p><span class="math display">\[\text{Risk Difference} = \Delta = p_1 -
p_2\]</span></p>
<p><span class="math display">\[\text{Relative Risk} = \phi =
\frac{p_1}{p_2}\]</span></p>
<p><span class="math display">\[\text{Odds Ratio} = \theta = \frac{p_1 /
(1-p_1)}{p_2 / (1-p_2)}\]</span></p>
<p>在这样的情境下我们希望做的检验即为 <span class="math inline">\(H_0 :
p_1 = p_2\)</span>，也即观察 medicine 相对 placebo
来说是否发生不良反应的可能性是相同的。事实上由于上述条件概率的定义，也就是希望检验
adverse reaction 和 medicine/placebo 的选择是独立的。这就归结为了
contingency table 的 independence inference，详见下一部分的 Pearson Test
和 Likelihood Ratio Test。</p>
<p>另外，我们希望使用观察到的数据 <span class="math inline">\(n_{ij}\)</span>
对上述参数做一些估计。但具体的估计与 clinical trial
的类型有关，此处分别考虑两种类型的 clinical trial，分别是 prospective
clinical trial 和 retrospective clinical trial。</p>
<p>虽然 contingency table 从理论上来说对于随机变量 <span class="math inline">\(Y,Z\)</span>
是完全对称的，但是在实验设计中我们需要先确定 <span class="math inline">\(Y\)</span> 或者 <span class="math inline">\(Z\)</span>，进行优先级的选择后再收集数据。这可能会导致条件概率不同。</p>
<h3 id="prospective-clinical-trial">Prospective clinical trial</h3>
<p>招募了许多患有某一疾病的被试者进行试药，<span class="math inline">\(Y
= E / E^C\)</span> 是 medicine 或者 placebo
组在实验开始之前就对全体被试者划分好了，于是 <span class="math inline">\(Z = D / D^C\)</span>
是是否出现不良反应的量度，是我们在实验中需要关注的。</p>
<p>在这一实验中由于是预先招募了被试者，所以 <span class="math inline">\(n_{1+},n_{2+},n_{++}\)</span> 是确定的数值。</p>
<p>Prospective clinical trial
显然更可控一些，但是也会遇到一些生存分析的问题。另外，如果是关于罕见病的实验，这一方式可能会比较低效。</p>
<p>此时有参数估计：</p>
<p><span class="math display">\[\hat p_1 = \frac{n_{11}}{n_{1+}}, \hat
p_2 = \frac{n_{21}}{n_{2+}}\]</span></p>
<p><span class="math display">\[\hat \phi = \frac{n_{11}/
n_{1+}}{n_{21}/ n_{2+}}\]</span></p>
<p><span class="math display">\[\hat \theta =
\frac{n_{11}n_{22}}{n_{21}n_{12}}\]</span></p>
<p><span class="math display">\[\hat{Var} ( \log \hat \theta) =
\frac{1}{n_{11}} + \frac{1}{n_{12}} + \frac{1}{n_{21}} +
\frac{1}{n_{22}}\]</span></p>
<p>注意一些参数含义：<span class="math inline">\(\phi\)</span> 和 <span class="math inline">\(\theta\)</span>
都表示了组间差距，如果这两个参数比较大就说明 <span class="math inline">\(Y\)</span> 对 <span class="math inline">\(Z\)</span> 和 <span class="math inline">\(Z^C\)</span> 的影响不同。</p>
<h3 id="retrospective-clinical-trial">Retrospective clinical trial</h3>
<p>招募了许多产生了不良反应和未产生不良反应的患者，<span class="math inline">\(Z = D/D^C\)</span>
是是否有不良反应的组在实验开始之前就对被试者划分好了。再对他们发放问卷或者进行采访，了解出现不良反应之前的用药历史。</p>
<p>在这一实验中对被试者进行的划分是关于 <span class="math inline">\(Z\)</span> 的，因此 <span class="math inline">\(n_{+1},n_{+2},n_{++}\)</span> 是确定的数值。</p>
<p>Retrospective clinical trial 显然是没有那么精准的，我们难以精准控制
<span class="math inline">\(Y\)</span>，但是数据的收集更快更方便。</p>
<p>此时有参数估计：</p>
<p><span class="math display">\[\hat p_1 = \frac{\rho
\frac{n_{11}}{n_{+1}}}{\rho \frac{n_{11}}{n_{+1}}+(1-\rho)
\frac{n_{12}}{n_{+2}}},\hat p_2 = \frac{\rho \frac{n_{21}}{n_{+1}}}{\rho
\frac{n_{21}}{n_{+1}}+(1-\rho) \frac{n_{22}}{n_{+2}}}  \]</span></p>
<p>其中 <span class="math inline">\(\rho\)</span> 是人群中的发病率。</p>
<p><span class="math display">\[\hat \phi = \frac{\hat p_1}{\hat
p_2}\]</span></p>
<p><span class="math display">\[\hat \theta =
\frac{n_{11}n_{22}}{n_{21}n_{12}}\]</span></p>
<p><span class="math display">\[\hat{Var} ( \log \hat \theta) =
\frac{1}{n_{11}} + \frac{1}{n_{12}} + \frac{1}{n_{21}} +
\frac{1}{n_{22}}\]</span></p>
<p>可以发现 odds ratio 在两种 clinical trial
里是一致的，因此这一参数更佳。</p>
<h2 id="gehans-two-stage-design">Gehan's Two-Stage Design</h2>
<p>如果某一实验看起来完全达不到我们的最低期望，那我们希望能够尽早在临床试验的早期抛弃这一选择。比如说，对于
<span class="math inline">\(n\)</span>
位患者，我们能够接受的最低治疗成功率是 <span class="math inline">\(20\%\)</span>，那么在治疗有效的患者数小于 <span class="math inline">\(m\)</span>
时就可以认为这一治疗方案是无效的，然后尽早放弃继续的探索。Gehan's
two-stage design 展示了选取 <span class="math inline">\(m\)</span>
的方式。</p>
<p>实际上这个过程类似于寻找算法的终止条件。在最初的状态下选择 <span class="math inline">\(n_0\)</span>
名患者参与治疗，如果这些人里面没有治疗有效的，那么直接停止这一实验过程；否则继续做实验，并且每次加入新的被试者，希望能够达到期望的最低治疗成功率。</p>
<p>比如说，我们认为当有 <span class="math inline">\(\pi _0 =
20\%\)</span>
的患者症状缓解时，可以认为这一治疗方案是有效的，这也就是可以接受的最低治疗成功率。在
Gehan's two-stage design 里设定 level 是 <span class="math inline">\(\alpha_0 = 5
\%\)</span>，在此基础下考虑第一次实验的被试数量 <span class="math inline">\(n_0\)</span> 的取值。</p>
<p>事实上治疗有效果的患者数是一个服从伯努利分布的随机变量 <span class="math inline">\(X \sim B(\pi)\)</span>，那么 <span class="math inline">\(P(X_0 = 0) = (1-\pi)^{n_0}\leq \alpha_0\)</span>
对于任意的 <span class="math inline">\(\pi \geq \pi_0\)</span>
是成立的，那么 <span class="math inline">\(n_0 \geq \frac{\log
(0.05)}{\log (1-0.20)}=14\)</span> 即为第一次实验的最少被试数量。</p>
<p>也可以通过置信区间的方法来确定。我们希望能够有 <span class="math inline">\(95 \%\)</span>
的信度认为这一实验可以继续下去，允许 <span class="math inline">\(\pi_0\)</span> 有 <span class="math inline">\(\pm
15 \%\)</span> 的浮动，则最少的被试参与数满足 <span class="math inline">\(1.96(\frac{(1-\pi_0)\pi_0}{n})^{\frac 1 2} =
0.15\)</span>，解得 <span class="math inline">\(n=28\)</span>。</p>
<h1 id="inference-on-contingency-table">Inference on Contingency
Table</h1>
<p>简单来说，孟德尔种豌豆那个表格就是一个 contingency
table，到底为什么呈现出 <span class="math inline">\(9:3:3:1\)</span>
的规律也可以用 goodness of fit test 进行检验。Contingency table analysis
本质上是对 categorical data 的检验。</p>
<h2 id="motivation-example">Motivation Example</h2>
<p>我们希望知道吸烟和肺癌之间有无确切的联系，采集了一些数据：吸烟且肺癌的有
<span class="math inline">\(688\)</span> 人，吸烟但没有得肺癌的有 <span class="math inline">\(650\)</span> 人；不吸烟且肺癌的有 <span class="math inline">\(21\)</span> 人，不吸烟且没有得肺癌的有 <span class="math inline">\(59\)</span> 人。样本量共计 <span class="math inline">\(1418\)</span> 人，列表如下：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Lung Cancer</th>
<th>Healthy</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Smoke</td>
<td>688</td>
<td>650</td>
<td>1338</td>
</tr>
<tr class="even">
<td>Not Smoke</td>
<td>21</td>
<td>59</td>
<td>80</td>
</tr>
<tr class="odd">
<td>Total</td>
<td>709</td>
<td>709</td>
<td>1418</td>
</tr>
</tbody>
</table>
<p>“看起来”吸烟和肺癌是有关系的，因为吸烟者得肺癌的频率看似更高。但是如何从频率得到概率，仍然需要一些检验的逻辑。</p>
<h2 id="contingency-table">Contingency Table</h2>
<p>抽象出来的 contingency table 的逻辑是这样的：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(Z=1\)</span></th>
<th><span class="math inline">\(Z=2\)</span></th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(Y=1\)</span></td>
<td><span class="math inline">\(n_{11}\)</span></td>
<td><span class="math inline">\(n_{12}\)</span></td>
<td><span class="math inline">\(n_{1+}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(Y=2\)</span></td>
<td><span class="math inline">\(n_{21}\)</span></td>
<td><span class="math inline">\(n_{22}\)</span></td>
<td><span class="math inline">\(n_{2+}\)</span></td>
</tr>
<tr class="odd">
<td>Total</td>
<td><span class="math inline">\(n_{+1}\)</span></td>
<td><span class="math inline">\(n_{+2}\)</span></td>
<td><span class="math inline">\(n_{++}\)</span></td>
</tr>
</tbody>
</table>
<p>当然，<span class="math inline">\(Y\)</span> 和 <span class="math inline">\(Z\)</span>
都可以有更多的指标，这不影响我们的构造。比如说它可以长成下面这种通用的形式：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>1</th>
<th>...</th>
<th>J</th>
<th>total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\(n_{11}\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_{1J}\)</span></td>
<td><span class="math inline">\(n_{1+}\)</span></td>
</tr>
<tr class="even">
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td>I</td>
<td><span class="math inline">\(n_{I1}\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_{IJ}\)</span></td>
<td><span class="math inline">\(n_{I+}\)</span></td>
</tr>
<tr class="even">
<td>total</td>
<td><span class="math inline">\(n_{+1}\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_{+J}\)</span></td>
<td><span class="math inline">\(n_{++}\)</span></td>
</tr>
</tbody>
</table>
<p>与此同时，<span class="math inline">\(Y\)</span> 和 <span class="math inline">\(Z\)</span>
的位置是完全对称的，可以交换二者在行和列里的顺序。</p>
<p>在 <span class="math inline">\(n_{++},n_{1+},n_{2+},n_{+1},n_{+2}\)</span>
都已知的情况下，完全可以把 <span class="math inline">\(n_{11}\)</span>
视作一个随机变量，当然表格中的 <span class="math inline">\(n_{ij}\)</span>
都可以被视为随机变量，但四者中有其一被确定后整个表格就完全被确定，因此只需要讨论
<span class="math inline">\(n_{11}\)</span> 的数值。</p>
<p>事实上，<span class="math inline">\(n_{11}\)</span>
服从的是超几何分布。<span class="math inline">\(P(n_{11} = k) =
\frac{C_{n_{1+}}^k C_{n_{2+}}^{n_{+1}-k}}{C_{n_{++}}^{n_{+1}}}\)</span>
对于 <span class="math inline">\(\max(0,n_{1+} + n_{+1}-n) \leq k \leq
\min(n_{1+},n_{+1})\)</span> 都成立。</p>
<h2 id="p-value-calculation-example-女士品茶">P-value Calculation
Example: 女士品茶</h2>
<p>对于一个如下所示的表格，希望判断品茶的女士是否真的有品尝先加奶还是先加茶的能力——尽管看起来是有的，<span class="math inline">\(4\)</span>
次尝试里她只失误了一次，但是我们希望通过一些更严谨的推断方法来证明。</p>
<table>
<thead>
<tr class="header">
<th>Actually poured first</th>
<th></th>
<th>Lady says poured first</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>tea</td>
<td>milk</td>
</tr>
<tr class="even">
<td>tea</td>
<td>3</td>
<td>1</td>
</tr>
<tr class="odd">
<td>milk</td>
<td>1</td>
<td>3</td>
</tr>
</tbody>
</table>
<p>由于 <span class="math inline">\(P(n_{11} = 3) = \frac{C_4 ^3 C_4
^1}{C_8 ^4} = \frac{16}{70}\)</span>，<span class="math inline">\(P(n_{11}=4) = \frac{C_4 ^4 C_4 ^0}{C_8 ^4} =
\frac{1}{70}\)</span>，回顾 p-value
的定义是“比所得数据更加极端的情形所出现的概率”，事实上也就是 <span class="math inline">\(P(n_{11} \geq 3) = \frac{16}{70} + \frac{1}{70} =
\frac{17}{70} =
0.243\)</span>，无法给出充足的证据证明这位女士能够品出添加的顺序。</p>
<h2 id="inference-on-independence">Inference on Independence</h2>
<p>Contingency table 的通用形式如下所示：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>1</th>
<th>...</th>
<th>J</th>
<th>total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\(n_{11}\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_{1J}\)</span></td>
<td><span class="math inline">\(n_{1+}\)</span></td>
</tr>
<tr class="even">
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td>I</td>
<td><span class="math inline">\(n_{I1}\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_{IJ}\)</span></td>
<td><span class="math inline">\(n_{I+}\)</span></td>
</tr>
<tr class="even">
<td>total</td>
<td><span class="math inline">\(n_{+1}\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_{+J}\)</span></td>
<td><span class="math inline">\(n_{++}\)</span></td>
</tr>
</tbody>
</table>
<p>另一个检验的重点在于 <span class="math inline">\(Y\)</span> 和 <span class="math inline">\(Z\)</span> 联合作用于 <span class="math inline">\(\{ n_{ij} \}\)</span>
的取值时，我们希望了解二者的作用是否独立。</p>
<p>如果二者的作用独立，就有 <span class="math inline">\(\pi_{ij} =
P(Y=i,Z=j) = P(Y=i)P(Z=j) = \pi_{i+}
\pi_{+j}\)</span>。因此我们只要检查实际的 contingency table
和理想中符合二者独立时的 contingency table 有何区别，此处用到 Goodness
of Fit Test。</p>
<h3 id="hypothesis">Hypothesis</h3>
<p><span class="math inline">\(H_0:\)</span> The independence model is
true, i.e. <span class="math inline">\(\pi_{ij}= \pi_{i+}
\pi_{+j}\)</span> for all pairs of <span class="math inline">\((i,j)\)</span>.</p>
<p><span class="math inline">\(H_1 :\)</span> The saturated model is
true, i.e. <span class="math inline">\(\pi_{ij}\neq \pi_{i+}
\pi_{+j}\)</span> for at least one pair of <span class="math inline">\((i,j)\)</span>.</p>
<h3 id="test-statistic">Test Statistic</h3>
<ul>
<li><p>The standard Pearson Chi-Square statistic:</p>
<p><span class="math display">\[X^2 = \Sigma_i \Sigma_j \frac{(O_{ij} -
E_{ij})^2}{E_{ij}} \sim ^{approx} \chi^2 _{(I-1)(J-1)}\]</span></p></li>
<li><p>Likelihood Ratio Test statistic:</p>
<p>$G^2 = -2 () = 2 <em>i <em>j O</em>{ij} {E</em>{ij} } ^{approx} ^2
_{(I-1)(J-1)} $</p></li>
</ul>
<p>注意 <span class="math inline">\(X^2\)</span> 和 <span class="math inline">\(G^2\)</span>
的分布都是近似分布，二者并不是等价的检验统计量，计算值时常不同，但检验结果往往是类似的。</p>
<h1 id="survival-analysis">Survival Analysis</h1>
<h2 id="basic-concepts">Basic Concepts</h2>
<p>首先要明确一些概念，给我的感觉是像黑话一样（</p>
<h3 id="concept">Concept</h3>
<p>Event
是指生存分析所研究的事件，大多数情况下是指某种治疗过程中患者死亡这样的事件发生，但其实生存分析的应用很广泛，甚至不只是在生医领域都有这些概念的使用。患者治疗后恢复/犯人被释放后再次犯罪/确诊新冠都可以作为研究所感兴趣的事件，这些事件发生就称为
event。</p>
<p>At risk 是指尚未发生 event 的个体。事实上大多数情况下研究的 event
都是患者去世之类的负面事件，因此尚未发生 event
的个体会被先入为主地定义成 at risk，即为暴露在即将发生 event
的风险下。<del>什么达摩克斯之剑</del></p>
<h3 id="function">Function</h3>
<p>一些常用的函数：</p>
<ul>
<li>survival function：<span class="math inline">\(S(t) = P(T &gt; t) =
1-P(T \leq t) = 1-F(t)\)</span></li>
<li>mean survival time：<span class="math inline">\(E(T) = \int_{0}
^{\infty} 1-F(t) dt = \int_{0} ^{\infty} S(t ) dt\)</span></li>
<li>hazard function：<span class="math inline">\(\lambda (t) = \lim_{t
\downarrow 0} \frac{P(t \leq T &lt; t+\Delta t | T \geq t)}{\Delta t} =
\frac{f(t)}{S(t)} = \frac{-S&#39;(t)}{S(t)} = -\frac{d}{dt} \log
S(t)\)</span></li>
<li>cumulative hazard function：<span class="math inline">\(\Lambda (t)
= \int_0 ^{t} \lambda(s) ds = - \log S(t)\)</span></li>
</ul>
<p>事实上都是对 <span class="math inline">\(T\)</span> 的分布函数 <span class="math inline">\(F(t)\)</span> 的变形。</p>
<h3 id="data">Data</h3>
<p>生存分析中有两种不同的数据，censored data 和 uncensored data。</p>
<p>Censored data 是指在研究过程中未能记录到 event 发生（未能记录到
failure）的数据，往往是因为直到研究结束 event
都尚未发生，或者研究对象中途退出研究，也可能是没有及时发现跟进从而未能记录准确的时间，等等。Censored
data 又分为三种情况，right-censored，left-censored 和 interval-censored
的情况。</p>
<ul>
<li>right-censored data 往往是生存期比所记录的时间要长的情况，censor
time 在 event time 之前。例如临床试验持续了一段时间，将 event
设定为观察到患者死亡。某一位患者在第一周加入试验，试验持续十周结束，他直到试验结束都保持健康，没有发生
event，则他的生存期是 10+ weeks，这是一个 right-censored data。</li>
<li>left-censored data 的一个例子是认为 event
是感染新冠，一位患者在试验第七天发现抗原阳性，但在这之前没有做过检测，不清楚是从什么时候开始感染新冠的，只知道
censor time 在 event time 之后。因此这是一个 left-censored data。</li>
<li>interval-censored data 的一个例子仍然是认为 event
是感染新冠，一位患者在试验第三天抗原阴性，第七天发现抗原阳性，但在这两次检测之间没有做过检测，也还是不清楚从什么时候开始感染新冠，只知道
event time 在两个 censor time 之间。称为一个 interval-censored
data。</li>
</ul>
<p>此处简化情况，只研究 right-censored data，尝试对它进行标记。记
survival time 为 <span class="math inline">\(T\)</span>，censor time 为
<span class="math inline">\(C\)</span>，记 right-censored data 为 <span class="math inline">\((X,\delta)\)</span>，其中 <span class="math inline">\(X = \min(T,C)\)</span>。<span class="math inline">\(\delta\)</span> 是一个示性变量，如果 <span class="math inline">\(X = C\)</span> 则 <span class="math inline">\(\delta=0\)</span>，也就是 event 未发生；否则 <span class="math inline">\(\delta=1\)</span>，<span class="math inline">\(X =
T\)</span>，也就是观察到了 event 发生。</p>
<p>每一组数据贡献的 likelihood 是 <span class="math inline">\(\lambda
(x)^\delta S(x)\)</span>，整体的 likelihood function 即为 $ L = _{i=1}
^n (x_i )^{_i} S(x_i)$。</p>
<h2 id="kaplan-meier-estimation">Kaplan &amp; Meier Estimation</h2>
<h3 id="theory">Theory</h3>
<p>一个估计 survival function 的方法。原理上来说是把 <span class="math inline">\(S(t) = P(T &gt;t)\)</span>
分解成了一列条件概率的积：</p>
<p><span class="math display">\[S(t) = P(T&gt;t) = P(T&gt;t_1) P(T&gt;t
| T&gt;t_1) = P(T&gt;t_1) \{\Pi_{j=2} ^k P(T&gt;t_j | T&gt;t_{j-1}) \}
P(T&gt;t|T&gt;t_k)\]</span></p>
<p>与此同时重新组织数据，计算每个时刻的 items at risk 和 count of
events，列表如下：</p>
<table>
<thead>
<tr class="header">
<th>Distinct Event Times</th>
<th><span class="math inline">\(t_0\)</span></th>
<th><span class="math inline">\(t_1\)</span></th>
<th>...</th>
<th><span class="math inline">\(t_k\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td># of events at <span class="math inline">\(t_j\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(d_1\)</span></td>
<td>...</td>
<td><span class="math inline">\(d_k\)</span></td>
</tr>
<tr class="even">
<td># at risk at <span class="math inline">\(t_j\)</span></td>
<td><span class="math inline">\(n\)</span></td>
<td><span class="math inline">\(n_1\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_k\)</span></td>
</tr>
</tbody>
</table>
<p>此时认为条件概率的估计量为 <span class="math inline">\(\hat P (T&gt;
t_j | T&gt; t_{j-1}) = \frac{n_j - d_j}{n_j}\)</span>，因此 survival
function 的估计是：</p>
<p><span class="math display">\[\hat S(t) = \Pi_{j=1}^k \frac{n_j -
d_j}{n_j} = \Pi_{j=1} ^n (1- \frac{d_j}{n_j})\]</span></p>
<h3 id="example">Example</h3>
<p>对于一组生存数据：<span class="math inline">\(4 \quad 5+ \quad 6
\quad 10+ \quad 6 \quad 2 \quad 6\)</span></p>
<p>重新排序得到：<span class="math inline">\(2 \quad 4 \quad 5+ \quad 6
\quad 6 \quad 6 \quad 10+\)</span></p>
<p>按照 event time 重新组织数据，并计算 Kaplan-Meier Estimator：</p>
<table>
<colgroup>
<col style="width: 31%">
<col style="width: 6%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="header">
<th>Distinct Event Times</th>
<th>0</th>
<th>2</th>
<th>4</th>
<th>6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td># of events at <span class="math inline">\(t_j\)</span></td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>3</td>
</tr>
<tr class="even">
<td># at risk at <span class="math inline">\(t_j\)</span></td>
<td>7</td>
<td>7</td>
<td>6</td>
<td>4</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\hat S(t)\)</span></td>
<td>1</td>
<td><span class="math inline">\(\frac{6}{7}\)</span></td>
<td><span class="math inline">\(\frac{5}{7}\)</span></td>
<td><span class="math inline">\(\frac{5}{28}\)</span></td>
</tr>
</tbody>
</table>
<h2 id="cox-proportional-hazard-model">Cox Proportional Hazard
Model</h2>
<h3 id="theory-1">Theory</h3>
<p>在生存分析中数据往往是 skewed
的情况，希望分析变量（比如，患者的年龄，所用的药物，实验组别）对于生存期的影响时，一般对
hazard function 采用 <span class="math inline">\(\lambda(t) = \lambda_0
(t) e^{X^T\beta}\)</span> 模型，类似于一个 transformed linear
regression。</p>
<p>其中，<span class="math inline">\(\lambda_0(t)\)</span>
作为一个调整参数，只和时间有关，和 explanatory variable <span class="math inline">\(X\)</span> 无关。</p>
<p>以一元的 explanatory variable <span class="math inline">\(X\)</span>
为例，不同数据之间的 hazard ratio 是：</p>
<p><span class="math display">\[\frac{\lambda_i(t)}{\lambda_j (t)} =
\frac{\lambda_0(t)}{\lambda_0(t)} \frac{exp(\beta_0 + \beta_1
X_i)}{exp(\beta_0 + \beta_1 X_j)} = e^{(X_i - X_j)\beta_1}\]</span></p>
<p>模型假设是 <span class="math inline">\((T_i ,C_i)\)</span> 在 <span class="math inline">\(X_i\)</span>
给定的条件下是条件独立的，这是一个针对 censored data 的假设。</p>
<p>另外一个结论是在时间 <span class="math inline">\(t\)</span>
处，uncensored 对象 <span class="math inline">\(i\)</span> 发生 event
的概率是 <span class="math inline">\(P_i(t) = \frac{ exp(x_i
\beta)}{\Sigma_j I(T_j \geq t) exp(x_j
\beta)}\)</span>。由此可知，用于估计 <span class="math inline">\(\beta\)</span> 的 likelihood function 是：</p>
<p><span class="math display">\[L(\beta) = \Pi_{j=1}^ k \frac{ exp(x_i
\beta)}{\Sigma_j I(T_j \geq t) exp(x_j \beta)}  = \Pi_{j=1} ^n (\frac{
exp(x_i \beta)}{\Sigma_j I(T_j \geq t) exp(x_j \beta)})^{\delta
_i}\]</span></p>
<p>仍然是以一元的 explanatory variable <span class="math inline">\(X\)</span> 为例，hazard ratio 是 <span class="math inline">\(HR = \frac{\lambda(t |
\text{exposure})}{\lambda(t| \text{not exposure})} = \frac{\lambda_0 (t)
exp(\beta_1)}{\lambda_0(t)} = exp(\beta_1)\)</span></p>
<h3 id="example-1">Example</h3>
<p>分别有五位患者参与两种试药，生存数据如下所示，希望通过 Cox Model
来比较不同种类的药物效果。</p>
<p>Drug A: <span class="math inline">\(8+ \quad 132 \quad 52 \quad 220
\quad 75+\)</span></p>
<p>Drug B: <span class="math inline">\(45 \quad 80 \quad 90+ \quad 20 +
\quad 120\)</span></p>
<p>此处的唯一一个 explanatory variable 即为用药种类，认为 <span class="math inline">\(X_i = \begin{cases} 1 \quad \text{i use drug A}\\
0 \quad \text{i use drug B} \end{cases}\)</span>；</p>
<p>对数据重新排序，得到：<span class="math inline">\(8+ \quad 20+ \quad
45 \quad 52 \quad 75+ \quad 80 \quad 90+ \quad 120 \quad 132 \quad
220\)</span>，对应的 <span class="math inline">\(X_i\)</span> 是 <span class="math inline">\(1,0,0,1,1,0,0,0,1,1\)</span>。</p>
<p>Cox model 设定为 <span class="math inline">\(\lambda_i (t) =
\lambda_0 (t) e^{X ^T\beta} = \lambda_0 (t) \exp(\beta_0 +\beta_1
X_i)\)</span>，<span class="math inline">\(i=1,2,...,10\)</span>。</p>
<p>此时的 partial likelihood function 是 <span class="math inline">\(PL(\beta) = \Pi_{i=1}^n (\frac{\exp(\beta^T
X_i)}{\Sigma_{j: t_j \geq t_i} \exp(\beta^T
X_j)})\)</span>，代入数据有：</p>
<p><span class="math display">\[PL(\beta) = \Pi_{i=1}^{10}
\frac{\exp(\beta_0 + \beta_1 X_i)}{\Sigma_{j: t_j \geq t_i} \exp(\beta_0
+ \beta_1 X_i)} = \frac{exp(2\beta_1)}{360(1+\exp (\beta_1))^3
(5+4\exp(\beta_1)) (3+4\exp(\beta_1)) (2+3\exp(\beta_1))
(1+3\exp(\beta_1))}\]</span></p>
<p>对其进行 maximum likelihood 处理即可得到 <span class="math inline">\(\beta_1\)</span> 的估计值。至于 <span class="math inline">\(\beta_0\)</span>
的估计其实没什么意义，上下直接消掉了。</p>
<h3 id="why-cox-model">Why Cox Model</h3>
<ul>
<li>体现了 explanatory variable 带来的影响</li>
<li>baseline hazard <span class="math inline">\(\lambda_0 (t)\)</span>
事实上并不重要，一般也用不到</li>
<li>得到 proportional hazard function
就可以作图比较是否有一个时间点处发生明显的差异</li>
<li>单独对不同组别的 event 发生情况使用 p-value
（见下一部分）并不够，需要精确到每个个体的生存时间</li>
</ul>
<h2 id="comparison-of-survival-curves">Comparison of Survival
Curves</h2>
<h3 id="log-rank-test">Log Rank Test</h3>
<p>想要比较两组数据的生存期情况，比如说，试药组和安慰剂组之间有无生存周期上的差别，来判断药物是否有效或者有副作用。这里涉及到的问题都属于比较简单的情况，一般用一个
log rank test 就可以了。</p>
<table>
<colgroup>
<col style="width: 20%">
<col style="width: 30%">
<col style="width: 12%">
<col style="width: 6%">
<col style="width: 12%">
<col style="width: 6%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Distinct Event Times</th>
<th><span class="math inline">\(t_1\)</span></th>
<th>...</th>
<th><span class="math inline">\(t_i\)</span></th>
<th>...</th>
<th><span class="math inline">\(t_k\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Pooled sample</td>
<td># of Events</td>
<td><span class="math inline">\(d_1\)</span></td>
<td>...</td>
<td><span class="math inline">\(d_i\)</span></td>
<td>...</td>
<td><span class="math inline">\(d_k\)</span></td>
</tr>
<tr class="even">
<td></td>
<td># at Risk at <span class="math inline">\(t_i\)</span></td>
<td><span class="math inline">\(n_1\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_i\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_k\)</span></td>
</tr>
<tr class="odd">
<td>Sample 1</td>
<td># of Events</td>
<td><span class="math inline">\(d_{11}\)</span></td>
<td>...</td>
<td><span class="math inline">\(d_{1i}\)</span></td>
<td>...</td>
<td><span class="math inline">\(d_{1k}\)</span></td>
</tr>
<tr class="even">
<td></td>
<td># at Risk at <span class="math inline">\(t_i\)</span></td>
<td><span class="math inline">\(n_{11}\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_{1i}\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_{1k}\)</span></td>
</tr>
<tr class="odd">
<td>Sample 2</td>
<td># of Events</td>
<td><span class="math inline">\(d_{21}\)</span></td>
<td>...</td>
<td><span class="math inline">\(d_{2i}\)</span></td>
<td>...</td>
<td><span class="math inline">\(d_{2k}\)</span></td>
</tr>
<tr class="even">
<td></td>
<td># at Risk at <span class="math inline">\(t_i\)</span></td>
<td><span class="math inline">\(n_{21}\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_{2i}\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_{2k}\)</span></td>
</tr>
</tbody>
</table>
<p>有以下的近似分布关系，对近似正态分布做检验即可：</p>
<p><span class="math display">\[ U = \Sigma_{i=1} ^k (d_{1i} - \frac{d_i
n_{1i}}{n_i})\]</span></p>
<p><span class="math display">\[\hat{Var} (U) = \Sigma_{i=1} ^k
(\frac{d_i n_{1i} (n_i - d_i)(n_i - n_{1i})}{n_i ^2 (n_i
-1)})\]</span></p>
<p><span class="math display">\[\frac{U}{\hat{Var} (U)^{\frac 1 2}} \sim
^{H_0,asy} N(0,1)\]</span></p>
<h3 id="p-value-mode">P-value mode</h3>
<p>对于组织成 contingency table 形式的数据，按照逻辑回归部分的 p-value
方法检验即可。一个数据的例子如下所示：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Drug A</th>
<th>Drug B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Alive</td>
<td>10</td>
<td>16</td>
</tr>
<tr class="even">
<td>Dead</td>
<td>8</td>
<td>4</td>
</tr>
</tbody>
</table>
<h1 id="完结撒花">完结撒花</h1>
<p>在这之后讲的东西都不考了，我不想做生统，也不是很感兴趣，不想写了。说到底高中的时候连生物都没选考，怎么会想到来尝试生统概论的（。希望大作业没事。</p>
<p>昨天才在路上遇到了 wty
老师和她男朋友/爱人，<del>相比之下（草）</del>她好娇小好可爱，呜呜呜（<del>虽然感觉她也瞟了我好几眼，不会也认识我吧，不会是这个发型太有辨识度了我又每次都苟在最后一排就被记住了吧（</del></p>
<p>传统艺能一下（不会现在还有人是 FGO 厨吧，不会吧不会吧（</p>
<p><img src="https://s2.loli.net/2022/12/21/6TEM1vSosXLcwOg.jpg" alt="HEA.jpg"></p>
<p>后记：莫名其妙拿了个
A，实际上期末考大寄特寄好几问没做完，我还在想这课能不挂就挺好的了，不知道是老师太善良还是毕业班同学太多帮忙抬上来的（（<del>只不过之前看
V1ncent19 说他这课是 A+，羡慕（x</del></p>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>统计</tag>
        <tag>课程实录</tag>
      </tags>
  </entry>
  <entry>
    <title>年轻人的第一门 optimization 是茶园课</title>
    <url>/2023/09/25/Introduction-to-Optimization-Theory/</url>
    <content><![CDATA[<p>我自己一个人能完成一个学期的 scribing，<del>所以能不能多给点
bonus</del>（确信</p>
<p>茶园老师和教务手都太快了，俩小时速通特殊原因选课，下次还来。</p>
<span id="more"></span>
<h1 id="lecture-1">Lecture 1</h1>
<p>打开 Introduction to Linear Optimization，看到第一章标题是 linear
programming，差点 PTSD 到当场退课（</p>
<p>实际上就是线性规划，和（我害怕的那个）programming 没什么关系（</p>
<h2 id="standardized-linear-programming">Standardized Linear
Programming</h2>
<h3 id="reduce-to-standardized-format">Reduce to Standardized
Format</h3>
<ul>
<li><p>线性优化众所周知应该是线性的（草），最朴素的想法下它可以转换为以下形式：</p>
<p><span class="math display">\[\text{minimize} \quad c^Tx\]</span></p>
<p><span class="math display">\[\text{subject to} \quad \begin{aligned}
&amp; a_i^Tx \geq b_i \quad i \in M_1 \\ &amp; a_i^Tx \leq b_i \quad i
\in M_2 \\ &amp; a_i^Tx = b_i \quad i \in M_3 \\ &amp; x_j \geq 0 \quad
\quad j \in N_1 \\ &amp; x_j \leq 0 \quad \quad j \in N_2
\end{aligned}\]</span></p>
<p>主要是通过取 <span class="math inline">\(-c\)</span> 把 maximize
问题变为 minimize，以及将不同的 constraints 分类。</p></li>
<li><p>想要改成更为统一、方便处理的形式，可以通过取负将所有的
constraints 改为 <span class="math inline">\(a_i ^T x \geq
b_i\)</span>，但还是全取等最好。</p>
<p><span class="math display">\[\text{minimize} \quad c^Tx\]</span></p>
<p><span class="math display">\[\text{subject to} \quad \begin{aligned}
&amp; A^Tx =b  \\ &amp; x_j \geq 0  \end{aligned}\]</span></p>
<p>具体来说只需要再经历以下两步化简：</p>
<ul>
<li>将不受限制的 free variable 拆解为 <span class="math inline">\(x_i =
x_i ^+ - x_i ^-\)</span>，则有 <span class="math inline">\(x_i^+ \geq 0,
x_i ^- \geq 0\)</span>；</li>
<li>将 <span class="math inline">\(\sum_{j=1} ^n a_{ij} x_j \leq
b_i\)</span> 改为 <span class="math inline">\(\sum_{j=1} ^n a_{ij} x_j +
y_i = b_i, \text{with} \; y_i \geq 0\)</span></li>
</ul>
<p>注意到 <span class="math inline">\(x_j \geq 0\)</span>
是对所有变量成立的，我还是第二次看才发现这个问题。</p></li>
</ul>
<h3 id="other-optimization-problems">Other Optimization Problems</h3>
<p>也会遇到一些其他形式的优化问题，在 cost function
之类的地方有些许改动，处理思想仍然是一样的。</p>
<ul>
<li><p><span class="math display">\[\text{minimize} \quad
\max_{i=1,2,...,m} (c_i^Tx+d_i)\]</span></p>
<p><span class="math display">\[\text{subject to} \quad Ax \geq
b\]</span></p>
<p>只需要把 cost function 变成 <span class="math inline">\(m\)</span> 个
constraints 就可以了：</p>
<p><span class="math display">\[\text{minimize} \quad z\]</span></p>
<p><span class="math display">\[\text{subject to} \begin{aligned} \quad
&amp; Ax \geq b \\ &amp; z \geq c_i^Tx + d_i  \quad \text{for} \; i =
1,2,...,m\end{aligned}\]</span></p></li>
<li><p><span class="math display">\[\text{minimize} \quad \sum_{i=1}^n
c_i | x_i|\]</span></p>
<p><span class="math display">\[\text{subject to} \quad Ax \geq
b\]</span></p>
<p>这个在日记里吐槽过了，我个人认为更符合直觉的是拆正负部，只是需要保证二者之一是
<span class="math inline">\(0\)</span>，还是不方便，学实分析学得。也可以改成：</p>
<p><span class="math display">\[\text{minimize} \quad \sum_{i=1}^n c_i
y_i\]</span></p>
<p><span class="math display">\[\text{subject to} \begin{aligned} \quad
&amp; Ax \geq b \\ &amp; x_i \leq y_i, -x_i \leq y_i \quad \text{for} \;
i=1,2,...,n \\ &amp; y_i \geq 0 \quad \quad \quad \ \ \ \qquad
\text{for} \; i =1,2,...,n  \end{aligned}\]</span></p></li>
</ul>
<p>都很 trivial，初等变换一下就好了。</p>
<h2 id="solutions-to-lp-problems">Solutions to LP Problems</h2>
<p>首先 LP problem 有四种可能性，学着学着都要忘了。</p>
<ul>
<li>There exists a unique optimal solution.</li>
<li>There exist multiple optimal solutions; in that case, the set of
optimal solutions can be either bounded or unbounded.</li>
<li>The optimal cost is <span class="math inline">\(-\infty\)</span>,
and no feasible solution is optimal.</li>
<li>The feasible set is empty. (The LP problem is infeasible.)</li>
</ul>
<h3 id="notations">Notations</h3>
<p>一些拼不对的单词了属于是。</p>
<p>突然发现其实可以在笔记里多放点迷言迷语：</p>
<p><img src="https://s2.loli.net/2023/09/26/PEzuQl2MOW37Jr1.jpg" alt="mi1.jpg"></p>
<ul>
<li><p>A <strong>polyhedron</strong> is a set that can be described as
<span class="math inline">\(\{x \in \mathbb R^n | Ax \geq b \}\)</span>,
where <span class="math inline">\(A\)</span> is an <span class="math inline">\(m\times n\)</span> matrix and <span class="math inline">\(b \in \mathbb R^m\)</span>.</p></li>
<li><p>A set <span class="math inline">\(S \subset \mathbb R^n\)</span>
is <strong>bounded</strong> if there exists a constant <span class="math inline">\(K\)</span> such that the absolute value of every
component of every element of <span class="math inline">\(S\)</span> is
less than or equal to <span class="math inline">\(K\)</span>.</p></li>
<li><p>Let <span class="math inline">\(a\)</span> be a non-zero vector
on <span class="math inline">\(\mathbb R^n\)</span> and let <span class="math inline">\(b\)</span> be a scalar, thus:</p>
<ul>
<li>The set <span class="math inline">\(\{x \in \mathbb R^n | a^Tx =b
\}\)</span> is called a <strong>hyperplane</strong>.</li>
<li>The set <span class="math inline">\(\{x \in \mathbb R^n | a^Tx \geq
b \}\)</span> is called a <strong>half-space</strong>.</li>
</ul></li>
<li><p>A set <span class="math inline">\(S \subset \mathbb R^n\)</span>
is <strong>convex</strong> if for any <span class="math inline">\(x , y
\in S\)</span> and any <span class="math inline">\(\lambda \in
[0,1]\)</span>, we have <span class="math inline">\(\lambda x +
(1-\lambda) y \in S\)</span>.</p></li>
<li><p>Let <span class="math inline">\(x_1 ,x_2,...,x_n\)</span> be
vectors in <span class="math inline">\(\mathbb R^k\)</span> and let
<span class="math inline">\(\lambda_1, \lambda_2,...,\lambda_n\)</span>
be non-negative scalars whose sum is unity.</p>
<p>The convex hull of <span class="math inline">\(x_1,
x_2,...,x_n\)</span> is the set of all convex combinations of these
vectors, i.e.,</p>
<p><span class="math display">\[\{\sum_{i=1}^n \lambda_i x_i |
\sum_{i=1}^n \lambda_i =1 \;  \text{and} \; \lambda_i \in [0,1]
\}\]</span></p></li>
</ul>
<p>有一些很 trivial 的结论，看起来既重要又不重要的，希望有脑子就行。</p>
<p><img src="https://s2.loli.net/2023/09/26/Q9FIPLlzdce5aux.jpg" alt="mi2.jpg"></p>
<ul>
<li>One writes <span class="math inline">\(f(x) = O(g(x))\)</span> if
there exists a positive real number <span class="math inline">\(M\)</span> and a real number <span class="math inline">\(x_0\)</span> s.t. <span class="math inline">\(f(x)
\leq Mg(x)\)</span> for any <span class="math inline">\(x \geq
x_0\)</span>.</li>
<li>One writes <span class="math inline">\(f(x) = \Omega (g(x))\)</span>
if there exists a positive real number <span class="math inline">\(M\)</span> and a real number <span class="math inline">\(x_0\)</span> s.t. <span class="math inline">\(f(x)
\geq M g(x)\)</span> for any <span class="math inline">\(x\geq
x_0\)</span>.</li>
<li>One writes <span class="math inline">\(f(x) = \Theta (g(x))\)</span>
if <span class="math inline">\(f(x)= O(g(x))\)</span> and <span class="math inline">\(f(x) = \Omega(g(x))\)</span>.</li>
</ul>
<p>这门课上为什么有人没学过算法不知道这些是什么啊.jpg</p>
<h3 id="how-to-describe-optimal-solutions">How to Describe Optimal
Solutions</h3>
<p>有三种刻画 corner point 的方法，我们稍后证明它们在 polyhedron
里是等价的。</p>
<ul>
<li><p>Let <span class="math inline">\(P\)</span> be a polyhedron. A
vector <span class="math inline">\(x\in P\)</span> is an <strong>extreme
point</strong> of <span class="math inline">\(P\)</span> if we cannot
find two vectors <span class="math inline">\(y,z \in P\)</span>, both
different from <span class="math inline">\(x\)</span>, and a scalar
<span class="math inline">\(\lambda \in [0,1]\)</span> such that <span class="math inline">\(x = \lambda y + (1-\lambda) z\)</span>.</p></li>
<li><p>Let <span class="math inline">\(P\)</span> be a polyhedron. A
vector <span class="math inline">\(x\in P\)</span> is an
<strong>vertex</strong> of <span class="math inline">\(P\)</span> if
there exists a vector <span class="math inline">\(c \in \mathbb
R^n\)</span> such that <span class="math inline">\(c^T x &lt; c^T
y\)</span> for all <span class="math inline">\(y \in P\)</span> and
<span class="math inline">\(y\neq x\)</span>. (Also holds for &gt; by
taking <span class="math inline">\(-c\)</span>)</p></li>
<li><p>Let <span class="math inline">\(P\)</span> be a polyhedron. A
vector <span class="math inline">\(x\in P\)</span> is an <strong>basic
solution</strong> of <span class="math inline">\(P\)</span> if:</p>
<ul>
<li>All equality constraints holds.</li>
<li>Out of the constraints that are active at <span class="math inline">\(x\)</span>, there are <span class="math inline">\(n\)</span> of them that are linearly
independent.</li>
</ul>
<p>Moreover, if <span class="math inline">\(x\)</span> is a basic
solution that satisfies all the constraints, we say it's a <strong>basic
feasible solution</strong>.</p></li>
</ul>
<p>所以说只要 constraints 的个数是有限的，那么其中选择 <span class="math inline">\(n\)</span> 个 linearly independent
的方法是有限的，basic (feasible) solution 的个数就是有限的。</p>
<p>注意到定义 basic solution 的时候事实上 equality constraints 和
inequality constraints
的地位不等，然而作为一个线性优化问题是可以在这方面有很多等价形式的，事实上
basic solution 会受到 polyhedron 定义形式的影响，具体的例子详见 P49
的平面规划问题。另外，basic feasible solution 不会受到 polyhedron
形式的影响。</p>
<p>最后是有关这三个定义等价性的定理：</p>
<p>Let <span class="math inline">\(P\)</span> be a nonempty polyhedron
and let <span class="math inline">\(x \in P\)</span>, then the following
are equivalent:</p>
<ul>
<li><span class="math inline">\(x\)</span> is an extreme point.</li>
<li><span class="math inline">\(x\)</span> is a vertex.</li>
<li><span class="math inline">\(x\)</span> is a basic feasible
solution.</li>
</ul>
<p><del>证明太长了，这里写不下（</del> 但说实话从 extreme point 推 basic
feasible solution 还不是很显然，要用一点点分析智慧（</p>
<h3 id="algebraic-approach-to-optimal-solutions">Algebraic Approach to
Optimal Solutions</h3>
<p>说了这么多，也把 basic feasible solution
用三种方式刻画出来了，但是对于具体例子的计算还是借助矩阵工具。</p>
<p>有一个 applicable procedure：</p>
<p>For constructing basic solutions for a polyhedron <span class="math inline">\(P= \{x \in \mathbb R^n | Ax = b , x \geq 0
\}\)</span>, use the three-step procedures below:</p>
<ul>
<li><p>Choose <span class="math inline">\(m\)</span> linearly
independent columns <span class="math inline">\(A_{B(1)}, A_{B(2)},
\cdots , A_{B(m)}\)</span> and solve</p>
<p><span class="math display">\[\begin{bmatrix} | &amp; | &amp; \cdots
&amp;| \\ A_{B(1)} &amp; A_{B(2)} &amp; \cdots &amp; A_{B(m)} \\ \cdots
&amp; \cdots &amp;\cdots  &amp; \cdots \\ | &amp; | &amp; \cdots &amp; |
\end{bmatrix} \begin{bmatrix} x_{B(1)} \\ x_{B(2)} \\ \cdots \\
x_{B(m)}  \end{bmatrix} = \begin{bmatrix}b_1 \\ b_2 \\ \cdots \\ b_m
\end{bmatrix}\]</span></p></li>
<li><p>Take <span class="math inline">\(x_i =0\)</span> for <span class="math inline">\(i \neq B(1),B(2), \cdots, B(m)\)</span></p></li>
<li><p>Combine all the components of <span class="math inline">\(x\)</span> and get the basic solution of the base
<span class="math inline">\((A_{B(1)}, A_{B(2)}, \cdots ,
A_{B(m)})\)</span>.</p></li>
</ul>
<p>不同的 base 可以得到不同的 basic solution，也可能会得到相同的。</p>
<p>在解 basic solution 的时候本质上只用到了 <span class="math inline">\(m\)</span> 个 constraint equalities 作为
base，以及 <span class="math inline">\(n-m\)</span> 个 non-negative
constraints，实际上 <span class="math inline">\(x\)</span> 可能不仅在这
<span class="math inline">\(n\)</span> 个 constraints 处
active，如果有多于 <span class="math inline">\(n\)</span> 个 constraints
在 <span class="math inline">\(x\)</span> 处 active 则称它是一个
degenerate basic solution。</p>
<p>很明显的一点是在 polyhedron 里如果一个 basic solution 有多于 <span class="math inline">\(n-m\)</span> 个分量是 <span class="math inline">\(0\)</span>，那么它一定
degenerate。由矩阵解的唯一性，这也是 degenerate basic solution
的唯一情形。</p>
<h3 id="existence-of-vertex">Existence of Vertex</h3>
<p>非常口胡地说，要有 basic feasible solution
至少区域的边界上要先有个角吧（比划</p>
<ul>
<li>A polyhedron <span class="math inline">\(P \subset \Re^n\)</span>
<span class="math inline">\(\textbf{contains a line}\)</span> if there
exists a vector <span class="math inline">\(x \in P\)</span> and a
nonzero vector <span class="math inline">\(d \in \Re^n\)</span> such
that <span class="math inline">\(x + \lambda d \in P\)</span> holds for
all scalar <span class="math inline">\(\lambda\)</span>.</li>
</ul>
<p>也就是说范围里面不能有直线才能有 vertex。</p>
<ul>
<li><p>Suppose that the polyhedron <span class="math inline">\(P = \{x
\in \Re^n \mid \textbf{a}_i^T x \geqslant b_i , i=1,2, \cdots, m
\}\)</span> is nonempty. Then the following is equivalent:</p>
<ul>
<li><p>The polyhedron <span class="math inline">\(P\)</span> has at
least one extreme point.</p></li>
<li><p>The polyhedron does not contain a line.</p></li>
<li><p>There exist <span class="math inline">\(n\)</span> vectors out of
the family <span class="math inline">\(\textbf{a}_1, \textbf{a}_2,
\cdots, \textbf{a}_m\)</span>, which are linearly independent.</p></li>
</ul></li>
</ul>
<p>一个更重要的定理是关于 bounded polyhedron 和 standardized problem
的：</p>
<ul>
<li>Every nonempty bounded polyhedron and every nonempty polyhedron in
standard form has at least one basic feasible solution.</li>
</ul>
<p>这是因为前者显然不含直线，后者定义在 <span class="math inline">\(\{x
\geq 0\}\)</span> 的区域里也不含直线。注意到所有的 LP problem
其实都可以转化为后者的形式，所以说实际上都是有 basic feasible solution
的。这话比较模糊，意思是对于新的 standardized problem 一定会有 basic
feasible solution，然而把这个解限制到原来问题的维度中得到的解未必会是
basic feasible solution。</p>
<p>不过没有关系，我们会在后面看到实际上这已经够用了，因为目的不是解
basic feasible solution，而是找出 optimal cost。在 standardized problem
下的 optimal cost 可以用 basic feasible solution 得到，而它和原问题的
optimal cost 一致。</p>
<h3 id="why-is-vertex-important">Why is Vertex Important?</h3>
<p>说了这么多，为啥要解 basic feasible solution，对做 optimal cost
有什么好处吗？事实上，optimal cost 要么 unbounded，要么是在 basic
feasible solution 处取到，所以说只要 optimal cost 不是 <span class="math inline">\(-\infty\)</span> 就就把所有的 basic feasible
solution 找出来溜一遍就好了。</p>
<p>严肃一点用定理来说明的话是以下几条，对应书上 Section 2.6：</p>
<ul>
<li>Suppose the linear programming problem <span class="math inline">\(P\)</span> has at least one extreme point, and
there exists at least one optimal solution. Then there exist one optimal
solution and is the extreme point of <span class="math inline">\(P\)</span>.</li>
<li>Suppose the linear programming problem <span class="math inline">\(P\)</span> has at least one extreme point. Then,
either the optimal cost is <span class="math inline">\(-\infty\)</span>
or there exist one extreme point, and it's also one of the optimal
solution.</li>
</ul>
<p>注意到任意一个 LP problem 都可以转化为标准形式并保持 cost
不变，每个标准形式都有 extreme point，所以说上一条定理实际上是对任意 LP
problem 成立的。</p>
<p>另外，第一个定理并不能推出第二个，因为并非 optimal cost 不是 <span class="math inline">\(-\infty\)</span> 就能推出有 optimal
solution，比如说在 <span class="math inline">\(x &gt;0\)</span> 上找
<span class="math inline">\(\frac 1x\)</span> 的最小值，既不是 <span class="math inline">\(-\infty\)</span> 也不存在 optimal solution。zjz 的
PPT 还有 yy 讲课的时候都说
trivial，实际上是不能这么推的。但可以通过沿特定方向移动到下一个 basic
feasible solution 的方法证明这种情况在 LP problem
里不会出现，这也就是第二个定理的证明。</p>
<h1 id="lecture-2">Lecture 2</h1>
<p>这节课和 Ruizhe Shi 合作的 scribing 见
https://www.overleaf.com/read/hwpxppmfnjbk。</p>
<p>说实话我觉得 scribing 是写给队友和老师看的罢了，所以当然还要有个
<del>从里面复制然后暴论的</del> 废话版本写给自己看。</p>
<h2 id="simplex-method">Simplex Method</h2>
<p>简单来说 simplex method 是从一个 basic feasible solution
出发，用最简单的计算方法寻找下一个 basic feasible solution
的方法。从几何的角度来说从多边形的一个顶点出发到另一个顶点，当然是沿着中间连接的边走过去最方便，所以也就是在寻找
adjacent basic feasible solution。</p>
<blockquote>
<p>Recap: Two basic solutions are said <strong>adjacent</strong> iff
there are <span class="math inline">\(n-1\)</span> linearly independent
constraints that are active at both of them. We also say that two bases
are adjacent if they share all but one column.</p>
</blockquote>
<p>也就是说，修改 solution vector 中的一对 component 即可。</p>
<h3 id="find-the-initial-solution">Find the Initial Solution</h3>
<p>想开始一个循环的算法得先有个 initial solution
才能开始罢（，为了计算复杂性不如选个最简单的。</p>
<p>在 LP 问题的标准化中经常会有加入一些 artificial variable
来把不等号改成等号的行为，比如说 <span class="math inline">\(a^T x \geq
b\)</span> 完全可以写成 <span class="math inline">\(a_1 x_1 + \cdots +
a_n x_n + y_1 = b\)</span>，里面这个 <span class="math inline">\(y_1\)</span> 就是一个 artificial
variable。它的系数是 <span class="math inline">\(1\)</span>，放在整个矩阵里其实可以作为最简单的
linearly independent column 选出来计算 basic feasible solution。</p>
<p>即使是在标准形式下也可以用这个思路来找一个简单的 initial
solution，考虑：</p>
<p><span class="math display">\[\begin{aligned}
    \text{minimize} \quad &amp; \textbf{c}^T x  \\
    \text{subject to} \quad &amp; \textbf{Ax} = \textbf{b} \\
                     &amp; \textbf{x} \geqslant \textbf{0}
\end{aligned}\]</span></p>
<p>By multiplying some rows of <span class="math inline">\(\textbf{A}\)</span> by <span class="math inline">\(-1\)</span>, we can assume without loss of
generality that <span class="math inline">\(\textbf{b} \geqslant
\textbf{0}\)</span>. We now introduce a vector of artificial variables
<span class="math inline">\(\textbf{y}\)</span> and consider the
auxiliary problem:</p>
<p><span class="math display">\[\begin{aligned}
    \text{minimize} \quad &amp; y_1 + y_2 + \cdots  + y_m \\
    \text{subject to} \quad &amp; \textbf{Ax} + \textbf{y} = b \\
                            &amp; \textbf{x} \geqslant 0 \\
                            &amp; \textbf{y} \geqslant 0
\end{aligned}\]</span></p>
<p>这个 auxiliary problem 的初始化很容易，让 <span class="math inline">\(\textbf {x} =0\)</span> 且 <span class="math inline">\(\textbf {y} = b\)</span> 就是 basic feasible
solution，对应 basis 为 <span class="math inline">\(\textbf {I}_{m
\times m}\)</span>。 某种程度上 auxiliary problem 等同于 original
problem。首先，如果 <span class="math inline">\(\textbf {x}\)</span> 是
original problem 的 basic feasible solution，则将 <span class="math inline">\(\textbf {x}\)</span> 和 <span class="math inline">\(\textbf {y} =0\)</span> 结合起来会产生 auxiliary
problem 的 optimal solution。另一方面，如果能获得 auxiliary problem 的
optimal solution，则根据约束 <span class="math inline">\(\textbf {y}
\geqslant 0\)</span>，它必须满足 <span class="math inline">\(\textbf
{y}=0\)</span>。于是 <span class="math inline">\(\textbf {x}\)</span> 是
original problem 的 basic feasible solution。</p>
<p>另外如果auxiliary problem 的 optimal cost 不是零，那么 original
problem 是 infeasible 的。所以我们可以直接考虑下面的 auxiliary problem
来解 original problem 的 optimal solution，用它简单形式下的 initial
solution 开始 simplex method。</p>
<h3 id="develop-feasible-direction">Develop Feasible Direction</h3>
<p>所谓的 feasible direction 其实就是我们希望“沿着边来移动 solution
point”的那个边。当然移动的时候未必会沿着边来移动，可能就直接按照两个顶点的连线移动，但是怎么说呢，就是个形象点的说法（</p>
<ul>
<li>Let <span class="math inline">\(\textbf{x}\)</span> be an element of
a polyhedron <span class="math inline">\(P\)</span>. A vector <span class="math inline">\(\textbf{d} \in \Re^n\)</span> is said to be a
<strong>feasible direction</strong> at <span class="math inline">\(x\)</span>, if there exists a positive scalar
<span class="math inline">\(\theta\)</span> for which <span class="math inline">\(\textbf{x}+\theta  \textbf{d} \in P\)</span>.</li>
</ul>
<p>在上一次得到的 basic feasible solution 里假设 basis <span class="math inline">\(B\)</span> 的下标是 <span class="math inline">\(B(1),B(2),\cdots, B(m)\)</span>，记 <span class="math inline">\(I = \{B(1) , B(2), \cdots ,
B(m)\}\)</span>。本质上每一次希望的移动就是在 <span class="math inline">\(I^c\)</span> 里面挑选一个新的下标 <span class="math inline">\(j\)</span> 然后将 <span class="math inline">\(x_j\)</span> 变为 <span class="math inline">\(1\)</span>，为了保证 basic feasible solution 的
<span class="math inline">\(n\)</span> 个 active constraints
的条件，还需要再在 <span class="math inline">\(I\)</span>
里面挑选一个下标 <span class="math inline">\(B(i)\)</span> 然后将 <span class="math inline">\(x_{B(i)}\)</span> 变为 <span class="math inline">\(0\)</span>。</p>
<p>从 applicable 的角度来说，具体的计算步骤是：</p>
<ul>
<li>选择一个 <span class="math inline">\(I^c\)</span> 中的 <span class="math inline">\(j\)</span> 作为新的下标，计算 <span class="math inline">\(B^{-1}A_j\)</span> 作为 <span class="math inline">\(d_{B(1)}, d_{B(2)}, \cdots, d_{B(m)}\)</span>
的值，记 <span class="math inline">\(d_j=1\)</span>，其余的分量保持
<span class="math inline">\(0\)</span>。</li>
<li>寻找一个合适的 <span class="math inline">\(\theta\)</span> 使得
<span class="math inline">\(x +\theta d\)</span> 是一个最合适的 basic
feasible solution</li>
</ul>
<p>实际上如果确定了 <span class="math inline">\(j\)</span>，这里的 <span class="math inline">\(\theta\)</span>
的选择范围就是有限的了，只有对于小于 <span class="math inline">\(0\)</span> 的 <span class="math inline">\(d_{B(i)}\)</span> 才能作为移动到 <span class="math inline">\(0\)</span> 的方向。</p>
<p><span class="math display">\[\begin{aligned}
      \theta =\left(-\frac{x_{B(i)}}{d_{B(i)}}\right), \;
\{i=1,\ldots,m,d_{B(i)}&lt;0\}
  \end{aligned}\]</span></p>
<p>然而其实连 <span class="math inline">\(j\)</span>
都没确定呢，一开始是随便取的，嘿嘿。所以下面要考虑怎么选择 <span class="math inline">\(j\)</span>，其后怎么选择 <span class="math inline">\(\theta\)</span>，或者两个其实也可以一起选就是了，但是计算复杂度可能又会提高。</p>
<h3 id="choice-of-adjacent-basic-feasible-solution">Choice of Adjacent
Basic Feasible Solution</h3>
<p>Feasible direction
确认了之后就要考虑到底按照哪个下标来移动，最朴素的想法是突然想起来这是个优化问题（，然后按照单次移动的
cost 相关的问题来考虑。</p>
<ul>
<li><p>Let <span class="math inline">\(\textbf{x}\)</span> be a basic
solution, let <span class="math inline">\(\textbf{B}\)</span> be an
associated basis matrix, and let <span class="math inline">\(\textbf{c}_B\)</span> be the vector of costs of
the basic variables. For each <span class="math inline">\(j\)</span>, we
define the <strong>reduced cost</strong> <span class="math inline">\(\bar c_j\)</span> of the variables <span class="math inline">\(x_j\)</span> according to the formula</p>
<p><span class="math display">\[\begin{aligned}
    \bar c_j=c_j-\textbf{c}_B \textbf{B}^{-1}\textbf{A}_j.
  \end{aligned}\]</span></p></li>
</ul>
<p>这样定义了一个关于各个 <span class="math inline">\(j\)</span>
对应的单位 reduced cost，也就是 <span class="math inline">\(x_j\)</span>
每增加 <span class="math inline">\(1\)</span> 会导致 cost
减少的量，当然是减得越多越好。另外 <span class="math inline">\(\bar
c_j\)</span> 在 <span class="math inline">\(j\)</span> 取 <span class="math inline">\(I\)</span> 中的下标时等于 <span class="math inline">\(0\)</span>，这其实很能 make sense，毕竟不能再按照
<span class="math inline">\(B(i)\)</span> 来作为加入 basis
的下标了，会导致的 cost 变化也只能是 <span class="math inline">\(0\)</span>。所以 reduced cost 是一个 general
definition，可以再用它们来定义一个向量 <span class="math inline">\(\bar
c\)</span>，其各个分量就是 reduced cost。</p>
<p>寻找下一个 basic feasible solution
的最好的选择就是找一个绝对值最大（实际上最小）的 <span class="math inline">\(\bar c_j\)</span>，沿着这个方向移动最大的一个
<span class="math inline">\(\theta^*&gt;0\)</span>，然后 cost 就减少了
<span class="math inline">\(\theta^* \bar c_j\)</span>。这样选择 <span class="math inline">\(\bar c_j\)</span> 和对应的下标 <span class="math inline">\(j\)</span> 从直觉上来说可以经历更少的步数到达
optimal solution，降低算法复杂度。</p>
<p>另外，也可以从某个点处的 reduced cost vector <span class="math inline">\(\bar c\)</span>
看出一些东西，主要有关这个点有没有达到 optimal cost，等等。</p>
<ul>
<li>Consider a basic feasible solution <span class="math inline">\(x\)</span> associated with a basis matrix <span class="math inline">\(B\)</span>, and let <span class="math inline">\(\bar c\)</span> be the corresponding vector of
reduced costs.
<ul>
<li>If <span class="math inline">\(\bar c \geq 0\)</span>, then <span class="math inline">\(x\)</span> is optimal.</li>
<li>If <span class="math inline">\(x\)</span> is optimal and
nondegenerate, then <span class="math inline">\(\bar c \geq
0\)</span>.</li>
</ul></li>
<li>A basis matrix <span class="math inline">\(B\)</span> is optimal iff
<ul>
<li><span class="math inline">\(B^{-1}b \geq 0\)</span></li>
<li><span class="math inline">\(\bar c^T = c^T - c^T _B B^{-1} A \geq
0^T\)</span></li>
</ul></li>
</ul>
<h3 id="termination">Termination</h3>
<p>最后两个问题是：算法会不会进入循环？会不会找不到 optimal solution
就停下来？答案是都不会。</p>
<p>因为只有有限个 basic feasible
solution，所以只要不经过同一个点两遍，就可以遍历所有的可能性。不经过同一个点两遍这件事通过
lexicographic pivoting rule
来决定，保证从字典序上来说所有的解是递增的，就不会出现循环。</p>
<p>另外既然 optimal solution 要么是 <span class="math inline">\(-\infty\)</span> 要么是在某个 basic feasible
solution 处取到，那么既然遍历（注意并不是真正的遍历，并不会走到 cost
比较大的一些 basic feasible solution，比如说比 initial solution 的 cost
更大的解就不可能取到，这能提高效率且不遗漏）了 basic feasible solution
就一定能找到 optimal solution，所以说 simplex method
是个非常完满的算法。</p>
<h3 id="summary">Summary</h3>
<p>最后总结一下 simplex method 的步骤。</p>
<ul>
<li>通过解 auxiliary problem 找到一个本质 trivial 的 initial
solution；它可能不存在，此时原问题 infeasible；</li>
<li>通过做 <span class="math inline">\(\bar c^T = c^T - c^T_B
B^{-1}A\)</span> 得到在此处的 reduced cost vector，
<ul>
<li>如果 <span class="math inline">\(\bar c \geq
0\)</span>，说明目前的解就是 optimal solution</li>
<li>否则找出绝对值最大的 <span class="math inline">\(\bar
c_j\)</span>，确定下标 <span class="math inline">\(j\)</span>，再找出对应的 feasible direction 是
<span class="math inline">\(d_B = -B^{-1}A, d_j=1\)</span>.</li>
</ul></li>
<li>通过找 <span class="math inline">\(\theta^* = \max \{\theta \geq 0
\mid x +\theta d \in P \}\)</span> 来更新 basic feasible solution 为
<span class="math inline">\(y = x+\theta d\)</span>，可能遇到：
<ul>
<li>如果 <span class="math inline">\(\theta\)</span> unbounded，则
optimal cost 也是 <span class="math inline">\(-\infty\)</span>；</li>
<li>否则可以更新 optimal cost 和对应的 basic feasible
solution，然后重复以上步骤直到找到 optimal solution。</li>
</ul></li>
</ul>
<h2 id="introduction-to-duality">Introduction to Duality</h2>
<p>把 LP problem 变成它的 dual problem 的 motivation
其实来自拉格朗日乘子法，本质上是对 cost function 的形式 penalize
一个条件，如果不满足条件的话 cost function
就会变大，从而找到最小值。</p>
<p><del>想必这个过程推起来很简单吧我就不写了</del></p>
<p>简单来说，primal problem 和 dual problem 的对应关系是这样的：</p>
<p><span class="math display">\[\begin{aligned} \text{minimize}
\quad  &amp; c^T x \\ \text{subject to} \quad &amp; a_i ^T x \geq b
\quad  i \in M_1 \\ &amp; a_i ^T x \leq b_i \quad  i \in M_2  \\ &amp;
a_i ^T x = b_i \quad  i \in M_3  \\ &amp; x_j  \geq 0 \quad  j \in
N_1  \\ &amp; x_j  \leq 0 \quad  j \in N_2  \\ &amp; x_j \; \text{free}
\quad  j \in N_3   \end{aligned} \quad \quad \quad \begin{aligned}
\text{maximize} \quad  &amp; p^T b \\ \text{subject to} \quad &amp;
p_i  \geq 0 \quad  i \in M_1 \\ &amp; p_i \leq 0 \quad  i \in M_2  \\
&amp; p_i \; \text{free} \quad  i \in M_3  \\ &amp; p^TA_j \leq c_j
\quad  j \in N_1  \\ &amp; p^TA_j  \geq c_j \quad  j \in N_2  \\ &amp;
p^TA_j = c_j \quad  j \in N_3   \end{aligned}\]</span></p>
<p>可以看出来 dual 的 dual 就是 primal。</p>
<p>除此之外还需要一些定理来说明 dual 和 primal 的 cost 之间的关系。</p>
<h3 id="duality-theorems">Duality Theorems</h3>
<ul>
<li><p>(Weak Duality) If <span class="math inline">\(x\)</span> is a
feasible solution to the primal problem and <span class="math inline">\(p\)</span> is a feasible solution to the dual
problem, then <span class="math inline">\(p^Tb\leqslant
c^Tx\)</span>.</p>
<p><strong>Proof</strong>: Set <span class="math inline">\(u_i = p_i
(a_i^Tx - b_i), v_j = (c_j - p^TA_j) x_j\)</span>, then by feasibility
<span class="math inline">\(u_i \geq 0, v_i \geq 0\)</span>.</p>
<p>Therefore <span class="math inline">\(\sum_{i,j}u_i +v_j = p^T(Ax-b)
+ (c^T- p^TA)x = c^Tx - p^Tb \geq 0\)</span>.</p>
<ul>
<li>If the optimal cost in the primal is <span class="math inline">\(-\infty\)</span>, then the dual one must be
infeasible.</li>
<li>If the optimal cost in the dual is <span class="math inline">\(+\infty\)</span>, then the primal one must be
infeasible.</li>
<li>Let <span class="math inline">\(x\)</span> and <span class="math inline">\(p\)</span> be feasible solutions to the primal and
the dual problem respectively, and suppose that <span class="math inline">\(p^T b = c^Tx\)</span> holds. Then <span class="math inline">\(x\)</span> and <span class="math inline">\(p\)</span> are optimal solutions to the primal and
the dual respectively.</li>
</ul></li>
</ul>
<p>Weak duality 引出的第三条最重要，如果 <span class="math inline">\(x\)</span> 不是 optimal solution 则对任意的
feasible solution <span class="math inline">\(x&#39;\)</span> 都有 <span class="math inline">\(c^Tx&#39; \geq p^Tb =
c^Tx\)</span>，导致矛盾，<span class="math inline">\(p\)</span> 的
optimality 同理。这说明了 <span class="math inline">\(c^Tx =
p^Tb\)</span> 可以导出二者分别在此处取到 optimal
cost，这引出了更重要的一条 strong duality，保证其一有 optimal solution
的时候另一个也有。</p>
<ul>
<li><p>(Strong Duality) If a linear programming problem has an optimal
solution, so does its dual, and the respective optimal costs are
equal.</p>
<p><strong>Proof</strong>: Consider the problem in standard form. The
simplex method (with lexicographic pivoting rule) terminates with an
optimal solution <span class="math inline">\(x^*\)</span> and an optimal
basis <span class="math inline">\(B\)</span>, then <span class="math display">\[\begin{aligned}
    \bar c^T=c^T-c_B^TB^{-1}A\geqslant0.
\end{aligned}\]</span></p>
<p>Let <span class="math inline">\(p^*=(c_B^T B^{-1})^T\)</span> as the
corresponding optimal solution <span class="math inline">\(p\)</span>,
then <span class="math display">\[\begin{aligned}
    (p^*)^TA=c_B^T B^{-1}A\leqslant c^T,
\end{aligned}\]</span> and <span class="math display">\[\begin{aligned}
(p^*)^Tb=c_B^TB^{-1}b=c_B^Tx_B=c^Tx^*.
\end{aligned}\]</span> So the strong duality holds.</p></li>
</ul>
<p>最后来个 Farka's lemma，把 constraints
作为一个矩阵从原来的优化问题里面抽出来看：</p>
<ul>
<li>(Farka's lemma) Let <span class="math inline">\(A\)</span> be a
matrix of dimensions <span class="math inline">\(m\times n\)</span> and
let <span class="math inline">\(b\)</span> be a vector in <span class="math inline">\(\Re ^m\)</span>. Then exactly one of the following
two alternative holds:
<ul>
<li>There exists some <span class="math inline">\(x\geqslant 0\)</span>
such that <span class="math inline">\(Ax=b\)</span>.</li>
<li>There exists some vector <span class="math inline">\(p\)</span> such
that <span class="math inline">\(p^TA\geqslant 0\)</span> and <span class="math inline">\(p^Tb&lt;0\)</span>.</li>
</ul></li>
<li>(Farka's corollary) Let <span class="math inline">\(A_1,\ldots,A_n\)</span> and <span class="math inline">\(b\)</span> be given vectors and suppose that any
vector <span class="math inline">\(p\)</span> that satisfies <span class="math inline">\(p^TA_i\geqslant 0\)</span>, <span class="math inline">\(i=1,\ldots,n\)</span>, must also satisfy <span class="math inline">\(p^Tb\geqslant 0\)</span>. Then <span class="math inline">\(b\)</span> can be expressed as a nonnegative
linear combination of the vectors <span class="math inline">\(A_1,\ldots, A_n\)</span>.</li>
</ul>
<p>就变成了很普通但是又看着有点奇怪的矩阵变换问题，谁知道背后还有个优化问题.jpg。事实上对于不同形式的
primal 和 dual problem
我们都可以写出来一对相反的条件，让它们二者成立其一。</p>
<h1 id="lecture-3">Lecture 3</h1>
<p>在上这节课之前我把 HW2 写完了，相应地其实就把 Nash equilibrium
那道题做了。是周二晚上吃饭之前写完的，吃饭之前多花了五分钟写成 LaTeX
然后超级开心地离开四教，吃完回来又读了一遍感觉证得很好，真的很喜欢这个方法还有这整个问题。</p>
<p>所以我还是忍不住在 acknowledge 里面写了 MashPlant 日记里那段话：</p>
<blockquote>
<p>All exercises but Ex 4.29 are finished on my own. Among them I
appreciate the solution of Ex 4.10 most (though trivial), as this is
actually quite a triumph, even if it's hard to explain to your friends
or family members.</p>
</blockquote>
<p><del>好了现在大家都知道我不会做 Ex 4.29 了</del></p>
<p>然后 Lecture 3
上又把这个问题拿出来讲了，顺便把这个作业题也证明了，有点不爽（（x</p>
<h2 id="nash-equilibrium">Nash Equilibrium</h2>
<p>先把 theorem 丢出来，然后写一个我的证明：</p>
<h3 id="theory">Theory</h3>
<p><strong>Ex 4.10</strong></p>
<p>Consider the standard form problem of minimizing <span class="math inline">\(c^Tx\)</span> subject to <span class="math inline">\(Ax = b, x \geq 0\)</span>. We define the
Lagrangean by</p>
<p><span class="math display">\[L(x,p) = c^Tx + p^T(b-Ax)\]</span></p>
<p>Consider the following game: player 1 chooses some <span class="math inline">\(x \geq 0\)</span>, and player 2 chooses some <span class="math inline">\(p\)</span>; then, player 1 pays to player 2 the
amount <span class="math inline">\(L(x,p)\)</span>. Player 1 would like
to minimize <span class="math inline">\(L(x,p)\)</span>, while player 2
would like to maximize it.</p>
<p>A pair <span class="math inline">\((x^*,p^*)\)</span> with <span class="math inline">\(x^* \geq 0\)</span>, is called an equilibrium
point if <span class="math inline">\(L(x^*,p) \leq L(x^*,p^*) \leq
L(x,p^*), \; \forall x \geq 0, \forall p\)</span>.</p>
<p>(Thus, we have an equilibrium if no player is able to prove her
performance by unilaterally modifying her choice.)</p>
<p>Show that a pair (<span class="math inline">\(x^*,p^*\)</span>) is an
equilibrium if and only if <span class="math inline">\(x^*\)</span> and
<span class="math inline">\(p^*\)</span> are optimal solutions to the
standard form problem under consideration and its dual respectively.</p>
<p><strong>Proof</strong>:</p>
<p>Consider the primal problem and the dual problem in the following
form:</p>
<p><span class="math display">\[\begin{aligned}
    \textbf{minimize} \quad &amp; c^Tx \\
    \textbf{subject to} \quad &amp; Ax = b \\
    &amp; x \geq 0
\end{aligned} \quad \quad \quad
\begin{aligned}
    \textbf{maximize} \quad &amp; p^Tb \\
    \textbf{subject to} \quad &amp; A^T b \leq c \\
    \\
\end{aligned}\]</span></p>
<ol type="1">
<li>If <span class="math inline">\(x^*\)</span> and <span class="math inline">\(p^*\)</span> are optimal solutions to the primal
problem and the dual problem respectively, then there is:</li>
</ol>
<p><span class="math display">\[L(x^*, p) = c^Tx^* + p^T(b -Ax^*) =
c^Tx^* = L(x^*, p^*)\]</span></p>
<p><span class="math display">\[L(x,p^*) = c^Tx + p^{*T} (b-Ax) = (c^T -
p^{*T} A)x + p^{*T} b \geq p^{*T} b = c^Tx^*\]</span></p>
<p>according to the strong duality theorem.</p>
<p>Therefore <span class="math inline">\(L(x^*,p) \leq L(x^*,p^*) \leq
L(x,p^*)\)</span> holds, and <span class="math inline">\((x^*,p^*)\)</span> is an equilibrium.</p>
<ol start="2" type="1">
<li>If <span class="math inline">\((x^*,p^*)\)</span> is an equilibrium,
first to prove that <span class="math inline">\(x^*\)</span> is a
feasible solution to the primal problem. Consider the first inequality
<span class="math inline">\(L(x^*, p ) \leq L(x^*, p^*)\)</span> which
holds for any <span class="math inline">\(p\)</span>. If <span class="math inline">\(b - Ax^* \neq 0\)</span>, by taking <span class="math inline">\(p = b - Ax^* +p^*\)</span>, we can obtain</li>
</ol>
<p><span class="math display">\[L(x^*,p) - L(x^*, p^*) = (p-
p^*)^T(b-Ax^*) = (b-Ax^*)(b-Ax^*) &gt;0,\]</span></p>
<p>which leads to contradiction. Therefore <span class="math inline">\(Ax^* = b\)</span> holds, <span class="math inline">\(x^*\)</span> is a feasible solution to the primal
problem and <span class="math inline">\(L(x^*, p^*) = c^T
x^*\)</span>.</p>
<p>Next step we prove that <span class="math inline">\(p^*\)</span> is a
feasible solution to the dual problem. Consider the second inequality
<span class="math inline">\(c^T x^* = L(x^*,p^*) \leq L(x, p^*)\)</span>
which holds for any <span class="math inline">\(x \geq 0\)</span>. By
taking <span class="math inline">\(x =0\)</span> we can obtain that
<span class="math inline">\(c^T x^* \leq L(0,p^*) = p^{*T}b\)</span>
holds.</p>
<p>Moreover, if there exists <span class="math inline">\(i\)</span> s.t.
<span class="math inline">\(c_i - p^T A_i &lt;0\)</span>, we can take
<span class="math inline">\(x_i = -\frac{p^{*T}b - c^Tx^*}{c_i - p^{*T}
A_i} +1\)</span> and <span class="math inline">\(x_j =0\)</span> for all
<span class="math inline">\(j \neq i\)</span>, then <span class="math inline">\(x \geq 0\)</span>. Take such <span class="math inline">\(x\)</span> to the inequality and there is:</p>
<p><span class="math display">\[c^Tx^* = L(x^*,p^*) \leq L(x,p^*) =
p^{*T} b + (c_i - p^{*T} A_i) x_i &lt;  p^{*T} b  - (p^{*T}b - c^Tx^*) =
c^Tx^* ,\]</span></p>
<p>which leads to contradiction. Thus <span class="math inline">\(c_i -
p^{*T} A_i \geq 0\)</span> holds for any subscript <span class="math inline">\(i\)</span>, i.e. <span class="math inline">\(c -
p^{*T}A \geq 0\)</span>. Therefore <span class="math inline">\(p^*\)</span> is a feasible solution to the dual
problem.</p>
<p>According to the inequality <span class="math inline">\(c^T x^* \leq
p^{*T}b\)</span> we obtained before and the weak duality theorem, there
is <span class="math inline">\(c^T x^* = p^{*T} b\)</span>, and
therefore <span class="math inline">\(x^*, p^*\)</span> are optimal
solutions to the primal problem and the dual problem respectively.</p>
<h3 id="application">Application</h3>
<p>其实已经挺清楚的了，就是说 <span class="math inline">\(\max_p \min_x
L(x,p) = \min_x \max_p L(x,p)\)</span> 这样子，所以说 dual 和 primal
得到的结果是一致的。</p>
<h3 id="application-of-farkas-lemma">Application of Farka's Lemma</h3>
<p>先回顾下 Farka's lemma：</p>
<p>(Farka's lemma) Let <span class="math inline">\(A\)</span> be a
matrix of dimensions <span class="math inline">\(m\times n\)</span> and
let <span class="math inline">\(b\)</span> be a vector in <span class="math inline">\(\Re ^m\)</span>. Then exactly one of the following
two alternative holds:</p>
<ul>
<li>There exists some <span class="math inline">\(x\geqslant 0\)</span>
such that <span class="math inline">\(Ax=b\)</span>.</li>
<li>There exists some vector <span class="math inline">\(p\)</span> such
that <span class="math inline">\(p^TA\geqslant 0\)</span> and <span class="math inline">\(p^Tb&lt;0\)</span>.</li>
</ul>
<p>除了用一对 primal problem 和 dual problem
记这个结论之外，还可以用一个图来直观地理解：</p>
<p><img src="https://s2.loli.net/2023/10/21/AzN5LGkDotKBbFh.png" alt="farka.png"></p>
<p>当 <span class="math inline">\(b\)</span> 不落在 <span class="math inline">\(A_i\)</span> 和 <span class="math inline">\(x \geq
0\)</span>
构造出的阴影范围内，也就是说第一个条件不满足的时候，就一定存在 <span class="math inline">\(p\)</span> 使得 <span class="math inline">\(p\)</span> 和 <span class="math inline">\(b\)</span> 的夹角是“钝角”，而且 <span class="math inline">\(p\)</span> 和每个 <span class="math inline">\(A_i\)</span> 的夹角是“锐角”。</p>
<p>考虑一个有 <span class="math inline">\(n\)</span>
种商品的贸易过程，每次购买的份额是一个 asset vector <span class="math inline">\(x =
(x_1,x_2,...,x_n)\)</span>，初始状态下的价格是一个 price vector <span class="math inline">\(p =
(p_1,p_2,...,p_n)\)</span>，因此初始状态下投入的资金是 <span class="math inline">\(p^Tx\)</span>。一段时间后会呈现出 <span class="math inline">\(m\)</span> 种状态之一，第 <span class="math inline">\(i\)</span> 种状态下这 <span class="math inline">\(n\)</span> 种商品的售价是一个 payoff vector <span class="math inline">\((r_{i1},r_{i2},...,r_{in})\)</span>。由此构造一个
payoff matrix：</p>
<p><span class="math display">\[R= \begin{bmatrix} r_{11} &amp; r_{12}
&amp; \cdots &amp; r_{1n} \\ \cdots &amp; \cdots &amp; \cdots &amp;
\cdots \\\cdots &amp; \cdots &amp; \cdots &amp; \cdots \\ r_{m1} &amp;
r_{m2} &amp; \cdots &amp;  r_{mn} \end{bmatrix}\]</span></p>
<p>取 <span class="math inline">\(w = Rx = (w_1,w_2,\cdots,w_m)\)</span>
作为购买份额为 <span class="math inline">\(x\)</span> 时，最终在 <span class="math inline">\(m\)</span> 个状态下分别得到的收入。有一个 absence
of arbitrage
condition，大概就是说不可能在负投资的状态下得到正收益，也就是说 <span class="math inline">\(Rx \geq 0\)</span> 可以推出 <span class="math inline">\(p^Tx \geq 0\)</span>。</p>
<p>由 Farka's lemma 可知此时第二条不成立，一定存在 <span class="math inline">\(q \geq 0\)</span> 使得 <span class="math inline">\(R ^T q = p\)</span>。</p>
<h2 id="the-center-of-gravity-method">The Center of Gravity Method</h2>
<p>实际上就是一个不断切割已有的 polyhedron 来找到 optimal solution
的过程。简单来说从初始状态开始，每个状态下手里有一个多边形 <span class="math inline">\(S_t\)</span>（feasible set 的 subset）和它的质心
<span class="math inline">\(x_t\)</span>，然后把使得取值大于 <span class="math inline">\(c^Tx_t\)</span> 的部分切掉，也就是取 <span class="math inline">\(S_t\)</span> 和 hyperapce <span class="math inline">\(\{x \in \mathbb R^n \mid c^T(x-x^T) &gt; 0
\}\)</span> 的交这一部分作为不可能取到 optimal cost
的区域，余下的部分是下一状态的多边形 <span class="math inline">\(S_{t+1}\)</span> 和相应的质心 <span class="math inline">\(x_{t+1}\)</span>，由此按照所需的精度来逼近 optimal
cost。</p>
<p>写成算法的步骤来说也非常简单，实际上每次就操作两步。先取整个 feasible
set 作为 <span class="math inline">\(S_1\)</span>，然后：</p>
<ol type="1">
<li>Take <span class="math inline">\(x_t = \frac{1}{Vol(S_t)} \int_{x
\in S_t} x \; dx\)</span> as the center of gravity of the polyhedron
<span class="math inline">\(S_t\)</span>;</li>
<li>Take <span class="math inline">\(S_{t+1} = S_t \cap \{x \mid
c^T(x-x_t) \leq 0 \}\)</span> as the new polyhedron.</li>
</ol>
<p>一直重复直到 <span class="math inline">\(S_t\)</span> 足够小，此时
<span class="math inline">\(c^T x_t\)</span> 和 optimal cost <span class="math inline">\(c^Tx^*\)</span>
的误差也会足够小。这由一些定理保证。</p>
<ul>
<li><p>Let <span class="math inline">\(K\)</span> be a centered convex
set (i.e. <span class="math inline">\(\int_{x \in K} xdx=0\)</span>),
then for any <span class="math inline">\(w \in \mathbb R^n\)</span>,
<span class="math inline">\(w \neq 0\)</span>, one has</p>
<p><span class="math display">\[Vol(\mathcal K \cap \{x \in \mathbb R^n
: x^T w \geq 0\}) \geq \frac 1 e Vol(\mathcal K)\]</span></p></li>
</ul>
<p>这告诉我们每个新的多边形和原多边形之间有一个体积关系是 <span class="math inline">\(Vol(S_{t+1}) \leq (1-\frac 1 e) Vol(S_t) \leq
\cdots \leq (1-\frac 1 e)^t Vol(S_1)\)</span>，再对于 <span class="math inline">\(\varepsilon = (1-\frac 1 e)^{t/n}\)</span> 取
<span class="math inline">\(\mathcal S_\varepsilon = \{(1-\varepsilon
)x^* + \varepsilon x, \forall x \in S_1\}\)</span>，实际上是对 <span class="math inline">\(S_1\)</span> 做了一个仿射变换。此时有 <span class="math inline">\(Vol(S_\varepsilon)=\varepsilon^n Vol(S_1) =
(1-\frac 1 e)^tVol(S_1) \geq Vol(S_{t+1})\)</span>，于是可以找到一个
<span class="math inline">\(x_\varepsilon \in S_\varepsilon\)</span>
使其在 <span class="math inline">\(t\)</span> 时刻时仍在 <span class="math inline">\(S_t\)</span> 中，而 <span class="math inline">\(t+1\)</span> 时刻就被“裁剪”了出去。</p>
<p>所以有</p>
<p><span class="math display">\[c^Tx_{t+1} &lt; c^Tx_\varepsilon =
c^T((1-\varepsilon)x^*+ \varepsilon x) \leq c^Tx^* + 2B\varepsilon
=c^Tx^*+2B(1-\frac 1 e)^{t/n}\]</span></p>
<p>也就是说 <span class="math inline">\(c^Tx_{t+1} - c^Tx^* &lt;
2B(1-\frac 1 e)^{t/n}\)</span> 作为 <span class="math inline">\(t+1\)</span> 时刻下取值距离 optimal cost
的误差可以被控制，并且我们可以在 <span class="math inline">\(O(n
\log(\frac{1}{\varepsilon}))\)</span> 时间下得到误差为 <span class="math inline">\(\varepsilon\)</span> 的 cost 和 solution。这比
simplex method 误差大一些，但是 polynomial time algorithm。</p>
<h2 id="the-ellipsoid-method">The Ellipsoid Method</h2>
<p><del>讲这个的时候我太困了，上楼找了个教室睡觉，没听。我估计我困成那样听也听不懂，他这个手稿太抽象了也看不大懂，貌似书上也没这一部分，哥们有点子崩溃（。等
scribing 了。</del></p>
<p>我都学会了 scribing 还没出来，自己写一个吧。</p>
<h3 id="notations-1">Notations</h3>
<p>首先是一些记号：</p>
<p><img src="https://s2.loli.net/2023/09/26/PEzuQl2MOW37Jr1.jpg" alt="mi1.jpg"></p>
<ul>
<li><p>A set <span class="math inline">\(E\)</span> of vectors in <span class="math inline">\(\mathbb R^N\)</span> of the form <span class="math inline">\(E = E(z,D) = \{x \in \mathbb R^n \mid (x- z)^T
D^{-1} (x-z) \leq1 \}\)</span>, where <span class="math inline">\(D\)</span> is an <span class="math inline">\(n
\times n\)</span> positive definite symmetric matrix, is called an
ellipsoid with center <span class="math inline">\(z \in \mathbb
R^n\)</span>.</p></li>
<li><p>If <span class="math inline">\(D\)</span> is a <span class="math inline">\(n \times n\)</span> nonsingular matrix and <span class="math inline">\(b \in \mathbb R^n\)</span>, then the mapping <span class="math inline">\(S: \mathbb R^n \to \mathbb R^n\)</span> defined by
<span class="math inline">\(S(x) = Dx + b\)</span>, is called an affine
transformation.</p></li>
</ul>
<p>注意到仿射变换都是可逆的，所以可以把仿射变换的像定义成</p>
<ul>
<li><span class="math inline">\(S(L) = \{y \in \mathbb R^n \mid y = Dx
+b, \text{for some } x\in L \}\)</span></li>
<li>The volume of a set <span class="math inline">\(L \in \mathbb
R^n\)</span>, which is denoted by <span class="math inline">\(Vol(L)\)</span>, is defined as <span class="math inline">\(Vol(L) = \int_{x \in L}dx\)</span></li>
</ul>
<p>然后就可以得到仿射变换后的体积是</p>
<ul>
<li><p>If <span class="math inline">\(S(x) = Dx + b\)</span> then <span class="math inline">\(Vol(S(L)) = |det(D)| Vol(L)\)</span></p>
<p><strong>Proof</strong>: <span class="math inline">\(Vol(S(L)) =
\int_{y \in S(L)} dy = \int_{x \in L} |det(D)| dx = |det(D)|
Vol(L)\)</span></p></li>
</ul>
<h3 id="algorithm">Algorithm</h3>
<p>目标是考虑一个 <span class="math inline">\(Ax \geq b\)</span>
形式的优化问题的 feasible set，也就是一个 polyhedron <span class="math inline">\(P\)</span> 是否是空集的问题，可以用一个 Ellipsoid
Algorithm
来解决。既然是用迭代算法解决，其实就不能太苛求精细程度，我们约定最后得到的覆盖椭圆的面积小于
<span class="math inline">\(\varepsilon\)</span> 时就认为 <span class="math inline">\(P\)</span> 是一个空集。</p>
<p>首先考虑一个覆盖所求 polyhedron <span class="math inline">\(P\)</span> 的椭圆 <span class="math inline">\(E_t\)</span>，如果其中心 <span class="math inline">\(x_t \in P\)</span> 则找到了一个 <span class="math inline">\(P\)</span> 中的解，可以得出 <span class="math inline">\(P\)</span> 是非空的；如果 <span class="math inline">\(x_t \notin P\)</span> 那么 <span class="math inline">\(x_t\)</span> 一定违反了其中的某个 constraint <span class="math inline">\(a_i ^Tx \geq b_i\)</span>，<span class="math inline">\(P\)</span> 一定在 halfspace <span class="math inline">\(\{x \in \mathbb R^n \mid a_i^T x \geq a_i^Tx_t
\}\)</span> 和 <span class="math inline">\(E_t\)</span>
的交集里，这样我们再做一个新的更小的椭圆 <span class="math inline">\(E_{t+1}\)</span>
来覆盖这一部分，就可以继续这一算法。</p>
<p>来个我非常喜欢的图！</p>
<p><img src="https://s2.loli.net/2023/10/21/Y79yhqJDgElijmI.png" alt="ellipsoid_method.png"></p>
<p>现在需要解决的问题仍然是 termination 问题，也就是是否 <span class="math inline">\(E_{t+1}\)</span> 的体积一定比 <span class="math inline">\(E_t\)</span>
更小。以下定理保证了它们的体积之间一定有一个指数级的减少：</p>
<ul>
<li><p>Let <span class="math inline">\(E = E(z,D)\)</span> be an
ellipsoid in <span class="math inline">\(\mathbb R^n\)</span>, and let
<span class="math inline">\(a\)</span> be a nonzero vector. Consider the
halfspace <span class="math inline">\(H = \{x \in \mathbb R ^n \mid a^Tx
\geq a^T z \}\)</span> and let</p>
<p><span class="math display">\[\bar z = z +
\frac{1}{n+1}  \frac{Da}{\sqrt{a^TDa}}\]</span></p>
<p><span class="math display">\[\bar D = \frac{n^2}{n^2-1} (D -
\frac{2}{n+1} \frac{Daa^TD}{a^TDa})\]</span></p>
<p>Then <span class="math inline">\(\bar D\)</span> is positive definite
and the new ellipsoid <span class="math inline">\(\bar E = E(\bar z,
\bar D)\)</span> satisfies the following properties:</p>
<ul>
<li><span class="math inline">\(E \cap H \subset \bar E\)</span></li>
<li><span class="math inline">\(Vol(\bar E) &lt; e^{-1/(2(n+1))}
Vol(E)\)</span></li>
</ul>
<p><strong>Proof</strong>: First consider <span class="math inline">\(a
= e_1. D = I_{n \times n}\)</span> and the center of <span class="math inline">\(E_0\)</span> as <span class="math inline">\(z =
0\)</span>. It's trivial to see that the first property holds. In this
case the positive definite matrix of <span class="math inline">\(\bar
E_0\)</span> is <span class="math inline">\(D = diag((\frac{n}{n+1})^2,
\frac{n^2}{n^2-1}, \cdots,\frac{n^2}{n^2-1})\)</span>, and the center is
<span class="math inline">\(a =
(\frac{1}{n+1},0,\cdots,0)^T\)</span>.</p>
<p>Now by constructing an affine transformation we can consider the
general case. The transformation T should let <span class="math inline">\(T(E) = E_0, T(H) = H_0\)</span> and <span class="math inline">\(T(\bar E) = \bar E_0\)</span>. By some elementary
observations we can obtain that affine transformations preserve set
inclusion, i.e. if <span class="math inline">\(E_0 \cap H_0 \subset \bar
E_0\)</span>, then there is <span class="math inline">\(T(E_0) \cap
T(H_0) \subset T(\bar E_0)\)</span>, therefore the first property holds
naturally.</p>
<p>Let <span class="math inline">\(R\)</span> be the rotation matrix
corresponding to the vector <span class="math inline">\(u = D^{\frac 1
2} a\)</span>, i.e.,</p>
<p><span class="math display">\[R^TR = I, \quad RD^{\frac 1 2}a_i =
\|D^{\frac 1 2} a_i \| e_1\]</span></p>
<p>Consider the following affine transformation:</p>
<p><span class="math display">\[T(x) = R(D^{-\frac 1
2}(x-z))\]</span></p>
<p>Therefore,</p>
<p><span class="math inline">\(\begin{aligned} x \in E &amp; \iff
(x-z)^TD^{-1}(x-z)\leq 1 \\ &amp; \iff (x-z)^TD^{-\frac 1
2}R^TRD^{-\frac 1 2}(x-z)\leq 1 \\ &amp; \iff T(x)^T T(x) \leq 1 \\
&amp; \iff T(x) \in E_0, \end{aligned}\)</span></p>
<p>which implies that <span class="math inline">\(T(E) =
E_0\)</span>.</p>
<p>Similarly,</p>
<p><span class="math display">\[\begin{aligned} x \in H &amp; \iff
a_i^T(x-z )\geq 0 \\ &amp; \iff \|D^{-\frac 1 2}a_i \| e_1 ^T RD^{-\frac
1 2} (x-z) \geq 0 \\ &amp; \iff e_1 ^T T(x) \geq 0 \\ &amp; \iff T(x)
\in H_0,  \end{aligned}\]</span></p>
<p>which implies <span class="math inline">\(T(H) = H_0\)</span>.</p>
<p>Moreover there is also <span class="math inline">\(T(\bar E) = \bar
E_0\)</span> and we omit the complicated algebraic manipulations.
Therefore <span class="math inline">\(E \cap H \subset \bar E\)</span>
holds according to the properties of affine transformation. Next we
prove the conclusion about the volume.</p>
<p><span class="math inline">\(\frac{Vol(\bar E)}{Vol(E)} =
\frac{Vol(T(\bar E))}{Vol(T(E))} = \frac{Vol(\bar E_0)}{Vol(E_0)} =
det(D_0 ^{\frac 1 2}) =
(\frac{n}{\sqrt{n^2-1}})^{n-1}(\frac{n}{n+1})\)</span></p>
<p>Consider</p>
<p><span class="math display">\[(\frac{n^2}{n^2-1})^{\frac{n-1}{2}}(\frac{n}{n+1})
= (1+\frac{1}{n^2-1})^{\frac{n-1}{2}}(1-\frac{1}{n+1}) \leq
(e^{\frac{1}{n^2-1}})^{\frac{n-1}{2}} e^{-\frac{1}{n+1}}
=  e^{-\frac{1}{2(n+1)}},\]</span></p>
<p>and the desired result follows.</p></li>
</ul>
<p>另外如果估计得再精细一点的话下界其实是 <span class="math inline">\(\exp(-\frac{1}{2n})\)</span>（详见
Bubeck），可以对函数求导做。</p>
<p>所以只要初始状态的 ellipsoid
体积有限，算法一定会在有限时间内终止，可以用来解决 feasiblility
的问题，这是一个可以在 <span class="math inline">\(O(n \log
\varepsilon)\)</span> 时间内结束的算法，实际上对于找 feasible solution
来说还是很快的。但 feasible solution
一个单点对于优化问题来说其实没什么用，我们的目标仍然是寻找 optimal
cost，为此需要一些类似于 center of gravity method 的方法。</p>
<p>另外 ellipsoid method 也可以用来解决 optimal cost
的逼近，有这样一个体积关系了之后原理和 center of gravity method
类似：</p>
<p><del>每个新的 ellipsoid 和上一时刻 ellipsoid 之间有一个体积关系是
<span class="math inline">\(Vol(S_{t+1}) \leq \exp(-\frac{1}{2n})
Vol(S_t) \leq \cdots \leq \exp(-\frac{t}{2n}) Vol(S_1)\)</span>，再对于
<span class="math inline">\(\varepsilon = \exp(-\frac{t}{2n^2})\)</span>
取 <span class="math inline">\(\mathcal S_\varepsilon = \{(1-\varepsilon
)x^* + \varepsilon x, \forall x \in S_1\}\)</span>，实际上是对 <span class="math inline">\(S_1\)</span> 做了一个仿射变换。此时有 <span class="math inline">\(Vol(S_\varepsilon)=\varepsilon^n Vol(S_1) =
\exp(-\frac{t}{2n}) Vol(S_1) \geq
Vol(S_{t+1})\)</span>，于是可以找到一个 <span class="math inline">\(x_\varepsilon \in S_\varepsilon\)</span> 使其在
<span class="math inline">\(t\)</span> 时刻时仍在 <span class="math inline">\(S_t\)</span> 中，而 <span class="math inline">\(t+1\)</span> 时刻就被“裁剪”了出去。</del></p>
<p><del>所以有：</del></p>
<p><del><span class="math display">\[c^Tx_{t+1} &lt; c^Tx_\varepsilon =
c^T((1-\varepsilon)x^*+ \varepsilon x) \leq c^Tx^* + 2B\varepsilon
=c^Tx^*+2B \exp(-\frac{t}{2n^2}),\]</span></del></p>
<p><del>也就是说 <span class="math inline">\(c^Tx_{t+1} - c^Tx^* &lt; 2B
\exp(-\frac{t}{2n^2})\)</span> 作为 <span class="math inline">\(t+1\)</span> 时刻下取值距离 optimal cost
的误差可以被控制，并且我们可以在 <span class="math inline">\(O(n^2
\log(\frac{1}{\varepsilon}))\)</span> 时间下得到误差为 <span class="math inline">\(\varepsilon\)</span> 的 cost 和
solution。同样是得到的 cost 比 simplex method 误差大一些并非精确值，但是
polynomial time algorithm，虽然比起 center of gravity method
来说消耗更大，但也有它的优势。</del></p>
<p>之前的想法一直有大问题，我当时也没怎么看懂 Bubeck
那本书的内容，更是完全不理解为什么 time usage 里面还有 <span class="math inline">\(R/r\)</span>
的项。今晚做出来优化作业第一题之后醍醐灌顶，直接复制到这里来就很清楚了。</p>
<p><strong>Problem</strong>: Consider the following convex optimization
problem (<span class="math inline">\(f,g_i\)</span> are convex):</p>
<p><span class="math display">\[\text{minimize} \quad f(x)\]</span></p>
<p><span class="math display">\[\text{subject to} \quad g_i(x) \leq 0,
i=1,2,\cdots,m.\]</span></p>
<p>Let <span class="math inline">\(\mathcal K = \{x \mid g_i(x) \leq 0,
i=1,2,\cdots,m\}\)</span>. Assume that there exists <span class="math inline">\(x_,x_0^\prime\)</span> s.t. <span class="math inline">\(\mathcal K\)</span> is between balls of radius
<span class="math inline">\(r,R\)</span>,</p>
<p><span class="math display">\[B(x_0,r) \subseteq \mathcal K \subseteq
B(x_0^\prime,R)\]</span></p>
<p>Further assume that <span class="math inline">\(\sup_{x \in \mathcal
K} |f(x)| \leq B\)</span>. Given any <span class="math inline">\(x \in
\mathbb R^n\)</span> one can evaluate <span class="math inline">\(f(x),g_i(x), \nabla f(x) , \nabla g_i(x)\)</span>.
Propose an efficient implementation of the Ellipsoid's method. Prove
that the algorithm converges in <span class="math inline">\(\mathcal
O(n^2 \log(\frac{BR}{r \varepsilon}))\)</span> iterations to find an
<span class="math inline">\(\varepsilon\)</span> optimal solution.</p>
<p><strong>Solution</strong>: To begin the algorithm, we set <span class="math inline">\(\mathcal E_0 = B(x_0^\prime, R)\)</span> and <span class="math inline">\(c_0 = x_0^\prime\)</span> as its center. At time
<span class="math inline">\(t\)</span> we divide the possible results
into two situations as follows.</p>
<ul>
<li><p>If <span class="math inline">\(c_t \notin \mathcal K\)</span>,
then there is some constraints <span class="math inline">\(g_i(x) \leq
0\)</span> violated so that <span class="math inline">\(c_t\)</span>
does not lie in the feasible set. We find the violated constraints by
calling the zeroth order oracle <span class="math inline">\(g_i(c_t)\)</span> and compare their value with
<span class="math inline">\(0\)</span>. To save the computational source
we just pick the violated constraint <span class="math inline">\(g_i(c_t) &gt;0\)</span> with the smallest
subscript, and number it as <span class="math inline">\(g_i^{(t)}\)</span>.</p>
<p>Thus the feasible set <span class="math inline">\(\mathcal K\)</span>
lies in <span class="math inline">\(\mathcal E _t \cap \{x \mid g_i
^{(t)} (x) \leq g_i ^{(t)} (c_t)\} \subseteq \mathcal E _t \cap \{x \mid
\nabla g_i^{(t)}(c_t)^T (x-c_t) \leq 0\}\)</span> according to the
definition of subgradient. And the exact value of subgradient <span class="math inline">\(\nabla g_i^{(t)}(c_t)\)</span> can be obtained by
calling the first order oracle <span class="math inline">\(\nabla
g_i^{(t)}\)</span>.</p>
<p>Then we can just construct the <span class="math inline">\((t+1)\)</span>-th ellipsoid by covering the set
shown above, i.e. <span class="math inline">\(\mathcal E_{t+1} \supseteq
\mathcal E _t \cap \{x \mid \nabla g_i^{(t)}(c_t)^T (x-c_t) \leq
0\}\)</span>.</p></li>
<li><p>The second case is much easier. If we found <span class="math inline">\(c_t \in \mathcal K\)</span>, by considering the
subset <span class="math inline">\(\mathcal E_t \cap \{ x \mid f(x) &lt;
f(c_t)\} \subseteq \mathcal E_t\)</span>, we can either find <span class="math inline">\(c_t\)</span> is optimal by observing that the set
is empty or found a better solution through iteration.</p>
<p>According to the definition of subgradient, there is <span class="math inline">\(\mathcal E_t \cap \{x \mid f(x) &lt; f(c_t)\}
\subseteq \mathcal E_t \cap \{ x \mid \nabla f(c_t)^T (x-c_t) \leq
0\}\)</span>. Then we can just construct the <span class="math inline">\((t+1)\)</span>-th ellipsoid by covering the set
shown above, i.e. <span class="math inline">\(\mathcal E_{t+1} \supseteq
\mathcal E _t \cap \{ x \mid \nabla f(c_t)^T (x-c_t) \leq 0\}\)</span>,
in which the value of subgradient <span class="math inline">\(\nabla
f(c_t)\)</span> can be obtained by calling the first order oracle <span class="math inline">\(\nabla f\)</span>.</p></li>
</ul>
<p>For both situations, we can obtain <span class="math inline">\(\mathcal E_{t+1}\)</span> with the least volume
such that <span class="math inline">\(Vol(\mathcal E_{t+1} ) \leq
\exp(-\frac{1}{2n}) Vol(\mathcal E_t)\)</span> according to the theorem
we proved in class (and we can construct the exact form of <span class="math inline">\(\mathcal E_{t+1}\)</span> through the complex
equation, which won't be shown again in this solution).</p>
<p>Therefore, if <span class="math inline">\(t \geq 2n^2
\log(\frac{R}{r})\)</span> there is <span class="math inline">\(Vol(\mathcal E_t) \leq Vol(B(x_0,r))\)</span> and
<span class="math inline">\(\{c_1,c_2,\cdots,c_t\} \cap \mathcal K \neq
\varnothing\)</span>. From now on we only consider the time that ensures
<span class="math inline">\(\{c_1,c_2,\cdots,c_t\} \cap \mathcal K \neq
\varnothing\)</span>.</p>
<p>For fixed <span class="math inline">\(\varepsilon &gt;0\)</span>, we
take <span class="math inline">\(\mathcal K_\varepsilon =
\{(1-\varepsilon)x^* + \varepsilon x \mid \forall x \in
B(x_0,r)\}\)</span> as an affine transformation, in which <span class="math inline">\(x^*\)</span> is the optimal solution of this
problem. Moreover we denote <span class="math inline">\(x_t \triangleq
\arg \min_{c_s \in \{c_0,c_1,\cdots, c_t\} \cap \mathcal K}
f(c_s)\)</span>.</p>
<p>When we take <span class="math inline">\(\varepsilon = \frac{R}{r}
\exp(-\frac{t}{2n^2})\)</span> there is <span class="math display">\[Vol(\mathcal K_\varepsilon ) = \varepsilon^n
Vol(B(x_0,r)) = \varepsilon^n (\frac{r}{R})^n Vol(B(x_0^\prime ,R)) =
\exp(-\frac{t}{2n^2}) Vol(B(x_0^\prime, R)) &gt; Vol(\mathcal
E_t)\]</span></p>
<p>This inequality implies that there exists one time <span class="math inline">\(r \in \{1,2,\cdots,t\}\)</span> s.t. there exists
<span class="math inline">\(x_\varepsilon \in \mathcal
K_\varepsilon\)</span>, <span class="math inline">\(x_\varepsilon \in
\mathcal E_{r-1}\)</span>, but <span class="math inline">\(x_\varepsilon
\notin \mathcal E_r\)</span>, therefore <span class="math inline">\(x_\varepsilon\)</span> is not optimal. According
to the convexity of <span class="math inline">\(f(x)\)</span>, there is
<span class="math display">\[f(x_t) &lt; f(c_r)
\leq  f(x_\varepsilon)  = f((1-\varepsilon)x^* + \varepsilon x_r) \leq
(1-\varepsilon) f(x^*) + \varepsilon f(x_r) \leq f(x^*) +
2B\varepsilon,\]</span> which implies that <span class="math display">\[f(x_t) - f(x^*) \leq 2B\varepsilon =
\frac{2BR}{r} \exp(-\frac{t}{2n^2}).\]</span></p>
<p>Then we can conclude that the algorithm converges in <span class="math inline">\(\mathcal O(n^2 \log(\frac{BR}{\varepsilon
r}))\)</span> iterations to find an <span class="math inline">\(\varepsilon\)</span> optimal solution, and the
desired result follows.</p>
<h1 id="lecture-4">Lecture 4</h1>
<p>睡了（，等个笔记（（</p>
<p>10.23 UPD：今天布置了个优化 HW3
但又迅速删掉了，我也不知道为什么要同时把讲义也删掉，当时正好在贴所以也没来得及下（。这助教是否也是一个优化算法控制的，要传就把所有的东西都传上来要删就全部删掉，来保证要么所有人都满意要么所有人都不满意（。</p>
<h2 id="convex-optimization">Convex Optimization</h2>
<h3 id="notations-2">Notations</h3>
<p>#每日迷神</p>
<p><img src="https://s2.loli.net/2023/09/26/PEzuQl2MOW37Jr1.jpg" alt="mi1.jpg"></p>
<ul>
<li>A set <span class="math inline">\(C \in \mathbb R^n\)</span> is
affine iff for any <span class="math inline">\(x,y \in C\)</span> and
any <span class="math inline">\(\theta \in \mathbb R\)</span>, there is
<span class="math inline">\(\theta x + (1-\theta) y \in C\)</span>,
therefore the whole line lies in <span class="math inline">\(C\)</span>.
<ul>
<li>Therefore, if <span class="math inline">\(C\)</span> is an affine
set and <span class="math inline">\(x_0 \in C\)</span>, then the set
<span class="math inline">\(V = \{x-x_0 \mid \forall x \in C\}\)</span>
is a subspace.</li>
</ul></li>
<li>An affine hull of <span class="math inline">\(C\)</span> is denoted
as <span class="math inline">\(aff(C) = \{\theta_1 x_1+ \theta_2
x_2+\cdots+ \theta_k x_k \mid \forall k \in \mathbb Z_+, x_i \in C,
\theta_i \in \mathbb R \}\)</span></li>
<li>The relative interior <span class="math inline">\(relint(C) = \{x\in
C \mid \exist r &gt;0 , \text{s.t. } B(x,r) \cap aff(C) \subseteq C
\}\)</span></li>
</ul>
<p>简单来说，affine set/affine hull 和 convex
版本的唯一区别就是参数不需要取在 <span class="math inline">\([0,1]\)</span> 之间，所以它一般是个平面。</p>
<ul>
<li><p>A set <span class="math inline">\(C\)</span> is called a cone iff
<span class="math inline">\(\forall x \in C\)</span> and for any <span class="math inline">\(\theta &gt; 0\)</span>, there is <span class="math inline">\(\theta x \in C\)</span>.</p></li>
<li><p>(Extended convex function) A function <span class="math inline">\(f : \mathbb R^n \to \mathbb R\)</span> is convex,
we can extend its domain <span class="math inline">\(dom(f)\)</span> to
<span class="math inline">\(\mathbb R^n\)</span> by taking <span class="math inline">\(f(x) = \infty\)</span> for any <span class="math inline">\(x \notin dom(f)\)</span>.</p></li>
<li><p>(Epigraph of a function) <span class="math inline">\(epi(f) =
\{(x,t) \mid t \geq f(x)\}\)</span></p>
<p>Therefore <span class="math inline">\(f\)</span> is a convex function
if and only if <span class="math inline">\(epi(f)\)</span> is a convex
set.</p></li>
</ul>
<h3 id="basic-theorems">Basic Theorems</h3>
<ul>
<li><p>(Seperating Hyperplane Theorem) Suppose <span class="math inline">\(C,D\)</span> are nonempty disjoint convex sets,
then there exists <span class="math inline">\(a \neq 0\)</span>, <span class="math inline">\(a,b \in \mathbb R^n\)</span> s.t. <span class="math inline">\(C \subseteq \{x \in \mathbb R^n \mid a^Tx \leq
b\}\)</span> and <span class="math inline">\(D \subseteq \{x \in \mathbb
R^n \mid a^Tx \geq b\}\)</span>.</p>
<p><strong>Proof</strong>: We only consider the case when <span class="math inline">\(C,D\)</span> are both closed and bounded.</p>
<p>Define <span class="math inline">\(dist(C,D) = \inf\{\|u-v\|_2 \mid u
\in C,v \in D \}\)</span> as the distance between <span class="math inline">\(C,D\)</span>, then by closed and boundness we can
find <span class="math inline">\(c \in C, d \in D\)</span> s.t. <span class="math inline">\(dist(C,D) = \|c-d\|_2\)</span>. Take <span class="math inline">\(a = d-c\)</span>, <span class="math inline">\(b =
\frac 1 2 (\|d\|_2^2 - \|c\|_2^2)\)</span>.</p>
<p>Then the affine transformation <span class="math inline">\(f(x) =
a^Tx - b\)</span> will let <span class="math inline">\(f(x)
&lt;0\)</span> for any <span class="math inline">\(x \in D\)</span>, and
<span class="math inline">\(f(x) &gt;0\)</span> for any <span class="math inline">\(x \in C\)</span>.</p></li>
<li><p>(Supporting Hyperplane Theorem) Suppose <span class="math inline">\(C\)</span> is convex, then for any <span class="math inline">\(x \in bd(C)\)</span> here exists a supporting
vector <span class="math inline">\(a \neq 0, a \in \mathbb R^n\)</span>,
s.t. <span class="math inline">\(\forall x \in C\)</span>, <span class="math inline">\(a^Tx_0 \leq a^Tx\)</span>. (<span class="math inline">\(bd(C)\)</span> is the boundary of <span class="math inline">\(C\)</span>)</p></li>
</ul>
<p>别的没什么了，convex function
的性质什么的真没必要再写一遍了，他又不讲 subgradient。</p>
<h1 id="lecture-5">Lecture 5</h1>
<p>才隔了两周，今天怎么又是哥们在做 scribing 啊（。read-only 的链接在<a href="https://www.overleaf.com/read/tvswmtjkgtsp#b147f8">这里</a>。</p>
<p>今天讲一些 convex optimization 里的例子，给哥们整的一愣一愣的。</p>
<h2 id="examples-in-convex-optimization">Examples in Convex
Optimization</h2>
<h3 id="notations-3">Notations</h3>
<p>#每日迷神</p>
<p><img src="https://s2.loli.net/2023/09/26/PEzuQl2MOW37Jr1.jpg" alt="mi1.jpg"></p>
<p>你还别说现在还真不一定书上都有了，那个 max cut 给哥们整不会了，Boyd
上面没写，Bubeck 就写了一点而且还把课上的内容跳过去了。而且 Bubeck
本来就简略，看了个寂寞。</p>
<ul>
<li><p>The following optimization problem is called a convex
optimization problem if <span class="math inline">\(x_0, f_i\)</span>
are convex, and <span class="math inline">\(h_i\)</span> are linear:</p>
<p><span class="math display">\[\begin{aligned}
\textbf{minimize}  \quad &amp; f_0(x) \\
\textbf{subject to} \quad &amp; f_i(x) \leq 0 \\
&amp; h_i (x) =0
\end{aligned}\]</span></p></li>
<li><p><span class="math inline">\(x\)</span> is a <span class="math inline">\(\varepsilon\)</span>-suboptimal if <span class="math inline">\(f_0(x) \leq p^* + \varepsilon\)</span>, in which
<span class="math inline">\(p^*\)</span> is the optimal value of the
convex optimization problem.</p></li>
<li><p><span class="math inline">\(x_0\)</span> is locally optimal if
there exists <span class="math inline">\(R &gt;0\)</span> s.t. <span class="math inline">\(x_0\)</span> is the optimal solution to:</p></li>
</ul>
<p>​ <span class="math display">\[\begin{aligned}
   \textbf{minimize}  \quad &amp; f_0(x) \\
   \textbf{subject to} \quad &amp; f_i(x) \leq 0 \\
   &amp; h_i (x) =0 \\
   &amp; \|x-x_0\| \leq R \end{aligned}\]</span></p>
<h3 id="why-convex-optimization">Why Convex Optimization?</h3>
<p>为什么研究凸优化？一个是 linear programming problem
有它的局限性，许多问题只能往凸优化的方向转化。另外凸性质实际上是非常美妙的。下面是一个很
trivial 的例子，我们对 convex optimization
的转化问题的探究远不止于此。</p>
<p>Why is convex optimization important? That's because some non-convex
problems have underlying convexity. For example, we consider the
following optimization problem:</p>
<p><span class="math display">\[\begin{aligned}
\textbf{minimize}  \quad &amp; f_0(x)=x_1^2+x_2^2 \\
\textbf{subject to} \quad &amp; f_1(x) = \frac{x_1}{1+x_2^2} \leq 0 \\
&amp; h_i (x) = (x_1+x_2)^2 =0
\end{aligned}\]</span></p>
<p>which can easily be transformed into a standard convex optimization
problem.</p>
<h2 id="example-max-cut-problem">Example: Max Cut Problem</h2>
<p>别 TCS 了求你了求你了求你了（</p>
<p>通过一个 max cut problem 来体现从 nonconvex optimization 向 convex
optimization 的转化，从方法论的层面上来说是两步。</p>
<p>Why are convex optimization problems important? That's because many
non-convex optimization problems can be transformed into convex ones,
and we can solve convex optimization problems through mature
technologies. Generally speaking, the process contains two steps:</p>
<ol type="1">
<li>First, transform the non-convex problem into convex ones through
relaxation.</li>
<li>Next recover a solution from the convex problem to the non-convex
one through random rounding.</li>
</ol>
<h3 id="notations-4">Notations</h3>
<ul>
<li>A cut in an undirected graph <span class="math inline">\(G = (V,
\mathcal E)\)</span> is defined as <span class="math inline">\(A
\subseteq V\)</span>.The capacity of a cut <span class="math inline">\(A\)</span> is defined as <span class="math inline">\(c(A) = | \{(u,v)\in \mathcal E \mid u \in A, u \in
A^c\}|\)</span>.</li>
</ul>
<p>而 max cut 问题就是寻找最大的 <span class="math inline">\(c(A)\)</span>，尽管我不知道这样做有什么意义，但它是
NP-hard 的。所以我们只需要找到一个 polynomial time
的算法就可以证明...（逃</p>
<ul>
<li>​ An <span class="math inline">\(\alpha\)</span>-approximate max cut
is a cut <span class="math inline">\(A\)</span> s.t. <span class="math inline">\(c(A) \geq \alpha \max_{U \subseteq V}
c(U)\)</span>.</li>
</ul>
<h3 id="frac-1-2-approximate-approach"><span class="math inline">\(\frac
1 2\)</span>-Approximate Approach</h3>
<p>怎么是概率做法，真稀奇。</p>
<p>To be more specific, we can give a <span class="math inline">\(\frac{1}{2}\)</span>-approximate max cut by
randomly adding each point <span class="math inline">\(v\)</span> in
<span class="math inline">\(V\)</span> to the cut <span class="math inline">\(A\)</span> with probability <span class="math inline">\(\frac{1}{2}\)</span>. Consider the expectation of
<span class="math inline">\(c(A)\)</span> here and we can get:</p>
<p><span class="math display">\[\mathbb E_A(c(A)) = \mathbb E_A
\sum_{(u,v)\in \mathcal E} 1_{(u \in A,v \in A^c)} = \sum_{(u,v) \in
\mathcal E} P(u \in A, v \in A^c) = \sum_{(u,v) \in \mathcal E}
\frac{1}{2} = \frac{|\mathcal E|}{2}.\]</span></p>
<p>然而这还是很粗糙。</p>
<h3 id="linear-approach">Linear Approach</h3>
<p>如果没有 convex optimization 的话就是考虑一些 linear programming
的近似，举两个失败的 approach 说明这很困难：</p>
<ul>
<li><p>Consider the following formulation of the problem:</p>
<p><span class="math display">\[\begin{aligned}
    \textbf{maximize}_{x\in \mathbb R^n} \quad &amp; \sum_{(u,v)\in
\mathcal E} \frac{1}{2}(1-x_ux_v) \\
    \textbf{subject to} \quad &amp; x_v \in \{-1,1\}
\end{aligned}\]</span></p></li>
<li><p>This is not a linear programming problem, and we can transform it
by denoting <span class="math inline">\(z_e = x_ux_v, e=(u,v) \in
\mathcal{E}\)</span>:</p>
<p><span class="math display">\[\begin{aligned}
    \textbf{maximize}_{x,z} \quad &amp; \sum_{e \in E} \frac{1}{2 }
(1-z_e) \\
    \textbf{subject to} \quad &amp; z_{(u,v)} \geq -x_u -x_v -1 \\
     &amp; z_{(u,v)} \geq x_u +x_v -1 \\
     &amp; x_v \in [-1,1]
\end{aligned}\]</span></p></li>
</ul>
<p>However, this still fails for we can choose <span class="math inline">\(x_v =x_u=0\)</span> and <span class="math inline">\(z_{(u,v)} =-1\)</span> in the feasible set, which
means the approach will only give a randomized choice of <span class="math inline">\(A\)</span>. Now turn to convex optimization for
help.</p>
<h3 id="convex-transformation">Convex Transformation</h3>
<ul>
<li><p>The basic idea is to replace <span class="math inline">\(x_u.x_v\)</span> with <span class="math inline">\(n-1\)</span> dimensional vectors and construct an
auxiliary problem, which is called semi-definite relaxation:</p>
<p><span class="math display">\[\begin{aligned}
    \textbf{maximize} \quad &amp; \sum_{(u,v) \in \mathcal E}
\frac{1}{2} (1-x_u^Tx_v) \\
    \textbf{subject to} \quad &amp; x_u \in S^{n-1} \text{ for any
}u=1,2,\cdots,n
\end{aligned}\]</span></p>
<p>in which <span class="math inline">\(S^{n-1}\)</span> is the unit
sphere in <span class="math inline">\(\mathbb R^{n-1}\)</span>. Observe
that <span class="math inline">\(\frac{1}{4}\|x_u-x_v\|^2 =\frac{1}{4}
(x_u -x_v)^T(x_u-x_v) = \frac{1}{2} (1-x_ux_v)\)</span>, and <span class="math inline">\(\frac{1}{2} \sum_{e \in \mathcal E} (1-z_e) =
\frac{1}{4} \sum_{(u,v)\in \mathcal E} \|x_u - x_v\|^2\)</span>.</p>
<p>Now we take <span class="math inline">\(\text{Maxcut}^\circ
(C)\)</span> as the optimal cost of the auxiliary problem and denote
<span class="math inline">\(\text{Maxcut} (C)\)</span> as the optimal
cost of the original problem. Then there is <span class="math inline">\(\text{Maxcut} (C) \leq \text{Maxcut}^\circ
(C)\)</span> because any optimal solution of the original problem can be
transformed into a feasible solution in the auxiliary one.</p>
<p>To be more precise, if <span class="math inline">\(\{x_u\}\)</span>
is an optimal solution to the original problem, then for any <span class="math inline">\(x_u = 1\)</span> there is <span class="math inline">\(x_v = -1\)</span> for each <span class="math inline">\(v \in \{v \mid (u,v) \in \mathcal E\}\)</span>.
Therefore we can take <span class="math inline">\(x_u = e_1\)</span>,
<span class="math inline">\(x_v = -e_1\)</span> for any <span class="math inline">\(v \in \{v \mid (u,v) \in \mathcal E\}\)</span> as
a feasible solution to the auxiliary problem, and the cost is equal to
the optimal cost of the original one.</p></li>
<li><p>However the auxiliary problem is still non-convex, we'd like to
consider another optimization problem as follows:</p>
<p><span class="math display">\[\begin{aligned}
    \textbf{minimize} \quad &amp; X \cdot A = \sum_{i,j \in V} X_{ij}
A_{ij} \\
    \textbf{subject to} \quad &amp; X \geq 0 \;  \\
     &amp; X_{ii}=1
\end{aligned}\]</span></p>
<p>in which <span class="math inline">\(X \geq 0\)</span> means <span class="math inline">\(X\)</span> is semi-definite, i.e. <span class="math inline">\(X \in S_+^n, X \in \mathbb R^{n \times
n}\)</span>.</p>
<p>We set <span class="math inline">\(A_{ij}=1\)</span> if <span class="math inline">\((i,j) \in \mathcal E\)</span>, else <span class="math inline">\(A_{ij}=0\)</span>. Now we prove that the two
problems above are equivalent.</p></li>
<li><p>The following two max-cut optimization problems are
equivalent:</p></li>
</ul>
<p>​ <span class="math display">\[\begin{aligned}
  ​            \textbf{maximize} \quad &amp; \sum_{(u,v) \in \mathcal E}
\frac{1}{2} (1-x_u^Tx_v) \\
  ​    \textbf{subject to} \quad &amp; x_u \in S^{n-1} \\
  ​    \\
  ​    \end{aligned} \quad \quad \quad
  ​    \begin{aligned}
  ​        \textbf{minimize} \quad &amp; X \cdot A = \sum_{i,j \in V}
X_{ij} A_{ij} \\
  ​    \textbf{subject to} \quad &amp; X \geq 0 \;  \\
  ​     &amp; X_{ii}=1
  ​    \end{aligned}\]</span></p>
<p><strong>Proof</strong>: Note that <span class="math inline">\(X_{ij}
= x_i^T x_j\)</span> (and sometimes <span class="math inline">\(X\)</span> is called the gram matrix),
therefore</p>
<p><span class="math display">\[\begin{aligned}
          X \in S_+^n \text{ is feasible } &amp; \iff X_{ij}=1 \text{
for any } i \in V \\
          &amp; \iff \|x_u \|=1 \text{ for any } u \in V \\
          &amp; \iff x_u \in S^{n-1} \text{ for any } u \in V
      \end{aligned}\]</span></p>
<p>and the desired result follows.</p>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>统计</tag>
      </tags>
  </entry>
  <entry>
    <title>数学分析 I 速通日志（下）</title>
    <url>/2023/02/01/Learn-Mathematical-Analysis-or-Die-2/</url>
    <content><![CDATA[<p>隔了几天才发是因为想不出来摘要可以写些什么，现在也还没想出来，所以就这样吧。差不多得了（</p>
<span id="more"></span>
<p>最近看到多元统计分析的先修要求包含“熟练运用
R”，给我整麻了，去推了几天 R 的进度，把数分耽搁了。我好菜。</p>
<p>如果还要多写几句的话，讲点近期见闻、甘主任的小故事以及毫无意义的竞赛往事！（</p>
<p>前两天看到 Chenlin Gu 的 homepage 上有这么一句话：</p>
<blockquote>
<p>Finally, let mention <a href="https://qingyunwu.com/">the guy</a> who
teaches me a lot. We have once trained for maths olympiad in high school
and also collaborated for (maybe) my first paper. I always remember the
epoch when I was younger and those friends with who we studied maths
together. I missed the old days, but perhaps to do maths is the only way
to keep them in my mind.</p>
<p>——<a href="https://chenlin-gu.github.io/trivia.html">Chenlin Gu's
homepage</a></p>
</blockquote>
<p>然后我想了想，若干年后我会不会也可以原文照抄这段话放在自己的关于页面里，然后链接到甘主任的
homepage（。前三句现在基本已经实现了（如果把我们高中的时候在新星那里生产的学术垃圾题解当做
maybe my first paper
的话，那就真的已经完全实现了）。听他之后的想法的话，最后一句或许也是有可能的。当然大家的想法都会慢慢变化，说不定将来在自己的
homepage 上写这句话然后链接到我的主页的人是他呢（笑</p>
<p>后来觉得很奇怪。我在进高中之前机缘巧合认识了甘主任，又过了两年直到退役也没在学校里找到新的学习数学的朋友。尽管我校也不算什么强校，但数学组加起来也有几十个人，这里面的人除了一些耳熟能详的神和同班同学之外，我几乎都不认识，还是只能和甘主任讨论问题。</p>
<p>不过有一个好朋友也该知足了。高一联赛时刚学了几个月，我属于是超常发挥，和彼时初三的甘主任拿到了相同的分数，大概是省二靠前的位置，一度因此产生“再学两年我一定可以和甘主任同时进省队”的幻觉（我始终认为自己的上限就是省队，所谓求上者得中，求中者得下，我就是那个求下者不入流的），甚至当时被教练当成种子选手之一，现在想想很对不起唐老师。第二年甘主任如愿拿到了省一，而我因为各种原因（精神状态很差，具体情况在此略过）耻辱省三。后来我的水平就被甘主任拉得越来越远，半退役了很长时间，还碰上了疫情和网课，变成了坚持到底就是胜利的乐子人。我高三的时候甘主任大约只差了五个名次没有进队，而我拿了个牌拿了个垫底省一就退役了，彻底离开了这个我当时已经并不特别喜欢的游戏。不喜欢的原因可以有很多，两个最大的因素是觉得还是在练习做题技巧，有点无聊，以及自己相对别人的基础实在差距太大，也不太聪明，感觉付出更多努力也弥补不了多少。高三的时候有一次我做梦梦到班主任问我为什么高二都摆过去了没有好好搞竞赛，我说我不喜欢这个游戏规则了，然后他对我嗤之以鼻，说你是学生，不喜欢也得搞。醒来之后我觉得这对话还挺符合他形象的，<del>男人至死是少年，所以他当了老师也还是不停强调自己当年是理科状元考进了清华所以会做题最牛逼也没什么不对的</del>。当然现实里的话他根本不会和我多啰嗦一个字，几乎没有和我说过话。</p>
<p>扯远了。拍毕业照的时候我把 CGMO
的金牌挂在甘主任脖子上和他合了影，半年后就把他奶成了货真价实的 CMO
Au，顺利签了隔壁数院的英才班。我常开玩笑说是我的破铁牌的功劳，建议请我吃饭，心里时不时想我清醒地知道自己怎么样也不可能在这场游戏里和他达到同样的水平，愿赌服输。无论是资源、基础这种已经改变不了了的东西，还是实在的努力，甚至耐心、心态、韧性这些听起来很玄学的因素，或许还有听起来很扎心的智力，我承认自己哪一点都比不过他。甚至我觉得，我的心早在退役之前就已经飞走了，在最后两次比赛之前就已经不怎么喜欢这个游戏了，只是在为沉没成本找补，以及试图最后寻找到一点独立解题的乐趣。当然寻找乐趣这件事还是令人欣慰的，最后半年的快乐回忆包括并不限于质心首届线上联考手推
Chebyshev 多项式拿了全国 rank
1（主要是全国也没几个人参加这个破玩意），CGMO Day 1
迅速切掉了压轴题，联赛那天只睡了不到五个小时还是几乎 ak
了一试，都是前所未有的愉快体验。当然这不能说明我水平怎么样，熟悉我的人都知道我无论是从前还是现在都很菜，大大小小的比赛和日常练习里失败的次数远远多于成功的，敝帚自珍而已。</p>
<p>又扯远了，我在说甘主任来着。总之，他是我高中的时候关系最好的同路的朋友，没有之一，现在或许也是。尽管我高中竞赛是真的学得很艰难，<del>他也没嫌弃过我菜还随时解答我的奇怪问题，泪目了</del>，也收到过不少他的鼓励（或者说毒奶），虽然毒奶里面只实现了签清华的约这件事情，强基之后还自动毁约了。运气不好被华子调剂了专业之后，他和我说过“有些人偶尔走失，但从未离开”，我当时一心转码，正处在一个走失的状态，没有意识到这句话的可贵之处。</p>
<p>可惜甘主任目前还没有自建的主页或者博客，先浅放一个他的公众号在这里：<a href="https://mp.weixin.qq.com/s/mYSd6U3REupMO1WUBpkoIQ">runzhi的随笔</a>（我不太会直接链接公众号的界面，就放了一篇最近的文章的链接），感觉功能上也是一样的。一个多月没更新了，隔空催更一下（不</p>
<p>最后贴一个今晚躺着刷知乎看到的回答，笑得想死，希望我没事：</p>
<p><img src="https://s2.loli.net/2023/02/06/SdyAbfTuWrFURO8.png" alt="no-analysis.png"></p>
<h1 id="导数">导数</h1>
<p>2023 年 2 月 1 日，星期三，学习一些轻松愉快的导数。</p>
<h2 id="我先简单喵两句">我先简单喵两句</h2>
<ul>
<li><p>一个处处不可微的连续函数的例子，不出意外地是无穷级数函数，通俗一点来说处处不可微是因为求导之后的级数就不收敛了。但是对无穷级数的求导暂时不好定义，所以是取一个收敛的点列来论证差分的极限发散。直接贴这儿吧：<a href="https://www.bananaspace.org/wiki/%E8%AE%B2%E4%B9%89:%E6%95%B0%E5%AD%A6%E5%88%86%E6%9E%90/%E5%AF%BC%E6%95%B0%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%A7%E8%B4%A8%E3%80%81%E5%BA%94%E7%94%A8%E4%B8%8E%E6%8E%A8%E5%B9%BF#%E5%A4%84%E5%A4%84%E4%B8%8D%E5%8F%AF%E5%BE%AE%E7%9A%84%E8%BF%9E%E7%BB%AD%E5%87%BD%E6%95%B0">Read
More</a></p></li>
<li><p>另外观察导数定义的形式：<span class="math inline">\(\lim _{x \to
x_0} \frac{f(x)-f(x_0)}{x-x_0}\)</span>，我们可以知道只要 <span class="math inline">\(f: \mathbb R \to V\)</span> 是连续映射，<span class="math inline">\((V,|| \cdot ||)\)</span>
是赋范线性空间，那么这个极限就有意义，可以定义导数。比如说映射 <span class="math inline">\(x \to exp (xA), \mathbb R \to M_n(\mathbb
R)\)</span> 就有导数。</p></li>
<li><p>一些可能没学过或者单纯是忘了的定理：</p>
<p>导函数不一定是连续的，但是它可以满足介值定理。所以 Cauchy
中值定理的形式 <span class="math inline">\(\frac{f&#39;(x)}{g&#39;(x)}\)</span> 实际上意味着
<span class="math inline">\(g(x)\)</span> 有比 <span class="math inline">\(f(x)\)</span> 更强的性质，<span class="math inline">\(g&#39;(x) \neq
0\)</span>，也就是说它是恒正或者恒负的，是单调且连续的，也就是一个连续的双射而且满足逆映射也连续，所以是一个同胚。</p>
<p>Cauchy 中值公式可以看做 Lagrange 中值定理在二维上的推广：对于映射
<span class="math inline">\(x \to (f(x),g(x))\)</span> 和 <span class="math inline">\(I\)</span> 上两点 <span class="math inline">\(a,b\)</span>，总可以找到一点 <span class="math inline">\(x_0 \in [a,b]\)</span> 满足 <span class="math inline">\((f(a),g(a))\)</span>，<span class="math inline">\((f(b),g(b))\)</span> 的斜率等于 <span class="math inline">\(x_0\)</span> 处的切线斜率，也就是 <span class="math inline">\((f&#39;(x_0),g&#39;(x_0))\)</span>。</p></li>
<li><p>然后是一些凸函数理论，挺应用的，有手就行，不细看了。</p></li>
</ul>
<p>其他没啥可写的，跑步进入习题环节！</p>
<h2 id="梦话经典的作业题胡说八道环节">梦话：经典的作业题胡说八道环节</h2>
<h3 id="导数的定义和计算">导数的定义和计算</h3>
<ul>
<li><p><span class="math inline">\(\mathbb R^n\)</span> 上配有范数 <span class="math inline">\(\|(x_1,\cdots,x_n)\|_2=\sqrt{(x_1)^2+\cdots+(x_n)^2}\)</span>，我们考虑映射</p>
<p><span class="math inline">\(f\colon \mathbb R \rightarrow \mathbb
R^n, \ \  x\mapsto f(x)=(f_1(x),\cdots, f_n(x))\)</span></p>
<p>证明，<span class="math inline">\(f\)</span> 在 <span class="math inline">\(x_0\)</span> 处的导数存在当且仅当对每个分量函数
<span class="math inline">\(f_k\)</span>，它在 <span class="math inline">\(x_0\)</span> 处的导数都存在并且</p>
<p><span class="math inline">\(f&#39;(x)=\bigl(f_1&#39;(x),\cdots,
f_n&#39;(x)\bigr)\)</span>。</p>
<p>Trivial.</p></li>
<li><p>考虑函数 <span class="math inline">\(e^{ix}\)</span>，将它视作是映射 <span class="math inline">\(f\colon \mathbb R\rightarrow \mathbb{C}, \ \ x
\mapsto e^{ix}\)</span></p>
<p>利用定义证明，<span class="math inline">\(f&#39;(0)=i ~(\in
\mathbb{C})\)</span>。仿照课堂上的做法证明 <span class="math inline">\(\bigl(e^{ix}\bigr)&#39;=ie^{ix}\)</span>。</p>
<p>老演员了，PIN 真的很喜欢 exp 函数。</p></li>
<li><p>利用上面两个问题的结论计算 <span class="math inline">\(\sin
x\)</span> 和 <span class="math inline">\(\cos x\)</span> 的导数。</p>
<p><span class="math inline">\(f:\mathbb R \to \mathbb
R^2\)</span>，<span class="math inline">\(x \to
(sinx,cosx)\)</span>，（？），把二者都写成 <span class="math inline">\(e^{ix}\)</span> 的变式。</p></li>
<li><p>定义映射 <span class="math inline">\(E\colon \mathbb R
\rightarrow \mathbb{C}=\mathbb R^2, \ \ \theta\mapsto (\cos\theta,
\sin\theta)\)</span>，我们用下面符号表示平面上的单位圆：</p>
<p><span class="math inline">\(\mathbf{S}^1=\bigl\{(x,y)\in \mathbb
R^2\bigm| x^2+y^2=1\bigr\}\)</span></p>
<p>证明，<span class="math inline">\(\mathbf{S}^1\)</span>
上的点可以写成 <span class="math inline">\((\sin\theta,\cos\theta)\)</span> 的形式，即 <span class="math inline">\(E(\mathbb R)=\mathbf{S}^1\)</span>。试计算 <span class="math inline">\(E&#39;(\theta)\)</span> 并验证对于这个映射（<span class="math inline">\(\mathbb R^2\)</span>
上取值），Rolle中值定理并不成立。</p>
<p>圆上的点可以视作一条过原点的直线和圆的交点，所以问题的重点是为什么
<span class="math inline">\(\frac{\cos \theta}{\sin \theta}\)</span>
可以表示一切实数，换成更熟悉的形式就是为什么 <span class="math inline">\(\tan \theta\)</span> 可以表示一切实数。实际上
<span class="math inline">\(\tan x = x + \frac{x^3}{3!}+...\)</span>
是发散的无穷级数，而且是连续函数（因为 <span class="math inline">\(\sin
x\)</span>，<span class="math inline">\(\cos x\)</span>
都是连续函数，导出 <span class="math inline">\(\tan x\)</span>
也是连续函数），所以它可以表示一切实数。</p>
<p><span class="math inline">\(E&#39;(\theta) = (\cos \theta , -\sin
\theta)\)</span>，考虑 Rolle 中值定理，有 <span class="math inline">\(E(0) = E(2 \pi)\)</span>，但是不存在 <span class="math inline">\(x \in [0,2\pi]\)</span> 满足 <span class="math inline">\(E&#39;(x) = (0,0)\)</span>。所以 Rolle
中值定理是只能对一维情况成立的。</p></li>
<li><p>如果函数 <span class="math inline">\(f\)</span> 在点 <span class="math inline">\(x_0\)</span> 处的导数 <span class="math inline">\(&gt;0\)</span>，不能推出存在该点的领域 <span class="math inline">\(U\)</span>，使得 <span class="math inline">\(f\)</span> 在这个邻域上是递增的：</p>
<p>考虑函数<span class="math inline">\(f(x)=\begin{cases}
x+2x^2\sin\left(\frac{1}{x}\right), \ \ &amp;x\neq 0;\\ 0, \ \ &amp;x=0.
\end{cases}\)</span></p>
<p>证明，<span class="math inline">\(f\)</span> 在 <span class="math inline">\(0\)</span> 处导数存在且大于零，但是对任意的 <span class="math inline">\(\varepsilon&gt;0\)</span>，<span class="math inline">\(f\)</span> 在 <span class="math inline">\((-\varepsilon,\varepsilon)\)</span>
上的限制都不是单调函数。</p>
<p><span class="math inline">\(f\)</span> 在 <span class="math inline">\(0\)</span> 处的导数值是 <span class="math inline">\(1\)</span>。第二问要证明的意思其实是，虽然 <span class="math inline">\(f&#39;(0) &gt;0\)</span>
但是在任意的邻域上不单调。</p>
<p><span class="math inline">\(x \neq 0\)</span> 时的导函数是 <span class="math inline">\(f&#39;(x) = 1+4x \sin (\frac{1}{x}) -2 \cos (\frac
1 x)\)</span>，在任意的邻域 <span class="math inline">\((-\varepsilon ,
\varepsilon)\)</span> 上不保证大于 <span class="math inline">\(0\)</span>。</p></li>
<li><p><span class="math inline">\(\mathbf{I}_n\)</span> 是 <span class="math inline">\(n\times n\)</span> 的单位矩阵，<span class="math inline">\(A\in \mathbf{M}_n(\mathbb R)\)</span>，计算 <span class="math inline">\(\dfrac{d}{dx}\Big|_{x=0}\det
(\mathbf{I}+xA)\)</span>，即 <span class="math inline">\(\det
(\mathbf{I}+xA)\)</span> 在 <span class="math inline">\(x=0\)</span>
处的导数。</p>
<p>从特征值的角度考虑就很 trivial 了，是 <span class="math inline">\(trace (A)\)</span>。</p></li>
<li><p>证明，（可微的）奇函数的导数是偶函数，（可微的）偶函数的导数是奇函数。</p>
<p>Trivial.</p></li>
<li><p>证明，Riemann 函数 <span class="math inline">\(f(x) =
\begin{cases} 1/q, &amp;x = \dfrac{p}{q} \in \mathbb{Q}, q\geqslant 1,
p~\text{和}~q~\text{互素};\\0, &amp;
x~\text{是无理数}.\end{cases}\)</span> 在 <span class="math inline">\(\mathbb{R}\)</span> 上处处不可微.</p>
<p>在有理数点处不连续自然不可微。无理数点处可以找一个收敛到 <span class="math inline">\(x\)</span> 的有理序列，逐点相对于 <span class="math inline">\(x\)</span>
的差商可以递增，不会收敛，所以也不可微。</p>
<p>具体一点来说，对于任意的素数 <span class="math inline">\(q_n\)</span>，取长度为 <span class="math inline">\(\frac 1 {q_n}\)</span> 的区间使得 <span class="math inline">\(x\)</span> 落在其中，可以表示成 <span class="math inline">\([a_n,b_n]=[\frac{[qx]}{q},\frac{[qx]+1}{q}]\)</span>，我们总是取
<span class="math inline">\(a_n,b_n\)</span> 中距离 <span class="math inline">\(x\)</span> 更近的一点作为 <span class="math inline">\(x_n\)</span>，由有理数的稠密性可以知道，$ = $
可以取成递增发散的序列。</p></li>
</ul>
<h3 id="无穷小量与无穷大量的阶的比较">无穷小量与无穷大量的阶的比较</h3>
<p>如果函数 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(x_0\)</span> 的附近（即某个 <span class="math inline">\(x_0\)</span> 的开邻域去掉 <span class="math inline">\(x_0\)</span>）满足 <span class="math inline">\(\displaystyle\lim_{x \to x_0} f(x) =
0\)</span>，我们就称 <span class="math inline">\(f\)</span> 是 <span class="math inline">\(x \to x_0\)</span> 时的无穷小量； 类似地，如果
<span class="math inline">\(\displaystyle\lim_{x \to x_0} f(x) =
+\infty\)</span> 或者 <span class="math inline">\(\displaystyle\lim_{x
\to x_0} f(x) =
-\infty\)</span>（其注意我们用的“或者”这个词的含义），我们就称 <span class="math inline">\(f\)</span> 是 <span class="math inline">\(x \to
x_0\)</span> 时的无穷大量。</p>
<p>现在假设 <span class="math inline">\(f, g\)</span> 都是 <span class="math inline">\(x \to x_0\)</span> 时的无穷小量并且 <span class="math inline">\(g(x)\)</span> 在 <span class="math inline">\(x_0\)</span>
的附近不取零值，我们现在引进记号：</p>
<ul>
<li><p>如果 <span class="math inline">\(\displaystyle\lim_{x \to
x_0}\frac{f(x)}{g(x)} = 0\)</span>， 我们就称 <span class="math inline">\(f\)</span> 是比 <span class="math inline">\(g\)</span> 高阶的无穷小，记作 <span class="math inline">\(f(x) = o(g(x)), x \to x_0\)</span>；</p></li>
<li><p>如果 <span class="math inline">\(\displaystyle\lim_{x \to
x_0}\frac{f(x)}{g(x)} = \ell, \ell \neq 0\)</span>，我们就称 <span class="math inline">\(f\)</span> 是与 <span class="math inline">\(g\)</span> 同阶的无穷小；</p></li>
<li><p>特别地，如果 <span class="math inline">\(f\)</span> 与 <span class="math inline">\(g\)</span> 同阶并且 <span class="math inline">\(\ell = 1\)</span>，我们就称 <span class="math inline">\(f\)</span> 是与 <span class="math inline">\(g\)</span> 等价的无穷小， 记作 <span class="math inline">\(f(x) \sim g(x), x \to x_0\)</span>；</p></li>
<li><p>如果 <span class="math inline">\(\displaystyle\limsup_{x \to
x_0}\frac{|f(x)|}{|g(x)|} &lt; +\infty\)</span>，我们将这种情况记作
<span class="math inline">\(f(x) = O(g(x)), x \to
x_0\)</span>。</p></li>
</ul>
<p>特别的 <span class="math inline">\(f(x) = O(1)\)</span> 与 <span class="math inline">\(f(x) = o(1)\)</span> 分别表示在 <span class="math inline">\(x \to x_0\)</span> 时 <span class="math inline">\(f\)</span> 有界与 <span class="math inline">\(f\)</span> 是无穷小.</p>
<p>类似地，我们可以定义无穷大量的阶之间的比较。这是通用的术语，同学们可参考任一本参考书或者网络。</p>
<ul>
<li><p>假设 <span class="math inline">\(x \to x_0\)</span> 时，函数
<span class="math inline">\(a(x)\)</span> 满足 <span class="math inline">\(a = o(1)\)</span>。试证明：</p>
<p><span class="math inline">\(o(a) + o(a) = o(a)\)</span></p>
<p>$ o(ca) = co(a), c $</p>
<p><span class="math inline">\((o(a)^k) = o(a^k)\)</span></p>
<p>$ = 1 - a + o(a)$</p>
<p>代定义就可以了，trivial.</p></li>
<li><p>假设 <span class="math inline">\(f(x), g(x)\)</span> 是 <span class="math inline">\(x \to x_0\)</span> 时的无穷小，那么</p>
<ul>
<li><p>证明，<span class="math inline">\(f(x) \sim g(x) \iff f(x) - g(x)
= o(g(x)), \quad x \to x_0\)</span>。</p>
<p>Trivial.</p></li>
<li><p>如果把 <span class="math inline">\(g\)</span>
作为基本的比较单位（小量），我们可以将另外的无穷小量与 <span class="math inline">\(g(x)^k\)</span>（<span class="math inline">\(k\)</span> 是正整数）进行比较。如果 <span class="math inline">\(f(x) \sim c g(x)^k\)</span>，我们就称 <span class="math inline">\(c g^k\)</span> 是 <span class="math inline">\(f\)</span> 的主部（这里 <span class="math inline">\(c\)</span>
是常数）。试定出下列无穷小或无穷大的主部（与 <span class="math inline">\(x-x_0\)</span> 或者 <span class="math inline">\(x\)</span> 比较）：</p>
<p><span class="math inline">\(\frac{1}{\sin \pi x}, \quad x \to
1\)</span></p>
<p>这是个无穷大量，或许主部是 <span class="math inline">\(\frac 1 \pi
(1-x)^{-1}\)</span>。</p>
<p><span class="math inline">\(\sqrt{1+x} - \sqrt{1-x}, \quad x \to
0\)</span></p>
<p>主部是 <span class="math inline">\(x\)</span>。</p>
<p><span class="math inline">\(\sin \left(\sqrt{1 + \sqrt{1+ \sqrt{x}}}
- \sqrt{2}\right), \quad x \to 0^+\)</span></p>
<p>主部是 <span class="math inline">\(\frac{1}{4 \sqrt{2} }
\sqrt{x}\)</span>，所以说 <span class="math inline">\(k\)</span>
真的一定是正整数吗？</p>
<p><span class="math inline">\(\sqrt{1 + \tan x} - \sqrt{1 - \sin x},
\quad x\to 0\)</span></p>
<p>主部是 <span class="math inline">\(x\)</span>。</p>
<p><span class="math inline">\(\sqrt{x + \sqrt{x + \sqrt{x}}}, \quad x
\to 0^+\)</span></p>
<p>主部是啥？</p>
<p><span class="math inline">\(\sqrt{x + \sqrt{x + \sqrt{x}}}, \quad x
\to +\infty\)</span></p>
<p>主部是 <span class="math inline">\(\sqrt{x}\)</span>。</p></li>
</ul></li>
<li><p>我们假设 <span class="math inline">\(f(x) \sim c x^k, x \to
0\)</span>（即 <span class="math inline">\(f(x) = c x^k +
o(x^k)\)</span>）。如果 <span class="math inline">\(f(x) - c
x^k\)</span> 可以再分出主部 <span class="math inline">\(c&#39;x^{k&#39;}\)</span>，其中 <span class="math inline">\(k&#39; &gt; k\)</span>，那么我们就将它写为 $f(x) =
c x^k + c' x^{k'} + o(x^{k'}) $。试将下列无穷小展开到 <span class="math inline">\(o(x^2)\)</span>：</p>
<ul>
<li><p><span class="math inline">\(\sqrt{1 + x} - 1\)</span></p>
<p><span class="math inline">\(\frac 1 2 x - \frac 1 4
x^2\)</span></p></li>
<li><p><span class="math inline">\(\sqrt[m]{1+x} - 1, m \in
\mathbb{Z}_{\geqslant 1}\)</span></p>
<p><span class="math inline">\(\frac 1 m x + \frac{1-m}{m^2}
x\)</span></p></li>
</ul></li>
</ul>
<h3 id="高木贞治函数学不完了咕了">*高木贞治函数（学不完了，咕了</h3>
<p>我们先在 <span class="math inline">\([0,1]\)</span> 区间上定义 <span class="math inline">\(\psi(x)=\begin{cases}x, \ \ \ \ 0\leqslant x
&lt;\dfrac{1}{2};\\1-x, \  \ \dfrac{1}{2}\leqslant x \leqslant
1.\end{cases}\)</span></p>
<p>接下来，以 <span class="math inline">\(1\)</span> 为周期，我们可以将
<span class="math inline">\(\psi\)</span> 延拓成 <span class="math inline">\(\mathbb R\)</span>
上的周期函数（连续）并且仍然将它记作 <span class="math inline">\(\psi\)</span>，它的函数图像好像是锯齿一般。</p>
<p>我们定义Takagi函数 <span class="math inline">\(T\colon \mathbb
R\rightarrow \mathbb R\)</span> 如下：<span class="math inline">\(T(x)=\sum_{k=0}^\infty \frac{1}{2^k}\psi(2^k
x)\)</span></p>
<p>我们实际上可以考虑部分和 <span class="math inline">\(\displaystyle
T_n(x)=\sum_{k=0}^n \frac{1}{2^k}\psi(2^k x)\)</span>。当 <span class="math inline">\(n\)</span>
越来越大的时候，它们的图像看起来逐渐地收敛。这个习题的目标是粗略地研究Takagi函数的性质。</p>
<ul>
<li><p>证明，<span class="math inline">\(T(x)\)</span> 是 <span class="math inline">\(\mathbb R\)</span> 上良好定义的有界连续函数。</p>
<p>良好定义：<span class="math inline">\(T(x) \leq \sum_{k=0}^\infty
\frac{1}{2^k} = 2\)</span>，一定是收敛级数，所以是良好定义的。</p>
<p>有界：如上所述。</p>
<p>连续函数：它是连续函数的级数和，也是连续函数。</p></li>
<li><p>对于 <span class="math inline">\(x\in [0,1]\)</span>，假设 <span class="math inline">\(x=\displaystyle\sum_{n=1}^\infty
\frac{a_n}{2^n}\)</span> 是 <span class="math inline">\(x\)</span> 的
<span class="math inline">\(2\)</span>-进制展开，其中 <span class="math inline">\(a_n=0\)</span> 或者 <span class="math inline">\(1\)</span>。我们令 <span class="math inline">\(v_n=\displaystyle\sum_{k=1}^n
a_k\)</span>。我们定义函数 <span class="math inline">\(\sigma_n(y)=a_n+(1-2a_n)y\)</span>，其中 <span class="math inline">\(y=0\)</span> 或者 <span class="math inline">\(1\)</span>。证明，<span class="math inline">\(\psi(2^m
x)=\sum_{n=1}^\infty\frac{\sigma_{m+1}(a_{m+n})}{2^n}\)</span></p>
<p>Trivial.</p></li>
<li><p>对于 <span class="math inline">\(x\in [0,1]\)</span>，假设 <span class="math inline">\(x=\displaystyle\sum_{n=1}^\infty
\frac{a_n}{2^n}\)</span> 是 <span class="math inline">\(x\)</span> 的
<span class="math inline">\(2\)</span>-进制展开。证明，<span class="math inline">\(T(x)=\sum_{n=1}^\infty\frac{(1-a_n)v_n+a_n(n-v_n)}{2^n}\)</span></p></li>
<li><p>假设 <span class="math inline">\(x_0=\dfrac{k_0}{2^{m_0}}\in(0.1]\)</span>，其中
<span class="math inline">\(k_0\in\mathbb{Z}_{\geqslant 1}\)</span>
是奇数，<span class="math inline">\(m_0\in \mathbb{Z}_{\geqslant
0}\)</span>。令 <span class="math inline">\(h_n=\dfrac{1}{2^n}\)</span>，其中 <span class="math inline">\(n\in \mathbb{Z}_{\geqslant
m_0}\)</span>。证明，数列 <span class="math inline">\(\bigl\{\dfrac{T(x+h_n)-T(x)}{h_n}\bigr\}_{n\geqslant
m_0}\)</span> 不收敛。</p></li>
<li><p><span class="math inline">\(f\)</span> 是定义在非空的开区间 <span class="math inline">\(I\)</span> 上实数值函数。如果 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(a\)</span> 处可导，</p>
<p>证明，<span class="math inline">\(\lim_{(h,h&#39;)\rightarrow (0,0),
\atop \\
h&gt;0,h&#39;&gt;0}\frac{f(a+h)-f(a-h&#39;)}{h+h&#39;}=f&#39;(a)\)</span>，</p>
<p>这里极限 <span class="math inline">\(\displaystyle
\lim_{(h,h&#39;)\rightarrow (0,0), \atop \\ h&gt;0,h&#39;&gt;0}\)</span>
的意义指的是任意的序列 <span class="math inline">\((h_n,h&#39;_n)\rightarrow (0,0),
h_n&gt;0,h&#39;_n&gt;0\)</span> 所对应的序列都收敛。</p></li>
<li><p><span class="math inline">\(f\)</span> 是定义在非空的开区间 <span class="math inline">\(I\)</span> 上实数值函数。假设 <span class="math inline">\(f\in C^1(I)\)</span>（连续可微），<span class="math inline">\(a\in I\)</span>，</p></li>
</ul>
<p>证明，<span class="math inline">\(\lim_{(h,h&#39;)\rightarrow (0,0),
\atop h+h&#39;\neq
0}\frac{f(a+h)-f(a-h&#39;)}{h+h&#39;}=f&#39;(a)\)</span></p>
<ul>
<li><p>假设 <span class="math inline">\(x\in
[0,1]\)</span>，使得对任意的正整数 <span class="math inline">\(n\)</span>，<span class="math inline">\(2^n
x\)</span> 都不是整数。对于每个正整数 <span class="math inline">\(n\)</span>，我们用下面的公式定义序列 <span class="math inline">\(\{h_n\}_{n \geqslant 1}\)</span> 和 <span class="math inline">\(\{h&#39;_n\}_{n \geqslant 1}\)</span>：<span class="math inline">\(\floor{2^n x}=2^n(x-h&#39;_n), \ \ \floor{2^n
x}+1=2^n(x+h_n)\)</span></p>
<p>其中函数 <span class="math inline">\(\floor{y}\)</span>
按照定义是不超过 <span class="math inline">\(y\)</span> 的最大的整数（即
<span class="math inline">\(y\)</span> 的整数部分（如果 <span class="math inline">\(y\geqslant 0\)</span>））。证明，对每个给定的
<span class="math inline">\(n\)</span>，<span class="math inline">\(h_n+h&#39;_n=2^{-n}\)</span> 并且对每个整数 <span class="math inline">\(1\leqslant \ell \leqslant n-1\)</span>，开区间
<span class="math inline">\(\bigl(2^\ell(x-h&#39;_n),2^\ell(x+h_n)\bigr)\)</span>
中不包含任何的整数和半整数。</p></li>
<li><p>假设 <span class="math inline">\(x\in
[0,1]\)</span>，使得对任意的正整数 <span class="math inline">\(n\)</span>，<span class="math inline">\(2^n
x\)</span> 都不是整数，我们沿用~E7)中的符号，</p>
<p>证明，数列 <span class="math inline">\(\Bigl\{\dfrac{T(x+h_n)-T(x-h&#39;_n)}{h_n+h&#39;_n}\Bigr\}_{n\geqslant
1}\)</span> 不收敛。</p></li>
<li><p>证明，<span class="math inline">\(T(x)\)</span> 是 <span class="math inline">\(\mathbb R\)</span>
上处处连续处处不可微的函数。</p></li>
<li><p>证明，我们有如下的函数方程：</p>
<p><span class="math inline">\(T(x)=\begin{cases}2x+\dfrac{T(4x)}{4},\ \
0\leqslant x &lt;\dfrac{1}{4};\\\dfrac{1}{2}+\dfrac{T(4x-1)}{4},\ \
\dfrac{1}{4}\leqslant x
&lt;\dfrac{1}{2};\\\dfrac{1}{2}+\dfrac{T(4x-2)}{4},\ \
\dfrac{1}{2}\leqslant x &lt;\dfrac{3}{4};\\2-2x+\dfrac{T(4x-3)}{4},\ \
\dfrac{3}{4}\leqslant x \leqslant 1.\end{cases}\)</span></p></li>
<li><p>（Takagi函数图像的自相似性）令 <span class="math inline">\(\Gamma=\bigl\{(x,T(x))\mid 0\leqslant x\leqslant
1\bigr\}\subset \mathbb R^2\)</span> 是 <span class="math inline">\(T\)</span> 在区间 <span class="math inline">\([0,1]\)</span>
上的函数图像。我们定义如下四个仿射变换 <span class="math inline">\(\Phi_i\colon \mathbb R^2\rightarrow \mathbb
R^2\)</span>：</p>
<ul>
<li><p><span class="math inline">\(\Phi_0 \left(\begin{array}{ccc}x \\y
\end{array} \right)&amp;= \left(\begin{array}{ccc}\frac{1}{4} &amp; 0
\\\frac{1}{2} &amp; \frac{1}{4} \end{array}
\right)\left(\begin{array}{ccc}x \\y \end{array}
\right)\)</span></p></li>
<li><p><span class="math inline">\(\Phi_1 \left(\begin{array}{ccc}x \\y
\end{array} \right)= \left(\begin{array}{ccc}\frac{1}{4} &amp; 0 \\0
&amp; \frac{1}{4} \end{array} \right)\left(\begin{array}{ccc}x \\y
\end{array} \right)+\left(\begin{array}{ccc}\frac{1}{4}
\\\frac{1}{2}\end{array}\right)\)</span></p></li>
<li><p><span class="math inline">\(\Phi_2 \left(\begin{array}{ccc}x \\y
\end{array} \right)&amp;= \left(\begin{array}{ccc}\frac{1}{4} &amp; 0
\\0 &amp; \frac{1}{4} \end{array} \right)\left(\begin{array}{ccc}x \\y
\end{array} \right)+\left(\begin{array}{ccc}\frac{1}{2}
\\\frac{1}{2}\end{array}\right)\)</span></p></li>
<li><p><span class="math inline">\(\Phi_3 \left(\begin{array}{ccc}x \\y
\end{array} \right)= \left(\begin{array}{ccc}\frac{1}{4} &amp; 0
\\-\frac{1}{2} &amp; \frac{1}{4} \end{array}
\right)\left(\begin{array}{ccc}x \\y \end{array}
\right)+\left(\begin{array}{ccc}\frac{3}{4}
\\\frac{1}{2}\end{array}\right)\)</span></p>
<p>证明，<span class="math inline">\(\Phi_i\)</span> 恰好把 <span class="math inline">\(\Gamma\)</span> 变成 <span class="math inline">\(T\)</span> 在区间 <span class="math inline">\([\dfrac{i}{4},\dfrac{i+1}{4}]\)</span>
上的图像，其中 <span class="math inline">\(i=0,1,2,3\)</span>。</p></li>
</ul></li>
<li><p>令 <span class="math inline">\(S_0=\{(x,y)\in \mathbb R^2 \mid
0\leqslant x\leqslant 1, 0\leqslant y \leqslant 1\}\)</span> 是 <span class="math inline">\(\mathbb R^2\)</span> 上的闭方块。对每个 <span class="math inline">\(n\geqslant 0\)</span>，我们定义 <span class="math inline">\(\displaystyle
S_{n+1}=\bigcup_{k=0}^3\Phi_k(S_n)\)</span>。证明，<span class="math inline">\(S_n\)</span> 是平面上一列单调下降的紧集并且 <span class="math inline">\(\displaystyle \Gamma=\bigcap_{n\geqslant
0}S_n\)</span>。我们有 <span class="math inline">\(S_1\)</span> 和 <span class="math inline">\(S_2\)</span> 的示意图：</p></li>
<li><p>证明，<span class="math inline">\(\displaystyle\sup_{x\in \mathbb
R}T(x) \leqslant \dfrac{2}{3}\)</span>。</p></li>
<li><p>找一个 <span class="math inline">\(c\in [0,1]\)</span>，使得
<span class="math inline">\(T(c)=\dfrac{2}{3}\)</span>。</p></li>
<li><p>（<span class="math inline">\(T^{-1}(\dfrac{2}{3})\)</span>
的Cantor集的结构）对于 <span class="math inline">\(x\in
[0,1]\)</span>，假设 <span class="math inline">\(x=\displaystyle\sum_{n=1}^\infty
\frac{b_n}{4^n}\)</span> 是 <span class="math inline">\(x\)</span> 的
<span class="math inline">\(4\)</span>-进制展开，其中 <span class="math inline">\(b_n=0,1,2,3\)</span>。</p>
<p>证明，<span class="math inline">\(\Bigl\{x\in [0,1]\bigm|
T(x)=\dfrac{2}{3}\Bigr\}=\Bigl\{x\in [0,1]\bigm| x=\sum_{n=1}^\infty
\frac{b_n}{4^n}, b_n\in \{1,2\}\Bigr\}\)</span></p></li>
<li><p>仿照 11，研究 <span class="math inline">\(\Phi_1\)</span> 和
<span class="math inline">\(\Phi_2\)</span> 在集合 <span class="math inline">\(\bigl\{(x,T(x))\bigm| x\in
[0,1],T(x)=\dfrac{2}{3}\bigr\}\)</span>
上自相似的作用。（这是一个Hausdorff维数为 <span class="math inline">\(\dfrac{1}{2}\)</span> 的集合）。</p></li>
</ul>
<h2 id="梦话-2.0这作业怎么这么多啊">梦话 2.0：这作业怎么这么多啊</h2>
<h3 id="中值定理和taylor展开">中值定理和Taylor展开</h3>
<p>如果不额外说明，<span class="math inline">\(f\)</span> 总代表一个区间
<span class="math inline">\(I\)</span> 上定义的函数。</p>
<ul>
<li><p>设 <span class="math inline">\(f\)</span> 在点 <span class="math inline">\(x\)</span>
处有二阶导数。证明，下面的极限给出了二阶导数：$ f''(x) = _{h } $</p>
<p>可以用定义，也可以直接洛。</p></li>
<li><p>（Taylor 展开式的唯一性，Peano余项）。假设 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(x_0\)</span> 附近的函数，并且当 <span class="math inline">\(x\rightarrow x_0\)</span> 是，满足</p>
<p>$ f(x) &amp;= a_0 + a_1 (x-x_0) + a_2 (x-x_0)^2 + + a_n (x-x_0)^n +
o(|x-x_0|^n)\ &amp;= b_0 + b_1 (x-x_0) + b_2 (x-x_0)^2 + + b_n (x-x_0)^n
+ o(|x-x_0|^n)$</p>
<p>其中 <span class="math inline">\(a_i, b_i, i=0,\cdots,n\)</span>
是实数，那么，对任意的 <span class="math inline">\(i\)</span>，我们都有
<span class="math inline">\(a_i=b_i\)</span>。</p>
<p>有 <span class="math inline">\(\lim _{x \to x_0}
\frac{A(x)-B(x)}{(x-x_0)^n} =0\)</span>，于是有 <span class="math inline">\(a_0 = b_0,...,a_{n-1}=
b_{n-1}\)</span>，最后可以推出 <span class="math inline">\(a_n =
b_n\)</span>。</p></li>
<li><p>假设 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(0\)</span> 处有 <span class="math inline">\(n\)</span> 阶导数。证明，如果 <span class="math inline">\(f(x)\)</span> 是偶函数（奇函数）， <span class="math inline">\(f\)</span> 在 <span class="math inline">\(0\)</span> 处的Taylor展开式（Peano余项）中只有
<span class="math inline">\(x\)</span> 的偶次项（奇数项）。</p>
<p>Trivial.</p></li>
<li><p>（Rolle定理的简单推广）设函数在有限或无穷的区间 <span class="math inline">\((a,b)\)</span> 上可微并且 <span class="math inline">\(\displaystyle\lim_{x \to a^+} f(x) = \lim_{x \to
b^-} f(x)\)</span>。证明，存在 <span class="math inline">\(x_0 \in
(a,b)\)</span>，使得 <span class="math inline">\(f&#39;(x_0) =
0\)</span>。</p>
<p>如果不存在，那么 <span class="math inline">\(f&#39;(x)\)</span> 在
<span class="math inline">\((a,b)\)</span> 上恒正或恒负，<span class="math inline">\(f(x)\)</span> 在 <span class="math inline">\((a,b)\)</span> 上是严格单调函数，矛盾。</p></li>
<li><p>设函数 <span class="math inline">\(f \in C^0([a,b])\)</span>
并且在 <span class="math inline">\((a,b)\)</span> 上可微。证明，<span class="math inline">\(f\)</span> 在 <span class="math inline">\([a,b]\)</span> 上严格递增的充分必要条件是对任意
<span class="math inline">\(x\in (a,b)\)</span>，<span class="math inline">\(f&#39;(x) \geqslant 0\)</span> 并且在任意子区间
<span class="math inline">\((c,d) \subset (a,b)\)</span> 上，<span class="math inline">\(f&#39;(x)\)</span> 不恒等于 <span class="math inline">\(0\)</span>。</p>
<p>如果 <span class="math inline">\(f(x)\)</span> 在 <span class="math inline">\([a,b]\)</span>
上严格单调递增，那么这两个结论很好推。</p>
<p>如果满足这两个条件，那么至少有 <span class="math inline">\(f(x)\)</span> 在 <span class="math inline">\([a,b]\)</span> 上非严格单调递增，可能存在 <span class="math inline">\(f(x_1) =f(x_2)\)</span> 的情况，<span class="math inline">\(x_1 \neq x_2\)</span>。此时对任意 <span class="math inline">\(s \in (x_1,x_2)\)</span> 都有 <span class="math inline">\(f(s)=f(x_1)\)</span>，于是在这一子区间上 <span class="math inline">\(f&#39;(x) =0\)</span>，矛盾。</p></li>
<li><p><span class="math inline">\(g\in C(\mathbb R)\)</span> 在 <span class="math inline">\(\mathbb{R}\)</span> 上可微。假设存在常数 <span class="math inline">\(M\)</span>，使得 <span class="math inline">\(\displaystyle\sup_{x \in \mathbb{R}}|g&#39;(x)|
\leqslant M\)</span>。 对任意的 <span class="math inline">\(\varepsilon
&gt; 0\)</span>，我们定义 <span class="math inline">\(f_\varepsilon(x) =
x + \varepsilon g(x)\)</span>，证明，存在仅依赖于 <span class="math inline">\(M\)</span> 的常数 <span class="math inline">\(\delta = \delta(M) &gt; 0\)</span>，使得当 <span class="math inline">\(\varepsilon &lt; \delta\)</span> 时，<span class="math inline">\(f\colon \mathbb{R} \rightarrow \mathbb{R}\)</span>
是双射。</p>
<p>取 <span class="math inline">\(\delta = \frac{1}{2M}\)</span>
即可。</p></li>
<li><p>设函数 <span class="math inline">\(f\)</span> 在 <span class="math inline">\([a,b]\)</span> 上有两阶导数并且 <span class="math inline">\(f&#39;(a) = f&#39;(b) = 0\)</span>。证明，存在
<span class="math inline">\(c \in (a,b)\)</span> 使得 <span class="math inline">\(|f&#39;&#39;(c)| \geqslant \frac{4}{(b-a)^2}|f(b)
- f(a)|\)</span></p>
<p>存在 <span class="math inline">\(s \in (a,b)\)</span> 使得 <span class="math inline">\(f&#39;(s) = \frac{f(b)-f(a)}{b-a}\)</span>，存在
<span class="math inline">\(t \in (a,s)\)</span> 满足 <span class="math inline">\(f&#39;&#39;(t) = \frac{f&#39;(s)}{s-a} =
\frac{f(b)-f(a)}{(b-a)(s-a)}\)</span>。</p>
<p>于是 <span class="math inline">\(t\)</span> 就是满足题意的 <span class="math inline">\(c\)</span>。</p></li>
<li><p>假设 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(\mathbb{R}\)</span> 上二次可导，对 <span class="math inline">\(k=0,1,2\)</span>，我们假设 <span class="math inline">\(M_k = \displaystyle\sup_{x \in \mathbb{R}}
|f^{(k)}(x)|\)</span> 都是有限的。 证明，<span class="math inline">\(M_1^2 \leq 2 M_0 M_2\)</span>。</p>
<p>随便写个 Lagrange 余项的泰勒展开：$f(x+h)= f(x)+f'(x)h+ 2 f''(t)h^2
<span class="math inline">\(，\)</span>t (x,x+h)$。</p>
<p>然后推一个不等式就行了。</p></li>
<li><p>假设 <span class="math inline">\(f\)</span> 在 <span class="math inline">\((0,+\infty)\)</span> 上二次可导，<span class="math inline">\(f&#39;&#39;\)</span> 在 <span class="math inline">\((0,+\infty)\)</span> 上有界并且 <span class="math inline">\(\displaystyle\lim_{x \rightarrow +\infty} f(x) =
0\)</span>。证明，<span class="math inline">\(\displaystyle\lim_{x \to
+\infty} f&#39;(x) = 0\)</span>。</p>
<p>随便写个 Lagrange 余项的泰勒展开：$f(x+h)= f(x)+f'(x)h+ 2 f''(t)h^2
<span class="math inline">\(，\)</span>t (x,x+h)$。</p>
<p>取 <span class="math inline">\(x \to + \infty\)</span>，于是此时
<span class="math inline">\(f&#39;(x) =- \frac 1 2 f&#39;&#39;(t) h
+\frac{f(x+h)-f(x)}{h}\)</span>。对任意的 <span class="math inline">\(\varepsilon &gt;0\)</span>，只要取 <span class="math inline">\(|f(x+h)-f(x)|&lt;\varepsilon ^2\)</span>（Cauchy
收敛准则），取 <span class="math inline">\(h &lt;
\varepsilon\)</span>，就有 <span class="math inline">\(|f&#39;(x)|&lt;\frac{M\varepsilon}{2}\)</span>，说明它也会收敛到
<span class="math inline">\(0\)</span>。</p></li>
</ul>
<h3 id="极大值的判定">极大值的判定</h3>
<p><span class="math inline">\(f\)</span> 在 <span class="math inline">\((a,b)\)</span> 上可微。假设对于 <span class="math inline">\(x_0 \in (a,b)\)</span>，我们有 <span class="math inline">\(f&#39;(x_0) = 0\)</span>。</p>
<ul>
<li><p>证明，<span class="math inline">\(f\)</span> 在 <span class="math inline">\(x_0\)</span>
处取局部极大值的一个充分条件是：存在某一邻域 <span class="math inline">\((x_0 - \delta, x_0 + \delta) \subset
(a,b)\)</span>，使得</p>
<p><span class="math inline">\(f&#39;(x)= \begin{cases}&lt; 0, \
\text{对所有的}~x \in (x_0-\delta, x_0);\\\\&gt; 0, \ \text{对所有的}~ x
\in (x_0, x_0+\delta).\end{cases}\)</span></p>
<p>Trivial.</p></li>
<li><p>（最重要的判别方法，有很多应用）证明，如果 <span class="math inline">\(f&#39;&#39;(x_0)\)</span> 存在并且 <span class="math inline">\(f&#39;&#39;(x_0) &lt; 0\)</span>，那么 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(x_0\)</span> 处取局部极大值。</p>
<p>说明在某个邻域 <span class="math inline">\((x_0 - \delta, x_0 +
\delta) \subset (a,b)\)</span> 有 $f''(x) $，也就是 <span class="math inline">\(f&#39;(x)\)</span>
在邻域上递减，也就是上题的情况。</p></li>
<li><p>假定 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(x_0\)</span> 处有 <span class="math inline">\(n\)</span> 阶导数，<span class="math inline">\(f&#39;(x_0) = \cdots = f^{(n-1)}(x_0) = 0\)</span>
并且 <span class="math inline">\(f^{(n)}(x_0) \neq 0\)</span>，试讨论
<span class="math inline">\(f\)</span> 在 <span class="math inline">\(x_0\)</span> 处取局部极大值的条件（对 <span class="math inline">\(n\)</span> 分奇偶讨论）。</p>
<p><span class="math inline">\(f(x)-f(x_0) = \frac{1}{n!} f^{(n)} (x_0)
(x-x_0)^n + o(|x-x_0|^n)\)</span>，所以 <span class="math inline">\(n\)</span> 是奇数则不是局部最值，<span class="math inline">\(n\)</span> 是偶数且 <span class="math inline">\(f^{(n)}(x_0) &lt; 0\)</span>
局部极大，否则局部极小。</p></li>
</ul>
<h3 id="多项式的根">多项式的根</h3>
<p>（提示：利用中值定理和 <span class="math inline">\(n\)</span>-次多项式的至多（恰好）有 <span class="math inline">\(n\)</span> 个根）</p>
<ul>
<li><p>证明，如果实系数多项式 <span class="math inline">\(P_n(x) = a_n
x^n + a_{n-1} x^{n-1} + \cdots + a_0\)</span> 的根都是实数（不妨设 <span class="math inline">\(a_n\neq 0\)</span>），那么它的逐次导函数 <span class="math inline">\(P_n&#39;(x)\)</span>，<span class="math inline">\(P_n&#39;&#39;(x)\)</span> ，<span class="math inline">\(\cdots\)</span>， <span class="math inline">\(P_n^{(n-1)}(x)\)</span> 的根也都是实数。</p>
<p>只考虑一阶导数的根。<span class="math inline">\(P_n(x)\)</span> 有
<span class="math inline">\(n\)</span> 个实数根（计入重根），Rolle
定理保证 <span class="math inline">\(P_n &#39; (x)\)</span> 有 <span class="math inline">\(n-1\)</span>
个实数根（也可能计入了重根，这个并不重要），归纳即证。</p></li>
<li><p>证明，Legendre 多项式 <span class="math inline">\(P_n(x) =
\dfrac{1}{2^n n!} \dfrac{d^n}{dx^n}(x^2 - 1)^n\)</span>
的根都是实数并且包含于区间 <span class="math inline">\((-1,1)\)</span>
中。</p>
<p><span class="math inline">\(P(x) = (x^2-1)^n\)</span>
的根都是实数，这是一个 <span class="math inline">\(2n\)</span>
阶多项式，它的 <span class="math inline">\(n\)</span>
次导函数的根也一定都是实数。Rolle 定理保证这些根全部落在 <span class="math inline">\(P(x)\)</span> 的根包围的区间里。</p>
<p>还要证明 <span class="math inline">\(P_n(x)\)</span> 的根不是 <span class="math inline">\(1,-1\)</span>。这个可以通过 <span class="math inline">\(n\)</span> 次求导之后的形式确定。</p></li>
<li><p>证明，<span class="math inline">\(L_n(x) = \dfrac{e^x}{n!}
\dfrac{d^n}{dx^n}(e^{-x}x^n)\)</span>
是多项式并且它所有的根都是正实数。</p>
<p>因为这是 Laguerre 多项式！（暴论</p>
<p>类似的考虑，也很 trivial.</p></li>
<li><p>证明，<span class="math inline">\(H_n(x) = (-1)^n e^{x^2}
\dfrac{d^n}{dx^n}(e^{-x^2})\)</span>
是多项式并且它所有的根都是实数。</p>
<p>因为这是 Hermite 多项式！（什么嘛，我的数值分析学得也没那么差嘛</p>
<p>写一个递推：<span class="math inline">\(H_{n+1} (x)=2xH_n(x) -
H_n&#39; (x)\)</span>，所以是多项式。归纳地证明 <span class="math inline">\(H_n\)</span> 的所有根都是实数时，<span class="math inline">\(H_{n+1}\)</span> 的所有根都是实数。</p></li>
</ul>
<h3 id="emile-borel-引理">Emile Borel 引理</h3>
<h4 id="第一部分截断函数的构造">第一部分：截断函数的构造</h4>
<ul>
<li><p>定义函数 <span class="math inline">\(\phi\colon \mathbb
R\rightarrow \mathbb R\)</span>：</p>
<p><span class="math inline">\(\phi(x)=\begin{cases}e^{-\frac{1}{x^2}},
\ \ x&gt;0;\\0, \ \ \ \ x\leqslant 0.\end{cases}\)</span></p>
<p>证明，<span class="math inline">\(\phi\in C^\infty(\mathbb
R)\)</span>。</p>
<p>只要证明在 <span class="math inline">\(x=0\)</span>
处无限可微。实际上一阶导数是 <span class="math inline">\(0\)</span>，二阶及以上可以归纳地证明都是 <span class="math inline">\(0\)</span>。</p></li>
<li><p>定义函数 <span class="math inline">\(\chi\colon \mathbb
R\rightarrow \mathbb R\)</span>：<span class="math inline">\(\chi(x)=\frac{\phi(2-|x|)}{\phi(2-|x|)+\phi(|x|-1)}\)</span>，证明，<span class="math inline">\(\chi(x)\in C^\infty(\mathbb R)\)</span> 并且 <span class="math inline">\(\chi\big|_{[-1,1]}\equiv 1\)</span>，<span class="math inline">\(\chi\big|_{(-\infty,-2]\cup [2,\infty)}\equiv
0\)</span>，<span class="math inline">\(0\leqslant \chi(x)\leqslant
1\)</span> 并且是偶函数。</p>
<p><span class="math inline">\(\chi\big|_{[-1,1]}\equiv
1\)</span>，<span class="math inline">\(\chi\big|_{(-\infty,-2]\cup
[2,\infty)}\equiv 0\)</span>
这两个结论是显然的，所以在这几个区间上都是无限维可导。在 <span class="math inline">\([1,2]\)</span> 上显然也无限维可导，所以只要证明在
<span class="math inline">\(1\)</span> 和 <span class="math inline">\(2\)</span>
两点处无限维可导。（因为是偶函数，所以很容易可以看出负数区间上是一样的）。这两个也很好证明，一阶导数都是
<span class="math inline">\(0\)</span>。</p></li>
<li><p>证明，对任意的 <span class="math inline">\(0&lt;a&lt;b\)</span>，存在光滑偶函数 <span class="math inline">\(\rho(x)\in C^\infty(\mathbb R)\)</span>，使得
<span class="math inline">\(\rho\big|_{[-a,a]}\equiv 1\)</span>，<span class="math inline">\(\rho\big|_{(-\infty,-b]\cup [b,\infty)}\equiv
0\)</span>，<span class="math inline">\(0\leqslant \rho(x)\leqslant
1\)</span>。</p>
<p>构造 <span class="math inline">\(\rho (x) =
\frac{\phi(b-|x|)}{\phi(b-|x|)+\phi(|x|-a)}\)</span>。</p></li>
<li><p>证明，存在偶函数 <span class="math inline">\(\psi \in
C^\infty(\mathbb R^n)\)</span>，使得 <span class="math inline">\(\psi\big|_{\{x\mid|x|\leqslant 1\}}\equiv
1\)</span>，<span class="math inline">\(\psi\big|_{\{x\mid|x|\geqslant
2\}}\equiv 0\)</span>，<span class="math inline">\(0\leqslant \psi(x
)\leqslant 1\)</span>。</p>
<p>构造 <span class="math inline">\(\psi (x) =
\chi(|x|)\)</span>。</p></li>
</ul>
<h4 id="第二部分逐项求导定理">第二部分：逐项求导定理</h4>
<p><span class="math inline">\(I=[a,b]\)</span> 是闭区间，<span class="math inline">\(\{f_k\}_{k\geqslant 0}\)</span> 是 <span class="math inline">\(C^1(I)\)</span> 的一列函数，我们假设 <span class="math inline">\(\displaystyle \sum_{k=0}^\infty f_k\)</span> 在
<span class="math inline">\(I\)</span> 上逐点收敛，即对任意的 <span class="math inline">\(x\in I\)</span>，<span class="math inline">\(\displaystyle \sum_{k=0}^\infty f_k(x)\)</span>
收敛，我们记 <span class="math inline">\(f(x)=\displaystyle
\sum_{k=0}^\infty f_k(x)\)</span>。</p>
<ul>
<li><p>我们假设函数级数 <span class="math inline">\(\displaystyle
\sum_{k=0}^\infty f&#39;_k(x)\)</span> 在 <span class="math inline">\(I\)</span> 上绝对收敛，即数项的级数 <span class="math inline">\(\displaystyle \sum_{k=0}^\infty
\|f&#39;_k\|_\infty\)</span> 收敛，其中 <span class="math inline">\(\displaystyle \|f\|_\infty=\sup_{x\in
I}|f(x)|\)</span>。证明，<span class="math inline">\(f\)</span>
是可导的并且 <span class="math inline">\(f&#39;(x)=\displaystyle
\sum_{k=0}^\infty f&#39;_k(x)\)</span>。（提示：设法将求和拆 <span class="math inline">\(\displaystyle \sum_{k=0}^\infty =
\sum_{k=0}^N+\displaystyle \sum_{k=N+1}^\infty\)</span>）</p>
<p><span class="math inline">\(\displaystyle \sum_{k=0}^\infty
f&#39;_k(x)\)</span> 在 <span class="math inline">\(I\)</span>
上绝对收敛，所以 <span class="math inline">\(\displaystyle
\sum_{k=0}^\infty f&#39;_k(x)\)</span> 在 <span class="math inline">\(I\)</span>
上逐点都是收敛的，上式右端一定收敛。所以只要证明这个等号成立。</p>
<p>对任意的 <span class="math inline">\(\varepsilon
&gt;0\)</span>，找一个合适的 <span class="math inline">\(|x-x_0| &lt;
\delta\)</span> 和一个合适的 <span class="math inline">\(N \in \mathbb
Z+\)</span>，满足：</p>
<p><span class="math inline">\(|\frac{f_k(x)-f_k(x_0)}{x-x_0} - f_k
&#39;(x_0) | &lt;\varepsilon\)</span> 对 <span class="math inline">\(k=0,1,2,...,N\)</span> 都成立（导数的定义），而且
<span class="math inline">\(|\displaystyle \sum_{k=N+1}^\infty
\|f&#39;_k\|_\infty|&lt;\varepsilon\)</span>（收敛列的 Cauchy
性质）。</p>
<p>于是 $|<em>{k=0}^- </em>{k=0}<sup>f'<em>k(x)| |</em>{k=0}</sup>N -
<em>{k=0}^N f'<em>k(x)|+|</em>{k=N+1}^- </em>{k=N+1}^f'_k(x)| $。</p>
<p>右边第一项的上界是 <span class="math inline">\(N\varepsilon\)</span>，第二项用一下 Lagrange
中值定理处理前一个级数和，可以知道上界是 <span class="math inline">\(2\varepsilon\)</span>。</p>
<p>因此 <span class="math inline">\(\lim _{x \to x_0} \displaystyle
\sum_{k=0}^\infty \frac{f_k(x)-f_k(x_0)}{x-x_0}- \displaystyle
\sum_{k=0}^\infty f&#39;_k(x) =0\)</span>，也就是 <span class="math inline">\(f&#39;(x)=\displaystyle \sum_{k=0}^\infty
f&#39;_k(x)\)</span>，得证。</p></li>
<li><p>（逐项求导定理）<span class="math inline">\(I=[a,b]\)</span>
是闭区间，<span class="math inline">\(\{f_k\}_{k\geqslant 0}\)</span> 是
<span class="math inline">\(C^1(I)\)</span> 的一列函数，我们假设 <span class="math inline">\(\displaystyle \sum_{k=0}^\infty f_k\)</span> 在
<span class="math inline">\(I\)</span> 上逐点收敛。如果函数级数 <span class="math inline">\(\displaystyle \sum_{k=0}^\infty
f&#39;_k(x)\)</span> 在 <span class="math inline">\(I\)</span>
上一致收敛，那么 <span class="math inline">\(f\)</span> 是可导的并且
<span class="math inline">\(f&#39;(x)=\displaystyle \sum_{k=0}^\infty
f&#39;_k(x)\)</span>。</p>
<p>证明 <span class="math inline">\(f\)</span>
是可导的只需要证明导函数的这个式子成立。</p>
<p><span class="math inline">\(\displaystyle \sum_{k=0}^\infty
f&#39;_k(x)\)</span> 在 <span class="math inline">\(I\)</span>
上一致收敛也可以推出，对 <span class="math inline">\(\varepsilon
&gt;0\)</span>，存在某个合适的 <span class="math inline">\(N\)</span>
使得 <span class="math inline">\(|\displaystyle \sum_{k=N+1}^\infty
f&#39;_k(x)| &lt; \varepsilon\)</span> 对任意的 <span class="math inline">\(x\in I\)</span>
都成立，所以前一题不等式里的第二项仍然被 <span class="math inline">\(2\varepsilon\)</span>
控制，不等式仍然可以成立。</p>
<p>同时，<span class="math inline">\(f&#39;(x)=\displaystyle
\sum_{k=0}^\infty f&#39;_k(x)\)</span> 右端也对任意的 <span class="math inline">\(x \in I\)</span>
都是收敛级数，是良定义的。</p></li>
<li><p>试利用逐项求导定理计算 <span class="math inline">\(e^x\)</span>
的导数。</p>
<p>Trivial，无穷级数求导之后形式仍然相同。</p></li>
</ul>
<h4 id="第三部分borel引理的证明">第三部分：Borel引理的证明</h4>
<p>我们现在任意给定一个数列 <span class="math inline">\(\{a_k\}_{k\geqslant 0}\)</span>。</p>
<ul>
<li><p>对任意给定的正数 <span class="math inline">\(\lambda_k&gt;0\)</span>，试计算函数 <span class="math inline">\(f_k(x)=\dfrac{a_k}{k!}x^k\chi(t_k x)\)</span> 在
<span class="math inline">\(x=0\)</span>
处的任意阶导数（包括零阶）。</p>
<p><span class="math inline">\(n\)</span> 阶导数：$n k $ 时是 <span class="math inline">\(0\)</span>，<span class="math inline">\(n=k\)</span> 时是 <span class="math inline">\(a_k\)</span>。</p></li>
<li><p>证明，当 <span class="math inline">\(k\geqslant 2n\)</span>
时，我们有 <span class="math inline">\(f_k^{(n)}(x)=a_k\sum_{\ell=0}^n{n
\choose \ell}\frac{t_k^{n-\ell}}{(k-\ell)!}x^{k-\ell}\chi^{(n-\ell)}(t_k
x)\)</span></p>
<p>归纳就好了。</p></li>
<li><p>（Borel引理）任意给定一个数列 <span class="math inline">\(\{a_k\}_{k\geqslant 0}\)</span>，证明，存在 <span class="math inline">\(\mathbb R\)</span> 上的光滑函数 <span class="math inline">\(f\)</span>，使得对任意的 <span class="math inline">\(k\geqslant 0\)</span>，<span class="math inline">\(f^{(k)}(0)=a_k\)</span>。（提示：略难。）</p>
<p>取 <span class="math inline">\(f(x) = \displaystyle \sum_{k=0}^\infty
f_k(x)\)</span>，如果它可以逐项求导，那么是能够满足后一个条件的，所以只要证明
<span class="math inline">\(f(x)\)</span> 在 <span class="math inline">\(0\)</span>
处的导数可以通过级数的逐项求导得到。另外想证明它是光滑函数的话，要归纳证明每一阶导函数都可以继续逐项求导。</p>
<p>注意这里还有个未知的数列 <span class="math inline">\(t_k\)</span>
可以用来取值并控制这一函数，所以只要证明对任意的 <span class="math inline">\(n \in \mathbb Z +\)</span>，有 <span class="math inline">\(\displaystyle \sum_{k=0}^\infty
f^{(n)}_k(x)\)</span> 是在 <span class="math inline">\(I=[-a,a]\)</span>
上一致收敛的。</p>
<p><span class="math inline">\(k\geq 2n\)</span> 时，<span class="math inline">\(\| f^{(n)}_k \| _\infty \leq a_k A
\sum_{\ell=0}^n{n \choose \ell}\frac{t_k^{n-\ell}}{(k-\ell)!}x^{k-\ell}
\leq a_kA \sum_{\ell=0}^n{n \choose \ell}t_k^{n-\ell}a^{k-\ell}= a_kAa^k
(\frac 1 a + t_k)^n\)</span>。其中我们取 <span class="math inline">\(a =
\frac{1}{t_k}\)</span>，于是右边可以继续放缩成 <span class="math inline">\(A2^n t_k^n (a_k \frac{1}{t_k ^k})\)</span>，只要取
<span class="math inline">\(t_k = 2|a_k| +1\)</span> 就能保证 <span class="math inline">\(\displaystyle \sum_{k=2n}^\infty \| a_k
\frac{1}{t_k ^k} \|\)</span> 是收敛的。</p>
<p>于是 $_{k=0}^| f<sup>{(n)}<em>k(x) | = </em>{k=0}</sup>{2n-1} |
f<sup>{(n)}<em>k(x) | + </em>{k=2n}</sup>| f^{(n)}_k(x) | $
右边两项一个有限，一个一致收敛，因此总体也是一致收敛的。于是有 <span class="math inline">\(\displaystyle \sum_{k=0}^\infty
f^{(n)}_k(x)\)</span> 是在 <span class="math inline">\(I=[-a,a]\)</span>
上一致收敛的。</p></li>
</ul>
<h4 id="第四部分peano对borel引理的证明选做部分不交作业">第四部分：Peano对Borel引理的证明（选做部分，不交作业）</h4>
<ul>
<li><p><span class="math inline">\(\{c_k\}_{k\geqslant 0}\)</span> 和
<span class="math inline">\(\{b_k\}_{k\geqslant 0}\)</span>
是两个序列，其中 <span class="math inline">\(b_k\)</span>
都是正数。证明，</p>
<p><span class="math inline">\(\Bigl(\frac{c_k x^k}{1+b_k
x^2}\Bigr)^{(n)}(0)=\begin{cases}n!(-1)^jc_{n-2j}b_{n-2j}^j, \
\text{若}~k=n-2j, j\in \mathbb{Z}_{\geqslant 0};\\0, \ \ \
\text{其它情形}.\end{cases}\)</span></p>
<p>Trivial.</p></li>
<li><p>证明，存在常数 <span class="math inline">\(C\)</span>，对任意的
<span class="math inline">\(k\geqslant n+2\)</span>，对任意的 <span class="math inline">\(x\)</span>，我们有</p>
<p><span class="math inline">\(\Big|\Bigl(\frac{c_k x^k}{1+b_k
x^2}\Bigr)^{(n)}(x)\Big|\leqslant
C(n+1)!\frac{|c_k|k!}{b_k}|x|^{k-n-2}\)</span></p>
<p>李在赣神魔.jpg</p></li>
<li><p>证明，当 <span class="math inline">\(\{c_k\}_{k\geqslant
0}\)</span> 给定的时候，我们可以选取 <span class="math inline">\(b_k\)</span>，使得 <span class="math inline">\(b_k\)</span> 仅依赖于 <span class="math inline">\(c_k\)</span> 的选取，并且函数级数 <span class="math inline">\(\displaystyle f(x)=\sum_{k=0}^\infty \frac{c_k
x^k}{1+b_k x^2}\)</span> 是无限次可微分的。</p>
<p>如果我们只要求 <span class="math inline">\(I=(-1,1)\)</span>
的区间应该是可以做到的，让 <span class="math inline">\(b_k = \frac{|c_k|
k!}{(n+1)!}\)</span> 就可以保证 <span class="math inline">\(\displaystyle \sum_{k=n+2}^\infty \frac{c_k
x^k}{1+b_k x^2}\)</span> 的 <span class="math inline">\(n\)</span>
阶微分是收敛列，对于任意取的 <span class="math inline">\(n \in \mathbb
Z+\)</span> 可以知道 <span class="math inline">\(\displaystyle
\sum_{k=0}^{n+1} \frac{c_k x^k}{1+b_k x^2}\)</span> 的 <span class="math inline">\(n\)</span> 阶微分是有限的。所以 <span class="math inline">\(f^{(n)}(x)\)</span> 存在。</p></li>
<li><p>证明，<span class="math inline">\(f(0)=c_0\)</span>，<span class="math inline">\(f&#39;(0)=c_1\)</span>，并且当 <span class="math inline">\(n\geqslant 2\)</span> 时，我们有</p>
<p><span class="math inline">\(\frac{f^{(n)}(0)}{n!}=d_n+\sum_{j=1}^{[\frac{n}{2}]}(-1)^jc_{n-2j}b_{n-2j}^j\)</span></p>
<p>第一问给出了，trivial.</p>
<p>这里这个 <span class="math inline">\(d_n\)</span> 或许就是 <span class="math inline">\(c_n\)</span>？</p></li>
<li><p>证明，我们可以通过恰当的选取 <span class="math inline">\(\{c_k\}_{k\geqslant 0}\)</span> 和 <span class="math inline">\(\{b_k\}_{k\geqslant 0}\)</span>
来证明Borel引理。</p>
<p>李在赣神魔.jpg</p>
<p><span class="math inline">\(f\)</span>
是光滑函数已经证明了，在第三问里面我们要求 <span class="math inline">\(b_k\)</span> 是依赖于 <span class="math inline">\(c_k\)</span> 的数列，因此只要求出所有的 <span class="math inline">\(c_k\)</span> 就可以了。</p>
<p>对简单的情形，取 <span class="math inline">\(c_0 =
a_0\)</span>，<span class="math inline">\(c_1 = a_1\)</span>，<span class="math inline">\(n=2\)</span> 时可以推出 <span class="math inline">\(a_2 = 2(c_2 - c_0 b_0)\)</span>，其中 <span class="math inline">\(c_0,b_0\)</span> 都已知，可以推出 <span class="math inline">\(c_2\)</span>。找规律就知道每个 <span class="math inline">\(\frac{f^{(n)}(0)}{n!}=d_n+\sum_{j=1}^{[\frac{n}{2}]}(-1)^jc_{n-2j}b_{n-2j}^j\)</span>
式中都可以推出新的 <span class="math inline">\(c_n\)</span>，依靠的是已知的 <span class="math inline">\(c_0,c_1,...,c_n\)</span> 的信息。此时 <span class="math inline">\(f\)</span> 满足 Borel 引理，得证。</p></li>
</ul>
<h2 id="梦话-3.0为什么积分章节的习题看起来还是导数">梦话
3.0：为什么积分章节的习题看起来还是导数</h2>
<p>如果不另加说明，<span class="math inline">\(f\)</span> 总代表某区间
<span class="math inline">\(I\)</span> 上实值函数。</p>
<p>如果对任意的 <span class="math inline">\(x,y \in I\)</span> 和 <span class="math inline">\(t \in (0,1)\)</span>，都有 <span class="math inline">\(f(tx + (1-t)y) &lt; tf(x) +
(1-t)f(y)\)</span>，我们就称 <span class="math inline">\(f\)</span>
为严格凸的。仿照课堂上凹函数的定义，我们可以类似地定义严格凹的函数（即
<span class="math inline">\(-f\)</span> 是严格凸的）。</p>
<h3 id="凸函数的基本性质">凸函数的基本性质</h3>
<ul>
<li><p>试证明凸函数的如下基本性质：</p>
<ul>
<li><p>如果 <span class="math inline">\(f,g\)</span> 是区间 <span class="math inline">\(I\)</span> 上的凸函数，那么 <span class="math inline">\(f+g\)</span> 也是凸函数。</p>
<p>Trivial.</p></li>
<li><p>如果 <span class="math inline">\(f,g\)</span> 是 区间 <span class="math inline">\(I\)</span> 上的单调递增的非负的凸函数, 那么 <span class="math inline">\(fg\)</span> 是凸函数。</p>
<p>Trivial.</p></li>
<li><p>如果 <span class="math inline">\(f\)</span> 是 区间 <span class="math inline">\(I\)</span> 上的凸函数，<span class="math inline">\(g\)</span> 是 区间 <span class="math inline">\(J
\supset f(I)\)</span> 上的单调递增凸函数, 那么 <span class="math inline">\(g \circ f\)</span> 是凸函数。</p>
<p>Trivial.</p></li>
<li><p>如果 <span class="math inline">\(f,g\)</span> 是 区间 <span class="math inline">\(I\)</span> 上的凸函数, 那么 <span class="math inline">\(h(x) = \max\{f(x),g(x)\}\)</span> 是凸函数。</p>
<p>Trivial.</p></li>
</ul></li>
<li><p>假设 <span class="math inline">\(f\in
C\bigl((a,b)\bigr)\)</span>。如果对任意的 <span class="math inline">\(x,y \in (a,b)\)</span>，都有 <span class="math inline">\(\displaystyle f\left(\frac{x+y}{2}\right)
\leqslant \frac{f(x) + f(y)}{2}\)</span>，证明，<span class="math inline">\(f\)</span> 是凸函数。</p>
<p>对任意的有理数可以用二进制，无理数点可以用有理数的稠密性逼近。</p></li>
<li><p><span class="math inline">\(f\)</span> 是 <span class="math inline">\([a,b]\)</span> 上的凸函数。如果存在 <span class="math inline">\(c \in (a,b)\)</span>，使得 <span class="math inline">\(f(c) \geqslant
\max\{f(a),f(b)\}\)</span>。试证明，<span class="math inline">\(f\)</span> 是常值函数。</p>
<p>Trivial.</p></li>
<li><p><span class="math inline">\(f\)</span> 是 <span class="math inline">\(\mathbb{R}\)</span> 上的凸函数。如果 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(\mathbb{R}\)</span> 上有界，证明，<span class="math inline">\(f\)</span> 是常值函数。</p>
<p>如果不是常值函数，也就是存在 <span class="math inline">\(f(a) =
f(b)\)</span>，那对于第三个点 <span class="math inline">\(c \to
\infty\)</span> 一起比较斜率就知道 <span class="math inline">\(f(c)\)</span> 无界了。</p></li>
<li><p>设 <span class="math inline">\(f\)</span> 是区间 <span class="math inline">\(I\)</span> 上的严格凸函数。假设 <span class="math inline">\(f(x_0) \in I\)</span> 是 <span class="math inline">\(f\)</span> 的局部极小值，证明，<span class="math inline">\(x_0\)</span> 是 <span class="math inline">\(f\)</span> 唯一的整体极小值点，即对任意的 <span class="math inline">\(x \in I-\{x_0\}\)</span>，我们有 <span class="math inline">\(f(x_0) &lt; f(x)\)</span>。</p>
<p>局部极小值的意思是存在一个邻域 <span class="math inline">\(J \subset
I\)</span> 使得 <span class="math inline">\(f(x_0)\)</span>
在其中最小。取 <span class="math inline">\(x_1 \in (x_0,x_0
+\delta)\)</span>，<span class="math inline">\(x_2 \notin J\)</span> 且
<span class="math inline">\(f(x_2) \leq
f(x_0)\)</span>，比较三者的斜率知道不符合严格凸条件。</p></li>
<li><p><span class="math inline">\(I\)</span> 是开区间。证明，<span class="math inline">\(f\)</span> 是凸函数等价于对任意点 <span class="math inline">\(x_0 \in I\)</span>，存在实数 <span class="math inline">\(a \in \mathbb{R}\)</span>，使得对任意的 <span class="math inline">\(x \in I\)</span>，我们都有 <span class="math inline">\(f(x) \geqslant a(x - x_0) + f(x_0)\)</span>。</p>
<p>正推取 <span class="math inline">\(a = f&#39;(x_0)\)</span>，反推考虑
<span class="math inline">\(x_0\)</span>
和左右两点组成的三点的斜率关系。</p></li>
</ul>
<h3 id="凸函数与不等式">凸函数与不等式</h3>
<ul>
<li><p>试求所有的正数 <span class="math inline">\(a\)</span>，使得不等式
<span class="math inline">\(a^x \geqslant x^a\)</span> 对任意的 <span class="math inline">\(x &gt; 0\)</span> 都成立。</p>
<p><span class="math inline">\(x=a\)</span> 是函数 <span class="math inline">\(f(x) = a^x - x^a\)</span>
的一个零点，于是它也是一个极小值点，此处导数值为 <span class="math inline">\(0\)</span> 且二阶导数为正。</p>
<p>于是 <span class="math inline">\(a=e\)</span>。</p></li>
<li><p>证明如下不等式并给出等号成立的条件：对任意正数 $x_i $ 和 $t_i
<span class="math inline">\(（\)</span>i=1,,n<span class="math inline">\(），\)</span>_{i=1}^n t_i = 1$，都有</p>
<p>$( <em>{i=1}^n t_i x_i )^{ </em>{i=1}^n t_i x_i} _{i=1}^n x_i^{t_i
x_i} $</p>
<p>两边取对数然后用 Jensen 不等式。</p></li>
<li><p>证明Young不等式并给出等号成立的条件：对于任意正数 <span class="math inline">\(a,b\)</span>，任意的实数 <span class="math inline">\(p,q\)</span>，其中 <span class="math inline">\(\dfrac{1}{p} + \dfrac{1}{q} = 1\)</span>（我们要求
<span class="math inline">\(p\)</span> 和 <span class="math inline">\(q\)</span> 不是 <span class="math inline">\(0\)</span> 或者 <span class="math inline">\(1\)</span>），我们有</p>
<p><span class="math inline">\(ab \leqslant \frac{a^p}{p} +
\frac{b^q}{q}, \ \ \text{如果}~p &gt; 1; \ \ ab \geqslant \frac{a^p}{p}
+ \frac{b^q}{q}, \ \  \text{如果}~p &lt; 1\)</span></p>
<p>这个高中竞赛的时候就证明过，咕了。</p></li>
<li><p>证明 Holder 不等式并给出等号成立的条件：设 <span class="math inline">\(x_i,y_i \geqslant 0\)</span>，其中 <span class="math inline">\(i = 1,\cdots,n\)</span>，<span class="math inline">\(p,q \neq 0,1\)</span>，其中 $ + = 1$，我们有</p>
<p><span class="math inline">\(\sum_{i=1}^{n} x_i y_i \leqslant
\left(\sum_{i=1}^{n}x_i^p\right)^{1/p}\left(\sum_{i=1}^{n}y_i^q\right)^{1/q},
\ \text{如果}~p &gt; 1; ~\sum_{i=1}^{n} x_i y_i \geqslant
\left(\sum_{i=1}^{n}x_i^p\right)^{1/p}\left(\sum_{i=1}^{n}y_i^q\right)^{1/q},\
\text{如果}~p &lt; 1\)</span></p>
<p>在上述不等式中，如果 <span class="math inline">\(p &lt;
0\)</span>，我们假设 <span class="math inline">\(x_i &gt;
0\)</span>。（这个不等式的结论比证明重要得多，同学们可以参考其它资料来写下证明）</p>
<p>高中竞赛的时候也证明过，咕了。</p></li>
</ul>
<h3 id="利用高阶导数的信息刻画函数低阶导数">利用（高阶）导数的信息刻画函数（低阶导数）</h3>
<p>在本习题中，我们把函数 <span class="math inline">\(f\)</span> 也记为
<span class="math inline">\(f^{(0)}\)</span>。</p>
<ul>
<li><p>我们假设 <span class="math inline">\(f\in
C\bigl([0,1]\bigr)\)</span>，<span class="math inline">\(g\)</span> 在
<span class="math inline">\([0,1]\)</span> 上可导且 <span class="math inline">\(g(0) = 0\)</span>。如果存在常数 <span class="math inline">\(\lambda \neq 0\)</span>，使得对任意的 <span class="math inline">\(x\in [0,1]\)</span>，都有 <span class="math inline">\(|g(x)f(x) + \lambda g&#39;(x)| \leqslant
|g(x)|\)</span>, 证明，<span class="math inline">\(g(x) \equiv
0\)</span>。</p></li>
<li><p><span class="math inline">\(f\)</span> 在 <span class="math inline">\((-1,1)\)</span> 上二阶可导，<span class="math inline">\(f(0) = f&#39;(0) = 0\)</span>。如果对任意的 <span class="math inline">\(x\in (-1,1)\)</span>，都有 <span class="math inline">\(|f&#39;&#39;(x)| \leqslant
|f(x)|+|f&#39;(x)|\)</span>，证明，<span class="math inline">\(f(x)
\equiv 0\)</span>。</p></li>
<li><p>设 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(\mathbb R\)</span> 上二阶可导，满足 <span class="math inline">\(f(0) = f&#39;(0) = 0\)</span>, 且存在正实数 <span class="math inline">\(C\)</span> 使得, 对所有的 <span class="math inline">\(x\in \mathbb R\)</span>, 有 <span class="math inline">\(|f&#39;&#39;(x)| \le
C|f(x)f&#39;(x)|\)</span>。证明，<span class="math inline">\(f(x) \equiv
0\)</span>, <span class="math inline">\(\forall x \in \mathbb
R\)</span>。</p></li>
<li><p><span class="math inline">\(n\)</span> 是正整数，<span class="math inline">\(f\)</span> 在 <span class="math inline">\(\mathbb
R\)</span> 上 <span class="math inline">\(n\)</span> 阶可导，<span class="math inline">\(f(0) = f&#39;(0) = \cdots = f^{(n-1)}(0) =
0\)</span>。如果 <span class="math inline">\(C\in\mathbb{R}_{&gt;0}\)</span> 和 <span class="math inline">\(\ell \in \mathbb{Z}_{\geqslant
0}\)</span>，使得对任意 <span class="math inline">\(x\in \mathbb
R\)</span> 都有 <span class="math inline">\(|f^{(n)}(x)| \leqslant
C|f^{(\ell)}(x)|\)</span>，证明，<span class="math inline">\(f(x) \equiv
0\)</span>。</p></li>
<li><p><span class="math inline">\(n\)</span> 是正整数，证明，多项式
<span class="math inline">\(\displaystyle P(x) = \sum_{k=0}^{n+1}
C_{n+1}^k (-1)^k (x-k)^n\)</span> 是 <span class="math inline">\(0\)</span>。</p>
<p>考虑 <span class="math inline">\(x^i\)</span> 的系数，全都是 <span class="math inline">\(0\)</span>。（好怪</p></li>
<li><p><span class="math inline">\(f\in C^\infty(\mathbb
R)\)</span>。假设存在正实数 <span class="math inline">\(C\)</span>，使得对任意 <span class="math inline">\(n \in \mathbb{Z}_{\geqslant 0}\)</span> 和任意的
<span class="math inline">\(x \in \mathbb R\)</span>，我们都有 <span class="math inline">\(|f^{(n)}(x)| \leqslant C\)</span>。</p>
<ul>
<li><p>证明，给定任意的 <span class="math inline">\(x_0 \in \mathbb
R\)</span>，我们可以(以 <span class="math inline">\(x_0\)</span>
为中心)将 <span class="math inline">\(f(x)\)</span> 在 <span class="math inline">\(\mathbb R\)</span> 上展开为无穷Taylor级数，即<span class="math inline">\(f(x) = \sum_{k=0}^\infty
\frac{f^{(k)}(x_0)}{k!}(x-x_0)^k, \qquad \forall x \in \mathbb
R\)</span></p>
<p>只要证明这个级数是逐点收敛的，实际上 <span class="math inline">\(|f(x) |\leq C \exp(x-x_0)\)</span>。</p></li>
<li><p><span class="math inline">\(E\subset \mathbb R\)</span>
是一个无穷集并且有界。证明，如果 <span class="math inline">\(f\)</span>
在 <span class="math inline">\(E\)</span> 上的取值都是零，那么 <span class="math inline">\(f\equiv 0\)</span>。</p></li>
</ul></li>
<li><p>假设 <span class="math inline">\(f\in
C^2\bigl((0,1)\bigr)\)</span>，<span class="math inline">\(\displaystyle\lim_{x\to 1^-}f(x) =
0\)</span>。如果存在 <span class="math inline">\(C&gt;0\)</span>，使得对任意 <span class="math inline">\(x\in (0,1)\)</span>，我们都有不等式 <span class="math inline">\((1-x)^2|f&#39;&#39;(x)| \leqslant
C\)</span>。证明，<span class="math inline">\(\displaystyle\lim_{x\to
1^-} (1-x)f&#39;(x) = 0\)</span>.</p></li>
</ul>
<h3 id="函数的重根">函数的重根</h3>
<p>上传者注：本题题设条件下可以举出很多反例，建议读者将可微条件全部改为足够高阶连续可微，或者光滑。</p>
<p>如果 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(x_0\)</span> 的一个邻域内满足 <span class="math inline">\(f(x) = (x-x_0)^r g(x)\)</span>，其中 <span class="math inline">\(r \in \mathbb{Z}_{\geqslant 0}\)</span>，<span class="math inline">\(g\)</span> 在 <span class="math inline">\(x_0\)</span> 处连续并且 <span class="math inline">\(g(x_0) \neq 0\)</span>，那么我们就称 <span class="math inline">\(x_0\)</span> 为 <span class="math inline">\(f\)</span> 的 <span class="math inline">\(r\)</span>-重根。我们注意到，<span class="math inline">\(0\)</span>-重根并非根。</p>
<ul>
<li><p>假设 <span class="math inline">\(x_0\)</span> 是 <span class="math inline">\(f\)</span> 的 <span class="math inline">\(r\)</span>-重根，其中 <span class="math inline">\(r\geqslant 1\)</span>。证明，如果 <span class="math inline">\(g(x) = \dfrac{f(x)}{(x-x_0)^r}\)</span> 可微，那么
<span class="math inline">\(x_0\)</span> 是 <span class="math inline">\(f&#39;\)</span> 的 <span class="math inline">\((r-1)\)</span>-重根。</p>
<p><span class="math inline">\(f&#39;(x) = (x-x_0)^r g&#39;(x) - rg(x)
(x-x_0)^{r-1}\)</span>。</p></li>
<li><p>假设 <span class="math inline">\(f\)</span> 为 <span class="math inline">\(\mathbb R\)</span> 上 <span class="math inline">\(n\)</span> 阶的可微函数。证明，如果 <span class="math inline">\(f(x) = 0\)</span> 有 <span class="math inline">\(n+1\)</span> 个不同的实根，那么 <span class="math inline">\(f^{(n)}(x) = 0\)</span> 至少有一个实根。</p>
<p>不停用 Lagrange 中值定理。</p></li>
<li><p><span class="math inline">\(f\)</span> 为 <span class="math inline">\(\mathbb R\)</span> 上的可微函数。假设 <span class="math inline">\(f(x) = 0\)</span> 按重数计算恰有 <span class="math inline">\(r\)</span> 个实根，也就是说，<span class="math inline">\(f(x) = 0\)</span> 有 <span class="math inline">\(s\)</span> 个相异的实根 <span class="math inline">\(x_1, x_2, \cdots, x_s\)</span>，它们的重数分别为
<span class="math inline">\(r_1, r_2, \cdots, r_s\)</span> 并且 <span class="math inline">\(r_1+r_2 + \cdots + r_s = r\)</span>。证明，<span class="math inline">\(f&#39;(x) = 0\)</span> 按重数计至少有 <span class="math inline">\(r-1\)</span> 个根。</p>
<p><span class="math inline">\(f&#39;(x)\)</span> 对于相异的实根 <span class="math inline">\(x_1, x_2, \cdots, x_s\)</span>，它们的重数分别为
<span class="math inline">\(r_1-1, r_2-1, \cdots, r_s-1\)</span>
，并且在 <span class="math inline">\(x_1, x_2, \cdots, x_s\)</span>
之间用 Lagrange 中值定理还有 <span class="math inline">\(s-1\)</span>
个根，于是共有 <span class="math inline">\(r-1\)</span> 个根。</p></li>
<li><p>假设 <span class="math inline">\(f\)</span> 为 <span class="math inline">\(\mathbb R\)</span> 上 <span class="math inline">\(n\)</span> 阶的可微函数。证明，如果 <span class="math inline">\(f(x) = 0\)</span> 按重数计恰有 <span class="math inline">\(n+1\)</span> 个实根，那么 <span class="math inline">\(f^{(n)}(x) = 0\)</span> 至少有一个实根。</p>
<p>归纳。</p></li>
</ul>
<h1 id="积分">积分</h1>
<p>2023 年 2 月 8
日，星期三，学了半天积分结果配套的作业题还是导数题，摸不着头脑.jpg</p>
<h2 id="riemann-积分">Riemann 积分</h2>
<ul>
<li><p>阶梯函数是最简单的一类积分函数，它的积分值对于任意相容的分划都是相等的。这是一个很美妙的证明，用到了一个简单的逻辑：$$
和 <span class="math inline">\(\sigma &#39;\)</span> 的并 <span class="math inline">\(\sigma \cup \sigma &#39;\)</span>
是二者的一个加细；如果 <span class="math inline">\(\sigma_1\)</span> 是
<span class="math inline">\(\sigma _2\)</span>
的一个加细且它们都是相容的分割，那么二者的积分值相等；因此 <span class="math inline">\(\sigma\)</span> 和 <span class="math inline">\(\sigma &#39;\)</span> 的积分都和 <span class="math inline">\(\sigma \cup \sigma &#39;\)</span>
的积分相等，由任意性可知任意划分的积分都相等。</p>
<p>阶梯函数的积分是满足线性性的，它还满足一些看起来很显然但其实证明也不是很难的性质，略了。</p></li>
<li><p>为了扩大可以“积分”的函数的种类（目前只有阶梯函数积分），试一下用阶梯函数积分逼近一般的连续函数。</p>
<p>一个技术性的引理（定义），实际上类似于极限的 <span class="math inline">\(\delta - \varepsilon\)</span>
描述和点列描述法：</p>
<blockquote>
<p><span class="math inline">\(I=[a,b]\)</span> 是有界闭区间，<span class="math inline">\(f\colon I\rightarrow \mathbb R\)</span>
是函数，如下命题是等价的：</p>
<ul>
<li><p>对任意的 <span class="math inline">\(\varepsilon&gt;0\)</span>，存在两个阶梯函数 <span class="math inline">\(F_\varepsilon\colon I \rightarrow \mathbb
R\)</span> 和 <span class="math inline">\(\Psi_\varepsilon\colon I
\rightarrow \mathbb R\)</span>，使得对任意的 <span class="math inline">\(x\in I\)</span>，都有</p>
<p><span class="math inline">\(\big|f(x)-F_\varepsilon(x)\big|&lt;\Psi_\varepsilon(x)\)</span>
并且 <span class="math inline">\(\int_I \Psi_\varepsilon
&lt;\varepsilon\)</span></p></li>
<li><p>存在两个阶梯函数的序列 <span class="math inline">\(\{f_n\}_{n\geqslant 1} \subset
\mathcal{E}(I)\)</span> 和 <span class="math inline">\(\{\psi_n\}_{n\geqslant 1} \subset
\mathcal{E}(I)\)</span>，使得对任意的 <span class="math inline">\(x\in
I\)</span>，都有</p>
<p><span class="math inline">\(\big|f(x)-f_n(x)\big|&lt;\psi_n(x)\)</span> 并且 $
_{n}_I _n =0$</p></li>
</ul>
</blockquote>
<p>满足二者之一时，称 <span class="math inline">\(f\)</span>
可以被阶梯函数逼近，是区间 <span class="math inline">\(I\)</span> 上
Riemann 可积的函数。<span class="math inline">\(\mathcal R (I)\)</span>
表示全体 <span class="math inline">\(I\)</span> 上 Riemann
可积的函数。此时可以定义 <span class="math inline">\(f\)</span> 的
Riemann 积分：<span class="math inline">\(\int_{I}=\int_{a}^b\colon
\mathcal{R}(I)\rightarrow V, \ \ f\mapsto \lim_{n\rightarrow \infty}
\int_a^b f_n\)</span>。</p>
<p>关于这个定义为什么是良定义的问题，首先要证明上述极限存在，再证明
<span class="math inline">\(f\)</span> 的积分定义不依赖于具体的 <span class="math inline">\(\lbrace f_n \rbrace\)</span> 和 <span class="math inline">\(\lbrace \psi_n
\rbrace\)</span>，实际上它们都是简单的阶梯函数，所以由定义都是容易证明的。</p></li>
<li><p>研究一下 <span class="math inline">\(I\)</span> 上的 Riemann
可积空间 <span class="math inline">\(\mathcal R (I)\)</span>
的性质，由于我之前根本没学会这个，还是写细一点。</p>
<p>比较容易证明的几个性质是：<span class="math inline">\(\mathcal R
(I)\)</span> 是实数域上的线性空间，<span class="math inline">\(\mathcal
R(I)\)</span> 上的函数都有界（注意 <span class="math inline">\(I\)</span>
还是一个闭区间的情况，这里还没有研究到广义积分），阶梯函数都在 <span class="math inline">\(\mathcal R (I)\)</span> 中，Riemann
可积函数取绝对值也还是 Riemann 可积的，乘积也是 Riemann 可积的。</p>
<p>其他的性质有：<span class="math inline">\(\mathcal R (I)\)</span>
包含所有的 <span class="math inline">\(C(I)\)</span>
上函数（利用一致连续性手动切出逼近的阶梯函数），有限维的情况。</p>
<blockquote>
<p><span class="math inline">\(C(I)\subset \mathcal{R}(I)\)</span>。</p>
<p>假设 <span class="math inline">\(f\in C(I)\)</span>，根据 <span class="math inline">\(f\)</span> 的一致连续性，对任意的 <span class="math inline">\(\varepsilon&gt;0\)</span>，存在 <span class="math inline">\(n\in\mathbb{Z}_{\geqslant
1}\)</span>，使得对任意的 <span class="math inline">\(x,y\in
I\)</span>，当 <span class="math inline">\(|x-y|&lt;\dfrac{1}{n}\)</span> 时，我们有 <span class="math inline">\(|f(x)-f(y)|&lt;\frac{\varepsilon}{b-a}\)</span>。此时，我们令</p>
<p><span class="math inline">\(F(x)=\sum_{k=1}^n
f\bigl(a+k\frac{b-a}{n}\bigr)\mathbf{1}_{[a+(k-1)\frac{b-a}{n},a+k\frac{b-a}{n}]}(x)\)</span>，</p>
<p>其中，<span class="math inline">\(\mathbf{1}_{[a+(k-1)\frac{b-a}{n},a+k\frac{b-a}{n}]}\)</span>
是示性函数。这个 <span class="math inline">\(F(x)\)</span>
显然是阶梯函数。由一致连续性，我们知道</p>
<p><span class="math inline">\(\big|f(x)-F(x)\big|&lt;\Psi_\varepsilon(x)\equiv
\frac{\varepsilon}{b-a}\)</span>，所以，<span class="math inline">\(\int_a^b \Psi_\varepsilon(x)
=\varepsilon\)</span>。从而，<span class="math inline">\(f\)</span>
是Riemann可积的函数。</p>
</blockquote></li>
</ul>
<h2 id="darboux-上下和">Darboux 上下和</h2>
<p>这是一个刻画 Riemann 可积的实数值函数的方法。</p>
<p>当然，刻画 Riemann
可积函数的方式一共有四种，彼此等价，具体就不说了，可见：<a href="https://www.bananaspace.org/wiki/%E8%AE%B2%E4%B9%89:%E6%95%B0%E5%AD%A6%E5%88%86%E6%9E%90/Riemann_%E5%8F%AF%E7%A7%AF%E5%87%BD%E6%95%B0%E7%9A%84%E5%88%BB%E7%94%BB,_Newton%E2%80%93Leibniz_%E5%85%AC%E5%BC%8F">Read
More</a></p>
<h2 id="梦话终于找到积分的作业在哪了但是还没写">梦话：终于找到积分的作业在哪了但是还没写</h2>
<h3 id="积分定义的补充与扩展">积分定义的补充与扩展</h3>
<p>我们总假设 <span class="math inline">\(I=[a,b]\subset \mathbb
R\)</span> 是一个有界闭区间，<span class="math inline">\(V\)</span>
是一个赋范线性空间。</p>
<ul>
<li><p><span class="math inline">\(\sigma_1,\sigma_2\in
\mathcal{S}\)</span> 是两个分划。证明，对任意的 <span class="math inline">\(\varepsilon&gt;0\)</span>，总存在分划 <span class="math inline">\(\sigma\)</span>，使得 <span class="math inline">\(\sigma\prec \sigma_1\)</span>，<span class="math inline">\(\sigma\prec \sigma_2\)</span> 并且它的步长 <span class="math inline">\(|\sigma|&lt;\varepsilon\)</span>。</p>
<p>对 <span class="math inline">\(\sigma_1 \cup \sigma_2\)</span>
再加细就可以了。</p></li>
<li><p>考虑在 <span class="math inline">\(V\)</span>
中取值的阶梯／简单函数的空间 <span class="math inline">\(\mathcal{E}(I)\)</span>，证明，这是 <span class="math inline">\(\mathbb R\)</span>-线性空间并且积分算子 <span class="math inline">\(\displaystyle\int_{a}^b\colon
\mathcal{E}(I)\rightarrow V\)</span>
是良好定义的（不依赖于分划的选取）并且是线性映射，其中积分的定义方式与函数在
<span class="math inline">\(\mathbb R\)</span>
中取值时的方式一致。据此，用阶梯函数逼近的方式定义在 <span class="math inline">\(V\)</span>
中取值的Riemann可积的函数。你不需要写下细节但是你应该对照笔记研究原来证明的每一步。</p></li>
<li><p>假设 <span class="math inline">\(f\colon I\rightarrow
\mathbb{R}^n\)</span>，其中 <span class="math inline">\(f_i\)</span> 是
<span class="math inline">\(f\)</span> 的每个分量。那么 <span class="math inline">\(f\in \mathcal{R}(I)\)</span> 当且仅当对每个分量
<span class="math inline">\(f_i\)</span> 我们都有 <span class="math inline">\(f_i\in \mathcal{R}(I)\)</span>。特别地，当 <span class="math inline">\(f\colon \mathbb R\rightarrow \mathbb{C}\)</span>
时，我们有 <span class="math inline">\(\displaystyle \int_a^b f =
\int_a^b \mathbb Re f+i\int_{a}^b \Im f\)</span>，其中 <span class="math inline">\(\mathbb Re f\)</span> 和 <span class="math inline">\(\Im f\)</span> 分别为 <span class="math inline">\(f\)</span> 的实部和虚部。</p></li>
<li><p>试证明积分的区间可加性：假设 <span class="math inline">\(a&lt;c&lt;b\)</span>，那么对于任意的 <span class="math inline">\(f\in \mathcal{R}(I)\)</span>，我们有 <span class="math inline">\(f\)</span> 在 <span class="math inline">\([a,c]\)</span> 和 <span class="math inline">\([c,b]\)</span> 上的限制都是阶梯函数，并且 <span class="math inline">\(\int_{a}^b f =\int_{a}^c f+\int_c^b
f\)</span>。</p></li>
<li><p>证明，对于任意两个分划 <span class="math inline">\(\sigma\)</span> 和 <span class="math inline">\(\sigma&#39;\)</span>，它们所对应的Darboux上下和满足</p>
<p><span class="math inline">\(\underline{S}(f;\sigma)\leqslant
\overline{S}(f;\sigma&#39;)\)</span></p>
<p>据此证明，如果 <span class="math inline">\(f\in
\mathcal{R}(I)\)</span>，就有 <span class="math inline">\(\displaystyle\lim_{|\sigma|\rightarrow
0}|\underline{S}(f;\sigma)-\overline{S}(f;\sigma)|=0\)</span>，即对任意的
<span class="math inline">\(\varepsilon&gt;0\)</span>，一定存在 <span class="math inline">\(\delta&gt;0\)</span>，对任意的分划 <span class="math inline">\(\sigma\)</span>，只要 <span class="math inline">\(|\sigma|&lt;\delta\)</span>，我们就有 <span class="math inline">\(|\underline{S}(f;\sigma)-\overline{S}(f;\sigma)|&lt;\varepsilon\)</span></p></li>
<li><p><span class="math inline">\(f\in
\mathcal{R}(I)\)</span>。证明，改变 <span class="math inline">\(f\)</span>
在有限个点上的取值所得到的函数仍是Riemann可积的并且积分与 <span class="math inline">\(f\)</span> 的相同。</p></li>
<li><p><span class="math inline">\(f\in C([a,b])\)</span>。假设对任意的
<span class="math inline">\(x\in I\)</span>，我们都有 <span class="math inline">\(f(x)\geqslant 0\)</span> 并且存在点 <span class="math inline">\(x_0 \in I\)</span> 使得 <span class="math inline">\(f(x_0) &gt; 0\)</span>。 证明，<span class="math inline">\(\displaystyle\int_a^b f &gt; 0\)</span>。</p></li>
<li><p>（不定积分的分部积分公式：对计算不定积分有用）假设 <span class="math inline">\(f,g\in C^1(I)\)</span>，那么，我们有</p>
<p><span class="math inline">\(\int f&#39;\cdot g=f\cdot g-\int f\cdot
g&#39;\)</span></p></li>
<li><p>（不定积分的变量替换公式：对计算不定积分有用）假设 <span class="math inline">\(\Phi\colon \mathbb R\rightarrow \mathbb R\)</span>
可微，<span class="math inline">\(f\)</span> 是连续函数，那么</p>
<p><span class="math inline">\(\int (f\circ \Phi)\Phi&#39;=\int
f\)</span></p></li>
</ul>
<h3 id="思考题多项式逼近和weierstrass--stone定理">思考题：多项式逼近和Weierstrass--Stone定理</h3>
<p>我们要证明如下著名的定理：任意给定有界闭区间 <span class="math inline">\(I=[a,b]\)</span>
上的连续函数，我们总是可以用一个多项式来足够好地逼近它。更精确地说，给定
<span class="math inline">\(f\in C([a,b])\)</span>，对任意的 <span class="math inline">\(\varepsilon&gt;0\)</span>，存在多项式 <span class="math inline">\(P_\varepsilon\)</span>，使得 <span class="math inline">\(\displaystyle \sup_{x\in
[a,b]}|f(x)-P_\varepsilon(x)|&lt;\varepsilon\)</span>，即若用 <span class="math inline">\(P([a,b])\)</span> 表示 <span class="math inline">\([a,b]\)</span> 上多项式函数组成的空间，则 <span class="math inline">\(P([a,b])\)</span> 在度量空间 <span class="math inline">\(C([a,b])\)</span> 中稠密（<span class="math inline">\(C([a,b])\)</span> 上用的范数是 <span class="math inline">\(\|f\|_\infty=\displaystyle \sup_{x\in
[a,b]}|f(x)|\)</span>）。</p>
<h4 id="dini定理及应用">Dini定理及应用</h4>
<ul>
<li><p>（Dini定理）假设 <span class="math inline">\(K\subset \mathbb
R^n\)</span> 是紧子集，<span class="math inline">\(f_n\colon
K\rightarrow \mathbb R\)</span> 是一列连续函数，它们逐点地收敛到连续函数
<span class="math inline">\(f\colon K\rightarrow \mathbb
R\)</span>，即对每个 <span class="math inline">\(x\in
K\)</span>，我们都有 <span class="math inline">\(\displaystyle
\lim_{n\rightarrow \infty}f_n(x)=f(x)\)</span>。证明，如果 <span class="math inline">\(\{f_n\}_{n\geqslant 1}\)</span>
是上升的函数列（即对任意 <span class="math inline">\(x\in K\)</span> 和
<span class="math inline">\(n\)</span>，我们都有 <span class="math inline">\(f_n(x)\leqslant f_{n+1}(x)\)</span>），那么 <span class="math inline">\(f_n\)</span> 一致收敛到 <span class="math inline">\(f\)</span>。（参考荆公子的某次习题课）</p></li>
<li><p>考虑区间 <span class="math inline">\(I=[-1,1]\)</span>。我们通过归纳的方式定义一族多项式函数：</p>
<p><span class="math inline">\(P_0(x)=0, \ \
P_{n+1}(x)=P_n(x)+\frac{1}{2}(x^2-P_n^2(x))\)</span></p>
<p>证明，对任意的 <span class="math inline">\(n\)</span> 和 <span class="math inline">\(x\)</span>，我们都有 <span class="math inline">\(0\leqslant P_n(x)\leqslant P_{n+1}(x)\leqslant
|x|\)</span>。</p></li>
<li><p>证明，绝对值函数 <span class="math inline">\(|x|\)</span> 在
<span class="math inline">\(I=[-1,1]\)</span>
上可以被多项式一致地逼近，即对任意的 <span class="math inline">\(\varepsilon&gt;0\)</span>，存在某个多项式函数
<span class="math inline">\(P_\varepsilon(x)\)</span>，使得 <span class="math inline">\(\displaystyle \sup_{x\in
[-1,1]}\big||x|-P_\varepsilon(x)\big|&lt;\varepsilon\)</span>。</p></li>
</ul>
<h4 id="区间上的情形">区间上的情形</h4>
<p>这一部分中，我们假设 <span class="math inline">\(I=[0,1]\)</span>，<span class="math inline">\(n\)</span> 是正整数。</p>
<ul>
<li><p>对任意的 <span class="math inline">\(0\leqslant k\leqslant
n\)</span>，我们定义 <span class="math inline">\(p_{n,k}(x)=\displaystyle{n \choose
k}x^k(1-x)^{n-k}\)</span>。证明，<span class="math inline">\(\displaystyle \sum_{0\leqslant k \leqslant
n}p_{n,k}(x-\frac{k}{n})^2=\frac{x(1-x)}{n}\)</span>。</p></li>
<li><p>任意给定 <span class="math inline">\(f\in
C([0,1])\)</span>，我们定义 <span class="math inline">\(B_{f,n}(x)=
\displaystyle\sum_{0\leqslant k \leqslant n}f\bigl(\frac{k}{n}\bigr){n
\choose k}x^k(1-x)^{n-k}\)</span>。对 <span class="math inline">\(x\in
[0,1]\)</span>，证明，</p>
<p><span class="math inline">\(|f(x)-B_{f,n}(x)|\leqslant \sum_{k=0}^n
\bigl|f(x)-f\bigl(\frac{k}{n}\bigr)\bigr|p_{n,k}(x)\)</span></p></li>
<li><p>（用Bernstein多项式逼近连续函数）任意给定 <span class="math inline">\(f\in C([0,1])\)</span>，证明，对任意 <span class="math inline">\(\varepsilon&gt;0\)</span>，总存在 <span class="math inline">\(n\)</span>，使得 <span class="math inline">\(\|f-B_{f,n}\|_\infty
&lt;\varepsilon\)</span>。</p></li>
</ul>
<blockquote>
<p>Remark：用概率论的观点，<span class="math inline">\(x\in
[0,1]\)</span> 给定，Bernstein多项式逼近的的方法讲的是概率测度</p>
<p><span class="math inline">\(\mu_x=\displaystyle\sum_{k=0}^n {n
\choose j}x^k(1-x)^{n-k}\delta_{\frac{k}{n}}\)</span> 的极限是Dirac测度
<span class="math inline">\(\delta_x\)</span>。</p>
</blockquote>
<h4 id="紧集上的情形">紧集上的情形</h4>
<p>从此往后，我们假设 <span class="math inline">\(K\subset \mathbb
R^n\)</span> 是紧集，<span class="math inline">\(C(K)\)</span> 是 <span class="math inline">\(K\)</span> 上的实数值连续函数所构成的线性空间，用
<span class="math inline">\(P(K)\)</span> 表示 <span class="math inline">\(K\)</span> 上多项式函数组成的空间（即形如 <span class="math inline">\(\displaystyle \sum_{|\alpha|\leqslant m} c_\alpha
x^\alpha\)</span> 的函数，其中 <span class="math inline">\(m\)</span>
是正整数，<span class="math inline">\(\alpha\)</span>
是多重指标，请参见关于多重偏导数的课堂笔记）。</p>
<ul>
<li><p>假设 <span class="math inline">\(\mathcal{A}\subset C(K)\)</span>
是非零的线性子空间。如果对任意的 <span class="math inline">\(f,g\in
\mathcal{A}\)</span>，它们的乘积 <span class="math inline">\(f\cdot g
\in \mathcal{A}\)</span>，我们就把 <span class="math inline">\(\mathcal{A}\)</span> 称作是 <span class="math inline">\(C(K)\)</span> 的一个子代数。证明，<span class="math inline">\(P(K)\)</span> 是 <span class="math inline">\(C(K)\)</span> 的子代数。</p></li>
<li><p>非零的线性子空间 <span class="math inline">\(\mathcal{A}\subset
C(K)\)</span> 是闭子代数，也就是说如果 <span class="math inline">\(\{f_k\}_{k \geqslant 1}\subset
\mathcal{A}\)</span>，<span class="math inline">\(f_k\)</span>
一致收敛到 <span class="math inline">\(f\)</span>，那么 <span class="math inline">\(f\in \mathcal{A}\)</span>。假设常值函数 <span class="math inline">\(1\in \mathcal{A}\)</span>，证明，如果 <span class="math inline">\(f\in \mathcal{A}\)</span>，那么 <span class="math inline">\(|f|\in \mathcal{A}\)</span>。(提示: 利用
W3)</p></li>
<li><p>假设 <span class="math inline">\(\mathcal{A}\subset C(K)\)</span>
是子集，如果对任意的 <span class="math inline">\(x,x&#39;\in
K\)</span>，<span class="math inline">\(x\neq x&#39;\)</span>，都存在
<span class="math inline">\(f\in \mathcal{A}\)</span>，使得 <span class="math inline">\(f(x)\neq f(x&#39;)\)</span>，我们就称 <span class="math inline">\(\mathcal{A}\)</span> 是能够区分点的。证明，<span class="math inline">\(P(K)\)</span> 是能够区分点的。</p></li>
<li><p>假设 <span class="math inline">\(f,g\in C(K)\)</span>。证明，函数
<span class="math inline">\(f\wedge g (x)=\min\{f(x),g(x)\}\)</span> 和
<span class="math inline">\(f\vee g (x)=\max\{f(x),g(x)\}\)</span>
都是连续的。</p></li>
<li><p>假设 <span class="math inline">\(\mathcal{A}\subset C(K)\)</span>
是子集，如果对任意的 <span class="math inline">\(f,g\in
\mathcal{A}\)</span>，<span class="math inline">\(f\wedge g, f\vee g \in
\mathcal{A}\)</span>，我们就称 <span class="math inline">\(\mathcal{A}\)</span> 是 <span class="math inline">\(\wedge\vee\)</span>-封闭的。证明，<span class="math inline">\(\overline{P(K)}\)</span> 是 <span class="math inline">\(\wedge\vee\)</span>-封闭的，其中 <span class="math inline">\(\overline{P(K)}=\bigl\{f\in
C(K)\bigm|\text{存在}\{f_k\}_{k\geqslant1}\subset P(K),
f_k\text{一致收敛到}f\bigr\}\)</span> 为 <span class="math inline">\(P(K)\)</span> 在 <span class="math inline">\(C(K)\)</span> 中的闭包。</p></li>
<li><p>我们现在假设 <span class="math inline">\(\mathcal{A}\subset
C(K)\)</span> 是 <span class="math inline">\(\wedge\vee\)</span>-封闭的，并且对任意的 <span class="math inline">\(\alpha,\beta \in \mathbb R\)</span>，任意的 <span class="math inline">\(x,y \in K\)</span>，<span class="math inline">\(x\neq y\)</span>（我们此时假设 <span class="math inline">\(K\)</span> 至少含有两个点）都存在函数 <span class="math inline">\(\varphi\in A\)</span>，使得 <span class="math inline">\(\varphi(x)=\alpha\)</span>，<span class="math inline">\(\varphi(y)=\beta\)</span>。</p>
<p>我们通过下面的步骤来证明 <span class="math inline">\(\mathcal{A}\subset C(K)\)</span>
是稠密的（即对任意给定的连续函数 <span class="math inline">\(f\in
C(K)\)</span>，对任意的 <span class="math inline">\(\varepsilon&gt;0\)</span>，总存在 <span class="math inline">\(\varphi \in \mathcal{A}\)</span>，使得 <span class="math inline">\(\|\varphi-f\|_{\infty}&lt;\varepsilon\)</span>）：</p>
<ul>
<li>固定 <span class="math inline">\(x_0\in X\)</span>，对任意的 <span class="math inline">\(y\in K\)</span>，我们选取 <span class="math inline">\(\varphi_y\in \mathcal{A}\)</span>，使得 <span class="math inline">\(\varphi_y(x_0)=f(x_0)\)</span> 并且 <span class="math inline">\(\varphi_y(y)=f(y)\)</span>，这样我们得到一族 <span class="math inline">\(\{f_y\in \mathcal{A}\mid y\in
K\}\)</span>，据此，对每个 <span class="math inline">\(y\in
K\)</span>，可以定义 <span class="math inline">\(U_y=\{z\in K\mid
\varphi_y(z)&gt;f(z)-\varepsilon\}\)</span>。证明，存在有限个 <span class="math inline">\(y_1,\cdots,y_m\in K\)</span>，使得 <span class="math inline">\(K\subset U_{y_1}\cup \cdots \cup
U_{y_m}\)</span>。</li>
<li>证明，<span class="math inline">\(\varphi_{x_0}=\displaystyle\sup_{x\in
K}\{\varphi_{y_1}(x),\cdots, \varphi_{y_m}(x)\}\in \mathcal{A}\)</span>
并且对任意的 <span class="math inline">\(x\in K\)</span>，我们都有 <span class="math inline">\(\varphi_{x_0}(x)-f(x)&gt;-\varepsilon\)</span>。</li>
<li>证明，存在 <span class="math inline">\(\varphi \in
\mathcal{A}\)</span>，使得对任意的 <span class="math inline">\(x\in
K\)</span>，都有 <span class="math inline">\(|\varphi(x)-f(x)|&lt;\varepsilon\)</span>。</li>
</ul></li>
<li><p>证明，如果子代数 <span class="math inline">\(\mathcal{A}\subset
C(K)\)</span> 是能够区分点的，<span class="math inline">\(\wedge\vee\)</span>-封闭的并且包含所有的常数值函数，那么
<span class="math inline">\(\mathcal{A}\subset C(K)\)</span>
是稠密的。</p></li>
<li><p>（Weierstrass--Stone定理）如果 <span class="math inline">\(\mathcal{A}\subset C(K)\)</span>
是一个能区分点的子代数并且包含常值函数 <span class="math inline">\(1\)</span>，那么 <span class="math inline">\(\mathcal{A}\subset C(K)\)</span>
是稠密的。</p></li>
</ul>
<blockquote>
<p>Remark：我们还有一种复值函数的Weierstrass--Stone定理，在很多的场合有着重要的应用，有兴趣的同学可以自己查阅。</p>
</blockquote>
<ul>
<li><p>多项式函数 <span class="math inline">\(P(K)\)</span>
在连续函数空间 <span class="math inline">\(C(K)\)</span>
中是稠密的。</p></li>
<li><p>给定以 <span class="math inline">\(2\pi\)</span> 为周期的连续函数
<span class="math inline">\(f\in C(\mathbb R)\)</span>。证明，任给 <span class="math inline">\(\varepsilon&gt;0\)</span>，总存在一个有限的三角级数</p>
<p><span class="math inline">\(T(x)=\sum_{-N\leqslant k \leqslant N} a_k
\cos(kx)+\sum_{-N\leqslant k \leqslant N} b_k \sin(kx)\)</span></p>
<p>其中 <span class="math inline">\(N\)</span> 是正整数，<span class="math inline">\(a_k,b_k\)</span> 是实数，使得对任意的 <span class="math inline">\(x\in \mathbb R\)</span>，我们都有 <span class="math inline">\(|f(x)-T(x)|&lt;\varepsilon\)</span>。（提示：考虑
<span class="math inline">\(C([0,2\pi])\)</span>
和它的某个子代数）</p></li>
</ul>
]]></content>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>陆家嘴签证申请材料合集（2024 春）</title>
    <url>/2024/02/08/Lokatse-Visa-2024-Spring/</url>
    <content><![CDATA[<p>梗源：</p>
<blockquote>
<p>【上海市出入境管理局】感谢您申请陆家嘴签证。非常遗憾的通知您，由于您过去三个月没内有
City Walk, Gap Hour 及 Camping 记录，我们在 Salomon, Lululemon, Tesla,
Omakase 及 Apple Store
均未查询到您的消费记录并且查到您在蜜雪冰城消费过多杯柠檬水，故本次签证被拒。</p>
</blockquote>
<p>再来点申请文学：</p>
<p>2024 Spring 申请选手，background 不强，身份证不是 310
开头的，目前住在浦西比较远的地方，主要的几个指标都消费不起。唯一的优势是高中有过张江高科的三年学签，虽然偏了些但到底在浦东，还和陆家嘴都在二号线上，就是不知道过了几年了还有没有用，求问证明材料还需要提交当时的成绩单吗？最近是三个月内正好买了
iPad 所以在 Apple Store 买过 Lanota
曲包，数额不大，其他消费记录无。打算趁这个寒假抽几个 Gap Day 刷一些 City
Walk/Ride 记录，年后申请陆家嘴签证，方便开学前去滨江骑行道骑车（</p>
<p>说人话：摆烂一天，出去骑车玩儿了（</p>
<span id="more"></span>
<h1 id="section">2024.02.08</h1>
<p>我以前没有在上海市区骑过车。一方面是高考之后才学会骑车，后来在上海的时间就少了，另一方面你沪的共享单车比北京贵一倍，我感觉都很难有慢下来看风景的想法（，自己家里没自行车，有车也不方便带去市区，不过搬到普陀之后可以考虑，而且我毕业之后还挺想把现在的车送回家的。还有就是一直听说市区骑行管得很严交警很多，路况也不是很好，更不可能像在北京一样还能随便逆行（好孩子不要学。</p>
<p>但内环以内适合逛的就那点地方，如果想去好几个地方玩的话地铁三块钱三块钱地刷也不是很值。何况这是冬天，现在还不骑车的话难道夏天骑吗，夏天我可是会买一张一日票无论多近多绕都坐地铁的（x</p>
<h2 id="哪里可以骑车">哪里可以骑车</h2>
<p>在我高中还不会骑车的时候就听说过高中同学骑车逆行惨遭被交警拦下罚款 50
的惨案，后来也知道淮海中路自行车禁行的名梗，所以今天去市区骑车还是有那么一点点小紧张，主要还是担心在毫不知情的情况下被罚款。当然最后没有，但十字路口交警的密度还是让我大开眼界，在他们身边停下的时候还听到对讲机里在说有电瓶车沿着某条路逆行了帮忙拦一下什么的，搞得我远远看到穿黄绿马甲的人就害怕。</p>
<p>所以怎么判断哪里不能骑车？</p>
<ul>
<li><p>如果能记住<a href="http://m.sh.bendibao.com/news/274476.html">哪些路段禁行</a>就没有问题啦！上海有
124 条道路禁止骑行，也不是很多嘛（迫真</p>
<p>我今天 random <del>walk</del> ride
的过程中经过了长宁、静安、黄浦、普陀、徐汇，反正我是分不清哪个区有哪些的（</p></li>
<li><p>禁行路段路口都会有标识，但其实整得我很紧张，一个是远远看到交警就有点慌，也担心看漏了。而且因为眼神不太好今天还看混了下面这两个，一开始以为右边的也是自行车禁行所以多绕了些路，实际上只是禁三轮车和摩托车（尴尬挠头</p>
<p>但是警用摩托车似乎可以走诶。（</p>
<p><img src="https://s2.loli.net/2024/02/09/2kzmRFx3XDBlNrZ.jpg" alt="禁行标志.jpeg"></p></li>
<li><p>骑行导航能通行的地方一般是可以骑车的，一般也是准确的毕竟禁行的路就那几条。但我更喜欢
random walk
而非提前确定好去哪里以及查路线，另外需要看导航也很麻烦。</p></li>
<li><p>有自行车道的地方可以骑自行车（大概吧？</p>
<p>但市区很多年岁比较久远的窄马路（点名梧桐区）分不出自行车道来，骑行体验也不是很好（下详）。没必要用一个必要条件做判断来限制自己（</p></li>
<li><p>最后也是最粗暴的方法，如果前面有车（不是共享单车的话就很稳了）跟着骑就行了（</p></li>
</ul>
<p>总的来说不是很难，我今天唯一路过的禁行路段就是大名鼎鼎的淮海中路，这个连我都本来就知道（。</p>
<h2 id="骑行体验">骑行体验</h2>
<p>除了第一次在这边骑车担心上错路，看到交警会有点紧张之外，其实路况也不算很好。一个是很多地方没有自行车道，只能在机动车道上和车挤一挤，另外老马路凹凸不平的很多，即使看起来稍微平整的也可能很颠，共享单车没有减震器本身也不行。今天在江苏路买了两盒鲍师傅然后去骑车玩，一路上颠得我感觉在徐汇的时候海苔肉松小贝已经变成了肉松小贝海苔，到长宁恐怕已经是小贝肉松海苔了。</p>
<p>但梧桐区确实很漂亮，有很多又安静风景又好的小路。像武康路本身就是建筑保护区，愚园路这种网红景点路上人和车都很多，但不远处的余庆路和天平社区也都有非常漂亮的小洋楼，路上几乎就没人。但我好像有点改不掉一不留神就开始快骑的习惯，一条小路五六百米很快就到头了，才发现错过了一些，又不愿意掉头了。</p>
<p>另外开个骑行卡会从容很多，不用寸止停车也不担心骑慢了倾家荡产。说到底我今天突然开始骑车玩就是因为发现投放了一批青桔新车，车筐里有一块钱开七天骑行卡的活动广告。</p>
<p><img src="https://s2.loli.net/2024/02/09/x2kswKlIDVnA4zc.jpg" alt="青桔活动.jpg"></p>
<p>青桔活动这四个字看起来怎么这么像青结活动（</p>
<h2 id="风景">风景</h2>
<p>不完全是骑车的时候看到的，总之我都很喜欢。</p>
<p><img src="https://s2.loli.net/2024/02/09/8yjJuzghfndNAe1.jpg" alt="Indonesia.jpg"></p>
<p>走不出的万航渡路，而且前两天美赛的一个具体案例分析我们就选了
Indonesia，现在看到就想吐（对不起</p>
<p><img src="https://s2.loli.net/2024/02/09/aDbvUR3G4TrEyLK.jpg" alt="武康大楼.jpg"></p>
<p>我做了一个违背祖宗的决定：我去看武康大楼了（</p>
<p>楼对面拍照的人很多，位于武康路和淮海中路（自行车禁行）路口，但我其实没觉得这个楼多好看诶，像火车头（<del>我自裁</del>。但是这张的天空颜色很漂亮，紫色柔柔地晕染开来的感觉，我也梦想融入这永恒。</p>
<p><img src="https://s2.loli.net/2024/02/09/F9MYItS817ydj3m.jpg" alt="灯笼.jpg"></p>
<p>这张看起来快到天平社区了，我超级喜欢这个小灯笼，远看像小柿子一样，还会在风里轻轻地
<del>匀速</del>
转动，喜庆又不土气（说的就是你啊某些路上挂的超大灯笼。后面的树枝上面缠了红色的彩灯，像红梅一样（逆风如解意容易莫摧残.mp3），特别漂亮。</p>
<p>这就不得不提天津站附近某些树上的彩灯了（鞭尸，不是缠上去的而是披上去的，敷衍就算了，之前看到<a href="http://xhslink.com/i4d8eB">这个</a>的时候真没绷住（</p>
<p><img src="https://s2.loli.net/2024/02/09/IPzw5AKJUkCTxQX.jpg" alt="奇怪的小玩意.jpg"></p>
<p>晚上去吃饭在旁边店里看到的小玩意，古灵精怪的，好有意思哦。</p>
<p>就是贵。</p>
<h2 id="路线">路线</h2>
<p><img src="https://s2.loli.net/2024/02/09/ARQyDG8nmXhiaLK.png" alt="route_24_02_08.png"></p>
<p>太混沌了，我回来之后按照感觉上走过的地方标了一下，至少它在存在路线重复的情况下是一个连通图，吧？</p>
<p>比如说华山路的一些路段我就在不同的行程里骑了好几遍，尤其是交通大学站附近的那一小段，精神
SJTU
人实锤（但这是徐汇校区而已.jpg）。今天还验证了二维随机游走是常返的，怎么也走不出万航渡路，江苏路和华山路，虽然后两条本质上是一条路（</p>
<p>美观起见我把地图横过来了，右下角是指北针。</p>
<h1 id="section-1">2024.02.10</h1>
<p>今天沿着铜川路骑了一趟，从岚皋路下地铁然后一路骑到了定边路地铁站，没有再往嘉怡路走，<!--因为高中的时候我有个不大喜欢的女同学名字叫这个名字（？），而且那边不是铜川路了，-->就回家了。</p>
<p>一开始扫了一辆旧车，大约是到真光公园的时候觉得骑着费劲，停下来换了一辆新的。除了新之外，座椅的确比以前的要软一些。这么阔气的原因还是七天单车卡没有用完，快到期了，急急急。</p>
<h2 id="路线-1">路线</h2>
<p>可能是居民区加上在外环和中环之间的原因，这边交警密度没有市区那么恐怖，心情挺好的（？</p>
<p>铜川路就是铜川路嘛，还要什么路线图（</p>
<p><img src="https://s2.loli.net/2024/02/11/1Kkx4XEmUP5Yyvw.png" alt="route_24_02_11.png"></p>
<h1 id="section-2">2024.02.11</h1>
<p>今天还是沿着铜川路骑车，果然还是跟我妈一起骑车更有那个成就感，因为共享单车也可以拉她好远（x。去环宇城吃山石榴，然后在地下二层逛了山姆会员店。我才知道这个店它只有会员才能进去，而会员甚至每年要交
60
块钱，还是我妈这位尊贵的会员紧急送我一个亲友卡才把我带进去，然后我进去看每个人都像在看六十块钱。</p>
<p>严谨一点来说，我看两个人一起逛的就像每个人三十块钱，三个人每个人二十块钱，四个人十五，五个人十二，六个人十块，不是葫芦娃一家出来逛街的话也不太会更多了，看来这个会费设置是很有道理的。</p>
<p>感觉线下逛过山姆之后申请签证的成功率又高了一些（x</p>
<p>线路图和昨天的一样，不再放一个了（</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>数值实验顺便 Python 复健</title>
    <url>/2022/10/16/Numerical-Analysis-Experiments/</url>
    <content><![CDATA[<p>数值分析的上机实验难度为 <span class="math inline">\(10\)</span>
的话，纸笔题的难度恐怕就是碘化银的 <span class="math inline">\(K_{sp}\)</span>（大致是 <span class="math inline">\(4.2×10^{−51}\)</span>（</p>
<p>我不会 MATLAB，又懒得学，就选了 Python。反正作业就是造轮子，也不能用
MATLAB 的函数，那 Python 不亏。</p>
<span id="more"></span>
<p>声明：本文更新时间均在数值实验作业截止日期后，详情可查询 commits
记录，不存在任何抄袭或协助抄袭现象。</p>
<h1 id="线性方程组直接解法">线性方程组直接解法</h1>
<p>一开始还是有点虚的，NumPy 和 Pandas
都是前学后忘，于是第一次作业拖到周末才写，意外地顺利。</p>
<p>反正就是不停地写循环，略烦。</p>
<h2 id="ldlt-法"><span class="math inline">\(LDL^T\)</span> 法</h2>
<ul>
<li><p>算法就是 <span class="math inline">\(LDL^T\)</span>
法。书上啥都有。</p>
<p>比较痛的一点是，这个方法为了提高效率把 <span class="math inline">\(L\)</span> 和 <span class="math inline">\(D\)</span> 直接存储在 <span class="math inline">\(A\)</span>
里了，但是最后计算误差的时候需要调用原值 <span class="math inline">\(A\)</span>，所以做分解之前应该先备份一个原矩阵。向量
<span class="math inline">\(b\)</span> 的备份同理。</p></li>
<li><p>实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 任务一：改进的平方根法求解线性方程组</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy.linalg <span class="keyword">import</span> norm</span><br><span class="line"></span><br><span class="line">n = <span class="number">32</span></span><br><span class="line">H = <span class="number">1.</span>/(np.arange(<span class="number">1</span>, n + <span class="number">1</span>)+np.arange(<span class="number">0</span>, n)[:,np.newaxis])  <span class="comment">#构造n阶Hilbert矩阵</span></span><br><span class="line">xtrue = np.ones((n, <span class="number">1</span>))</span><br><span class="line">x = np.ones((n, <span class="number">1</span>))</span><br><span class="line">b = H.dot(xtrue)</span><br><span class="line"></span><br><span class="line"><span class="comment">#待定系数法计算LDL^t分解</span></span><br><span class="line">K = H.copy()</span><br><span class="line">c = b.copy()</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, n):</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, j):</span><br><span class="line">        K[j, j] = K[j, j] - K[j, k] * K[j, k] * K[k, k]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(j + <span class="number">1</span>, n):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, j):</span><br><span class="line">            K[i, j] = K[i, j] - K[i, k] * K[j, k] * K[k, k]</span><br><span class="line">        K[i,j] = K[i, j] / K[j, j]</span><br><span class="line"></span><br><span class="line"><span class="comment">#写出L和D的具体形式</span></span><br><span class="line">L = np.zeros((n, n))</span><br><span class="line">D = np.zeros((n, n))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, n):</span><br><span class="line">    L[i, i] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, i):</span><br><span class="line">        L[i, j] = K[i, j]</span><br><span class="line">    D[i, i] = K[i, i]</span><br><span class="line"></span><br><span class="line"><span class="comment">#解方程Ly=b</span></span><br><span class="line">y = np.zeros((n, <span class="number">1</span>))</span><br><span class="line">y[<span class="number">0</span>] = c[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, i):</span><br><span class="line">        c[i] = c[i] - K[i, j] * y[j]</span><br><span class="line">    y[i] = c[i]</span><br><span class="line"></span><br><span class="line"><span class="comment">#解方程DL^tx=y</span></span><br><span class="line">x = np.zeros((n, <span class="number">1</span>))</span><br><span class="line">x[n-<span class="number">1</span>] = c[n-<span class="number">1</span>] / K[n-<span class="number">1</span>,n-<span class="number">1</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">2</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">    x[i] = y[i] / K[i,i]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, n):</span><br><span class="line">        x[i] = x[i] - K[j,i] * x[j]</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;相对残量为: %.4f&#x27;</span>%(norm(b - np.matmul(H, x)) / norm(b)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;相对误差为: %.4f&#x27;</span>%(norm(x - xtrue) / norm(xtrue)))</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">相对残量为: <span class="number">0.0000</span></span><br><span class="line">相对误差为: <span class="number">111.3149</span></span><br></pre></td></tr></table></figure>
<p>残量为 <span class="math inline">\(0\)</span> 说明分解正确。考虑到
<span class="math inline">\(Hilbert\)</span>
矩阵是个病态矩阵，这个值还算可以接受。虽然真值是一个分量全为 <span class="math inline">\(1\)</span> 的 <span class="math inline">\(32\)</span> 阶向量，而数值解从第 <span class="math inline">\(7\)</span>
个分量开始就大量出现绝对值是两位数的情况了。</p>
<p><span class="math inline">\(LDL^T\)</span> 分解从结果来看仍然是 <span class="math inline">\(LU\)</span> 分解的一种变形，但在本实验中，利用
<span class="math inline">\(LU\)</span>
分解得到的数值解各分量量级偏小，甚至达到 <span class="math inline">\(10^{-5}\)</span> 级别。输出结果为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">相对残量为: <span class="number">0.0000</span></span><br><span class="line">相对误差为: <span class="number">73385.0585</span></span><br></pre></td></tr></table></figure>
<p>相对误差大了两个量级，说明对于对称矩阵来说 <span class="math inline">\(LDL^T\)</span> 分解是更好的选择。</p>
<p>我在做数值实验的过程中先解决了 <span class="math inline">\(LU\)</span> 分解，回头又做了 <span class="math inline">\(LDL^T\)</span>
分解，因此二者的结果不能很好地匹配也造成了不小的困难..</p></li>
</ul>
<h2 id="lu-法"><span class="math inline">\(LU\)</span> 法</h2>
<ul>
<li><p>我感觉最难的是从 <code>.mat</code> 文件里载入矩阵...</p>
<p><span class="math inline">\(LU\)</span>
法，学过线代就能做，我大一上学期的 C++ 大作业里还写这个了..</p></li>
<li><p>实现如下：</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 任务二：实现按列存储的JKI型LU分解</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> loadmat</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy.linalg <span class="keyword">import</span> norm</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">LU_JKI</span>(<span class="params">B</span>):</span><br><span class="line">    A = B.copy()</span><br><span class="line">    (m, n) = A.shape  <span class="comment">#本任务中m=n</span></span><br><span class="line">    L = np.zeros((m, n))</span><br><span class="line">    U = np.zeros((m, n))</span><br><span class="line">    <span class="comment">#计算L矩阵和U矩阵</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, i):</span><br><span class="line">            A[i, k] = A[i, k] / A[k, k]</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(k + <span class="number">1</span>, n):</span><br><span class="line">                A[i, j] = A[i, j] - A[i, k] * A[k, j]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, n):</span><br><span class="line">        L[i, i] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, i):</span><br><span class="line">            L[i, j] = A[i, j]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, n):</span><br><span class="line">            U[i, j] = A[i, j]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> L,U</span><br><span class="line"></span><br><span class="line"><span class="comment">#主函数部分</span></span><br><span class="line">A = loadmat(<span class="string">&#x27;./data.mat&#x27;</span>)[<span class="string">&#x27;A&#x27;</span>] <span class="comment">#载入数据</span></span><br><span class="line"></span><br><span class="line">L,U = LU_JKI(A)</span><br><span class="line"></span><br><span class="line"><span class="comment">#测试，计算相对误差 ||A - L*U|| / ||A||，这里用 F-范数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;relerr = %.4f&#x27;</span>%(norm(A - np.matmul(L, U),<span class="string">&#x27;fro&#x27;</span>) / norm(A, <span class="string">&#x27;fro&#x27;</span>)))</span><br></pre></td></tr></table></figure>
<p>类似地，注意算法虽然是在 <span class="math inline">\(A\)</span>
上进行的，但在程序中需要保留 <span class="math inline">\(A\)</span>
的原值来计算相对误差，因此在函数中使用的应该是 <span class="math inline">\(A\)</span> 的复制，也就有了
<code>A=B.copy()</code> 这一步。</p>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">relerr = <span class="number">0.0000</span></span><br></pre></td></tr></table></figure>
<p>相对误差接近于 <span class="math inline">\(0\)</span>，说明实验是成功的。</p>
<h1 id="后记">后记</h1>
<p>不是，这玩意不是我后来咕咕了没再写，而是布置过一次作业之后就再也没有了（</p>
<p>本来说是基本每一讲后面都有数值实验的，结果不知道是老师咕咕还是助教咕咕，总之是并没有再布置过实验，少了很多乐趣。之前看过贵系数值分析的资料
Repo，两边的风格还是很不一样的。</p>
<p>就这么草率地结束了..</p>
]]></content>
      <tags>
        <tag>这里面看起来很好玩</tag>
        <tag>数学</tag>
        <tag>课程实录</tag>
      </tags>
  </entry>
  <entry>
    <title>还就那个线性回归分析</title>
    <url>/2023/02/21/Linear-Regression-Analysis/</url>
    <content><![CDATA[<p>本来真没打算连载这个，结果这课居然把课程笔记算成百分制里面的 10
分（，那就写罢。</p>
<p>有参考 <a href="https://blog.vicayang.cc/tags/statistics/">Vica Yang
的统辅笔记</a>，<a href="https://www.zhihu.com/column/c_1332050772843511808">JhZhang
的课堂笔记</a>和 <a href="https://v1ncent19.github.io/SummaryNotes/">V1ncent19
的统辅笔记</a>，如有引用均会在文中注明，在此向前辈表示感谢。</p>
<span id="more"></span>
<h1 id="lecture-1">Lecture 1</h1>
<p>主要是在吹水，开玩笑以及活跃气氛。正经的内容大概就一个古老的回归现象，我还没有听得很懂，麻了。</p>
<h2 id="galtons-experiment">Galton's Experiment</h2>
<p>以下全是胡说八道，不能保证完全对。</p>
<p>介绍正态分布的时候会有一个很经典的小球过钉板的演示实验，最后落在底部的球似乎呈现出一个正态分布。但实际上球和钉子的每次碰撞都是一个
Bernoulli 过程，过了 n 层钉板就是 n 次 Bernoulli
过程加和，可以近似为正态分布。实际上只要 n
够大，由中心极限定理任何分布的加和都可以被近似为正态分布。</p>
<p>但我觉得实际上小球的情况并不是独立的，毕竟过程中会有相互的碰撞，真的没问题吗（</p>
<p>回归现象的起源是 Galton
对于父代和子代的身高做了一个统计，发现身高远离均值的父母的后代往往身高会比他们更接近平均水平，也就是某一身高水平的父母的孩子的身高中位数作为因变量，父母身高作为自变量时，拟合出的直线的斜率小于
<span class="math inline">\(1\)</span>。</p>
<p>假设不发生回归现象，则和钉板现象一样，后代的性状会逐渐分散，这被认为是一个种群稳定性状的方式。听起来很玄学，似乎也有一个稍微合理的生物学解释了，但我们希望从统计学的角度分析这件事，背后是存在数学规律的。</p>
<p><img src="https://s2.loli.net/2023/02/26/AHxRkaSBD87fW3V.png" alt="Galton.png"></p>
<p>上图是课程中反复出现的一张图，对此做了很多解释。最上面的正态分布是父代的身高情况（实际上是父母身高的加权和），通过一个“倾斜槽”之后的第二个正态分布展示了子代的身高情况，比父代更加靠近中心。下方也有一个类似于钉板的装置，n
层钉板指的就是 n
代繁衍的过程，或者也可以指代一代繁衍中的其他影响身高的非基因因素，它们被视作独立同分布的，因此加和由中心极限定理可以被近似为正态分布。</p>
<p>图中还呈现出了父代中的一个小组“过钉板”后的结果，是一个小的正态分布。实际上子代的数据就是由一个一个小的正态分布叠加起来的，而正态分布可以线性相加，所以最后呈现出的还是正态分布。</p>
<p>好玄学，我也不知道我在说什么，甚至不是很确定自己理解对了没有。</p>
<p>Anyway，还是 think mathematically，记 <span class="math inline">\(X_i\)</span> 为第 <span class="math inline">\(i\)</span> 代的种群身高变化量，<span class="math inline">\(\lbrace X_i \rbrace\)</span>
是独立同分布的。则记父代种群的随机变量为 <span class="math inline">\(F=
\Sigma _{i=1} ^n X_i\)</span>，子代种群的随机变量为 <span class="math inline">\(S=
\Sigma_{i=1}^nX_i\)</span>，考虑二者的相关系数：</p>
<p><span class="math inline">\(\rho(F,S) =
\frac{cov(F,S)}{\sqrt{Var(F)Var(S)} } = \frac{Var(F) + Cov
(F,X_n)}{\sqrt{Var(F)Var(S)} }
=1+\frac{cov(F,X_n)}{Var(F)}&lt;1\)</span>，因此 <span class="math inline">\(\rho(F,X_n)&lt;0\)</span> 也即二者呈负相关。</p>
<h2 id="一些术语">一些术语</h2>
<ul>
<li><p>一般来说，我们把 <span class="math inline">\(X\)</span> 作为
predictor/input/explanatory variable，把 <span class="math inline">\(Y\)</span> 作为 response/output/dependent
variable。</p></li>
<li><p><span class="math inline">\(Y \sim X\)</span> 被称为 simple
regression，一元总归是简单的。</p>
<p><span class="math inline">\(Y \sim X_1,X_2,...,X_p\)</span> 称为
multiple/multivariate regression，实际上这两者是不一样的。</p>
<p>如果每个回归式中有超过一个 <span class="math inline">\(X\)</span>
就称为 multiple regression，如果有多个 <span class="math inline">\(Y\)</span> 就称为 multivariate
regression，并且每个式子里只能有一个不同的 dependent variable。</p>
<p>还有叫做 multivariate multiple regression 的回归方法，也就是用多个
<span class="math inline">\(X\)</span> 来预测多个 <span class="math inline">\(Y\)</span> 的情况，每个 <span class="math inline">\(Y\)</span> 出现在不同的式子里。</p></li>
<li><p>一般来说 <span class="math inline">\(Y\)</span>
是连续型随机变量，<span class="math inline">\(X\)</span>
可以是连续型、离散型或者分类型随机变量。有一些名词，不抄了，简单列一下：</p>
<p><img src="https://s2.loli.net/2023/02/26/iRyejXI6TuSvroJ.png" alt="regression.png"></p></li>
</ul>
<h1 id="lecture-2">Lecture 2</h1>
<h2 id="simple-linear-regression">Simple Linear Regression</h2>
<h3 id="数据的组织和表示">数据的组织和表示</h3>
<p>Simple linear regression 的数据一般是二元数据对 <span class="math inline">\((X_i , Y_i)\)</span>，每一对数据称为一个
case。数据集记作 <span class="math inline">\((X_1,Y_1),...,(X_n,Y_n)\)</span>，其中 <span class="math inline">\(X_i\)</span> 是 i-th observed explanatory
variable，<span class="math inline">\(Y_i\)</span> 是 i-th observed
response variable。</p>
<h3 id="模型的表示">模型的表示</h3>
<p><span class="math inline">\(Y_i = \beta_0 + \beta_1 X_i + \varepsilon
_i\)</span>，<span class="math inline">\(\varepsilon _i\)</span> 被称为
random error term，其中 <span class="math inline">\(\beta_0,\beta_1\)</span>
是参数。为了简化模型便于操作，需要对 random error term 做一些假设：</p>
<ul>
<li>均值为 <span class="math inline">\(E(\varepsilon_i) =
0\)</span>，方差为 <span class="math inline">\(Var(\varepsilon _i) =
\sigma ^2\)</span>，注意 <span class="math inline">\(\sigma\)</span>
是一个未知常数，也视作参数；</li>
<li>不同的 <span class="math inline">\(\varepsilon _i\)</span> 和 <span class="math inline">\(\varepsilon _j\)</span>
是不相关的。注意此处不需要不独立。</li>
</ul>
<p>对于更强的模型，例如 simple linear regression model with normal
error，我们直接要求 <span class="math inline">\(\varepsilon_1,...,\varepsilon_n i.i.d. \sim
N(0,\sigma^2)\)</span>（因为正态分布的不相关性和独立性等价）。这是一个很广泛的假设，但有时正态假设是明显有问题的，需要修正。</p>
<p>事实上，在 linear regression model 中，<span class="math inline">\(X_i\)</span> 和 <span class="math inline">\(Y_i\)</span> 的地位是不对等的。<span class="math inline">\(X_i\)</span> 被视为不带随机性的常数，而 <span class="math inline">\(Y_i\)</span> 因为 <span class="math inline">\(\varepsilon_i\)</span> 的存在是一个随机变量，有
<span class="math inline">\(E(Y_i) = \beta_0 + \beta_1
X_i\)</span>，<span class="math inline">\(Var(Y_i)=Var(\varepsilon_i) =
\sigma^2\)</span>。因此，回归线可以视作 <span class="math inline">\((X_i, E(Y_i))\)</span> 连成的直线，而数据点 <span class="math inline">\((X_i,Y_i)\)</span> 分布在回归线附近。</p>
<p>特别地，在正态假设下， 有 <span class="math inline">\(Y_i \sim
N(\beta_0 + \beta_1 X_i,\sigma^2)\)</span>，<span class="math inline">\(i=1,2,...,n\)</span>。</p>
<h3 id="参数的意义和求算">参数的意义和求算</h3>
<p>斜率 <span class="math inline">\(\beta_1\)</span> 的意义为 <span class="math inline">\(X_i\)</span> 增加 1 单位时 <span class="math inline">\(Y_i\)</span> 的变化量；截距 <span class="math inline">\(\beta_0\)</span> 的意义分两种情况解释，当 <span class="math inline">\(X_i\)</span> 取值范围中有 <span class="math inline">\(0\)</span> 时即为 <span class="math inline">\(X_i=0\)</span> 时的平均响应 <span class="math inline">\(E(Y_i)\)</span>，否则截距没有意义。</p>
<h4 id="least-sum-of-square-方法">Least Sum of Square 方法</h4>
<p>求算最佳参数实际上就是求使得 sum of squared diff 最小的 <span class="math inline">\(\hat{\beta_0},\hat{\beta_1}\)</span>，从而得到
<span class="math inline">\(Y_i\)</span> 的估计值 $= + X_i $。于是有
<span class="math inline">\(\hat{\beta_0},\hat{\beta_1} = \arg \min
_{\beta_0,\beta_1} \Sigma(Y_i - \beta_0 - \beta_1X_i)^2=\arg \min
_{\beta_0,\beta_1} \Sigma_{i=1 } ^n e_i
^2\)</span>。求导即可简单地得出：</p>
<p><span class="math display">\[b_1 = \hat{\beta_1} = \frac{\Sigma_i
(X_i - \bar{X})(Y_i - \bar{Y})}{\Sigma _i (X_i-\bar{X})^2}\]</span></p>
<p><span class="math display">\[b_0 = \hat{\beta_0} = \bar{Y} - b_1
\bar{X}\]</span></p>
<p>记残差为 <span class="math inline">\(e_i = Y_i - \hat{Y_i}= Y_i -
\hat{\beta_0} - \hat{\beta_1} X_i=\beta_0 + \beta_1X_i +\varepsilon _i -
\hat{\beta_0} - \hat{\beta_1}X_i \approx \varepsilon _i\)</span> ，也即
<span class="math inline">\(e_i\)</span> 为某一组 observed data <span class="math inline">\(Y_1,Y_2,...,Y_n\)</span> 之下得到的残差，但绝非
<span class="math inline">\(\varepsilon _i\)</span>
本身。残差是观测到的确定值，而 <span class="math inline">\(\varepsilon
_i\)</span> 是随机变量。</p>
<p>事实上求导的过程蕴含以下结论：</p>
<p><span class="math display">\[\Sigma _{i=1} ^n e_i=0\]</span></p>
<p><span class="math display">\[\Sigma _{i=1} ^{n} X_i e_i =
0\]</span></p>
<p>以上二式可以看做对 <span class="math inline">\(e_i\)</span>
的线性约束，<span class="math inline">\(\lbrace e_i \rbrace\)</span>
的自由度是 <span class="math inline">\(n-2\)</span>，互相之间不是独立的，这也是和 <span class="math inline">\(\lbrace \varepsilon _i \rbrace\)</span>
的差别之一。由此还可以得到一些其他性质，例如回归线必过 <span class="math inline">\((\bar{X},\bar{Y})\)</span>，不在此一一列举。</p>
<p>以上即为参数 <span class="math inline">\(\beta_0,\beta_1\)</span>
的估计方法。下面再考虑参数 <span class="math inline">\(\sigma\)</span>
的估计，使用残差 <span class="math inline">\(e_1,...,e_n\)</span>
来考虑。</p>
<p>取 <span class="math inline">\(\hat{\sigma ^2} = \frac{\Sigma _{i=1}
^n e_i ^2}{n-2}\)</span>。这是因为 <span class="math inline">\(e_1,e_2,...,e_n\)</span> 的自由度为 <span class="math inline">\(df_E = n-2\)</span>，由此考虑 sum of square <span class="math inline">\(SSE= \Sigma_{i=1} ^n (Y_i - \hat{Y_i})^2=\Sigma
_{i=1} ^n e_i ^2\)</span>，定义 mean of squared errors <span class="math inline">\(MSE= \frac{SSE}{df_E} = \frac{\Sigma_{i=1}^n e_i
^2}{n-2}\)</span> 为 <span class="math inline">\(\hat{\sigma
^2}\)</span>。</p>
<h4 id="mle-方法">MLE 方法</h4>
<p>也可以用推断课上的 MLE 方法。实际上，我们想找到一个 <span class="math inline">\(\beta_0,\beta_1\)</span> 的最佳估计，还可以使用
MLE 方法进行估计。</p>
<p>在正态假设下，我们可以将 <span class="math inline">\(n\)</span>
组数据视作 <span class="math inline">\(n\)</span>
个互相独立的随机变量，取使得其likelihood function 最大的一组 <span class="math inline">\(\beta_0,\beta_1,\sigma^2\)</span>
作为估计量。likelihood function 即为 <span class="math inline">\(f(y_1,y_2,...,y_n) =
f_1(y_1)...f_n(y_n)\)</span>，得到的 estimator 中 <span class="math inline">\(\hat{\beta_0},\hat{\beta_1}\)</span> 与 least sum
of square 中得出的估计量相同，但 <span class="math inline">\(\hat{\sigma
^2} = \frac{\Sigma _{i=1} ^n e_i
^2}{n}\)</span>。注意这是一个有偏的估计量，而 least sum of square
得到的估计量是无偏的。</p>
<h2 id="推断复习">推断复习</h2>
<p>咕了。什么嘛，我推断学得还是可以的嘛（x</p>
<h1 id="lecture-3">Lecture 3</h1>
<h2 id="线性回归中的推断">线性回归中的推断</h2>
<p>回顾一下，无论是 OLS 方法还是 MLE 方法，我们得到的参数估计 <span class="math inline">\(b_0\)</span>,<span class="math inline">\(b_1\)</span> 都是相同的：</p>
<p><span class="math display">\[b_1 = \hat{\beta_1} = \frac{\Sigma_i
(X_i - \bar{X})(Y_i - \bar{Y})}{\Sigma _i (X_i-\bar{X})^2}\]</span></p>
<p><span class="math display">\[b_0 = \hat{\beta_0} = \bar{Y} - b_1
\bar{X}\]</span></p>
<p>通过简单的计算可以知道：</p>
<p><span class="math display">\[E(b_1) = \beta_1,Var(b_1) ={\sigma^2
\over S_{XX}},s^2(b_1) = \frac{s^2}{S_{XX}}\]</span>，</p>
<p>其中 <span class="math inline">\(S_{XX} = \Sigma_{i=1} ^n (X_i -
\bar{X})^2\)</span>, <span class="math inline">\(s^2 = \hat{\sigma}^2 =
\frac{\Sigma_{i=1}^n e_i^2}{n-2}\)</span>。</p>
<p>而且有 <span class="math inline">\(Cov(b_1, \bar Y)=0\)</span>。</p>
<h3 id="参数推断">参数推断</h3>
<ul>
<li><p>对 <span class="math inline">\(\beta_1\)</span> 进行推断：null
hypothesis 为 <span class="math inline">\(H_0: \beta_1
=0\)</span>，这样设置是因为关心两个变量之间是否存在线性关系。</p>
<p>在假设 <span class="math inline">\(H_0\)</span> 下可以考虑 test
statistic 为 <span class="math inline">\(T= \frac{b_1 -0}{s(b_1)} \sim
t_{n-2}\)</span>，这是因为 <span class="math inline">\(H_0\)</span>
假设下 <span class="math inline">\(b_1-0 \sim
N(0,\frac{\sigma}{\sqrt{Sxx}})\)</span>，我们一般用 <span class="math inline">\(\sigma\)</span> 的无偏估计 <span class="math inline">\(\hat{\sigma} = \sqrt{\frac{\Sigma_{i=1}^n e_i
^2}{n-2}}\)</span> 来处理。</p>
<p>level of significance 为 <span class="math inline">\(\alpha\)</span>，于是当 observed data <span class="math inline">\(t_0\)</span> 满足 <span class="math inline">\(|t_0| &gt; t_{n-2,1-\alpha /2}\)</span> 时 reject
<span class="math inline">\(H_0\)</span>。</p>
<p>如果没有拒绝 <span class="math inline">\(H_0\)</span>，通常的可能有以下三种：</p>
<ul>
<li>发生了 Type II Error，没有成功拒绝掉 <span class="math inline">\(H_0\)</span> 而事实相反；</li>
<li><span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span> 之间确实没有什么线性关系；</li>
<li><span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span> 之间有关系，但是非线性。（这句话原来的
typo 是“有线性关系，但是非线性”，绷不住了，中午被 Photon
指出来了，非常感谢他）</li>
</ul></li>
<li><p>对 <span class="math inline">\(\beta_1\)</span> 做 confidence
interval：由于在 <span class="math inline">\(\beta_1\)</span>
代表斜率的情况下，有 <span class="math inline">\(\frac{b_1 -
\beta_1}{s(b_1)} \sim^{H_0} t_{n-2}\)</span>。</p>
<p>于是 <span class="math inline">\(P(\frac{|b_1-\beta_1|}{s(b_1)} &lt;
t_{n-2,1-\alpha /2}) = 1-\alpha\)</span>，<span class="math inline">\(\beta_1\)</span> 的 100%<span class="math inline">\((1-\alpha)\)</span> confidence interval 是</p>
<p><span class="math display">\[(b_1 - t_{n-2,1-\alpha /2} s(b_1),b_1 +
t_{n-2,1-\alpha /2} s(b_1))\]</span></p></li>
<li><p>类似地可以对 <span class="math inline">\(\beta_0\)</span>
做推断，有 <span class="math inline">\(\frac{b_0 -\beta_0}{s(b_0)} \sim
t_{n-2}\)</span>，因此如果 null hypothesis 为 <span class="math inline">\(H_0: \beta_0 =0\)</span>，rejection region
即为满足条件 $ &gt; t_{n-2,1-/2} $ 的数据。对于偏移的 null hypothesis
<span class="math inline">\(H_0 : \beta_0 =c\)</span>，也只要相应地移动
rejection region 即可。</p>
<p>100%<span class="math inline">\((1-\alpha)\)</span> confidence
interval 为 <span class="math inline">\((b_0 - t_{n-2,1-\alpha /2}
s(b_0),b_0 + t_{n-2,1-\alpha /2} s(b_0))\)</span>。</p>
<p>实际上我们一般对 <span class="math inline">\(\beta_0\)</span>
的推断不感兴趣，因为这个参数未必有意义，依赖于 <span class="math inline">\(X\)</span> 的取值范围。</p></li>
<li><p>以上都是对单个参数进行推断，实际上我们也可以进行 joint
inference：</p>
<p>同时推断两个参数 <span class="math inline">\((\beta_0,\beta_1)\)</span>，这时候得到的就是
confidence region，使得 <span class="math inline">\(P((\beta_0,\beta_1)
\in S \subset \mathbb R^2) = 100(1-\alpha) \%\)</span>。实际上因为 <span class="math inline">\((b_0 , b_1) ^T \sim N((\beta_0,\beta_1)^T ,
\sigma^2 \Sigma_{2\times 2})\)</span>，所以最小的 confidence region
是一个椭圆。</p>
<p>实际上我们也可以考虑做一个矩形的 confidence
region，也即对两个参数分别作 confidence interval，confidence coefficient
分别为 <span class="math inline">\(\sqrt{1-\alpha} \approx
1-\frac{\alpha}{2}\)</span>。因此 confidence region 为：</p>
<p><span class="math display">\[ (b_1 - t_{n-2,1-\alpha /4} s(b_1),b_1 +
t_{n-2,1-\alpha /4} s(b_1)) \times (b_0 - t_{n-2,1-\alpha /4} s(b_0),b_0
+ t_{n-2,1-\alpha /4} s(b_0))\]</span></p></li>
</ul>
<p>参数推断的角度来说 <span class="math inline">\(\beta_1\)</span>
的推断远比 <span class="math inline">\(\beta_0\)</span>
重要，它表征线性关系，而且从预测的角度来说，<span class="math inline">\(\beta_1\)</span> 的推断如果不够精细，会导致远离
<span class="math inline">\(\bar X\)</span> 处的 <span class="math inline">\(X_h\)</span> 对应的估计量误差很大。</p>
<h3 id="power-function">Power Function</h3>
<p>一个 significance test 的 power 指的是 reject <span class="math inline">\(H_0\)</span> 时 <span class="math inline">\(H_1\)</span> 是正确的的概率，也就是 <span class="math inline">\(1-P(\)</span>Type II Error<span class="math inline">\()\)</span>。实际上一个推断是好的的情况下需要既不
over-powered 也不 under powered，这和 Type I Error 与 Type II Error
此消彼长的性质有关。</p>
<p>Power function 一般是一个关于参数的函数。以推断 <span class="math inline">\(\beta_1\)</span> 的过程为例，计算这一推断的 power
function。</p>
<ul>
<li><p>我们在线性回归参数推断里会用到一种非中心化 t-分布。普通的
t-分布是关于 <span class="math inline">\(x=0\)</span> 对称的，非中心化
t-分布有一定的偏差。注意并不是整体在坐标轴方向上的移动，其形状也发生了变化。表达式为
<span class="math inline">\(t(df, \delta ) = \frac{N(0,1) +
\delta}{\sqrt{\chi_{df} / df}}\)</span>。</p></li>
<li><p>对 <span class="math inline">\(\beta_1\)</span> 进行推断：null
hypothesis 为 <span class="math inline">\(H_0: \beta_1
=0\)</span>，这样设置是因为关心两个变量之间是否存在线性关系。</p>
<p>在假设 <span class="math inline">\(H_0\)</span> 下可以考虑 test
statistic 为 <span class="math inline">\(T= \frac{b_1 -0}{s(b_1)} \sim
t_{n-2}\)</span>，然而在 <span class="math inline">\(H_1\)</span>
下,</p>
<p><span class="math display">\[T=\frac{b_1}{s(b_1)} = \frac{b_1 -
\beta_1 + \beta_1}{s(b_1)} = \frac{b_1-\beta_1}{s(b_1)} + \frac{\beta_1
/ \sigma(b_1)}{s(b_1)/\sigma(b_1)} =  \frac{N(0,1) +
\delta}{\sqrt{\chi_{df} / df}} \sim
t(n-2,\beta_1/\sigma(b_1))\]</span></p>
<p>于是 <span class="math inline">\(Power(\beta_1) = P(Reject H_0 | H_1
holds) = P(|T| &gt; t_{n-2,1-\alpha /2} | \beta_1 \neq 0) =
P(T&lt;t_{n-2,\alpha /2}) +1-P(T&lt;t_{n-2,1-\alpha
/2})\)</span>，其中在 <span class="math inline">\(\beta_1 \neq
0\)</span> 的条件下，<span class="math inline">\(T\sim t(n-2,\beta_1 /
\sigma(b_1))\)</span>。</p></li>
</ul>
<h2 id="blue">BLUE</h2>
<p><a href="https://record.umich.edu/articles/origins-go-blue/">Go Blue
!</a>（</p>
<p>简单来说，OLS Estimators 是 the best linear unbiased estimator，简称
OLS estimators 是 BLUE。best 的意思是方差最小，这是不难证明的。</p>
<p>BLUE 是非常好的性质，也希望我以后能 go blue（逃</p>
<h1 id="lecture-4">Lecture 4</h1>
<p>Prediction &amp; ANOVA，感谢 zzy 救我的生统概论（</p>
<h2 id="estimation-prediction">Estimation &amp; Prediction</h2>
<h3 id="平均响应的推断">平均响应的推断</h3>
<p>有了线性回归模型之后当然是要用来做预测，通过已有数据拟合出一个线性模型，再用来估计未知点的值。对于需要估计的点
<span class="math inline">\(X_h\)</span>，一般来说估计值都是考虑平均响应
(mean response) <span class="math inline">\(\mu_h = E(Y_h) = \beta_0
+\beta_1 X_h\)</span>，把 <span class="math inline">\(\hat{\mu_h} = b_0
+ b_1 X_h\)</span> 作为 <span class="math inline">\(\mu_h\)</span>
的估计。这是一个
estimator，既然如此就要考虑它的性质，也要先考虑平均响应的置信区间。</p>
<ul>
<li><p><span class="math inline">\(E(\hat{\mu_h}) = E(b_0) + E(b_1)X_h =
\beta_0 + \beta_1 X_h = \mu_h\)</span> ，是 unbiased estimator</p></li>
<li><p><span class="math inline">\(Var(\hat{\mu_h}) = Var(\bar{Y}+
b_1(X_h - \bar{X})) = \sigma^2 [\frac{1}{n} + \frac{(X_h -
\bar{X})^2}{\Sigma (X_i -\bar{X})^2}]\)</span> ，是 minimum
variance</p></li>
<li><p><span class="math inline">\(\hat{\mu_h} = \bar{Y} + (X_h -
\bar{X}) b_1\)</span>，由于 <span class="math inline">\(\bar{Y}\)</span>
和 <span class="math inline">\(b_1\)</span> 都有正态假设，因此 <span class="math inline">\(\hat{\mu_h}\)</span> 也服从正态分布，<span class="math inline">\(\hat{\mu_h} \sim N(\mu_h ,
Var(\hat{\mu_h}))\)</span>。</p></li>
<li><p><span class="math inline">\(Var(\hat{\mu_h})\)</span> 的估计量是
<span class="math inline">\(s^2(\hat{\mu_h}) = s^2[\frac 1 n +
\frac{(X_h-\bar{X})^2}{\Sigma(X_i - \bar{X})^2}]\)</span>，于是有 <span class="math inline">\(\frac{\hat{\mu_h} - \mu_h}{s(\hat{\mu_h})} \sim
t_{n-2}\)</span>。</p>
<p>因此，<span class="math inline">\(\mu_h\)</span> 的 <span class="math inline">\(100 \% (1-\alpha)\)</span> confidence interval 是
<span class="math inline">\((\hat{\mu_h} - t_{n-2, 1-\alpha /2}
s(\hat{\mu_h}),\hat{\mu_h} + t_{n-2, 1-\alpha /2}
s(\hat{\mu_h}))\)</span>。confidence interval 的长度为 $2t_{n-2, 1-/2}
s() = 2t_{n-2, 1-/2} s $，其中 <span class="math inline">\(s =
\sqrt{[\frac{\Sigma_{i=1}^n
e_i^2}{n-2}]}\)</span>。因此置信区间的长度是近似于随 <span class="math inline">\(X_h - \bar{X}\)</span>
递增而递增的。<strong>也就是说，<span class="math inline">\(X_h\)</span>
距离 <span class="math inline">\(\bar{X}\)</span>
越远，置信区间的长度越大，准确性越难保证。</strong></p>
<p>综上，我们成功找到了这个对于 <span class="math inline">\(\mu_h\)</span> 的估计的置信区间。</p></li>
</ul>
<h3 id="预测值的推断">预测值的推断</h3>
<p>上述估计的是预测值的平均响应，对于新观测点的值需要改成：<span class="math inline">\(Y_{h(new)} = \beta_0 + \beta_1 X_h
+\varepsilon\)</span> 且有 <span class="math inline">\(E(\varepsilon) =
0,Var(\varepsilon) = \sigma^2\)</span>。注意这里 <span class="math inline">\(\varepsilon\)</span> 是随机变量，<span class="math inline">\(\beta_0,\beta_1\)</span> 是未知值的参数，<span class="math inline">\(X_h\)</span> 是已知的常数。</p>
<p>对它做估计 <span class="math inline">\(\hat{Y}_{h(new)} = \hat{\mu_h}
= b_0+b_1 X_h\)</span> 仍然是和平均响应相同，考虑这个估计的性质。</p>
<ul>
<li><p><span class="math inline">\(E(\hat{Y}_{h(new)}) = E(b_0 + b_1
X_h) = \beta_0 + \beta_1 X_h\)</span></p></li>
<li><p>从简单的情形开始，如果 <span class="math inline">\(\beta_0,\beta_1,\sigma\)</span>
都是已知的参数，则在正态假设下 <span class="math inline">\(\frac{Y_{h(new)} -E(Y_h)}{\sigma}\sim
N(0,1)\)</span>（非正态假设情况下服从未知分布），<span class="math inline">\(Y_{h(new)}\)</span> 的 confidence interval 是
<span class="math inline">\((E(Y_h) - z_{1-\alpha /2} \sigma,E(Y_h) +
z_{1-\alpha /2} \sigma)\)</span>。</p></li>
<li><p>一般情况下，设 <span class="math inline">\(d_h = Y_{h(new)} -
\hat{Y}_{h(new)} = Y_{h(new)} - \hat{\mu_h}\)</span>，于是有 <span class="math inline">\(E(d_h) = 0\)</span>。</p>
<p>计算可知方差 <span class="math inline">\(Var(d_h) = Var(Y_{h(new)} -
\hat{\mu} _h) = Var(Y_{h(new)})+Var(\hat{\mu_h}) = \sigma^2[1+\frac 1 n
+\frac{(X_h - \bar{X})^2}{\Sigma(X_i - \bar{X})^2}]\)</span>；</p>
<p>standard error 为 <span class="math inline">\(s^2(d_h) = s^2 [1+\frac
1 n +\frac{(X_h - \bar{X})^2}{\Sigma(X_i - \bar{X})^2}]\)</span>；</p>
<p>于是有 <span class="math inline">\(\frac{d_h - E(d_h)}{s(d_h)} =
\frac{d_h}{s(d_h)} = \frac{Y_{h(new)} - \hat{\mu}_h}{s(d_h)} \sim
t_{n-2}\)</span>，<span class="math inline">\(Y_{h(new)}\)</span>
的置信区间是 <span class="math inline">\((\hat{\mu}_h - s(d_h)
t_{n-2,1-\alpha/2},\hat{\mu}_h + s(d_h)
t_{n-2,1-\alpha/2})\)</span>，这个区间一般叫做 prediction
interval，长度是 <span class="math inline">\(2 t_{n-2,1-\alpha/2}
s(d_h)\)</span>，其中 <span class="math inline">\(s^2(d_h) = s^2 +
s^2(\hat{\mu}_h
^2)\)</span>，因此<strong>预测区间比平均响应的置信区间略宽</strong>。</p></li>
</ul>
<h3 id="预测值的平均的推断">预测值的平均的推断</h3>
<p>考虑在新值 <span class="math inline">\(X_h\)</span> 处的 <span class="math inline">\(m\)</span> 个观测值的平均值，为 ${Y_h} = m
<em>{i=1} ^m Y</em>{h(new) i} = _0 +<em>1 X_h+ 1m </em>{i=1}^m _i
$，预测值的平均仍然是 <span class="math inline">\(\hat{Y_h}=b_0 + b_1
X_h\)</span>。有 <span class="math inline">\(\varepsilon _i \sim
N(0,\sigma^2)\)</span> 为正态假设。于是 <span class="math inline">\(Var(\bar{Y}_h - \hat{Y_h}) = \sigma^2 [\frac 1m +
\frac 1 n + \frac{(X_h - \bar{X})^2}{\Sigma(X_i - \bar{X})^2}] \leq
Var(d_h)\)</span>。</p>
<p>它的宽度小于 prediction interval，但也大于平均响应的 confidence
interval。</p>
<h3 id="confidence-band-for-entire-regression-line">Confidence Band for
Entire Regression Line</h3>
<p>怎么翻译都没那味，就写原文吧。</p>
<p>希望找到一个 confidence band：<span class="math inline">\(\lbrace
(x,y): L(x)&lt;y&lt;U(x), x\in \mathbb R \rbrace\)</span>，对于任意点
<span class="math inline">\(x\)</span> 有 <span class="math inline">\(P[l(x) &lt; \beta_0 +\beta_1 x &lt;u(x)] =
1-\alpha\)</span>。对于固定的点 <span class="math inline">\(x\)</span>，<span class="math inline">\(100 \%
(1-\alpha)\)</span> 置信区间为 <span class="math inline">\((\hat{\mu_x}
- t_{n-2, 1-\alpha /2} s(\hat{\mu_x}),\hat{\mu_x} + t_{n-2, 1-\alpha /2}
s(\hat{\mu_x}))\)</span>。</p>
<p>所以只要取 <span class="math inline">\(W=max\{(\hat{\mu}_x -
\mu_x)/s(\hat{\mu}_x) \}\)</span>，即有置信区间为 <span class="math inline">\((\hat{\mu}_x - W s(\hat{\mu_x}),\hat{\mu}_x + W
s(\hat{\mu_x}))\)</span>，其中 <span class="math inline">\(W =
\sqrt{2F_{1-\alpha,2,n-2}}\)</span>。实际上 <span class="math inline">\(W &gt; t_{n-2,1-\alpha /2}\)</span>，也就是说
confidence band 处处比 confidence interval 更宽，level of confidence
<span class="math inline">\(\alpha&#39;\)</span> 也更小。</p>
<h3 id="summary">Summary</h3>
<p>一个显示 confidence interval of mean response，prediction interval 和
confidence band 宽度关系的图：</p>
<p><img src="https://s2.loli.net/2023/03/16/XO3Bt8FehprNz5q.png" alt="bands.png"></p>
<h2 id="analysis-of-variance-anova">Analysis of Variance (ANOVA)</h2>
<h3 id="variance-estimator">Variance Estimator</h3>
<p>先上点概念：</p>
<ul>
<li><p>Total Sum of Squares: <span class="math inline">\(SST= \Sigma(Y_i
- \bar{Y})^2\)</span>，<span class="math inline">\(df_{SST} =
n-1\)</span></p>
<p>Sample Variance: <span class="math inline">\(S_n ^2 =
\frac{SST}{n-1}\)</span>，是非常熟悉的统计量。</p></li>
<li><p>Variation due to Error: <span class="math inline">\(SSE =
\Sigma(Y_i -\hat{Y}_i)^2= \Sigma e_i ^2\)</span>, <span class="math inline">\(df_{SSE} = n-2\)</span></p>
<p>Mean Square Error: <span class="math inline">\(MSE = \frac{SSE}{df} =
\frac{\Sigma_{i=1} ^n e_i ^2}{n-2}\)</span>，可以作为 <span class="math inline">\(\sigma^2 = Var(\varepsilon)\)</span>
的一个估计。</p>
<p><span class="math inline">\(E(MSE) = \sigma^2\)</span></p></li>
<li><p>Variation due to Regression: <span class="math inline">\(SSR =
\Sigma(\hat{Y}_i - \bar{Y})^2 = b_1 ^2 \Sigma (X_i-\bar{X})^2\)</span>,
<span class="math inline">\(df_{SSR} = 1\)</span></p>
<p>Mean Squares of Regression: <span class="math inline">\(MSR =
\frac{SSR}{df} = SSR\)</span></p>
<p>$E(MSR) = E(SSR) = E(b_1 ^2) ((X_i - {X})^2)= ^2 + _1^2 (X_i - {X})^2
$;</p></li>
</ul>
<p>可以计算得到 <span class="math inline">\(SST=SSE+SSR\)</span>，自由度方面也是 <span class="math inline">\(df_{SST} = df_{SSE}+df_{SSR}\)</span>。</p>
<p>事实上在 Lecture 2 中我们考虑过是选取 sample variance 还是选取 MSE
作为 <span class="math inline">\(\hat{\sigma}^2\)</span>，这里的定义给出了更清晰的答案：<span class="math inline">\(SSE\)</span> 更加注重原值和模型之间的联系，把
<span class="math inline">\(\hat{Y_i}\)</span> 作为 <span class="math inline">\(Y_i\)</span> 的估计值，在 sample variance 中是把
<span class="math inline">\(\bar{Y}\)</span> 作为 <span class="math inline">\(Y_i\)</span> 的估计值，前者更好地体现了 <span class="math inline">\(\varepsilon\)</span> 的场景。</p>
<h3 id="f-检验">F-检验</h3>
<p>我们希望通过以上统计量检验 <span class="math inline">\(X,Y\)</span>
之间是否存在线性关系。考虑假设 <span class="math inline">\(H_0: \beta_1
= 0 ; H_1 : \beta_1 \neq 0\)</span>。</p>
<p>在正态假设和 <span class="math inline">\(H_0\)</span> 成立条件下，取
test statistic 为 <span class="math inline">\(F= \frac{MSR}{MSE} =
\frac{SSR / df_R}{SSE / df_E} = \frac{\chi_{dfR}/df_R}{\chi_{dfE}/df_E}
\sim F_{df_R,df_E} = F_{1,n-2}\)</span>。考虑拒绝 <span class="math inline">\(H_0\)</span> 的情况，我们要求 <span class="math inline">\(F_0 &gt; F_{1-\alpha,df_R,df_E} = F_{1-\alpha,
1,n-2}\)</span>，满足此条件的 <span class="math inline">\((X,Y)\)</span>
构成 rejection region。或者从 P-value 的角度来看，满足不等式 <span class="math inline">\(P(F&gt;F_0 | F_{1,n-2}) &lt; \alpha\)</span>
的全体 <span class="math inline">\((X,Y)\)</span> 落在 rejection region
中。</p>
<p>考虑检验的 power function。在 <span class="math inline">\(H_1:
\beta_1 \neq 0\)</span> 条件下，Power(<span class="math inline">\(\beta_1\)</span>) = <span class="math inline">\(P(F&gt; F_{1-\alpha , 1,n-2} | non-central
F)\)</span>。</p>
<h3 id="general-linear-test">General Linear Test</h3>
<p>另一种检验上述假设的方式。考虑假设 <span class="math inline">\(H_0:
\beta_1 = 0 ; H_1 : \beta_1 \neq
0\)</span>，我们来比较两种不同的模型：</p>
<p>full model: <span class="math inline">\(Y_i = \beta_0+\beta_1 X_i
+\varepsilon _i\)</span>，reduced model: <span class="math inline">\(Y_i
= \beta_0 + \varepsilon_i\)</span>，在 <span class="math inline">\(H_0\)</span>
假设成立时两个模型是等价的。考虑方差统计量：</p>
<ul>
<li><span class="math inline">\(SSE(F) = SSE\)</span> for full model
with <span class="math inline">\(df_{EF}\)</span>，在 simple linear
regression 下 <span class="math inline">\(df_{EF}=n-2\)</span>，<span class="math inline">\(SSE(F) = SSE\)</span></li>
<li><span class="math inline">\(SSE(R) = SSE\)</span> for reduced model
with <span class="math inline">\(df_{ER}\)</span>，在 simple linear
regression 下 <span class="math inline">\(df_{ER}=n-1\)</span>，<span class="math inline">\(SSE(R) = SST\)</span></li>
</ul>
<p>在 <span class="math inline">\(H_0\)</span> 假设下，$F =
F_{(df_{ER}-df_{EF}),df_{EF}} $。实际上，在 simple linear regression
下和 F-检验是一致的。但是 general linear test
是一个更广泛的方法，可以用于任何形式的线性检验。</p>
<h3 id="pearson-correlation-r">Pearson Correlation r</h3>
<p><span class="math inline">\(r = \frac{\Sigma (X_i - \bar{X})(Y_i -
\bar{Y})}{\sqrt{\Sigma(X_i - \bar{X})^2} \sqrt{\Sigma(Y_i -
\bar{Y})^2}}\)</span> 被称为相关系数，反映了一组数据 <span class="math inline">\((X,Y)\)</span> 之间的线性关系程度。</p>
<p><span class="math inline">\(R^2 = \frac{SSR}{SST}\)</span>
被称为决定系数，事实上在 simple linear regression 下有 <span class="math inline">\(r^2=R^2\)</span>，因为 <span class="math inline">\(r = b_1 \frac{\sigma_X}{\sigma_Y}\)</span>。</p>
<p><img src="https://s2.loli.net/2023/03/16/3tpYiuFSd7Xw2vK.png" alt="2dimtest.png"></p>
<h1 id="lecture-5">Lecture 5</h1>
<p>回顾一下简单线性回归的模型假设：<span class="math inline">\(Y_i =
\beta_1 X_i + \beta_0 +\varepsilon _i\)</span></p>
<ul>
<li><span class="math inline">\(\varepsilon _1, \varepsilon _2 ,...,
\varepsilon_n\)</span> 相互独立</li>
<li><span class="math inline">\(\varepsilon_i\)</span> 服从正态分布</li>
<li><span class="math inline">\(\mathbb E(\varepsilon _i) =
0\)</span>，<span class="math inline">\(Var(\varepsilon_i) =
\sigma^2\)</span></li>
</ul>
<p>可以总结成 LINE: linearity, independence, normality, equal
variance</p>
<h2 id="diagnostics-of-x">Diagnostics of X</h2>
<p>诊断的方式粗暴一点来说就是肉眼诊断，用一些可视化工具（主要是画图）和其他方式来检验模型的假设是否符合。如果违反了模型假设，结果很有可能不可靠。此时需要用一些弥补的方式来处理。</p>
<h3 id="why-diagnosedistribution-and-confounding">Why
diagnose——Distribution and Confounding</h3>
<p>诊断过程需要关注的是 <span class="math inline">\(X\)</span> 而非
<span class="math inline">\(Y\)</span>，因为 <span class="math inline">\(Y\)</span> 之间是独立异分布的。<span class="math inline">\(Y_i \sim N(\beta_0 +\beta_1 X_i ,
\sigma^2)\)</span>。</p>
<p><span class="math inline">\(X\)</span> 完全是常数，所谓的 <span class="math inline">\(X\)</span> 的分布指的仅仅是 <span class="math inline">\(X_1,X_2,...,X_n\)</span>
在数轴上的排布，不是概率分布。但 <span class="math inline">\(X_i\)</span>
的分布会影响到模型的效果，直观上举个例子来说，<span class="math inline">\(X_i\)</span> 的位置至少会影响到 <span class="math inline">\(Var(b_1) = \frac{1}{\Sigma_i (X_i - \bar X)^2}
\sigma^2\)</span> 也就是 <span class="math inline">\(b_1\)</span>
的分散程度，这是会影响到推断显著性的因素，所以即使是常数也还是要对 <span class="math inline">\(X\)</span> 进行一些诊断。</p>
<p>我们一般希望 <span class="math inline">\(X\)</span>
是类似于正态的分布，这样的数据比较有代表性。可以使用 qq-plot
进行检查。</p>
<p>除此之外诊断 <span class="math inline">\(X\)</span> 的另一意义在于
<span class="math inline">\(X\)</span>
本身可能也是和其他因素有混杂的。举个例子来说，如果高温既会导致冰激凌销量增加又会导致鲨鱼攻击人的次数增加，很可能会发现冰激凌销量和鲨鱼攻击行为次数之间有线性的关系，事实上这就是一个没有选对合适的
explanatory variable <span class="math inline">\(X\)</span>
却得到了看似合理的模型的例子，但这样的结论是有问题的，<span class="math inline">\(X\)</span> 本身和气温这一因素混杂。</p>
<p>此时如果分别对冰激凌销量-气温和鲨鱼攻击行为-气温作一个 sequence
plot，会发现二者都分别和气温有关系，那就有必要把气温作为一个 explanatory
variable 加入模型的考虑，这是一种针对 confounding 的诊断方法。</p>
<h3 id="四参数">四参数</h3>
<p>有一些可以关心的量（甚至不能说是统计量，毕竟 <span class="math inline">\(X\)</span> 也不是随机变量），除了 range
之外实际上就是一阶到四阶矩：</p>
<ul>
<li>sample mean 展现了 <span class="math inline">\(X\)</span>
的主要位置</li>
<li>standard deviation 展现了数据的分散程度</li>
<li>偏度 skewness <span class="math inline">\(g_1 = \frac{m_3}{m_2
^\frac 3 2} = \frac{\frac 1 n \Sigma_{i=1}^n (x_i - \bar x)^3}{(\frac 1
n \Sigma_{i=1}^n (x_i -\bar x)^2)^\frac 3 2}\)</span>
展现了数据的对称性</li>
<li>峰度 kurtosis <span class="math inline">\(g_2 = \frac{m_4}{m_2 ^2}
-3 = \frac{\frac 1 n \Sigma_{i=1}^n (x_i - \bar x )^4}{(\frac 1 n
\Sigma_{i=1} ^n (x_i -\bar x)^2)^2} - 3\)</span>
展现了数据相对于正态分布的尾迹</li>
<li>range 展现了 <span class="math inline">\(X\)</span> 的分布范围</li>
</ul>
<p>其中值得关注的是偏度和峰度两个统计量，<del>因为之前没有提过</del>。想起来一个乐子，Pearson
在《Lady Tasting
Tea》里曾经认为一个分布只要有一阶到四阶矩的参数就可以完全确定，但实际上
Poisson 分布的四个参数都是 <span class="math inline">\(\lambda\)</span>，是不行的。</p>
<ul>
<li><p>关于偏度：</p>
<ul>
<li><span class="math inline">\(g_1 &lt;0\)</span> 时称为 negatively
skewed，左尾比较长，所以也会称为 skewed left</li>
<li><span class="math inline">\(g_1 &gt;0\)</span> 时称为 positively
skewed，右尾比较长，所以也会称为 skewed right</li>
</ul>
<p>由图可见偏度是能够体现数据的对称程度的。实际上对称程度是相对正态分布而言的。</p>
<p>一般来说对于一个左偏的分布，会有 mean &lt; median &lt;
mode（众数），如果右偏则会是 mode &lt; median &lt; mean。当然 mean 和
median 的顺序不一定准确，以及对于完全对称的分布会有三者相等。</p>
<p>注意如果分布有多个峰值，此时 skewness 不一定还适用。</p></li>
<li><p>关于峰度：</p>
<ul>
<li><span class="math inline">\(g_2&gt;0\)</span> 时称为
leptokurtic，尖峰态下双尾较长。</li>
<li><span class="math inline">\(g_2 &lt;0\)</span> 时称为
platykurtic，低峰态下双尾较短。</li>
</ul>
<p>注意峰度的所谓尖峰态低峰态和尾部数据性质也都是相对正态分布而言的。正态分布的峰度就是
<span class="math inline">\(3\)</span>，因此峰度的公式里有一个减去 <span class="math inline">\(3\)</span> 的操作，作为和正态分布的比对。</p>
<p>有的时候会把不减去 <span class="math inline">\(3\)</span> 的称为
kurtosis，减去 <span class="math inline">\(3\)</span> 则称为 excess
kurtosis，使用的时候要注意。</p>
<p>实际上峰度带来的度量信息包括峰和尾两部分，单独出现尖峰的条件不能作为判断
<span class="math inline">\(g_2\)</span> 正负性的依据，只是表征了 <span class="math inline">\(\bar X\)</span>
附近的情况，和尾部情况综合起来看才可以；峰度的正负性和方差的大小无关。</p>
<p>尾部的情况可以通过 Q-Q plot 查看：</p>
<p><img src="https://s2.loli.net/2023/05/29/VtZpD4vuSkA27eU.png" alt="kurtosis.png"></p></li>
</ul>
<h2 id="诊断-assumptions">诊断 assumptions</h2>
<p>最常用的 assumption
诊断方法是使用残差图进行诊断，一元线性回归中我们可以直接使用 <span class="math inline">\(e_i \sim X\)</span> 图，也可以使用 <span class="math inline">\(e_i \sim \hat Y\)</span>
图进行诊断，二者本质上只相差横轴的尺度和位置。在多元线性回归中就直接使用
<span class="math inline">\(e_i \sim \hat Y\)</span> 图进行诊断。</p>
<p>除此之外也有很多理论检验的方法，虽然听起来更
concrete，但其实实际应用中还是肉眼检查最有效。</p>
<p>模型诊断可能发现的一些问题：</p>
<ul>
<li><span class="math inline">\(Y\)</span> 和 <span class="math inline">\(X\)</span> 之间没有线性关系但是硬拟合了一个</li>
<li><span class="math inline">\(\sigma ^2\)</span>
不能视作常数，也即异方差</li>
<li><span class="math inline">\(\varepsilon _i\)</span>
不服从正态分布</li>
<li><span class="math inline">\(\varepsilon _i\)</span>
之间彼此不独立</li>
<li>模型可以拟合，但数据中有 outlier</li>
</ul>
<p>以下给出一些发现问题的方法：</p>
<h3 id="非线性关系">非线性关系</h3>
<p>简而言之，<span class="math inline">\(Y\)</span> 和 <span class="math inline">\(X\)</span>
之间可能并不是一个线性关系，但是我们采用了线性模型进行拟合。</p>
<p>找出问题的手段是使用 <span class="math inline">\(e_i \sim
X_i\)</span> 图诊断 <span class="math inline">\(Y\)</span> 和 <span class="math inline">\(X\)</span> 的线性关系是否过拟合。具体来说，给
<span class="math inline">\(e_i \sim X_i\)</span> 再做一个拟合图线
<code>scatter.smooth</code>，观察和 <span class="math inline">\(h=0\)</span> 是否偏离较大。虽然通过 <span class="math inline">\(Y \sim X\)</span> 也可以看出来，但是 <span class="math inline">\(e_i \sim X\)</span> 图更加明显。</p>
<p>即使线性关系是显著的（R 中得到 <span class="math inline">\(R^2\)</span> 较大、斜率 <span class="math inline">\(\beta_1\)</span>
显著），也不说明线性模型是最好的拟合模型。</p>
<h3 id="异方差问题">异方差问题</h3>
<ul>
<li><p>实际上的残差并不符合方差相等的假设，则称为异方差问题。即使发生这样的情况也未必会影响到
<span class="math inline">\(\beta_1,\beta_0\)</span>
的估计值，因为计算过程和这一假设实际上是无关的。但是，异方差问题会导致
<span class="math inline">\(b_0,b_1\)</span>
不再是使得方差最小的估计，失去了 BLUE
性质，但仍然是无偏的估计。问题会反映在关于 <span class="math inline">\(\beta_1,\beta_0\)</span>
的推断中，导致推断或者置信区间不是效率最高的。</p>
<p>举个例子，比如说 <span class="math inline">\(Y_i = 30 +100X_i + 10X_i
\varepsilon_i\)</span>，实际上是有 <span class="math inline">\(\varepsilon_i \sim N(0,10X_i
\sigma^2)\)</span>，方差并不相同。</p>
<p>画图检查最典型的异方差情况是画出 <span class="math inline">\(e_i \sim
X\)</span> 图后发现 <span class="math inline">\(X\)</span> 越大，<span class="math inline">\(e_i\)</span>
越分散，呈现出一个扇形的分布形态。</p></li>
<li><p>模型的诊断也可以使用一些理论方法，异方差检验中常用的几种检验如下所示：</p>
<ul>
<li><p>Bartlett 方法，本质上是 likelihood ratio
test，但非常依赖残差的正态假设。也即，如果检验结果是拒绝原假设，未必是真的发生了异方差现象，也可能是因为残差不服从正态分布造成了干扰。</p></li>
<li><p>Levene &amp; modified Levene (B.F.) 方法，非常常见。</p></li>
<li><p>对于可能影响方差导致异方差的因素 <span class="math inline">\(Z\)</span>，将 <span class="math inline">\(e_i
^2\)</span> 相对于 <span class="math inline">\(Z\)</span>
再做一次线性回归，得到的 SSR 记为 <span class="math inline">\(SSR^*\)</span>。</p>
<p>此时 <span class="math inline">\(LM = \frac{SSR^*/2}{(SSE/n)^2} \sim
\chi_1 ^2\)</span> 再进行检验。</p></li>
</ul></li>
</ul>
<h3 id="正态性假设">正态性假设</h3>
<p><span class="math inline">\(\varepsilon _i\)</span>
并不服从正态分布，这可以通过 QQ-plot 观察是否有 <span class="math inline">\(\varepsilon_{(i)} = \mu + \sigma
Z_i\)</span>，或者直接画 histogram 检查是否有正态的形状。</p>
<p><img src="https://s2.loli.net/2023/05/29/iQKNWpv8IseAoFj.png" alt="qq-plot.png"></p>
<p>理论方法之中 Shapiro-Wilk 方法是最佳的，有最大的
power，但是对于样本量是敏感的。也就是说，如果检验结果是 <span class="math inline">\(\varepsilon_i\)</span>
不服从正态分布，也可能是因为样本量太大导致了错误判断。</p>
<p>注意正态性检验是完全可以把 <span class="math inline">\(\{\varepsilon
_i \}\)</span> 作为一组数据放在一起观察整体的分布的，但是对 <span class="math inline">\(\{Y_i \}\)</span>
不可以这样做，它们彼此之间服从的是不同的条件分布。</p>
<h3 id="相关性">相关性</h3>
<p><span class="math inline">\(\varepsilon_i\)</span>
之间可能并不独立，有可能都受到 <span class="math inline">\(t_i\)</span>
的影响，等等。如果有类似可能考虑的因素可以对其做 sequence plot。</p>
<p>理论方法中最常用的是 Durbin-Watson 方法。</p>
<h3 id="outlier">Outlier</h3>
<p>模型的数据里有 outlier，不同性质的 outlier
对回归线的影响不尽相同，具体的在 Lecture 6
中再细说。简单来说就是，outlier 的 <span class="math inline">\(X_i\)</span> 越接近 <span class="math inline">\(\bar{X}\)</span>，对于回归线的斜率影响越小，但如果距离
<span class="math inline">\(\bar{X}\)</span>
比较远，则会产生比较强的杠杆效应。</p>
<p>即使模型中存在 outlier，参数的估计也可以是比较准确的。做 <span class="math inline">\(e_i \sim X\)</span> 图可以查看是否存在
outlier，也可以使用 <span class="math inline">\(Y_i \sim X_i\)</span>
的图来观察是否有距离回归线很远的点，这是最明显的一类
outlier。然后可以尝试剔除这样的点再重新做回归，检查各系数。</p>
<h2 id="关于-r2">关于 <span class="math inline">\(R^2\)</span></h2>
<p>如果在某一线性模型中得到 <span class="math inline">\(R^2 =
0.69\)</span>，能否说明这一线性模型是显著的？</p>
<ul>
<li>事实上可以。<span class="math inline">\(R^2 = 0.69\)</span>
已经是相对大的数值了，说明模型对于方差的解释能力是相对好的；另一方面考虑
<span class="math inline">\(r = \sqrt{R^2} &gt;
0.8\)</span>，相关系数其实是比较大的，可以认为这一模型是合适的。</li>
<li>但是，这并不能说明线性模型是这一问题下最好的模型。<span class="math inline">\(R^2\)</span>
想要多大就可以多大，例如给模型加入新的多项式型变量，总能更多地解释一些方差，不能单纯地追求
<span class="math inline">\(R^2\)</span> 的大小。</li>
<li>另外，如果在不同的模型比较中对 <span class="math inline">\(\{Y_i
\}\)</span> 做了变换，比如进行了标准化或者 Box-Cox
transform，此时是不能和原始的模型再进行 <span class="math inline">\(R^2\)</span> 的比较的，只能检查单个 <span class="math inline">\(R^2\)</span> 的值能否接受。这是因为 <span class="math inline">\(SST\)</span> 已经随着 <span class="math inline">\(\{Y_i \}\)</span>
的变化而变化了，模型的方差解释能力 <span class="math inline">\(\frac{SSR}{SST}\)</span> 无法比较。</li>
</ul>
<h1 id="lecture-6">Lecture 6</h1>
<h2 id="built-in-diagnostic-plots-in-r">Built-in Diagnostic Plots in
R</h2>
<p>R 内置的四个诊断图是 <span class="math inline">\(e_i \sim \hat
Y\)</span>，Q-Q plot，<span class="math inline">\(\sqrt{|\text{Standardized Residuals}|} \sim \hat
Y\)</span>，Cook's distance
图。前两个都比较简单，一个是万能的残差图，另一个是残差的正态性检验，主要说一下后两个图。</p>
<h3 id="scale-location-plot">Scale-Location Plot</h3>
<p><span class="math inline">\(\sqrt{|\text{Standardized Residuals}|}
\sim \hat Y\)</span> 作图体现了 residuals
随拟合值的分布情况，主要用来检验异方差。实际上在上一讲里面是直接用 <span class="math inline">\(e_i \sim X\)</span>
来检验异方差的，这里用了标准化的残差开方，有一些考虑：</p>
<ul>
<li><p>关注 magnitude 所以需要一个正值，选择了先取绝对值</p></li>
<li><p>取绝对值之后的数据往往人为造成了右偏，开方可以缓解一些</p></li>
<li><p>standardize 之后绝大多数 <span class="math inline">\(e_i\)</span>
都收入了 <span class="math inline">\([-2,2]\)</span>
这一范围内（正态分布的主要区间），更清晰，有可比性</p></li>
<li><p>虽然理论上的 <span class="math inline">\(\varepsilon_i\)</span>
是独立分布的，但是残差之间是有约束关系的，<span class="math inline">\(Var(e_i) = (1-h_{ii})\sigma^2\)</span>，也就是说
<span class="math inline">\(e_i\)</span> 的变动范围本身就和其在 <span class="math inline">\(x\)</span> 轴上的位置（也即 <span class="math inline">\(X_i\)</span> 的大小）相关。较大的 <span class="math inline">\(X_i\)</span> 会对应 <span class="math inline">\(e_i\)</span>
的更大方差，导致可能会看起来像异方差。</p>
<p>标准化并开方能够一定程度缓解这样的问题。</p></li>
</ul>
<p>如果此图上的残差点分布看起来比较随机，拟合线也相对平行于 <span class="math inline">\(x\)</span> 轴，基本可以认为是异方差。</p>
<h3 id="cooks-distance">Cook's Distance</h3>
<p>图中被标出数字的点/靠近右上角和右下角/红线之外的点需要重视一下，是
high leverage point 或者 outlier，可以进一步检验。</p>
<h2 id="residuals-leverage">Residuals &amp; Leverage</h2>
<h3 id="leverage">Leverage</h3>
<p>定义每一点的杠杆值为 <span class="math inline">\(h_{ii} =
\frac{\partial \hat Y_i}{\partial Y_i} \in [0,1]\)</span>，表征了某一个
<span class="math inline">\(X_i\)</span> 对应的 <span class="math inline">\(Y_i\)</span>
变动一个单位时，会导致回归线上的响应值变动的大小，也就是说，这一点的变化对于整个回归模型的影响。</p>
<p>事实上，<span class="math inline">\(X_i\)</span> 对应的点的 leverage
是 <span class="math inline">\(h_{ii} = \frac 1 n + \frac{(X_i - \bar
X)^2}{\Sigma_j (X_i - \bar X)^2}\)</span>，<span class="math inline">\(h_{ii}\)</span> 越大会导致 <span class="math inline">\(Var(e_i) = (1- h_{ii})\sigma^2\)</span> 越小，因此
<span class="math inline">\(e_i\)</span> 的变动范围变小，<span class="math inline">\(\hat Y_i\)</span>
能够变动的范围也较小，会导致回归线受较大的影响；从 leverage
的表达式可以看出来，<span class="math inline">\(|X_i -\bar X|\)</span>
越大会导致杠杆值越大，也就是说远离中心的点对回归线造成的影响较大。</p>
<p>我们对 extreme values 做一些分类：</p>
<ul>
<li><p>Outlier: 离群值是对于其 <span class="math inline">\(Y\)</span>
值而言的，<span class="math inline">\(Y_i\)</span>
的实际取值远离通常该有的范围，则这一点会被认为是 outlier。</p></li>
<li><p>High Leverage Point: 高杠杆值点是对于其 <span class="math inline">\(X_i\)</span> 的取值而言的，由上述分析可以得到
<span class="math inline">\(h_{ii}\)</span> 较大的主要条件。</p></li>
<li><p>Influential Point:
强影响力点指的是移除此点后，回归线会发生较大的变化的点。</p>
<p>如果一个点既是 outlier 又是 high leverage point，那它一定是
influential point，直觉上来看是因为它的 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span>
都具有一定的特征，会对回归线造成较大的影响。</p></li>
</ul>
<p>如果 <span class="math inline">\(h_{ii} &gt; 2p/n\)</span>
一般就称为高杠杆值点。</p>
<h3 id="studentized-residual">Studentized Residual</h3>
<p>一个 influential point
造成回归线的巨大改变无法在残差图上体现出来，因此我们希望有一种手段能够体现出它和其他正常点的巨大差异。一个自然的想法是先移除它再做回归线，然后在这一模型上体现残差，即为
studentized residual。</p>
<p>这么说还是太抽象了，放个图好了：</p>
<p><img src="https://s2.loli.net/2023/05/29/Uy8JvP4eBmWS1GT.png" alt="studentized-residual.png"></p>
<p>具体来说，studentized residual 和 standardized residual
有一些差别：</p>
<ul>
<li><p>standardized residual: <span class="math inline">\(\frac{e_i}{s(e_i)}\)</span>，由于 <span class="math inline">\(Var(e_i) = (1-h_{ii})\sigma^2\)</span>，则 <span class="math inline">\(s^2 (e_i) =
(1-h_{ii})MSE\)</span>，代入即可。</p></li>
<li><p>deleted residual: <span class="math inline">\(d_i = Y_i - \hat
Y_{i(-i)}\)</span>，其中 <span class="math inline">\(\hat
Y_{i(-i)}\)</span> 是 <span class="math inline">\(X_i\)</span>
在去除这一点的模型中所对应的响应。</p></li>
<li><p>studentized residual: <span class="math inline">\(\frac{d_i}{s(d_i)}\)</span>，同理有 <span class="math inline">\(s^2(d_i) = (1-h_{ii})MSE_i\)</span>，<span class="math inline">\(MSE_i\)</span> 是去除第 <span class="math inline">\(i\)</span> 点的模型对应的 MSE。</p>
<p>事实上 <span class="math inline">\(e_i^* = \frac{d_i}{s(d_i)} =
\frac{e_i}{\sqrt{MSE(1-h_{ii})}}\)</span> 是 internal studentized
residual，当 <span class="math inline">\(|e_i ^*| &gt;2\)</span>
时认为是一个 outlier。</p>
<p>studentized deleted residual 如下所示：</p>
<p><img src="https://s2.loli.net/2023/06/01/WTrmCsZ1oyLFzpQ.png" alt="studentized-deleted-residual.png"></p></li>
</ul>
<h3 id="cooks-distance-1">Cook's Distance</h3>
<p>考虑 <span class="math inline">\(D_i = \frac{\Sigma_j (\hat Y_j -
\hat Y_{j(-i)})^2}{ps^2}= \frac{e_i^2}{p\cdot MSE}
\frac{h_{ii}}{(1-h_{ii})^2}\)</span>，其中 <span class="math inline">\(\hat Y_{j(-i)}\)</span> 指的是 <span class="math inline">\(X_j\)</span> 在去除第 <span class="math inline">\(i\)</span> 点的模型中对应的平均响应值。第 <span class="math inline">\(i\)</span> 点的 Cook's distance <span class="math inline">\(D_i\)</span> 表征的是第 <span class="math inline">\(i\)</span>
点的值对全体预测值（也就是回归线）的影响力。<span class="math inline">\(D_i\)</span> 越大越说明这是个 high influential
point，一般吧 threshold 作为 <span class="math inline">\(0.5\)</span>
或者 <span class="math inline">\(\frac 4 n\)</span>。</p>
<h2 id="lack-of-fit-test">Lack of fit test</h2>
<p>怀疑某个模型并不符合线性，且其某一 <span class="math inline">\(X_i\)</span> 点处有多个对应的 <span class="math inline">\(Y\)</span>，也即这一点处存在 replicates 或者说
repeated observation 的时候，可以进行失拟检验。具体来说，可以进一步细分
SSE 为 sum of pure error 和 sum of lack of fit
error，前者由数据的随机性导致，后者由线性模型的失拟性造成。</p>
<p>事实上也是 general linear test 的一种，这里的 full model 就是 cell
mean model <span class="math inline">\(Y_{ij} = \mu_i +
\varepsilon_{ij}\)</span>，reduced model 是线性模型 <span class="math inline">\(Y_{ij}=\beta_0 +\beta_1 X_i +
\varepsilon_{ij}\)</span>。也就是说，实际上的 <span class="math inline">\(H_0: \mu_i = \beta_0 + \beta_1 X_i\)</span>，拒绝
<span class="math inline">\(H_0\)</span> 时说明 reduced model 失拟。</p>
<p>对 SSE 进行进一步的拆分，将其改变为 <span class="math inline">\(SSE =
SSPE +SSLF\)</span>，具体表达式和自由度如下所示：</p>
<p><span class="math display">\[\Sigma_{i=1} ^c
\Sigma_{j=1}^{n_i}(Y_{ij} - \hat Y_{ij})^2 = \Sigma_{i=1} ^c
\Sigma_{j=1}^{n_i}(Y_{ij} - \bar Y_{i.})^2+ \Sigma_{i=1} ^c
\Sigma_{j=1}^{n_i}(\bar Y_{i.} - \hat Y_{ij})^2\]</span></p>
<p><span class="math display">\[SSE = SSPE + SSLF\]</span></p>
<p><span class="math display">\[(n-2) = (n-c)+(c-2)\]</span></p>
<p>因此，对应地有 <span class="math inline">\(E(MSPE) = \sigma^2,E(MSLF)
= \sigma^2 + \frac{\Sigma_i n_i (\mu_i - (\beta_0 + \beta_1
X_i))^2}{c-2}\)</span>，test statistic 是 <span class="math inline">\(F^* = \frac{MSLF}{MSPE} \sim ^{H_0}
F(n-c,c-2)\)</span>。</p>
<p>这也就说明了为什么失拟检验只有在存在 replicates
的时候才能做，因为这时才会有 <span class="math inline">\(n &gt;
c\)</span>，使得模型不至于退化。</p>
<h2 id="remedy-methods">Remedy Methods</h2>
<h3 id="补救非线性">补救非线性</h3>
<p>通过 <span class="math inline">\(e_i \sim X\)</span>
观察到模型并不是完全线性的时候，如果不想再改变
assumptions，可以转而选择非线性的模型。</p>
<p>R 中可以调用函数 <code>nls</code>。</p>
<h3 id="补救异方差">补救异方差</h3>
<p>可以使用 weighted analysis，具体参见 Lecture 12 的内容。</p>
<h3 id="补救非正态">补救非正态</h3>
<p>如果残差体现出非正态分布的性质，可以对 <span class="math inline">\(Y\)</span>
做变换继续使用线性模型，也可以使用其他的模型来允许残差不同分布。在 R
中可以调用函数 <code>glm</code>。</p>
<h3 id="transformation">Transformation</h3>
<p>有以下任一需求的时候都可以考虑对 <span class="math inline">\(Y_i\)</span> 做变换：</p>
<ul>
<li>稳定方差：观察到 <span class="math inline">\(\varepsilon_i\)</span>
似乎是异方差的</li>
<li>提高正态性</li>
<li>简化模型，提高解释性</li>
</ul>
<p>最普遍的方法是 Box-Cox Transformation，取 <span class="math inline">\(Y^* =
(Y^\lambda-1)/\lambda\)</span>，首要任务是找到最合适的 <span class="math inline">\(\lambda\)</span>
做变换。事实上所谓的“最合适”包含两层意义，其一是希望模型拟合程度较高，其二是希望
<span class="math inline">\(\lambda\)</span> 使得 <span class="math inline">\(Y^*\)</span>
的形式尽量简洁明了，解释性强，也就是取所谓的 convenient lambda。例如取
<span class="math inline">\(\lambda=0\)</span> 时有 <span class="math inline">\(Y^* = \log Y\)</span>，取 <span class="math inline">\(\lambda\)</span>
为整数时即为多项式回归，等等。</p>
<p>另外不同的 <span class="math inline">\(\lambda\)</span>
值会对数据的右偏有不同程度的改善，右尾压缩最明显的是开根和取对数；也可以取负值来压缩左尾。</p>
<p>在实际使用中往往是直接对 <span class="math inline">\(\lambda\)</span>
取一个 sequence，找到近似取到 maximum likelihood 或者使得 SSE 最小的
<span class="math inline">\(\lambda\)</span>
的一个置信区间，再在其中寻找合适的 convenient lambda。</p>
<p>一些典型的数据分布和变换方法：</p>
<p><img src="https://s2.loli.net/2023/05/29/VwIlizq5vsEFot6.png" alt="prototype-box-cox-trans.png"></p>
<h2 id="miscellaneous-topics">Miscellaneous Topics</h2>
<p>一些杂谈，关于 simple linear regression 的最后内容。</p>
<h3 id="regression-through-the-origin">Regression Through the
Origin</h3>
<p>非常坏回归，爱来自自由度（</p>
<p>强迫过原点回归的时候斜率的估计是 <span class="math inline">\(\hat
\beta_1 = \frac{\Sigma X_iY_i}{\Sigma
X_i^2}\)</span>，这会导致一些很严重的后果：</p>
<ul>
<li>残差的和 <span class="math inline">\(\Sigma e_i \neq
0\)</span>，这导致 <span class="math inline">\((Y_i - \bar Y)^2 = (Y_i -
\hat Y_i)^2 + (\hat Y_i - \bar Y)^2 + 2(Y_i - \hat Y_i)(\hat Y_i - \bar
Y)\)</span> 的交互项无法消去，于是也不能再对 SST 做分解成为 SSE 和 SSR
之和。</li>
<li>SSE 此时的自由度是 <span class="math inline">\(n-1\)</span>，SST
的自由度也不再是 SSE 和 SSR 的自由度之和。</li>
</ul>
<h3 id="inverse-predictions">Inverse Predictions</h3>
<p>对 <span class="math inline">\(Y \sim X\)</span> 做回归得到 <span class="math inline">\(y = b_0 + b_1 x\)</span> 和对 <span class="math inline">\(X \sim Y\)</span> 做回归得到 <span class="math inline">\(x = a_0 + a_1 y\)</span>
中，实际上在绝大多数情况下都有 <span class="math inline">\(a_1 b_1 \neq
1\)</span>。也就是说，两种回归的结果不能简单地用线性求反函数得到，这听起来有点反直觉但确实是合理的，做
<span class="math inline">\(Y \sim X\)</span> 回归的目标是取得关于 <span class="math inline">\(Y\)</span> 的最小残差平方和，做 <span class="math inline">\(X\sim Y\)</span> 回归的目标是取得关于 <span class="math inline">\(X\)</span>
的最小残差平方和，目标不一致得到的结果自然不同。</p>
<p>用理论来解释的话，取相关系数 <span class="math inline">\(r =
\frac{\sum (X_i - \bar X)(Y_i - \bar Y)}{\sqrt{\sum (X_i - \bar X)^2}
\sqrt{\sum (Y_i - \bar Y)^2}}\)</span>，记 <span class="math inline">\(S_Y = \sqrt{\sum (Y_i - \bar Y)^2},S_X =
\sqrt{\sum (X_i - \bar X)^2}\)</span>，于是有：</p>
<p><span class="math inline">\(b_1 = r \frac{S_Y}{S_X},a_1 = r
\frac{S_X}{S_Y}\)</span>，因此 <span class="math inline">\(b_1a_1 =
r^2\)</span>。两条回归线之间的夹角是 <span class="math inline">\(\tan
\theta = \frac{1-r^2}{r(\frac{S_X}{S_Y} +
\frac{S_Y}{S_X})}\)</span>。</p>
<p>如果对于某个响应值 <span class="math inline">\(Y_i\)</span>
需要反向预测输入变量 <span class="math inline">\(X_i\)</span>，应该选择
<span class="math inline">\(\hat X_h = \frac{Y_h - b_0}{b_1}\)</span>
而不是反过来做 <span class="math inline">\(X\)</span> 关于 <span class="math inline">\(Y\)</span> 的回归。</p>
<h3 id="limitations-of-r2">Limitations of <span class="math inline">\(R^2\)</span></h3>
<p>使用 <span class="math inline">\(R^2\)</span>
作为判断依据的时候要注意以下问题：</p>
<ul>
<li><p><span class="math inline">\(R^2\)</span>
不能作为拟合程度的度量。<span class="math inline">\(R^2 = \frac{b_1 ^2
\sum (X_i - \bar X)^2}{\sum (Y_i - \bar Y)^2}\)</span>
的形式显示了，实际上如果把 <span class="math inline">\(X\)</span>
的取值变得足够分散，<span class="math inline">\(R^2\)</span>
的取值想要多大就能有多大。</p>
<p>不同的散点分布情况可以得到几乎相同的 <span class="math inline">\(R^2\)</span>，一定要画图检查线性模型是不是最合理的。</p>
<p><img src="https://s2.loli.net/2023/05/29/OJZi635KwUQ8quf.png" alt="same-r-square-but-different-models.png"></p></li>
<li><p>不能对于不同的模型比较 <span class="math inline">\(R^2\)</span>，归根结底 <span class="math inline">\(R^2\)</span> 反映的是模型对于 SST 的解释能力，SST
一旦改变就不能交叉对比。因此上述 transformation 中对于系数 <span class="math inline">\(\lambda\)</span> 的比选标准是 maximum
likelihood。</p></li>
<li><p><span class="math inline">\(R^2\)</span> 不能显示 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span> 之间的因果关系，因为 <span class="math inline">\(Y\sim X\)</span> 和 <span class="math inline">\(X
\sim Y\)</span> 这两种回归得到的 <span class="math inline">\(R^2\)</span> 是相等的。</p></li>
</ul>
<h1 id="lecture-7">Lecture 7</h1>
<p>从一元线性回归过渡到多元回归的部分，介绍回归方程的矩阵表达。</p>
<h2 id="矩阵表达">矩阵表达</h2>
<p>把 <span class="math inline">\(n\)</span> 个回归方程的形式改成：</p>
<p><span class="math display">\[\begin{bmatrix}Y_1 \\ Y_2 \\ ... \\ Y_n
\end{bmatrix} = \begin{bmatrix}1 &amp; X_{1,1} &amp; X_{2,1} &amp;...
&amp; X_{p-1,1} \\ 1 &amp; X_{1,2} &amp; X_{2,2} &amp; ... &amp;
X_{p-1,2} \\ ... &amp; ... &amp; ... &amp;... &amp; ... \\ 1 &amp;
X_{1,n} &amp; X_{2,n} &amp; ... &amp; X_{p-1,n} \end{bmatrix}
\begin{bmatrix}\beta_0 \\ \beta_1 \\ ... \\ \beta_{p-1} \end{bmatrix} +
\begin{bmatrix}\varepsilon_1 \\ \varepsilon_2  \\ ... \\ \varepsilon_n
\end{bmatrix}\]</span></p>
<p><span class="math display">\[Y = X \beta + \varepsilon\]</span></p>
<p>假设 <span class="math inline">\(\varepsilon \sim N_n(0, \sigma^2
I_{n \times n})\)</span>，则有 <span class="math inline">\(Y \sim N_n(X
\beta , \sigma^2 I_{n \times n})\)</span>，以下考虑参数矩阵 <span class="math inline">\(\beta\)</span> 的估计：</p>
<p><span class="math display">\[b = \hat \beta = (X^TX)^{-1} X^T Y \sim
N_p(\beta , (X^TX)^{-1} \sigma^2)\]</span></p>
<p>和 simple linear regression 相同，<span class="math inline">\(b\)</span> 也有 BLUE 的性质。</p>
<p>因此有 <span class="math inline">\(Y\)</span> 的平均响应为 <span class="math inline">\(\hat Y = X \hat \beta = X(X^TX)^{-1}
X^TY\)</span>，其中记 <span class="math inline">\(H = X(X^TX)^{-1}
X^T\)</span>，这就是著名的 hat
matrix，围绕它有很多性质，后面再说；由于残差 <span class="math inline">\(e = Y - \hat Y = (I - X(X^TX)^{-1}
X^T)Y\)</span>，因此 simple linear regression 中对于 <span class="math inline">\(e\)</span> 的限制在此处相应地修改为 <span class="math inline">\(e^T \hat Y = Y^T(I - X(X^TX)^{-1} X^T)
(X(X^TX)^{-1} X^T)Y = 0\)</span>。</p>
<p>相应地，<span class="math inline">\(\sigma\)</span> 的估计量可以改成
<span class="math inline">\(s^2 = \frac{e^Te}{n-p} =
\frac{Y^T(I-H)Y}{n-p}\)</span>，这就是 MSE，是 <span class="math inline">\(\sigma^2\)</span> 的无偏估计；又因为 <span class="math inline">\(Var(b) = (X^TX)^{-1} \sigma^2\)</span>，因此有
<span class="math inline">\(\hat Var(b) = (X^TX)^{-1} \hat \sigma^2 =
s^2 (X^TX)^{-1}\)</span> 是 <span class="math inline">\(Var(b)\)</span>
的估计。</p>
<p>ANOVA 中的方差和自由度拆分在这里仍然适用：</p>
<p><span class="math display">\[SST = (Y - \bar Y \mathbb 1_n)^T (Y -
\bar Y \mathbb 1_n), \quad df = n-1\]</span></p>
<p><span class="math display">\[SSM = (\hat Y - \bar Y \mathbb
1_n)^T(\hat Y - \bar Y \mathbb 1_n), \quad df = p-1\]</span></p>
<p><span class="math display">\[SSE  = (Y - \hat Y)^T(Y- \hat Y), \quad
df=n-p\]</span></p>
<p><span class="math inline">\(F-\)</span>test 的检验统计量是 <span class="math inline">\(F^* = \frac{MSM}{MSE} \sim^{H_0}
F_{p-1,n-p}\)</span>，其中假设是 <span class="math inline">\(H_0
:\beta_1 = \beta_2 = ... =\beta_{p-1}=0\)</span>；决定系数 <span class="math inline">\(R^2 = \frac{SSM}{SST}\)</span>
仍然保持不变，显示了线性模型解释方差的能力；adjusted <span class="math inline">\(R^2\)</span> 定义为 <span class="math inline">\(1-
\frac{MSE}{MST} = 1- \frac{n-1}{n-p} \frac{SSE}{SST}\)</span>，相对于
<span class="math inline">\(R^2\)</span> 的优势在于，<span class="math inline">\(R^2\)</span>
在有任意的变量进入模型时都会增大，但如果新变量的显著性不足会导致
adjusted <span class="math inline">\(R^2\)</span>
下降，是一个更有力的参数。</p>
<h2 id="hat-matrix">Hat Matrix</h2>
<p>Hat Matrix 有丰富的性质，在这里列举一些和统计关联比较大的。</p>
<p><span class="math display">\[Cov(e) = Cov((I-H)Y) = (I-H)^T \sigma^2
(I-H) = \sigma^2 (I-H)\]</span></p>
<p><span class="math display">\[Cov(e_i , e_j) = -\sigma^2
h_{ij}\]</span></p>
<p><span class="math display">\[Var(e_i) = \sigma^2
(1-h_{ii})\]</span></p>
<p>其中 <span class="math inline">\(h_{ij}\)</span> 是矩阵 <span class="math inline">\(I -H\)</span> 的分量。</p>
<p>事实上，第 <span class="math inline">\(i\)</span> 点的杠杆值就是
<span class="math inline">\(h_{ii}\)</span>。可以通过 <span class="math inline">\(H = H^2\)</span> 这一性质简单地证明出 <span class="math inline">\(h_{ii} \leq
1\)</span>，这也和杠杆值的定义是符合的。</p>
<h2 id="multiple-linear-regression">Multiple Linear Regression</h2>
<ul>
<li><p>关于多元回归的系数 <span class="math inline">\(\beta_1,\beta_2,...,\beta_{p-1}\)</span>（也称为偏回归系数），我们仍然可以按照
SLR 时的方式解释它们：<span class="math inline">\(\beta_i\)</span> 是在
<span class="math inline">\(X_1,X_2,...,X_{i-1},X_{i+1},...,X_{p-1}\)</span>
不变时，<span class="math inline">\(X_i\)</span> 变化一个单位导致 <span class="math inline">\(E(Y)\)</span> 的变化量。</p>
<p>实际上这就引出了多元回归的一个巨大隐患：并不是所有的变量都完全不相关，一旦
<span class="math inline">\(X_1,X_2\)</span> 之间有相关性存在，改变
<span class="math inline">\(X_1\)</span> 的时候很难保证 <span class="math inline">\(X_2\)</span>
不变，多元回归的系数解释性因此变差。</p>
<p>虽然理论上确实可能存在完全不相关的变量，但是对应的数据也很难不相关。</p></li>
<li><p><span class="math inline">\(Var(e_i) = \sigma^2
(1-h_{ii})\)</span>，因此在线性回归中，位于中间（靠近 <span class="math inline">\(\bar X\)</span>）的 <span class="math inline">\(X\)</span>
拟合能力较弱（杠杆值低，对回归线的影响较弱）但是预测能力较好（<span class="math inline">\(Var(e_i)\)</span> 较小，<span class="math inline">\(\hat Y\)</span>
能够变动的范围小）。相反地，位于两端的 <span class="math inline">\(X\)</span> 拟合能力较强但是预测能力较弱。</p>
<p>事实上我们是不能轻易预测已有数据范围之外的 <span class="math inline">\(x\)</span>
的响应的，理由如上所述，此时的预测能力很弱。</p></li>
</ul>
<h1 id="lecture-8">Lecture 8</h1>
<h2 id="explanatory-data-analysistransformation">Explanatory Data
Analysis——Transformation</h2>
<h3 id="why-look-at-y">Why look at Y</h3>
<p>一般来说 <span class="math inline">\(Y\)</span>
的分布我们是不用太在意的，毕竟不是同分布，但其实考虑到做变换的话还是要稍微看一下它的分布。</p>
<p>如果分布是高度有偏的，做变换把长尾的部分往中央收一收可以得到的效果有：</p>
<ul>
<li><p>减小 SST，修正模型的显著性；</p></li>
<li><p>把拖尾方向可能的 outlier
向内收，有可能可以变成正常的数据来使用；另一侧原来数据比较集中，做变换如果可以将分布拉长的话便于观察其中的一些特征；</p>
<p>实际上 outlier
并不能随意的扔掉，做变换的想法是能够保留就尽量保留。有些时候很多现象就隐藏在出现了
outlier
这件事情上面，比如臭氧层空洞没有被尽早发现就是因为相关的数据被当成
outlier 扔掉了。</p></li>
<li><p>方差对于 skewed data 和 outlier 都比较敏感；</p></li>
<li><p>对于 skewed data，均值并不是中心位置很好的显示。</p></li>
</ul>
<p>但通常来说做变换之前都需要三思：</p>
<ul>
<li>做变换后可解释性会有问题，比如 Box-Cox Transformation 中奇怪的 <span class="math inline">\(\lambda\)</span>
取值会导致可解释性变差，实验数据有的时候需要保留单位，做变换之后会失去意义；</li>
<li>会导致 <span class="math inline">\(H_0\)</span> 改变；</li>
<li>不一定能够改进正态性，做变换未必有好的效果；</li>
<li>做了变换得到结果之后，变回原始数据很可能破坏无偏性；</li>
<li>破坏了残差的分布。</li>
</ul>
<p>有一些平替方案：GLM, resampling methods, non-parametric methods</p>
<p>另外我们一般不会对 <span class="math inline">\(X\)</span>
做变换，除非做变换之后和 <span class="math inline">\(Y\)</span>
有非常明确的关系，另一个原因是做变换可能会导致共线性。</p>
<h3 id="why-log-transformation">Why log Transformation</h3>
<p>对 right-skewed data 做 log transformation
的好处是显著多于其他类型的变换的：</p>
<ul>
<li><span class="math inline">\(\log Y_1 - \log Y_2 = \log (1+ \frac{Y_1
- Y_2}{Y_2}) \approx \frac{Y_1 -
Y_2}{Y_2}\)</span>，可以把绝对误差变为相对误差来讨论；</li>
<li><span class="math inline">\(\log Y\)</span>
可以让数据的分布更对称，出于计算的考虑</li>
<li>如果 <span class="math inline">\(Y\)</span> 全部都是正数，但 <span class="math inline">\(Y = X \beta + \varepsilon \sim N(X \beta, \sigma^2
I)\)</span>，一个多元正态分布的数据全部是正数的概率非常小，假设不合理。</li>
</ul>
<p>但是最大的问题就是可解释性。对于参数 <span class="math inline">\(\beta\)</span> 的解释是在 <span class="math inline">\(X\)</span> 增长一个单位时 <span class="math inline">\(Y\)</span>
的平均响应的对应变化，在这里我们选择的是报告平均响应变化的百分比，也即
<span class="math inline">\(\frac{e^{(X+1)b} - e^{Xb}}{e^{Xb}} = e^b
\times 100 \%\)</span>，作为一个补救措施。</p>
<h2 id="mlr-vs-slr">MLR vs SLR</h2>
<p>相比于 simple linear regression，MLR
的变量增多了之后需要考虑的问题也增加了，复杂度也变大了。</p>
<h3 id="变量选择">变量选择</h3>
<p>破事很多：</p>
<ul>
<li>单独一个 <span class="math inline">\(X_i\)</span>
在模型里不显著也不能直接扔掉，它可能是 suppressor
variable，会让别的变量显著</li>
<li>多个变量的模型显著不能推出单个变量显著</li>
<li>单变量模型中，变量显著性 <span class="math inline">\(t\)</span>
检验和模型显著性 <span class="math inline">\(F\)</span> 检验的 p-value
相等，因为 <span class="math inline">\(F_{1,n} = t_n ^2\)</span></li>
<li>其余变量是否需要进入模型，可以先考虑残差对于其余各个变量的回归显著性，先测试最显著的变量进入模型</li>
</ul>
<p>有的时候我们认为模型里变量越多越好，有的时候越少越好，这取决于做回归的目的：</p>
<ul>
<li>回归模型是为了预测：变量越多或者说 adjusted <span class="math inline">\(R^2\)</span>
越大，解释的方差越多，预测水平越好</li>
<li>回归模型是为了解释：变量越少，explanatory variable 和 response
之间的关系越明确，解释性越好</li>
</ul>
<p>总之，会随着模型中进入的变量而改变的参数有：</p>
<ul>
<li>回归系数（<span class="math inline">\(\hat \beta_i\)</span>）</li>
<li>standard error</li>
<li>模型显著性</li>
</ul>
<h3 id="诡异的现象">诡异的现象</h3>
<p>有的时候会遇到 Significance &amp; low <span class="math inline">\(R^2\)</span>
同时出现的情况，也就是某个变量看起来是显著的，但是 <span class="math inline">\(R^2\)</span>
很低，解释方差的能力并不好。这是正常的现象。</p>
<ul>
<li><p>回到 <span class="math inline">\(R^2\)</span> 的定义和 F
检验的本质可以发现，<span class="math inline">\(R^2 = \frac{SSR}{SST},
F^* = \frac{MSR}{MSE} = \frac{R^2}{1-R^2} \frac{n-p}{p-1}\)</span>，如果
<span class="math inline">\(n\)</span> 非常大，即使 <span class="math inline">\(R^2\)</span> 很小也和 <span class="math inline">\(F^*\)</span> 很大之间并不矛盾。</p></li>
<li><p><span class="math inline">\(R^2\)</span> 的分母 <span class="math inline">\(SST\)</span>
实际上表征了数据的分散程度，数据非常分散的时候是可能导致 <span class="math inline">\(R^2\)</span>
减小的。但是数据分散和存在线性并不矛盾，图中的两个线性关系当然都显著，但是
<span class="math inline">\(R^2\)</span> 有巨大的差距。</p>
<p><img src="https://s2.loli.net/2023/05/29/BkYA4IrhbLXjTna.png" alt="central-tendency-and-variability.png"></p></li>
</ul>
<h3 id="inference">Inference</h3>
<ul>
<li><p>多重线性回归的推断里面也有一个著名定理：<span class="math inline">\(Y \sim N_n(X \beta , \sigma^2 I)\)</span>，于是有
<span class="math inline">\(b \sim N_p(\beta , \sigma^2
(X^TX)^{-1})\)</span>，以及：</p>
<ul>
<li><span class="math inline">\(\frac{e^Te}{\sigma^2} =
\frac{SSE}{\sigma^2} \sim \chi^2_{n-p}\)</span></li>
<li><span class="math inline">\(b\)</span> 和 <span class="math inline">\(SSE\)</span> 相互独立</li>
</ul>
<p>由此得到很多推断方法。</p></li>
<li><p>关于 <span class="math inline">\(b_k\)</span> 的推断和
CI，主要关注 <span class="math inline">\(b_k \sim N(\beta_k,
\sigma^2((X^TX)^{-1})_{k,k})\)</span>，希望检验 <span class="math inline">\(H_0 : \beta_k =0; H_1 : \beta_k \neq
0\)</span>。</p>
<p>检验统计量是 <span class="math inline">\(t^* = \frac{b_k}{s(b_k)} =
\frac{b_k}{\sqrt{MSE ((X^TX)^{-1})_{k,k}}}\sim ^{H_0}
t_{n-p}\)</span>，由此可以检查单个变量的显著性。注意此处所谓的显著性，指的是第
<span class="math inline">\(k\)</span>
个变量最后一个进入模型时的显著性，无论它在 R table 里排列在哪里。和
general linear test 的结果一致。如果这一检验体现出来变量 <span class="math inline">\(X_k\)</span>
不显著，绝大多数情况下是可以不保留的。</p>
<p><span class="math inline">\(100(1-\alpha) \%\)</span> 置信区间是
<span class="math inline">\((b_k \pm t_{1-\alpha /2,n-p}
s(b_k))\)</span>，注意 <span class="math inline">\(s(b_k)\)</span>
的含义在上述已经提到。</p></li>
<li><p>关于 <span class="math inline">\(E(Y_h)\)</span> 的推断和
CI，考虑 <span class="math inline">\(\mu_h = E(Y_h) = X_{h}
\beta\)</span>。</p>
<p>其估计量是 <span class="math inline">\(\hat \mu_h = X_h b = X_h
(X^TX)^{-1} X^TY \sim N(\mu_h , \sigma^2 X_h (X^TX)^{-1}
X_h^T)\)</span>，于是 <span class="math inline">\(s^2(\hat \mu_h) = MSE
\cdot X_h (X^TX)^{-1} X_h^T\)</span>。因此 <span class="math inline">\(\mu_h\)</span> 的 <span class="math inline">\(100
(1-\alpha) \%\)</span> 置信区间是 <span class="math inline">\((\hat
\mu_h \pm t_{1-\alpha /2 , n-p} s(\hat \mu_h))\)</span></p>
<p>考虑 <span class="math inline">\(Y_h = X_h \beta +
\varepsilon\)</span>，有 <span class="math inline">\(\hat Y_h - Y_h \sim
N(0,\sigma^2 + \sigma^2 X_h (X^TX)^{-1} X_h^T)\)</span>， <span class="math inline">\(s^2(\hat Y_h - Y_h) = MSE \cdot (1+X_h (X^TX)^{-1}
X_h ^T)\)</span>，因此 <span class="math inline">\(Y_h\)</span> 的 <span class="math inline">\(100 (1-\alpha) \%\)</span> 置信区间是 <span class="math inline">\((\hat Y_h \pm t_{\alpha /2 , n-p} s(\hat Y_h -
Y_h))\)</span></p></li>
</ul>
<h1 id="lecture-9">Lecture 9</h1>
<h2 id="extra-sum-of-squares">Extra Sum of Squares</h2>
<p>想法很简单，定义就是把一个新的变量加入模型后可以额外解释的方差，例如模型中本来存在
<span class="math inline">\(X_2\)</span> 时，加入 <span class="math inline">\(X_1\)</span> 后可以额外解释的方差是 <span class="math inline">\(SSR(X_1 | X_2) = SSR(X_1 ,X_2) - SSR(X_2) =
SSE(X_2) - SSE(X_1,X_2)\)</span>。</p>
<p>在多重回归中分解 sum of squares 的方式最常见的是 Type I method：</p>
<p><span class="math inline">\(SSR(X_1,X_2,X_3,X_4) = SSR(X_1) + SSR(X_2
|X_1) + SSR(X_3 |X_1,X_2)+SSR(X_4 |X_1,X_2,X_3)\)</span></p>
<p>也就是所谓的 sequential sum of squares 的方法，在
<code>anova()</code> 中的列表就是这样的分解方式，分掉了所有的 SSR。</p>
<p>SAS 中的 sum of square 分解有三种模式，以考虑 A,B,AB 三种因子（2-way
ANOVA）的情况如下排列：</p>
<p><img src="https://s2.loli.net/2023/05/30/KrAcZO2aIPQvYlS.png" alt="3-types-anova.png"></p>
<p>可以看到 type I 就是按照 sequential
的模式进入模型，认为不同的变量有重要性的排序，先进入理论上来说最有必要进入模型的
A，再进入 B，最后进入 AB，分别计算 extra sum of squares；type II
忽略了交互效应 AB，对于 A 和 B 的单变量分解是与 type I 相同的；type III
和之前提到的 t 检验类似，每个模型的 extra sum of square
分解都是考虑它最后一个进入模型时带来的方差解释能力，但这里实际上存在一个问题，按照
hierarchy 的原则来说如果主效应 A,B
之一不显著/没有进入模型，是不能允许交互项 AB 进入模型的。</p>
<h2 id="general-linear-test-1">General Linear Test</h2>
<h3 id="test-reduced-model">Test Reduced Model</h3>
<p>一种检验 full model 和 reduced model
之间关系的检验方法，例如对于存在五个变量 <span class="math inline">\(X_1,X_2,X_3,X_4,X_5\)</span> 的 full model
和存在三个变量 <span class="math inline">\(X_1,X_2,X_3\)</span> 的
reduced model 来说，假设 <span class="math inline">\(H_0: \beta_4 =
\beta_5 = 0; H_1:\beta_4,\beta_5\)</span> 中至少有一个不是 <span class="math inline">\(0\)</span>。</p>
<p>检验统计量是 <span class="math inline">\(F^* = \frac{(SSE(R) -
SSE(F))/(df_E(R) - df_E(F)}{SSE(F)/df_E(F)}\sim ^{H_0}
F_{df_E(R)-df_E(F),df_E(F)}\)</span>，注意第一个自由度实际上是两个模型相差的变量个数，分母中的
<span class="math inline">\(SSE(R) - SSE(F) = SSR(F) - SSE(R) =
SSR(X_4,X_5|X_1,X_2,X_3)\)</span> 实际上是 extra sum of squares。</p>
<p>事实上我们是 prefer 接受 <span class="math inline">\(H_0\)</span>
的，就相当于可以使用变量更少的模型，解释性更强；但是有的时候检验做出来接受
<span class="math inline">\(H_0\)</span>，也需要考虑一下是不是数据量太小导致
power 不够，如果数据量够大就可以放心地使用 reduced model 了。</p>
<h3 id="test-linear-hypothesis">Test Linear Hypothesis</h3>
<p>实际上只要是关于回归系数的线性检验就都可以用 general linear test
来进行，比如 <span class="math inline">\(H_0 : \beta_1 + 3 \beta_2
=12\)</span>，等等。</p>
<p><span class="math inline">\(H_0 : C \beta =t\)</span>，<span class="math inline">\(C\)</span> 是有关 <span class="math inline">\(\beta\)</span> 的约束条件的矩阵，检验统计量是
<span class="math inline">\(F = \frac{(C \hat \beta - t)^T (C(X^TX)^{-1}
C^T)^{-1} (C \hat \beta - t)}{qs^2} \sim^{H_0} F_{q,n-p}\)</span>，其中
<span class="math inline">\(q=rank(C)\)</span>。</p>
<h2 id="偏决定系数-偏相关系数">偏决定系数 &amp; 偏相关系数</h2>
<p><span class="math inline">\(R^2_{Yk|1,2,...,k-1,k+1,...,q} =
\frac{SSR(X_k |
X_1,..,X_{k-1},X_{k+1},...,X_q)}{SSE(X_1,...,X_{k-1},X_{k+1},...,X_q)} =
1-
\frac{SSE(X_1,X_2,...,X_q)}{SSE(X_1,...,X_{k-1},X_{k+1},...,X_q)}\)</span></p>
<p>本质上说的是，模型中新进入的 <span class="math inline">\(X_k\)</span>
带来的 extra sum of squares 解释了 SSE
的比例，也即解释了没有由原来的变量解释掉的方差比率。</p>
<p>实际上另一种表现形式可以是，我们认为 <span class="math inline">\(R^2_{Yk|1,2,...,k-1,k+1,...,q} =
\frac{SSE(R)-SSE(F)}{SSE(R)} = \frac{SSR(X_k |X_{-k})}{SST(Y|X_{-k})} =
R^2(Y|X_{-k}, X_k|X_{-k})\)</span></p>
<p>也就是说，实际上是对于 <span class="math inline">\(Y|X_{-k} \sim
X_k|X_{-k}\)</span> 这两组残差做线性回归，得到的决定系数正好是 <span class="math inline">\(X_k\)</span> 的偏决定系数。</p>
<p>实际上偏相关系数 <span class="math inline">\(r_{k|1,2,...,k-1,k+1,...,q} = sign(\hat
\beta_k)\sqrt{R^2_{Yk|1,2,...,k-1,k+1,...,q}}\)</span>
表征的就是这两组残差之间的相关系数，如果有 <span class="math inline">\(0
&lt; r_{3|12} &lt; r_{12}\)</span> 就说明变量 <span class="math inline">\(X_3\)</span> 可以部分解释 <span class="math inline">\(X_1,X_2\)</span> 之间的相关性。</p>
<h2 id="标准回归">标准回归</h2>
<h3 id="motivation">Motivation</h3>
<ul>
<li>如果 <span class="math inline">\(X_1,X_2\)</span>
之间的尺度差距过大会导致 <span class="math inline">\(\beta_1,\beta_2\)</span>
的尺度也有差距，无法直接比较，也可能会影响变量显著性。</li>
<li>会导致 designed matrix 接近不满秩，计算逆矩阵出现问题。</li>
</ul>
<h3 id="methodcorrelation-transformation">Method——Correlation
Transformation</h3>
<p>考虑 <span class="math inline">\(s_Y = \sqrt{\frac{\sum_i (Y_i - \bar
Y)^2}{n-1}}, s_{X_k} = \sqrt{\frac{\sum_i (X_{ik}-\bar
X_k)^2}{n-1}}\)</span>，对变量和响应值分别做标准化：</p>
<p><span class="math display">\[\begin{aligned} \frac{1}{\sqrt{n-1}}
\frac{Y_i - \bar Y}{s_Y}&amp; = \frac{1}{\sqrt{n-1}} \frac{(\beta_0 +
\beta_1 X_{i1} + \beta_2 X_{i2} + \varepsilon_i)-(\beta_0 + \beta_1 \bar
X_1 + \beta_2 \bar X_2 + \bar
\varepsilon)}{s_Y}\\&amp;=\frac{1}{\sqrt{n-1}}\frac{\beta_1(X_{i1} -
\bar X_1) + \beta_2 (X_{i2}-\bar X_2) + (\varepsilon_i - \bar
\varepsilon)}{s_Y}\\&amp;=\frac{\beta_1 s_{X1}}{s_Y} \frac{(X_{i1}-\bar
X_1)}{\sqrt{n-1} s_{X1}} + \frac{\beta_2 s_{X2}}{s_Y} \frac{(X_{i2}-\bar
X_2)}{\sqrt{n-1} s_{X2}} + \frac{\varepsilon_i - \bar
\varepsilon}{\sqrt{n-1}s_Y} \end{aligned}\]</span></p>
<p><span class="math display">\[Y_i^* = 0 + \beta_1^* X_{i1}^* +
\beta_2^* X_{i2}^* + ... +\beta_{p-1}^* X_{i,p-1}^* +
\varepsilon_i\]</span></p>
<p>其中 <span class="math inline">\(\beta_k ^* = \frac{s_{X_k}}{S_Y}
\beta_k\)</span> 是新的回归系数。</p>
<ul>
<li><p>注意这个方法是有一些问题的，比如说破坏了残差的假设，以及强迫过原点。</p></li>
<li><p>标准回归的系数估计和 ANOVA table 都发生了改变，这是因为 SST
变成了 <span class="math inline">\(1\)</span>，ANOVA table
自然会变化。但是偏决定系数都是由偏相关系数直接决定的，所以没有变化。</p>
<p>类似地，如果只对 <span class="math inline">\(X\)</span>
做变换而不改变 <span class="math inline">\(Y\)</span>，会有系数发生改变，但是 ANOVA table
和偏决定系数都不变。</p></li>
</ul>
<h2 id="suppressor-variable">Suppressor Variable</h2>
<p>如果有 <span class="math inline">\(SSR(X_2 |X_1) &gt;
SSR(X_2)\)</span>，也就是 <span class="math inline">\(X_1\)</span>
在模型里的时候会让 <span class="math inline">\(X_2\)</span> 更显著，则称
<span class="math inline">\(X_1\)</span> 是一个 suppressor
variable。原理是 <span class="math inline">\(X_1\)</span>
可以帮助解释一部分 <span class="math inline">\(X_2\)</span>
中的噪音，使得 <span class="math inline">\(X_2\)</span> 更显著。</p>
<p><span class="math inline">\(X_1\)</span>
本身未必是显著的，这也就说明了如果单一变量不显著的话也不能贸然扔掉，它可能会是一个抑制变量。更极端的情况下，假设
<span class="math inline">\(X_1\)</span> 和 <span class="math inline">\(Y\)</span> 完全无关，有 <span class="math inline">\(X_2\)</span> 在模型中不会改变 <span class="math inline">\(X_1\)</span> 的系数估计，但是会导致 <span class="math inline">\(R^2_{Y2|1} \neq R^2_{Y2}\)</span>。</p>
<p>一般来说脑补一下这种类似韦恩图的直观解释就好。</p>
<p><img src="https://s2.loli.net/2023/05/30/4hFWcryX6lbspt5.png" alt="venn.png"></p>
<h1 id="lecture-10">Lecture 10</h1>
<h2 id="multicollinearity">Multicollinearity</h2>
<p>关于多重共线性的一些研究，先考虑一些极端情况，然后观察多重共线性会导致什么后果。</p>
<h3 id="zero-collinearity">Zero Collinearity</h3>
<p>在几个解释变量完全没有共线性的情况称为正交设计，也就是说设计矩阵的各列之间是正交的。这是一个很好的情况，互相之间并不会干扰，有
<span class="math inline">\(X^TX = diag(||X_0||^2 ,
||X_1||^2,...,||X_{p-1}||^2)\)</span>，且有 <span class="math inline">\(b_j = \frac{X_j ^TY}{||X_j||^2}\)</span>，<span class="math inline">\(Var(b_j) =
\frac{\sigma^2}{||X_j||^2}\)</span>。</p>
<p>结果就是无论进多少变量都不会影响单个 <span class="math inline">\(b_j\)</span> 的估计，但是会影响到 <span class="math inline">\(MSE\)</span> 导致 p-value 的变化。与此同时 type I,
II, III ANOVA table 的结果是一样的，这是因为 extra sum of squares
就是单个变量能解释的方差。</p>
<p><img src="https://s2.loli.net/2023/05/31/g3Abuh529lnpV7r.png" alt="venn-for-orthogonal-design.png"></p>
<h3 id="linearly-dependent">Linearly Dependent</h3>
<p>一个比较极端的例子是完全线性相关，比如变量之间有 <span class="math inline">\(c_1 X_1 + ... +c_{p-1}X_{p-1}=c\)</span>
这样的关系，会导致设计阵不满秩无法求逆。从数学上来说只要去掉其中一个变量即可，但是在统计上未必合适的。</p>
<h3 id="multicollinearity-1">Multicollinearity</h3>
<p>正常一些的情况就是普通的多重共线性，从回归结果来看多重共线性的一大特征就是模型整体显著，但是没有一个变量是显著的。回归结果的显著性是代表每个变量最后一个进入模型时的显著性，也就是说明每个变量几乎都是可以被前面进入模型的变量表示出来的。多重共线性有以下危害：</p>
<ul>
<li><span class="math inline">\(X_1,X_2\)</span>
之间较大的多重共线性会导致对于单个变量的 <span class="math inline">\(Var(b_i)\)</span>
增大，但是仍然是无偏估计。这也就说明了，出现多重共线性时 <span class="math inline">\(b_i\)</span> 的方差很大，会导致 <span class="math inline">\(b_i\)</span>
的估计值并不准确。举个例子来说，有的时候理论上 <span class="math inline">\(X_i\)</span> 和 <span class="math inline">\(Y\)</span>
之间是正相关，但是得到的系数估计是负的，就有可能是因为 <span class="math inline">\(Var(b_i)\)</span>
过大导致一组数据得到的结果距离“真实值”有很大的偏差，甚至从正相关变成了负相关。</li>
<li>Type I SS 和 Type II SS
的结果可能是不同的，因为变量之间对方差解释有竞争，也可能有 suppressor
variable，进入模型的顺序在此时变得重要了起来，二者不同的结果可能导致判断上的问题。</li>
<li>两部分解释变量解释了同一部分的方差，导致模型解释能力下降。模型整体显著但每一个变量都不显著，很有可能是过拟合了。</li>
<li>从数学上来说 <span class="math inline">\(X^TX\)</span>
接近退化，求逆时导致数值误差增大。</li>
</ul>
<p><img src="https://s2.loli.net/2023/05/31/iNHqIePg5rVKTQM.png" alt="multicollinearity.png"></p>
<p>有一些弥补的方案，但是要视建立模型的目的而定：</p>
<ul>
<li><p>如果单纯是为了预测，其实增大模型的 sample size
是可以解决问题的</p></li>
<li><p>如果是为了解释性，需要做很多其他的努力，比如移除一些变量，对变量做变换，PCA
方法等等。</p>
<p>仍然存在很多问题，比如移除变量时万一移除了某个重要的类别型变量，可能会导致
Simpson's Paradox 出现，移除变量也会导致系数估计的方差减小，可能减小 MSE
但是会导致 bias 增大，但如果移除了一个重要的解释变量会导致它进入 error
term，进而导致 <span class="math inline">\(\sigma^2\)</span>
的估计增大，需要 trade-off；</p>
<p>做变换不一定能成功降低共线性还会造成解释上的困难，PCA
的解释性更差，等等。</p></li>
</ul>
<p>Multicollinearity 可能有以下来源：</p>
<ul>
<li>抽样时 <span class="math inline">\(X\)</span> 的区域太小</li>
<li>理论上两个变量就是相关的却一起放进了模型，比如家庭收入和房屋面积</li>
<li>使用多项式回归</li>
<li><span class="math inline">\(p&gt;n\)</span></li>
<li>某些变量彼此是受同一隐含的因素影响的，比如一些 time series data</li>
</ul>
<h2 id="polynomial-regression">Polynomial Regression</h2>
<p>多项式回归可能会导致很强的共线性，比如一个只取 <span class="math inline">\(0\)</span> 和 <span class="math inline">\(1\)</span> 的类别型变量取 <span class="math inline">\(x\)</span> 和 <span class="math inline">\(x^2\)</span>进入模型就完全共线。</p>
<p>有一个弥补的方案就是使用 centered
data，为每一个变量减去一个均值，导致数值有正有负，再做非负的平方项就得到共线性不那么强的两个解释变量。实际上再进一步对数据做尺度上的标准化也可以，但是对系数估计没有任何影响。</p>
<p>对数据做中心化不会导致高阶项的系数改变，但有可能会导致低阶项的系数和
extra sum of squares
变化。另外如果显著性不随之变化的话也有可能是出现了正交设计的情况，需要按照结果分析。</p>
<h2 id="交互项">交互项</h2>
<p>模型中存在交互项的本质就是 <span class="math inline">\(X_i\)</span>
对于 <span class="math inline">\(Y\)</span> 的效应和回归系数估计都会受到
<span class="math inline">\(X_j\)</span> 的影响。</p>
<ul>
<li><p>如果 <span class="math inline">\(X_2\)</span> 是连续型变量而
<span class="math inline">\(X_1\)</span>
是类别型变量，回归模型中包含二者的交互项，例如：</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2
+ \beta_3 X_1X_2+\varepsilon\]</span></p>
<p>这就说明对于 group 1，也就是 <span class="math inline">\(X_1 =
0\)</span> 时模型是 <span class="math inline">\(Y = \beta_0+ \beta_2 X_2
+ \varepsilon\)</span>，对于 group 2 也就是 <span class="math inline">\(X_1 = 1\)</span> 时模型是 <span class="math inline">\(Y = (\beta_0 + \beta_1 )+(\beta_2 + \beta_3)X_2 +
\varepsilon\)</span>。希望检验的问题是 <span class="math inline">\(\beta_1,\beta_3\)</span> 是否为 <span class="math inline">\(0\)</span>
来查看两组回归线的斜率、截距之间是否存在差异。</p></li>
<li><p>如果二者都是连续型变量也是类似的情况，相比之下类别型变量和连续型变量的交互效应有显著的分组意义。</p></li>
</ul>
<h1 id="lecture-11">Lecture 11</h1>
<h2 id="模型选择方法">模型选择方法</h2>
<h3 id="一些没那么数学的">一些没那么数学的</h3>
<ul>
<li>喜闻乐见的穷举，可惜只能处理不超过 <span class="math inline">\(n=40\)</span> 个变量的情况</li>
<li>stepwise greedy method，不喜闻乐见的要写代码，理解 idea
就好（心虚</li>
</ul>
<h3 id="一些准则">一些准则</h3>
<p>假设可供选择的 explanatory variable 有 <span class="math inline">\(P-1\)</span> 个，从中选择 <span class="math inline">\(p-1\)</span> 个并进行判断。</p>
<ul>
<li><p>观察 <span class="math inline">\(R^2\)</span> 和 adjusted <span class="math inline">\(R^2\)</span>，取后者较大的模型</p></li>
<li><p>观察 mallow's <span class="math inline">\(C_p\)</span>，<span class="math inline">\(\Gamma_p = \frac{E(SSE(p))}{\sigma^2} - (n-2p)
\geq p\)</span>，实际上在操作中只能取 <span class="math inline">\(\hat
\Gamma_p = \frac{SSE(p)}{MSE(P)}-(n-2p)\)</span>。</p>
<ul>
<li>如果 <span class="math inline">\(\hat \Gamma_p \gg p\)</span>
说明存在显著的误差，可能遗漏了重要的变量没有进入模型</li>
<li>如果 <span class="math inline">\(\hat \Gamma_p \ll p\)</span>
说明过拟合了，导致 <span class="math inline">\(SSE(p) \ll
MSE(P)\)</span></li>
<li>如果 <span class="math inline">\(\hat \Gamma_p \approx p\)</span>
说明是 unbiased，取接近于 <span class="math inline">\(p\)</span> 的
mallow's <span class="math inline">\(C_p\)</span>
中最小的一个对应的模型。</li>
</ul>
<p>实际上理论的形式对于 <span class="math inline">\(P\)</span> 有 <span class="math inline">\(\Gamma_P =P\)</span>。</p></li>
<li><p><span class="math inline">\(AIC = n \log (\frac{SSE(p)}{n}) +
2p\)</span>，<span class="math inline">\(BIC = n \log (\frac{SSE(p)}{n})
+ (\log n)p\)</span>，二者都是最小值对应的模型最合适。</p>
<p>注意 BIC 实际上相比 AIC
加了一个更大的惩罚在模型的变量数上，更注重解释性；一般来说有 <span class="math inline">\(BIC&gt;AIC\)</span>。</p></li>
<li><p>Predicted Residual Error Sum of Squares：<span class="math inline">\(PRESS(p) = \sum_{i=1}^n (Y_i - \hat
Y_{i(-i)})^2\)</span>，实际上有 <span class="math inline">\(Y_i - \hat
Y_{i(-i)} = \frac{e_i}{1-h_{ii}}\)</span>。</p>
<p>取使得 <span class="math inline">\(PRESS(p)\)</span>
最小的模型。用来观察过拟合与否。</p></li>
<li><p>Prediction <span class="math inline">\(R_p^2\)</span>：<span class="math inline">\(R_p^2 =
1-\frac{PRESS}{SST}\)</span>，如果模型里噪音过大，则有 <span class="math inline">\(PRESS &gt;SST\)</span>，此时 <span class="math inline">\(R_p^2&lt;0\)</span> 也是可以取负值的。如果有 <span class="math inline">\(R_p^2 \ll R^2\)</span>
则也可能是过拟合了，即使有些独立变量是显著的。</p></li>
</ul>
<p>我们选择模型一般会考虑 adjusted <span class="math inline">\(R^2\)</span>，AIC 或者 mallow's <span class="math inline">\(C_p\)</span>。</p>
<h2 id="模型诊断">模型诊断</h2>
<h3 id="partial-regression-plots">Partial Regression Plots</h3>
<p>每个 <span class="math inline">\(X_i\)</span> 都可以做出一张 partial
regression plot，也即所谓的 AV-plot，实际上就是对 <span class="math inline">\(Y|X_{-i} \sim X_i|X_{-i}\)</span>
这两部分残差互相做回归得到的图，展示了完整模型中 <span class="math inline">\(Y \sim X_i\)</span>
之间的边际关系。也可以用来检测非线性关系、异方差问题和 outliers。</p>
<h3 id="studentized-residuals">Studentized Residuals</h3>
<p>补充在 Lecture 6 里了。</p>
<h3 id="assessing-outliers">Assessing Outliers</h3>
<p>有以下指标可以考虑：</p>
<ul>
<li><p>Difference caused to fitted values：<span class="math inline">\((DFFIT)_i = \hat Y_i - \hat Y_{i(-i)} =
\frac{h_{ii}}{1-h_{ii}} e_i\)</span></p></li>
<li><p>Studentized DFFIT：<span class="math inline">\((DFFITS)_i =
\frac{\hat Y_i - \hat Y_{i(-i)}}{\sqrt{MSE_{-i} h_{ii}}} = t_i
\sqrt{\frac{h_{ii}}{1-h_{ii}}}\)</span>。</p>
<p>对于不太大的数据量，如果 <span class="math inline">\(|DFFITS|&gt;1\)</span>
则认为是强影响力点，大数据量时认为 <span class="math inline">\(|DFFITS|&gt;2\frac{\sqrt p}{\sqrt n}\)</span>
是强影响力点。</p></li>
<li><p>Cook's Distance：<span class="math inline">\(D_i = \frac{e_i^2}{p
\cdot MSE} \frac{h_{ii}}{(1-h_{ii})^2}\)</span>，在 R
中认为某个点有强影响力的 threshold 是 <span class="math inline">\(0.5\)</span>，事实上如果一个点的 Cook's distance
分布距离其他点较远，就可以认为是强影响力点了。</p></li>
<li><p>Difference in Beta Estimates：<span class="math inline">\((DFBETAS)_{k(-i)} = \frac{b_k -
b_{k(-i)}}{\sqrt{MSE_{(-i)} c_{kk}}}\)</span>，其中 <span class="math inline">\(c_{kk}\)</span> 是 <span class="math inline">\((X^TX)^{-1}\)</span> 的第 <span class="math inline">\(k \times k\)</span> 个分量。</p>
<p>对于大的数据量，如果 <span class="math inline">\(|DFFITS|&gt;1\)</span>
则认为是对于回归系数估计值的强影响力点，不太大的数据量时认为 <span class="math inline">\(|DFFITS|&gt;\frac{2}{\sqrt n}\)</span>
是对于回归系数估计值的强影响力点。</p></li>
</ul>
<h3 id="multicollinearity-diagnose">Multicollinearity Diagnose</h3>
<p>有以下两个指标：</p>
<ul>
<li>Variance Inflation
Factor：多重共线性经常导致方差膨胀，这是一个表征的指标，<span class="math inline">\((VIF)_k = (1- R_k^2)^{-1}\)</span>，其中 <span class="math inline">\(R_k^2\)</span> 指的是将 <span class="math inline">\(X_k\)</span> 相对于其他 <span class="math inline">\(p-2\)</span> 个 explanatory variable
做回归得到的决定系数。如果 <span class="math inline">\((VIF)_k \gg
1\)</span> 则认为第 <span class="math inline">\(k\)</span> 个变量 <span class="math inline">\(X_k\)</span> 是会发生多重共线性的变量。</li>
<li>Tolerance：<span class="math inline">\(TOL =
1/VIF\)</span>，判断准则类似上述。</li>
</ul>
<h1 id="lecture-12">Lecture 12</h1>
<p>本节探讨 remedies for multiple linear
regression，主要是异方差情况和多重共线性。</p>
<h2 id="equal-variance-remedy">Equal Variance Remedy</h2>
<p>这一部分主要处理模型发生异方差问题的情况。</p>
<p>也就是说，实际上有 <span class="math inline">\(\varepsilon_1,
\varepsilon_2, ..., \varepsilon_n\)</span> 的方差不全为 <span class="math inline">\(\sigma^2\)</span>，记方差为 <span class="math inline">\(\sigma_1 ^2,\sigma_2 ^2 , ..., \sigma_n
^2\)</span>。此时的 likelihood function 是：</p>
<p><span class="math display">\[L(\beta_1,\beta_2) = \Pi_{i=1} ^n
f_i(\beta_1, \beta_2 |X_i,Y_i) = \Pi_{i=1}^n (\frac{1}{\sqrt{2\pi}
\sigma_i} exp(-\frac 1 2 (\frac{Y_i - \beta_0 -\beta_1
X_i}{\sigma_i})^2)) \]</span></p>
<p>可以看到 ordinary least square 条件得到的 <span class="math inline">\(b_0 = \hat \beta_0,b_1 = \hat \beta_1\)</span>
不再满足 MLE 的条件。但如果是在不知异方差的情况下仍然使用 OLS 或者 MLE
条件得到的参数估计，仍然是可以满足无偏性的，但不满足最小方差性质。</p>
<h3 id="weighted-regression">Weighted Regression</h3>
<p>简单来说，通过选取 <span class="math inline">\(\{ w_i =
\frac{1}{\sigma_i ^2} \}_{i=1} ^n\)</span> 作为权重，考虑 <span class="math inline">\(\Sigma_{i=1} ^n w_i e_i^2 = \Sigma_{i=1} ^n
(\frac{Y_i - \beta_0 - \beta_1 X_{i,1} - ... - \beta_{p-1}
X_{i,p-1}}{\sigma_i})^2\)</span> 的最小性问题。</p>
<ul>
<li><p>最简单的情况，<span class="math inline">\(\sigma_1,...,\sigma_n\)</span> 均已知，则有 <span class="math inline">\(w_i = \frac{1}{\sigma_i ^2}\)</span>，</p>
<p>取 <span class="math inline">\(W = \begin{bmatrix} \frac{1}{\sigma_1
^2} &amp; &amp; &amp; \\ &amp;...&amp; &amp; \\ &amp; &amp; &amp;
\frac{1}{\sigma_n^2} \end{bmatrix}\)</span> 使得回归问题变为 <span class="math inline">\(W^{\frac 1 2} Y = W^{\frac 1 2} X \beta + W^{\frac
1 2} \varepsilon\)</span>，记 <span class="math inline">\(Y^* = W^{\frac
1 2} Y, X^* = W^{\frac 1 2} X, \varepsilon^* = W^{\frac 1 2}
\varepsilon\)</span>，由于 <span class="math inline">\(Var(\varepsilon^*) = I_{n\times n}\)</span>
满足同方差条件，因此新的回归问题是符合条件的。</p>
<p>注意新的回归问题 <span class="math inline">\(Y^* = X^* \beta +
\varepsilon^*\)</span> 事实上没有改变系数 <span class="math inline">\(\beta\)</span>，但系数估计 <span class="math inline">\(b_w = (X^TWX)^{-1} (X^TWY)\)</span>
是改变了的，这是正常现象，因为对这一问题做 remedy
的主要原因就是假设不满足，导致按照 OLS 做出的系数估计不准确，因此
weighted regression 做出的修正也是相对于原系数 <span class="math inline">\(\beta\)</span> 的。</p>
<p><span class="math inline">\(b_w\)</span> 仍然是无偏估计，也保证 <span class="math inline">\(Var(b_w) = (X^TWX)^{-1}\)</span>
是最小方差。</p></li>
<li><p>稍微复杂一点的情况，虽然 <span class="math inline">\(\sigma_i^2\)</span> 未知但 <span class="math inline">\(\sigma^2_i / \sigma_j ^2\)</span> 均已知，取 <span class="math inline">\(w_i = \frac{\sigma_1 ^2}{\sigma_i^2 }\)</span>
即可。于是有：</p>
<p>取 <span class="math inline">\(W = \sigma_1 ^2 \begin{bmatrix}
\frac{1}{\sigma_1 ^2} &amp; &amp; &amp; \\ &amp;...&amp; &amp; \\ &amp;
&amp; &amp; \frac{1}{\sigma_n^2} \end{bmatrix}\)</span> 使得回归问题变为
<span class="math inline">\(W^{\frac 1 2} Y = W^{\frac 1 2} X \beta +
W^{\frac 1 2} \varepsilon\)</span>，记 <span class="math inline">\(Y^* =
W^{\frac 1 2} Y, X^* = W^{\frac 1 2} X, \varepsilon^* = W^{\frac 1 2}
\varepsilon\)</span>，由于 <span class="math inline">\(Var(\varepsilon^*) = \sigma_1 ^2 I_{n\times
n}\)</span> 满足同方差条件，因此新的回归问题是符合条件的。</p>
<p>新的回归系数估计是 <span class="math inline">\(b_w =
(X^TWX)^{-1}(X^TWY)\)</span>，<span class="math inline">\(Var(b_w) =
\sigma_1^2(X^TWX)^{-1}\)</span>，由此还可以做出对 <span class="math inline">\(\sigma_1\)</span> 的参数估计，<span class="math inline">\(\hat \sigma_1 ^2 = MSE_{wls} = \frac{\Sigma(Y^*_i
- \hat Y^*_i)^2}{n-p}= \frac{\Sigma w_i(Y_i - \hat Y_i)^2}{n-p} =
\frac{\Sigma w_i e_i ^2}{n-p}\)</span>，其中 <span class="math inline">\(w_i =
\frac{\sigma_1^2}{\sigma_i^2}\)</span>。</p></li>
<li><p>一般情况下 <span class="math inline">\(\{ \sigma_i \}\)</span>
是完全未知的，我们是在模型诊断中发现异方差的现象，因此不可能直接通过方差值推权重系数。这个时候一般有两种选择：</p>
<ul>
<li><p>重复试验取 <span class="math inline">\(Y_i\)</span> 的方差估计
<span class="math inline">\(s_i^2\)</span>，于是权重系数为 <span class="math inline">\(w_i = \frac{1}{s_i ^2}\)</span>。</p></li>
<li><p>先对 <span class="math inline">\(Y\sim X\)</span> 进行 OLS
回归，取出此时的 residual <span class="math inline">\(\{e_i \}\)</span>
作为 <span class="math inline">\(\{ \sigma _i \}\)</span> 的估计，取
<span class="math inline">\(w_i = \frac{1}{e_i ^2}\)</span>
作为权重即可。</p>
<p>效果不明显时多迭代几次。</p></li>
</ul></li>
</ul>
<p>在观察 weighted least square 和 ordinary least square
模型差别时，注意：</p>
<ul>
<li><span class="math inline">\(R^2\)</span> 以及 adjusted <span class="math inline">\(R^2\)</span> 的数值差别没有很强的意义，WLS
情况下原始数据 <span class="math inline">\(\{ Y_i \}\)</span>
已经发生了变化，实际上 SST 也已经变了，没有什么比较的意义。</li>
<li>需要关注的点是 residual standard error，越接近 <span class="math inline">\(1\)</span> 越说明异方差的调整是成功的。</li>
<li>有时会观察到 WLS 情况下 <span class="math inline">\(\hat
\sigma^2\)</span> 在减小，似乎数据的分散程度在减小，这是因为 MSE
在减小。但是 WLS 和 OLS 情况下的 MSE 和 MST 都没有比较的意义，因此 <span class="math inline">\(\hat \sigma\)</span>
的变化也没有研究的价值。唯一确定的是它会接近于 <span class="math inline">\(1\)</span>，这一点可以证明异方差的调整效果是成功的。</li>
</ul>
<h2 id="multicollinearity-remedy">Multicollinearity Remedy</h2>
<p>如果存在多重共线性，主要发生的问题是 <span class="math inline">\(X^TX\)</span>
求逆是一个病态的数值问题，误差很大。实际上极端来说如果存在完全共线性，<span class="math inline">\(X^TX\)</span> 会退化为不满秩的情况。</p>
<p>可以用 ridge regression 对多重共线性进行弥补。</p>
<h3 id="ridge-regression">Ridge Regression</h3>
<p>主要的 idea 是如果 <span class="math inline">\((X^TX)\)</span>
接近于不满秩，则在参数估计中将其改变为 <span class="math inline">\((X^TX
+\lambda I)\)</span>，<span class="math inline">\(\lambda\)</span>
是待取的参数。对于矩阵的对角元进行改变如同突起的山脊，因此得名岭回归。</p>
<p>Ridge regression 的本质是对优化问题进行了修改。OLS
中的优化问题是求使得 <span class="math inline">\((Y-X\beta)^T
(Y-X\beta)\)</span> 最小的 <span class="math inline">\(\beta\)</span>，ridge regression 中将 <span class="math inline">\(|| \beta ||_2 ^2 = \Sigma_{i=0} ^{p-1}
\beta_i^2\)</span> 加入了优化，对 <span class="math inline">\(\beta\)</span> 的长度（事实上应该称之为 2-
范数）做惩罚。因此，实际上是求使得 <span class="math inline">\((Y-X
\beta )^T (Y-X \beta) + \lambda \Sigma_{i=0} ^{p-1}\beta_i ^2\)</span>
最小的 <span class="math inline">\(\hat \beta = (X^TX + \lambda I)^{-1}
X^TY\)</span>，这使得参数估计 <span class="math inline">\(b = \hat
\beta\)</span> 呈现出比 OLS 下长度和方差都更小的特征。</p>
<p>在实际应用中，需要通过确定最佳的 <span class="math inline">\(\lambda\)</span> 从而得到合适的参数估计，一般是对
<span class="math inline">\(\lambda\)</span> 取一个 sequence
进行尝试。如果发现某个 explanatory variable 的系数在 <span class="math inline">\(\lambda\)</span> 增大时很快下降到 <span class="math inline">\(0\)</span>，实际上它很有可能是不需要进入模型的。</p>
<p>应用岭回归来弥补模型的多重共线性的时候，既是为了消除共线性，也是在牺牲一些
<span class="math inline">\(\hat \beta\)</span>
的无偏性来换取更小的方差。</p>
<h3 id="lasso-elastic-net">LASSO &amp; Elastic Net</h3>
<p>LASSO 中把惩罚的 <span class="math inline">\(\beta\)</span>
长度替换为了 <span class="math inline">\(\beta\)</span> 的 1-
范数，弹性网络则是对 LASSO 和 ridge regression 进行了结合。</p>
<p>本质上都是 Bayesian modes。</p>
<h2 id="influencial-cases-remedy">Influencial Cases Remedy</h2>
<p>更改一些更 robust 的优化模型，例如 least absolute deviation 和 least
median of squares，缺点是算起来会比较困难。</p>
<p>或者考虑非参数模型。</p>
<h2 id="nonlinearity-remedy">Nonlinearity Remedy</h2>
<p>考虑局部多项式回归/局部回归，总之是对数据进行分块，所谓的
lowess。</p>
<h1 id="lecture-13">Lecture 13</h1>
<h2 id="one-factor-anova">One Factor ANOVA</h2>
<p>（从生统笔记复制来的）</p>
<p>首先给出一个希望做检验的场景：<span class="math inline">\(n_T\)</span> 个实验对象被分成 <span class="math inline">\(r\)</span> 组，每组有 <span class="math inline">\(n_i\)</span> 个实验对象，有 <span class="math inline">\(n_T = \Sigma_{i=1} ^r n_i\)</span>。由此我们得到
<span class="math inline">\(n_T\)</span> 个数据 <span class="math inline">\(Y_{ij}\)</span>，<span class="math inline">\(i\)</span> 表示组别，<span class="math inline">\(1\leq i \leq r\)</span>，<span class="math inline">\(j\)</span> 表示在某一组内的编号，<span class="math inline">\(1 \leq j \leq n_i\)</span>。</p>
<h3 id="cell-means-model">Cell means model</h3>
<ul>
<li><p>模型假设是 <span class="math inline">\(Y_{ij} = \mu_i +
\varepsilon_{ij}\)</span>。</p>
<p>其中，<span class="math inline">\(\mu_i\)</span> 是第 <span class="math inline">\(i\)</span> 组的理论均值，<span class="math inline">\(\varepsilon _{ij}\)</span> i.i.d. <span class="math inline">\(\sim
N(0,\sigma^2)\)</span>。注意到在这一模型假设中有 <span class="math inline">\(r+1\)</span> 个参数，分别是 <span class="math inline">\(\mu_1,\mu_2,...,\mu_r,\sigma^2\)</span>，我们需要用得到的数据来对这些未知参数进行估计。考虑一些统计量作为参数的估计量：</p>
<p><span class="math display">\[\bar{Y}_{i.} = \frac{1}{n_i} \Sigma_{j=1
}^{n_i} Y_{ij}  = \hat \mu _i\]</span></p>
<p><span class="math display">\[\bar{Y}_{..} = \frac{1}{n_T}
\Sigma_{i=1}^r \Sigma_{j=1} ^{n_i} Y_{ij} = \frac{1}{n_T} \Sigma_{i=1}^r
n_i \bar{Y}_{i.}\]</span></p>
<p><span class="math display">\[s_i ^2 = \Sigma_{j=1} ^{n_i} (Y_{ij} -
\bar Y_{i.})^2 / (n_i -1) \]</span></p>
<p><span class="math display">\[s^2 =\Sigma_{i=1} ^r \Sigma_{j=1} ^{n_i}
(Y_{ij} - \bar Y_{i.})^2  =\frac{1}{n_T- r} \Sigma_{i=1}^r (n_i -1) s_i
^2 = \hat \sigma^2\]</span></p></li>
<li><p>在这一模型中，我们关注的假设检验是 <span class="math inline">\(i\)</span> 组实验之间是否存在差异，假设检验表示为
<span class="math inline">\(H_0 : \mu_1= \mu_2 = ... = \mu_r =
\mu\)</span>，对应的备择假设即为 <span class="math inline">\(\{ \mu_i
\}_{i=1} ^r\)</span> 中存在不同的项。检验最经典的方法即为
ANOVA，analysis of variance。核心是以下的分解：</p>
<p><span class="math display">\[\begin{aligned} SSTO = \Sigma_i
\Sigma_j(Y_{ij} - \bar Y_{..})^2 &amp;= \Sigma_i \Sigma_j (Y_{ij} - \bar
Y_{i.} +\bar Y_{i.} - \bar Y_{..})^2 \\&amp; = \Sigma_i n_i (\bar Y_{i.}
- \bar Y_{..})^2 + \Sigma_i \Sigma_j (Y_{ij} - \bar Y_{i.})^2 \\
&amp;=SSTR + SSE \end{aligned}\]</span></p>
<p>可以观察到，<span class="math inline">\(SSTR\)</span>
是组间差距，体现了不同组别之间的差别，<span class="math inline">\(SSE\)</span>
是组内差距，体现了同一组内各数据的偏差。注意 <span class="math inline">\(SSTR\)</span> 的自由度是 <span class="math inline">\(r-1\)</span>，<span class="math inline">\(SSE\)</span> 的自由度是 <span class="math inline">\(n_T - r\)</span>，<span class="math inline">\(SSTO\)</span> 的自由度是 <span class="math inline">\(n_T - 1\)</span>。</p>
<p>两个统计量的期望是 <span class="math inline">\(\mathbb E(MSE) =
\sigma^2\)</span>，<span class="math inline">\(\mathbb E(MSTR) =
\sigma^2 +\frac{\Sigma_i n_i (\mu _i -\mu_.)^2}{r-1}\)</span>，其中
<span class="math inline">\(\mu_. = \frac{\Sigma_i n_i
\mu_i}{n_T}\)</span>。</p>
<p>在 <span class="math inline">\(H_0\)</span> 成立时，<span class="math inline">\(\frac{SSE}{\sigma^2} \sim \chi^2 _{n_T -
r}\)</span>，<span class="math inline">\(\frac{SSTR}{\sigma^2} \sim
\chi^2_{r-1}\)</span>。因此 <span class="math inline">\(F=\frac{MSTR}{MSE} \sim F_{r-1,n_T -r}\)</span>
作为最终的检验统计量。</p>
<p>当 <span class="math inline">\(F^* &gt; F(1-\alpha , r-1 , n_T
-r)\)</span> 时拒绝原假设，否则接受；<span class="math inline">\(Power =
P(F^* &gt; F(1-\alpha , r-1,n_T -r)| \delta)\)</span>，其中 <span class="math inline">\(\delta\)</span> 是一个非中心偏移量，<span class="math inline">\(\delta = \frac{1}{\sigma} \sqrt{\frac 1 r \Sigma_i
n_i (\mu_i - \mu_.)^2}\)</span>。</p></li>
<li><p>也可以作为一个线性回归的问题来看待，design matrix 是 $ X =</p>
<span class="math display">\[\begin{bmatrix} 1 &amp; 0  &amp; 0 &amp;
... &amp; 0 \\ 0 &amp; 1  &amp; 0 &amp; ... &amp; 0 \\ ...
&amp;...&amp;...&amp;...&amp;... \\ 0 &amp; 0 &amp; 0 &amp; ... &amp; 1
\end{bmatrix}\]</span>
<p>$，系数向量是 <span class="math inline">\(\mu = \begin{bmatrix} \mu_1
\\ \mu_2 \\ ... \\ \mu_r \end{bmatrix}\)</span>，因此整体的回归方程是 $
Y = X + $，注意这个回归问题是<strong>强迫过原点</strong>的。</p></li>
</ul>
<h3 id="factor-effects-model">Factor Effects Model</h3>
<ul>
<li><p>Factor Effects Model 是 Cell Means Model
的一个重新参数化的结果。模型假设是 <span class="math inline">\(Y_{ij} =
\mu + \tau_i + \varepsilon_{ij}\)</span>。</p>
<p>其中，<span class="math inline">\(\mu_i\)</span>
是整体的理论均值，<span class="math inline">\(\varepsilon _{ij} i.i.d.
\sim N(0,\sigma^2)\)</span>。它的参数比 cell mean model 多一个，分别是
<span class="math inline">\(\mu , \tau_1 , ..., \tau_r ,
\sigma^2\)</span>，但是自由度是相同的，因为 <span class="math inline">\(\{ \tau _i \}_{i=1}^r\)</span> 存在一个约束 <span class="math inline">\(\Sigma_{i=1}^r \tau_i =
0\)</span>，如果没有这个约束会导致存在多组解。考虑一些统计量作为参数的估计量：</p>
<p><span class="math display">\[\bar{Y}_{i.} = \frac{1}{n_i} \Sigma_{j=1
}^{n_i} Y_{ij}  = \hat \tau _i + \hat \mu\]</span></p>
<p><span class="math display">\[\bar{Y}_{..} = \frac{1}{n_T}
\Sigma_{i=1}^r \Sigma_{j=1} ^{n_i} Y_{ij} = \frac{1}{n_T} \Sigma_{i=1}^r
n_i \bar{Y}_{i.} = \hat{\mu}\]</span></p>
<p><span class="math display">\[s_i ^2 = \Sigma(Y_{ij} - \bar Y_{i.})^2
/ (n_i -1) \]</span></p>
<p><span class="math display">\[s^2 = \frac{1}{n_T- r} \Sigma_{i=1}^r
(n_i -1) s_i ^2 = \hat \sigma^2\]</span></p></li>
<li><p>在这一模型中，我们关注的假设检验仍然是 <span class="math inline">\(i\)</span> 组实验之间是否存在差异，假设检验表示为
<span class="math inline">\(H_0 : \tau_1= \tau_2 = ... = \tau_r =
0\)</span>，对应的备择假设即为 <span class="math inline">\(\{ \mu_i
\}_{i=1} ^r\)</span> 中存在不同的项。factor effects model
在参数的含义上比 cell mean model 更清晰。</p></li>
<li><p>可以作为一个线性回归的问题来看待，design matrix 是 $ X =</p>
<span class="math display">\[\begin{bmatrix} 1 &amp; 1  &amp; 0 &amp;
... &amp; 0 \\ 1 &amp; 0  &amp; 1 &amp; ... &amp; 0 \\ ...
&amp;...&amp;...&amp;...&amp;... \\ 1 &amp; -1 &amp; -1 &amp; ... &amp;
-1 \end{bmatrix}\]</span>
<p>$，系数向量是 <span class="math inline">\(\mu = \begin{bmatrix} \mu
\\ \tau_1 \\ \tau_2 \\ ... \\ \tau_{r-1}
\end{bmatrix}\)</span>，因此整体的回归方程是 $ Y = X +
$，注意这个回归问题的截距就是 <span class="math inline">\(\mu\)</span>，不强迫过原点，相比 cell mean model
算是做了一点点优化。</p></li>
</ul>
<h3 id="example">Example</h3>
<ul>
<li><p>在做回归之前要注明哪些变量是 factor：</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> data<span class="operator">$</span>design <span class="operator">=</span> factor<span class="punctuation">(</span>data<span class="operator">$</span>design<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> fit <span class="operator">=</span> lm<span class="punctuation">(</span>cases <span class="operator">~</span> design<span class="punctuation">,</span> data <span class="operator">=</span> data<span class="punctuation">)</span></span><br><span class="line"><span class="operator">&gt;</span> summary<span class="punctuation">(</span>fit<span class="punctuation">)</span></span><br></pre></td></tr></table></figure></li>
<li><p>方便查看 <span class="math inline">\(\hat \mu_i\)</span>
的命令是过原点回归，但查看 MSR 的方式是不过原点回归。</p></li>
<li><p><span class="math inline">\(Std.Error_i ^2 = Var(\hat \mu_i) =
Var(\frac{\Sigma_{j=1}^{n_i} Y_{ij}}{n_i}) = \frac{\hat \sigma^2}{n_i}=
\frac{s^2}{n_i}\)</span></p>
<p><span class="math inline">\(sd_i ^2 = s_i ^2\)</span>，由此计算出
<span class="math inline">\(s^2\)</span> 后再得到每个 <span class="math inline">\(Std.Error\)</span> 的值是 <span class="math inline">\(\frac{s}{\sqrt n_i}\)</span>。</p></li>
</ul>
<h2 id="inference-on-one-way-anova">Inference on One-Way ANOVA</h2>
<h3 id="confidence-interval-for-mu_i">Confidence Interval for <span class="math inline">\(\mu_i\)</span></h3>
<p>事实上这只是个理论上可做的问题而已，现实中不会对 <span class="math inline">\(\mu_i\)</span> 做推断，我们关注的是 <span class="math inline">\(\mu_i\)</span> 之间的差异。</p>
<p>由于 <span class="math inline">\(\bar Y_{i.} \sim N(\mu_i , \sigma^2
/ n_i)\)</span>，因此 <span class="math inline">\(\mu_i\)</span> 的
pooled confidence interval 是 <span class="math inline">\((\bar Y_{i.} -
t_c \frac{s}{\sqrt n_i} , \bar Y_{i.} + t_c \frac{s}{\sqrt
n_i})\)</span>，其中 <span class="math inline">\(t_c =
t(1-\frac{\alpha}{2}, n_T -r)\)</span>。注意其中的 <span class="math inline">\(s^2\)</span> 在上面已经有定义，实际上就是
SSE。</p>
<p>当然也可以认为是 <span class="math inline">\((\bar Y_{i.} - t_c s_i ,
\bar Y_{i.} + t_c s_i)\)</span>，<span class="math inline">\(s_i\)</span> 是每个 <span class="math inline">\(\mu_i\)</span> 对应的 <span class="math inline">\(sd_i\)</span>。但是这样得到的置信区间一般来说较宽，准确性不如
pooled confidence interval，我们不太会采用。</p>
<p>实际上这样做 t-test 的话 family-wise error rate
很大，即使做出显著的效果也很有可能是发生了 Type I Error。</p>
<h3 id="bonferroni-confidence-intervals-for-mu_i">Bonferroni Confidence
Intervals for <span class="math inline">\(\mu_i\)</span></h3>
<p>想要同时估计所有的 <span class="math inline">\(\mu_i\)</span>
的时候可以采用 Bonferroni method，但是也有明显的缺点是一旦 factor level
<span class="math inline">\(r\)</span> 较大，就会导致每个 <span class="math inline">\(\mu_i\)</span> 都不显著，置信区间的 level of
significance 只有 <span class="math inline">\(\alpha /
2r\)</span>，几乎是无效的。</p>
<p>同样是 t-test，但过于保守了。对于较小的 <span class="math inline">\(r\)</span> 可以进行尝试。</p>
<h3 id="test-difference-in-means">Test Difference in Means</h3>
<p>由于 <span class="math inline">\(\bar Y_{i.} - \bar Y_{j.} \sim
N(\mu_i - \mu_k , \frac{\sigma^2}{n_i} + \frac{\sigma
^2}{n_j})\)</span>，<span class="math inline">\(\mu_i - \mu_k\)</span>
的 confidence interval 是 <span class="math inline">\((\bar Y_{i.} -
\bar Y_{j.}-t_c s(\bar Y_{i.} - \bar Y_{k.}), \bar Y_{i.} - \bar
Y_{j.}+t_c s(\bar Y_{i.} - \bar Y_{k.}))\)</span>，其中 <span class="math inline">\(s(\bar Y_i. - \bar Y_k.) = \sqrt{\frac{\hat
\sigma^2}{n_i} + \frac{\hat \sigma^2}{n_j}} = s \sqrt{\frac{1}{n_i} +
\frac{1}{n_j}}\)</span>，<span class="math inline">\(t_c\)</span>
是和检验方法有关的常数。</p>
<p>由于一共有 <span class="math inline">\(r\)</span> 个 mean <span class="math inline">\(\mu_i\)</span>，所以一共要做 <span class="math inline">\(\frac{r(r-1)}{2}\)</span>
次检验来确定两两之间有无差异。</p>
<ul>
<li>Tukey's HSD Method: 使用 q-test，取 <span class="math inline">\(t_c
= \frac{\bar y _{max} - \bar y_{min}}{\sqrt 2 s /\sqrt
n}\)</span>；适用于两两检验。</li>
<li>Scheffe's Method: 使用 F-test，取 <span class="math inline">\(t_c =
\sqrt{(r-1)F(1-\alpha, r-1, n_T
-r)}\)</span>，适用于线性组合的对照（contrast，见下）。实际上也过于保守了，导致
power 比较低。</li>
</ul>
<h2 id="contrast">Contrast</h2>
<h3 id="concept">Concept</h3>
<p>关于对照的具体定义是，取一组均值为 <span class="math inline">\(0\)</span> 的常数作为权重，即为 <span class="math inline">\(\Sigma_{i=1} ^r c_i =0\)</span>，此时研究 <span class="math inline">\(L = \Sigma_{i=1} ^r c_i \mu_i\)</span>
的推断。</p>
<p>注意到 <span class="math inline">\(\hat L = \Sigma c_i \bar Y_i .
\sim N(L, Var(\hat L))\)</span>，其中 <span class="math inline">\(Var(\hat L) = \Sigma c_i ^2 Var(\bar Y_i
.)\)</span>，<span class="math inline">\(\hat Var (\hat L) = MSE \Sigma(
c^2_i / n_i)\)</span>。</p>
<p>test statistic 是 <span class="math inline">\(T= \frac{\hat L -
L_0}{\sqrt{\hat Var(\hat L)}} \sim t(n_T-r)\)</span>。例如在 <span class="math inline">\(H_0 : L =0\)</span> 下有 <span class="math inline">\(T = \frac{\Sigma c_i \bar Y_i .}{\sqrt{MSE \Sigma
c^2_i / n_i}} \sim t(n_T -r)\)</span>，于是 <span class="math inline">\(T^2 = \frac{(\Sigma c_i \bar Y_i.)^2}{MSE \Sigma
c_i^2 /n_i} = \frac{SSC/1}{MSE} \sim F(1,n_T-r)\)</span>，其中定义 <span class="math inline">\(SSC = (\Sigma c_i \bar Y_i.)^2 / \Sigma
(c_i^2/n_i)\)</span>，称为 sum of contrast。</p>
<h3 id="multiple-contrasts">Multiple Contrasts</h3>
<p>可以利用 R 同时检验若干组 contrast，比如同时检验 <span class="math inline">\(\mu_1 = \mu_2, \mu_3 = \mu_2 , \mu_1 =( \mu_1 +
\mu_2+\mu_3 )/ 3\)</span></p>
<p>实际上 linear hypothesis test 和 multiple comparison
的主要差别在于自由度，比如说对于 <span class="math inline">\(\mu_1 =
\mu_2 = \mu_3\)</span> 做检验，前者会将其拆成两个两两检验，自由度是
<span class="math inline">\(2\)</span>，后者会作为一个整体的
contrast，自由度是 <span class="math inline">\(1\)</span>。</p>
<h1 id="lecture-14">Lecture 14</h1>
<p>依旧来自生统概论的笔记。</p>
<h2 id="two-way-anova">Two-Way ANOVA</h2>
<p>首先给出一个希望做检验的场景：<span class="math inline">\(nab\)</span> 个实验对象被分成 <span class="math inline">\(a\times b\)</span> 组，每组有 <span class="math inline">\(n\)</span> 个实验对象。第 <span class="math inline">\(ij\)</span> 组的实验条件是 <span class="math inline">\(A\)</span> 因素的等级为 <span class="math inline">\(i\)</span>，<span class="math inline">\(B\)</span>
因素的等级为 <span class="math inline">\(j\)</span>，其中有 <span class="math inline">\(1 \leq i \leq a, 1\leq j \leq
b\)</span>。由此我们得到 <span class="math inline">\(nab\)</span> 个数据
<span class="math inline">\(Y_{ijk}\)</span>，<span class="math inline">\(i\)</span> 表示以 <span class="math inline">\(A\)</span> 因素分类的组别，<span class="math inline">\(j\)</span> 表示以 <span class="math inline">\(B\)</span> 因素分类的组别，<span class="math inline">\(k\)</span> 表示在某一组内的编号，<span class="math inline">\(1 \leq k \leq n\)</span>。</p>
<p>每一组都是 <span class="math inline">\(n\)</span> 个人，这是一个
balanced design。</p>
<h3 id="cell-mean-model">Cell Mean Model</h3>
<p>模型假设是 <span class="math inline">\(Y_{ijk} = \mu_{ij} +
\varepsilon_{ijk}\)</span>。</p>
<p>其中，<span class="math inline">\(\mu_{ij}\)</span> 是第 <span class="math inline">\({i \times j}\)</span> 水平的均值，<span class="math inline">\(\varepsilon_{ijk}\)</span> i.i.d. <span class="math inline">\(\sim N(0,\sigma^2)\)</span>，模型中实际上有 <span class="math inline">\(ab+1\)</span> 个未知参数需要估计。</p>
<p><span class="math inline">\(\mu_{ij}\)</span> 的估计量是 <span class="math inline">\(\bar Y_{ij.} = \sum_k Y_{ijk} /n\)</span>，对于
<span class="math inline">\(i \times j\)</span> 水平的方差估计是 <span class="math inline">\(s_{ij}^2 = \sum_k (Y_{ijk} - \bar Y_{ij.})^2 /
(n-1)\)</span>。但是想要估计 <span class="math inline">\(\sigma^2\)</span> 时必须要将所有的数值加权 pool
起来做估计，是 <span class="math inline">\(s^2 = \sum_{ij} (n_{ij}-1)
s_{ij} ^2 / \sum_{ij} (n_{ij}-1)\)</span>，注意到如果是 balanced test
的情况实际上就是 <span class="math inline">\(s^2 = \sum_{ij} s^2_{ij} /
ab\)</span> 直接做平均的结果。更倾向于 pooled <span class="math inline">\(s^2\)</span>
是因为自由度更大，数据利用更充分。</p>
<p>直接通过看图来观察两个因子之间是否存在交互效应、单因子是否显著这件事的时候，比较经典的情况就是以下两种：</p>
<p><img src="https://s2.loli.net/2023/06/02/Hb1oPSrA2IJFcmC.png" alt="cell-mean-model.png"></p>
<p>上面第一张图中可以发现两条回归线之间存在斜率的差异，说明 B 因子对于 A
因子的效果存在影响，也就是存在交互效应；在 <span class="math inline">\(b_2\)</span> level 上 A 因子是不显著的，但在 <span class="math inline">\(b_1\)</span> level 上 A 因子显著；同理在 <span class="math inline">\(a_1\)</span> level 上 B 因子不显著，但在 <span class="math inline">\(a_2\)</span> level 上 B
因子显著。实际上在这个情况下交互效应显著，主效应虽然显著但也没有太大意义了，不过想要解释也是可以的，可以认为
A 因子带来的效应至少不是负效应。</p>
<p>第二张图里更有两条回归线交叉，存在斜率的差异，交互效应显著；但主效应此时可能无法解释，尤其是如果两条回归线完全交叉成
<span class="math inline">\(\times\)</span> 形状，A 因子会在不同的 B
因子条件下起到相反的作用。所以一般是认为交互效应显著时主效应显著，但没有解释意义。显著性和解释性之间无关。</p>
<p>在读 R code 的时候直接把所有的 estimation 读作 factor effect model
的系数，再代回就可以理解系数的来源了。这一部分在 factor effects model
里详述。</p>
<h3 id="factor-effects-model-1">Factor Effects Model</h3>
<p>模型假设是 <span class="math inline">\(Y_{ijk} = \mu +\alpha_i +
\beta_j +(\alpha \beta)_{ij} + \varepsilon_{ijk}\)</span>。</p>
<p>其中，<span class="math inline">\(\mu\)</span> 是整体的均值，<span class="math inline">\(\alpha_i\)</span> 代表只和等级为 <span class="math inline">\(i\)</span> 的因素 <span class="math inline">\(A\)</span> 有关的变化，<span class="math inline">\(\beta_j\)</span> 表示只和等级为 <span class="math inline">\(j\)</span> 的因素 <span class="math inline">\(B\)</span> 有关的变化，<span class="math inline">\((\alpha \beta)_{ij}\)</span>
表示和两个因素同时相关的变化，相当于一个交叉项。</p>
<p>这里面有 <span class="math inline">\((a+1)(b+1)\)</span>
个参数，对其也有一定的约束：<span class="math inline">\(\Sigma_i
\alpha_i = \Sigma_j \beta_j = \Sigma_i (\alpha \beta)_{ij} = \Sigma_j
(\alpha \beta)_{ij} =0\)</span>，事实上有 <span class="math inline">\(a+b-1\)</span> 个关于交互效应的约束，有 <span class="math inline">\(2\)</span> 个关于单因子效应的约束，实际上包含
<span class="math inline">\(\sigma^2\)</span> 后仍然是有 <span class="math inline">\(ab+1\)</span>
个参数。做一些其他的参数假设，让参数含义更清晰：</p>
<p><span class="math display">\[\mu_{i.} = \alpha_i
+\mu_{..}\]</span></p>
<p><span class="math display">\[\mu_{.j} = \beta _j +
\mu_{..}\]</span></p>
<p><span class="math display">\[\mu_{ij} = \mu_{..} +\alpha_i + \beta_j
+(\alpha \beta)_{ij}\]</span></p>
<p>如果 <span class="math inline">\((\alpha \beta)_{ij}=0\)</span>
则说明因素 <span class="math inline">\(A,B\)</span>
之间不存在相互作用的关系，这样的模型称为 additive model。</p>
<p>考虑一些统计量作为参数的估计量：</p>
<p><span class="math display">\[\bar{Y}_{ij.} = \frac{1}{n} \Sigma_{k=1
}^{n} Y_{ijk}  = \hat \mu_{ij} = \hat \mu + \hat \alpha _i + \hat
\beta_j + \hat{(\alpha \beta)}_{ij}\]</span></p>
<p><span class="math display">\[\bar{Y}_{i..} = \frac{1}{bn}
\Sigma_{j=1}^b \Sigma_{k=1} ^{n} Y_{ijk} = \hat{\mu} +\hat \alpha_i =
\hat \mu_{i.}\]</span></p>
<p><span class="math display">\[\bar{Y}_{.j.} = \frac{1}{an}
\Sigma_{i=1}^a \Sigma_{k=1} ^{n} Y_{ijk} = \hat{\mu} +\hat \beta_j =
\hat \mu_{.j}\]</span></p>
<p><span class="math display">\[\bar{Y}_{...} =
\frac{1}{abn}\Sigma_{i=1}^a \Sigma_{j=1}^b \Sigma_{k=1} ^{n} Y_{ijk} =
\hat{\mu} \]</span></p>
<p>Two factors ANOVA 的方差分解更复杂一些：</p>
<p><span class="math display">\[\begin{aligned} SSTO &amp;= \Sigma_i
\Sigma_j \Sigma_k (Y_{ijk} - \bar Y_{...})^2   \\ &amp;=  \Sigma_i
\Sigma_j \Sigma_k ((\bar Y_{i..} - \bar Y_{...})+(\bar{Y}_{.j.} - \bar
Y_{...}) +(\bar{Y}_{ij.} - \bar Y_{i..} -\bar Y_{.j.} +\bar Y_{...})
+(Y_{ijk} - \bar Y_{ij.}))^2 \\&amp;=bn\Sigma_i (\bar Y_{i..} - \bar
Y_{...})^2+an\Sigma_j (\bar{Y}_{.j.} - \bar Y_{...})^2+n\Sigma_i
\Sigma_j (\bar{Y}_{ij.} - \bar Y_{i..} -\bar Y_{.j.} +\bar Y_{...})^2+
\Sigma_{i}\Sigma_j \Sigma_k (Y_{ijk} - \bar Y_{ij.})^2  \\&amp;=SSA
+SSB+SSAB+SSE  \end{aligned}\]</span></p>
<p>其中，<span class="math inline">\(SSA\)</span> 的自由度是 <span class="math inline">\(a-1\)</span>，<span class="math inline">\(SSB\)</span> 的自由度是 <span class="math inline">\(b-1\)</span>，<span class="math inline">\(SSAB\)</span> 的自由度是 <span class="math inline">\((a-1)(b-1)\)</span>，<span class="math inline">\(SSE\)</span> 的自由度是 <span class="math inline">\(ab(n-1)\)</span>，<span class="math inline">\(SSTO\)</span> 的自由度是 <span class="math inline">\(abn-1\)</span>。在这一个复杂问题中我们关心不同的问题，可以做出三种不同的假设检验，有对应的检验统计量。</p>
<ul>
<li><span class="math inline">\(A\)</span> 因素是否会导致差异？<span class="math inline">\(H_0: \alpha_1 =\alpha_2=...=\alpha_a\)</span>，在
<span class="math inline">\(H_0\)</span> 下有 <span class="math inline">\(F^* = \frac{SSA/(a-1)}{SSE/(ab(n-1))} \sim
F_{a-1,ab(n-1)}\)</span></li>
<li><span class="math inline">\(B\)</span> 因素是否会导致差异？<span class="math inline">\(H_0: \beta_1 =\beta_2=...=\beta_b\)</span>，在
<span class="math inline">\(H_0\)</span> 下有 <span class="math inline">\(F^* = \frac{SSB/(b-1)}{SSE/(ab(n-1))} \sim
F_{b-1,ab(n-1)}\)</span></li>
<li><span class="math inline">\(A,B\)</span> 是否联合作用？<span class="math inline">\(H_0:(\alpha \beta)_{ij}=0, \forall 1 \leq i \leq
a,1\leq j \leq b\)</span>，在 <span class="math inline">\(H_0\)</span>
下有 <span class="math inline">\(F^*=\frac{SSAB/(a-1)(b-1)}{SSE/(ab(n-1))} \sim
F_{(a-1)(b-1),ab(n-1)}\)</span></li>
</ul>
<p>不能直接用 chi-square 统计量作为检验统计量的原因是实际上 <span class="math inline">\(MSE,MSA\)</span> 等统计量中都带有未知的 <span class="math inline">\(\sigma^2\)</span> 参数项。</p>
<p>注意 <span class="math inline">\(n_{ij}\)</span>
是相等的也就是平衡设计，所以 Type I 和 Type III ANOVA
的结果是一样的。</p>
<h3 id="two-way-anova-in-r">Two-Way ANOVA in R</h3>
<p>模型假设是 <span class="math inline">\(Y_{ijk} = \mu +\alpha_i +
\beta_j +(\alpha \beta)_{ij} + \varepsilon_{ijk}\)</span>。</p>
<p>其中，<span class="math inline">\(\mu\)</span> 是整体的均值，<span class="math inline">\(\alpha_i\)</span> 代表只和等级为 <span class="math inline">\(i\)</span> 的因素 <span class="math inline">\(A\)</span> 有关的变化，<span class="math inline">\(\beta_j\)</span> 表示只和等级为 <span class="math inline">\(j\)</span> 的因素 <span class="math inline">\(B\)</span> 有关的变化，<span class="math inline">\((\alpha \beta)_{ij}\)</span>
表示和两个因素同时相关的变化，相当于一个交叉项。</p>
<p>这里面有 <span class="math inline">\((a+1)(b+1)\)</span>
个参数，对其也有一定的约束。R code 中的约束是和上述理论不同的，因此
estimator 的读取也并不相同，认为 <span class="math inline">\(\alpha_1 =
\beta_1 = (\alpha \beta)_{1j} = (\alpha
\beta)_{i1}=0\)</span>，事实上也还是 <span class="math inline">\(a+b+1\)</span> 个约束条件，可以估计出 <span class="math inline">\(ab+1\)</span> 个不同参数。</p>
<p>相应地，对应的 design matrix 也不尽相同。这里以 <span class="math inline">\(a=3,b=2,n=2\)</span> 为例，coefficient table
如下所示：</p>
<p><img src="https://s2.loli.net/2023/06/02/tjVnAgmPvwBoeQF.png" alt="coefficient-table.png"></p>
<p>Coefficient table 里的 Intercept 代表的实际上是 <span class="math inline">\(\mu\)</span>，预设了 <span class="math inline">\(\beta_1=0\)</span>，height2 即为 <span class="math inline">\(\beta_2\)</span>，height3 即为 <span class="math inline">\(\beta_3\)</span>；预设了 <span class="math inline">\(\alpha_1=0\)</span>，width2 即为 <span class="math inline">\(\alpha_2\)</span>；关于交互效应项，由于预设了
<span class="math inline">\((\alpha \beta)_{11} = (\alpha \beta)_{12} =
(\alpha \beta)_{13} =(\alpha
\beta)_{21}=0\)</span>，不为零的交互效应项只有两个，分别由
height2:weight2 对应 <span class="math inline">\((\alpha
\beta)_{22}\)</span>，height2:weight3 对应 <span class="math inline">\((\alpha \beta)_{23}\)</span>。</p>
<p>由此我们可以依次按照 <span class="math inline">\(\mu_{ij} = \mu +
\alpha_i + \beta_j +(\alpha \beta)_{ij}\)</span> 算出所有的 <span class="math inline">\(\mu_{ij}\)</span> 的估计量。</p>
<p>在这之后我们希望得到一个关于 <span class="math inline">\(12\)</span>
个数据的设计阵，实际上就是把数据和上述分析对应起来：</p>
<p><img src="https://s2.loli.net/2023/06/02/bAZXemT5kDncjoy.png" alt="design-matrix.png"></p>
<h2 id="least-square-means">Least Square Means</h2>
<p>遇到非平衡设计，或者 covariates
的情况（连续型变量和类别性变量产生交互效应的情况），需要考虑 least
square means 而不是 pooled means。简单来说 least square means
是均值的均值，达到了最小的方差，而 pooled means
就是全体数据的均值，在非平衡设计的情况下很可能引入偏差。</p>
<p><img src="https://s2.loli.net/2023/06/02/RP89DuvkNQlVUqi.png" alt="LSM.png"></p>
<h3 id="balanced-test">Balanced Test</h3>
<p>对于一个平衡设计来说，它本质上是一个正交设计，模型中进一个因子还是两个因子都不会改变彼此的系数估计，只有自由度会有改变。least
square mean 就是普通的 pooled mean，one-way ANOVA 和 two-way ANOVA
的结果一致。</p>
<h3 id="unbalanced-test">Unbalanced Test</h3>
<p>非平衡设计的时候 one-way ANOVA 的结果仍然是一样的，least square mean
和 pooled mean 得到的都是这一组内所有的观测值的平均。在这里就是认为 A
因子的 height1 level 的估计值是 <span class="math inline">\(\hat \mu_{1}
= \frac 1 3(X_{11} +X_{12} +X_{13}) = 43\)</span>。</p>
<p>但是新加入一个因子做 two-way ANOVA 就会导致 least square mean
下的系数估计发生变化，从 coefficient table 可以看出 <span class="math inline">\(\mu_{i1}\)</span> 和 <span class="math inline">\(\mu_{i2}\)</span>
都改变了（绷不住了，虽然并不知道是怎么变的，但是会从系数表读出每一个
<span class="math inline">\(\mu_{ij}\)</span> 就可以了），仍然使用 <span class="math inline">\(\frac 1 2(\mu_{i1}+\mu_{i2})\)</span> 作为 <span class="math inline">\(\mu_{i.}\)</span>
的估计，就也会相应地发生变化。</p>
<p>事实上 least square mean 还可以称作 predicted mean 的原因就是，此处的
<span class="math inline">\(\mu_{11}\)</span> 和 <span class="math inline">\(\mu_{12}\)</span> 分别作为 <span class="math inline">\(1\times 1,1\times 2\)</span>
这两格的预测值出现，它们的平均就作为 <span class="math inline">\(\mu_{1.}\)</span> 这一个 A 因子的 height1 level
对应的预测值出现。在具体的例子里，此处因为得到的估计是 <span class="math inline">\(\hat \mu_{11} = 41, \hat \mu_{12} =
44\)</span>，于是认为 <span class="math inline">\(\hat \mu_{1.} = \frac
1 2 (\hat \mu_{11} + \hat \mu_{12}) = 42.5\)</span>。</p>
<p><img src="https://s2.loli.net/2023/06/02/McpX95nUsHYWRmT.png" alt="predicted-means.png"></p>
<p>总之可以看到，unbalance test 会导致实验设计并不是正交的，B
因子的加入会对 A 因子的均值估计产生影响，这也是我们一般希望使用 balanced
test 的理由。</p>
<h2 id="model-diagnose-remedy">Model Diagnose &amp; Remedy</h2>
<p>马上要告别应统了，于是不考也就不想学了，摆烂。</p>
<h1 id="附录">附录</h1>
<h2 id="常见重要分布">常见重要分布</h2>
<p>From <a href="https://v1ncent19.github.io/SummaryNotes/">Statistic
Note</a> P10, by V1ncent19</p>
<table style="width:100%;">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(X\)</span></th>
<th><span class="math inline">\(p_X(k)\big/f_X(x)\)</span></th>
<th><span class="math inline">\(\mathbb{E}\)</span></th>
<th><span class="math inline">\(var\)</span></th>
<th>PGF</th>
<th>MGF</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\mathrm{Bern} (p)\)</span></td>
<td></td>
<td><span class="math inline">\(p\)</span></td>
<td><span class="math inline">\(pq\)</span></td>
<td></td>
<td><span class="math inline">\(q+pe^s\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(B (n,p)\)</span></td>
<td><span class="math inline">\(C_n^k p^k(1-p)^{n-k}\)</span></td>
<td><span class="math inline">\(np\)</span></td>
<td><span class="math inline">\(npq\)</span></td>
<td><span class="math inline">\((q+ps)^n\)</span></td>
<td><span class="math inline">\((q+pe^s)^n\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mathrm{Geo} (p)\)</span></td>
<td><span class="math inline">\((1-p)^{k-1}p\)</span></td>
<td><span class="math inline">\(\dfrac{1}{p}\)</span></td>
<td><span class="math inline">\(\dfrac{q}{p^2}\)</span></td>
<td><span class="math inline">\(\dfrac{ps}{1-qs}\)</span></td>
<td><span class="math inline">\(\dfrac{pe^s}{1-qe^s}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(H(n,M,N)\)</span></td>
<td><span class="math inline">\(\dfrac{C_M^kC_{N-M}^{n-k}}{C_N^n}\)</span></td>
<td><span class="math inline">\(n\dfrac{M}{N}\)</span></td>
<td><span class="math inline">\(\dfrac{nM(N-n)(N-M)}{N^2(n-1)}\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(P(\lambda)\)</span></td>
<td><span class="math inline">\(\dfrac{\lambda^k}{k!}e^{-\lambda}\)</span></td>
<td><span class="math inline">\(\lambda\)</span></td>
<td><span class="math inline">\(\lambda\)</span></td>
<td><span class="math inline">\(e^{\lambda(s-1)}\)</span></td>
<td><span class="math inline">\(e^{\lambda(e^s-1)}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(U(a,b)\)</span></td>
<td><span class="math inline">\(\dfrac{1}{b-a}\)</span></td>
<td><span class="math inline">\(\dfrac{a+b}{2}\)</span></td>
<td><span class="math inline">\(\dfrac{(b-a)^2}{12}\)</span></td>
<td></td>
<td><span class="math inline">\(\dfrac{e^{sb}-e^{sa}}{(b-a)^s}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(N(\mu,\sigma^2)\)</span></td>
<td><span class="math inline">\(\dfrac{1}{\sigma
\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\)</span></td>
<td><span class="math inline">\(\mu\)</span></td>
<td><span class="math inline">\(\sigma^2\)</span></td>
<td></td>
<td><span class="math inline">\(e^{\frac{\sigma^2s^2}{2}+\mu
s}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\epsilon(\lambda)\)</span></td>
<td><span class="math inline">\(\lambda e^{-\lambda x}\)</span></td>
<td><span class="math inline">\(\dfrac{1}{\lambda}\)</span></td>
<td><span class="math inline">\(\dfrac{1}{\lambda^2}\)</span></td>
<td></td>
<td><span class="math inline">\(\frac{\lambda}{\lambda-s}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\Gamma(\alpha,\lambda)\)</span></td>
<td><span class="math inline">\(\dfrac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda
x}\)</span></td>
<td><span class="math inline">\(\dfrac{\alpha}{\lambda}\)</span></td>
<td><span class="math inline">\(\dfrac{\alpha}{\lambda^2}\)</span></td>
<td></td>
<td><span class="math inline">\(\left(\frac{\lambda}{\lambda-s}\right)^\alpha\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(B(\alpha,\beta)\)</span></td>
<td><span class="math inline">\(\dfrac{1}{B(\alpha,\beta)}x^{\alpha-1}(1-x)^{\beta-1}\)</span></td>
<td><span class="math inline">\(\dfrac{\alpha}{\alpha+\beta}\)</span></td>
<td><span class="math inline">\(\dfrac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\chi^2_n\)</span></td>
<td><span class="math inline">\(\dfrac{1}{2^{\frac{n}{2}}\Gamma(\frac{n}{2})}x^{\frac{n}{2}-1}e^{-\frac{x}{2}}\)</span></td>
<td><span class="math inline">\(n\)</span></td>
<td><span class="math inline">\(2n\)</span></td>
<td></td>
<td>$ (1-2s)^{-n/2} $</td>
</tr>
<tr class="even">
<td><span class="math inline">\(t_\nu\)</span></td>
<td><span class="math inline">\(\dfrac{\Gamma(\frac{\nu+1}{2})}{\sqrt{\nu\pi}\Gamma(\frac{\nu}{2})}(1+\frac{x^2}{\nu})^{-\frac{\nu+1}{2}}\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(\dfrac{\nu}{\nu-2}\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(F_{m,n}\)</span></td>
<td><span class="math inline">\(\dfrac{\Gamma(\frac{m+n}{2})}{\Gamma(\frac{m}{2})\Gamma(\frac{n}{2})}\dfrac{m^\frac{m}{2}n^\frac{n}{2}x^{\frac{m}{2}-1}}{(mx+n)^{\frac{m+n}{2}}}\)</span></td>
<td><span class="math inline">\(\dfrac{n}{n-2}\)</span></td>
<td><span class="math inline">\(\dfrac{2n^2(m+n-2)}{m(n-2)^2(n-4)}\)</span></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Consider <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>
i.i.d. <span class="math inline">\(\sim N(0,1)\)</span>; <span class="math inline">\(Y,Y_1,Y_2,\ldots,Y_m\)</span> i.i.d. <span class="math inline">\(\sim N(0,1)\)</span> - <span class="math inline">\(\chi^2\)</span> Distribution：</p>
<p><span class="math inline">\(\chi^2\)</span> distribution with degree
of freedom <span class="math inline">\(n\)</span>：$ =_{i=1}^n
X_i<sup>2</sup>2_n$。 For independent <span class="math inline">\(\xi_i\sim\chi^2_{n_i},\,
i=1,2,\ldots,k\)</span>：<span class="math inline">\(x_{i_0}=\sum_{i=1}^k\xi_i\sim\chi^2_{n_1+\ldots+n_k}\)</span></p>
<ul>
<li><p><span class="math inline">\(t\)</span> Distribution：</p>
<p><span class="math inline">\(t\)</span> distribution with degree of
freedom <span class="math inline">\(n\)</span>：$ T==t_n$</p>
<p>Upper <span class="math inline">\(\alpha\)</span>-fractile of <span class="math inline">\(t_\nu\)</span>, satisfies <span class="math inline">\(\mathbb{P}(T\geq
c)=\alpha\)</span>，$t_{,}=<em>{c}(Tc)=,Tt</em>$</p></li>
<li><p><span class="math inline">\(F\)</span> Distribution：</p>
<p><span class="math inline">\(F\)</span> distribution with degree of
freedom <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span>：$ F=F_{m,n}$</p>
<ul>
<li>If <span class="math inline">\(Z\sim F_{m,n}\)</span>, then <span class="math inline">\(\dfrac{1}{Z}\sim F_{n,m}\)</span>；</li>
<li>If <span class="math inline">\(T\sim t_n\)</span>, then <span class="math inline">\(T^2\sim F_{1,n}\)</span>；</li>
<li><span class="math inline">\(F_{m,n,1-\alpha}=\dfrac{1}{F_{n,m,\alpha}}\)</span>
。</li>
</ul></li>
</ul>
<p>Some useful lemmas in statistical inference：</p>
<ul>
<li><p>For <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>
independent with <span class="math inline">\(X_i\sim
N(\mu_i,\sigma^2_i)\)</span>, then <span class="math inline">\(\sum_{i=1}^n\left(\frac{X_i-\mu_i}{\sigma_i}\right)^2\sim
\chi^2_n\)</span></p></li>
<li><p>For <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>
i.i.d.<span class="math inline">\(\sim N(\mu,\sigma^2)\)</span>, then $
T=t_{n-1} $</p></li>
<li><p>For <span class="math inline">\(X_1,X_2,\ldots,X_m\)</span>
i.i.d.<span class="math inline">\(\sim N(\mu_1,\sigma^2)\)</span>, <span class="math inline">\(Y_1,Y_2,\ldots,Y_n\)</span> i.i.d.<span class="math inline">\(\sim N(\mu_2,\sigma^2)\)</span>,d enote sample
pooled variance <span class="math inline">\(S_{\omega}^2=\dfrac{(m-1)S^2_1+(n-1)S^2_2}{m+n-2}\)</span>,
then <span class="math inline">\(T=\frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}{S_{\omega}}\cdot
\sqrt{\frac{mn}{m+n}}\sim t_{m+n-2}\)</span></p></li>
<li><p>For <span class="math inline">\(X_1,X_2,\ldots,X_m\)</span>
i.i.d.<span class="math inline">\(\sim N(\mu,\sigma^2)\)</span>, <span class="math inline">\(Y_1,Y_2,\ldots,Y_n\)</span> i.i.d.<span class="math inline">\(\sim N(\mu_2,\sigma^2)\)</span>, then
$T=F_{m-1,n-1} $</p></li>
<li><p>For <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>
i.i.d. <span class="math inline">\(\sim \varepsilon(\lambda)\)</span>,
then $ 2n{X}=2<em>{i=1}^nX_i ^2</em>{2n} $</p>
<p>Remark：for <span class="math inline">\(X_i\sim\varepsilon(\lambda)=\Gamma(1,\lambda)\)</span>，<span class="math inline">\(2\lambda\sum_{i=1}^nX_i\sim\Gamma(n,1/2)=\chi^2_{2n}\)</span>.</p></li>
</ul>
<h2 id="分位数速查">分位数速查</h2>
<p>来自 Package stats, version 4.2.1。</p>
<p>其实都可以直接查文档啦（，R 的文档还是很保姆式的。</p>
<h3 id="t-分布模拟">t-分布模拟</h3>
<p>t-distribution 下有四个函数，分别是 density, CDF, quantile
function(<span class="math inline">\(CDF^{-1}\)</span>)，还有一个是随机生成一个模拟数组。</p>
<p><code>dt(x, df, ncp, log = FALSE)</code> 用来计算 PDF 的函数值 <span class="math inline">\(f(x)\)</span>，df 是自由度，ncp 表示非中心化参数
<span class="math inline">\(\delta\)</span>；</p>
<p><code>pt(x, df, ncp, lower.tail = TRUE, log.p = FALSE)</code>
用来计算 CDF 的函数值 <span class="math inline">\(F(x)\)</span>，注意
<code>lower.tail = TRUE</code> 时计算的是左边值 <span class="math inline">\(F(x)\)</span>，否则实际计算了 <span class="math inline">\(1-F(x)\)</span>。</p>
<p><code>qt(p, df, ncp, lower.tail = TRUE, log.p = TRUE)</code>
用来计算分位数，也即 <span class="math inline">\(F^{-1}(p)\)</span>，其他参数意义同上。</p>
<p>一些我的作业里的函数参考：</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> qt<span class="punctuation">(</span><span class="number">1</span> <span class="operator">-</span> <span class="number">0.025</span><span class="punctuation">,</span> df <span class="operator">=</span> <span class="number">8</span><span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">2.306004</span></span><br></pre></td></tr></table></figure>
<p>这里计算的是 <span class="math inline">\(t_{8,0.975}\)</span>
的下分位数，实际上是一个 level of significance 为 <span class="math inline">\(0.05\)</span> 的双尾检验中用到的分位数。</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> <span class="number">2</span> <span class="operator">*</span> pt<span class="punctuation">(</span><span class="operator">-</span><span class="number">8.529</span><span class="punctuation">,</span> df <span class="operator">=</span> <span class="number">8</span><span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">2.74639e-05</span></span><br></pre></td></tr></table></figure>
<p>这里是在计算一个 P-value，计算的是比 observed data <span class="math inline">\(-8.529\)</span> 更极端的数据的出现概率，单边是
<span class="math inline">\(F (-8.529)\)</span>，注意此处的“极端”包含比
<span class="math inline">\(-8.529\)</span> 更小和比 <span class="math inline">\(8.529\)</span> 更大这两种情况，实际上是 <span class="math inline">\(F(-8.529) + 1- F(8.529)\)</span>。</p>
<p>由于 t-distribution 是对称的，可以简化为 <span class="math inline">\(2 \times F(-8.529)\)</span>。</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> ncp <span class="operator">&lt;-</span> 2.0<span class="operator">/</span><span class="number">0.50</span></span><br><span class="line"><span class="operator">&gt;</span> <span class="built_in">c</span> <span class="operator">&lt;-</span> qt<span class="punctuation">(</span><span class="number">1</span><span class="operator">-</span><span class="number">0.025</span><span class="punctuation">,</span>df<span class="operator">=</span><span class="number">8</span><span class="punctuation">)</span></span><br><span class="line"><span class="operator">&gt;</span> pt<span class="punctuation">(</span><span class="operator">-</span><span class="built_in">c</span><span class="punctuation">,</span> df<span class="operator">=</span><span class="number">8</span><span class="punctuation">,</span> ncp<span class="punctuation">)</span> <span class="operator">+</span> <span class="number">1</span> <span class="operator">-</span> pt<span class="punctuation">(</span><span class="built_in">c</span><span class="punctuation">,</span> df<span class="operator">=</span><span class="number">8</span><span class="punctuation">,</span> ncp<span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">0.9367429</span></span><br></pre></td></tr></table></figure>
<p>这是一个非中心的 t 检验，实际上是在计算 Power Function。</p>
<h3 id="正态分布模拟">正态分布模拟</h3>
<p>常用的三个函数是
<code>dnorm</code>，<code>pnorm</code>，<code>qnorm</code>，含义与
t-分布中的 <code>dt</code>，<code>pt</code>，<code>qt</code> 相似。</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">dnorm<span class="punctuation">(</span>x<span class="punctuation">,</span> mean <span class="operator">=</span> <span class="number">0</span><span class="punctuation">,</span> sd <span class="operator">=</span> <span class="number">1</span><span class="punctuation">,</span> <span class="built_in">log</span> <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br><span class="line">pnorm<span class="punctuation">(</span>q<span class="punctuation">,</span> mean <span class="operator">=</span> <span class="number">0</span><span class="punctuation">,</span> sd <span class="operator">=</span> <span class="number">1</span><span class="punctuation">,</span> lower.tail <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">,</span> log.p <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br><span class="line">qnorm<span class="punctuation">(</span>p<span class="punctuation">,</span> mean <span class="operator">=</span> <span class="number">0</span><span class="punctuation">,</span> sd <span class="operator">=</span> <span class="number">1</span><span class="punctuation">,</span> lower.tail <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">,</span> log.p <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<p>注意一般正态检验中都是使用标准正态分布，也就是不需要去改变
<code>mean</code> 和 <code>sd</code> 的默认值。</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> pnorm<span class="punctuation">(</span><span class="number">0</span><span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">0.5</span></span><br><span class="line"><span class="operator">&gt;</span> qnorm<span class="punctuation">(</span><span class="number">0.025</span><span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="operator">-</span><span class="number">1.959964</span></span><br></pre></td></tr></table></figure>
<h3 id="f-分布模拟">F-分布模拟</h3>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">df<span class="punctuation">(</span>x<span class="punctuation">,</span> df1<span class="punctuation">,</span> df2<span class="punctuation">,</span> ncp<span class="punctuation">,</span> <span class="built_in">log</span> <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br><span class="line">pf<span class="punctuation">(</span>q<span class="punctuation">,</span> df1<span class="punctuation">,</span> df2<span class="punctuation">,</span> ncp<span class="punctuation">,</span> lower.tail <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">,</span> log.p <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br><span class="line">qf<span class="punctuation">(</span>p<span class="punctuation">,</span> df1<span class="punctuation">,</span> df2<span class="punctuation">,</span> ncp<span class="punctuation">,</span> lower.tail <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">,</span> log.p <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<p>注意 <span class="math inline">\(F\)</span>
分布的两个自由度都可以取到无穷，写作 <code>df1 = Inf</code>。</p>
<h3 id="chi-square-分布模拟">Chi-square 分布模拟</h3>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">dchisq<span class="punctuation">(</span>x<span class="punctuation">,</span> df<span class="punctuation">,</span> ncp <span class="operator">=</span> <span class="number">0</span><span class="punctuation">,</span> <span class="built_in">log</span> <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br><span class="line">pchisq<span class="punctuation">(</span>q<span class="punctuation">,</span> df<span class="punctuation">,</span> ncp <span class="operator">=</span> <span class="number">0</span><span class="punctuation">,</span> lower.tail <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">,</span> log.p <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br><span class="line">qchisq<span class="punctuation">(</span>p<span class="punctuation">,</span> df<span class="punctuation">,</span> ncp <span class="operator">=</span> <span class="number">0</span><span class="punctuation">,</span> lower.tail <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">,</span> log.p <span class="operator">=</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<h2 id="其他常用-r-命令">其他常用 R 命令</h2>
<p>持续更新中，基本都是作业里扒出来的。</p>
<h3 id="confidence-interval">confidence interval</h3>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">confint<span class="punctuation">(</span>object<span class="punctuation">,</span> parm<span class="punctuation">,</span> level <span class="operator">=</span> <span class="number">0.95</span><span class="punctuation">,</span> ...<span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<p>注意 confidence coefficient 的默认值是 <span class="math inline">\(0.95\)</span>，<code>confint</code>
函数是用于拟合模型参数的置信区间估计，例如：</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">model <span class="operator">&lt;-</span> lm<span class="punctuation">(</span>data<span class="punctuation">)</span></span><br><span class="line">confint<span class="punctuation">(</span>model<span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">               <span class="number">2.5</span> <span class="operator">%    97.5 %</span></span><br><span class="line"><span class="punctuation">(</span>Intercept<span class="punctuation">)</span> <span class="number">8.670370</span> <span class="number">11.729630</span></span><br><span class="line">V2          <span class="number">2.918388</span>  <span class="number">5.081612</span></span><br></pre></td></tr></table></figure>
<p>这个附录怎么全咕了啊，不过无所谓了，这课我本来就是在摆烂（</p>
<h1 id="完结撒花">完结撒花</h1>
<p>一点都不 happily ever
after，说是找到了新的方向，谁知道概率又会不会很艰难呢。</p>
<p>这课明显东西比统计推断多，但是导出成 PDF
一看比统推笔记少了二十多页。</p>
<p>总之都结束了，笑一个吧（</p>
<p><img src="https://s2.loli.net/2022/12/21/6TEM1vSosXLcwOg.jpg" alt="HEA.jpg"></p>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>统计</tag>
        <tag>课程实录</tag>
      </tags>
  </entry>
  <entry>
    <title>基础物理光学实验备忘录</title>
    <url>/2022/07/03/Physics-Lab2-Notes/</url>
    <content><![CDATA[<p>考虑到开学之后肯定没空每周研究实验怎么做，最近又很颓不想干活。于是一边补番一边写一份从零开始的，<strong>讲人话的</strong>实验备忘录，目的是将来做实验前快速阅读一遍，然后对着设计好的实验表和博文就能<del>优雅地</del>动手不动脑地做完实验，还能从这篇备忘录里抄点东西去写实验报告。</p>
<span id="more"></span>
<p>这个操作是合理的。<del>我和物理本来就不合适，</del>结合上学期的经验可以发现，无论有没有学过原理，我唯一的解决方案就是按计划一帧一帧地做实验，才不至于大脑空白。加之我秋季学期就没选理论课，理论水平也就是现在这样了，倘若现在不写，将来更写不出来。上学期因为仓促，只在讲义上手写了一些要点，有的时候记不清了就会不知所措，所以这次码个字可以详细一点。</p>
<p>这样的话，物理实验就变成了<del>大猩猩也能做的</del>体力活罢了。我不否认这个想法，也无意论辩这门课是否有意义，将本文视作作者的救命手册即可。</p>
<p><strong>注：未经授权禁止转载，本人不希望在院系里受到关注；所有提到的引用，包括图片，文字，数据信息等，著作权归原作者所有；一概不提供文中提到的自用实验表格，请自行阅读实验讲义，勿直接伸手。</strong></p>
<h1 id="完整报告篇">完整报告篇</h1>
<h2 id="用单色仪测定介质的吸收曲线">用单色仪测定介质的吸收曲线</h2>
<h3 id="原理简述">原理简述</h3>
<p>一束光入射到有一定厚度的介质上时，有一部分光被反射，另一部分被吸收，其余被透射——也即进入有厚度<span class="math inline">\(d\)</span>的介质。根据各部分的光强，可以定义出介质板的光谱外透射率<span class="math inline">\(T=\frac{I_T}{I_0}\)</span>和光谱透射率<span class="math inline">\(T_{i}=\frac{I_2}{I_1}\)</span>。</p>
<p>（此处应该有图，但是没有图。）</p>
<p>光谱透射率同时与介质的性质和入射光的波长<span class="math inline">\(\lambda\)</span>​相关。为什么这么说呢？因为忽略介质内散射的情况下<span class="math inline">\(T_{i}=e^{-\alpha d}\)</span>​，<span class="math inline">\(\alpha\)</span>​称为介质的线性吸收系数，与介质的性质和入射光波长有关。</p>
<p>经过若干次透射后，透射光的光强为一个等比数列的和，即为<span class="math inline">\(I_T=\frac{I_0(1-R)^2e^{-\alpha
d}}{1-R^2e^{-2\alpha d}}\)</span>​。其中，<span class="math inline">\(I_{0}\)</span>​为入射光强，<span class="math inline">\(R\)</span>​为单一界面上的反射率。由此可以计算光谱外透射率<span class="math inline">\(T=\frac{I_T}{I_0}\)</span>​。</p>
<p>在实际实验中，使用了两块仅厚度不同的试样，计算后近似得出光谱外透射率的比值，<strong>我们不加证明地给出吸收系数的近似：<span class="math inline">\(\alpha=\frac{lnT_{1}-lnT_{2}}{d_{2}-d_{1}}\)</span></strong>
。实际实验中，<strong>用微电流放大器的显示值</strong><span class="math inline">\(V_{1}\)</span>,<span class="math inline">\(V_{2}\)</span><strong>分别替换上式的</strong><span class="math inline">\(T_{1}\)</span>,<span class="math inline">\(T_{2}\)</span>。</p>
<h3 id="应该做什么在纸上记什么">应该做什么？在纸上记什么？</h3>
<p>你不懂仪器的构造，但是没关系，跟着做就行了。</p>
<h4 id="校对单色仪的波长示值">校对单色仪的波长示值</h4>
<p>单色仪长这个样子：</p>
<p><a href="https://imgtu.com/i/jGNzVO"><img src="https://s1.ax1x.com/2022/07/04/jGNzVO.png" alt="jGNzVO.png"></a></p>
<p><strong>第一步</strong>，通过两个鼓轮调入射狭缝 S1 和出射狭缝 S2
的宽度，分别约为 1mm 和 2mm（目测即可）。</p>
<p><strong>第二步</strong>，把汞灯放在 S1 前面，打开汞灯，把手轮转到
577.0~579.1nm 之间的某一位置（通过波长示数器观察）。</p>
<p>显微镜目镜和物镜拧紧放在 S2 前面，调一调高度和与 S2
的距离，观察到像这样的图像。黄的叫谱线，黑的叫狭缝刃口。</p>
<p><a href="https://imgtu.com/i/jGUpIe"><img src="https://s1.ax1x.com/2022/07/04/jGUpIe.png" alt="jGUpIe.png"></a></p>
<blockquote>
<p>关小入射狭缝 S1
使两条谱线分开，在谱线沿缝方向宽度基本均匀、亮度好的前提下，
使狭缝尽量窄，谱线尽量细。再关小出射狭缝
S2，同时微动手轮，使其中一条谱线始终在狭缝中央，直至狭缝宽度与谱线同宽（此时微动手轮，谱线即被遮挡，谱线消失）。</p>
</blockquote>
<p>纸上谈兵来说，如上操作可以得到单条谱线的波长示值（显示在波长计数器上）。按这个办法慢慢调波长，在标准值附近分别找两条黄线，一条紫线和一条绿线的示值，把它们记在第一个表里，<strong>差值的平均值就是单色仪波长示值的系统误差，之后要修约。</strong></p>
<p>标准值是黄线 579.1nm， 黄线 577.0nm，绿线 546.1nm，紫线 435.8nm。</p>
<h4 id="用汞灯调狭缝宽度">用汞灯调狭缝宽度</h4>
<p><strong>第一步</strong>，将单色仪的波长读数装置转到示值在
577.0~579.1nm 之间的某一位置。将出射缝 S2 的宽度暂时调至约
2mm。用显微镜<strong>观察汞的两条黄谱线（577.0nm 和
579.1nm）</strong>。如果看不到谱线，增加 S2 缝宽或改变波长示值。</p>
<p><strong>第二步</strong>，缓慢增加入射狭缝 S1
的宽度，使谱线变宽，<strong>直到两条黄谱线刚好碰上且不重叠为止</strong>，此时入射狭缝宽约0.8mm。再调节出射狭缝
S2
的宽度，同时微调手轮，<strong>使出缝宽度与其中一条谱线宽度大致相同</strong>，此时出缝与入缝同宽，约
0.8mm。</p>
<p>此后不要再动单色仪，光强就能满足吸收系数测量的要求。此部分不需要记录数据。</p>
<h4 id="溴钨灯光路调节而不是溴钨灯光路调节">溴钨灯/光路调节，而不是溴钨灯光/路调节</h4>
<p><strong>第一步</strong>，溴钨灯按讲义上写的接三路输出电源，调整设置。</p>
<p>然后，讲义上是这样写的：</p>
<blockquote>
<p>为了减少单色仪的光能损失，提高透光效率（充分利用单色仪的全孔径和相对孔径
<em>D</em>/<em>f</em>），根据图 12 光路图，计算聚光镜和光源的位置。</p>
<p>聚光(透)镜的参数见前面。单色仪焦距 <em>f</em>=300mm (即图 12 的
<em>b</em>=300mm)，单色仪球面镜（准直镜）的光栏宽度
<em>D</em>=50mm。成像规律符合 Gauss 公式。</p>
<p>使球面镜的孔径 <em>D</em>
充分照明，两个相似三角形应有下列关系：<em>d/D</em>=<em>a/b</em>。</p>
</blockquote>
<p><strong>翻译成人话：聚光镜摆在狭缝前面 18cm 处，溴钨灯摆在聚光镜前面
9cm
处，注意共轴。</strong>当然，得在表格上画个图，装模作样算一下这两个数据。</p>
<p><strong>第二步</strong>，手轮调到
610.0nm，调整各种位置。用眼睛靠近出射狭缝 S2 观察红色谱线。</p>
<p>具体怎么调？<strong>先粗调后细调。</strong></p>
<p>粗调：溴钨灯电流建议用
2.0A。微调光源的位置，用眼睛观察溴钨灯在入射狭缝 S1
处所成的清晰实像，粗略调节等高同轴。</p>
<p>细调：溴钨灯电流建议用 1.50A。用眼睛靠近出射狭缝 S2
观察光谱，左右(共轴)调节聚光镜至合适位置，不管条纹亮度均匀否，只关注条纹上、下边缘的圆弧左右对称否，调至对称。</p>
<p>再前后、左右微调溴钨灯，眼睛能看到亮度均匀的光谱(条纹)，差不多这样。</p>
<p><a href="https://imgtu.com/i/jGUPGd"><img src="https://s1.ax1x.com/2022/07/04/jGUPGd.png" alt="jGUPGd.png"></a></p>
<p>调节好透镜和溴钨灯位置后，固定好它们。</p>
<h4 id="最后的仪器安装">最后的仪器安装</h4>
<p><strong>第一步</strong>，把样品装在 S2
上，先薄再厚，具体操作摘录如下：</p>
<blockquote>
<p>将装有钕玻璃吸收片的样品反面的红点对准S2
上红点，顺时针旋转样品，听到咔的声音，样品已锁定，往外拉一下，确认已安装好。</p>
<p>取样品时侧面小螺钉往里轻推，逆时针旋转即可取下。</p>
</blockquote>
<p><strong>第二步</strong>，装硅光电二极管探头。</p>
<blockquote>
<p>将探头插入样品正面的圆柱孔内(插到底)，确认电缆接头处于拧紧状态。</p>
</blockquote>
<p>如果还是手笨接不好仪器，就求助一下旁边同学吧<del>，没救了</del>。</p>
<h4 id="测量环节">测量环节</h4>
<p>对每一个样品，观察对各色光的吸收情况。</p>
<p>从 610.0nm 到 550.0nm
转动手轮测定两个最大的吸收峰（光电探测器上的电压示值最小）的波长位置并记录。要求每隔
2nm 测一次示值，在吸收峰左右 4nm 范围内测量点更密，取整数每隔 0.5nm
测量一次，记录在最后一个表里。</p>
<p>注意：测量要消空程，即只向一个方向转动手轮， 一次完成。</p>
<h3 id="测完数据要分析计算什么画哪些图">测完数据要分析计算什么？画哪些图？</h3>
<ul>
<li>根据<span class="math inline">\(\alpha=\frac{lnV_{1}-lnV_{2}}{d_{2}-d_{1}}\)</span>，列表计算每个波长对应的<span class="math inline">\(\alpha\)</span></li>
<li>画一个<span class="math inline">\(\lambda-\alpha\)</span>图，是为吸收曲线。从中读出两个峰值的数值，然后按波长修正规则修一下。</li>
<li>误差分析讨论和回答思考题，可参考祖传实验报告。</li>
</ul>
<h3 id="本文写作中用到的参考">本文写作中用到的参考</h3>
<ul>
<li><p>单色仪实验操作视频：</p>
<p>https://www.bilibili.com/video/BV17A411L7mg?spm_id_from=333.337.search-card.all.click&amp;vd_source=6ae5c31a80120436d23cf7b7c7ceb3ba</p></li>
<li><p>清华大学2021秋基础物理实验(2)讲义</p></li>
</ul>
<h2 id="偏振光学系列实验">偏振光学系列实验</h2>
<h3 id="原理简述-1">原理简述</h3>
<ul>
<li>什么是偏振光？<del>这不重要</del></li>
</ul>
<p>一个单色偏振光可以分解为两个互相垂直的线偏振光的叠加。表示如下：</p>
<p><span class="math display">\[ \begin{cases}{}   \  E_x =  a_1\cos
\omega t \\\\ E_y = a_2\cos (\omega t+\delta) \\     \end{cases}
\]</span></p>
<p>其中的<span class="math inline">\(\delta\)</span>被称为<span class="math inline">\(x\)</span>方向偏振分量相对于<span class="math inline">\(y\)</span>方向偏振分量的<strong>位相延迟量</strong>。显然，偏振光的“形状”由式中参数决定，主要探讨椭圆、圆和线偏振光的情况。引入<strong>偏振方向</strong>的概念：
<span class="math inline">\(\alpha=arctan(\frac{a_2}{a_1}
cos\delta)\)</span></p>
<p>我们不加证明地给出关于椭圆偏振光的参数求解式。其中定义<span class="math inline">\(\psi\)</span>为<strong>椭圆的长轴方位角</strong><del>，我也不知道这个是什么意思</del>。</p>
<p><span class="math display">\[ \begin{equation}
\begin{cases}      \psi &amp;= \frac{1}{2}arctan(tan2\beta cos\delta)
\\\\         \frac{b^2}{a^2} &amp;= \frac{2}{1+\sqrt{1-(sin2\beta
sin\delta)^2}}-1 \\\\   \beta
&amp;=arctan(\frac{a_2}{a_1})  \\     \end{cases}     \end{equation}
\]</span></p>
<ul>
<li>偏振片是干什么的？好像是用来产生线偏振光的。</li>
</ul>
<p><a href="https://imgtu.com/i/jdtZaq"><img src="https://s1.ax1x.com/2022/07/06/jdtZaq.png" alt="jdtZaq.png"></a></p>
<p>首先，在这张图中，透射轴是偏振片上的那条轴，我们简称为<span class="math inline">\(x\)</span>轴；消光轴是垂直于偏振片的轴，简称为<span class="math inline">\(y\)</span>轴。沿<span class="math inline">\(x\)</span>轴振动光波的光强透射率为<span class="math inline">\(T_1\)</span>，它接近<span class="math inline">\(1\)</span>；沿<span class="math inline">\(y\)</span>轴振动光波的光强透射率为<span class="math inline">\(T_2\)</span>，它接近<span class="math inline">\(0\)</span>。二者小比大得到一个很小的值<span class="math inline">\(e\)</span>，即为<strong>消光比</strong>。</p>
<p>马吕斯定律：振动方向和<span class="math inline">\(x\)</span>轴方向成<span class="math inline">\(\theta\)</span>角的线偏振光，经过偏振片后的透射率为
<span class="math display">\[T_\theta=(T_1-T_2)cos^2\theta+T_2\]</span>
提出这个定律有什么意义？</p>
<p>实验中两个偏振片的组合（一个称为起偏器，一个称为检偏器）成为一组仪器。起偏器产生的线偏振光经过检偏器。因此，由马吕斯定律，二者的<span class="math inline">\(x\)</span>轴夹角即为<span class="math inline">\(\theta\)</span>。从结论来看，二者的<span class="math inline">\(x\)</span>轴垂直（<span class="math inline">\(\cos
\theta=0\)</span>）则发生消光现象，二者的<span class="math inline">\(x\)</span>轴平行（<span class="math inline">\(\cos
\theta=1\)</span>）则透射光强最大。</p>
<ul>
<li>反射和折射时的起偏现象</li>
</ul>
<p>电矢量形式的菲涅耳公式我看不懂，也不知道是干嘛的（直球）。</p>
<p>和实验相关的东西翻译成人话来说就是，偏振器的透射轴方向可以由布儒斯特角确定。具体如下：</p>
<p><a href="https://imgtu.com/i/jdtuGT"><img src="https://s1.ax1x.com/2022/07/06/jdtuGT.png" alt="jdtuGT.png"></a></p>
<p>预置光束在三棱镜上的入射角<span class="math inline">\(\theta_i\)</span>为<span class="math inline">\(arctan\text n\)</span>，其中<span class="math inline">\(\text
n\)</span>为玻璃的反射率，也即初入射角约为56°。旋转偏振片到某个角度可以发现白纸屏上的光点很暗。微调二者，使得光点达到最暗时的入射角为布儒斯特角<span class="math inline">\(\theta_B\)</span>，且此时偏振片的透射轴（<span class="math inline">\(x\)</span>轴）方向平行于三棱镜上的入射面。</p>
<p><strong>以下与实验无关，可在实验前阅读中跳过。</strong>讲义上还有一段关于S分量反射率的叙述，目测是菲涅尔定律的推导：</p>
<blockquote>
<p>此时， <em>S</em> 分量的反射率为<span class="math inline">\(R_{SB}=\frac{(n^2-1)^2}{(n^2+1)^2}\)</span>。</p>
</blockquote>
<p>关于<del>反应堆</del>玻片堆：</p>
<blockquote>
<p>上式表示的反射率<span class="math inline">\(R_{SB}\)</span>
一般较小，反射光较弱。光束以<span class="math inline">\(\theta_B\)</span>射入多块平行玻璃板以获得只有
<em>P</em> 分量的线偏振透射光，经过 <em>N</em> 块玻璃片的 2<em>N</em>
个表面后，<em>S</em> 分量的总透射率为<span class="math display">\[(1-R_{SB})^{2N}=[1+(n-1)^2/2n]^{-4N}\]</span>在<span class="math inline">\(N\)</span>较大时，其值接近于<span class="math inline">\(0\)</span>。这种起偏装置就叫做玻片堆。</p>
</blockquote>
<ul>
<li>延迟器和波片</li>
</ul>
<p>一般来说，线偏振光入射延迟器后出射为椭圆偏振光。其他的我就一句都没看懂了...<strong>不过没关系，一样可以做实验。</strong></p>
<p>实验中需要操作的是判断波片快慢轴，定出方向，做一些测量。我们直接在下一部分说明。</p>
<h3 id="应该做什么在附的实验表上记什么">应该做什么？在附的实验表上记什么？</h3>
<h4 id="组装仪器">组装仪器</h4>
<p><a href="https://imgtu.com/i/jdt1sJ"><img src="https://s1.ax1x.com/2022/07/06/jdt1sJ.png" alt="jdt1sJ.png"></a></p>
<p>这是一个分光计改装的实验仪。</p>
<p>打开激光器，粗调2,3的轴线，小平台基本水平且与分光计主轴垂直。激光光斑不要太靠近偏振片区域的边缘。</p>
<p>电阻箱阻值100Ω，使得毫伏表示数大于1毫伏。</p>
<h4 id="观测布儒斯特角和偏振器的特性">观测布儒斯特角和偏振器的特性</h4>
<p>玻璃片放在平台上，反射面过平台中心点。以下的此为“x”指实验表中的部分填写。</p>
<p><strong>第一步</strong>，确定光束正入射棱镜表面时平台方位角<span class="math inline">\(\alpha_{i=0}\)</span>。用小纸片扎一个小孔，放在激光器出射光束处，调整棱镜表面的反射光在纸屏上的亮点和小孔重合，记下此时的平台方位角即为<span class="math inline">\(\alpha_{i=0}\)</span>。<del>能不能搞点正常的下标啊</del></p>
<p><strong>第二步</strong>，<strong>旋转棱镜</strong>使得光束的入射角<span class="math inline">\(\theta_i\)</span>约为55°。旋转2到某个角度可以发现白纸屏上的光点很暗。微调入射角和起偏器，使得光点达到最暗时的平台方位角为<span class="math inline">\(\alpha_B\)</span>。起偏器2的方向角为<span class="math inline">\(P_{\leftrightarrow}\)</span>。<del>能不能搞点正常的下标啊</del></p>
<p><strong>第二步要连做三次</strong>，得到一个平台方位角的平均值<span class="math inline">\(\alpha_B\)</span>，然后布儒斯特角测量值就是<span class="math inline">\(\alpha_{i=0}-\alpha_B\)</span>，然后折射率就是布儒斯特角取一个正切值。此为“4”。</p>
<p><strong>第三步</strong>，如上得到一个起偏器方向角的平均值<span class="math inline">\(P_{\leftrightarrow}\)</span>，把2置于平均值位置。拿走玻璃片，转动3使得光强探测器上电压值最小，此时即为正交消光。在表格里记下3上度盘的度数为<span class="math inline">\(a_\uparrow\)</span>，可以看一下<span class="math inline">\(a_\uparrow\)</span>是否和<span class="math inline">\(P_{\leftrightarrow}\)</span>大约相差<span class="math inline">\(90°\)</span>作为验证，此为“5”。<del>能不能搞点正常的下标啊</del></p>
<p><strong>第四步</strong>，保持偏振器2不动，将3的轮盘角多加<span class="math inline">\(90\)</span>度，从而恢复到二者<span class="math inline">\(x\)</span>轴平行的情况。在此基础上每次加上<span class="math inline">\(0,15,30,45,60,75,80,84,87,90\)</span>度，得到二者<span class="math inline">\(x\)</span>轴的夹角为以上数据。记下对应的电压值，注意夹角为<span class="math inline">\(90\)</span>度时<strong>可以视作已经消光，示数为环境光光强</strong>。此为“6”。</p>
<h4 id="波片的特性研究">波片的特性研究</h4>
<p><strong>第一步</strong>，把3的轮盘角调回<span class="math inline">\(a_\uparrow\)</span>，安装波片<span class="math inline">\(C_0\)</span>到2盘的度盘上，使得<span class="math inline">\(C_0\)</span>上白点处对应的直径大致竖直。微调<span class="math inline">\(C_0\)</span>使得电压示数最小，记录下此时内圈的游标盘示数为<span class="math inline">\(C_0\)</span>，此时有<span class="math inline">\(C_0\)</span>的快轴竖直。此为“7”。</p>
<p><strong>第二步</strong>，<span class="math inline">\(C_0\)</span>不动，在小平台上放上<span class="math inline">\(C_x\)</span>使得光束可以垂直透过。旋转<span class="math inline">\(C_x\)</span>使得电压示数最小，此时<span class="math inline">\(C_x\)</span>的某个轴已经垂直于2的透射轴，达到竖直方向。记下此时<span class="math inline">\(C_x\)</span>的度盘数值，记为<span class="math inline">\(C_x\)</span>。此为“8”。</p>
<p><strong>第三步</strong>，此时二者都不要再动，就有<span class="math inline">\(C_0\)</span>的快轴和<span class="math inline">\(C_x\)</span>的某一个轴平行。保证偏振器2的轮盘角为<span class="math inline">\(P_{\leftrightarrow}\)</span>，偏振器3的轮盘角为<span class="math inline">\(a_\uparrow\)</span>。<strong>然后在此基础上给</strong><span class="math inline">\(P_{\leftrightarrow}\)</span><strong>加上</strong><span class="math inline">\(15°\)</span>，转动3的轮盘角使得二者消光（表现为电压示数最小），记下此时的3度盘角度和转动的差值角度。<strong>每次测量结束后，将偏振器3的轮盘角归回<span class="math inline">\(a_\uparrow\)</span>。</strong></p>
<p>还要再做两次，分别给<span class="math inline">\(P_{\leftrightarrow}\)</span>加上<span class="math inline">\(30°\)</span>和<span class="math inline">\(45°\)</span>，调节3的轮盘角。可以发现3的转动差值和给<span class="math inline">\(P_{\leftrightarrow}\)</span>加上的角度差不多，作为验证。因为这组成了一个<strong>半波片</strong>。此为“9”。</p>
<p><strong>第四步</strong>，转动<span class="math inline">\(C_0\)</span>，给<span class="math inline">\(C_0\)</span>加上90°使得<span class="math inline">\(C_0\)</span>的快轴处于水平位置，和<span class="math inline">\(C_x\)</span>的某一个轴垂直。与第三步类似地求出3的轮盘角增加差值。可以发现3的转动差值约等于给<span class="math inline">\(P_{\leftrightarrow}\)</span>加上的角度取负，作为验证。因为这组成了一个<strong>全波片</strong>。此为“10”。</p>
<p>这几步操作证明了<span class="math inline">\(C_x\)</span>竖直的“某一个轴”其实是<strong>快轴</strong>。</p>
<h4 id="单个frac14波片的特性研究">单个<span class="math inline">\(\frac{1}{4}\)</span>波片的特性研究</h4>
<p><strong>第一步</strong>，取下<span class="math inline">\(C_x\)</span>，把2归回<span class="math inline">\(P_{\leftrightarrow}\)</span>，把3归回<span class="math inline">\(a_\uparrow\)</span>。将2的轮盘角多加<span class="math inline">\(22.5°\)</span>，于是记录下<span class="math inline">\(P=P_{\leftrightarrow}+22.5°\)</span>。调节3使得偏振器3的透射轴与偏振器2的透射轴平行，记下此时的轮盘角<span class="math inline">\(a_i\)</span>。然后转动<span class="math inline">\(C_0\)</span>，分别记录最大的电压值和最小的电压值。</p>
<p>然后，重复第一步，仅把其中的“<span class="math inline">\(22.5°\)</span>”分别改为<span class="math inline">\(45°,67.5°\)</span>实验两次即可。把此过程中的数据都记在表格里，下面的计算暂时先不用管。</p>
<p><strong>第二步</strong>，把光源挡住，记一个系统误差电压值<span class="math inline">\(I_0\)</span>，填在表格边上那个空里面。此为“11”。</p>
<h3 id="测完数据要分析计算什么画哪些图-1">测完数据要分析计算什么？画哪些图？</h3>
<ul>
<li>计算实验元件玻璃的布儒斯特角和折射率。前文已体现。</li>
<li>绘图验证马吕斯定律</li>
</ul>
<p>用表6的数据分析<span class="math inline">\(\frac{I_m-I_{min}}{I_{max}-I_{min}}\)</span>和<span class="math inline">\((\cos
x)^2\)</span>之间的线性关系（即二者相等），并绘制一个以<span class="math inline">\(\theta\)</span>为自变量的图，体现<span class="math inline">\(\frac{I_m-I_{min}}{I_{max}-I_{min}}\)</span>和<span class="math inline">\((\cos x)^2\)</span>两条曲线的变化。其中<span class="math inline">\(I_{min}\)</span>和<span class="math inline">\(I_{max}\)</span>分别代表<span class="math inline">\(\theta\)</span>为<span class="math inline">\(90°\)</span>和<span class="math inline">\(0°\)</span>时的光强测量值。</p>
<ul>
<li>观测偏振光通过半波片和全波片的现象。前文已体现。</li>
<li>线偏振光通过<span class="math inline">\(\frac{1}{4}\)</span>波片</li>
</ul>
<p>其实就是把表格补满的过程。</p>
<p>其中，计算波片相延可以使用<span class="math inline">\(|sin\delta_r|=\frac{2\sqrt{(I_{min}/I_{max})}}{sin(2\beta)(1+I_{min}/I_{max})}\)</span>来计算。三个值都略小于<span class="math inline">\(90°\)</span>。理论值均为<span class="math inline">\(90°\)</span>。</p>
<p>用<span class="math inline">\(\alpha\)</span>计算长轴方位角则有<span class="math inline">\(\psi\)</span>和<span class="math inline">\(\alpha\)</span>相差<span class="math inline">\(90°\)</span>，但要把<span class="math inline">\(\psi\)</span>调到<span class="math inline">\([-90°,90°]\)</span>的范围内。三个理论值分别为<span class="math inline">\(0°,45°,90°\)</span>。</p>
<p>用公式计算长轴方位角，则把<span class="math inline">\(\psi=\frac{1}{2}arctan(tan2\beta
cos\delta)\)</span>代入算一下即可。理论值罗列同上，应该差距不大。</p>
<p>其余分析参考祖传实验报告即可。</p>
<h3 id="本文写作中用到的参考-1">本文写作中用到的参考</h3>
<ul>
<li><p>清华大学2021秋基础物理实验(2)讲义</p></li>
<li><p>清华大学2011级尚恩垚学长的大物实验报告《偏振光学实验》</p></li>
</ul>
<p>（说来惭愧，我一个学基物的，看了别人的大物实验祖传报告，才学会了这个实验x）</p>
<h2 id="塞曼效应实验">塞曼效应实验</h2>
<p>待填坑。</p>
<h2 id="光栅衍射实验">光栅衍射实验</h2>
<p>笔者直到实验结束也没明白这是在做什么。</p>
<p>放一个我自己的实验报告在这里，希望将来的社恐同学们不要再被困扰到了，到期末我会把信息脱敏后上传
GitHub 和课程资源共享计划。<a href="https://cloud.tsinghua.edu.cn/d/9eec91a1826542e79d93/">Click
Here</a></p>
<h1 id="简要报告篇">简要报告篇</h1>
<h2 id="摩擦系数实验">摩擦系数实验</h2>
<p>为什么这学期会有这么个实验...</p>
<p>是新出的题目，暑假期间没有拿到讲义，可能不会写了。</p>
<h2 id="弗兰克-赫兹实验">弗兰克-赫兹实验</h2>
<h3 id="原理简述-2">原理简述</h3>
<p>完全看不懂，拉倒吧。<del>总感觉也不影响实验</del></p>
<h3 id="应该做什么">应该做什么？</h3>
<h4 id="第一次实验的接线">第一次实验的接线</h4>
<p><a href="https://imgtu.com/i/jrORQH"><img src="https://s1.ax1x.com/2022/07/10/jrORQH.png" alt="jrORQH.png"></a></p>
<p>实验仪“放大倍数”档位选择“<span class="math inline">\(×1\)</span>”档，“扫描选择”档位置于“手动”档。打开一体机电脑。参考讲义上的<span class="math inline">\(10(a)\)</span>给实验管箱接线<del>（或者照抄上图）</del>，检查无误后准备通电。</p>
<p>通电时先打开实验仪背后红色按钮，再按下实验仪前面的“灯丝电流开关”（若不按下此按钮，灯丝电流输出为
0A）。然后<strong>在实验仪上调整</strong>灯丝电流在<span class="math inline">\(0.8A\)</span>附近，拒斥场电压在<span class="math inline">\(7.5V\)</span>附近，控制栅电压在<span class="math inline">\(1.5V\)</span>左右。</p>
<h4 id="寻找实验条件">寻找实验条件</h4>
<p>缓慢<strong>在实验仪上增加</strong>扫描电压<span class="math inline">\(U_a\)</span>，观察<strong>板极电流<span class="math inline">\(I_p\)</span>的变化情况</strong>。
当看到其起伏变化时，分别改变<strong>实验仪上</strong>的三个参数，定性观察每个参量对<span class="math inline">\(I_p\)</span>的影响。如果随着<span class="math inline">\(U_a\)</span>的增加在 <span class="math inline">\(0
∼ 85V\)</span> 内能大致观察到<span class="math inline">\(I_p\)</span>有
<span class="math inline">\(6\)</span>
个峰，峰与谷的差别相对比较明显，则达到最佳测试条件。此时把实验仪上的档位切成自动扫描，启动自动采集软件绘制曲线，获取峰值电压。</p>
<p>太抽象了，所以我找了一份实验数据，来自刘丁菡学长，大概这样：</p>
<p><a href="https://imgtu.com/i/jrOWyd"><img src="https://s1.ax1x.com/2022/07/10/jrOWyd.md.png" alt="jrOWyd.md.png"></a></p>
<p>注意以下要点：</p>
<ul>
<li>实验仪上的灯丝电流不能一次改变很大，大概在<span class="math inline">\(0.01∼0.02A\)</span>左右；调整灯丝电流后要等两三分钟再观察<span class="math inline">\(I_p\)</span>的变化，有一个滞后。</li>
<li>扫描电压<span class="math inline">\(U_a\)</span>较大时尽量使用自动挡位测量，用完之后尽快调零。如果出现电流表指针打表，要尽快调小扫描电压，关闭灯丝电流的开关。</li>
</ul>
<h4 id="跟着fh软件教程操作">跟着FH软件教程操作</h4>
<p>按照教程一直做到第三步，第四步校准仪器的时候<strong>输入自动扫描电压</strong><span class="math inline">\(U_a\)</span>的最大值为<span class="math inline">\(90V\)</span>，扫描出完整的<span class="math inline">\(6\)</span>个峰和谷。第五步数据采集模块中选择数据个数为<span class="math inline">\(200\)</span>，点间延时为<span class="math inline">\(100ms\)</span>为最佳。此后一直根据教程行动即可，得到第一份数据。</p>
<h4 id="定性研究的操作">定性研究的操作</h4>
<p>保持灯丝电流和拒斥电压不动，改变控制栅电压在<span class="math inline">\(1.0V,1.5V,2.0V,2.5V,3.0V\)</span>这些值上变化，扫出曲线。</p>
<p>保持灯丝电流和控制栅电压不动，改变拒斥电压在<span class="math inline">\(5.0V,6.0V,7.0V,8.0V,9.0V\)</span>这些值上变化，扫出曲线。</p>
<h4 id="氩原子更高激发态的情况">氩原子更高激发态的情况</h4>
<p><del>这一次是两人一组，等待大佬救我</del></p>
<p>类似的操作，把亚克力板接进电路，设定最佳实验条件。<strong>在软件上调整扫描电压最大值为<span class="math inline">\(30V\)</span></strong>​。<strong>在实验仪上调整</strong>灯丝电流在<span class="math inline">\(0.78A\)</span>附近，控制栅电压在<span class="math inline">\(1.5V\)</span>左右。拒斥场电压分别调整为<span class="math inline">\(2.0V,2.5V,3.0V\)</span>。类似扫描出<span class="math inline">\(I_p-U_a\)</span>的归一化和非归一化曲线。</p>
<p>注意以下的要点：</p>
<ul>
<li>只需要图上有两个峰。第二个峰大约出现在<span class="math inline">\(25V\)</span>左右，因此最大扫描电压只需要<span class="math inline">\(30V\)</span>。而且<span class="math inline">\(I_p\)</span>的最大峰值对应不超过<span class="math inline">\(50\mu A\)</span>。</li>
<li>祖传报告中指出这一步实验仪上的另两个参数保持不变即可，和讲义不是很一样。<strong>我倾向于相信祖传报告。</strong></li>
</ul>
<p>实验结束后可以断开其他元件的连接，整理仪器，处理自己的数据。</p>
<h3 id="测完数据要分析计算什么">测完数据要分析计算什么？</h3>
<h4 id="测试i_p-u_a曲线得到氩原子第一激发电位">测试<span class="math inline">\(I_p-U_a\)</span>曲线，得到氩原子第一激发电位</h4>
<p>找到第一部分数据的 Excel 表格 Data
页，取六个峰值的电压数据和测量次数（注意舍去一看就不对的值），到 Origin
里拟合数据。由于曲线上相邻两峰值之间的电位差就是氩原子的第一激发电<span class="math inline">\(U_g\)</span>，因此处理得到的斜率就是第一激发电位。</p>
<p>太抽象了，这是一张示例处理表格，来自刘丁菡学长，其中的 <span class="math inline">\(Slope-Value\)</span> 就是所需要的值。</p>
<p><a href="https://imgtu.com/i/jrO2Se"><img src="https://s1.ax1x.com/2022/07/10/jrO2Se.png" alt="jrO2Se.png"></a></p>
<p>关于不确定度的计算，公式都在下面了：</p>
<p><span class="math display">\[\Delta_A=S_b=b\sqrt{\frac{2(1-R^2)}{n-2}}\]</span></p>
<p><span class="math display">\[\Delta_B=0.001×b+0.01\]</span></p>
<p><span class="math display">\[U_g=(b±\Delta_{U_g})\]</span></p>
<p>其中<span class="math inline">\(b\)</span>是斜率，<span class="math inline">\(R^2\)</span>是拟合的最后一列方差，<span class="math inline">\(n\)</span>是实验次数（即为<span class="math inline">\(6\)</span>），<span class="math inline">\(\Delta_{U_g}\)</span>是两个系差平方和的开方。</p>
<h4 id="氩原子受击后回到基态辐射出的光波波长">氩原子受击后回到基态辐射出的光波波长</h4>
<p>套下面两个公式：</p>
<p><span class="math display">\[\lambda=\frac{hc}{eU_g}\]</span></p>
<p><span class="math display">\[\Delta_\lambda=\lambda\frac{\Delta_{U_g}}{U_g}\]</span></p>
<p>实验中观测不到发光是因为这是紫外波段而不是可见光波段，也因此用壳罩住了管子防止对人体造成伤害。</p>
<h4 id="定性研究栅极电压和拒斥电压对i_p的影响">定性研究栅极电压和拒斥电压对<span class="math inline">\(I_p\)</span>的影响</h4>
<p>控制栅电压的影响：由图可知，从峰值对应的扫描电压上看，随着 <span class="math inline">\(U_G\)</span> 值的增大，曲线中峰
值所对应的扫描电压值稍向左偏移；从峰值的相对大小来看，随着 <span class="math inline">\(U_G\)</span> 值的增大，峰值先增大后减小，在 <span class="math inline">\(U_G≈ 2.0V\)</span>
附近能观测到峰值最大，说明此时单位时间到达极板的电子最多。
理论解释见祖传报告，反正我也写不出来。例图如下，来自刘丁菡学长：</p>
<p><a href="https://imgtu.com/i/jrOcWD"><img src="https://s1.ax1x.com/2022/07/10/jrOcWD.md.png" alt="jrOcWD.md.png"></a></p>
<p>拒斥电压的影响：由图可知，随着 <span class="math inline">\(U_R\)</span>
值的增大，曲线绝对值下移、峰谷值之间的差距变
大、曲线中峰值所对应的扫描电压值稍向右偏移。理论解释见祖传报告，反正我也写不出来。例图如下，来自刘丁菡学长：</p>
<p><a href="https://imgtu.com/i/jrO6JO"><img src="https://s1.ax1x.com/2022/07/10/jrO6JO.md.png" alt="jrO6JO.md.png"></a></p>
<h4 id="更高激发态的研究">更高激发态的研究</h4>
<p>例图如下，来自刘丁菡学长。<span class="math inline">\(U_R\)</span>
整体对曲线的影响与第一激发态是类似的，即随着 <span class="math inline">\(U_R\)</span>
的增大，曲线整体下移，峰谷差值增大，峰值向右移动。但差别在于曲线的形状有所不同，即没有出现很明显的一个峰值，而是峰值附近有一个小平台。理论解释见祖传报告，反正我也写不出来。</p>
<p><a href="https://imgtu.com/i/jrOfOA"><img src="https://s1.ax1x.com/2022/07/10/jrOfOA.md.png" alt="jrOfOA.md.png"></a></p>
<h4 id="解答思考题">解答思考题</h4>
<p>见祖传报告。</p>
<h3 id="本文写作中用到的参考-2">本文写作中用到的参考</h3>
<ul>
<li>清华大学2020级刘丁菡学长的基物实验报告《弗兰克-赫兹实验》</li>
</ul>
<p>感谢学长的图救我老命，不然这个实验真的看不懂在干嘛...</p>
<h2 id="几何光学系列实验">几何光学系列实验</h2>
<p>不喜欢系列实验，真的好麻烦。</p>
<h3 id="原理简述-3">原理简述</h3>
<p><del>会算相似三角形就行</del></p>
<ul>
<li>薄透镜的成像规律</li>
</ul>
<p>经典公式：<span class="math inline">\(\frac{1}{f}=\frac{1}{p}+\frac{1}{q}\)</span>，其中
<span class="math inline">\(p\)</span>,<span class="math inline">\(q\)</span> 分别代表物距和像距；<span class="math inline">\(\beta=-\frac{q}{p}\)</span>称为线放大率。</p>
<p>它们有很多正负性质的要求：前三者实物/实像/凸透镜为正，虚物/虚像/凹透镜为负，<span class="math inline">\(\beta\)</span>在实像时为负，虚像时为正。</p>
<ul>
<li>内调焦望远镜</li>
</ul>
<p>望远镜是由一个物镜一个目镜组成的。当我们用一组物镜组替代物镜时，不必移动物镜和目镜间的距离<span class="math inline">\(l\)</span>，而是直接改变物镜组的焦距即可达到整体调焦的效果。这就叫做内调焦望远镜。</p>
<p>实验中用到的物镜组是一个凸透镜<span class="math inline">\(L_1\)</span>和一个凹透镜<span class="math inline">\(L_2\)</span>组成的。这是一个最简单的变焦<del>物竞组</del>物镜组。原理是<span class="math inline">\(L_2\)</span>的物方焦点在<span class="math inline">\(L_1\)</span>的像方焦点右侧时，改变两个透镜的间距<span class="math inline">\(d\)</span>就能达到内部调焦的效果。此时取二者的“正焦距”（我不太会描述）为<span class="math inline">\(f_1&#39;\)</span>和<span class="math inline">\(f_2\)</span>，物镜的组合焦距即为<span class="math inline">\(f_o&#39;=\frac{f_1&#39;f_2}{d+f_2-f_1&#39;}\)</span>。要求满足<span class="math inline">\(f_1&#39;-f_2&lt;d&lt;f_1&#39;\)</span>才能如上调节。</p>
<p>我们把目镜的焦距记作<span class="math inline">\(f_e\)</span>。望远镜的视放大率即为<span class="math inline">\(\Gamma_T=-\frac{f_o}{f_e}\)</span>。这个数值的绝对值越大，观察到的像越大。比如说，观察远物的时候可以通过调小<span class="math inline">\(d\)</span>来放大<span class="math inline">\(f_o\)</span>，观察近物的时候不想改变物镜组和目镜组之间的距离，直接放大<span class="math inline">\(d\)</span>即可。</p>
<h3 id="应该做什么-1">应该做什么？</h3>
<h4 id="a0.薄透镜成像规律">A0.薄透镜成像规律</h4>
<p>为了满足近轴光线条件，要进行共轴调节。</p>
<p>粗调的时候，先把光源，物，透镜靠拢，调节到中心大约在一条平行于导轨的直线上。总之怎么看着舒服就怎么调。</p>
<p>细调的原理是<del>大象追小象</del>大像追小像。当物与像的距离大于 <span class="math inline">\(4f\)</span>
时，凸透镜从物移到像的过程中会成两次清晰的像，一大一小。<strong>要做的就是</strong>移动像和透镜的位置，使得<span class="math inline">\(B_1\)</span>追上<span class="math inline">\(B_2\)</span>，也即两个像差不多大，这可以通过像屏上的坐标贴纸判断。此时像在透镜的主光轴上。</p>
<p><a href="https://imgtu.com/i/jrwiY4"><img src="https://s1.ax1x.com/2022/07/09/jrwiY4.png" alt="jrwiY4.png"></a></p>
<p>不要动平行光管，就是那个<del>挺长的不认识的东西。</del>此处无记录要求。</p>
<h4 id="b1.物像距法测量薄凸透镜焦距">B1.物像距法测量薄凸透镜焦距</h4>
<p>这很明示了，读个数据套公式就行。</p>
<h4 id="b2.共轭法测量薄凸透镜焦距">B2.共轭法测量薄凸透镜焦距</h4>
<p>读个数据套另一个公式：<span class="math inline">\(f=\frac{b^2-a^2}{4b}\)</span>，其中 <span class="math inline">\(a\)</span> 指两次透镜位置间距离。</p>
<h4 id="b3.焦距仪法测薄凸透镜焦距">B3.焦距仪法测薄凸透镜焦距</h4>
<p>读六组数据写在表格上，比较麻烦的是算不确定度。这一部分已经在讲义和实验表上详细手写了，照做即可，不再打一遍了。</p>
<h4 id="c1.主面间距测量">C1.主面间距测量</h4>
<p><a href="https://imgtu.com/i/jrwAp9"><img src="https://s1.ax1x.com/2022/07/09/jrwAp9.md.png" alt="jrwAp9.md.png"></a></p>
<p>5中的C.2应为B.3。不过我不太懂怎么通过这几个参数算主面间距，好怪。<strong>此处留坑。</strong></p>
<h4 id="c2.修正共轭法系差">C2.修正共轭法系差</h4>
<p>again，算就对了。</p>
<h4 id="d.用焦距仪测凸透镜的焦距的附加透镜法">D.用焦距仪测凸透镜的焦距的附加透镜法</h4>
<p>这个讲义上也说的挺清楚的。注意先给玻罗板取某一线对记录下来，第一步和第二步要用一样的线对<del>（废话）</del>。</p>
<p>最后的凹透镜焦距是<span class="math inline">\(f_2=-\frac{f_1
y_0}{y&#39;&#39;}\)</span>，由于是凹透镜的原因，焦距记为负的。</p>
<h4 id="e.内调焦望远镜的物镜组研究">E.内调焦望远镜的物镜组研究</h4>
<p><strong>第一步</strong>，分别对物镜组中的凹凸透镜进行共轴调节，用焦距仪法测此组光具焦距值<span class="math inline">\(f_o&#39;\)</span>作为物镜焦距。反推得到此时凹凸透镜的距离<span class="math inline">\(d=\frac{f_2f_1&#39;}{f_o&#39;}+f_1&#39;-f_2\)</span>。其中，由于凹凸透镜的焦距已经在B和D实验中测出，直接取用其值即可。</p>
<p><strong>第二步</strong>，改变凹凸透镜距离使得长焦透镜<span class="math inline">\(L_1\)</span>距离测微目镜约<span class="math inline">\(10cm\)</span>。得到第二个测量值。</p>
<p><strong>第三步</strong>，分别假设凹凸透镜的焦距，然后画一个类似下图的图。</p>
<p><a href="https://imgtu.com/i/jrwFfJ"><img src="https://s1.ax1x.com/2022/07/09/jrwFfJ.md.png" alt="jrwFfJ.md.png"></a></p>
<p>这张图的逻辑是：以纵轴表示自变量<span class="math inline">\(d\)</span>，横轴表示四个因变量。其计算公式分别为：</p>
<p><span class="math display">\[l_{L_1H}=-\frac{f_1&#39;d}{d+f_2-f_1&#39;}\]</span></p>
<p><span class="math display">\[l_{L_1H&#39;}=-\frac{d(d-f_1&#39;)}{d+f_2-f_1&#39;}\]</span></p>
<p><span class="math display">\[F&#39;=l_{L_1H&#39;}+f_o&#39;\]</span></p>
<p><span class="math display">\[F=l_{L_1H}-f_o&#39;\]</span></p>
<p>其中，凸透镜<span class="math inline">\(f_1&#39;=0.3m\)</span>,凹透镜<span class="math inline">\(f_2=0.2m\)</span>。<del>所以这个图是不是实验之前就能画出来</del></p>
<h3 id="本文写作中用到的参考-3">本文写作中用到的参考</h3>
<ul>
<li>透镜焦距实验-仪器详解</li>
</ul>
<p>https://www.bilibili.com/video/BV163411q7NP?spm_id_from=333.999.0.0&amp;vd_source=6ae5c31a80120436d23cf7b7c7ceb3ba</p>
<ul>
<li>清华大学2011级耿强学长的大物实验报告《透镜焦距的测定》P181</li>
</ul>
<h1 id="写在最后">写在最后</h1>
<p>我一向把物理实验当成“可以摆弄仪器的好玩的课”，高中学竞赛的时候就羡慕物化生竞赛的同学可以做实验<del>，我们只能一直待在教室里写题</del>。但是哪怕基物实验
1 拿了
A-，对于实验的原理仍然不甚了解。到最后每学期六次做实验三次写报告成为了生活中的调剂，不用太动脑子就能写出一大片东西，好像自己很努力一样。</p>
<p>在 Overleaf 上无意间找到了<a href="https://www.overleaf.com/latex/templates/thu-emp-qing-hua-da-xue-jin-dai-wu-li-shi-yan-bao-gao-mo-ban/mbgqcryqhwqd">清华大学近代物理实验报告模板</a>。朱老师的要求和这个还是很不一样。发现也没有用于普通实验的模板，于是改了改我的自用模板，还行。</p>
<p>GitHub
地址：https://github.com/Chiyuru/THU-Fundamental-Physics-Report</p>
<p><del>但是用 LaTeX 写实验报告的人哪个没有自己的模板啊</del></p>
<p><del>您又在假装干活了是吗</del></p>
]]></content>
      <tags>
        <tag>课程实录</tag>
      </tags>
  </entry>
  <entry>
    <title>多元问题对我来说太难了，但是多元统计分析</title>
    <url>/2023/02/25/Multivariate-Statistical-Analysis/</url>
    <content><![CDATA[<p>既然线性回归都写了，怎么能没有多元统计呢（？</p>
<p>其实是在课上同步写笔记体验很不错，dwl
老师的风格一如既往的稳健，课堂节奏正好。在课上敲笔记总比摸鱼好。</p>
<span id="more"></span>
<h1 id="lecture-1">Lecture 1</h1>
<p>吹水，然后讲了点基本概念。</p>
<h2 id="多元数据的组织">多元数据的组织</h2>
<p>对于多元数据，常见的形式是一个 population 中的样本个体（称为
item）有不同的项，每个 item 呈现出 p 个 variable 的取值。我们每次在
population 中抽样会取出 <span class="math inline">\(n\)</span> 个
item，实际上获得了 <span class="math inline">\(np\)</span> 个数据。</p>
<p>一般用矩阵组织二元数据，以随机变量作为列元素，把 population 中的 item
作为横行。也就是说 <span class="math inline">\(n\)</span> 个 item 各自有
p 个随机变量项目的情况下，可以把它组织成 <span class="math inline">\(n
\times p\)</span> 尺寸的表格：</p>
<table>
<colgroup>
<col style="width: 11%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 7%">
<col style="width: 18%">
<col style="width: 7%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Variable 1</th>
<th>Variable 2</th>
<th>...</th>
<th>Variable i</th>
<th>...</th>
<th>Variable p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Item 1</td>
<td><span class="math inline">\(x_{11}\)</span></td>
<td><span class="math inline">\(x_{12}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{1i}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{1p}\)</span></td>
</tr>
<tr class="even">
<td>Item 2</td>
<td><span class="math inline">\(x_{21}\)</span></td>
<td><span class="math inline">\(x_{22}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{2i}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{2p}\)</span></td>
</tr>
<tr class="odd">
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="even">
<td>Item j</td>
<td><span class="math inline">\(x_{j1}\)</span></td>
<td><span class="math inline">\(x_{j2}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{ji}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{jp}\)</span></td>
</tr>
<tr class="odd">
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="even">
<td>Item n</td>
<td><span class="math inline">\(x_{n1}\)</span></td>
<td><span class="math inline">\(x_{n2}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{ni}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{np}\)</span></td>
</tr>
</tbody>
</table>
<p>实际上就是一个 <span class="math inline">\(n \times p\)</span>
大小的矩阵，每个 <span class="math inline">\(X_{ji}\)</span>
都可以视作随机变量。因此，每一次从 population 中随机抽样出 <span class="math inline">\(n\)</span> 个
item，都能得到一个不同的多元数据矩阵作为 observed data，在 multivariate
statistics 中，observed data 一般是矩阵。</p>
<p>更本质地，可以把一个随机矩阵视为 <span class="math inline">\(n\)</span> 个随机向量，每个随机向量代表了一个 item
的具体分量数据。并且可以认为这 <span class="math inline">\(n\)</span> 个
items 是彼此独立的（<span class="math inline">\(n\)</span>
次独立的取样），于是可以认为 joint distribution 是 <span class="math inline">\(n\)</span> 个 PDF 之积。</p>
<h2 id="描述性统计量">描述性统计量</h2>
<p>老生常谈了捏。对于上述的 observed data，可以纵向观察各个 variable
的性质。</p>
<ul>
<li><p>列均值/sample mean ：<span class="math inline">\(\bar{x_k} =
\frac{1}{n} \Sigma_{i=1}^{n} x_{ik}\)</span>，<span class="math inline">\(k=1,2,...,p\)</span></p>
<p>直观来说体现了分布的位置。</p></li>
<li><p>列方差/sample variance ：<span class="math inline">\(s_k ^2 =
s_{kk} = \frac{1}{n} \Sigma_{i=1}^n (x_{ik}-\bar{x_k})^2\)</span>，<span class="math inline">\(k=1,2,...,p\)</span></p>
<p>直观来说体现了分布的分散程度。</p>
<p>实际上，可以看到此处列方差的系数是 <span class="math inline">\(\frac{1}{n}\)</span> 而不是传统的 <span class="math inline">\(\frac{1}{n-1}\)</span>，这是由使用场景决定的。在统计推断中，如果需要无偏统计量则使用
<span class="math inline">\(\frac{1}{n-1}\)</span>，如果需要极大似然估计（MLE）则使用
<span class="math inline">\(\frac{1}{n}\)</span>。尤其是样本量 <span class="math inline">\(n\)</span>
很大的情况下，二者的差别并不大，可以不做严格的区分。</p></li>
<li><p>协方差，相关系数：直观上来说体现了线性相关性，相关系数为正则正相关，否则负相关，为
<span class="math inline">\(0\)</span> 不相关。</p>
<p>协方差定义为 <span class="math inline">\(s_{ik} = \frac 1 n
\Sigma_{j=1}^n (x_{ji} - \bar{x_i}) (x_{ji} -
\bar{x_k})\)</span>，可以看到实际上 <span class="math inline">\(s_{ik} =
s_{ki}\)</span>，于是协方差矩阵有</p>
<p><span class="math display">\[ \begin{bmatrix} s_{11} &amp; s_{12}
&amp; ...&amp; s_{1p}\\ s_{21} &amp; s_{22} &amp; ...&amp; s_{2p} \\ ...
&amp; ...&amp;...&amp;... \\ s_{p1} &amp; s_{p2} &amp;...&amp;s_{pp}
\end{bmatrix}\]</span></p>
<p>的形式，这是一个对角元为正的对称矩阵。</p>
<p>类似地，相关系数定义为 $_{ik} = { } $
的形式，也有对应的协方差矩阵，是一个对角元均为 <span class="math inline">\(1\)</span> 的对称矩阵。</p></li>
</ul>
<p>也可以由随机向量矩阵得到相应的 sample mean 向量和 sample variance
向量。</p>
<h2 id="mahalanobis-distance">Mahalanobis Distance</h2>
<p>用来判断不同 item 的 的“距离”，从来衡量两组数据的相似性。实际上不同的
variance 有不同的量纲，我们想比较不同 item 的差异，需要把 variance
的量纲“统一”来计算二者的差异。使用 Mahalanobis distance 来计算。</p>
<p>假设两个 item 的数据值分别是 <span class="math inline">\(P =
(x_1,x_2,...,x_p),Q= (y_1,y_2,...,y_p)\)</span>，记整体 sample mean
向量为 <span class="math inline">\(\mu =
(\mu_1,\mu_2,...,\mu_p)\)</span>，协方差矩阵为 <span class="math inline">\(\Sigma\)</span>。在不同的使用场景下，Mahalanobis
distance 有不同的形式，主要在以下方面处理了差异：</p>
<ul>
<li><p>通过给差值除掉此维度数据的协方差，来规范尺度差异。本质上是个仿射变换。</p>
<p><span class="math inline">\(d(P,Q) = \sqrt{\frac{(x_1 -
y_1)^2}{s_{11} } + \frac{(x_2 - y_2)^2}{s_{22} } + ... +\frac{(x_p -
y_p)^2}{s_{pp} } }\)</span></p></li>
<li><p>希望能够用二次型的形式直观表述 <span class="math inline">\(P\)</span> 和 <span class="math inline">\(Q\)</span>，或者 <span class="math inline">\(P\)</span> 和 <span class="math inline">\(\mu\)</span> 之间的差异。</p>
<p><span class="math inline">\(d(P,\mu) = \sqrt{(x-\mu) ^T \Sigma ^{-1}
(x-\mu)}\)</span></p>
<p><span class="math inline">\(d(P,Q) = \sqrt{(x-y)^T \Sigma^{-1}
(x-y)}\)</span></p></li>
</ul>
<p>此外还有两个结论：</p>
<ul>
<li><p>设 <span class="math inline">\(Z\)</span>
是一个随机向量，记它的均值向量为 <span class="math inline">\(\mu
_Z\)</span>，协方差矩阵为 <span class="math inline">\(\Sigma
_Z\)</span>，二者均有限。<span class="math inline">\(A\)</span>
是任意的对称矩阵。于是有 <span class="math inline">\(E[Z^T AZ] =
trace(A\Sigma_Z) + \mu_Z ^T A \mu_Z\)</span>。</p>
<p><strong>Proof</strong>:考虑迹的性质。<span class="math inline">\(E[Z^T AZ] = tr(E[Z^T AZ]) = E[tr(Z^TAZ)] =
E[tr(AZZ^T)] = tr(E[AZZ^T]) = tr(AE[ZZ^T])\)</span>，由<span class="math inline">\(Z\)</span> 是随机向量，<span class="math inline">\(E[ZZ^T] = (\Sigma_Z + \mu_Z ^T \mu_Z)\)</span>，故
<span class="math inline">\(tr(AE[ZZ^T]) = tr(A\Sigma_Z) + tr(A\mu_Z
\mu_Z^T) = trace(A\Sigma_Z) + \mu_Z ^T A \mu_Z\)</span>。</p></li>
<li><p>2-范数的期望：<span class="math inline">\(p\)</span> 阶随机向量
<span class="math inline">\(X\)</span> 有有限的均值向量 <span class="math inline">\(\mu\)</span> 和协方差矩阵 <span class="math inline">\(\Sigma\)</span>，于是 <span class="math inline">\(E[|| X - \mu ||_2 ^2] = \Sigma_{i=1} ^p
\sigma_{ii}\)</span>。</p>
<p><strong>Proof</strong>: 在上一个结论中取 <span class="math inline">\(A=I\)</span>，于是 <span class="math inline">\(E[|| X - \mu ||_2 ^2] = E[(X-\mu )^T I (X-\mu)] =
tr(I\Sigma) = \Sigma_{i=1} ^p \sigma_{ii}\)</span>。</p>
<p><strong>Remark</strong>: 对于独立同分布的 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span>，有相同的均值向量和协方差矩阵，于是
<span class="math inline">\(E[||X-Y||_2^2] = 2 \Sigma _{i=1} ^p \sigma
_{ii}\)</span>。</p></li>
</ul>
<p>最后来考虑 Mahalanobis distance 的期望。<span class="math inline">\(p\)</span> 阶随机向量 <span class="math inline">\(X\)</span> 有有限的均值向量 <span class="math inline">\(\mu\)</span> 和协方差矩阵 <span class="math inline">\(\Sigma\)</span>，其 Mahalanobis distance 定义为
<span class="math inline">\(||X- \mu ||_\Sigma = d(X,\mu) =
\sqrt{(X-\mu)^T \Sigma^{-1} (X-\mu)}\)</span>，利用上述结论则 <span class="math inline">\(E[||X- \mu ||_\Sigma ^2] = p\)</span>。</p>
<p>同理，对于独立同分布的 <span class="math inline">\(X\)</span> 和
<span class="math inline">\(Y\)</span>，有 <span class="math inline">\(E[||X-Y||_\Sigma ^2] = 2p\)</span>。</p>
<h2 id="exploratory-data-analysis-eda">Exploratory Data Analysis
(EDA)</h2>
<p>这个其实在线性回归课上也学过，主要讲的是数据清洗的原则和方法，也没有什么很实际的内容，感觉在扯皮。wljj
的课上比较注重解释一些看起来很炫酷的图是怎么画的，真的很应用。</p>
<p>这个能用 RMarkdown 写的话就好了，Typora 什么时候能支持
RMarkdown（暴论</p>
<h3 id="boxplot">Boxplot</h3>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">data <span class="operator">=</span> matrix<span class="punctuation">(</span><span class="number">0</span><span class="punctuation">,</span>nrow<span class="operator">=</span><span class="number">12</span><span class="punctuation">,</span>ncol<span class="operator">=</span><span class="number">2</span><span class="punctuation">)</span></span><br><span class="line">data<span class="punctuation">[</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">,</span><span class="number">4</span><span class="punctuation">,</span><span class="number">4</span><span class="punctuation">,</span><span class="number">5</span><span class="punctuation">,</span><span class="number">8</span><span class="punctuation">,</span><span class="number">8</span><span class="punctuation">,</span><span class="number">9</span><span class="punctuation">,</span><span class="number">10</span><span class="punctuation">,</span><span class="number">10</span><span class="punctuation">,</span><span class="number">12</span><span class="punctuation">,</span><span class="number">13</span><span class="punctuation">)</span> <span class="comment"># dataset 1</span></span><br><span class="line">data<span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">,</span><span class="number">4</span><span class="punctuation">,</span><span class="number">4</span><span class="punctuation">,</span><span class="number">5</span><span class="punctuation">,</span><span class="number">8</span><span class="punctuation">,</span><span class="number">8</span><span class="punctuation">,</span><span class="number">9</span><span class="punctuation">,</span><span class="number">10</span><span class="punctuation">,</span><span class="number">10</span><span class="punctuation">,</span><span class="number">12</span><span class="punctuation">,</span><span class="number">19</span><span class="punctuation">)</span> <span class="comment"># dataset 2</span></span><br><span class="line"></span><br><span class="line">boxplot<span class="punctuation">(</span>data<span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2023/02/25/CU1SBYayWI3MHDO.png" alt="box.png"></p>
<p>（假装在用 Rmd（</p>
<p>boxplot 包含了很多信息。盒子的上边表示数据中的 75% 分位数，下边表示
25% 分位数，盒子中间的线表示中位数。我们将 75% 分位数和 25%
分位数的差记作 IQR，则盒子上边距离最上方的“触角”的距离是 1.5
IQR，下边同理。</p>
<p>对于正态分布来说，两个触角之间的距离表示了所有正常数据的范围，离开这个范围的数据基本上是
out of 3<span class="math inline">\(\sigma\)</span> 的，可以直观地去除
outlier。</p>
<p>在 R 的绘图中会将上“触角”的值定为 75% quantile + 1.5 IQR
和最大数据之间的较大值，下“触角”同理，因此在上面的这个例子里，两组数据的
25% quantile 和 75% quantile 都是相同的，绘图结果有差别。</p>
<h3 id="histogram">Histogram</h3>
<p>柱状图的宽度还是有讲究的，适当的宽度可以看出分布的形状。通用的是
<span class="math inline">\(h =( \frac{24\sqrt{\pi} } {n})^{\frac{1}{3}
}\)</span>。</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">hist<span class="punctuation">(</span>mpg<span class="operator">$</span>hwy<span class="punctuation">,</span>main <span class="operator">=</span> <span class="string">&quot;Histogram of highway miles per gallon&quot;</span><span class="punctuation">,</span>breaks <span class="operator">=</span> <span class="built_in">round</span><span class="punctuation">(</span><span class="built_in">max</span><span class="punctuation">(</span>mpg<span class="operator">$</span>hwy<span class="punctuation">)</span><span class="operator">-</span><span class="built_in">min</span><span class="punctuation">(</span>mpg<span class="operator">$</span>hwy<span class="punctuation">)</span><span class="operator">/</span><span class="punctuation">(</span><span class="number">24</span><span class="operator">*</span><span class="built_in">sqrt</span><span class="punctuation">(</span><span class="built_in">pi</span><span class="punctuation">)</span><span class="operator">/</span><span class="built_in">length</span><span class="punctuation">(</span>mpg<span class="operator">$</span>hwy<span class="punctuation">)</span><span class="punctuation">)</span><span class="operator">^</span><span class="punctuation">(</span><span class="number">1</span><span class="operator">/</span><span class="number">3</span><span class="punctuation">)</span><span class="punctuation">)</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2023/02/25/hMJW9TKGEmcptCa.png" alt="hist.png"></p>
<h3 id="scatter-plot">Scatter Plot</h3>
<p>散点图有很 fancy 的版本，这里展示一些实现：</p>
<ul>
<li><p>Scatter Plot</p>
<p>放一个我线性回归作业里的图罢。</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">men <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">72.5</span><span class="punctuation">,</span><span class="number">71.5</span><span class="punctuation">,</span><span class="number">70.5</span><span class="punctuation">,</span><span class="number">69.5</span><span class="punctuation">,</span><span class="number">68.5</span><span class="punctuation">,</span><span class="number">67.5</span><span class="punctuation">,</span><span class="number">66.5</span><span class="punctuation">,</span><span class="number">65.5</span><span class="punctuation">,</span><span class="number">64.5</span><span class="punctuation">)</span></span><br><span class="line">brothers <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">71.1</span><span class="punctuation">,</span><span class="number">70.2</span><span class="punctuation">,</span><span class="number">69.6</span><span class="punctuation">,</span><span class="number">69.5</span><span class="punctuation">,</span><span class="number">68.7</span><span class="punctuation">,</span><span class="number">67.7</span><span class="punctuation">,</span><span class="number">67.0</span><span class="punctuation">,</span><span class="number">66.5</span><span class="punctuation">,</span><span class="number">65.6</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">p <span class="operator">=</span> plot.default<span class="punctuation">(</span>men<span class="punctuation">,</span>brothers<span class="punctuation">,</span>xlim <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">63</span><span class="punctuation">,</span><span class="number">73</span><span class="punctuation">)</span><span class="punctuation">,</span>ylim<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">65</span><span class="punctuation">,</span><span class="number">72</span><span class="punctuation">)</span><span class="punctuation">,</span>main <span class="operator">=</span> <span class="string">&#x27;Heights of men and their brothers&#x27;</span><span class="punctuation">,</span>xlab <span class="operator">=</span> <span class="string">&#x27;medium heights of the men&#x27;</span><span class="punctuation">,</span>ylab <span class="operator">=</span> <span class="string">&#x27;medium heights of the brothers&#x27;</span><span class="punctuation">,</span>col <span class="operator">=</span> <span class="string">&quot;blue&quot;</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">abline<span class="punctuation">(</span>lm<span class="punctuation">(</span>brothers<span class="operator">~</span>men<span class="punctuation">)</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2023/02/25/I6NaJMgb7L8RiYr.png" alt="plt.png"></p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">lm<span class="punctuation">(</span>brothers<span class="operator">~</span>men<span class="punctuation">)</span></span><br></pre></td></tr></table></figure></li>
<li><p>Scatter Plot Matrix</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">library<span class="punctuation">(</span>GGally<span class="punctuation">)</span></span><br><span class="line">lizard<span class="operator">&lt;-</span>read.csv<span class="punctuation">(</span><span class="string">&#x27;t1-3.dat&#x27;</span><span class="punctuation">,</span>sep<span class="operator">=</span><span class="string">&#x27;&#x27;</span><span class="punctuation">,</span>header<span class="operator">=</span><span class="built_in">F</span><span class="punctuation">)</span></span><br><span class="line"><span class="built_in">names</span><span class="punctuation">(</span>lizard<span class="punctuation">)</span><span class="operator">&lt;-</span><span class="built_in">c</span><span class="punctuation">(</span><span class="string">&#x27;mass&#x27;</span><span class="punctuation">,</span><span class="string">&#x27;svl&#x27;</span><span class="punctuation">,</span><span class="string">&#x27;hls&#x27;</span><span class="punctuation">)</span></span><br><span class="line">ggpairs<span class="punctuation">(</span>lizard<span class="punctuation">,</span>title <span class="operator">=</span> <span class="string">&#x27;scatter plot matrix of lizard&#x27;</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2023/02/25/KibpxcuaedowJLO.png" alt="spm.png"></p></li>
<li><p>3D Scatter Plot</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">library<span class="punctuation">(</span>scatterplot3d<span class="punctuation">)</span></span><br><span class="line">data<span class="punctuation">(</span>iris<span class="punctuation">)</span></span><br><span class="line">head<span class="punctuation">(</span>iris<span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">scatterplot3d<span class="punctuation">(</span>iris<span class="punctuation">[</span><span class="punctuation">,</span><span class="number">1</span><span class="operator">:</span><span class="number">3</span><span class="punctuation">]</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2023/02/25/S3V5gv7AYCD4Efy.png" alt="3d1.png"></p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">colors <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">&quot;#999999&quot;</span><span class="punctuation">,</span><span class="string">&quot;#E69F00&quot;</span><span class="punctuation">,</span><span class="string">&quot;#56B4E9&quot;</span><span class="punctuation">)</span></span><br><span class="line">colors <span class="operator">&lt;-</span> colors<span class="punctuation">[</span><span class="built_in">as.numeric</span><span class="punctuation">(</span>iris<span class="operator">$</span>Species<span class="punctuation">)</span><span class="punctuation">]</span></span><br><span class="line"></span><br><span class="line">scatterplot3d<span class="punctuation">(</span>iris<span class="punctuation">[</span><span class="punctuation">,</span><span class="number">1</span><span class="operator">:</span><span class="number">3</span><span class="punctuation">]</span><span class="punctuation">,</span>pch<span class="operator">=</span><span class="number">16</span><span class="punctuation">,</span>color<span class="operator">=</span>colors<span class="punctuation">,</span>main<span class="operator">=</span><span class="string">&#x27;3D scatter plot of iris flower&#x27;</span><span class="punctuation">,</span> grid<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">,</span> box<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">,</span> type<span class="operator">=</span><span class="string">&quot;h&quot;</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p><img src="https://s2.loli.net/2023/02/25/pRaLXMxUrKqOi5Q.png" alt="3d2.png"></p>
<h1 id="lecture-2">Lecture 2</h1>
<p>介绍了一些矩阵方法，以及复习线性代数。</p>
<h2 id="linear-algebra">Linear Algebra</h2>
<p>什么嘛，我线代学得还可以嘛（喜</p>
<p>矩阵分解的复习就跳过了，也就那点东西，主要是谱分解和奇异值分解。</p>
<h3 id="matrix-interpretation-of-mahalanobis-distance">Matrix
Interpretation of Mahalanobis-distance</h3>
<p>注意一些左乘矩阵代表的意义，比如在 Mahalanobis
距离中常用的处理方式是旋转和伸缩，二者分别可以左乘一个正交矩阵/对角矩阵来完成。</p>
<p>因此，回忆一下 Mahalanobis 距离的表达式 <span class="math inline">\(d(P,Q) = \sqrt{(x-y)^T \Sigma^{-1}
(x-y)}\)</span>，其中要求 <span class="math inline">\(\Sigma\)</span>
是一个对称正定矩阵，可以分解为 <span class="math inline">\(\Sigma = P
AP^T\)</span> 的形式，其中 <span class="math inline">\(P\)</span>
是正交矩阵，<span class="math inline">\(A\)</span>
是特征值对角矩阵。</p>
<h3 id="matrix-inequality">Matrix Inequality</h3>
<p><strong>Extended Cauchy-Schwartz Inequality</strong>：对于两个 <span class="math inline">\(p \times 1\)</span> 大小的向量 <span class="math inline">\(b,d\)</span>，任意的 <span class="math inline">\(B\)</span> 满足是对称正定矩阵，于是有</p>
<p><span class="math display">\[(b^T d)^2 \leq (b^T Bb)(d B^{-1}
d)\]</span>，</p>
<p>等号成立当且仅当 <span class="math inline">\(b=cB^{-1}
d\)</span>，<span class="math inline">\(c\)</span> 是常数。</p>
<p><strong>Proof</strong>（证明摘自 <a href="https://blog.vicayang.cc/Note-Matrix-Foundation-for-MSA/#%E5%B9%BF%E4%B9%89cauchy-schwarz%E4%B8%8D%E7%AD%89%E5%BC%8F">Vica's
Blog</a>）：注意到</p>
<p><span class="math display">\[\boldsymbol{b}^\intercal\boldsymbol{d}=\boldsymbol{b}^\intercal\boldsymbol{I}\boldsymbol{d}=\boldsymbol{b}^\intercal\boldsymbol{B}^{1/2}\boldsymbol{B}^{-1/2}\boldsymbol{d}=(\boldsymbol{B}^{1/2}\boldsymbol{b})^\intercal(\boldsymbol{B}^{-1/2}\boldsymbol{d})\]</span></p>
<p>然后套用柯西不等式即得证。</p>
<p><strong>Maximization Lemma</strong>：<span class="math inline">\(B\)</span> 是对称正定矩阵，<span class="math inline">\(d\)</span> 是给定的向量，于是对于任意不为零的向量
<span class="math inline">\(x\)</span>，有</p>
<p><span class="math display">\[\max _{x\neq 0} \frac{(x^T d)^2}{x^T Bx}
= d^T B^{-1} d\]</span>，</p>
<p>取到最大值时有 <span class="math inline">\(x = c B^{-1}
d\)</span>，<span class="math inline">\(c\)</span> 是常数。</p>
<p><strong>Proof</strong>：即为 Extended Cauchy-Schwartz Inequality
的变形。</p>
<h2 id="描述性统计量的矩阵表示">描述性统计量的矩阵表示</h2>
<p>上次说到把二维数据组织成 <span class="math inline">\(n \times
p\)</span> 尺寸的表格：</p>
<table>
<colgroup>
<col style="width: 11%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 7%">
<col style="width: 18%">
<col style="width: 7%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Variable 1</th>
<th>Variable 2</th>
<th>...</th>
<th>Variable i</th>
<th>...</th>
<th>Variable p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Item 1</td>
<td><span class="math inline">\(x_{11}\)</span></td>
<td><span class="math inline">\(x_{12}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{1i}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{1p}\)</span></td>
</tr>
<tr class="even">
<td>Item 2</td>
<td><span class="math inline">\(x_{21}\)</span></td>
<td><span class="math inline">\(x_{22}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{2i}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{2p}\)</span></td>
</tr>
<tr class="odd">
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="even">
<td>Item j</td>
<td><span class="math inline">\(x_{j1}\)</span></td>
<td><span class="math inline">\(x_{j2}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{ji}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{jp}\)</span></td>
</tr>
<tr class="odd">
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="even">
<td>Item n</td>
<td><span class="math inline">\(x_{n1}\)</span></td>
<td><span class="math inline">\(x_{n2}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{ni}\)</span></td>
<td>...</td>
<td><span class="math inline">\(x_{np}\)</span></td>
</tr>
</tbody>
</table>
<p>实际上就是一个 <span class="math inline">\(n \times p\)</span>
大小的矩阵，记为 <span class="math inline">\(A =
[y_1,y_2,...,y_p]\)</span>。</p>
<p>sample mean vector 也可以写成矩阵变换的表示：$ {X} = A^T _n$，其中
<span class="math inline">\(\mathbb 1_p\)</span> 表示 <span class="math inline">\(p\)</span> 个分量都是 <span class="math inline">\(1\)</span> 的向量。</p>
<p>covariance matrix 也可以写成矩阵表达：$ n S_p = A^T (I_n - _n _n^T)
A$，事实上 <span class="math inline">\(\mathbb 1_n \mathbb 1_n
^T=\mathbb 1_{n\times n}\)</span> 是一个分量都为 <span class="math inline">\(1\)</span> 的矩阵。</p>
<p>correlation matrix 在 covariance matrix 的基础上继续做变换即可。记
$D^{ 2} = diag(,..., ) $，于是 correlation matrix 可以记为 <span class="math inline">\(R_p= D^{-\frac 1 2} S_p D^{-\frac 1
2}\)</span></p>
<p>在此基础上再定义一个 generalized sample variance，事实上是 covariance
matrix
的行列式值的绝对值，也就是这个对称矩阵的全体特征值的积的绝对值。由行列式的形式可以知道它是一个和各个
covariance coefficient
相关的式子，一定程度上可以反映数据的离散程度（但因为是标量，缺乏各个方向上的数据的离散情况）。例如对于二维数据（<span class="math inline">\(p=2\)</span>），可以知道 <span class="math inline">\(|S|=s_{11} s_{22} (1- r_{12}^2)\)</span>。</p>
<p>另一个常用的表示是 covariance matrix
的迹，也即这个对称矩阵的全体特征值的和。</p>
<h1 id="lecture-3">Lecture 3</h1>
<p>今天介绍多元正态分布。</p>
<h2 id="多元正态分布">多元正态分布</h2>
<ul>
<li><p>多元正态分布的概率密度形式和一元是完全类似的：</p>
<p><span class="math display">\[f(x) = \frac{1}{(2\pi) ^{p/2} |\Sigma
|^{1/2}} exp(-\frac{(x-\mu)^T \Sigma^{-1} (x-\mu)}{2})\]</span></p>
<p>其中，<span class="math inline">\(\mu\)</span> 是 <span class="math inline">\(x\)</span> 的均值，<span class="math inline">\(\Sigma\)</span> 是 <span class="math inline">\(x\)</span>
的协方差矩阵，这是一个正定矩阵。</p></li>
<li><p>先把二元的情况拿出来观察，<span class="math inline">\(p=2\)</span>，于是有 <span class="math inline">\(f(x) = \frac{1}{2\pi |\Sigma|^{1/2}}
exp(-\frac{(x-\mu)^T \Sigma^{-1} (x-\mu)}{2})\)</span>。其中有</p>
<p><span class="math display">\[\mu = \begin{bmatrix} \mu_1 \\ \mu_2
\end{bmatrix} = \begin{bmatrix} E(X_1) \\ E(X_2) \end{bmatrix}, \Sigma =
\begin{bmatrix} Var{X_1} &amp; Cov(X_1,X_2)  \\ Cov(X_1,X_2) &amp;
Var(X_2)\end{bmatrix}\]</span></p></li>
<li><p>我们想对 <span class="math inline">\(\mu\)</span> 和 <span class="math inline">\(\Sigma\)</span> 做一些估计，回顾一下统计推断里的
MLE 估计，矩估计等等方法。</p></li>
</ul>
<h2 id="补充矩阵向量求导期望">补充：矩阵向量求导、期望</h2>
<ul>
<li><p>向量求导很熟悉了，就是 Jacobian matrix
那一套。但在多元统计里使用的求导矩阵是 Jacobian matrix
的转置。有一些看起来轻微抽象的结论：</p>
<p><span class="math display">\[\frac{\partial}{\partial x} Ax =
A^T\]</span></p>
<p><span class="math display">\[\frac{\partial}{\partial x} x^TA =
A\]</span></p>
<p><span class="math display">\[\frac{\partial}{\partial x} x^Tx =
2x\]</span></p>
<p><span class="math display">\[\frac{\partial}{\partial x} x^TAx =
Ax+A^Tx\]</span></p>
<p>实际上都非常容易推导，把 <span class="math inline">\(Ax\)</span> 视为
<span class="math inline">\(x\)</span>
的线性变换，再对分量求导即可。</p></li>
<li><p>对矩阵的求导暂时只考虑对称正定的情况。</p>
<p><span class="math display">\[\frac{\partial |A|}{\partial A} = |A|
A^{-1}\]</span></p>
<p><span class="math display">\[\frac{\partial tr(AB)}{\partial A}
=B^T\]</span></p>
<p><span class="math display">\[\frac{\partial tr(A^{-1}B)}{\partial A}
= -A^{-1}B^TA^{-1}\]</span></p>
<p>有点抽象（</p></li>
<li><p>对于某一个 population <span class="math inline">\(c^T X =
\begin{bmatrix} c_1 &amp; c_2 &amp; ... &amp;c_p \end{bmatrix}
\begin{bmatrix} X_1 \\ X_2 \\...\\X_p \end{bmatrix}\)</span>, 其期望变为
<span class="math inline">\(c^T \mu\)</span>，方差变为 <span class="math inline">\(c^T \Sigma c\)</span>；</p>
<p>如果 <span class="math inline">\(c^TX\)</span> 是一个
sample，同理样本均值变为 <span class="math inline">\(c^T
\mu\)</span>，样本方差变为 <span class="math inline">\(c^T
Sc\)</span>。</p>
<p>对于两个 population <span class="math inline">\(b^TX\)</span> 和
<span class="math inline">\(c^TX\)</span>，有 <span class="math inline">\(Cov(b^T X,c^TX) = b^TXc\)</span>。</p>
<p>注意这里是对一个随机向量的 <span class="math inline">\(p\)</span>
个分量在做线性组合，而不是对若干个随机向量的组合，期望和方差都是标量而不是向量！</p></li>
</ul>
<h2 id="多元正态分布参数估计">多元正态分布参数估计</h2>
<h3 id="极大似然估计">极大似然估计</h3>
<p>这个我在课上自己推出来了（喜），还喜提了 dwl 老师在我身边叫我名字 +
纠正书写，她居然还记得我，但想起来我开摆的初概，真是又开心又尴尬（。结论是：</p>
<p>对于 <span class="math inline">\(X_1,X_2,...,X_n\)</span> i.i.d.
<span class="math inline">\(\sim N_p (\mu,\Sigma)\)</span>，参数 <span class="math inline">\(\mu\)</span> 和 <span class="math inline">\(\Sigma\)</span> 的极大似然估计是：</p>
<p><span class="math display">\[ \hat{\mu}_{MLE} = \bar{X}\]</span></p>
<p><span class="math display">\[\hat{\Sigma}_{MLE} = \frac{1}{n}
\Sigma_{i=1} ^n (X_j - \bar{X})(X_j - \bar{X})^T\]</span></p>
<h3 id="无偏估计">无偏估计</h3>
<p>首先考虑样本方差为 <span class="math inline">\(S = \frac{1}{n-1}
\Sigma_{i=1} ^n (X_j - \bar{X})(X_j - \bar{X})^T = \frac{n}{n-1}
\hat{\Sigma}_{MLE}\)</span>，它是 <span class="math inline">\(\Sigma\)</span> 的无偏估计；<span class="math inline">\(\mu\)</span> 的无偏估计显然是 <span class="math inline">\(\bar{X}\)</span>。</p>
<p>事实上还有性质：<span class="math inline">\(Cov(\bar{X}) = \frac 1 n
\Sigma\)</span>；<span class="math inline">\(S\)</span> 和 <span class="math inline">\(\bar{X}\)</span>
互相独立，且是一组充分统计量（用因子分解定理简单看一下）。</p>
<h2 id="多元正态分布的性质">多元正态分布的性质</h2>
<ul>
<li><p><span class="math inline">\(X \sim N_p(\mu , \Sigma) \iff a^TX
\sim N(a^T\mu,a^T\Sigma a)\)</span> 对任意的 <span class="math inline">\(a \in \mathbb R^p\)</span> 成立。</p>
<p><span class="math inline">\(X\sim N_p(\mu ,\Sigma) \iff AX+d \sim
N_p(A\mu +d , A\Sigma A^T)\)</span> 对任意的 <span class="math inline">\(d\in \mathbb R^p\)</span> 成立。</p></li>
<li><p>对于特定的 <span class="math inline">\(N_p(\mu ,
\Sigma)\)</span>，我们可以用 <span class="math inline">\(p\)</span>
个标准正态分布捏出来。对于任意的 <span class="math inline">\(Z_1,Z_2,...,Z_p\)</span> i.i.d. <span class="math inline">\(\sim N(0,1)\)</span>，记 <span class="math inline">\(Z=(Z_1,Z_2,...,Z_p)^T\)</span>。对任意的对称正定矩阵
<span class="math inline">\(\Sigma\)</span> 和实向量 <span class="math inline">\(\mu \in \mathbb R^p\)</span>，有 <span class="math inline">\(X = \mu + \Sigma^{\frac 1 2} Z \sim
N_p(\mu,\Sigma)\)</span>。</p></li>
<li><p>对于满足多元正态分布的 <span class="math inline">\(X =
(X_1,X_2,...,X_p)^T \sim N_p(\mu ,\Sigma)\)</span>，我们可以根据 <span class="math inline">\(\mu\)</span>，<span class="math inline">\(\Sigma\)</span> 的信息找到任意一组 <span class="math inline">\((X_{i1},X_{i2},...,X_{ij})\)</span>
的期望和方差，也可以通过协方差矩阵得到任意一对 <span class="math inline">\((X_i,X_j)\)</span>
之间的独立性关系（注意对于正态分布，独立和不相关是等价的，对于其他分布不能这样推理）。</p>
<p>然而对于相关的随机向量，例如 <span class="math inline">\(\begin{bmatrix} X_1 \\ X_2\end{bmatrix}\sim
N_{q_1+q_2} (\begin{bmatrix}\mu_1 \\ \mu_2 \end{bmatrix},\begin{bmatrix}
\Sigma_{11} &amp;\Sigma_{12} \\ \Sigma_{21} &amp; \Sigma_{22}
\end{bmatrix})\)</span>，其中 <span class="math inline">\(|
\Sigma_{22}|&gt;0\)</span>，可以看到 <span class="math inline">\(X_1,X_2\)</span>
之间并不独立。此时我们有另一种结果： $(X_1 | X_2 = x_2) N(<em>1 +
</em>{12} <em>{22}^{-1} (x_2 - <em>2),</em>{11} - </em>{12 }
<em>{22}^{-1} </em>{21}) $</p>
<p><strong>Proof：</strong>（这是我写在作业里的一个方法，写个作业用蹩脚英文，现在看看绷不住了）</p>
<p>According to the resolution:</p>
<p><span class="math display">\[\Sigma =  \begin{bmatrix} \Sigma_{11}
&amp; \Sigma_{12} \\ \Sigma_{21} &amp; \Sigma_{22} \end{bmatrix}
=  \begin{bmatrix}\Sigma_{11} - \Sigma_{12 } \Sigma_{22}^{-1}
\Sigma_{21} &amp; \Sigma _{12} \\ 0  &amp;
\Sigma_{22}\end{bmatrix}   \begin{bmatrix}I &amp;0 \\ -\Sigma_{22} ^{-1}
\Sigma_{21}  &amp; I\end{bmatrix}^{-1}\]</span></p>
<p>Note that:</p>
<p><span class="math inline">\((x-\mu)^T \Sigma ^{-1} (x-\mu) =
\begin{bmatrix}x_1^T - \mu_1^T &amp; x_2^T - \mu_2^T\end{bmatrix}
\begin{bmatrix} I &amp; 0 \\ -\Sigma_{22}^{-1} \Sigma_{21} &amp;
I\end{bmatrix} \begin{bmatrix}(\Sigma_{11} - \Sigma_{12 }
\Sigma_{22}^{-1} \Sigma_{21})^{-1} &amp; 0 \\ 0 &amp; \Sigma_{22}^{-1}
\end{bmatrix} \begin{bmatrix}I &amp; -\Sigma_{12} \Sigma_{22} ^{-1} \\ 0
&amp;I\end{bmatrix} \begin{bmatrix}x_1 - \mu_1 \\ x_2-
\mu_2\end{bmatrix}\)</span></p>
<p>We can know that <span class="math inline">\((x_1^T -\mu_1^T) -
(x_2^T - \mu_2^T ) \Sigma_{22}^{-1} \Sigma_{21} \sim N(0,\Sigma_{11} -
\Sigma_{12 } \Sigma_{22}^{-1} \Sigma_{21})\)</span>,</p>
<p>so that <span class="math inline">\(X_1 \sim N(\mu_1 +\Sigma_{21}
\Sigma_{22}^{-1} (x_2 - \mu_2)\)</span>,$<em>{11} - </em>{12 }
<em>{22}^{-1} </em>{21}) $, the conditional distribution can be derived
from the distribution.</p>
<p>因此可以看到，即使随机向量的两部分之间有相关性，也可以进行分离。</p></li>
<li><p><span class="math inline">\(X \sim
N_p(\mu,\Sigma)\)</span>，于是有 <span class="math inline">\((X-\mu) ^T
\Sigma^{-1}(X-\mu) \sim \chi_p ^2\)</span>。</p>
<p><strong>Proof：</strong>取 <span class="math inline">\(Z=\Sigma^{\frac 1 2} \sim N_p
(0,I_p)\)</span>。</p>
<p>于是 <span class="math inline">\((X-\mu) ^T \Sigma^{-1} (X-\mu) =
[(X-\mu)^T \Sigma^{-\frac 1 2}] [\Sigma^{-\frac 1 2} (X-\mu)] = Z^TZ
=\Sigma_{i=1} ^p Z_i ^2 \sim \chi_p ^2\)</span>。</p></li>
<li><p><span class="math inline">\(X_1,X_2,..,X_n\)</span>
是相互独立的多元正态分布，<span class="math inline">\(X_j \sim N_p(\mu_j
, \Sigma)\)</span>，记 <span class="math inline">\(V_1 =
c_1X_1+c_2X_2+...+c_nX_n = c^TX\)</span>。</p>
<ul>
<li><span class="math inline">\(V_1 \sim N_p(c^T \mu , c^Tc
\Sigma)\)</span>；</li>
<li>对于 <span class="math inline">\(V_2 =
b_1X_1+b_2X_2+...+b_nX_n\)</span>，有 <span class="math inline">\(V_1,V_2\)</span> 的协方差矩阵为 <span class="math inline">\(\begin{bmatrix} c^Tc\Sigma &amp; b^Tc\Sigma \\
b^Tc\Sigma &amp; b^Tb\Sigma \end{bmatrix}\)</span>。</li>
<li><span class="math inline">\(V_1,V_2\)</span> 相互独立 <span class="math inline">\(\iff b^Tc = 0\)</span>（由上一结论直接得出）</li>
</ul>
<p>尤其要注意此处与上一部分最后一段的关系，<span class="math inline">\(V_1,V_2\)</span>
是在对若干随机向量做线性组合，上一部分最后一段是在对一个随机向量的全体分量做线性组合。也可以从所得结果的维数来判断。</p></li>
</ul>
<h1 id="lecture-4">Lecture 4</h1>
<p>单正态分布总体的推断。</p>
<h2 id="wishart-distribution">Wishart Distribution</h2>
<ul>
<li><p>$S = _{i=1} ^n (X_j - {X})(X_j - {X})^T $，有 <span class="math inline">\((n-1)S =\Sigma_{i=1} ^{n-1} Z_i Z_i^T \sim
W_p(n-1,\Sigma)\)</span>，其中 <span class="math inline">\(Z_i \sim N_p
(0,\Sigma)\)</span>。</p>
<p>类似于一个 <span class="math inline">\(\chi^2\)</span>
分布在多元分布上的推广。</p></li>
<li><p>对于 <span class="math inline">\(A_1 \sim
W_p(m_1,\Sigma)\)</span>，<span class="math inline">\(A_2 \sim
W_p(m_2,\Sigma)\)</span> 且 <span class="math inline">\(A_1,A_2\)</span>
相互独立，则有 <span class="math inline">\(A_1 +A_2 \sim W_p
(m_1+m_2,\Sigma)\)</span>。</p></li>
<li><p>对于 <span class="math inline">\(A \sim
W_p(m,\Sigma)\)</span>，$C $ 是一个 <span class="math inline">\(p\times
p\)</span> 大小的可逆矩阵，则 <span class="math inline">\(C^TAC \sim
W_p(m,C^T\Sigma C)\)</span>。</p>
<p>注意 <span class="math inline">\(C\)</span> 可以是 $k p $
大小的矩阵，此时也有 <span class="math inline">\(C^TAC \sim W_k(m,
C^T\Sigma C)\)</span>。这是因为 <span class="math inline">\(A =
\Sigma_{i=1}^m Z_iZ_i ^T\)</span>，其中 <span class="math inline">\(Z
\sim N_p(0,\Sigma)\)</span>，于是有 <span class="math inline">\(C^TAC
=\Sigma_{i=1} ^m C^TZ_i Z_i ^TC\)</span> 且 <span class="math inline">\(C^TZ_i \sim N_k ( 0, C^T\Sigma C)\)</span>，因此
<span class="math inline">\(C^TAC \sim W_k(m,C^T\Sigma
C)\)</span>。此处尤其需要注意随机向量的维数改变为 <span class="math inline">\(k\)</span> 维。</p>
<p>以上两个性质都可以轻松地通过 Wishart distribution
的构造推出。</p></li>
</ul>
<h2 id="one-sample-t-test">One Sample T-test</h2>
<ul>
<li><p>在一元情况下有 <span class="math inline">\(\frac{\sqrt{n}(\bar{X}
- \mu_0)}{\sigma} \sim N(0,1)\)</span> 和 <span class="math inline">\(\frac{(n-1)S^2}{\sigma^2} \sim \chi_{n-1}
^2\)</span>，以及 <span class="math inline">\(\frac{\bar{X} -
\mu_0}{S/\sqrt n} \sim t_{n-1}\)</span> 和 <span class="math inline">\((\frac{\bar{X} - \mu_0}{S/\sqrt n})^2 \sim
F_{1,n-1}\)</span>，这些都是假设检验中常用的检验统计量。我们希望能够推广到多元的情况。</p>
<p>对于一族 <span class="math inline">\(X_1,X_2,...,X_n \sim N_p(\mu ,
\Sigma)\)</span>，假设 <span class="math inline">\(H_0 :\mu = \mu_0 ;
H_1 :\mu \neq \mu_0\)</span>。</p>
<p>在 <span class="math inline">\(H_0\)</span> 下有</p>
<p><span class="math display">\[\frac{T^2}{n-1} = \sqrt n (\bar{X} -
\mu_0)^T (\Sigma (X_j - \bar X)(X_j - \bar X)^T)^{-1} \sqrt n (\bar{X} -
\mu_0) = Z_1 (\Sigma_{i=1} ^n Z_iZ_i^T)^{-1}Z_i^T \sim \frac{p}{n-p}
F_{p,n-p}\]</span></p>
<p>也就是说 <span class="math inline">\(\frac{n-p}{p(n-1)} T^2 \sim
F_{p,n-p}\)</span>，当 <span class="math inline">\(T_0 ^2 &gt; T^2
(\alpha) = \frac{p(n-1)}{n-p} F_{p,n-p}(\alpha)\)</span>
时拒绝原假设。这被称为 Hotelling distribution。</p></li>
<li><p>对于 <span class="math inline">\(X_i \sim
N_p(\mu,\Sigma)\)</span>，考虑 <span class="math inline">\(Y_i =
CX_i+d\)</span>，其中 $C $ 是 <span class="math inline">\(p \times
p\)</span> 的矩阵，<span class="math inline">\(d\)</span> 是 <span class="math inline">\(p \times 1\)</span>
的向量。这是一族多元正态分布的线性变换。</p>
<p>于是有 <span class="math inline">\(\bar{Y} = C
\bar{X}+d\)</span>，<span class="math inline">\(S_Y =
\frac{1}{n-1}\Sigma_{i=1}^n (Y_i - \bar{Y_i})(Y_i-\bar Y_i)^T =
CS_XC^T\)</span>，考虑其期望有 <span class="math inline">\(\mu _Y = C
\mu +d\)</span>，在假设 <span class="math inline">\(H_0\)</span> 下有
<span class="math inline">\(\mu_{Y,0} = C \mu_0 +d\)</span>。于是对应的
Hotelling Statistic 是</p>
<p><span class="math inline">\(\begin{aligned} T^2 _Y &amp;= \sqrt n
(\bar Y - \mu_{Y,0})^T (\Sigma (Y_i - \bar{Y})(Y_i - \bar Y)^T)^{-1}
\sqrt n (\bar{Y} - \mu_{Y,0}) \\&amp; =\sqrt n (\bar{X} - \mu_0)^T C^T
C^{-T}(\Sigma (X_j - \bar X)(X_j - \bar X)^T)^{-1}C^{-1}C \sqrt n
(\bar{X} - \mu_0) \\&amp; =\sqrt n (\bar{X} - \mu_0)^T (\Sigma (X_j -
\bar X)(X_j - \bar X)^T)^{-1} \sqrt n (\bar{X} - \mu_0) \\&amp; =T^2_X
\end{aligned}\)</span></p>
<p>可以看到与做线性变换之前是相同的，也即对于 <span class="math inline">\(Y_i = CX_i +d\)</span>，可以使用相同的 test
statistic 进行检验。</p></li>
<li><p>实际上，Hotelling test 和 likelihood ratio test
是完全等价的，这个可以在一元的情况下看到，也可以推广到多元。多元情况下的
likelihood ratio 是：</p>
<p><span class="math display">\[\Lambda = (\frac{|\hat \Sigma|}{|\hat
\Sigma_0|}) ^{\frac n 2}= (\frac{|\Sigma_{j=1} ^n (x_j - \bar x)(x_j -
\bar x)^T|}{|\Sigma_{j=1} ^ n (x_j - \mu_0)(x_j-\mu_0)^T|})^{\frac n
2}\]</span></p>
<p>由此得到 test statistic 的另一表示，不需要对矩阵 <span class="math inline">\(S\)</span> 求逆：</p>
<p><span class="math display">\[T^2 = (n-1) \frac{|\Sigma_{j=1} ^n (x_j
- \mu_0)(x_j - \mu_0)^T|}{|\Sigma_{j=1} ^ n (x_j - \bar x)(x_j-\bar
x)^T|} - (n-1)\]</span></p></li>
</ul>
<h2 id="confidence-interval-of-mu_p-times-1">Confidence Interval of
<span class="math inline">\(\mu_{p \times 1}\)</span></h2>
<h3 id="confidence-region-of-the-mean">Confidence Region of the
Mean</h3>
<p>已知 <span class="math inline">\(Z_1,Z_2,...,Z_n i.i.d \sim
N_p(\mu,\Sigma)\)</span>，对于已有的数据 <span class="math inline">\(z_1,z_2,...,z_n\)</span> 希望求得 <span class="math inline">\(\mu\)</span> 的置信区间，其中 <span class="math inline">\(\mu ,\Sigma\)</span> 均未知。在一元的情况下 (<span class="math inline">\(p=1\)</span>) 可以使用 <span class="math inline">\(\frac{\bar Z - \mu}{s / \sqrt n} \sim
t_{n-1}\)</span> 进行估计。<span class="math inline">\(\mu\)</span> 的
<span class="math inline">\(100(1-\alpha)\%\)</span> 置信区间是 <span class="math inline">\((\bar Z - t_{n-1,\alpha /2} \frac{s}{\sqrt n},\bar
Z +t_{n-1,\alpha /2} \frac{s}{\sqrt n})\)</span>。</p>
<p>在多元情况下，有 $ T^2 F_{p,n-p}$，其中 <span class="math inline">\(T^2 = n (\bar Z - \mu)^T S^{-1} (\bar Z -
\mu)\)</span>。于是 <span class="math inline">\(\mu\)</span> 的 <span class="math inline">\(100(1-\alpha)\%\)</span>
置信域是满足以下条件的区域：</p>
<p><span class="math display">\[R(x) = \{\mu: n(\bar Z - \mu )^T S^{-1}
(\bar Z -\mu) \leq c^2 , c^2 = T^2(\alpha) =
\frac{p(n-1)}{n-p}F_{p,n-p}(\alpha) \}\]</span></p>
<p>这是一个椭圆。</p>
<h3 id="individual-coverage-intervals">Individual Coverage
Intervals</h3>
<p>接下来考虑 <span class="math inline">\(Z_1,Z_2,...,Z_n\)</span>
的线性组合 <span class="math inline">\(a^T Z = a_1 Z_1 + ... +a_n
Z_n\)</span>，我们希望估计它的均值 <span class="math inline">\(a^T
\mu\)</span>，这是一个标量。</p>
<p>由于 <span class="math inline">\(a^T Z \sim N(a^T \mu, a^T \Sigma
a)\)</span>，因此 <span class="math inline">\(a^T \mu\)</span> 的 <span class="math inline">\(100 \% (1-\beta)\)</span> 置信区间是 <span class="math inline">\((a^T \bar Z - t_{n-1}(\beta/2) \sqrt{a^T \frac S n
a},a^T \bar Z + t_{n-1}(\beta/2) \sqrt{a^T \frac S n a})\)</span></p>
<p>以下继续考虑 <span class="math inline">\(Z_1,Z_2,...,Z_n\)</span>
的一族共 <span class="math inline">\(m\)</span> 个线性组合 <span class="math inline">\(a_1 ^T Z,a_2 ^T Z,...,a_m ^TZ\)</span>
的置信区间推断。</p>
<h3 id="bonferronis-method">Bonferroni's Method</h3>
<p>对于 <span class="math inline">\(m\)</span> 个不同的线性组合 <span class="math inline">\(a_1^TZ,a_2^TZ,...,a_m^TZ\)</span>，分别对其做置信系数为
<span class="math inline">\(\frac \alpha m\)</span> 的置信区间，则这
<span class="math inline">\(m\)</span>
个区间拼在一起得到的矩体就至少能够包含住真正的置信域。</p>
<p>也就是说，对每个 <span class="math inline">\(a_i^T\mu\)</span>
做置信区间：<span class="math inline">\((a_i ^T\bar{X} -
t_{n-1}(\frac{\alpha}{2m}) \sqrt{a_i ^T \frac S n a_i},a_i ^T\bar{X} +
t_{n-1}(\frac{\alpha}{2m}) \sqrt{a_i ^T \frac S n a_i} )\)</span></p>
<p>拼在一起得到的矩体</p>
<p><span class="math display">\[(a_1 ^T\bar{X} -
t_{n-1}(\frac{\alpha}{2m}) \sqrt{a_1 ^T \frac S n a_1},a_1 ^T\bar{X} +
t_{n-1}(\frac{\alpha}{2m}) \sqrt{a_1 ^T \frac S n a_1} ) \times  \cdots
\times(a_m ^T\bar{X} - t_{n-1}(\frac{\alpha}{2m}) \sqrt{a_m ^T \frac S n
a_m},a_m ^T\bar{X} + t_{n-1}(\frac{\alpha}{2m}) \sqrt{a_m ^T \frac S n
a_m} )\]</span></p>
<p>即为一个符合条件的置信域。实际上这一置信域的置信系数比 <span class="math inline">\(\alpha\)</span> 更大，只是一个粗略的估计。</p>
<h3 id="t2-interval"><span class="math inline">\(T^2\)</span>
interval</h3>
<p>事实上，对任意的线性变换 <span class="math inline">\(a^TZ\)</span>
都存在一个统一的 simultaneous coverage interval，也称作 <span class="math inline">\(T^2\)</span> interval，是</p>
<p><span class="math inline">\((a^T \bar{X} - c\sqrt{a^T \frac S n
a},a^T \bar{X} + c\sqrt{a^T \frac S n a})\)</span>，其中 <span class="math inline">\(c^2 = T^2(\alpha) = \frac{p(n-1)}{n-p}
F_{p,n-p}(\alpha)\)</span>。</p>
<p>这个置信域比 Bonferroni's Method 得到的置信域更大。</p>
<p>注意当 <span class="math inline">\(a\)</span> 在 <span class="math inline">\(S^{-1}\bar X\)</span> 方向上时以上区间正好是一个
<span class="math inline">\(100\%(1-\alpha)\)</span>
的置信区间，也即这个时候区间取到最大。但这一方向会随着样本的变化而变化。</p>
<h3 id="real-world">Real World（？</h3>
<p>对 <span class="math inline">\(Z_i\)</span>
做线性变换得到的椭圆会在形状和方向上有所变化，但与 <span class="math inline">\(T^2\)</span> interval
得到的矩形相切。不同置信区间的覆盖面积如图所示。</p>
<p><img src="https://s2.loli.net/2023/03/18/7zqKjhLmbZRWMf4.png" alt="regions.png"></p>
<h1 id="lecture-5">Lecture 5</h1>
<h2 id="two-population-test">Two Population Test</h2>
<h3 id="双正态同方差总体的均值比较">双正态同方差总体的均值比较</h3>
<ul>
<li><p>两个总体中随机抽样得到的样本和相关统计量分别表示如下：</p>
<table>
<colgroup>
<col style="width: 16%">
<col style="width: 41%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Sample</th>
<th><span class="math inline">\(X_{11},X_{12},...,X_{1n_1}\)</span></th>
<th><span class="math inline">\(X_{21},X_{22},...,X_{2n_2}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sample Mean</td>
<td><span class="math inline">\(\bar X_1 = \frac{1}{n_1} \Sigma_{j=1}
^{n_1} X_{1j}\)</span></td>
<td><span class="math inline">\(\bar X_2= \frac{1}{n_2} \Sigma_{j=1}
^{n_2} X_{2j}\)</span></td>
</tr>
<tr class="even">
<td>Sample Covariance Matrix</td>
<td><span class="math inline">\(S_1 = \frac{1}{n_1 -1 }\Sigma_{j=1}
^{n_1} (X_{1j} - \bar X_1)(X_{1j} - \bar X_1)^T\)</span></td>
<td><span class="math inline">\(S_2= \frac{1}{n_2 -1 }\Sigma_{j=1}
^{n_2} (X_{2j} - \bar X_2)(X_{2j} - \bar X_2)^T\)</span></td>
</tr>
</tbody>
</table></li>
<li><p>检验前对于两个总体的假设：</p>
<ul>
<li><span class="math inline">\(X_{11},X_{12},...,X_{1n_1}\)</span>
i.i.d. <span class="math inline">\(\sim
N_p(\mu_1,\Sigma_1)\)</span>，<span class="math inline">\(X_{21},X_{22},...,X_{2 n_2}\)</span> i.i.d. <span class="math inline">\(\sim N_p(\mu_2,\Sigma_2)\)</span></li>
<li>两组样本之间相互独立</li>
<li>在 <span class="math inline">\(n_1,n_2\)</span> 较小的情况下，假设
<span class="math inline">\(\Sigma = \Sigma_1 = \Sigma_2\)</span></li>
</ul></li>
<li><p>Hypothesis: <span class="math inline">\(H_0 : \mu_1 - \mu_2 =
\delta_0\)</span>，<span class="math inline">\(H_1 : \mu_1 - \mu_2 \neq
\delta_0\)</span></p></li>
<li><p>检验统计量的构造：</p>
<p>由于 <span class="math inline">\(S_{pooled} = \frac{n_1 -1
}{n_1+n_2-2}S_1 + \frac{n_2 -1}{n_1 + n_2 -2}S_2 \sim \frac{W_p(n_1 +n_2
-2,\Sigma)}{n_1+n_2-2}\)</span>，可以以此构造 Test statistic：</p>
<p><span class="math display">\[(\frac{1}{n_1} + \frac{1}{n_2})^{-1}
(\bar X_1 - \bar X_2 - \delta_0)^T S_{pooled}^{-1} (\bar X_1 - \bar X_2
- \delta_0) \sim \frac{p(n_1+n_2-2)}{n_1+n_2-p-1}
F_{p,n_1+n_2-p-1}\]</span></p>
<p>当 <span class="math inline">\(T_0 ^2 &gt;
\frac{p(n_1+n_2-2)}{n_1+n_2-p-1} F_{p,n_1+n_2-p-1} (\alpha)\)</span>
时拒绝原假设。</p></li>
<li><p>置信区间的构造：</p>
<p>对于任意的线性变换 <span class="math inline">\(a^T(\mu_1 -
\mu_2)\)</span>，simultaneous confidence interval 是</p>
<p><span class="math display">\[(a^T(\bar X_1 - \bar X_2) - c \sqrt{a^T
(\frac{1}{n_1} + \frac{1}{n_2}) S_{pooled} a},a^T(\bar X_1 - \bar X_2) +
c \sqrt{a^T (\frac{1}{n_1} + \frac{1}{n_2}) S_{pooled} a})\]</span></p>
<p>其中 <span class="math inline">\(c^2 = \frac{p(n_1+n_2
-2)}{n_1+n_2-p-1}\)</span>。</p>
<p>注意到 <span class="math inline">\(a\)</span> 的任意性，可以通过取
<span class="math inline">\(a_i=e_i\)</span> 的方式来求得 <span class="math inline">\(\mu_1 - \mu_2\)</span> 的各个分量的置信区间；当
<span class="math inline">\(a\)</span> 与 <span class="math inline">\(S_{pooled}^{-1} (\bar X_1 - \bar X_2)\)</span>
时上述置信区间的 confidence level 恰为 <span class="math inline">\(100
\% (1-\alpha)\)</span>。</p></li>
</ul>
<h2 id="large-sample-test">Large Sample Test</h2>
<h3 id="large-sample-behavior">Large Sample Behavior</h3>
<p>在大样本场景下，类似于一元的中心极限定理，我们不需要正态性也可以推出一些关于
<span class="math inline">\(\bar X,S\)</span> 在此时的近似分布。</p>
<p>$X_1 , X_2 ,...,X_n $ i.i.d. 来自某一总体，其均值为 <span class="math inline">\(\mu\)</span>，协方差矩阵为 <span class="math inline">\(\Sigma\)</span>，不必要求正态分布。于是有：</p>
<ul>
<li><span class="math inline">\(\sqrt n (\bar X - \mu) \sim
N_p(0,\Sigma)\)</span></li>
<li><span class="math inline">\(n (\bar X - \mu) S^{-1} (\bar X - \mu)
\sim \chi^2 _p\)</span></li>
</ul>
<p>注意其中 <span class="math inline">\(S = \frac{1}{n-1} \Sigma_{i=1}
^n (X_i - \bar X)(X_i - \bar X)^T\)</span>，上述两式为近似分布，在 <span class="math inline">\(n\)</span> 远大于 <span class="math inline">\(p\)</span> 的条件下成立。</p>
<p>这是我们进行后续推断的基础。</p>
<h3 id="大样本单总体均值推断">大样本单总体均值推断</h3>
<p>$X_1 , X_2 ,...,X_n $ i.i.d. 来自某一总体，其均值为 <span class="math inline">\(\mu\)</span>，协方差矩阵为 <span class="math inline">\(\Sigma\)</span>，不必要求正态分布。</p>
<p>假设 <span class="math inline">\(H_0 : \mu = \mu_0; H_1 : \mu \neq
\mu_0\)</span>，于是 test statistic 是 <span class="math inline">\(n(\bar x - \mu_0)^T S^{-1} (\bar x - \mu_0 ) \sim
\chi^2 _p\)</span>，当 <span class="math inline">\(T_0^2 &gt; \chi_p ^2
(\alpha)\)</span> 时拒绝原假设。</p>
<p>对于任意的线性变换 <span class="math inline">\(a^TX\)</span>，<span class="math inline">\(a^T \mu\)</span> 的 simultaneous CI 是 <span class="math inline">\((a^T \bar X - \sqrt{\chi^2 _p (\alpha)}
\sqrt{\frac{a^TSa}{n} },a^T \bar X + \sqrt{\chi^2 _p (\alpha)}
\sqrt{\frac{a^TSa}{n} })\)</span></p>
<h3 id="大样本双异方差总体均值推断">大样本双异方差总体均值推断</h3>
<ul>
<li><p>检验前对于两个总体的假设：</p>
<ul>
<li><span class="math inline">\(X_{11},X_{12},...,X_{1n_1}\)</span>
i.i.d. <span class="math inline">\(\sim
Population(\mu_1,\Sigma_1)\)</span>，<span class="math inline">\(X_{21},X_{22},...,X_{2 n_2}\)</span> i.i.d. <span class="math inline">\(\sim Population(\mu_2,\Sigma_2)\)</span></li>
<li>两组样本之间相互独立</li>
<li>在 <span class="math inline">\(n_1,n_2\)</span> 较大（均远大于 <span class="math inline">\(p\)</span>）的情况下，我们允许 <span class="math inline">\(\Sigma_1 \neq \Sigma_2\)</span></li>
</ul></li>
<li><p>Hypothesis: <span class="math inline">\(H_0 :\mu_1 - \mu_2 =
\delta_0; H_1 : \mu_1 - \mu_2 \neq \delta_0\)</span></p></li>
<li><p>Test statistic: <span class="math inline">\((\bar X_1 - \bar X_2
- \delta_0 )^T (\frac{1}{n_1} S_1 + \frac{1}{n_2} S_2 )^{-1} (\bar X_1 -
\bar X_2 - \delta_0) \sim ^{H_0} \chi^2 _p\)</span>，当 <span class="math inline">\(T_0 ^2 &gt; \chi^2_p(\alpha)\)</span>
时拒绝原假设。</p></li>
<li><p>标准的 <span class="math inline">\(\mu_1 - \mu_2\)</span> 的
<span class="math inline">\(100\% (1-\alpha)\)</span>
置信域是一个椭圆，由区域</p>
<p><span class="math display">\[\{\mu_1 -\mu_2 : ( \bar X_1 - \bar X_2 -
(\mu_1 - \mu_2))^T(\frac{1}{n_1}S_1 +\frac{1}{n_2}S_2)^{-1}(\bar X_1 -
\bar X_2 - (\mu_1 - \mu_2)) \leq \chi^2_p(\alpha)=c^2 \}\]</span></p>
<p>表示。</p>
<p>类似地考虑 <span class="math inline">\(X_1,X_2\)</span>
的线性变换，<span class="math inline">\(a^T(\mu_1 - \mu_2)\)</span> 的
simultaneous CI 是</p>
<p><span class="math display">\[(a^T(\bar X_1 - \bar X_2) - c
\sqrt{a^T(\frac{1}{n_1} S_1 + \frac{1}{n_2} S_2)a},a^T(\bar X_1 - \bar
X_2) + c \sqrt{a^T(\frac{1}{n_1} S_1 + \frac{1}{n_2} S_2)a} ),c^2 =
\chi^2_p(\alpha)\]</span></p></li>
</ul>
<h3 id="大样本双总体方差推断">大样本双总体方差推断</h3>
<ul>
<li><p>检验前对于两个总体的假设：</p>
<ul>
<li><span class="math inline">\(X_{11},X_{12},...,X_{1n_1}\)</span>
i.i.d. <span class="math inline">\(\sim
Population(\mu_1,\Sigma_1)\)</span>，<span class="math inline">\(X_{21},X_{22},...,X_{2 n_2}\)</span> i.i.d. <span class="math inline">\(\sim Population(\mu_2,\Sigma_2)\)</span></li>
<li>两组样本之间相互独立</li>
</ul></li>
<li><p>Hypothesis: <span class="math inline">\(H_0 : \Sigma_1 =
\Sigma_2; H_1 : \Sigma_1 \neq \Sigma_2\)</span></p></li>
<li><p>Test statistic：考虑 likelihood ratio <span class="math inline">\(\Lambda = \frac{max_{\theta \in \Theta_0}
L(\theta)}{max_{\theta \in \Theta} L(\theta)} = \frac{|S_1|^{n_1 /2}
|S_2|^{n_2/2}}{|S_{pooled}|^{n_1+n_2-2/2}}\)</span>，自由度之差为 <span class="math inline">\(v-v_0 = df(\Theta) - df(\Theta_0)\)</span>，于是在
<span class="math inline">\(H_0\)</span> 假设下有 <span class="math inline">\(-2 \ln \Lambda \sim \chi^2_{v-v_0}\)</span>
是为检验统计量。</p>
<p>George Box 对其进行了修改，使得可以对 <span class="math inline">\(g\)</span> 个总体进行方差推断，具体略去。</p></li>
</ul>
<h2 id="assumption-check">Assumption Check</h2>
<p>类似于线性回归中所讲的内容，此处略去。</p>
<h1 id="lecture-6">Lecture 6</h1>
<p>关于主成分分析（Principal Component Analysis）在 population
上的理论和在 sample
上的应用。希望通过对一系列随机变量的线性变换和组合，分析维度更小的数据来达到同样的结果。</p>
<h2 id="for-population">For Population</h2>
<h3 id="pca-方法的具体操作">PCA 方法的具体操作</h3>
<p>面对的问题模型可以视作：随机向量 <span class="math inline">\(X^T =
[X_1 , X_2,...,X_p]\)</span> 有 <span class="math inline">\(p \times
p\)</span> 维的协方差矩阵 <span class="math inline">\(\Sigma\)</span>
和对应的 <span class="math inline">\(p\)</span> 个非负特征值 <span class="math inline">\(\lambda _1 \geq \lambda_2 \geq ... \geq \lambda_p
\geq 0\)</span>，分别对应单位特征向量 <span class="math inline">\(e_1,e_2,...,e_p\)</span>，这是一组正交基。</p>
<p>我们希望能够找出 <span class="math inline">\(Y_1,
Y_2,...,Y_p\)</span> 满足 <span class="math inline">\(Y_i = a_i ^T
X\)</span>，使得 <span class="math inline">\(a_i ^T a_i
=1\)</span>，<span class="math inline">\(Var(Y_i)\)</span> 最大，且
<span class="math inline">\(Cov(Y_i, Y_j)=a_i ^T \Sigma
a_j=0\)</span>。事实上由 Rayleigh 商可以知道，只要取 <span class="math inline">\(a_i = e_i\)</span> 就可以三个愿望一次满足（，且有
<span class="math inline">\(Var(Y_i) = \lambda_i\)</span>，证明是
trivial 的。</p>
<p>这个变换有一些性质：</p>
<ul>
<li><p><span class="math inline">\(\Sigma_{i=1}^p Var(X_i) =
\Sigma_{i=1}^p \sigma_{ii} = trace(\Sigma) = \Sigma_{i=1}^p \lambda_i =
\Sigma_{i=1}^p Var(Y_i)\)</span></p>
<p>说明 PCA 前后的信息没有损失。</p></li>
<li><p>可以通过 <span class="math inline">\(Var(Y_i)\)</span> 在 <span class="math inline">\(\Sigma_{i=1} ^p Var(Y_i)\)</span>
中的占比判断这一信息的重要程度，这一数值为 <span class="math inline">\(\frac{\lambda_i}{\lambda_1 + ...
\lambda_p}\)</span></p></li>
<li><p><span class="math inline">\(Cov(Y_i , X_j) = Cov(e_i ^T X, I_j ^T
X) = e_i ^T \Sigma I_j = \lambda_i e_i^T I_j = \lambda_i
e_{ij}\)</span></p>
<p>因此二者之间的相关系数为 <span class="math inline">\(\rho_{Y_i , X_j}
= \frac{Cov(Y_i,X_j)}{\sqrt{Var(Y_i) Var(X_j)}} = \frac{e_{ij} \sqrt
\lambda_i}{\sqrt \sigma_{ii}}, i,j = 1,2,...,p\)</span>。</p>
<p>对于固定的 <span class="math inline">\(j\)</span> 有 <span class="math inline">\(\Sigma_{i=1}^p \rho_{Y_i,X_j}^2 =
1\)</span>。这一相关系数显示了 <span class="math inline">\(X_j\)</span>
的方差可以被 <span class="math inline">\(Y_i\)</span>
解释的比例。</p></li>
</ul>
<p>事实上，有的时候直观显示出来 <span class="math inline">\(Y_i =
e_i^TX\)</span> 中 <span class="math inline">\(X_j\)</span>
前系数较小，这并不说明 <span class="math inline">\(X_j\)</span>
的影响较小，计算 <span class="math inline">\(\rho_{Y_i,X_j}\)</span>
可能会体现出较大的相关系数，显示二者之间有较大的相关性。</p>
<h3 id="正规化随机变量下的-pca">正规化随机变量下的 PCA</h3>
<p>实际使用中可能存在一些单位的变化、尺度变化导致 PCA
的系数出现不同的情况。我们讨论 standardized variable <span class="math inline">\(Z_k= \frac{(X_k - \mu_k)}{\sqrt \sigma_{kk}}, k
=1,2,...,p\)</span> 下的 PCA 变换。</p>
<p>事实上有 <span class="math inline">\(Z = diag(\sqrt{\sigma_{11}^{-1}
},\sqrt{\sigma_{22}^{-1} },...,\sqrt{\sigma_{pp}^{-1} } )
(X-\mu)\)</span>，于是 <span class="math inline">\(Cov(Z) =
diag(\sigma_{11},\sigma_{22},...,\sigma_{pp})\)</span>。
由此即得正规化情况下的 PCA 变化的参数细节，不再赘述。</p>
<h3 id="多元正态分布下的-pca">多元正态分布下的 PCA</h3>
<p>当 <span class="math inline">\(X\sim N_p(\mu ,\Sigma)\)</span>
时，好像下节课再讲（</p>
<h2 id="for-sample">For Sample</h2>
<p>回顾一下多元情况下的样本方差：</p>
<blockquote>
<p>协方差定义为 <span class="math inline">\(s_{ik} = \frac 1 n
\Sigma_{j=1}^n (x_{ji} - \bar{x_i}) (x_{ji} -
\bar{x_k})\)</span>，可以看到实际上 <span class="math inline">\(s_{ik} =
s_{ki}\)</span>，于是协方差矩阵有</p>
<p><span class="math display">\[ \begin{bmatrix} s_{11} &amp; s_{12}
&amp; ...&amp; s_{1p}\\ s_{21} &amp; s_{22} &amp; ...&amp; s_{2p} \\ ...
&amp; ...&amp;...&amp;... \\ s_{p1} &amp; s_{p2} &amp;...&amp;s_{pp}
\end{bmatrix}\]</span></p>
<p>的形式，这是一个对角元为正的对称矩阵。</p>
</blockquote>
<p>事实上，对于已知的 <span class="math inline">\(x =
[x_1,x_2,...,x_p]\)</span>，希望取 <span class="math inline">\(\hat{y_i}
= \hat{e_i} ^T x = \hat e_{i1}x_1 + \hat e_{i2} x_2 + ... +\hat e_{ip}
x_p\)</span> 满足 <span class="math inline">\(\hat e_i ^T \hat e_i =
1\)</span>，$Cov(y_i , y_j) = 0 $ 对不相等的 <span class="math inline">\(i ,j\)</span> 都成立，且 <span class="math inline">\(Var(\hat y_i) = \hat \lambda_i, i =
1,2,...,p\)</span>。<span class="math inline">\(\hat y_i\)</span> 称为
<span class="math inline">\(i\)</span>-th sample principal component
(score)，即 sample PCs。</p>
<p>类似于 population 情况下的 PCA，sample PCs 有以下性质：</p>
<ul>
<li><span class="math inline">\(\Sigma_{i=1} ^p Var(\hat y_i) =
\Sigma_{i=1}^p s_{ii} = \Sigma_{i=1}^p \hat \lambda_i\)</span></li>
<li><span class="math inline">\(\rho_{\hat{y_i} ,x_k} =
\frac{\hat{e}_{ik} \sqrt {\hat{\lambda}_k} }{\sqrt s_{kk}
}\)</span></li>
</ul>
<h2 id="practical-issues">Practical Issues</h2>
<p>在实践中求得了 PC
的表达式，还需要进行一定的取舍和判断，从而选出需要使用的值。</p>
<p>理论很巧妙，但我真的不想写代码实现（</p>
<h3 id="how-many-principal-components-to-retain">How many principal
components to retain</h3>
<p>可以画一个 scree plot，值在底端且明显小的需要排除。对于 sample
principal component score 且是 standardized sample 的情况下，可以选取
cutoff point 是 <span class="math inline">\(1\)</span>，舍弃所有使得
<span class="math inline">\(Var(Y_i) &lt;1\)</span> 的
PCs，留下的即是真正的主成分。</p>
<h3 id="check-normality-assumption-detect-outliers">Check normality
assumption &amp; detect outliers</h3>
<ul>
<li>检验正态性可以用最大的几个 PCs</li>
<li>检验离群值可以用最小的几个 PCs</li>
</ul>
<h3 id="limitations">Limitations</h3>
<ul>
<li>PCA
只使用了协方差矩阵里的值，实际上没有把数据包含的信息利用完全</li>
<li>只进行线性变换</li>
<li>很难反映变量之间的线性关系</li>
<li>对离群值敏感</li>
</ul>
<h1 id="后记">后记</h1>
<p>期中考完就退课了，于是这一篇写到 lecture 6 就烂尾了，乐（</p>
<p>多元问题确实太难了，我到现在绩点最低的一门数学课是微积分
A(2)，<del>意思是别的都 4.0 就它 3.6
还是五个学分（这是可以说的吗）</del>。当时就觉得多元微积分真的好麻烦。然而多元统计难度不在多元而在统计，这属实是我没想到的。</p>
<p>之前在 Vincent19 主页上看到过这样一句话：</p>
<blockquote>
<p>A key difference between mathematics and statistics is that the
former is full of lemmas while the latter is full of dilemmas.</p>
</blockquote>
<p>事实上，统计对我来说最大的困难还是面对 dilemma
应该怎么做这样的问题。半个学期下来我始终觉得如今学到的处理统计问题的方法都是原始而
trivial
的，你能想到的最容易的方法就是最好的解决方案。线性回归课堂上没有任何需要动脑超过五分钟的推导，周老师时不时说我们这个不是数学课，数学不好也不要害怕，这让我无比难受，我自己是否也有点阴暗了。然而无论是看图用眼睛做模型诊断，还是写无穷无尽却又几乎一成不变的
R code 然后在 ANOVA table
里分析数据和模型参数的细微差别，都几乎让我崩溃。多元统计时不时出现的 CI
选择和“几何直观”也一样困扰我。我想我真的不擅长处理这么具体的场景，我宁愿去读晦涩的
lemma，像解谜游戏一样，我还是只喜欢做游戏。</p>
<p>所以，统计中心的应统课果然还是不适合我，或许数学系的统计课会稍有不同，或许不会这么纠结现实的应用问题，但我还是厌倦了。另外，我发觉自己的分析水平也没那么差。如果不是再退线性回归的话这学期要没课上了，其实是想一起丢掉的。只能说我还是太弱了，从数学转去搞统计的同学不在少数，好像只有我这样困扰。</p>
<p>当时写统推笔记的时候在开头写下了“实在不行的话，（方向）该换还得换啊”这样的话，然而统推很顺利地上完了，还以为方向就这么定下来了，不用再继续颠沛流离。现在却是又一次要换掉了，再一次抛弃一切。开玩笑的，统计转概率也不算是放弃一切，不然怎么会合称“概统”呢。</p>
<p>我之前写“感觉自己 20th
的主题是出走”，后来觉得不是，出走会是我一生的主题，cause I have a vast,
vast soul.</p>
<p>希望自己在概率这条路上走得远一点吧，暂时先和统计说再见了...等等还有两门课还在上呢（</p>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>统计</tag>
        <tag>课程实录</tag>
      </tags>
  </entry>
  <entry>
    <title>数学分析 I 速通日志（上）</title>
    <url>/2023/01/15/Learn-Mathematical-Analysis-or-Die/</url>
    <content><![CDATA[<p>大二的寒假，我居然为了下学期不在概率论和复分析课上被爆杀，而在这儿速通数分。</p>
<p>转数环环友：你可以以任意顺序完成培养方案（</p>
<span id="more"></span>
<p>虽然已经学过一遍初级版，这次速通是作为观点的补充和复习，但还是很虚的。</p>
<p>说到这个任意顺序完成培养方案，摘一个 PIN 的前言（逃</p>
<blockquote>
<p>事实上，我们所接触的大多国内优秀同学都直接或者间接地默认数学学习一定顺序，须得按部就班，层层递进，才能扎实地进步。这种想法本身没有错，但是数学的发展绝对不是线性的，知识也不存在先天的顺序。一个普遍被提及的例证就是从
Newton 引入积分 (反流数术) 到 Cauchy
的极限理论被广泛接受中间至少有半个世纪的光景，
那个优秀的数学家层出不穷，利用还没有被严格化的积分理论作出了很多享誉后世的工作。</p>
<p>数学学习不应该被课程设置 (甚至被其名称)
切割。比如说，所谓的曲线或者曲面的几何学、数学物理方程都可以称为 (多元)
微积分学习的好例题，很多微积分知识就是为了解决这样的问题应运而生的。微积分课程就应该学习和研究这样的例子，不能简单地将它们归结为是微分几何或者微分方程的内容而忽略。仅仅为了教学而刻意构造的各种例题长远来看有目光短浅之嫌。这种做法通常还会从心理上折射出胆怯的影子，以至于有同学误以为课程的顺序和难度有关联，“后面”
的课程比 “前面” 的课程困难。唯有正视，方能前行。</p>
</blockquote>
<p>高二的时候我曾经备考过一阵子丘班
(prototype)，不过因为当年联赛翻车省三的原因（，连初审都没有通过。组队备考的五个人里只有我们的队长
ycj
顺利去了北京，又通过了笔试，最终在面试中被刷掉了，他现在在上海理工大学，真的很可惜。cy
后来放弃了，安心备考
CMO，拿了银牌，现在在华子读数学，太成功了！不过虽然秋季学期一同上了数值分析，我至今也没和他面基成功。xzx
和 wry
似乎分别去了西安交大和上海财大，和他们没有很熟，后来也没再联系了。</p>
<p>同时，这一段自学给我留下了对数分深刻的心理阴影，和不知道怎么手选又问不明白并列成为了大一没有学数分，而是选了微积分
A 的两大原因，也成为了我本科很可能延毕一年的众多原因之二（</p>
<p>使用的教材是常庚哲、史济怀《数学分析教程》，速通讲义是北京大学数学分析讲义和<a href="https://www.bananaspace.org/wiki/%E8%AE%B2%E4%B9%89:%E6%95%B0%E5%AD%A6%E5%88%86%E6%9E%90">一千零一页</a>，前者是后者的子集，的确更友善一些，用于提点重点，感谢甘主任对速通事业的支持！习题册是谢惠民《数学分析习题课讲义》，不过我觉得应该来不及做太多。</p>
<p>并不是打算写知识点，没什么必要，只是想在这里哔哔赖赖一下，或许会试着虚空使用
Feynman
学习法？毕竟是速通，要快一些，不然下学期就寄了。发这一篇的主要目的是虚空被监督进度，毕竟我的效率实在是低下。</p>
<p>按照欧老师的年终（粗略）统计，数分二和三课后加起来花了 210
h，我打算速通到数分二为止，也就是整个寒假每天都在学的话，日均也要学 7
h（。这显然是不可能的，毕竟我同时还有一些其他事务要做，比如点 R
的技能树、编写统推讲义、推
SRT、以及准备缓考科目。最重要的是，我还得摸鱼和出去玩啊！但还是尽量试试看，学到哪算哪，够用就行（了吗？</p>
<h1 id="实数的构造">实数的构造</h1>
<h2 id="从抽代出发事情变得简单了很多">从抽代出发，事情变得简单了很多</h2>
<p>2023 年 1 月 17 日，星期二，很冷还没有暖气。</p>
<p>大一的时候报了 wxf 老师的微积分
A，这一块他其实也讲了一些，但是并不够严谨，我听着有点痛苦。说实在的我就不喜欢他这个授课的方式，下放知识又不彻底，等于炫技，不如不要下放。</p>
<p>结果因为他不查考勤，微积分 A2 还是选了他的，最后大翻车。</p>
<p>这一次会更加严谨、耐心，并保持好奇。</p>
<ul>
<li><p>用域公理、序公理和 Achimedes
公理定义了实数域；整数和有理数可以用映射嵌入实数域，这个嵌入映射对于整数是单射。</p>
<p>这个学过抽代之后倒是很好理解了，构造出域之后就有了最基本的三个元素
<span class="math inline">\(0,1,-1\)</span>，把 <span class="math inline">\(n\)</span> 个 <span class="math inline">\(1\)</span> 加起来就是正整数 <span class="math inline">\(n\)</span>，考虑整数的分式域就是有理数域。实数域是一个特征为
<span class="math inline">\(0\)</span>
的域，这样构造出来的有理数域是它的最小子域，也即素域。</p>
<p>为有理数定义了序关系 <span class="math inline">\(\frac{m}{n}&gt;\frac{p}{q} \iff mq&gt;np\)</span>
之后， 就可以把序关系也嵌入到实数域里了，是成立的。</p></li>
<li><p><span class="math inline">\(\mathbb{Q} \subseteq
\mathbb{R}\)</span>，但是还没有从域的角度定义出 <span class="math inline">\(\mathbb{R} - \mathbb{Q}\)</span>
里的元素，也就是无理数。仅仅是如上定义的话，一个所谓的实数域里完全可以只有有理数，也能满足序公理、域公理和
Achimedes 公理，而我们想要一些其他的元素。比如说，<span class="math inline">\(\sqrt{2}\)</span> 怎么定义？</p>
<p>当然可以对 <span class="math inline">\(\mathbb{Q}\)</span>
做关于多项式 <span class="math inline">\(x^2-2\)</span> 的 Galois
扩域（暴论，我不是很清楚这两个理论体系到底谁先谁后，还是别这么干比较好），但是这样可以做出很多形式上不相同的域，比如熟知的
<span class="math inline">\(\mathbb{Q} (\sqrt{2})\)</span> 和 <span class="math inline">\(\mathbb{Q}[x] /
(x^2-2)\)</span>，虽然它们本质上是同构的，但序关系无从保障。所以还是换个方法，也就是后面的
Dedekind 分割。</p></li>
<li><p>确界原理的证明非常炫酷，我每次写完一遍都觉得非常牛逼，可惜后来只记得是用每次缩小一半的区间套证明，具体细节还是自己写不出来。</p>
<p>但是这样得到的 <span class="math inline">\(sup X\)</span>
是一个闭区间套的极限，并不好用。更加好用的定义是对于任意 <span class="math inline">\(\varepsilon &gt;0\)</span>，存在 <span class="math inline">\(x \in X\)</span>，使得 <span class="math inline">\(x&gt;sup X -
\varepsilon\)</span>。通俗一些说，上确界再小一点点都不可以。</p>
<p>如果反过来假设确界定理成立，闭区间套公理可以很容易地被证明，只要分别取
<span class="math inline">\(\lbrace a_n \rbrace\)</span> 的上确界和
<span class="math inline">\(\lbrace b_n \rbrace\)</span>
的下确界，夹出的区间就恰好是所有区间的交集。在已有序公理、域公理和
Achimedes 公理的情况下二者是等价的。</p></li>
<li><p>度量空间在数值分析课堂的引论里学过，当时在讲矩阵的范数如何定义，是从最普通的
<span class="math inline">\(\mathbb{R}
^n\)</span>讲起的，赞美包老师。虽然他这样根本不像在给数学系讲课，感觉有点照顾非数学系选课学生的意思。我的数分真是吃百家饭，这样也很好，多少消除一些曾经的心理阴影。</p>
<p>对于度量空间 <span class="math inline">\((X,d)\)</span>，<span class="math inline">\(Y \subset X\)</span> 是子集，如果对任意的 <span class="math inline">\(x \in X\)</span> 和任意的 <span class="math inline">\(\varepsilon &gt;0\)</span> 都存在 <span class="math inline">\(y \in Y\)</span>，使得 <span class="math inline">\(d(y,x)&lt; \varepsilon\)</span>，那么称 <span class="math inline">\(Y\)</span> 在 <span class="math inline">\(X\)</span> 上是稠密的。直观上来说，就是 <span class="math inline">\(X\)</span> 上任意一个点都有 <span class="math inline">\(Y\)</span>
上的一个点和它离得要多近有多近。举个例子的话，有理数和无理数在实数上都是稠密的，证明起来很简单，反复二分就可以了。</p></li>
<li><p>然后就是线性空间的定义，印象里线性代数的最后一章就是学这个，当时不知道数域是什么，给我愁的，以为真的要把八条运算法则都背下来来证明一个东西是某个域上的线性空间，<del>当时要是会抽代就好了</del>。</p>
<p>总之，<span class="math inline">\(F\)</span> 是一个数域，<span class="math inline">\(V\)</span>
是某一集合，满足一些运算法则的时候，三元组 <span class="math inline">\((V,+,\times )\)</span> 是一个 <span class="math inline">\(F-\)</span> 线性空间。</p></li>
</ul>
<p>今天的数分就学到这里
.jpg，内容大约是一周的量，还是有点少。明天再来.jpg</p>
<p>2023 年 1 月 18 日，星期三，还是很冷但是稍微升温了一些。</p>
<ul>
<li><p>要开始构造实数了！用的是 Dedekind 分割。这个我也在 wxf 的微 A
课上听过，但他讲得并不认真，仅限念了一遍定义。后一节课课前有同学提问说，为什么一左一右两个集合就能代表一个实数呢？他不是很愿意理会的样子，反问说你是不是补退选进来的所以没听过第一节课啊，一只羊为什么代表
<span class="math inline">\(1\)</span>
呢，两个集合怎么不能代表一个数呢。</p>
<p>他可能是觉得这个问题太 trivial
了吧，也或许只是当天心情不好而已，然而提问的同学看起来还是没理解的样子，还平白无故被敲打了一下，就茫然地坐下了。Anyway，在这之后我对这个课堂的印象就不是很好，后续也很少再去上课了。只是觉得，为什么不能好好讲清楚道理呢，就告诉同学理由是从几何直观的角度来看，把实数轴任意截断的一点都是实数，有这样的一个定义不就好了吗。当然，当然，应该是我吹毛求疵了，他可能真的只是当天心情不好，所以不太想解释，后来我也没怎么再听过他上课，不清楚还有没有类似的状况，可能属于是不小心碰到了一个极端情况。</p>
<p>另外，单是讲过这个有什么意思呢，不说 Dedekind
分割满足序公理所以确实可以定义出实数，也不拿来用一下，就莫名其妙放一个定义在这里，课后又让做题目，感觉是在炫技。后来我也看过一部分他的讲义和回放，挺多莫名其妙的安排都有点像炫技，就彻底放弃跟进度，自己单开了。不过确实也没人逼你选他的微积分课，接受不了的话，换别的老师的课堂就好了，或许是个伪命题吧。</p>
<p>虽然大多数同学都吹 wxf
讲课有多好，但我其实相当怀疑他们有一部分并没有听明白课堂内容，觉得老师讲的内容很高深，自己吹捧老师的话会显得很厉害而已。另外听说
wxf
的答疑确实很认真，或许大家说他好是指这一部分吧，还是指他喜欢在课堂上和群里讲笑话？PPT
和讲义是准备得挺认真的，可惜我并不觉得设计得好，<del>感觉白认真了</del>。总之我是不太喜欢这种不彻底也不成体系的高阶知识下放，或许它自有意义，带大家了解一下也好。当然，和我相反的典型就是
wl 他们，是真的学得很好，也喜欢 wxf
的课堂，所以我这些话很可能只是弱者的托词而已。也是啊，我觉得他讲得不好，大一的时候干嘛不自己去看一千零一页，而是单开去拟合微积分往年习题了呢，乐。</p>
<p>弱者的牢骚暂且发到这里，下面继续说点正经的。</p></li>
<li><p>这下三纸无驴了。注意 Dedekind
分割的断点是有理数时，会把它归到右侧区间里，这是为了保证左侧无最大元。一般把左侧的区间记为
<span class="math inline">\(X\)</span>，也称这个分割代表的实数是 <span class="math inline">\(X\)</span>。</p>
<p>Dedekind
分割是满足序公理的，在这里需要先定义这一分割的序关系。对于实数 <span class="math inline">\(X,Y\)</span>，如果 <span class="math inline">\(X
\subsetneq Y\)</span>，则有 <span class="math inline">\(X&lt;Y\)</span>。这个很好理解，<span class="math inline">\(X\)</span> 比 <span class="math inline">\(Y\)</span> 短一些，也就是 <span class="math inline">\(X\)</span> 的端点在 <span class="math inline">\(Y\)</span> 左侧，即 <span class="math inline">\(X&lt;Y\)</span>。再证明这个序关系满足序公理的五条要求即可。</p>
<p>有了这样一个对实数的描述，就可以写出确界定理的第二种证明，也很炫酷。</p></li>
<li><p>现在我们有了一个叫做实数的东西（Dedekind
分割），它离组成实数域还差很远，因为域上的两种运算，加法和乘法，尚未被定义。我们来定义一下，然后先证明它是良好定义的，不会出
bug。这指的是，对于两个实数的运算结果也是 Dedekind
分割，且满足若干加法公理，并且是加法良定义的。</p>
<p>加法定义：<span class="math inline">\(X+Y=\lbrace x+y | x \in X,y \in
Y \rbrace\)</span>，零元素为 <span class="math inline">\(\bar{0} = X_0 =
\lbrace x \in \mathbb{Q} | x&lt;0 \rbrace\)</span>。</p>
<p>乘法定义：恒等元为 <span class="math inline">\(\bar{1}= X_1 = \lbrace
x \in \mathbb{Q} | x &lt;1
\rbrace\)</span>，需要根据正负性来分类定义。这个是 PIN
的作业，我写作业去了。</p></li>
</ul>
<h2 id="summary">Summary</h2>
<p>总之，在第一章里面，于我而言实际上是在抽代的基础上，为一个特征为
<span class="math inline">\(0\)</span>
的域在其素域的基础上添置了一些多余元素，让它也满足序公理和 Achimedes
公理，这就符合实数域的定义了。为了使用的方便起见，又用 Dedekind
分割确定了实数域元素的具体形式，把它和日常使用的实数域对应起来。这一过程中为了磨合一些
bug，完成了不计其数的良定义确认，我愿称之为夜话团圆。</p>
<p>素域就是熟知的 <span class="math inline">\(\mathbb{Q}\)</span>，由恒等元和零元素造出的整数环与其分式域构成。在此基础上，对素域元素做了一个序关系的定义，并嵌入实数域中，证明了它是符合序公理和
Achimedes
公理的。这说明这一做法可行，下一个任务就是具象化实数域的元素，也即实数。</p>
<p>第二个创举是用 Dedekind
分割构造所谓的实数的确切形式，这里用了一个几何的观点，就是把实数轴折断，把左半边的集合
<span class="math inline">\(X\)</span>
称为一个实数，通俗意义上来说，它代表的实际上是断点处的那个真正的实数。我们对创造出的这个实数进行了集合意义上的序、加法和乘法的定义。于是全体
Dedekind 分割真正意义上构成了一个满足序公理和 Achimedes
公理的域，这便和我们日常使用的实数没有差别了。</p>
<p>此外，还有一个很有趣的东西叫做确界原理，它描述的是一个有上/下界的集合必有上/下确界。围绕它有三个证明，前两个是证明确界原理和区间套公理等价，第三个是用
Dedekind
分割作出的确切的实数来证明确界原理的确成立。用区间套公理推确界原理的证明最酷炫，希望我以后还能记得怎么做，以及它的细节。</p>
<p>抽代真好用，赞美。我建议大家都和我一样，先学代数再学分析（什么啊</p>
<p>学到这里，学过的几门数学课已经被充分利用过了。微积分自不必说，抽代上面说过了，高代的线性空间定义也出现过了，赋范空间和度量空间在数值分析的引论课上听过，甚至写习题写到可数理论，给了我一点小小的离散数学震撼，我以前一直以为这课没用，白学了。往后云端漫步了一点，在数分
II 里找到了上学期在初概里了解过的 <span class="math inline">\(\sigma
-\)</span>代数，其实属于是测度知识了，但把它当成高等概率论知识也未尝不可嘛（。另外我的初概学得稀烂，可以近似认为是在统计推断里学会的，也算是做了贡献（，不然就它还没出镜啦。</p>
<p>什么叫做可以以任意顺序修完培养方案啊。我现在也理解为什么说数分难了，大一入学第一节课就学这玩意的话，反正我一下子受不了，会很想退学。不过这以前是
Yau 班讲义来着，难怪我不配（</p>
<h2 id="梦话可数集与不可数集">梦话：可数集与不可数集</h2>
<p>2023 年 1 月 19 日，星期四，v 我 50，谢谢。</p>
<p>在第一章继续逗留了一会，想补充一些可数（或者说可列）的东西。</p>
<p>刚拿到习题的时候以为是离散数学，后来发现还是不太一样。这一部分先由
PIN
的习题展开，顺便理一下我在离散数学里学到的东西，发现两边在用不太类似的定义逻辑，接合在一起之后也有些
happily ever after 了。</p>
<p>终于在香蕉空间找到了开源的页面，省了很多打字的心力，赞美！以及发现原来最初编写这份讲义的是曾经访问了我博客的
zrc 学长，由可爱的 _rqy
完成了香蕉空间上的工作，世界真小，qwq，感谢前辈做出的贡献。</p>
<h3 id="课后习题可数集与不可数集">课后习题：可数集与不可数集</h3>
<p>令 <span class="math inline">\(\mathbb{N}\)</span>
表示自然数的集合（包括 <span class="math inline">\(0\)</span>）。<span class="math inline">\(X\)</span> 是一个集合，如果存在单射 <span class="math inline">\(f\colon X\rightarrow \mathbb{N}\)</span>，我们就称
<span class="math inline">\(X\)</span> 是可数的。如果 <span class="math inline">\(X\)</span> 不是可数的，我们就称它是不可数的。</p>
<ul>
<li><p>证明，有限集是可数的。</p>
<p>Trivial.</p></li>
<li><p>证明，可数集合的子集是可数的。</p>
<p>Trivial，原映射的“一部分”，也就是它的导出映射对于剩余的元素仍然为单射。</p></li>
<li><p>证明，如果 <span class="math inline">\(X\)</span>
是可数集，那么我们总可以将 <span class="math inline">\(X\)</span> 写成
<span class="math inline">\(X=\{x_1,x_2, x_3,
\cdots\}\)</span>（即可以把 <span class="math inline">\(X\)</span>
中的元素用自然数来标号）。（我们可以从一个开始一个一个的数下去把这些元素都罗列出来，所以叫做可数集）</p>
<p>存在单射 <span class="math inline">\(f\colon X\rightarrow
\mathbb{N}\)</span>，考虑 <span class="math inline">\(Im f\)</span>
是一个自然数集合，由其一般性知可以表示为 <span class="math inline">\(\{
1,2,3,... \}\)</span>。</p></li>
<li><p>证明，有理数 <span class="math inline">\(\mathbb{Q}\)</span>
是可数集。</p>
<p>可以按分子分母绝对值之和写个大三角，不过我在知乎上看到过<a href="https://www.zhihu.com/question/361519628/answer/1872181083">一个很酷的证明</a>，摘录如下：</p>
<blockquote>
<p>不难证明 <span class="math inline">\(\mathbb {N}\times \mathbb
{N}\)</span> 是可数集（考虑双射 $(n,m)^n(2m+1)-1 $），从而 <span class="math inline">\(\mathbb Z\times(\mathbb Z\backslash
\{0\})\)</span> 可数。</p>
<p>由 Cantor-Schröder–Bernstein 定理即得证。</p>
</blockquote></li>
<li><p>证明，可数个可数集合的并集也是可数集，也就是说，如果 <span class="math inline">\(X_1,X_2, \cdots, X_n, \cdots\)</span>
都是可数集合，那么它们的并集 <span class="math inline">\(\displaystyle
\bigcup_{n\geqslant 1} X_n\)</span>
也是可数集合。（提示：这是一个需要记住的经典证明，请查阅参考书或者网络）</p>
<p>排矩阵，列大三角。</p></li>
<li><p><span class="math inline">\(X\)</span> 是可数的，映射 <span class="math inline">\(f\colon X\rightarrow Y\)</span>
是满射。证明，<span class="math inline">\(Y\)</span> 是可数的。</p>
<p>存在单射 <span class="math inline">\(g \colon Y \to X\)</span> 和
<span class="math inline">\(h \colon X \to \mathbb N\)</span>，其复合
<span class="math inline">\(g \cdot h \colon Y \to \mathbb N\)</span>
也是单射。</p></li>
<li><p>按照以下步骤证明 <span class="math inline">\(\mathbb R\)</span>
是不可数的（同学们可以查阅一个用所谓对角线法则的经典证明，我们的证明基于区间套原理）：</p>
<ul>
<li><p>若 <span class="math inline">\(J\subset \mathbb R\)</span>
是闭区间并且它的长度 <span class="math inline">\(|J|&gt;0\)</span>。证明，对任意的 <span class="math inline">\(x\in \mathbb R\)</span>，总存在闭区间 <span class="math inline">\(I\)</span>，使得 <span class="math inline">\(I\subset J\)</span>，<span class="math inline">\(|I|&gt;0\)</span> 且 <span class="math inline">\(x\notin I\)</span>。</p>
<p>用实数 <span class="math inline">\(x\)</span> 的 Dedekind
分割定义，取 $ I = J X^ $，只要证明它的长度非 <span class="math inline">\(0\)</span>，trivial.</p></li>
<li><p>证明，如果 <span class="math inline">\(\{x_1,x_2,\cdots\}\)</span> 是 <span class="math inline">\(\mathbb R\)</span>
的一个可数子集，那么存在闭区间套 <span class="math inline">\(I_1\supset
I_2 \supset \cdots\)</span>，使得对任意的 <span class="math inline">\(n\)</span>，<span class="math inline">\(x_n \notin
I_{n}\)</span>。</p>
<p>取 <span class="math inline">\(I_1\)</span> 为 <span class="math inline">\(X_1 ^\prime\)</span> 的长度大于 <span class="math inline">\(0\)</span> 的闭区间，按上一问的方法构造闭区间
<span class="math inline">\(I_2\)</span>，使得 <span class="math inline">\(I_2 \subset I_1\)</span>，<span class="math inline">\(|I_2|&gt;0\)</span> 且 <span class="math inline">\(x_2\notin I_2\)</span>。类似地构造 <span class="math inline">\(I_3,I_4,...\)</span> 即可。</p></li>
<li><p>证明，<span class="math inline">\(\mathbb R\)</span> 不可数。</p>
<p>反证法，设 <span class="math inline">\(\mathbb R\)</span> 可数，也即
<span class="math inline">\(\mathbb R\)</span> 可以表示成 <span class="math inline">\(\mathbb R =\lbrace x_1,x_2,... \rbrace\)</span>
的形式。因此存在上述的闭区间套，使得闭区间的交集里不含有 <span class="math inline">\(\mathbb R\)</span>
的任何一个元素，是一个空集。这和区间套公理是矛盾的。</p>
<p>嗯？这就证明完了？好美妙！</p></li>
</ul></li>
<li><p>证明，如果 <span class="math inline">\(X\)</span>
是不可数集，<span class="math inline">\(A\)</span> 是 <span class="math inline">\(X\)</span> 的可数子集，那么 <span class="math inline">\(X-A\)</span> 是不可数的。</p>
<p>反证法，trivial.</p></li>
<li><p>证明，任意的长度不为 <span class="math inline">\(0\)</span>
的区间（无论开或闭）都是不可数的。</p>
<p>反证法，否则它是可数的，可以表示成 $X= x_1,x_2,... $
的形式。于是也可以按前述方法构造出其上的一个区间套 <span class="math inline">\(X \supset X_1 \supset X_2 \supset
...\)</span>，满足除了 <span class="math inline">\(X\)</span>
之外的区间都是闭区间，且闭区间的交集是空集，这是矛盾的。</p></li>
<li><p>证明，复数 <span class="math inline">\(\mathbb{C}\)</span>
是不可数的。</p>
<p>反证法，如果复数集是可数的，它的子集 <span class="math inline">\(\mathbb R\)</span> 也一定可数，矛盾。</p></li>
<li><p>假设 <span class="math inline">\(\mathcal{I}\)</span> 是 <span class="math inline">\(\mathbb R\)</span>
上的某些开区间组成的集合，它满足如下性质：对任意的 <span class="math inline">\(I,J \in \mathcal{I}\)</span>，<span class="math inline">\(I\neq J\)</span>，那么它们的交集是空集，即 <span class="math inline">\(I\cap J=\emptyset\)</span>。证明，<span class="math inline">\(\mathcal{I}\)</span> 是可数集。</p>
<p>习题没有答案，于是我只能做一些不负责任的暴论：</p>
<p>回到定义，想找一个从 <span class="math inline">\(\mathcal I\)</span>
到 <span class="math inline">\(\mathbb N\)</span> 的单射 <span class="math inline">\(f\)</span>。只要考虑在 <span class="math inline">\(R_ +\)</span> 上的全体集合，对任意的 <span class="math inline">\(I \in \mathcal I\)</span>，取 <span class="math inline">\(f(I)\)</span> 为区间 <span class="math inline">\(I\)</span>
覆盖的最小整数，这些整数一定两两不同，也就构成了一个到 <span class="math inline">\(\mathbb N\)</span> 的单射。</p>
<p>但是不一定每个区间都覆盖一个整数，所以我想做个不负责任的操作：如果
<span class="math inline">\(I = (a,b)\)</span>
不覆盖整数，则将所有区间的端点关于 <span class="math inline">\(a\)</span> 的距离放大，直到放大后的区间 <span class="math inline">\(I ^ \prime =(a,b ^ \prime)\)</span>
能覆盖住某一个整数，从左至右对每一个区间都这样操作。</p></li>
</ul>
<p>找到了作者在源代码注释里留下的彩蛋：</p>
<ul>
<li><p>证明，不能用可数条直线覆盖平面，即如果 <span class="math inline">\(\ell_1,\ell_2,\cdots\)</span> 是平面 <span class="math inline">\(\mathbb{R}^2\)</span> 上可数条直线，那么 <span class="math inline">\(\displaystyle \bigcup_{k\geqslant 1}\ell_k\neq
\mathbb R^2\)</span>。</p></li>
<li><p>一个圆心在 <span class="math inline">\((x_0,y_0)\)</span>
处，半径为 <span class="math inline">\(r&gt;0\)</span> 的闭圆盘 <span class="math inline">\(\overline{B_r(x_0,y_0)}\)</span>，指的是：</p>
<p><span class="math inline">\(\overline{B_r(x_0,y_0)}=\{(x,y)\mid
(x-x_0)^2+(y-y_0)^2\leqslant r^2\}\)</span>；</p>
<p>证明，不能用（无论可数个还是不可数个）两两不相交的闭圆盘（半径大于零）（圆心和半径可以变化）覆盖
<span class="math inline">\(\mathbb
R^2\)</span>，使得两个不同的圆盘至多有一个点是重合的。</p></li>
<li><p>纯属娱乐，对后面学习分析并无帮助。</p></li>
</ul>
<h3 id="课后习题-schroeder-bernstein-定理">课后习题：
Schroeder-Bernstein 定理</h3>
<p>实际上，PIN 还有一道习题 Schroeder-Bernstein
定理。这道题就不打算写了，学不完了
.jpg，我把它轻轻放在这里，作为后面补充的引子：</p>
<p>假设 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span> 是两个集合，映射 <span class="math inline">\(f\colon X\rightarrow Y\)</span> 和 <span class="math inline">\(g\colon Y\rightarrow X\)</span> 都是单射。我们令
<span class="math inline">\(X&#39;=X-g(Y)\)</span>。</p>
<ul>
<li><p>如果 <span class="math inline">\(X\)</span> 是有限集，证明，存在
<span class="math inline">\(\varphi\colon X\rightarrow Y\)</span>，使得
<span class="math inline">\(\varphi\)</span> 是双射。</p></li>
<li><p>如果 <span class="math inline">\(X\)</span> 是可数集，证明，存在
<span class="math inline">\(\varphi\colon X\rightarrow Y\)</span>，使得
<span class="math inline">\(\varphi\)</span> 是双射。</p></li>
</ul>
<p>从现在开始，对 <span class="math inline">\(X\)</span>
不加任何的限制。 我们令 <span class="math inline">\(h\colon X\rightarrow
X\)</span> 是复合映射 <span class="math inline">\(h=g\circ
f\)</span>。</p>
<ul>
<li><p>考虑 <span class="math inline">\(X\)</span> 的子集的集合 <span class="math inline">\(\mathcal{F}=\{A \subset X\mid X&#39;\cup
h(A)\subset A \}\)</span>。证明，<span class="math inline">\(\mathcal{F}\)</span> 非空。</p></li>
<li><p>证明，如果 <span class="math inline">\(A\in
\mathcal{F}\)</span>，那么 <span class="math inline">\(X&#39;\cup
h(A)\in \mathcal{F}\)</span>。</p></li>
</ul>
<p>我们定义<span class="math inline">\(A_0=\bigcap_{A\in
\mathcal{F}}A=\{x\in X\mid\)</span>对任意的<span class="math inline">\(A\in \mathcal{F},\)</span>都有<span class="math inline">\(x\in A\}\)</span>。</p>
<ul>
<li><p>证明，<span class="math inline">\(A_0\in\mathcal{F}\)</span>。</p></li>
<li><p>证明，<span class="math inline">\(X&#39;\cup
h(A_0)=A_0\)</span>。</p></li>
<li><p>令 <span class="math inline">\(B_0=X-A_0\)</span>。证明，<span class="math inline">\(f(A_0)\cap g^{-1}(B_0)=\emptyset\)</span> 并且
<span class="math inline">\(f(A_0)\cup g^{-1}(B_0)=Y\)</span>。</p></li>
<li><p>我们定义映射 <span class="math inline">\(\varphi\colon
X\rightarrow Y\)</span>：对于 <span class="math inline">\(x\in
X\)</span>，我们要求 <span class="math inline">\(\varphi(x)=\begin{cases}f(x), \ &amp;\text{如果}
x\in A_0;\\g^{-1}(x), \ &amp;\text{如果} x\in
B_0.\end{cases}\)</span></p>
<p>证明，这是双射。</p></li>
</ul>
<p>根据上述，我们证明了 Schroeder-Bernstein 定理：如果有单射 <span class="math inline">\(f\colon X\rightarrow Y\)</span> 和单射 <span class="math inline">\(g\colon Y\rightarrow
X\)</span>，那么存在着两个集合之间的双射 <span class="math inline">\(\varphi\colon X\rightarrow Y\)</span>。</p>
<h3 id="离散数学复习等势与基数">离散数学复习：等势与基数</h3>
<ul>
<li><p>在离散数学里，更确切一点讲，在集合论里，介绍了一种关系，叫做等势。这一概念由
Cantor
提出，用来解决这样的一个困惑：为什么完全平方数貌似比正整数少很多，但是它们却可以一一对应？如何比较两个无穷集合谁的元素多，谁的元素少，谁更“无穷”？</p>
<p>等势被定义为：如果集合 <span class="math inline">\(X\)</span> 和
<span class="math inline">\(Y\)</span>
之间如果存在双射，那么称二者等势，利用 Schroeder-Bernstein
定理可知如果有单射 <span class="math inline">\(f\colon X\rightarrow
Y\)</span> 和单射 <span class="math inline">\(g\colon Y\rightarrow
X\)</span>，那么 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span> 等势，写作 <span class="math inline">\(X \approx Y\)</span>。实际上有 <span class="math inline">\(\mathbb N \approx \mathbb Q \approx \mathbb
Z\)</span>，等等。</p></li>
<li><p>另外一个定义是集合的基数，记为 <span class="math inline">\(card(X)\)</span>，精确地测量集合的某些性质。我们定义
<span class="math inline">\(card(X) \leq card(Y)\)</span> 等价于有单射
<span class="math inline">\(f\colon X\rightarrow
Y\)</span>，因此由等势的结论，有 <span class="math inline">\(card(X)=card(Y)\)</span> 等价于 <span class="math inline">\(X \approx
Y\)</span>。与此同时，我们希望对这个虚无缥缈的概念做一些基本的规定，比如说把某些特殊的集合的基数作为标尺，来衡量其他集合的基数大小。我们选取了
<span class="math inline">\(card(\mathbb N) = \aleph _0\)</span>，<span class="math inline">\(card(\mathbb R) = \aleph _1\)</span>
作为这样的尺度。</p>
<p>当然，对于有穷的集合，它的基数就是它的元素个数，此时称为有限基数，否则称为无限基数，我们不对有限基数多做讨论。上述的“尺度”中，<span class="math inline">\(\aleph _0\)</span>
是最小的无限基数，它也大于所有的有限基数。</p></li>
<li><p>基数理论的一个用处在于，可以用来衡量无穷集合的可数性。一个集合
<span class="math inline">\(X\)</span> 满足 <span class="math inline">\(card(X) \leq \aleph _0\)</span>
等价于它是可数的，也就是说，可数集 <span class="math inline">\(X\)</span> 要么是有限集合，要么基数是 <span class="math inline">\(\aleph _0\)</span>，可以和 <span class="math inline">\(\mathbb N\)</span>
一一对应，也就是习题里面提到的，可数集可以表示成 <span class="math inline">\(X = \lbrace x_1,x_2,... \rbrace\)</span>
的形式。</p></li>
</ul>
<p>但是，离散数学没有解答的是，为什么基数可以比较大小？我们可以看到
<span class="math inline">\(\aleph _0\)</span>，$_1 $
的出现，就代表了基数的取值未必是实数域上的子集。那么它的取值集合上的序关系是怎么定义的，是否满足序公理？</p>
<ul>
<li>实际上，对于集合 <span class="math inline">\(X,Y\)</span>，序关系
<span class="math inline">\(card(X) \leq card(Y)\)</span>
成立等价于有单射 <span class="math inline">\(f\colon X\rightarrow
Y\)</span>。由此就可以验证这个关系满足序公理了。</li>
</ul>
<p>但是为什么任意两个基数都可以比较大小呢？在 <span class="math inline">\(\mathbb R\)</span>
之外还有更多稀奇古怪的集合，以前可能想象不出来，学了抽代之后一想这些真的毛骨悚然，它们都可以互相将基数拿来比较大小吗？</p>
<ul>
<li>答案是可以的，但还是到实分析里再学吧（</li>
</ul>
<p>这样再看 Cantor 定理，也就是实数集 <span class="math inline">\(\mathbb R\)</span>
不可数这一条定理，写成基数的形式就等价于，<span class="math inline">\(\aleph _1 = card(\mathbb R) &gt; \aleph
_0\)</span>。</p>
<ul>
<li><p>我们在离散数学里定义了 <span class="math inline">\(card(\mathbb
N) = \aleph _0\)</span>
是最小的无限基数，却没有说明为什么最小。也就是没有说明，为什么可数的无限集是无限集里面最小的。所以，暂时只能从已经证明出的
<span class="math inline">\(\mathbb R\)</span> 不可数，来证明 <span class="math inline">\(\aleph _1 &gt; \aleph _0\)</span>
这两个特殊的无限基数之间的大小关系。</p></li>
<li><p>Cantor 给出了另外一个证明。记 <span class="math inline">\(\mathcal P(X)\)</span> 为 <span class="math inline">\(X\)</span> 的幂集合，也即 <span class="math inline">\(X\)</span>
的全体子集（包括空集和自身）构成的集合。</p>
<p>引理：如果 <span class="math inline">\(X\)</span> 非空，那么 <span class="math inline">\(card(\mathcal P (X)) &gt;
card(X)\)</span>。使用反证法证明，否则二者相等，存在 <span class="math inline">\(\mathcal P (X)\)</span> 和 <span class="math inline">\(X\)</span> 之间的一一对应 <span class="math inline">\(f \colon X \to \mathcal P (X)\)</span>。记 <span class="math inline">\(A = \lbrace x \colon x \notin f(x)
\rbrace\)</span>，证明 <span class="math inline">\(f^{-1} (A)\)</span>
和 $ A$ 不等即可。</p>
<p>而 <span class="math inline">\([0,1]\)</span>
上的实数用二进制表示后，<span class="math inline">\(0\)</span>
的位置构成了自然数集的子集；自然数的任意一个子集都对应一个实数。因此
<span class="math inline">\(R \supset \mathcal P (\mathbb
N)\)</span>，有 <span class="math inline">\(card([0,1]) = card (\mathbb
R) \geq card(\mathcal P (\mathbb N)) &gt; card(\mathbb N) = \aleph
_0\)</span>，实数集不可数。</p></li>
</ul>
<p>最后，虽然看起来有些夜话团圆了，但基数还是很抽象。希尔伯特 23
问的第一问连续统假设即是关于基数的一个看似很基本的问题，问 <span class="math inline">\(\aleph _0\)</span> 和 <span class="math inline">\(\aleph _1\)</span>
之间是否还有别的基数。这一问题被证明和 ZFC
公理体系互相独立，目前仍不知真伪。</p>
<h1 id="极限">极限</h1>
<h2 id="极限数列和级数">极限，数列和级数</h2>
<p>2023 年 1 月 20
日，星期五，睡前本来想看极限结果去写了可数集的补充内容，字数翻了个倍。</p>
<p>这样下去的话，大概要每一个章节开一篇文章写比较合适了。昨天改标题的时候差点把文件名改了，想了想那样的话原有的两条评论显示不出来，不是很妙。或许有迁移
issue
之类的方法，没有试过也没有研究，不清楚能不能做到，多一事不如少一事。</p>
<p>好像没什么可写的，这一部分都和微积分 A
学的内容差不多。不过讲义里的一些观点很有意思，我把原文摘录下来：</p>
<blockquote>
<p>然而，根据极限的定义，如果有极限，我们要先验地知道极限是什么才可以利用定义来证明。事实上，要想猜到这个极限的值是很困难的。通过这个例子，我们发现极限的定义对于判断极限是否存并没有太大的帮助。</p>
<p>从概念上而言，极限的定义在哲学意义上有一个先天的缺陷：判断数列收敛与否，应该由数列本身所决定而不需要依赖于外在的信息，比如说事先知道极限是什么。换句话说，我们想要内蕴地来考虑极限问题。这种看法和思考方式对数学的学习是大有裨益的。</p>
</blockquote>
<p>想起来数值分析学过的一些方法，比如对牛顿法失败的方程，也即有重根的方程重做某种牛顿法的时候，需要先知道重根是几次才能做出来，笑死。不过按照这个思路还是做出了很多改进方法，像魔法
qwq</p>
<p>此处“内蕴地”考虑极限问题，指的就是后面的 Cauchy
收敛原则：一个数列收敛等价于它是柯西列。</p>
<blockquote>
<p>在数学中, 对于每一个数学对象 (例如极限) ,
我们会例行公事般地考虑它的一些常见的性质. 比如说,
这个对象最基本的例子是什么, 这种对象是否存在,
如果存在的话它是否具有唯一性, 它的子对象和商对象 (如果有的话)
都具有什么性质 (比如说遗传了原来的对象的什么性质) ,
这个对象的可计算性以及在特定映射下的行为等等. 作为例子,
我们刚刚见到一个点列的子对象 (即子列) 遗传了点列的收敛性 (和有界性) .
尽管这是一种八股文一般的讨论方式 (Bourbaki 学派是这种方式最忠实的实践者)
, 但是是非常有效率的一种学习和记忆方式,
我们在课程上会尽量的按照这种习惯来学习. 特别要强调的是,
每一个定义大家都应该搞清楚最基本的例子是什么。</p>
</blockquote>
<p>你知道那个叫概念的东西是什么嘛.jpg</p>
<p>然后是学微积分的时候讲过就过了，不会再用的一个定理：</p>
<ul>
<li><p>(Bolzano–Weierstrass 的列紧性定理) 任意有界的实数序列 <span class="math inline">\(\{x_n\}_{n\geq 1}\)</span>
必有单调收敛的子列。</p></li>
<li><p>Cauchy 判别法（略）</p>
<p>注意 Cauchy
判别法仅能在实数列中使用，因为其证明需要关于有界的论述。</p></li>
</ul>
<p>另外，把级数的部分和视为一个数列的话，也可以用数列的性质来判断无穷级数是否收敛。也即，对于无穷级数
<span class="math inline">\(x_1 + x_2 + ...+x_n +...\)</span>，考虑
<span class="math inline">\(X_i = x_1 + x_2 + ... +
x_i\)</span>，于是有无穷级数收敛等价于实数序列 <span class="math inline">\(\{x_n\}_{n\geq 1}\)</span> 收敛，可以使用 Cauchy
判别法或定义判别的方式进行判断。考虑一种特殊的级数：</p>
<ul>
<li><p><span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span>
是递减的正实数的数列并且 <span class="math inline">\(\displaystyle\lim_{n\rightarrow
\infty}a_n=0\)</span>。假设级数 <span class="math inline">\(\sum_{k=1}^\infty\)</span> <span class="math inline">\(a_k\)</span> 发散。那么，对任意 <span class="math inline">\(x\in \mathbb R\)</span>，我们可以选取一组正负号
<span class="math inline">\(\iota_k\in \{\pm 1\}\)</span>，使得级数
<span class="math inline">\(\sum_{k=1}^\infty \iota_k a_k\)</span>
收敛并且 <span class="math inline">\(\Sigma_{k=1}^\infty \iota_k
a_k=x\)</span>。</p>
<p>或许算是后面习题里的 Riemann
重排定理的一个变式，总之证明是一样的。</p></li>
</ul>
<p>实际上，学级数的时候讲了很多判别法，无外乎绝对收敛和比较收敛。原理上都是
Cauchy 收敛的变式。</p>
<h2 id="指数函数和三角函数的级数定义">指数函数和三角函数的级数定义</h2>
<p>2023 年 1 月 22 日，星期日，吃着素感觉脑子转不起来了（x</p>
<p>我们假装自己只会用整数和有理数，然后用级数和极限分别定义了 <span class="math inline">\(e\)</span>，不仅在级数角度有熟知的 <span class="math inline">\(\displaystyle\lim_{n\rightarrow \infty}(1+
\frac{1}{n})^n=e\)</span>，级数的表示是 <span class="math inline">\(\sum
_{k=0} ^{+\infty} \frac{1}{k!} =
e\)</span>。同样的，我们也想假装只会用多项式，来定义指数函数和三角函数。</p>
<ul>
<li><p>定义指数函数 <span class="math inline">\(\exp\colon \mathbb R
\rightarrow \mathbb R\)</span> 如下：<span class="math inline">\(x\mapsto \exp(x)=e^x=\sum_{k=0}^\infty
\frac{x^k}{k!}\)</span>。可以看到这个形式和 <span class="math inline">\(e\)</span> 的定义是很相似的。</p>
<p>首先需要验证这是良定义的，也就是对于任意的 <span class="math inline">\(x \in \mathbb R\)</span>，有 <span class="math inline">\(\exp(x)=\sum_{k=0}^\infty \frac{x^k}{k!}\)</span>
是一个收敛的无穷级数。证明的话，实际上是从某一位处截断，对后面的无穷项进行一个放缩控制。</p>
<p>虽然我们熟知对任意的 <span class="math inline">\(x,y\in \mathbb
R\)</span> 有 <span class="math inline">\(e^{x+y}=e^x\cdot
e^y\)</span>，但是这在级数层面是不那么明显的。</p>
<p>上述性质对于复数 <span class="math inline">\(x\)</span>
也成立，从而引出对三角函数的定义。</p></li>
<li><p>利用指数映射 <span class="math inline">\(\exp(z)\)</span>
可以定义正弦和余弦函数：</p>
<p><span class="math inline">\(\cos z =\frac{e^{iz}+e^{-iz}}{2} =
\sum_{k=0}^\infty \frac{(-1)^k x^{2k}}{(2k)!}\)</span>，</p>
<p>$ z ={e<sup>{iz}-e</sup>{-iz} 2i} = _{k=0}^$。</p>
<p>换句话说，目前 <span class="math inline">\(\sin(z)\)</span> 和 <span class="math inline">\(\cos(z)\)</span>
使用级数来定义的。至于其余三角函数，是根据 <span class="math inline">\(\cos z ,\sin z\)</span>
的和差积商定义的。特别地，有 Euler公式：<span class="math inline">\(e^{iz}=\cos z + i \sin z\)</span>。</p>
<p>所以，三角函数完全可以被代数地定义，只用无穷项的多项式，不需要用到三角形。级数实际是沟通代数和几何的重要工具。我们可以用上述两个公式和已知的指数函数性质，证明出三角函数的众多性质，例如平方和为
<span class="math inline">\(1\)</span>，等等。</p></li>
</ul>
<h2 id="summary-1">Summary</h2>
<p>这一部分最大的贡献是定义出了 <span class="math inline">\(e\)</span>，指数函数和三角函数。不同于之前的视角，一千零一页中介绍了一个内蕴的判别角度，即从数列本身的性质出发推出其自身是否收敛，得出了重要的
Cauchy 判别法。当然，Cauchy
判别法的使用场景限于实数，在其他的距离空间上未必成立。当然，极限还有其他的求法，例如夹逼方法，上下极限，定义法。</p>
<p>与此同时，回忆了一些级数的内容，而级数本质上还是数列。级数这一部分在微积分里是放在微积分
A(2)
的最后一章介绍的，感觉很不合理，实际上完全可以在极限的地方就讲，不过没有必要，另外可能也是为了引出
Fourier
变换。总之，有了两组级数函数之后，对于中学里已知的内容的使用就可以更加大胆一些了。</p>
<h2 id="梦话既然习题没有答案那我就胡说八道了">梦话：既然习题没有答案那我就胡说八道了</h2>
<p>2023 年 1 月 23
日，星期一，其实我不喜欢在初学（？）的时候做没有答案的习题，anyway
还是写一写。</p>
<h3 id="riemann-重排定理">Riemann 重排定理</h3>
<p>证明下面有趣的定理：如果实数项级数 <span class="math inline">\(\displaystyle\sum_{n=1}^\infty a_n\)</span>
收敛但不绝对收敛，那么可以将级数重新排列，使得重排后的级数可以收敛到任意事先指定的
<span class="math inline">\(\alpha\in \mathbb
R\cup\{-\infty,+\infty\}\)</span>。假设 <span class="math inline">\(\varphi\colon \mathbb{Z}_{\geqslant 1}\rightarrow
\mathbb{Z}_{\geqslant 1}\)</span> 是正整数到自身的双射，令 <span class="math inline">\(b_k = a_{\varphi(k)}\)</span>，序列 <span class="math inline">\(\{b_k\}_{k\geqslant 1}\)</span> 被称为是 <span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span> 的一个重排，级数
<span class="math inline">\(\displaystyle\sum_{k=1}^\infty b_k\)</span>
被称为是级数 <span class="math inline">\(\displaystyle\sum_{n=1}^\infty
a_n\)</span> 的一个重排。</p>
<p>我们将 <span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span>
中的非负项（<span class="math inline">\(\geqslant
0\)</span>）的全体按照它们在 <span class="math inline">\(\{a_n\}_{n
\geqslant 1}\)</span> 中的先后次序排列得到序列 <span class="math inline">\(c_1,c_2,c_3,...\)</span>；类似地，将 <span class="math inline">\(\{a_n\}_{n \geqslant 1}\)</span> 中的负项（<span class="math inline">\(&lt;0\)</span>）按原顺序排列得到序列 <span class="math inline">\(d_1,d_2,d_3,\cdots\)</span>。</p>
<ul>
<li><p>证明，<span class="math inline">\(\displaystyle\lim_{n\to \infty}
c_n = 0\)</span>，<span class="math inline">\(\displaystyle\lim_{n\to
\infty} d_n = 0\)</span>。</p>
<p>Trivial，它们分别是原序列 <span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span>
的两个子列，收敛结果和原序列相同。</p></li>
<li><p>证明，<span class="math inline">\(\displaystyle\sum_{n=1}^\infty
c_n = +\infty\)</span>，<span class="math inline">\(\displaystyle\sum_{n=1}^\infty d_n =
-\infty\)</span>。</p>
<p>Trivial，反证法假设否则有 <span class="math inline">\(\displaystyle\sum_{n=1}^\infty c_n =
C\)</span>，且有 <span class="math inline">\(\displaystyle\sum_{n=1}^\infty
a_n=A\)</span>，<span class="math inline">\(A,C \in \mathbb
R\)</span>，那么有 <span class="math inline">\(\displaystyle\sum_{n=1}^\infty d_n = A-C \in
\mathbb R\)</span>，级数绝对收敛。矛盾。</p></li>
<li><p>证明: 对任意 <span class="math inline">\(\alpha \in \mathbb
R\)</span>，存在级数 <span class="math inline">\(\displaystyle\sum_{n=1}^\infty a_n\)</span>
的一个重排 <span class="math inline">\(\displaystyle\sum_{k=1}^\infty
b_k\)</span>，使得 <span class="math inline">\(\displaystyle
\sum_{k=1}^\infty b_k = \alpha\)</span>。</p>
<p>不妨设 <span class="math inline">\(\alpha
&gt;0\)</span>。正项是发散的，于是存在一个 <span class="math inline">\(n_1\)</span> 使得 $ c_1 + c_2 +...+ c_{ {n_1} }
&lt; c_1 + c_2 +...+ c_{ {n_1} }+c_{ {n _1} + 1}$。</p>
<p>取 <span class="math inline">\(\delta _1 = c_1 + c_2 +...+ c _{n_1}+c
_{n _1 + 1} - \alpha &gt;0\)</span>，由负项是发散的，于是存在一个 <span class="math inline">\(m_1\)</span> 使得：</p>
<p>$d_1 + d_2 + ... +d _{ {m _1} } &gt; -_1 d <em>1 + d_2 + ... +d
</em>{ {m _1} +1 } $。再取 <span class="math inline">\(0 &lt; \delta _2
= d_1 + d_2 + ... +d _{m _1 } + \delta _1 &lt; \delta
_1\)</span>，此为一次操作。</p>
<p>每做一次操作，<span class="math inline">\(\delta\)</span>
都会相应地减小，始终非负。于是有 <span class="math inline">\((c_1+...+c
_ {n_1 +1 }) + (d_1+...+d _{m _1})+...\)</span> 是一个收敛到 <span class="math inline">\(\alpha\)</span> 的重排级数。</p></li>
<li><p>证明: 存在级数 <span class="math inline">\(\displaystyle\sum_{n=1}^\infty a_n\)</span>
的一个重排 <span class="math inline">\(\displaystyle\sum_{k=1}^\infty
x_k\)</span>，使得 <span class="math inline">\(\displaystyle
\sum_{k=1}^\infty x_k = +\infty\)</span>。</p>
<p>我不是很确定啊，但是我打算徒手捏一个：取一个固定的实数 <span class="math inline">\(M&gt;0\)</span>，每一次操作分别从正的部分和负的部分，取一段
<span class="math inline">\(c_i + ... + c_{i+k}\)</span> 和 <span class="math inline">\(d_j + ... + d _{j+l}\)</span> 使得其和大于等于
<span class="math inline">\(M\)</span>。于是每一次操作得到的小段和都大于等于
<span class="math inline">\(M\)</span>，最后的级数和是发散的。</p></li>
</ul>
<h3 id="cesaro-求和极限">Cesaro 求和极限</h3>
<p>设 <span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span>
为实数序列，我们定义算数平均值序列 <span class="math inline">\(\displaystyle\sigma_n = \frac{a_1 + a_2 + \cdots +
a_n}{n}\)</span>，其中 <span class="math inline">\(n=1,2,3,\cdots\)</span>。</p>
<ul>
<li><p>假设 <span class="math inline">\(\displaystyle\lim_{n\to \infty}
a_n = a\)</span>。证明，<span class="math inline">\(\displaystyle\lim_{n\to \infty} \sigma_n =
a\)</span>。</p>
<p>Trivial.</p></li>
<li><p>构造一个不收敛的序列 <span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span>，使得 <span class="math inline">\(\displaystyle\lim_{n \to \infty} \sigma_n =
0\)</span>。</p>
<p><span class="math inline">\(a_ i = (-1) ^i\)</span>。</p></li>
<li><p>是否存在序列 <span class="math inline">\(\{a_n\}_{n\geqslant
1}\)</span>，使得对任意 <span class="math inline">\(n\geqslant
1\)</span>，都有 <span class="math inline">\(a_n &gt; 0\)</span> 并且
<span class="math inline">\(\displaystyle\limsup_{n\to \infty} a_n =
\infty\)</span> 然而 <span class="math inline">\(\displaystyle\lim_{n\to
\infty} \sigma_n = 0\)</span>?</p>
<p><span class="math inline">\(a_{i^2}=\sqrt{i},\)</span> 其余为 <span class="math inline">\(1 \over i^2\)</span>。（感谢 neruko
的勘误！qwq</p></li>
<li><p>对 <span class="math inline">\(k \geqslant 1\)</span>, 记 <span class="math inline">\(b_k = a_{k+1} - a_k\)</span>。证明，对任意的 <span class="math inline">\(n\geqslant 2\)</span>，都有 <span class="math inline">\(\displaystyle a_n - \sigma_n = \frac{1}{n}
\sum_{k=1}^{n-1} k b_k\)</span>。</p>
<p>Trivial.</p></li>
<li><p>设 <span class="math inline">\(\displaystyle\lim_{k\to \infty} k
b_k = 0\)</span> 并且 <span class="math inline">\(\{\sigma_n\}_{n\geqslant 1}\)</span>
收敛。证明，<span class="math inline">\(\{a_n\}\)</span> 也收敛。</p>
<p>注意，这是 (1) 在条件 <span class="math inline">\(n|a_{n+1}-a_n| \to
0\)</span> 这一额外条件下的逆命题。</p>
<p>Trivial，上一题左右对 <span class="math inline">\(n\)</span>
取极限，利用极限的可加性。至于右边的极限为什么是 <span class="math inline">\(0\)</span>，用 <span class="math inline">\(\varepsilon - N\)</span> 写一下。</p></li>
<li><p>把 (5) 的条件减弱为: <span class="math inline">\(\{ k
b_k\}_{k\geqslant 1}\)</span> 是有界的并且 <span class="math inline">\(\displaystyle\lim_{n \to \infty} \sigma_n =
\sigma\)</span>。证明，<span class="math inline">\(\displaystyle\lim_{n\to \infty} a_n =
\sigma\)</span>。</p>
<p><strong>？不会.jpg</strong></p></li>
</ul>
<h3 id="根式和指数的定义">根式和指数的定义</h3>
<p>这个问题的目的是在 <span class="math inline">\(\mathbb R\)</span>
上定义初等函数 <span class="math inline">\(\sqrt[n]{x}\)</span> 和 <span class="math inline">\(b^x\)</span>，比如说我们自然希望定义 <span class="math inline">\(\sqrt[n]{x}\)</span> 为满足 <span class="math inline">\(y^n = x\)</span> 唯一的正实数。</p>
<ul>
<li><p>给定正整数 <span class="math inline">\(n\)</span> 和实数 <span class="math inline">\(x&gt;0\)</span>，证明：如果正实数 <span class="math inline">\(y_1\)</span> 和 <span class="math inline">\(y_2\)</span> 满足 <span class="math inline">\(y_1^n = x=y_2^n\)</span>，那么 <span class="math inline">\(y_1=y_2\)</span>。</p>
<p>Trivial.</p></li>
<li><p>证明，如果 <span class="math inline">\(x&gt;0\)</span>，那么集合
<span class="math inline">\(E(x) = \{t \in \mathbb R \mid t^n &lt;
x\}\)</span> 是非空的并且有上界。</p>
<p>Trivial，首先 <span class="math inline">\(0 \in E(x)\)</span>，再对
<span class="math inline">\(x\)</span> 讨论。当 <span class="math inline">\(0&lt;x&lt;1\)</span> 时有 <span class="math inline">\(\forall t \in E(x), t&lt;1\)</span>，当 $1 x $
时有 <span class="math inline">\(\forall t \in E(x),t \leq
x\)</span>。</p></li>
<li><p>证明，<span class="math inline">\(y = \sup E(x)\)</span> 满足
<span class="math inline">\(y^n = x\)</span> 并且 <span class="math inline">\(y&gt;0\)</span>。</p>
<p>首先有 <span class="math inline">\(0 \in E(x)\)</span>，于是 <span class="math inline">\(sup E(x) \geq 0\)</span>。如果 <span class="math inline">\(supE(x) = 0\)</span> 则不存在 <span class="math inline">\(\varepsilon &gt;0,\varepsilon ^n
&lt;x\)</span>。取 <span class="math inline">\(\varepsilon ^n =
\frac{x}{2}\)</span> 则矛盾。于是 <span class="math inline">\(y&gt;0\)</span>。再证明 <span class="math inline">\(y^n =x\)</span>。显然对于 <span class="math inline">\(\forall y \in \mathbb R, y^n \geq x\)</span> 都有
$y $ 是 <span class="math inline">\(E(x)\)</span> 的上界，而对于 <span class="math inline">\(\forall z \in \mathbb R,z^n &lt; x\)</span>，存在
<span class="math inline">\((z ^\prime) ^n = z_n +x\)</span> 使得 <span class="math inline">\(z^ \prime \in E(x)\)</span> 且 <span class="math inline">\(z^\prime &gt;z\)</span>，于是这样的 <span class="math inline">\(z\)</span> 都不是上界。因此 <span class="math inline">\(supE(x) = min \lbrace y \in \mathbb R, y^n \geq x
\rbrace\)</span>，也即题中定义。</p></li>
<li><p>证明， 映射 <span class="math inline">\(\sqrt[n]{\cdot}\colon
\mathbb R_{&gt;0}\to \mathbb R_{&gt;0}, \ \ x \mapsto
\sqrt[n]{x}=y\)</span> 是良好定义的。我们也记 <span class="math inline">\(\sqrt[n]{x}\)</span> 为 <span class="math inline">\(x^{\frac1n}\)</span>。</p>
<p>良好定义的意思是，对于任意的 <span class="math inline">\(x =
x^\prime\)</span>，有 <span class="math inline">\(y=y^
\prime\)</span>。否则 <span class="math inline">\(y \neq y^
\prime\)</span>，但由上题定义，上确界是唯一的。</p></li>
<li><p>证明，<span class="math inline">\(\sqrt[n]{\cdot}\colon \mathbb
R_{&gt;0}\to \mathbb R_{&gt;0}\)</span> 是双射。</p>
<p>有以上铺垫后是显然的。</p></li>
<li><p><span class="math inline">\(a,b\)</span> 是正实数，<span class="math inline">\(n\)</span> 为正整数。证明，<span class="math inline">\((ab)^{\frac1n} =
a^{\frac1n}b^{\frac1n}\)</span></p>
<p>定义 <span class="math inline">\(A(x) = \lbrace t \in \mathbb R \mid
t^n &lt;a \rbrace\)</span>，<span class="math inline">\(B(x) = \lbrace t
\in \mathbb R \mid t^n &lt;b \rbrace\)</span>，<span class="math inline">\(C(x) = \lbrace t \in \mathbb R \mid t^n &lt;a
b\rbrace\)</span>，只要证明 <span class="math inline">\(A(x)B(x)=C(x)\)</span>，（集合相等的证明是左右互相包含），然后考虑两个集合的上确界则得证。</p></li>
</ul>
<p>在接下来的问题里，我们给定实数 <span class="math inline">\(b&gt;1\)</span> 来定义以 <span class="math inline">\(b\)</span> 为底的指数函数 <span class="math inline">\(x \mapsto b^x\)</span>。</p>
<ul>
<li><p>设 <span class="math inline">\(m,n,p,q \in
\mathbb{Z}\)</span>，其中 <span class="math inline">\(n&gt;0\)</span>，<span class="math inline">\(q&gt;0\)</span>。令 <span class="math inline">\(r
= \dfrac{m}{n} = \dfrac{p}{q}\)</span> 为有理数 <span class="math inline">\(r\)</span> 的两种表示。证明 <span class="math inline">\((b^m)^{\frac1n} = (b^p)^{\frac1q}\)</span></p>
<p>Trivial.</p></li>
<li><p>证明，对任意的有理数 <span class="math inline">\(r\)</span>，函数
<span class="math inline">\(r\mapsto b^r\)</span> 是良好定义的。</p>
<p>Trivial.</p></li>
<li><p>证明，对任意的有理数 <span class="math inline">\(r,s\)</span>，我们有 <span class="math inline">\(b^{r+s} = b^rb^s\)</span>。</p>
<p>记 <span class="math inline">\(r = \frac mn ,s= \frac
pq\)</span>，于是 <span class="math inline">\(b^{r+s} =
b^{\frac{mq+np}{nq} }=(b^{mq} b^{np} ) ^{\frac{1}{nq} }= b ^{\frac mn}
b^{\frac pq} = b^r b^s\)</span>。</p></li>
<li><p>对于 <span class="math inline">\(x \in \mathbb R\)</span>，令
<span class="math inline">\(B(x)=\{b^t \mid t \in \mathbb{Q}, t
\leqslant x\}\)</span>。证明，<span class="math inline">\(B(x)\)</span>
非空且有上界。我们定义 <span class="math inline">\(b^x = \sup
B(x)\)</span>, 这就定义了映射 <span class="math inline">\(x \mapsto
b^x\)</span>。</p>
<p>其实和之前那个也差不多，不写了。</p></li>
<li><p>证明，如果 <span class="math inline">\(r\)</span> 是有理数，那么
<span class="math inline">\(b^r = \sup B(r),\forall r \in
\mathbb{Q}\)</span>。我们定义的指数映射在 <span class="math inline">\(r\in \mathbb{Q}\)</span> 时和之前是一致的。</p>
<p>和上一题一样。</p></li>
<li><p>证明，上题中定义的映射满足， 对任意的 <span class="math inline">\(x,y \in \mathbb R\)</span>，都有 <span class="math inline">\(b^{x+y} = b^x b^y\)</span>。</p>
<p>证明 <span class="math inline">\(X(r)Y(r)=Z(r)\)</span>，于是上确界相等。</p></li>
<li><p>证明，当 <span class="math inline">\(b=e\)</span>
时，这样定义的函数和课程中定义的 <span class="math inline">\(e^x\)</span> 是一致的。</p>
<p>嗯？</p>
<p><span class="math inline">\(\exp(x)=\sum_{k=0}^\infty
\frac{x^k}{k!}\)</span>。上述定义的 <span class="math inline">\(e^x =
sup B(x) = sup \{e^t \mid t \in \mathbb{Q}, t \leqslant
x\}\)</span>。</p>
<p>我不到啊，或许他想让我证明的是 <span class="math inline">\((\sum_{k=0}^\infty \frac{1}{k!}) ^x =
\sum_{k=0}^\infty \frac{x^k}{k!}\)</span>
吗？这个课上好像证过。</p></li>
</ul>
<h3 id="根式的逼近">根式的逼近</h3>
<p>给定正实数 <span class="math inline">\(\alpha\)</span> 和初始值 <span class="math inline">\(x_1 &gt;
\sqrt{\alpha}\)</span>，我们归纳地定义序列 <span class="math inline">\(\{x_n\}_{n\geqslant 1}\)</span>：<span class="math inline">\(x_{n+1} = \frac{1}{2}\left(x_n +
\frac{\alpha}{x_n}\right), n = 1,2,\cdots\)</span></p>
<ul>
<li><p>证明，<span class="math inline">\(\{x_n\}_{n\geqslant 1}\)</span>
是递减的并且 <span class="math inline">\(\displaystyle\lim_{n\to \infty}
x_n = \sqrt{\alpha}\)</span>（在问题E中已经定义）。这表明，从任意大于
<span class="math inline">\(\sqrt{\alpha}\)</span>
的初值出发，可用上述迭代公式近似地计算（逼近）<span class="math inline">\(\sqrt{\alpha}\)</span>。</p>
<p>Trivial，因为这就是 Newton 法（狗头</p></li>
<li><p>定义逼近的误差项 <span class="math inline">\(\varepsilon_n = x_n
- \sqrt{\alpha}\)</span>。证明，<span class="math inline">\(\displaystyle\varepsilon_{n+1} =
\frac{\varepsilon_n^2}{2x_n} &lt;
\frac{\varepsilon_n^2}{2\sqrt{\alpha}}\)</span>。</p>
<p>Trivial，这是 Newton 法的二阶收敛性质（逃</p></li>
<li><p>证明，如果 <span class="math inline">\(\beta =
2\sqrt{\alpha}\)</span>，那么 <span class="math inline">\(\displaystyle\varepsilon_{n+1} &lt; \beta
\left(\frac{\varepsilon_1}{\beta}\right)^{2^n}\)</span>。这表明它的收敛速度非常快。</p>
<p>Trivial.</p></li>
<li><p>设 <span class="math inline">\(\alpha = 3\)</span>，<span class="math inline">\(x_1 = 2\)</span>，验证 <span class="math inline">\(\dfrac{\varepsilon_1}{\beta} &lt;
0.1\)</span>，继而 <span class="math inline">\(\varepsilon_5 &lt; 4\cdot
10^{-16}\)</span>，<span class="math inline">\(\varepsilon_6 &lt; 4
\cdot 10^{-32}\)</span>。</p>
<p>略（</p></li>
<li><p>试用纸和笔，计算 <span class="math inline">\(\sqrt{3}\)</span>
的精确到小数点5位的近似值。</p>
<p>略（</p></li>
</ul>
<p>接下来，我们换另外一个迭代公式。固定 <span class="math inline">\(\alpha &gt; 1\)</span> 和 <span class="math inline">\(y_1 &gt; \sqrt{\alpha}\)</span>，定义 <span class="math inline">\(y_{n+1} = {\alpha + {y_n} \over 1 + {y_n}} = y_n +
{\alpha - {y_n}^2 \over 1+{y_n} }\)</span>，$ n = 1,2,... $</p>
<ul>
<li><p>证明，<span class="math inline">\(\{y_{2k-1}\}_{k\geqslant
1}\)</span> 为递减序列。</p>
<p>这是一个大于 <span class="math inline">\(\sqrt{\alpha }\)</span>
的序列，有 <span class="math inline">\(y_3 = \frac{\alpha + y_2}{1+y_2}
= \frac{(\alpha +1 )y_1 + 2 \alpha}{2y_1 + \alpha +1} &lt;
y_1\)</span>，可以推广到每一项。</p></li>
<li><p>证明，<span class="math inline">\(\{y_{2k}\}_{k\geqslant
1}\)</span> 为递增序列。</p>
<p>Trivial，基本同上。</p></li>
<li><p>证明，<span class="math inline">\(\displaystyle\lim_{n\to \infty}
y_n = \sqrt{\alpha}\)</span>。</p>
<p>上述的两个序列分别单调有界，各自收敛。由递推式可知都收敛到 <span class="math inline">\(\sqrt{\alpha }\)</span>，于是整体收敛。</p></li>
<li><p>试讨论逼近 <span class="math inline">\(\sqrt{\alpha}\)</span>
的收敛速度并与之前的比较。</p>
<p>肯定是不如 Newton 方法收敛得快的。</p>
<p>记逼近的误差项 <span class="math inline">\(\varepsilon_n = x_n -
\sqrt{\alpha}\)</span>，于是 <span class="math inline">\(\displaystyle\lim_{n\to \infty} \frac{\varepsilon
_{n+1} } {\varepsilon _n } = \frac{1-\sqrt{\alpha} }{1+\sqrt{\alpha}
}\)</span>，这个序列线性收敛，而 Newton 方法二阶收敛。</p></li>
</ul>
<p>给我一点小小的数值分析震撼，但我感觉比前面的题都简单（</p>
<h2 id="梦话-2.0乘积级数">梦话 2.0：乘积级数</h2>
<p>其实乘积级数完全可以用对数函数拆成求和级数，可惜的是我们现在还没有对数函数，所以都是靠各种技巧来证明。</p>
<ul>
<li><p>乘积级数的收敛以及 Cauchy 判别法：<span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span>
是复数的数列，我们假设对任意的 <span class="math inline">\(n\)</span>，<span class="math inline">\(a_n\neq
0\)</span>。令 <span class="math inline">\(P_n=a_1\cdot a_2\cdot \cdots
\cdot a_n\)</span>，如果数列 <span class="math inline">\(\{P_n\}_{n\geqslant 1}\)</span> 的极限存在且不是
<span class="math inline">\(\mathbf{0}\)</span>，称无限乘积 <span class="math inline">\(\displaystyle\prod_{n\geqslant 1}a_n\)</span>
收敛且记 <span class="math inline">\(\displaystyle\prod_{n\geqslant
1}a_n=\lim_{n\rightarrow \infty}P_n\)</span>。</p>
<p>我们有这种情况下的 Cauchy 判别准则：<span class="math inline">\(\displaystyle\prod_{n\geqslant 1}a_n\)</span>
收敛当且仅当对任意的 <span class="math inline">\(\varepsilon&gt;0\)</span>，存在 <span class="math inline">\(N\)</span>，使得对任意的 <span class="math inline">\(n\geqslant N\)</span>，任意的 <span class="math inline">\(p\geqslant 0\)</span>，我们都有 <span class="math inline">\(\big|a_n\cdot a_{n+1}\cdot \cdots \cdot
a_{n+p}-1\big|&lt;\varepsilon\)</span>。</p></li>
<li><p>除此之外还有一个特殊情况：对于正数列 <span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span>，乘积 <span class="math inline">\(\displaystyle\prod_{n=1}^{\infty}(1+a_n)\)</span>
收敛（极限必然不是零）等价于 <span class="math inline">\(\displaystyle\sum_{n =1}^{\infty} a_n\)</span>
收敛。当然，有对数的话可以近似成 <span class="math inline">\(ln(1+a_n)
\approx a_n\)</span>，直观上二者就相等。严格的证明也不困难。</p>
<p>实际上，如果数列介于区间 <span class="math inline">\((0,1)\)</span>
之间，二者也等价于乘积 <span class="math inline">\(\displaystyle\prod_{n=1}^{\infty}(1-a_n)\)</span>
收敛。从对数的直观上来说也是明显的，但证明稍有不同。</p>
<p>这样的话限制还是比较多的，只对正实数有效。如果想要推广到复数，就需要更强的条件。<span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span> 是复数的数列，如果
<span class="math inline">\(\displaystyle\prod_{n=1}^{\infty}(1+|a_n|)\)</span>
收敛（等价地说，就是 <span class="math inline">\(\displaystyle\sum_{n
=1}^{\infty} a_n\)</span> 绝对收敛），则 <span class="math inline">\(\displaystyle\prod_{n=1}^{\infty}(1+a_n)\)</span>
收敛（极限不是零）。</p></li>
</ul>
<p>2023 年 1 月 24 日，星期二，修了半天 LaTeX 然后摸了半天鱼（</p>
<p>顺便解决了一些历史问题，比如把博客搬到（去年八月换的）新电脑上来了，说来真的有点蠢，感觉搬家好麻烦就同时用着两个电脑了（。旧电脑是
surface，换掉之后一直仍然承担着晚上回寝室之后负责 deploy
博客和时不时需要一块手写屏的功能。</p>
<p>其实后来检查了半天，发现除了 NexT
之外都是最新版本，不清楚究竟是哪里有问题，就换了个
renderer，然后就好了（其实去看了下最新版 NexT
的文档，它的意思好像也是最好不要用 hexo-renderer-marked，就换了
hexo-renderer-pandoc，虽然还有少量问题但基本还是在人工排查没那么费劲的范围里，先这样吧）。倒是也把新版本的
NexT 设置好了，但是当时搞的彩色标签暂时没找到好的替代 =
=，原来的办法不太好用了，就还是暂时再用用旧的，哪天确定是它出了问题的话也可以一键搬家到新版（，以及有问题就可以自己在新版上测了，这次还要谢谢
JasonL 老师的帮助，谢谢华子音游群让我半夜加到了老师的好友（（</p>
<p>到底是什么原因呢，是换了新电脑的原因还是魔改的原因，总之仓库里原来
200 多条 commits
没有了。本来想着内容都还在也没什么问题，但是今天无聊翻邮件的时候突然想起来，有一条在
commits
里的评论也跟着消失了。怪我没什么经验还不咋仔细，要是想到开个新的分支的话就好了。或许有什么恢复的方法吗，感觉没有（</p>
<p>凌晨的时候本来在等备份，随手开了局舟，没想到一次通关，大概是什么回坑
buff（。不过感觉不咋好玩，逐渐失去兴趣了，打算把活动打完就卸载掉。</p>
<p>（这不是数分日志来着吗）（问题在这里发现的就在这儿解决一下好了）</p>
<p><img src="https://s2.loli.net/2023/01/25/1FkScU8xRrQbZzD.png"></p>
<p>2023 年 1 月 25 日，星期三，= =</p>
<ul>
<li><p>定义了一个很新的函数，叫做欧拉乘积公式，也可以就叫 <span class="math inline">\(\zeta\)</span>- 函数。</p>
<p>假设 <span class="math inline">\(\mathcal{P}\)</span>
是所有的素数组成的集合，我们可以将它们从小到大排列为 <span class="math inline">\(2=p_1&lt;p_2&lt;p_3&lt;\cdots\)</span>。对于 <span class="math inline">\(s&gt;1\)</span>，<span class="math inline">\(\zeta\)</span>- 函数</p>
<p><span class="math inline">\(\zeta(s)=\sum_{n=1}^\infty
\frac{1}{n^s}\)</span> 是良好定义的。那么， 我们有 <span class="math inline">\(\zeta(s)=\prod_{p\in
\mathcal{P}}\frac{1}{1-p^{-s}}\)</span>，</p>
<p>其中上面的乘积是收敛的（我们可以假定是按照素数从小到大的顺序来做乘积的）。</p></li>
<li><p>又到了高中竞赛的噩梦环节，Abel
求和公式。形式很简单，证明也很简单，但是应用和技巧多得离谱（</p>
<p><span class="math inline">\(\{a_k\}_{k\geqslant 1}\)</span> 和 <span class="math inline">\(\{b_k\}_{k\geqslant 1}\)</span>
是复数（矩阵）的序列，那么 <span class="math inline">\(\sum_{k=1}^n{a_kb_k}=S_nb_n+\sum_{k=1}^{n-1}S_k(b_k-b_{k+1})\)</span>，其中我们用
<span class="math inline">\(S_n=a_1+a_2+\cdots+a_n\)</span> 表示数列
<span class="math inline">\(\{a_k\}_{k\geqslant 1}\)</span>
的部分和。</p>
<p>Abel 公式其实就是离散形式的分部积分公式，而且 Abel
和的部分截断和的形式也很不错：</p>
<p><span class="math inline">\(\sum_{n+1\leqslant k \leqslant m} a_k b_k
= S_mb_m-S_nb_n+\sum_{k=n}^{m-1}S_k(b_k-b_{k+1})\)</span></p>
<p>于是有一个针对它的 Dirichlet
收敛判别法，证明即是对上面的部分截断和放缩，做 Cauchy 判别法：如果<span class="math inline">\(\{b_k\}_{k\geqslant 1}\)</span> 是单调数列并且
<span class="math inline">\(\displaystyle\lim_{k\rightarrow
\infty}b_k=0\)</span>，而且存在 <span class="math inline">\(M\)</span>，使得对任意的 <span class="math inline">\(n\geqslant 1\)</span>，<span class="math inline">\(|S_n|\leqslant M\)</span>，那么无穷级数 <span class="math inline">\(\displaystyle\sum_{k=1}^\infty{a_kb_k}\)</span>
收敛。</p>
<p>相应地还有 Abel 收敛判别法：<span class="math inline">\(\{b_k\}_{k\geqslant 1}\)</span>
是单调有界数列，级数 <span class="math inline">\(a_1+a_2+a_3+\cdots\)</span> 收敛，则级数 <span class="math inline">\(\displaystyle\sum_{k=1}^\infty{a_kb_k}\)</span>
收敛。同样使用截断和的 Cauchy 判别即可。</p></li>
</ul>
<h2 id="梦话-3.0距离空间与赋范线性空间">梦话
3.0：距离空间与赋范线性空间</h2>
<p>赋范线性空间这我也熟啊，也是数值分析里学的（学的时候有点痛苦就是了，而且有点惶恐，因为感觉附近都是数学系的人，他们好像都会了
qwq（而且都是大三的同学，天哪当时选课的时候真有勇气</p>
<ul>
<li><p>距离空间是一个不够强的定义，只对空间上的两个点的距离做了定义，要求它们满足三角不等式。比如说，以绝对值为距离的距离空间
<span class="math inline">\(\mathbb Q\)</span> 上有 <span class="math inline">\(x_n=\displaystyle \sum_{k=0}^n
\frac{1}{k!}\)</span> 是 Cauchy 列但不收敛（因为收敛到 <span class="math inline">\(e\)</span>，是无理数）。因此，定义完备的距离空间
<span class="math inline">\((X,d)\)</span>，如果其上每个 Cauchy
列都收敛。比如 <span class="math inline">\(X=\mathbb R\)</span>，<span class="math inline">\(d(x,y)=|x-y|\)</span>
就是完备的距离空间。</p></li>
<li><p>然后讲义上讲了一个压缩映射定理（或者 Banach
不动点定理更好听），嗨呀这个我也熟，是数值分析里非线性方程的迭代解法那一章里面的最初条件，某种意义上来说也是做迭代能找到不动点的前提。不过这次把它放到完备距离空间里了。</p>
<p>数值分析里用的是更完备的空间，也就是赋范线性空间，实际上就是让距离空间的距离定义又满足了范数的条件，也就是数乘的线性性质而已。另外要求空间是线性空间，这个也没什么难的。</p>
<blockquote>
<p>这三种范数都是上面线性空间情况直接搬过来的. 实际上, 利用矩阵的知识,
我们还可以定义其他更有几何意义的范数,
比如说我们可以利用矩阵的特征值来定义一些范数, 限于知识范围,
我们不再展开.</p>
</blockquote>
<p>嘿嘿，这个我会（这不是应该的吗到底在自豪什么.jpg</p></li>
<li><p>最后在完备的赋范线性空间（也就是 <del>Banana</del> Banach
空间）上证明了一些极限的相容性，其实我的感受就是把绝对值推广成了范数，证明某些对于实数的操作，在赋范线性空间上对向量
/ 矩阵也是能成立的。</p>
<p>比如说定义一个 <span class="math inline">\(e^A\)</span>，但 <span class="math inline">\(A\)</span> 是一个 <span class="math inline">\(n
\times n\)</span>
大小的复系数矩阵。听起来很抽象，不知道会得到一个什么怪物结果，但是回顾
<span class="math inline">\(e^x\)</span> 的级数定义就可以知道，<span class="math inline">\(e^A = \sum_{k=0} ^\infty {A^k \over
k!}\)</span>，也就是说 exp 函数在矩阵上是一个 <span class="math inline">\(M_n (\mathbb R) \to M_n (\mathbb R)\)</span>
的映射，得到的结果还是一个 <span class="math inline">\(n \times
n\)</span> 大小的复系数矩阵。</p>
<p>要做的任务就是证明 <span class="math inline">\(e^A\)</span>
的良定义性质，也就是级数的收敛性。在这里用一个赋范空间上的绝对收敛概念，原本实数空间上的绝对收敛是对于绝对值而言，在赋范空间上改成对范数而言即可，这样还是能够通过绝对收敛推出收敛（因为范数和绝对值同样有三角不等式性质）。关于
<span class="math inline">\(e^A = \sum_{k=0} ^\infty {A^k \over
k!}\)</span>
的绝对收敛性质也很好证明，可以使用矩阵范数的等价性。当然，如果这个矩阵范数是一个向量相容范数，就更简单了。</p>
<p>不过，在这样的定义里，<span class="math inline">\(e^{A+B} = e^A
e^B\)</span> 是不一定成立的，因为两个矩阵未必交换。但是 <span class="math inline">\(e^{sA} e^{tA} = e^{(s+t)A}\)</span>
仍然成立。</p></li>
</ul>
<h2 id="梦话-4.0既然习题没有答案那我就继续胡说八道了">梦话
4.0：既然习题没有答案那我就继续胡说八道了</h2>
<p>怎么作业这么多啊！</p>
<p>说到习题没有答案这个问题，今天在知乎搜了一下居然有<a href="https://github.com/huanghaox1212/huanghaox1212.github.io/releases/tag/yp-solution-part-1">民间版本</a>流传，作者是
MO 和 OI 双修的高中生，太升级了。</p>
<p>习题还在做，做完了再来碎碎念，然后就终于可以离开极限去学连续性了（</p>
<p>2023 年 1 月 26 日，星期四，今天没有 die
只是作业写起来真的有点慢（，这一章的习题全都做了哦。</p>
<h3 id="连续函数的定义和基本性质">连续函数的定义和基本性质</h3>
<ul>
<li><p>（函数极限的Cauchy判别准则）给定函数 <span class="math inline">\(f\colon (a,x_0)\cup (x_0,b)\rightarrow
\mathbb{R}\)</span>。那么，<span class="math inline">\(f\)</span> 在
<span class="math inline">\(x_0\)</span> 处有极限当且仅当对任意的 <span class="math inline">\(\varepsilon&gt;0\)</span>，存在 <span class="math inline">\(\delta&gt;0\)</span>，使得对任意的 <span class="math inline">\(x_1,x_2\in (x_0-\delta,x_0+\delta)\)</span>，都有
<span class="math inline">\(|f(x_1)-f(x_2)|&lt;\varepsilon\)</span>。</p>
<p>如果有极限，这是定义，trivial.</p>
<p>如果对任意的 <span class="math inline">\(\varepsilon&gt;0\)</span>，存在 <span class="math inline">\(\delta&gt;0\)</span>，使得对任意的 <span class="math inline">\(x_1,x_2\in (x_0-\delta,x_0+\delta)\)</span>，都有
<span class="math inline">\(|f(x_1)-f(x_2)|&lt;\varepsilon\)</span>，那么取某一个固定的
<span class="math inline">\(\varepsilon\)</span>，找到这样的区间 <span class="math inline">\(X=(x_0-\delta,x_0+\delta)\)</span>，任意取一组
<span class="math inline">\(X\)</span> 上收敛到 <span class="math inline">\(x_0\)</span> 的点列 <span class="math inline">\(y_0,y_1,...,y_n,...\)</span>，它们的函数值序列
<span class="math inline">\(\lbrace f(y_n) \rbrace _{n \geq 1}\)</span>
是 Cauchy 列，一定收敛。</p>
<p>至于为什么会收敛到 <span class="math inline">\(f(x_0)\)</span>
这一点，这是因为 <span class="math inline">\(\lbrace y_n \rbrace _{n
\geq 1}\)</span> 的极限是 <span class="math inline">\(x_0\)</span>。</p></li>
<li><p>假设 <span class="math inline">\(I\)</span> 是一个非空的区间并且
<span class="math inline">\(I\)</span> 不是一个点，证明，<span class="math inline">\(I\)</span> 上的连续函数 <span class="math inline">\(C(I)\)</span> 所构成的 <span class="math inline">\(\mathbb R\)</span>-线性空间是无限维的。</p>
<p>这题我会！数值分析里学过！多项式的基 <span class="math inline">\(\lbrace 1,x,x^2,... \rbrace\)</span>
是无限维的，因为它们彼此线性无关。</p></li>
<li><p>假设 <span class="math inline">\((X,d_X)\)</span> 和 <span class="math inline">\((Y,d_Y)\)</span> 是距离空间，<span class="math inline">\(f\colon X\rightarrow Y\)</span> 是映射。假设 <span class="math inline">\(x_0\in X\)</span>，如果对任意 <span class="math inline">\(X\)</span> 中的点列 <span class="math inline">\(\{x_n\}_{n\geqslant 1}\)</span>，<span class="math inline">\(x_n\stackrel{d_X}{\longrightarrow}x_0\)</span>，我们都有
<span class="math inline">\(f(x_n)\stackrel{d_Y}{\longrightarrow}f(x_0)\)</span>，我们就称
<span class="math inline">\(f\)</span> 在 <span class="math inline">\(x_0\)</span> 处是连续的。如果 <span class="math inline">\(f\)</span> 在一切 <span class="math inline">\(x\in
X\)</span> 处均连续，那么我们就称 <span class="math inline">\(f\)</span>
是距离空间之间的连续映射。</p>
<p>假设 <span class="math inline">\((X,d_X)\)</span>，<span class="math inline">\((Y,d_Y)\)</span> 和 <span class="math inline">\((Z,d_Z)\)</span> 是三个距离空间，<span class="math inline">\(f\colon X\rightarrow Y\)</span>，<span class="math inline">\(g\colon Y\rightarrow Z\)</span>
均为连续映射。证明，它们的复合 <span class="math inline">\(g\circ
f\colon X\rightarrow Z\)</span> 也是连续映射。</p>
<p>一句话题意：连续映射的复合还是连续映射（</p>
<p>Trivial.</p></li>
<li><p>假设 <span class="math inline">\((X,d_X)\)</span> 和 <span class="math inline">\((Y,d_Y)\)</span> 是距离空间，<span class="math inline">\(f\colon X\rightarrow Y\)</span> 是连续映射。如果
<span class="math inline">\(d&#39;_X\)</span> 是与 <span class="math inline">\(d_X\)</span> 等价的距离，<span class="math inline">\(d&#39;_Y\)</span> 是与 <span class="math inline">\(d_Y\)</span> 等价的距离，那么，对于 <span class="math inline">\((X,d&#39;_X)\)</span> 和 <span class="math inline">\((Y,d&#39;_Y)\)</span> 而言，<span class="math inline">\(f\)</span> 也是连续映射。</p>
<p>等价的距离意思是对任意的 <span class="math inline">\(x_1 , x_2 \in
X\)</span>，存在固定的参数 <span class="math inline">\(c,C \in
R\)</span>，使得 <span class="math inline">\(c d^{\prime} _X (x_1,x_2)
\leq d _X (x_1,x_2) \leq C d^{\prime} _X
(x_1,x_2)\)</span>，代入一下连续的定义，取一个小一点的 <span class="math inline">\(\varepsilon\)</span> 就可以了。</p></li>
<li><p>在 <span class="math inline">\(\mathbb R^n\)</span>
上我们配有常见的距离，比如说 <span class="math inline">\(d_2\)</span>（请参考之前的讲义）；<span class="math inline">\((X,d_X)\)</span> 是距离空间。我们将映射 <span class="math inline">\(f\colon X\rightarrow \mathbb R^n\)</span>
写成分量的形式：<span class="math inline">\(f\colon X\rightarrow \mathbb
R^n, \ \ x\mapsto f(x)=(f_1(x),f_2(x),\cdots,f_n(x))\)</span></p>
<p>其中 <span class="math inline">\(f_i\colon X\rightarrow \mathbb
R\)</span> 是函数。证明，<span class="math inline">\(f\)</span>
是连续映射当且仅当对所有的 <span class="math inline">\(i=1,\cdots,n\)</span>，<span class="math inline">\(f_i\)</span> 是连续函数。</p>
<p>如果每个 <span class="math inline">\(f_i (x)\)</span>
都是连续函数，那么对于收敛到 <span class="math inline">\(x_0\)</span>
的点列 <span class="math inline">\(\lbrace x_i \rbrace _{i \geq
1}\)</span>，对任意的 <span class="math inline">\(\varepsilon
&gt;0\)</span>，存在一个最小的 <span class="math inline">\(\delta\)</span> 和最大的 <span class="math inline">\(N\)</span>，使得对任意分量函数，都有 <span class="math inline">\(n &gt;N\)</span> 时，<span class="math inline">\(|
f_i(x_n)-f_i(x_0) | &lt;\varepsilon\)</span>。于是此时也有 <span class="math inline">\(| f(x_n) - f(x_0) | &lt;\sqrt{n}
\varepsilon\)</span>，连续。（追求美观的话可以在第一步把 <span class="math inline">\(\varepsilon\)</span> 改成 <span class="math inline">\(\varepsilon \over \sqrt{n}\)</span>）</p>
<p>如果 <span class="math inline">\(f(x)\)</span>
是连续函数，那么分量的误差小于整体误差，每个分量都收敛。</p>
<p>（这个我在数值分析也学过！耶！</p></li>
<li><p>假设 <span class="math inline">\((X,d_X)\)</span>
是距离空间，<span class="math inline">\((V,\|\cdot\|)\)</span>
是赋范线性空间，<span class="math inline">\(f\colon X\rightarrow
V\)</span> 和 <span class="math inline">\(g\colon X\rightarrow
V\)</span> 是连续映射。证明，它们的和与差（自然的定义）<span class="math inline">\(f\pm g\colon X\rightarrow V\)</span>
也是连续映射。</p>
<p>如果 <span class="math inline">\(V=\mathbb{C}\)</span>（或者 <span class="math inline">\(n\times n\)</span>
的矩阵构成的赋范线性空间），那么 <span class="math inline">\(f\cdot
g\colon X\rightarrow \mathbb{C}\)</span> 是连续映射。</p>
<p>如果 <span class="math inline">\(V=\mathbb{C}\)</span> 并且对任意的
<span class="math inline">\(x\in X\)</span>，<span class="math inline">\(g(x)\neq 0\)</span>，那么 <span class="math inline">\(\dfrac{f}{g}\colon X\rightarrow
\mathbb{C}\)</span> 是连续映射。</p>
<p>你可以选择上面的一个情况来证明。</p>
<p>PIN 你真的有点无聊（哭），其实都挺 trivial 的。</p></li>
<li><p>试找出 <span class="math inline">\(\mathbb R\)</span>
上定义的函数</p>
<p><span class="math inline">\(f(x)=\begin{cases}\frac{1}{q}, \
&amp;\text{如果 $x=\dfrac{p}{q}$ 是有理数，其中 $p\in \mathbb{Z}$，$q\in
\mathbb{Z}_{\geqslant 1}$ 且 $p$ 和 $q$ 互素};\\ 0, \ &amp;\text{如果
$x$ 是无理数}\end{cases}\)</span></p>
<p>的所有不连续点。</p>
<p>回顾一下：连续点的含义是 <span class="math inline">\(f\)</span> 在
<span class="math inline">\(x_0\)</span>
处有（唯一的，左右相等的）极限，当且仅当对任意的 <span class="math inline">\(\varepsilon&gt;0\)</span>，存在 <span class="math inline">\(\delta&gt;0\)</span>，使得对任意的 <span class="math inline">\(x_1,x_2\in (x_0-\delta,x_0+\delta)\)</span>，都有
<span class="math inline">\(|f(x_1)-f(x_2)|&lt;\varepsilon\)</span>。</p>
<p>对于有理数点，其实很容易就能找到一个趋近于它的无理数点列。取一个它左侧的无理数点
<span class="math inline">\(k\)</span>，二者一起不停找二分点，就可以取出一个趋近于这个有理数点的无理数点列。它的函数值是收敛不到
<span class="math inline">\(\frac 1 q\)</span>
的，于是所有的有理数点都是不连续点。</p>
<p>但是 <span class="math inline">\(0\)</span>
的函数值是咋定义的呢？如果函数值就是 <span class="math inline">\(0\)</span>，那它是唯一一个有理数连续点。</p>
<p>对于无理数点 <span class="math inline">\(t\)</span>，对任意的 <span class="math inline">\(\varepsilon &gt;0\)</span>，总能够取 <span class="math inline">\(\delta\)</span> 满足 <span class="math inline">\(t\)</span> 的去心邻域 <span class="math inline">\(T = (t-\delta,t) \cup (t,t+\delta)\)</span>
里面没有形如 <span class="math inline">\(p \over q\)</span>
的有理数，使得分子分母互素，而且 <span class="math inline">\(q &lt;
\frac{1}{\varepsilon}\)</span>，因此对任意 $ x_1 ,x_2 T$，有 <span class="math inline">\(| f(x_1 ) - f(x_2) | &lt;
\varepsilon\)</span>，总是收敛的。</p>
<p>至于为什么可以做到这一点，这是因为记把 <span class="math inline">\(t\)</span> 附近 <span class="math inline">\(q &lt;
{1 \over \varepsilon }\)</span> 的有理数点中离它最近的距离记为 <span class="math inline">\(d\)</span>，取 <span class="math inline">\(\delta
= \frac d 2\)</span> 即可，而这样的有理数点是有穷个，一定可以找到对应的
<span class="math inline">\(d&gt;0\)</span>。</p>
<p>总之，所有的不连续点的集合是 <span class="math inline">\(\mathbb
Q\)</span>，视情况可能 <span class="math inline">\(0\)</span>
会是连续的，这里定义的好像不是很好。</p></li>
</ul>
<h3 id="级数收敛性">级数收敛性</h3>
<p>眼前一黑，我直接一个梦回微积分 A2（，这一部分就比较水字数了。</p>
<ul>
<li>试判断下列级数的收敛性。
<ul>
<li><p><span class="math inline">\(\sum_{n=1}^\infty
(\sqrt{n+1}-\sqrt{n})\)</span></p>
<p>发散，trivial.</p></li>
<li><p><span class="math inline">\(\sum_{n=1}^\infty
\frac{\sqrt{n+1}-\sqrt{n}}{n}\)</span></p>
<p>收敛，trivial.</p></li>
<li><p>$_{n=2}<sup>(-1)</sup>n $</p>
<p>收敛，因为数列 <span class="math inline">\(n^{1 \over n}\)</span>
单调减并趋近 <span class="math inline">\(1\)</span>，对于某个被 <span class="math inline">\(\varepsilon\)</span> 控制的 <span class="math inline">\(n &gt;N\)</span>，有 <span class="math inline">\(\sum_{n=N+1}^\infty (\sqrt[n]{n}-1)^n &lt;
\sum_{n=N+1}^\infty \varepsilon ^n\)</span>。</p></li>
<li><p>$_{n=1}^ (x) $</p>
<p><span class="math inline">\(|x|&lt;1\)</span> 或 <span class="math inline">\(x=1\)</span> 时单项收敛不到 <span class="math inline">\(0\)</span>，级数发散；否则收敛。</p></li>
<li><p>$_{n=1}^ $</p>
<p>收敛，trivial.</p></li>
<li><p>$_{n=1}<sup>()</sup>n $</p>
<p>收敛，单项放缩。</p></li>
<li><p>$_{n=1}^ $</p>
<p>发散，验一下不符合 Cauchy 列。</p></li>
<li><p><span class="math inline">\(\sum_{n=2}^\infty \frac{1}{(\log
n)^{\log n}}\)</span></p>
<p>感觉可以用积分法判断收敛（，但是还没学过积分（，怎么办呢。</p>
<p>也可以放缩，<span class="math inline">\(n &gt; N\)</span> 时有 <span class="math inline">\(\frac{1}{(\log n)^{\log n}} &lt;
\frac{1}{n^M}\)</span>。收敛。</p></li>
<li><p>$_{n=1}^ $</p>
<p>单项可以写成更好的形式：${(n^{1 n} / (n+ {1 n} ) ^{1 } )}^{n ^2 +1} $
（天哪这个能渲染出来吗，好担心）</p>
<p>发散。</p></li>
<li><p>$_{n=1}<sup>(-1)</sup>{n-1} $</p>
<p>收敛，Dirichlet 判别。</p></li>
<li><p>$_{n=1}^ $</p>
<p>发散，trivial.</p></li>
<li><p><span class="math inline">\(\sum_{n=1}^\infty
\left(1+\frac{1}{2}+\cdots + \frac1n\right)\frac{\sin
nx}{n}\)</span></p>
<p>收敛。拆分 <span class="math inline">\(b_n = \frac{1}{n} (1 + \frac 1
2 +...+ \frac 1 n)\)</span>，<span class="math inline">\(a_n = \sin
nx\)</span>，用 Dirichlet 判别法，其中 <span class="math inline">\(b_n
&lt; \frac{log _2 n}{n}\)</span>。</p>
<p>需要注意的是要讨论一下 <span class="math inline">\(x = 2k
\pi\)</span> 的情况。</p></li>
</ul></li>
<li>试判断下列级数的收敛性并确定它们是否绝对收敛。
<ul>
<li><p>$_{n=2}<sup>(-1)</sup>n $</p>
<p>不绝对收敛，感觉也可以用积分判别，懒得多想了（</p>
<p>收敛，trivial.</p></li>
<li><p>$_{n=2}^ $</p>
<p>不绝对收敛，求一下 <span class="math inline">\(\sin
\frac{n\pi}{4}\)</span> 的值就知道了。</p>
<p>收敛，trivial.</p></li>
<li><p>$_{n=1}<sup>(-1)</sup>n $</p>
<p>不绝对收敛，分离常数之后发现一部分收敛一部分不收敛。</p>
<p>收敛，仍然是分离常数，trivial.</p></li>
<li><p><span class="math inline">\(\sum_{n=1}^\infty
(-1)^{\frac{n(n-1)}{2}} \frac{n^{10}}{a^n} \qquad (a&gt;1)\)</span></p>
<p>绝对收敛，trivial.</p></li>
</ul></li>
</ul>
<h3 id="递减正项级数的凝聚检验法">递减正项级数的凝聚检验法</h3>
<p>假设正整数 <span class="math inline">\(b\geqslant 2\)</span>，<span class="math inline">\(f\colon (1,\infty)\rightarrow
\mathbb{R}_{&gt;0}\)</span> 是递减（未必严格递减）函数。</p>
<ul>
<li><p>证明下面的不等式：<span class="math inline">\((b-1)b^{k-1}f(b^{k})\leqslant
\sum_{j=b^{k-1}}^{b^k-1} f(j) \leqslant
(b-1)b^{k-1}f(b^{k-1})\)</span></p>
<p>什么茶歇题。Trivial.</p></li>
<li><p>证明：级数 $<em>{n=1}^f(n) $ 和 $ </em>{n=1}<sup>b</sup>n f(b^n)$
同时收敛或者同时发散。</p>
<p>我们称通过后者的收敛来判断前者收敛的方法为凝聚检验法。</p>
<p>根据上一问求和，trivial.</p></li>
<li><p>证明，<span class="math inline">\(\displaystyle \sum_{n=2}^\infty
\frac{1}{n\log n}\)</span> 是发散的。</p>
<p>不如试试积分收敛法（被捂嘴拖走</p>
<p>取 <span class="math inline">\(b=2\)</span>
知道它和调和级数是同收敛同发散的。</p></li>
<li><p>证明，<span class="math inline">\(\displaystyle\sum_{n=100}^\infty \frac{1}{(n\log
n) (\log (\log n))}\)</span> 是发散的。</p>
<p>它和上一问的级数是同收敛同发散的。</p></li>
<li><p>证明，如果 <span class="math inline">\(s&gt;1\)</span>，那么
<span class="math inline">\(\displaystyle\sum_{n=1}^\infty
\frac{1}{n^s}\)</span> 是收敛的；如果 <span class="math inline">\(0&lt;s&lt;1\)</span>，那么 <span class="math inline">\(\displaystyle\sum_{n=1}^\infty
\frac{1}{n^s}\)</span> 是发散的。</p>
<p>取 <span class="math inline">\(b=2\)</span>
知它和一个等比数列同收敛同发散。</p></li>
<li><p>假设 <span class="math inline">\(s&gt;1\)</span>。证明，<span class="math inline">\(\displaystyle\sum_{n=2}^\infty \frac{1}{n(\log
n)^s}\)</span> 和 <span class="math inline">\(\displaystyle\sum_{n=10}^\infty \frac{1}{(n\log
n)(\log(\log n))^s}\)</span> 都收敛。</p>
<p>前一个和上一问同收敛同发散。后一个和 <span class="math inline">\(\displaystyle\sum_{n=10}^\infty \frac{1}{n {\log^s
n} }\)</span> 同收敛同发散。</p></li>
</ul>
<blockquote>
<p>Remark：上述的几个收敛的结论是标准并且重要的，记住这几个结论对于收敛以及函数大小的理解很有帮助。这里的证明尽管巧妙，但是等我们接触到积分的时候，我们就可以用统一的、简单的、更本质的也更容易记忆的方法来证明这些结论。</p>
</blockquote>
<h3 id="实数列的上下极限的刻画">实数列的上下极限的刻画</h3>
<p>设 <span class="math inline">\(\{a_n\}_{n \geqslant 1}\)</span>
是一个实数列。先补充几个定义：</p>
<p><span class="math inline">\(\alpha \in \mathbb R\)</span>，如果对任意
<span class="math inline">\(\varepsilon&gt;0\)</span>, 存在无穷多 <span class="math inline">\(n\)</span>，使得 <span class="math inline">\(a_n
\in (\alpha-\varepsilon,\alpha+\varepsilon)\)</span>，我们称 <span class="math inline">\(\alpha\)</span> 为 <span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span> 的一个极限点；</p>
<p>如果对任意 <span class="math inline">\(M&gt;0\)</span>，存在无穷多个
<span class="math inline">\(n\)</span>，使得 <span class="math inline">\(a_n \in (M,\infty)\)</span>，我们就称 <span class="math inline">\(+\infty\)</span> 为 <span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span> 的一个极限点；</p>
<p>如果对任意 <span class="math inline">\(M&gt;0\)</span>，存在无穷多个
<span class="math inline">\(n\)</span>，使得 <span class="math inline">\(a_n \in (-\infty,-M)\)</span>，我们就称 <span class="math inline">\(-\infty\)</span> 为 <span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span> 的一个极限点。</p>
<ul>
<li><p>证明，<span class="math inline">\(\alpha\in \mathbb R\)</span> 是
<span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span>
的极限点当且仅当该数列有子序列 <span class="math inline">\(\{a_{n_k}\}_{k\geqslant 1}\)</span> 收敛于 <span class="math inline">\(\alpha\)</span>。</p>
<p>对于 <span class="math inline">\(\varepsilon _1 = 1\)</span>，取
<span class="math inline">\(a_1 \in
(\alpha-\varepsilon_1,\alpha+\varepsilon_1)\)</span>；再取 <span class="math inline">\(\varepsilon _2 = |\alpha - a_1|\)</span>，继续取
<span class="math inline">\(a_2\)</span>，依次操作就得到了收敛子序列。</p>
<p>反过来是显然的。</p></li>
<li><p>证明，<span class="math inline">\(+\infty\)</span> 是 <span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span>
的极限点当且仅当该数列有子序列 <span class="math inline">\(\{a_{n_k}\}_{k\geqslant 1}\)</span> 使得 <span class="math inline">\(\displaystyle\lim_{k\to \infty} a_{n_k} =
+\infty\)</span>。</p>
<p>Trivial.</p></li>
<li><p>令 <span class="math inline">\(E = \bigl\{\alpha \in \mathbb R
\cup \{\pm \infty\} \,\rvert\, \alpha \text{ 是 } \{a_n\}_{n\geqslant 1}
\text{ 的极限点}\bigr\}\)</span> 为 <span class="math inline">\(\{a_n\}_{n\geqslant1}\)</span>
的所有极限点所组成的集合（它是 <span class="math inline">\(\mathbb R
\cup \{\pm \infty\}\)</span> 的子集）。证明，<span class="math inline">\(E \ne \emptyset\)</span>。</p>
<p>考察 $sup {a_n}_{n} = + $ 或者 <span class="math inline">\(inf
\{a_n\}_{n\geqslant1} = -\infty\)</span>，如果有二者之一则有 <span class="math inline">\(+\infty \in E\)</span> 或者 <span class="math inline">\(-\infty \in E\)</span>。</p>
<p>否则，<span class="math inline">\(\{a_n\}_{n\geqslant1}\)</span>
是有界的。如果它收敛于一点，则这一点是极限点，<span class="math inline">\(E\)</span> 非空。</p>
<p>否则，<span class="math inline">\(\{a_n\}_{n\geqslant1}\)</span>
有界且不收敛，它也有收敛的子列，子列收敛的极限是极限点。（救命，差点忘了这个</p></li>
<li><p>证明：<span class="math inline">\(E \subset \mathbb R\)</span>
当且仅当数列 <span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span>
有界。</p>
<p>Trivial.</p></li>
<li><p>假设 <span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span>
有界。试证明，<span class="math inline">\(\displaystyle \sup E =
\limsup_{n\to \infty} a_n\)</span>，<span class="math inline">\(\displaystyle\inf E = \liminf_{n\to \infty}
a_n\)</span>。</p>
<p>是我困迷糊了吗？我不是很理解诶，比如说数列 <span class="math inline">\(1,1,100000,1,1,1,1,1,...\)</span>，真的符合第一条吗？</p></li>
<li><p>假设 <span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span>
有界。令 <span class="math inline">\(a^*= \displaystyle\limsup_{n\to
\infty} a_n\)</span>，证明如下两个命题：</p>
<ul>
<li><p><span class="math inline">\(a^* \in E\)</span>（所以 <span class="math inline">\(\sup E\in E\)</span>）;</p></li>
<li><p>对任意 <span class="math inline">\(x &gt; a^*\)</span>，存在
<span class="math inline">\(N \in \mathbb{Z}_{\geqslant
1}\)</span>，使得对任意 <span class="math inline">\(n&gt;N\)</span>，都有 <span class="math inline">\(a_n &lt; x\)</span>。</p></li>
</ul></li>
<li><p>试举一个数列 <span class="math inline">\(\{a_n\}_{n\geqslant
1}\)</span> 作为例子，使得 <span class="math inline">\(E\cap \mathbb R
\ne \emptyset\)</span> 且 <span class="math inline">\(E\not\subseteq
\mathbb R\)</span>。</p>
<p>这题我会！</p>
<p><span class="math inline">\(1,2,1,3,1,4,...,1,n,1,n+1,...\)</span>，于是 <span class="math inline">\(E=\lbrace 1 , +\infty \rbrace\)</span>。</p></li>
<li><p>试举一个数列 <span class="math inline">\(\{a_n\}_{n\geqslant
1}\)</span> 作为例子，使得 <span class="math inline">\(E\)</span>
为无穷集。</p>
<p>这题我也会！</p>
<p><span class="math inline">\(1,1,2,1,2,3,1,2,3,4,1,2,3,4,5,...\)</span>，于是
<span class="math inline">\(E=\mathbb Z ^{+} \cup \lbrace + \infty
\rbrace\)</span>。</p>
<p>有可数集那味了！</p></li>
</ul>
<h3 id="素数的倒数和">*素数的倒数和</h3>
<p>根据第七次课的内容，对于 <span class="math inline">\(s&gt;1\)</span>，我们可以定义 <span class="math inline">\(\zeta\)</span>-函数 <span class="math inline">\(\zeta(s)=\sum_{n=1}^\infty
\frac{1}{n^s}\)</span>，</p>
<p>并且证明了Euler乘积公式：<span class="math inline">\(\zeta(s)=\prod_{p\in
\mathcal{P}}\frac{1}{1-p^{-s}}\)</span>，其中 <span class="math inline">\(\mathcal{P}\)</span> 是全体素数的集合。</p>
<p>据此证明，级数 <span class="math inline">\(\sum_{p\in
\mathcal{P}}\frac{1}{p^s}\)</span> 对于 <span class="math inline">\(s&gt;1\)</span> 是收敛的；对于 <span class="math inline">\(0&lt;s\leqslant 1\)</span>
是发散的（这给出了有无穷多个素数的另一个证明）。</p>
<p><strong>胡说八道：</strong></p>
<p>我觉得吧，<span class="math inline">\(\zeta(s)=\prod_{p\in
\mathcal{P}}\frac{1}{1-p^{-s}} = \prod_{p\in
\mathcal{P}}(1+\frac{1}{p^{s} - 1})\)</span> 收敛等价于 <span class="math inline">\(\sum_{p\in \mathcal{P}} \frac{1}{p^{s} -
1}\)</span> 收敛，那么 <span class="math inline">\(s &gt;1\)</span>
时素数的倒数和也收敛。</p>
<p>（毫无必要啊！直接小于调和级数和就可以了 T_T）</p>
<p>其实我想胡说八道的是，<span class="math inline">\(\zeta(s)=\prod_{p\in
\mathcal{P}}\frac{1}{1-p^{-s}}\)</span> 收敛能不能等价于 <span class="math inline">\(\zeta(s)=\prod_{p\in
\mathcal{P}}(1-p^{-s})\)</span> 收敛，再等价于 <span class="math inline">\(\sum_{p \in \mathcal P} p^{-s}\)</span> 收敛？</p>
<h3 id="basel问题的euler证明">*Basel问题的Euler“证明”</h3>
<p>对任意的 <span class="math inline">\(\theta\in \mathbb R\)</span> 和
<span class="math inline">\(n\in \mathbb{Z}_{\geqslant
1}\)</span>，试证明恒等式 <span class="math inline">\(\frac{\sin\bigl((2n+1)\theta\bigr)}{(2n+1)\sin\theta}=\prod_{k=1}^n
\left(1-\frac{\sin^2(\theta)}{\sin^2\left(\frac{k\pi}{2n+1}\right)}\right)\)</span></p>
<p>据此证明，对任意的 <span class="math inline">\(x\in \mathbb
R\)</span>，我们都有 <span class="math inline">\(\frac{\sin(\pi x)}{\pi
x}=\prod_{n=1}^\infty\left(1-\frac{x^2}{n^2}\right)\)</span></p>
<p>（如果 <span class="math inline">\(x=0\)</span>，我们将左边定义为极限
<span class="math inline">\(\displaystyle \lim_{x\rightarrow
0}\frac{\sin(\pi x)}{\pi x}\)</span>）</p>
<p><strong>胡说八道</strong>：</p>
<p>这题还真的不是胡说八道，第一问是数值分析里学过的，第二类 Chebyshev
多项式代入化简（（</p>
<p>后一问大概只要取 <span class="math inline">\(\theta = \frac{\pi
x}{2n+1}\)</span>，然后让 <span class="math inline">\(n \to
\infty\)</span>。</p>
<blockquote>
<p>Remark：</p>
<p>根据上面的公式，形式上，我们就有 <span class="math inline">\(sin(\pi
x)=\pi x\prod_{n=1}^\infty\left(1-\frac{x^2}{n^2}\right)=\pi
x\left(1-\left(\sum_{n=1}^\infty\frac{1}{n^2}\right)x^2+(\cdots)x^4+(\cdots)x^6+\cdots
\right)\)</span></p>
<p>所以，右边 <span class="math inline">\(x^3\)</span> 的系数就是 <span class="math inline">\(\displaystyle-\pi\sum_{n=1}^\infty\frac{1}{n^2}\)</span>。根据我们对于
<span class="math inline">\(\sin\)</span> 的定义</p>
<p><span class="math inline">\(\sin z =\frac{e^{iz}-e^{-iz}}{2i} =
\sum_{k=0}^\infty \frac{(-1)^k z^{2k+1}}{(2k+1)!}\)</span></p>
<p>所以，<span class="math inline">\(\sin(\pi x)\)</span> 中展开式的
<span class="math inline">\(x^3\)</span> 项的系数是 <span class="math inline">\(-\dfrac{\pi^3}{6}\)</span>。比较系数，我们得到所谓的Basel问题的解：</p>
<p><span class="math inline">\(\sum_{n=1}^\infty\frac{1}{n^2}=\frac{\pi^2}{6}\)</span></p>
<p>这是 Euler 原始的想法，他就是利用了上面的乘积公式来猜测最终的极限是
<span class="math inline">\(\dfrac{\pi^2}{6}\)</span>。有趣的是，他观察到
<span class="math inline">\(\dfrac{\sin(\pi x)}{\pi x}\)</span>
的零点恰好是 <span class="math inline">\(x=\pm n\)</span>，所以如果
<span class="math inline">\(\dfrac{\sin(\pi x)}{\pi x}\)</span>
的行为与多项式类似的话，那么这个函数应该是单项式的乘积，所以 Euler
认为</p>
<p><span class="math inline">\(\frac{\sin(\pi x)}{\pi x}=c\prod_{n\in
\mathbb{Z}-\{0\}}\left(1-\frac{x}{n}\right)=c\prod_{n=1}^\infty\left(1-\frac{x^2}{n^2}\right)\)</span>。</p>
<p>其中 <span class="math inline">\(c\)</span> 是一个待定的常数，通过取
<span class="math inline">\(x\rightarrow 0\)</span> 的极限，他计算出
<span class="math inline">\(c=1\)</span>。</p>
</blockquote>
<h1 id="连续性">连续性</h1>
<p>进入新的章节啦！qwq</p>
<p>2023 年 1 月 27 日，星期五，我要先去睡个觉（（</p>
<h2 id="函数的连续性">函数的连续性</h2>
<ul>
<li><p>函数值在单点处的收敛有两种定义方式，一个是任意收敛点列，一个是
<span class="math inline">\(\varepsilon - \delta\)</span>
语言。关于在单点处的连续性，Heine 定理保证二者是等价的。</p>
<p>证明中可以灵活选用两种定义方式，很可能一种比另一种叙述起来简单很多。</p></li>
<li><p>单点连续，局部连续和全局连续是完全不一样的概念。最基础的定义是关于函数值的单点连续性的，全局连续往往由开覆盖的全体局部连续推出。</p>
<p>*所以说，函数的连续性本质上是一个局部的性质。很重要的一个例子是，假设函数
<span class="math inline">\(f\colon I_1\cup I_2\rightarrow \mathbb
R\)</span> 定义在两个不相交的开区间的并集上，按照定义，如果 <span class="math inline">\(f\)</span> 在每个点上都连续，<span class="math inline">\(f\)</span> 就是在 <span class="math inline">\(I_1\cup I_2\)</span> 上连续的。尽管函数图像在
<span class="math inline">\(I_1\cup I_2\)</span>
是“断开的”，这个函数仍然是连续的（因为连续性本质上是个局部性质，在 <span class="math inline">\(I_1\)</span> 和 <span class="math inline">\(I_2\)</span> 上分别连续即可）。</p>
<p>用 <span class="math inline">\(C(I)\)</span> 表示区间 <span class="math inline">\(I\)</span> 上的连续函数的全体所构成的集合，<span class="math inline">\((C(I),+,⋅)\)</span> 是一个环。</p></li>
<li><blockquote>
<p>不夸张的说，我们在数学中遇到（几乎）一切连续函数都是通过两种手段构造的：第一，通过连续函数的复合和四则运算；第二，通过逼近的方式，特别是级数的方式来定义，比如说
<span class="math inline">\(\exp\)</span>
的构造。这种逼近的方式是最值得我们注意的，我们很快会发现，<span class="math inline">\(C(I)\)</span> 这个空间和实数 <span class="math inline">\(\mathbb R\)</span>
很相似，构造无理数就是通过有理数逼近的方式。</p>
<p>更具体一点，我们会在 <span class="math inline">\(C(I)\)</span>
上面给定一个范数 <span class="math inline">\(\|\cdot
\|_{\infty}\)</span> 并且证明这样得到的赋范线性空间是完备的。此时，任给
<span class="math inline">\(f\in
C(I)\)</span>，我们可以仿照实数的情况定义 <span class="math inline">\(e^f : =\sum_{n=0}^\infty
\frac{f^k}{n!}\)</span>。</p>
<p>在完备的赋范线性空间中，我们只要全盘照抄实数的情况就可以证明上面的（函数）级数收敛，从而
<span class="math inline">\(e^f\)</span>
是良好定义的并且是连续函数。特别地，我们可以通过这种方式定义 <span class="math inline">\(e^x\)</span>（把 <span class="math inline">\(x\)</span> 看成是函数 <span class="math inline">\(f\)</span>）而且说明这和我们最初定义的 <span class="math inline">\(\exp(x)\)</span> 是一码事。</p>
<p>在这种类比下，我们就可以利用对实数的直观来研究函数空间，从而得到很多关于函数的深刻结果。在课程后面的学习中，我们会遇到很具体的例子，比方说存在处处连续但是处处都不能微分的函数，我们就是通过构造函数的级数来实现的。</p>
</blockquote>
<p>总之，从用具体的级数和定义 <span class="math inline">\(e\)</span>，再定义出 <span class="math inline">\(e^x\)</span>，然后介绍了赋范线性空间以及为矩阵定义了
<span class="math inline">\(e^A\)</span>，现在又为函数定义了 <span class="math inline">\(e^f\)</span>。每当不知道怎么理解 <span class="math inline">\(e\)</span>
的时候，试着代入级数就懂了。期待一些函数级数收敛构造出的连续函数。</p></li>
</ul>
<h2 id="连续映射">连续映射</h2>
<ul>
<li><p>连续函数是一个局限比较强的定义，把 $C $
映射到它自身而已。所以要定义一个连续映射的概念；</p>
<p>假设 <span class="math inline">\((X,d)\)</span> 和 <span class="math inline">\((Y,d_Y)\)</span> 是两个距离空间，<span class="math inline">\(f\colon X\rightarrow Y\)</span>
是这两个距离空间之间的映射。假设 <span class="math inline">\(x_0\in
X\)</span>，<span class="math inline">\(y_0=f(x_0)\in
Y\)</span>。如果对任意 <span class="math inline">\(\varepsilon&gt;0\)</span>，总存在 <span class="math inline">\(\delta&gt;0\)</span>，使得对任意满足 <span class="math inline">\(d(x,x_0)&lt;\delta\)</span> 的 <span class="math inline">\(x \in X\)</span>，都有 <span class="math inline">\(d_Y\bigl(f(x),f(x_0)\bigr)&lt;\varepsilon\)</span>，我们就称
<span class="math inline">\(f\)</span> 在 <span class="math inline">\(x_0\)</span> 处连续。如果 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(X\)</span> 的每个点处都连续，那么我们就称 <span class="math inline">\(f\)</span> 是连续映射。</p>
<p>我们可以看到，连续映射的自由度很大，两个距离空间的元素，各自的范数定义都很自由。</p></li>
<li><p>考虑一个 <span class="math inline">\(\exp : M_n(\mathbb C) \to
M_n(\mathbb C)\)</span>
的映射，它的定义我们用级数写过也证明收敛了，下面来证明它是连续映射。记
<span class="math inline">\(M_n(\mathbb C)\)</span> 上的范数是 Frobenius
范数，它是一个相容范数，放缩起来会比较容易（我不是很懂为什么讲义上说这是
<span class="math inline">\(2-\)</span>范数，矩阵的 <span class="math inline">\(2-\)</span>范数不是特征值相关的那个嘛？），<span class="math inline">\(\exp(A) = \sum_{k=0} ^{+\infty} {A^k \over
k!}\)</span>。</p>
<p><span class="math inline">\(\exp : \mathbb R \to \mathbb R\)</span>
的证明用 <span class="math inline">\(\varepsilon - \delta\)</span>
语言就能轻松地写完。把它迁移到矩阵空间上，证明会复杂一些，用了相容范数的性质。</p></li>
</ul>
<h2 id="连续函数的性质">连续函数的性质</h2>
<ul>
<li><p>一个关于单调函数的性质，感觉还挺有必要记一下：</p>
<p><span class="math inline">\(I\)</span> 是区间（可开可闭），<span class="math inline">\(f\colon I \rightarrow \mathbb R\)</span> 是 <span class="math inline">\(I\)</span> 上的单调函数，那么</p>
<ul>
<li><p>对任意 <span class="math inline">\(x_0\in I\)</span>，<span class="math inline">\(f\)</span> 在 <span class="math inline">\(x_0\)</span> 处的左极限 <span class="math inline">\(\displaystyle\lim_{x\rightarrow
x_0^-}f(x)\)</span> 和右极限 <span class="math inline">\(\displaystyle\lim_{x\rightarrow
x_0^+}f(x)\)</span> 都存在（原文如此。但是如果 <span class="math inline">\(I\)</span> 是闭区间而 <span class="math inline">\(x_0\)</span> 是其端点，那么 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(x_0\)</span> 处的左/右极限可能为无穷）</p></li>
<li><p><span class="math inline">\(f\)</span> 在 <span class="math inline">\(I\)</span>
上的不连续点的集合是可数的。(这表明单调函数 <span class="math inline">\(f\)</span> 在“大部分”点处都是连续的）</p></li>
</ul>
<p>第一问的证明其实也是取 <span class="math inline">\(x_0\)</span>
点左侧的无穷点列，它们的函数值构成有上界的无穷点列，一定有极限。不妨设
<span class="math inline">\(f\)</span>
是一个单调增函数，则这个极限可以表示为 <span class="math inline">\(\sup
f(x) , x \in (x_0 , x_0 -
\delta)\)</span>。再验证这个极限是左极限，用上确界的性质。</p>
<p>第二问的话，放一个证明在这里：</p>
<blockquote>
<p>考虑 <span class="math inline">\(f\)</span> 的不连续点的集合 <span class="math inline">\(Y=\bigl\{y\in I\bigm| \text{$f$ 在 $y$
处不连续}\bigr\}\)</span>。</p>
<p>对于任意 <span class="math inline">\(y\in Y\)</span>，按照定义，<span class="math inline">\(\displaystyle \lim_{x\rightarrow x_0^-}f(x)\neq
\lim_{x\rightarrow
x_0^+}f(x)\)</span>。再利用上面推论中的结论，我们知道，对任意 <span class="math inline">\(y\in Y\)</span>，我们有 <span class="math inline">\(\lim_{x\rightarrow y^-}f(x) &lt;
\lim_{x\rightarrow y^+}f(x)\)</span>。</p>
<p>据此，对于任意 <span class="math inline">\(y\in
Y\)</span>，都唯一地确定了一个非空的开区间 <span class="math inline">\(I_y=(\lim_{x\rightarrow
y^-}f(x),\lim_{x\rightarrow y^+}f(x))\)</span>，即我们构造了映射 <span class="math inline">\(Y\rightarrow \bigl\{\text{$\mathbb R$
上的全体非空开区间}\bigr\}, \ \ y\mapsto I_y\)</span></p>
<p>利用单调性，我们首先说明对任意的 <span class="math inline">\(y_1,y_2\in Y\)</span>，<span class="math inline">\(y_1\neq y_2\)</span>，<span class="math inline">\(I_{y_1}\cap I_{y_2}=\emptyset\)</span>：</p>
<p>不妨假设 <span class="math inline">\(y_1&lt;y_2\)</span>，根据上面的推论的结论，我们可以选取单调下降的数列
<span class="math inline">\(\{x_k\}_{k\geqslant 1}\)</span>，使得 <span class="math inline">\(x_k \downarrow y_1\)</span>（从右边逼近）并且
<span class="math inline">\(\displaystyle\lim_{k\rightarrow \infty}
f(x_k)\)</span> 为 <span class="math inline">\(I_{y_1}\)</span>
的右端点；类似地，我们选取单调上升的数列 <span class="math inline">\(\{z_k\}_{k\geqslant 1}\)</span>，<span class="math inline">\(z_k\uparrow y_2\)</span>（从左边逼近），使得 <span class="math inline">\(\displaystyle\lim_{k\rightarrow \infty}
f(z_k)\)</span> 为 <span class="math inline">\(I_{y_2}\)</span>
的左端点。由于 <span class="math inline">\(y_1&lt;y_2\)</span>，我们可以假设对任意 <span class="math inline">\(k\)</span> 都有 <span class="math inline">\(x_k&lt;z_k\)</span>，所以 <span class="math inline">\(\displaystyle\lim_{k\rightarrow \infty}
f(x_k)\leqslant \displaystyle\lim_{k\rightarrow \infty}
f(z_k)\)</span>，也就是说 <span class="math inline">\(I_{y_1}\)</span>
的右端点要么在 <span class="math inline">\(I_{y_2}\)</span>
的左端点的左边要么重合，由于这两个区间都是开区间，所以它们的交集是空集。</p>
<p>这样，我们就得到了一组 <span class="math inline">\(\mathbb R\)</span>
上两两不相交的非空开区间 <span class="math inline">\(\bigl\{I_y\bigm|
y\in Y\bigr\}\)</span>，我们在每个开区间 <span class="math inline">\(I_y\)</span> 里选定一个有理数 <span class="math inline">\(q_y\)</span>，由于这些开区间互不相交，这些有理数
<span class="math inline">\(q_y\)</span>
也决定了这些开区间。从而，我们得到了单射</p>
<p><span class="math inline">\(Y\rightarrow \mathbb{Q}, \ \ y\mapsto
q_y\)</span>。</p>
<p>由于有理数是可数的，所以 <span class="math inline">\(Y\)</span>
可数。</p>
</blockquote></li>
<li><p>介值定理。</p>
<p>又到了我最爱的闭区间套定理时间！.jpg。为什么说是我最爱的闭区间套定理呢，因为：</p>
<blockquote>
<p>我：先做 ddl 最晚的作业，然后往前慢慢推，就能正好在最早的 ddl
之前写完所有作业</p>
<p>室友：那要是最早的 ddl 之前没完成怎么办</p>
<p>我：不会的，闭区间套定理保证哪怕有无穷个
ddl，也还可以有一个时刻在“做完所有作业”和“第一个 ddl
到来”这个区间里（</p>
</blockquote>
<p>我们要求介值定理的区间一定是一个“连通的”区间，也即所谓的 <span class="math inline">\([a,b]\)</span>，否则会举出反例。毕竟，函数的连续性并不要求定义域也是连续的，在若干个区间上分别定义出的连续函数接在一起，就是一个全局连续的函数，但是不能满足介值定理。</p>
<p>介值定理有很多奇技淫巧的题目，我在学微积分 A
的时候也写过一些，虽然挺好玩，但是感觉并没有什么意义。它比较有意义的一个点在于，第一次成功通过给定的一个任意函数值找到它的原像，也就是说可以用来得到一些“逆映射”的结论。对于闭区间上的单调函数，直观上来说它的逆是比较好找的，这是一个可以通过介值定理得到的结论。</p>
<p><span class="math inline">\(f\colon [a,b]\rightarrow \mathbb
R\)</span> 是严格递增（或者递减）的连续函数，那么 <span class="math inline">\(f\)</span> 是从 <span class="math inline">\([a,b]\)</span> 到 <span class="math inline">\([f(a),f(b)]\)</span> 的双射，并且其逆映射 <span class="math inline">\(f^{-1}\colon [f(a),f(b)]\rightarrow [a,b]\)</span>
是连续的。</p>
<blockquote>
<p>Remark：这是 <span class="math inline">\(1\)</span>-元函数的特殊性质，究其根本，是因为
<span class="math inline">\(1\)</span> 维空间上面 <span class="math inline">\(\mathbb R\)</span> 有序关系 <span class="math inline">\(\leqslant\)</span> 而在 <span class="math inline">\(\mathbb R^n\)</span> 上是没有的。</p>
</blockquote>
<p>由此，我们可以为一些单调的初等函数构造它们的逆，也终于可以得到 <span class="math inline">\(\sqrt{x},\log x\)</span> 这样的函数了。</p>
<p>一般的对数函数和幂函数只要改变一些系数就能得到，比如 <span class="math inline">\(x^ \alpha = e^ {\alpha \log{x} }\)</span>，<span class="math inline">\(\log_\alpha (x)= {\log x \over \log
\alpha}\)</span>。实际上，这二者既分别关于 <span class="math inline">\(x\)</span> 和 <span class="math inline">\(\alpha\)</span> 连续，也关于 <span class="math inline">\((x,\alpha)\)</span>
连续。（这是两个不同的概念）</p>
<blockquote>
<p>Remark：中学我们对 <span class="math inline">\(e\)</span>
的了解很少，所以和 <span class="math inline">\(e\)</span>
相关的对象反而变得容易理解，因为我们只需要验证关于 <span class="math inline">\(e\)</span>
的很少的几个已经知道的性质即可；然而，对于 <span class="math inline">\(\pi\)</span> 以及相关的 <span class="math inline">\(\sin x\)</span>
等三角函数，我们了解很多它们的性质，这反而给我们新发展的函数理论带来了很大的挑战：我们在定义这些对象的同时要能够证明它们满足所知的所有性质。实际上，我们必须建立了整个微积分的理论之后才能够做到这一点。</p>
<p>日本京都大学的数学家望月新一在他的宇宙际Teichmuller理论的论文（他在这一系列论文中声称他证明了abc猜想，目前还没有得到承认）里说：Unlike
many mathematical papers, which are devoted to verifying properties of
mathematical objects that are either well-known or easily constructed
from well-known mathematical objects, in the present series of papers,
most of our efforts will be devoted to constructing new mathematical
objects. 我们这里构造的幂函数就是他所说的“well-known or easily
constructed from well-known mathematical objects”。</p>
</blockquote></li>
<li><p>假设 <span class="math inline">\(\mathbb R\)</span> 上定义函数
<span class="math inline">\(f(x)\)</span> 是连续的，如果我们知道 <span class="math inline">\(f\)</span> 在有理数上的取值，那么对任意的无理数
<span class="math inline">\(x\)</span>，我们任取一列有理数 <span class="math inline">\(r_i\)</span>，使得 <span class="math inline">\(r_i\rightarrow x\)</span>，连续性保证了 <span class="math inline">\(\displaystyle f(x)=f(\lim_{i\rightarrow \infty}
r_i)=\lim_{i\rightarrow \infty } f(r_i)\)</span>，所以 <span class="math inline">\(f(x)\)</span> 可以确定。注意到 <span class="math inline">\(\mathbb{Q}\)</span> 是 <span class="math inline">\(\mathbb R\)</span>
中“很小”的子集，由连续性，它已经可以确定 <span class="math inline">\(f\)</span>
了！这是分析学最重要的精神之一：如何从“局部”到整体。</p>
<p><strong>如果这个局部是对于整体稠密的，那么它完全可以决定整体</strong>。严格的表述是：</p>
<p><span class="math inline">\((X,d)\)</span> 和 <span class="math inline">\((Y,d_Y)\)</span> 是距离空间，<span class="math inline">\(X&#39; \subset X\)</span>
是一个稠密的子集，我们仍然用 <span class="math inline">\(d\)</span> 表示
<span class="math inline">\(X&#39;\)</span> 上的距离。对任意的连续映射
<span class="math inline">\(F_1\colon X\rightarrow Y\)</span> 和 <span class="math inline">\(F_2\colon X\rightarrow Y\)</span>，<span class="math inline">\(F_1\big|_{X&#39;}=F_2\big|_{X&#39;}\)</span>，那么，<span class="math inline">\(F_1=F_2\)</span>，换而言之，连续映射被它在一个稠密子集上的限制所决定。</p>
<p>假设 <span class="math inline">\(x\in X\)</span>，我们任意选取 <span class="math inline">\(\{x&#39;_n\}_{n\geqslant 1}\subset
X&#39;\)</span>，使得 <span class="math inline">\(x&#39;_n\rightarrow
x\)</span>。因为 <span class="math inline">\(F_1\)</span> 和 <span class="math inline">\(F_2\)</span> 在 <span class="math inline">\(X\)</span> 上连续，所以</p>
<p><span class="math inline">\(F_1(x)=\lim_{n\rightarrow
\infty}F_1(x&#39;_n)=\lim_{n\rightarrow
\infty}F_2(x&#39;_n)=F_2(x)\)</span>，命题得证。</p></li>
</ul>
<h2 id="连续函数的拓扑刻画">连续函数的拓扑刻画</h2>
<p>不是，怎么唐突开始升级了啊！</p>
<p>2023 年 1 月 28
日，星期六，我妈开始上班了所以我终于可以白天学这个东西了.jpg</p>
<blockquote>
<p>在开始介绍拓扑的概念之前, 我们引用 John von Neumann 的一段话:</p>
<p>Young man, in mathematics you don’t understand things. You just get
used to them.</p>
</blockquote>
<p>稍微有点难（</p>
<p>大概也没什么可写的，因为全都没见过所以大概只能抄概念，那还不如直接看原文，而且我已经纸质抄过一遍了
qwq</p>
<p>而且实际上所有的东西又在习题里以距离空间的加强版出现了。实数轴上唯一不同的是，开集可以表示为可数个开区间的并，这是特有的性质。</p>
<h2 id="summary-2">Summary</h2>
<p>之前讨论极限某种意义上来说都是关于点，性质也都是离散的。这一节考虑了函数的性质，涉及到连续变化的集合的函数值的性质。但令人欣慰的是，至少关于函数连续性的讨论还是可以通过点列、<span class="math inline">\(\varepsilon - \delta\)</span>
语言来进行，这是已经熟悉的内容。</p>
<p>其次，我们在这一部分之前对于函数的定义，只有基本的多项式函数、一些收敛的级数和
<span class="math inline">\(e^x\)</span>。一方面，通过介值定理我们基于单调函数的逆映射得到了
<span class="math inline">\(x^{1 \over n}\)</span>，<span class="math inline">\(\log _{\alpha} x\)</span>
函数的定义，并确认它们也是连续函数；另一方面，我们继续拓展了 <span class="math inline">\(e\)</span> 相关函数的定义丰富性，从原始的 <span class="math inline">\(e\)</span> 到 <span class="math inline">\(e^x\)</span>，再到赋范线性空间上的 <span class="math inline">\(e^A\)</span>（尽管它不能满足一些 <span class="math inline">\(e^x\)</span> 有的性质），这一次又添加了 <span class="math inline">\(e^f\)</span>
的定义。即使都是在级数的意义下进行定义，看起来大同小异，但是分别验证收敛性是必要的，这次还额外验证了
<span class="math inline">\(e^A\)</span> 在 Frobenius
范数下的连续性。</p>
<p>然后学了一点拓扑内容，大概讲了讲开集闭集的概念，引出了连续函数的第三种刻画：等价于任意开集的逆映集还是开集。</p>
<h2 id="梦话胡说八道一些证明题">梦话：胡说八道一些证明题</h2>
<p>计算对于做题家来说太 trivial
了，所以胡说八道一些证明题。我想我也没有非常胡说八道，毕竟不会做的题你让我胡说八道，我也说不出来什么，sigh。</p>
<h3 id="距离空间上的拓扑与连续性">距离空间上的拓扑与连续性</h3>
<ul>
<li><p>（距离空间上的Heine定理）假设 <span class="math inline">\((X,d_X)\)</span> 和 <span class="math inline">\((Y,d_Y)\)</span> 是距离空间，<span class="math inline">\(f\colon X\rightarrow Y\)</span>
是映射。我们有两种方式来定义连续映射（参见第3次作业题的A3)和第9次课）</p>
<ul>
<li><p>假设 <span class="math inline">\(x_0\in X\)</span>，如果对任意
<span class="math inline">\(X\)</span> 中的点列 <span class="math inline">\(\{x_n\}_{n\geqslant 1}\)</span>，<span class="math inline">\(x_n\stackrel{d_X}{\longrightarrow}x_0\)</span>，我们都有
<span class="math inline">\(f(x_n)\stackrel{d_Y}{\longrightarrow}f(x_0)\)</span>，我们就称
<span class="math inline">\(f\)</span> 在 <span class="math inline">\(x_0\)</span> 处是连续的。如果 <span class="math inline">\(f\)</span> 在一切 <span class="math inline">\(x\in
X\)</span> 处均连续，那么我们就称 <span class="math inline">\(f\)</span>
是距离空间之间的连续映射。</p></li>
<li><p>假设 <span class="math inline">\(x_0\in X\)</span>，<span class="math inline">\(y_0=f(x_0)\in Y\)</span>。如果对任意的 <span class="math inline">\(\varepsilon&gt;0\)</span>，总存在 <span class="math inline">\(\delta&gt;0\)</span>，使得对任意满足 <span class="math inline">\(d_X(x,x_0)&lt;\delta\)</span> 的 <span class="math inline">\(x \in X\)</span>，都有 <span class="math inline">\(d_Y\bigl(f(x),f(x_0)\bigr)&lt;\varepsilon\)</span>，我们就称
<span class="math inline">\(f\)</span> 在 <span class="math inline">\(x_0\)</span> 处连续。如果 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(X\)</span> 的每个点处都连续，那么我们就称 <span class="math inline">\(f\)</span> 是连续映射。</p>
<p>证明，上面两个对连续映射的定义是等价的。</p></li>
</ul>
<p>Trivial.</p></li>
<li><p><span class="math inline">\((X,d)\)</span> 是距离空间。对任意的点
<span class="math inline">\(x\in X\)</span>，<span class="math inline">\(r&gt;0\)</span>，我们称 <span class="math inline">\(B(x,r)=\bigl\{y\in X\mid
d(y,x)&lt;r\bigr\}\)</span> 为以 <span class="math inline">\(x\)</span>
为中心以 <span class="math inline">\(r\)</span>
为半径的开球。证明，对任意的点 <span class="math inline">\(x\in
X\)</span>，<span class="math inline">\(r&gt;0\)</span>，如果 <span class="math inline">\(x&#39;\in B(x,r)\)</span>，那么存在 <span class="math inline">\(r&#39;&gt;0\)</span>，使得 <span class="math inline">\(B(x&#39;,r&#39;)\subset B(x,r)\)</span>。</p>
<p>如果 <span class="math inline">\(U\subset X\)</span>
是若干开球的并，即 <span class="math inline">\(U=\displaystyle
\bigcup_{\alpha \in \mathcal{A}} B(x_\alpha,r_\alpha)\)</span>（指标集
<span class="math inline">\(\mathcal{A}\)</span> 是任意的），就称 <span class="math inline">\(X\)</span> 是距离空间 <span class="math inline">\((X,d)\)</span> 中的开集。证明，<span class="math inline">\(U\subset X\)</span> 是开集当且仅当对任意的 <span class="math inline">\(x\in U\)</span>，存在 <span class="math inline">\(\delta_x&gt;0\)</span>，使得 <span class="math inline">\(B(x,\delta_x)\subset U\)</span>。</p>
<p>前一问按照定义写一下就可以了；后一问用前一问的结论。Trivial.</p>
<p>直观上来看就是，取开球内部的一个点，有一个这个点决定的小球在开球内。其实就是开区间的推广。</p></li>
<li><p>（距离空间上的标准拓扑）我们用 <span class="math inline">\(\mathcal{T}\)</span> 表示距离空间 <span class="math inline">\((X,d)\)</span> 上的开集的全体，其中，我们规定
<span class="math inline">\(\emptyset\)</span> 和 <span class="math inline">\(X\)</span> 都是开集。证明，它们满足:</p>
<ul>
<li><span class="math inline">\(\emptyset \in \mathcal{T}\)</span>，
<span class="math inline">\(X \in \mathcal{T}\)</span>。</li>
<li>对任意开集的集合 <span class="math inline">\(\{U_{\alpha}\}_{\alpha
\in \mathcal{A}}\)</span>，其中 <span class="math inline">\(\mathcal{A}\)</span> 为指标集合，我们有 <span class="math inline">\(\displaystyle\bigcup_{\alpha \in
\mathcal{A}}U_\alpha \in \mathcal{T}\)</span>。</li>
<li>对任意有限个开集 <span class="math inline">\(U_1,U_2,\cdots, U_m \in
\mathcal{T}\)</span>，我们有 <span class="math inline">\(\displaystyle\bigcap_{1\leqslant i\leqslant m}U_i
\in \mathcal{T}\)</span>。</li>
</ul>
<p>第一个是定义，第二个也是定义。</p>
<p>第三个的话，取 <span class="math inline">\(x \in
\displaystyle\bigcap_{1\leqslant i\leqslant m}U_i\)</span>，有小球 <span class="math inline">\(B(x,\delta _i) \in
U_i\)</span>，则最小的一个开球在全体开集的交集中。由 <span class="math inline">\(x\)</span>
的任意性，用一下上一题的结论即证。</p></li>
<li><p><span class="math inline">\((X,d)\)</span> 是距离空间。如果 <span class="math inline">\(F\subset X\)</span> 的补集是开集，我们就称 <span class="math inline">\(F\)</span> 是闭集。证明，<span class="math inline">\(F\)</span> 是闭集当且仅当对任意点列 <span class="math inline">\(\{x_n\}_{n\geqslant 1}\in F\)</span>，如果 <span class="math inline">\(\displaystyle \lim_{n\rightarrow \infty}x_n =
x\)</span>，那么 <span class="math inline">\(x \in F\)</span>。</p>
<p>如果 <span class="math inline">\(F\)</span>
是闭集，且对于这样的序列有 <span class="math inline">\(x \notin
F\)</span>，则 <span class="math inline">\(x \in X-F\)</span>，也就是说
<span class="math inline">\(x\)</span> 在一个开集中，有一个包裹 <span class="math inline">\(x\)</span>
的小球也在开集中，所有这个序列里的点都和 <span class="math inline">\(x\)</span> 隔着小球半径的距离，不可能收敛到 <span class="math inline">\(x\)</span>，矛盾。</p>
<p>如果对任意的序列都有这样的结论，而且 <span class="math inline">\(F\)</span> 不是闭集，<span class="math inline">\(X-F\)</span> 不是开集，那么存在一个 <span class="math inline">\(x \in X-F\)</span> 使得对任意 <span class="math inline">\(\delta &gt;0\)</span>，都有 <span class="math inline">\(B(x,\delta)\)</span> 不完全在 <span class="math inline">\(X-F\)</span> 中。也就是说，对任意的 <span class="math inline">\(\delta &gt;0\)</span>，总存在 <span class="math inline">\(y \in F\)</span> 使得 <span class="math inline">\(d(x,y)&lt;\delta\)</span>。也就是说，存在一个
<span class="math inline">\(F\)</span> 中的收敛到 <span class="math inline">\(x\)</span> 的序列，使得 <span class="math inline">\(x \notin F\)</span>，这和前提矛盾。</p>
<blockquote>
<p>写逆命题也是一种技术，比如我差点以为一个集合不是开集就是闭集，这是不对的。</p>
<p>比如说在实数集上，有 <span class="math inline">\((1,2) \cup
(3,5]\)</span> 既不是开集也不是闭集。</p>
</blockquote></li>
<li><p>证明，距离空间 <span class="math inline">\((X,d)\)</span>
上的闭集，</p>
<ul>
<li><span class="math inline">\(\emptyset\)</span> 和 <span class="math inline">\(X\)</span> 都是闭集。</li>
<li>任意多闭集的交集还是闭集。</li>
<li>有限个闭集的并集还是闭集。</li>
</ul>
<p>这都是上上题的逆否，自然是成立的。</p></li>
<li><p>假设 <span class="math inline">\((X,d_X)\)</span> 和 <span class="math inline">\((Y,d_Y)\)</span> 是距离空间，<span class="math inline">\(f\colon X\rightarrow Y\)</span>
是映射。那么，如下三个叙述是等价的：</p>
<ul>
<li><span class="math inline">\(f\)</span> 是连续映射。</li>
<li>对任意 <span class="math inline">\(Y\)</span> 中的开集 <span class="math inline">\(U\)</span>，其逆像 <span class="math inline">\(f^{-1}(U)\)</span> 为 <span class="math inline">\(X\)</span> 中的开集。</li>
<li>对任意 <span class="math inline">\(Y\)</span> 中的闭集 <span class="math inline">\(F\)</span>，其逆像 <span class="math inline">\(f^{-1}(F)\)</span> 为 <span class="math inline">\(X\)</span> 中的闭集。</li>
</ul>
<p>我不想证明 <span class="math inline">\((1)\)</span> 和 <span class="math inline">\((3)\)</span> 之间的关系，所以验证 <span class="math inline">\((1) \to (2)\)</span>，<span class="math inline">\((2) \to (1)\)</span>，<span class="math inline">\((2) \iff (3)\)</span>。</p>
<p><span class="math inline">\((1) \to (2)\)</span>：如果 <span class="math inline">\(f\)</span> 是连续映射，<span class="math inline">\(U\)</span> 是开集，我们想证明对于任意的 <span class="math inline">\(x \in f^{-1}(U)\)</span>，有 <span class="math inline">\(x\)</span> 为中心的一个开球也在 <span class="math inline">\(f^{-1}(U)\)</span> 中。令 <span class="math inline">\(y=f(x)\)</span>，而 <span class="math inline">\(f\)</span> 是连续映射，所以在 <span class="math inline">\(x\)</span> 点也连续。于是对任意的 <span class="math inline">\(\varepsilon &gt;0\)</span>，存在 <span class="math inline">\(\delta\)</span> 使得对任意的 <span class="math inline">\(x&#39;\in B(x,\delta)\)</span>，有 <span class="math inline">\(d(f(x),f(x&#39;))&lt;\varepsilon\)</span>，也即
<span class="math inline">\(f(x&#39;) \in B(f(x),\varepsilon
)=B(y,\varepsilon)\)</span>。因此，只要取满足 <span class="math inline">\(B(y,\varepsilon) \subset U\)</span> 的 <span class="math inline">\(\varepsilon\)</span>，就能得到 <span class="math inline">\(B(x,\delta) \subset f^{-1}(U)\)</span>。于是 <span class="math inline">\(f^{-1}(U)\)</span> 也是开集，得证。</p>
<p><span class="math inline">\((2) \iff (3)\)</span>：只要证明 <span class="math inline">\(f^{-1}(F) \subset X-f^{-1}(X-F)\)</span>，还有
<span class="math inline">\(f^{-1}(U) \subset
X-f^{-1}(X-U)\)</span>，trivial.</p>
<p><span class="math inline">\((2) \to
(1)\)</span>​：现在假设对任意的开集 <span class="math inline">\(U\)</span>，<span class="math inline">\(f^{-1}(U)\)</span> 是开集，我们来证明 <span class="math inline">\(f\)</span> 是连续的：给定 <span class="math inline">\(x_0\in \mathbb R\)</span>，令 <span class="math inline">\(y_0=f(x_0)\)</span>，考虑 <span class="math inline">\(y_0\)</span> 处的开集 <span class="math inline">\(B(y_0,\delta)\)</span>。由于 <span class="math inline">\(f^{-1}\bigl(B(y_0,\delta)\bigr)\)</span> 为开集且
<span class="math inline">\(x_0\in
f^{-1}\bigl(B(y_0,\delta)\bigr)\)</span>，所以存在 <span class="math inline">\(\varepsilon &gt;0\)</span>，使得 <span class="math inline">\(B(x_0,\varepsilon)\subset
f^{-1}\bigl(B(y_0,\delta)\bigr)\)</span>，从而，<span class="math inline">\(f\bigl(B(x_0,\varepsilon)\bigr)\subset
B(y_0,\delta)\)</span>，这说明对任意的 <span class="math inline">\(\delta\)</span>，存在 <span class="math inline">\(\varepsilon\)</span>，使得当 $ d(x,x_0)&lt;$
时，我们有 <span class="math inline">\(d(f(x),f(x_0))&lt;\delta\)</span>，从而 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(x_0\)</span> 处连续。</p></li>
<li><p><span class="math inline">\((X,d)\)</span> 是距离空间，<span class="math inline">\(A\subset X\)</span> 是子集，我们将包含 <span class="math inline">\(A\)</span> 的所有闭集交 <span class="math inline">\(\overline{A}\)</span> 为 <span class="math inline">\(A\)</span> 的闭包，根据上题，这是闭集，所以是包含
<span class="math inline">\(A\)</span> 的最小闭集。</p>
<p>对于 <span class="math inline">\(x\in X\)</span>，如果存在点列 <span class="math inline">\(\{a_k\}_{k\geqslant 1}\subset A\)</span>，使得
<span class="math inline">\(\displaystyle \lim_{k\rightarrow \infty}a_k
= x\)</span>，并且其中 <span class="math inline">\(a_k\neq
x\)</span>，我们就称 <span class="math inline">\(x\)</span> 是 <span class="math inline">\(A\)</span> 的一个聚点。</p>
<p><span class="math inline">\(A\)</span> 的聚点不一定都在 <span class="math inline">\(A\)</span> 中，<span class="math inline">\(A\)</span> 中的点也不一定都是 <span class="math inline">\(A\)</span> 的聚点。<span class="math inline">\(A\)</span> 中不是 <span class="math inline">\(A\)</span> 的聚点的点被称为 <span class="math inline">\(A\)</span> 的孤立点。<span class="math inline">\(A\)</span> 的聚点组成的集合被称为 <span class="math inline">\(A\)</span> 的导集，记作 <span class="math inline">\(A&#39;\)</span>。如果 <span class="math inline">\(X=X&#39;\)</span>，我们称 <span class="math inline">\(X\)</span> 为完美集。</p>
<p>证明，<span class="math inline">\(\overline{A}=A&#39;\cup
A\)</span>。特别地，<span class="math inline">\(F\)</span>
是闭集当且仅当 <span class="math inline">\(F\)</span> 的聚点都在 <span class="math inline">\(F\)</span> 中，即 <span class="math inline">\(F=F&#39;\cup F=\overline{F}\)</span>。</p>
<p>首先证明闭包里包含所有聚点（包含 <span class="math inline">\(A\)</span> 是显然的）。如果有一个序列和它们的极限
<span class="math inline">\(x\)</span> 使得 <span class="math inline">\(x \neq x_n\)</span>，且 <span class="math inline">\(x \notin \bar{A}\)</span>，这和 <span class="math inline">\(\bar{A}\)</span> 是闭集矛盾。因此 <span class="math inline">\(\overline{A} \supset A&#39;\cup
A\)</span>（看起来好别扭</p>
<p>再证明闭包里所有的点要么在 <span class="math inline">\(A\)</span>
中，要么是聚点。如果有 <span class="math inline">\(x \in
\bar{A}\)</span> 且 <span class="math inline">\(x \notin
A\)</span>，我们要证明它是一个聚点，只要构造出一个收敛到 <span class="math inline">\(x\)</span> 的 <span class="math inline">\(A\)</span> 中序列。实际上，对任意的 <span class="math inline">\(\varepsilon &gt;0\)</span> 都存在 <span class="math inline">\(x&#39; \in A\)</span> 使得 <span class="math inline">\(d(x&#39;,x)&lt;\varepsilon\)</span>，也就是说
<span class="math inline">\(B(x,\varepsilon)\)</span> 始终和 <span class="math inline">\(A\)</span> 有交。否则存在某个 <span class="math inline">\(\varepsilon\)</span> 使得 <span class="math inline">\(A \cap B(x,\varepsilon) =
\emptyset\)</span>，那么一定有一个包含 <span class="math inline">\(A\)</span> 的闭集 <span class="math inline">\(S=X-B(x,\varepsilon)\)</span>，<span class="math inline">\(x \notin S\)</span>，这和 <span class="math inline">\(x \in \bar{A}\)</span> 矛盾。所以 <span class="math inline">\(x\)</span> 一定是一个聚点。</p>
<p>如果 <span class="math inline">\(A\)</span> 是闭集，那么 <span class="math inline">\(A=\bar{A}\)</span>，所以聚点一定都在 <span class="math inline">\(A\)</span> 中。</p></li>
<li><p>（距离空间的乘积与连续映射）假设 <span class="math inline">\((Y,d_Y)\)</span> 和 <span class="math inline">\((Z,d_Z)\)</span> 是距离空间，我们定义 <span class="math inline">\(Y\times Z\)</span> 上的距离函数</p>
<p><span class="math inline">\(d_{Y\times Z}\colon \bigl(Y\times
Z\bigr){ \times} \bigl(Y\times Z\bigr) \rightarrow \mathbb R_{\geqslant
0}, \ \ \bigl((y_1,z_1),(y_2,z_2)\bigr)\mapsto
\sqrt{d(y_1,y_2)^2+d(z_1,z_2)^2}\)</span></p>
<p>证明，<span class="math inline">\(d_{Y\times Z}\)</span> 是 <span class="math inline">\(Y\times Z\)</span>
上的距离函数。证明，两个自然的投影映射是连续的：</p>
<p><span class="math inline">\(\pi_Y\colon Y\times Z \rightarrow Y, \
(y,z)\mapsto y; \ \pi_Z\colon Y\times Z \rightarrow Z, \ (y,z)\mapsto
z\)</span></p>
<p>证明，给定距离空间 <span class="math inline">\((X,d)\)</span> 和
<span class="math inline">\((Y\times Z,d_{Y\times Z})\)</span>
之间的映射 <span class="math inline">\(F\colon X\rightarrow Y\times
Z\)</span>，那么，<span class="math inline">\(F\)</span>
连续当且仅当两个复合映射 <span class="math inline">\(\pi_Y \circ F\colon
X\rightarrow Y\)</span> 和 <span class="math inline">\(\pi_Z \circ
F\colon X\rightarrow Z\)</span> 都连续。</p>
<p>其实都挺 trivial 的。</p></li>
<li><p>证明，加法映射 <span class="math inline">\(+\)</span> 和乘法映射
<span class="math inline">\(\times\)</span> 都是连续映射，其中</p>
<p><span class="math inline">\(+\colon \mathbb R^2\rightarrow \mathbb R,
\ \ (x,y)\mapsto x+y; \ \ \ \ \times \colon \mathbb R^2\rightarrow
\mathbb R, \ \ (x,y)\mapsto x\cdot y\)</span></p>
<p>Trivial.</p></li>
<li><p>证明，矩阵上的加法映射 <span class="math inline">\(+\)</span>
和乘法映射 <span class="math inline">\(\bullet\)</span>
都是连续映射，其中</p>
<p><span class="math inline">\(+\colon \mathbf{M}_n(\mathbb R)\times
\mathbf{M}_n(\mathbb R)\rightarrow \mathbf{M}_n(\mathbb R), \ \
(A,B)\mapsto A+B;\ \ \ \ \bullet\colon \mathbf{M}_n(\mathbb R)\times
\mathbf{M}_n(\mathbb R)\rightarrow \mathbf{M}_n(\mathbb R), \ \
(A,B)\mapsto A\cdot B\)</span></p>
<p>定义距离为 <span class="math inline">\(d(A,B) =
||A-B||_F\)</span>（Frobenius
范数），然后就可以用相容性的不等式了，trivial.</p></li>
<li><p>证明，<span class="math inline">\(\mathbf{M}_n(\mathbb
R)\)</span> 上的可逆矩阵的全体 <span class="math inline">\(\mathbf{GL}_n(\mathbb R)\)</span> 是 <span class="math inline">\(\mathbf{M}_n(\mathbb R)\)</span>
中的开集。（提示：构造一个连续映射使得该集合是连续映射的逆像）</p>
<p>做连续映射（行列式）<span class="math inline">\(det: \mathbb R^{n
\times n} \to \mathbb R\)</span>，<span class="math inline">\(A \to
det(A)\)</span>，于是 <span class="math inline">\(det^{-1} ((-\infty,0)
\cup (0,\infty)) = GL_n(\mathbb R)\)</span> 是开集。</p>
<p>至于行列式运算为什么是连续的，因为它本质上是关于 <span class="math inline">\(n^2\)</span>
个变量的多项式（，所以关于各个分量连续。</p>
<p>我胡说八道的啊，我觉得我好像有必要补一补高代（</p></li>
<li><p>证明，取逆映射 <span class="math inline">\({\rm Inv}\colon
\mathbf{GL}_n(\mathbb R)\rightarrow \mathbf{GL}_n(\mathbb R), \ \
A\mapsto A^{-1}\)</span> 是连续映射。</p>
<p>记任意可逆矩阵集 <span class="math inline">\(U\)</span> 的原像为
<span class="math inline">\(Inv^{-1} U\)</span>，它是 <span class="math inline">\(GL_n (\mathbb R)\)</span>
的子集，也是一个开集。所以 <span class="math inline">\(Inv\)</span>
是连续映射。</p>
<p>看到这个 <span class="math inline">\(Inv\)</span> 我还以为要联动
Galois 理论了，吓一跳。</p></li>
</ul>
<h3 id="函数的零点">函数的零点</h3>
<p>其实一共有八道题，但另外七个都很
trivial，这个没有一眼看出来，所以还是写一写。</p>
<ul>
<li><p><span class="math inline">\(f\colon \mathbb R\rightarrow \mathbb
R\)</span> 是函数，对 <span class="math inline">\(c\in \mathbb
R\)</span>，我们定义 <span class="math inline">\(f^{-1}(c)=\{x\in
\mathbb R\mid f(x)=c\}\)</span>。证明，如果对任意 <span class="math inline">\(c\in \mathbb R\)</span>，我们都有 <span class="math inline">\(|f^{-1}(c)|=2\)</span>，那么 <span class="math inline">\(f\)</span> 不是连续函数。</p>
<p>说明任意取一个开集 <span class="math inline">\(U \subset
R\)</span>，都有 <span class="math inline">\(f^{-1}(U) = \lbrace 2
\rbrace\)</span> 或 <span class="math inline">\(\lbrace -2
\rbrace\)</span> 或 <span class="math inline">\(\lbrace 2,-2
\rbrace\)</span>，都不是开集，所以 <span class="math inline">\(f\)</span> 不连续。</p>
<p>给我一点小小的拓扑震撼（</p>
<p>貌似也可以用介值定理，就随便讨论一下，夹几个区间出来就行，但是没必要。</p></li>
</ul>
<h3 id="思考题">*思考题</h3>
<ul>
<li><p>假设 <span class="math inline">\(A\subset \mathbb R\)</span>
是一个可数集。证明，存在单调函数 <span class="math inline">\(f\colon
\mathbb R\rightarrow \mathbb R\)</span>，使得 <span class="math inline">\(f\)</span> 的不连续点的集合恰好是 <span class="math inline">\(A\)</span>。</p>
<p>大概可以分段构造 <span class="math inline">\(f(x)=x+T_i,x \in
(x_i,x_{i+1})\)</span>，来保证是单调增函数且不连续。</p></li>
<li><p>函数 <span class="math inline">\(f\colon [0,1]\rightarrow
[0,1]\)</span> 是递增的函数，证明，<span class="math inline">\(f\)</span> 有不动点。</p>
<p>考虑 <span class="math inline">\(F(x)=f(x)-x\)</span>，一定有不动点。</p></li>
<li><p>考虑 <span class="math inline">\([0,1]\)</span>
到自身的自同胚，即 <span class="math inline">\({\rm
Homeo}([0,1])=\bigl\{f\colon [0,1]\rightarrow [0,1]\bigm| \text{$f$
为连续的双射}\bigr\}\)</span></p>
<p>我们知道对于任意的 <span class="math inline">\(f\in {\rm
Homeo}([0,1])\)</span>，<span class="math inline">\(f^{-1}\in {\rm
Homeo}([0,1])\)</span>。假设 <span class="math inline">\(f\in {\rm
Homeo}([0,1])\)</span> 并且 <span class="math inline">\(0\)</span> 和
<span class="math inline">\(1\)</span> 是它仅有的不动点，<span class="math inline">\(g\in {\rm Homeo}([0,1])\)</span> 并且 <span class="math inline">\(0\)</span> 和 <span class="math inline">\(1\)</span> 也是它仅有的不动点，证明，存在 <span class="math inline">\(h\in {\rm Homeo}([0,1])\)</span>，使得 <span class="math inline">\(h^{-1}\circ f\circ h =g\)</span>。</p></li>
</ul>
<h1 id="一致连续性">一致连续性</h1>
<p>2023 年 1 月 29
日，星期日，我觉得凡是带有“一致”的东西都蛮恐怖的，比如 UMVUE（</p>
<p>惭愧地说，一致连续性其实我以前没有学会过，因为考试不考（。再来一遍.jpg</p>
<p>草，我之前把数分分成 I 和 II
都觉得挺奇怪的，但目前已经三万多字了，Typora
开始有点卡了（。所以这次又分别分了上下，暂且以期中考试为界吧。</p>
<h2 id="紧性与开覆盖">紧性与开覆盖</h2>
<p>是没接触过的很新的东西（，我怀疑这也不是数分内容，全在抄。好像也没抄会。</p>
<h2 id="一致连续性-1">一致连续性</h2>
<ul>
<li><p>假设 <span class="math inline">\(f\colon X\rightarrow \mathbb
R\)</span> 是连续函数，如果对任意的 <span class="math inline">\(\varepsilon&gt;0\)</span>，存在 <span class="math inline">\(\delta&gt;0\)</span>，使得对任意的 <span class="math inline">\(x,y\in X\)</span>，只要 <span class="math inline">\(d(x,y)&lt;\delta\)</span>，就有 <span class="math inline">\(|f(x)-f(y)|&lt;\varepsilon\)</span>，就称 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(X\)</span> 上一致连续。</p>
<p>看起来很像 Lipschitz 条件，不过 Lipschitz
条件其实是特化版的，是一致连续的充分条件，用来解决一些不动点问题。</p></li>
<li><p>有界闭区间上的连续函数一定一致连续。</p></li>
<li><p>一致收敛和逐点收敛的区别实际上是关于点 <span class="math inline">\(x\)</span> 的差别，对 <span class="math inline">\(N\)</span> 的依赖进行区分即可。对于一个函数序列
<span class="math inline">\(\lbrace f_n : X \to R \rbrace\)</span>
和函数 <span class="math inline">\(f: X \to R\)</span>，有：</p>
<p>逐点收敛是指，对任意的 <span class="math inline">\(x \in
X\)</span>，任意 <span class="math inline">\(\varepsilon
&gt;0\)</span>，存在 <span class="math inline">\(N=N(\varepsilon ,
x)\)</span> 使得当 <span class="math inline">\(n &gt;N\)</span>
时，<span class="math inline">\(| f_n(x) - f(x) | &lt;
\varepsilon\)</span>。</p>
<p>一致收敛是指，对任意的 <span class="math inline">\(\varepsilon
&gt;0\)</span>，存在 <span class="math inline">\(N=N(\varepsilon)\)</span> 使得对任意的 <span class="math inline">\(x \in X\)</span>，有 <span class="math inline">\(|f_n(x) - f(x) | &lt;\varepsilon\)</span>，也就是
<span class="math inline">\(\sup_{x \in X} | f_n(x) - f(x) |
&lt;\varepsilon\)</span>。</p>
<p>这样来看的话，显然有一致收敛能够推出逐点收敛，逐点收敛能推出一致收敛的要求是固定
<span class="math inline">\(\varepsilon\)</span> 时存在 <span class="math inline">\(N\)</span> 的上确界 <span class="math inline">\(\sup _{x \in X}N(\varepsilon ,
x)\)</span>，这个上确界不能是无穷。但 <span class="math inline">\(X\)</span> 的形式不能在任意条件下保证这一点。</p>
<p>从计算的角度来看，逐点收敛到的函数相当于固定 <span class="math inline">\(x\)</span>，取 <span class="math inline">\(n \to
\infty\)</span>，可以由此继续判断是否一致收敛到逐点收敛的函数。</p></li>
</ul>
<h2 id="级数收敛构造连续函数">级数收敛构造连续函数</h2>
<p>本质上是把绝对值推广成函数的无穷范数，用来证明收敛。</p>
<h2 id="梦话证明题但胡说八道">梦话：证明题，但胡说八道</h2>
<h3 id="连续一致连续和一致收敛">连续，一致连续和一致收敛</h3>
<ul>
<li><p>证明，函数 <span class="math inline">\(e^x\)</span> 在 <span class="math inline">\(\mathbb R\)</span> 上不是一致连续的而在 <span class="math inline">\((-\infty,0]\)</span> 上是一致连续的。</p>
<p>Trivial.</p></li>
<li><p>证明，幂函数映射 <span class="math inline">\(\mathbb
R_{&gt;0}\times \mathbb R, \ \ (x,\alpha)\mapsto x^\alpha\)</span> 是
<span class="math inline">\(\mathbb R_{&gt;0}\times \mathbb R\)</span>
上的连续函数。</p>
<p>因为 <span class="math inline">\(x^\alpha = e^{\alpha \ln
x}\)</span>，且 <span class="math inline">\(\mathbb R_{&gt;0}\times
\mathbb R \to \mathbb R\)</span>，<span class="math inline">\((x,\alpha)
\to \alpha \ln x\)</span> 连续，<span class="math inline">\(\mathbb R
\to \mathbb R\)</span>，<span class="math inline">\(x \to e^x\)</span>
也连续。</p>
<p>二者的叠加（？？这个叫什么来着啊）也是连续函数，而且是 <span class="math inline">\(\mathbb R_{&gt;0}\times \mathbb R \to \mathbb
R\)</span> 的连续函数。</p></li>
<li><p>证明，第九次课中定义的幂函数满足如下的性质：对任意 <span class="math inline">\(x,y&gt;0\)</span> 和 <span class="math inline">\(\alpha, \beta\)</span>，我们有 <span class="math inline">\((xy)^\alpha=x^\alpha y^\alpha\)</span>，<span class="math inline">\((x^\alpha)^\beta=x^{\alpha \beta}\)</span>； <span class="math inline">\(a^{\log_a x} =x\)</span>；如果 <span class="math inline">\(x&gt;0\)</span>，<span class="math inline">\(y&gt;0\)</span>，那么 <span class="math inline">\(a^{x+y}=a^x a^y\)</span>，<span class="math inline">\(\log_a(x\cdot
y)=\log_a(x)+\log_a(y)\)</span>。</p>
<p><span class="math inline">\((xy) ^\alpha = e^{\alpha \ln xy} =
e^{\alpha (\ln x+\ln y)} = e^{\alpha \ln x}e^{\alpha \ln y} = x^\alpha
y^\alpha\)</span>。</p>
<p>类似地证明其他几个式子，总之一些 trivial 的性质对于 <span class="math inline">\(e^x\)</span> 和 <span class="math inline">\(\ln
x\)</span> 成立，只要努力代入就可以了。</p></li>
<li><p>在 <span class="math inline">\([0,1)\)</span>
区间上考虑连续函数的序列 <span class="math inline">\(\{f_n(x)\}_{n\geqslant 1}\)</span>，其中 <span class="math inline">\(f_n(x)=x^n\)</span>。证明，对任意的 <span class="math inline">\(a&lt;1\)</span>，<span class="math inline">\(\{f_n(x)\}_{n\geqslant 1}\)</span> 在 <span class="math inline">\([0,a]\)</span> 上一致收敛到 <span class="math inline">\(0\)</span> 这个函数；但是 <span class="math inline">\(\{f_n(x)\}_{n\geqslant 1}\)</span> 在 <span class="math inline">\([0,1)\)</span> 上不一致收敛。</p>
<p>连续函数列在闭区间上有一致控制：<span class="math inline">\(\sup_{x
\in X} | f_n(x) - f(x) | = a^n &lt;\varepsilon\)</span>，只要取 <span class="math inline">\(N &gt; \log _a \varepsilon\)</span>
即可，于是一致收敛。</p>
<p>在 <span class="math inline">\([0,1)\)</span> 上也还是逐点收敛到
<span class="math inline">\(f=0\)</span> 的，只要证明不一致收敛到 <span class="math inline">\(f=0\)</span> 即可。实际上有 <span class="math inline">\(\sup_{x \in X} | f_n(x) - f(x) | =
1\)</span>。</p></li>
<li><p>在 <span class="math inline">\(\mathbb R\)</span>
上考虑连续函数的序列 <span class="math inline">\(\{f_n(x)\}_{n\geqslant
1}\)</span>，其中 <span class="math inline">\(f_n(x)=\dfrac{nx}{1+n^2x^2}\)</span>。证明，<span class="math inline">\(\{f_n(x)\}_{n\geqslant 1}\)</span> 在 <span class="math inline">\(\mathbb R\)</span> 上逐点收敛到 <span class="math inline">\(0\)</span> 这个函数但是 <span class="math inline">\(\{f_n(x)\}_{n\geqslant 1}\)</span> 在 <span class="math inline">\(\mathbb R\)</span> 上不一致收敛。</p>
<p>逐点收敛只要对 <span class="math inline">\(n \to \infty\)</span>
即可，是收敛到 <span class="math inline">\(f=0\)</span> 的。</p>
<p>考虑一致收敛的问题，$<em>{x X} | f_n(x) - f(x) | = </em>{x X} | { nx
+{ 1 nx}}| = 2 $，并不会一致收敛。</p></li>
<li><p>在 <span class="math inline">\(\mathbb R\)</span>
上考虑连续函数的序列 <span class="math inline">\(\{f_n(x)\}_{n\geqslant
1}\)</span>，其中 <span class="math inline">\(f_n(x)=\begin{cases}\dfrac{nx^2}{1+nx}, \
&amp;x&gt;0;\\&amp; \\\dfrac{nx^3}{1+nx^2}, \ &amp;x\leqslant
0\end{cases}\)</span>.</p>
<p>试研究 <span class="math inline">\(\{f_n(x)\}_{n\geqslant 1}\)</span>
在 <span class="math inline">\(\mathbb R\)</span>
上逐点收敛性和一致收敛性。</p>
<p>逐点收敛到 <span class="math inline">\(f=x\)</span>，有手就行（，以下考虑一致收敛性。</p>
<p>对于 <span class="math inline">\(x &gt;0\)</span>，有 <span class="math inline">\(\sup_{x \in X} | f_n(x) - f(x) | = \sup_{x \in X}
|\frac{x}{1+nx}|&lt;\frac 1 n &lt; \varepsilon\)</span> 可以在 <span class="math inline">\(N &gt;\frac 1 \varepsilon\)</span> 时做到。</p>
<p>对于 <span class="math inline">\(x \leq 0\)</span>，有 <span class="math inline">\(\sup_{x \in X} | f_n(x) - f(x) | = \sup_{x \in X}
|\frac{x}{1+nx^2 }|&lt;\frac{1}{2 \sqrt{n} } &lt;
\varepsilon\)</span>，可以在 <span class="math inline">\(N&gt;
\frac{1}{4\varepsilon^2}\)</span> 时做到。</p>
<p>所以取 <span class="math inline">\(N =[ \max \lbrace \frac 1
\varepsilon , \frac{1}{4\varepsilon^2} \rbrace ] +1\)</span>
即有一致收敛。</p></li>
<li><p>给定连续函数 <span class="math inline">\(\varphi\colon \mathbb
R_{\geqslant 0}\rightarrow \mathbb R\)</span>，满足 <span class="math inline">\(\varphi(0)=0\)</span>，<span class="math inline">\(\displaystyle \lim_{x\rightarrow
\infty}\varphi(x)=0\)</span> 并且 <span class="math inline">\(\varphi\)</span> 不恒为零。证明，<span class="math inline">\(\mathbb R_{\geqslant 0}\)</span>
上的连续函数的序列 <span class="math inline">\(\{f_n(x)\}_{n\geqslant
1}\)</span> 和 <span class="math inline">\(\{g_n(x)\}_{n\geqslant
1}\)</span> 逐点收敛到 <span class="math inline">\(0\)</span>
这个函数但是不一致收敛，其中 <span class="math inline">\(f_n(x)=\varphi(nx)\)</span>，<span class="math inline">\(g_n(x)=\varphi\left(\dfrac{x}{n}\right)\)</span>。</p>
<p>Trivial.</p></li>
<li><p>（一致连续性的应用：积分的定义）<span class="math inline">\([a,b]\)</span> 是有限闭区间，<span class="math inline">\(f\in C\bigl([a,b]\bigr)\)</span>
是实数值的函数。给定 <span class="math inline">\(n\geqslant
1\)</span>，我们将 <span class="math inline">\([a,b]\)</span> 均分为
<span class="math inline">\(n\)</span> 份：<span class="math inline">\([[a,b]=[a_1,b_1]\cup [a_2,b_2]\cup \cdots \cup
[a_n,b_n], \ \ a_1=a, b_k=a_{k+1}~(k=1,\cdots, n-1),
b_n=b\)</span>，</p>
<p>其中对于 <span class="math inline">\(k=1,2,\cdots,n\)</span>，<span class="math inline">\(a_k=a+\dfrac{k-1}{n}(b-a)\)</span>。我们定义 <span class="math inline">\(S_n=\sum_{k=1}^n \frac{b-a}{n}f(a_k)\)</span></p>
<p>证明，<span class="math inline">\(\{S_n\}_{n\geqslant 1}\)</span>
收敛，我们用 $_{a}^b f $ 这个符号来记极限 <span class="math inline">\(\displaystyle \lim_{n\rightarrow
\infty}S_n\)</span>。进一步证明，映射</p>
<p>$<em>{a}^bC([a,b])R,   f</em>{a}^b f $ 是线性映射,并且如果我们在
<span class="math inline">\(C\bigl([a,b]\bigr)\)</span> 用距离函数 <span class="math inline">\(d_\infty\)</span> 来考虑，那么这是连续映射。</p>
<p>（提示：为了证明 <span class="math inline">\(\{S_n\}_{n\geqslant
1}\)</span> 是Cauchy列，我们可以将 <span class="math inline">\(S_{n}\)</span> 和 <span class="math inline">\(S_m\)</span> 都与 <span class="math inline">\(S_{nm}\)</span> 做比较）</p>
<p>考虑部分和序列收敛。是因为 <span class="math inline">\(f\)</span>
在闭区间 <span class="math inline">\([a,b]\)</span>
上有最大值和最小值，于是 <span class="math inline">\((b-a)s \leq S_n
\leq (b-a)S\)</span>。比较 <span class="math inline">\(S_m\)</span> 和
<span class="math inline">\(S_{nm}\)</span>
能比出来什么呢...？作差用中值定理的话，二者的差可以控制在 <span class="math inline">\([\frac{n-1}{2mn} s,\frac{n-1}{2mn} S]\)</span>
之间，确实可以控制在 <span class="math inline">\(\varepsilon\)</span>
之内。但是只用 <span class="math inline">\(S_m\)</span> 和 <span class="math inline">\(S_{mn}\)</span> 做比较就可以得到是 Cauchy
列的结论吗？</p>
<p>线性映射是因为 <span class="math inline">\(f + g \to \int_{a}^b
f+g\)</span>，有 <span class="math inline">\(\int_{a}^b f+g
=\displaystyle \lim_{n\rightarrow \infty}(S_n+T_n)= \displaystyle
\lim_{n\rightarrow \infty}S_n + \displaystyle \lim_{n\rightarrow
\infty}T_n = \int_{a}^b f +\int_{a}^b g\)</span>。</p>
<p>回顾一下距离函数是 <span class="math inline">\(d_\infty (f,g) =
\sup_{x \in X} |f(x)-g(x)|\)</span>，想证明映射 <span class="math inline">\(\int_{a}^b\colon C\bigl([a,b]\bigr)\rightarrow
\mathbb R\)</span> 是连续映射，只要证明对任意的 <span class="math inline">\(\varepsilon &gt;0\)</span>，存在 <span class="math inline">\(\delta\)</span> 使得 <span class="math inline">\(d_\infty (f,g) &lt; \delta\)</span> 时有 <span class="math inline">\(|\int_{a}^b f - \int_{a}^b
g|&lt;\varepsilon\)</span>。</p>
<p>由于这个映射是线性的，我们知道 <span class="math inline">\(|\int_{a}^b f - \int_{a}^b g| = |\int_{a}^b (f-g)|
&lt; |\int_{a}^b d_{\infty}(f,g) | =
(b-a)d_{\infty}(f,g)\)</span>，因此只要取 <span class="math inline">\(\delta = \frac {\varepsilon} {(b-a)}\)</span>
就能够满足要求。因此这个映射是连续的。</p></li>
<li><p>证明Cauchy的一个定理: 任给函数 <span class="math inline">\(f\colon [a,+\infty) \to
\mathbb{R}\)</span>，我们假设 <span class="math inline">\(f\)</span>
任意闭子区间 <span class="math inline">\([a,b]\)</span> 上有界
(上界可能依赖于 <span class="math inline">\(b\)</span>)，
那么下面两个式子当等号右边极限存在时成立：</p>
<p><span class="math inline">\(\lim_{x \to +\infty} \frac{f(x)}{x} =
\lim_{x \to + \infty} [f(x+1) - f(x)],\\\lim_{x \to + \infty}
[f(x)]^{1/x} = \lim_{x \to + \infty} \frac{f(x+1)}{f(x)}, \ \
\text{进一步假设对任意的 $x \in [a,\infty)$，$f(x) \geqslant c &gt;
0$}\)</span></p>
<p>首先，给下面的式子取个对数就能得到上面的式子，所以只要证明上面的式子。</p>
<p>记 <span class="math inline">\(A = \lim_{x \to + \infty} [f(x+1) -
f(x)]\)</span>，于是对任意 <span class="math inline">\(\varepsilon
&gt;0\)</span>，存在 <span class="math inline">\(N \in \mathbb
Z^+\)</span> 使得 <span class="math inline">\(x &gt;N\)</span>
时都有：</p>
<p><span class="math inline">\(A-\varepsilon &lt; f(x+1) - f(x) &lt;
A+\varepsilon\)</span> 成立。</p>
<p>因此 <span class="math inline">\(f(y) = (f(y)-f(y-1)) +
(f(y-1)-f(y-2))+ ... +( f(n+1)-f(n)) +f(n)\)</span>，其中 <span class="math inline">\(n = N\)</span>，再做 <span class="math inline">\(\frac{f(y)}{y}\)</span>
取极限即得到结论。</p></li>
</ul>
<h3 id="和一致连续性相关的问题">和一致连续性相关的问题</h3>
<ul>
<li><p>如果连续函数 <span class="math inline">\(f\)</span>
在开区间（有限或无限）<span class="math inline">\(I \subset
\mathbb{R}\)</span> 上是单调并且有界的，那么 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(I\)</span> 上一致连续。</p>
<p>Trivial.</p></li>
<li><p><span class="math inline">\(I\)</span>
是长度有限的区间（不一定是闭的）。 证明，<span class="math inline">\(I\)</span> 上的实值函数 <span class="math inline">\(f\)</span> 一致连续的充分必要条件是 <span class="math inline">\(f\)</span> 把Cauchy列映成Cauchy列（即如果 <span class="math inline">\(\{x_n\}_{n \geqslant 1} \subset I\)</span>
是Cauchy列，那么 <span class="math inline">\(\{f(x_n) \}_{n \geqslant
1}\)</span> 也是Cauchy列）。</p>
<p>如果 <span class="math inline">\(f\)</span> 一致连续，由 Cauchy
列和一致连续的定义知道 <span class="math inline">\(\{f(x_n) \}_{n
\geqslant 1}\)</span> 也是 Cauchy 列。</p>
<p>如果映射到的点列也是 Cauchy 列，且 <span class="math inline">\(f\)</span> 不一致连续。那么存在一个 <span class="math inline">\(\varepsilon &gt;0\)</span>，使得对任意的 <span class="math inline">\(\delta\)</span>，都存在 <span class="math inline">\(x,y \in I\)</span> 满足 <span class="math inline">\(|x-y|&lt;\delta\)</span> 且
$|f(x)-f(y)|&gt;$。取一个和 <span class="math inline">\(\lbrace x_n
\rbrace\)</span> 相近的数列 <span class="math inline">\(\lbrace y_n
\rbrace\)</span>，满足 <span class="math inline">\(|x_n - y_n |&lt;
\frac 1 n\)</span> 而且 <span class="math inline">\(|f(x_n) - f(y_n)|
&gt;\varepsilon\)</span>，而且一定满足 <span class="math inline">\(\lbrace y_n \rbrace \subset I\)</span>。那么 <span class="math inline">\(\lbrace x_n \rbrace\)</span> 是收敛的 Cauchy
列，<span class="math inline">\(\lbrace y_n \rbrace\)</span>
也是收敛到同一点的 Cauchy 列。</p>
<p>取序列 <span class="math inline">\(x_1,y_1,x_2,y_2,...,\)</span>
也是一个 Cauchy 列，但它的映射并不是 Cauchy 列，矛盾。</p>
<p>不会做于是 MSE 了半天 qwq</p></li>
<li><p><span class="math inline">\(f\)</span> 在 <span class="math inline">\(\mathbb{R}\)</span> 上一致连续。证明，存在 <span class="math inline">\(a, b \in \mathbb{R}_{&gt;0}\)</span>，使得对任意的
<span class="math inline">\(x\in \mathbb R\)</span>，我们都有 <span class="math inline">\(|f(x)| \leqslant a |x| + b\)</span></p>
<p>取 <span class="math inline">\(b = |f(0)|\)</span>，对 <span class="math inline">\(\varepsilon = 1\)</span>，取一致连续定义中对应的
<span class="math inline">\(\delta\)</span>，于是 <span class="math inline">\(|x - 0| &lt;\delta\)</span> 时一定有 $ |f(x) -
f(0)|&lt;1$，可以得到 <span class="math inline">\(|f(x)| &lt; |f(0)| +1
= b+1\)</span>。</p>
<p>因此，对于任意的 <span class="math inline">\(x \in \mathbb
R_+\)</span>，有 <span class="math inline">\(|f(x) - f(x-\delta)| &lt;
1\)</span>，可以推出 <span class="math inline">\(|f(x) - f(0)| &lt;
([\frac{1}{\delta}]+1) |x|\)</span>。对于 <span class="math inline">\(x
\in R_-\)</span> 也可以得到类似的结论，于是只要取 <span class="math inline">\(b=|f(0)|\)</span>，<span class="math inline">\(a =
[\frac 1 \delta] +1\)</span>，原式成立。</p></li>
<li><p>假设函数 <span class="math inline">\(f\)</span> 在 <span class="math inline">\([0,\infty)\)</span> 上一致连续并且对任意的 <span class="math inline">\(x \in [0,1]\)</span>，我们都有 <span class="math inline">\(\displaystyle \lim_{n \rightarrow +\infty}f(x+n) =
0\)</span>（这里 <span class="math inline">\(n\)</span> 是整数）。
证明，<span class="math inline">\(\lim_{x \to +\infty}f(x) =
0\)</span>。如果我们将条件减弱为 <span class="math inline">\(f\)</span>
在 <span class="math inline">\([0,\infty)\)</span> 连续，
结论是否依然成立? 证明或举出反例。</p>
<p>如果有一致连续条件：</p>
<p>先取一个固定的 <span class="math inline">\(x\in [0,1]\)</span>
和一个固定的 <span class="math inline">\(\varepsilon
&gt;0\)</span>，存在一个 <span class="math inline">\(\delta =
\delta(\varepsilon)\)</span> 使得对任意的 <span class="math inline">\(|x-y|&lt;\delta\)</span>，有 <span class="math inline">\(|f(x)-f(y)|&lt;\varepsilon\)</span>。存在一个
<span class="math inline">\(N=N(x,\varepsilon)\)</span>，使得对任意的
<span class="math inline">\(n&gt;N\)</span>，有 <span class="math inline">\(|f(x+n)|&lt;\varepsilon\)</span>。我们先固定这个
<span class="math inline">\(n\)</span>。</p>
<p>对任意的 <span class="math inline">\(t \in [x+n,x+n+1]\)</span>，有
<span class="math inline">\(|x+n-t|&lt;p\delta\)</span>，于是 <span class="math inline">\(|f(t)-f(x+n)|&lt;p\varepsilon\)</span>，<span class="math inline">\(p = \frac{1}{\delta}\)</span>。于是有 <span class="math inline">\(|f(t)|&lt;(p+1)\varepsilon\)</span>。</p>
<p>把上述中的 <span class="math inline">\(n\)</span> 改成 <span class="math inline">\(n+1,n+2,...\)</span>，都有 <span class="math inline">\(|f(t)|&lt;(p+1)\varepsilon\)</span>。于是对任意的
<span class="math inline">\(y \in [x+n,+\infty)\)</span>，有 <span class="math inline">\(|f(y)|&lt;(p+1)\varepsilon\)</span>，也就是说
<span class="math inline">\(\lim_{x \to +\infty}f(x) = 0\)</span>。</p>
<p>如果没有一致连续条件，结论是不成立的。取 <span class="math inline">\(f(x) = \frac{xsin \pi x}{1+x^2 \sin^2 \pi
x}\)</span>，它没有极限吧？</p></li>
<li><p>假设 <span class="math inline">\(X\)</span> 是区间，<span class="math inline">\(f\colon X \rightarrow \mathbb{R}\)</span>
是连续函数。如果存在正常数 <span class="math inline">\(L\)</span>，使得对任意的 <span class="math inline">\(x, y \in X\)</span>，都有 <span class="math inline">\(|f(x) - f(y)| \leqslant L|x-y|\)</span>，我们就称
<span class="math inline">\(f\)</span> 在 <span class="math inline">\(X\)</span> 上满足Lipschitz条件。</p>
<ul>
<li><p>证明，<span class="math inline">\(f\)</span> 在 <span class="math inline">\(X\)</span> 上满足Lipschitz条件是 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(X\)</span> 一致连续的充分条件。</p>
<p>Trivial.</p></li>
<li><p>判断上述条件是否是必要条件? 证明或举出反例。</p>
<p>不是必要的，比如取 <span class="math inline">\(f(x) =
\sqrt{x}\)</span>，<span class="math inline">\(x \in [0,1]\)</span>
即有一致连续，但不满足 Lipschitz 条件。</p></li>
<li><p>假设 <span class="math inline">\(f\)</span> 在 <span class="math inline">\([a,+\infty)\)</span> 上满足Lipschitz条件，其中
<span class="math inline">\(a &gt; 0\)</span>，试证明 <span class="math inline">\(\dfrac{f(x)}{x}\)</span> 在 <span class="math inline">\([a,+\infty)\)</span> 一致连续。</p>
<p>取任意的 <span class="math inline">\(\delta \in \mathbb
R+\)</span>，考虑 <span class="math inline">\(x,y \in
[a,+\infty)\)</span> 且 <span class="math inline">\(|x-y|=\delta\)</span> 的情况。此时有 <span class="math inline">\(|f(x) - f(y)|\leq L\delta\)</span>，且 <span class="math inline">\(f(x)\)</span> 一致连续。于是 <span class="math inline">\(|\frac{f(x)}{x} - \frac{f(y)}{y}| &lt; |\frac{f(y)
\delta}{xy} |+|\frac{L\delta}{x}| &lt; (\frac{L+t}{a}+ \frac{b}{a^2})
\delta\)</span>，也满足 Lipschitz 条件，也一致连续。</p>
<p>上述的 <span class="math inline">\(t\)</span> 和 <span class="math inline">\(b\)</span> 是使得 <span class="math inline">\(|f(x)| \leq t|x| + b\)</span> 成立的值。</p>
<p>我超，好难（</p></li>
</ul></li>
</ul>
<h3 id="思考题-1">*思考题</h3>
<ul>
<li><p>连续函数 <span class="math inline">\(f\colon \mathbb R\rightarrow
\mathbb R\)</span> 满足如下性质：对任意的 <span class="math inline">\(\delta&gt;0\)</span>，我们都有 <span class="math inline">\(\displaystyle \lim_{n\rightarrow \infty}
f(n\delta)=0\)</span>，证明，<span class="math inline">\(\displaystyle
\lim_{x\rightarrow +\infty} f(x)=0\)</span>。</p>
<p>对任意的 <span class="math inline">\(\delta &gt;0\)</span>，<span class="math inline">\(\varepsilon &gt;0\)</span>，存在 <span class="math inline">\(N=N(\delta,\varepsilon)\)</span> 满足对任意的
<span class="math inline">\(n &gt;N\)</span>，有 <span class="math inline">\(|f(n \delta)| &lt;\varepsilon\)</span>。于是只要取
<span class="math inline">\(X= \sup \{\delta N(\delta ,
\varepsilon)\}\)</span>，就有 <span class="math inline">\(\forall x &gt;
X\)</span>，<span class="math inline">\(|f(x)|&lt;\varepsilon\)</span>。问题在于这个 <span class="math inline">\(X\)</span> 是否存在。</p>
<p>我们规定 <span class="math inline">\(\delta \in (0,1]\)</span>，于是
<span class="math inline">\(X &lt; \sup
\{N(\delta,\varepsilon)\}\)</span>，其中 <span class="math inline">\(\delta \in (0,1]\)</span> 且 <span class="math inline">\(\varepsilon\)</span> 固定。</p></li>
<li><p>连续函数 <span class="math inline">\(\varphi\colon \mathbb
R\rightarrow \mathbb R\)</span> 满足如下两个性质：</p>
<ul>
<li><p>它在无穷远的行为如下：<span class="math inline">\(\displaystyle
\lim_{x\rightarrow +\infty}\bigl(
\varphi(x)-x\bigr)=+\infty\)</span>。</p></li>
<li><p><span class="math inline">\(\varphi\)</span> 的不动点集 <span class="math inline">\(\bigl\{x\in \mathbb R\bigm|
\varphi(x)=x\bigr\}\)</span> 是非空的有限集。</p></li>
</ul>
<p>证明，如果 <span class="math inline">\(f\colon \mathbb R\rightarrow
\mathbb R\)</span> 是连续函数并且满足 <span class="math inline">\(f\circ
\varphi =f\)</span>，那么 <span class="math inline">\(f\)</span>
一定是常值函数。</p>
<p>对于 <span class="math inline">\(\forall M&gt;0\)</span>，存在 <span class="math inline">\(N &gt;0\)</span>，满足 <span class="math inline">\(x &gt; N\)</span> 时一定有 <span class="math inline">\(\varphi(x) - x &gt;M\)</span>。</p>
<p>？.jpg</p></li>
<li><p>连续函数 <span class="math inline">\(f\colon \mathbb R_{\geqslant
0}\rightarrow \mathbb R\)</span> 满足 <span class="math inline">\(\displaystyle \lim_{x\rightarrow +\infty}
\frac{f(x)}{x}=0\)</span>。假设 <span class="math inline">\(\{a_n\}_{n\geqslant 1}\)</span>
是一列非负实数的数列并且数列 <span class="math inline">\(\{\dfrac{a_n}{n}\}_{n\geqslant 1}\)</span>
是有界的，证明，<span class="math inline">\(\displaystyle
\lim_{n\rightarrow \infty} \frac{f(a_n)}{n}=0\)</span></p>
<p>对任意 <span class="math inline">\(\varepsilon &gt;0\)</span>，存在
<span class="math inline">\(M\)</span> 使得 <span class="math inline">\(x&gt;M\)</span> 时总有 <span class="math inline">\(|f(x)|&lt;\varepsilon x\)</span>。</p>
<p>如果数列 <span class="math inline">\(\lbrace a_n \rbrace\)</span>
无界，则取 <span class="math inline">\(N = \sup \lbrace |\frac{a_n}{n}|
\rbrace\)</span>，<span class="math inline">\(|\frac{f(a_n)}{n}| =
|\frac{f(a_n)}{a_n}| |\frac{a_n}{n}|\leq N |\frac{f(a_n)}{a_n}| \leq
N\varepsilon\)</span>，或有 <span class="math inline">\(|\frac{f(a_n)}{n}| &lt;|\frac{\sup |f([0,K])|}{n}|
\to 0\)</span>。</p>
<p>如果数列 <span class="math inline">\(\lbrace a_n \rbrace\)</span>
有界，则显然有 <span class="math inline">\(|\frac{f(a_n)}{n}|
&lt;|\frac{\sup |f([\inf a_n,\sup a_n])|}{n}| \to 0\)</span>。</p></li>
</ul>
<h3 id="娱乐问题素数是无限多的拓扑证明-furstenberg-1955">*娱乐问题：素数是无限多的拓扑证明
(Furstenberg, 1955)</h3>
<p><span class="math inline">\(X\)</span> 是集合，<span class="math inline">\(\mathcal{T}=\{U\mid U\subset X\}\)</span> 是 <span class="math inline">\(X\)</span>
的某些子集所组成的集合。如果下面三个条件成立</p>
<ul>
<li><p><span class="math inline">\(\emptyset \in \mathcal{T}\)</span>，
<span class="math inline">\(X \in \mathcal{T}\)</span>。</p></li>
<li><p>对任意的 <span class="math inline">\(\{U_{\alpha}\}_{\alpha \in
\mathcal{A}}\subset \mathcal{T}\)</span>，其中 <span class="math inline">\(\mathcal{A}\)</span> 为指标集合，我们有 <span class="math inline">\(\displaystyle\bigcup_{\alpha \in
\mathcal{A}}U_\alpha \in \mathcal{T}\)</span>。</p></li>
<li><p>对任意有限个 <span class="math inline">\(U_1,U_2,\cdots, U_m \in
\mathcal{T}\)</span>，我们有 <span class="math inline">\(\displaystyle\bigcap_{1\leqslant i\leqslant m}U_i
\in \mathcal{T}\)</span>。</p></li>
</ul>
<p>我们就称 <span class="math inline">\(\mathcal{T}\)</span> 是 <span class="math inline">\(X\)</span> 上的一个拓扑，每个 <span class="math inline">\(U\in \mathcal{T}\)</span> 都被称作是（拓扑 <span class="math inline">\(\mathcal{T}\)</span> 下的）开集。我们把二元组
<span class="math inline">\((X,\mathcal{T})\)</span>
称作是一个拓扑空间。</p>
<p>假设 <span class="math inline">\((X&#39;,\mathcal{T}&#39;)\)</span>
是拓扑空间，<span class="math inline">\(f\colon X\rightarrow
X&#39;\)</span>，如果对每个 <span class="math inline">\(U&#39;\in
\mathcal{T}&#39;\)</span>，我们有 <span class="math inline">\(f^{-1}(U&#39;)\in \mathcal{T}\)</span>，我们就称
<span class="math inline">\(f\)</span> 是连续映射。</p>
<p>给定拓扑空间 <span class="math inline">\((X,\mathcal{T})\)</span>，考虑子集 <span class="math inline">\(F\subset X\)</span>，如果其补集 <span class="math inline">\(X-F\)</span> 是开集（即 <span class="math inline">\(X-F\in \mathcal{T}\)</span>），我们就称 <span class="math inline">\(F\)</span> 是在拓扑 <span class="math inline">\(\mathcal{T}\)</span>
下的）闭集。对于闭集，我们有如下的性质：</p>
<ul>
<li><p><span class="math inline">\(\emptyset\)</span> 和 <span class="math inline">\(X\)</span> 都是闭集。</p></li>
<li><p>任意多闭集的交集是闭集。</p></li>
<li><p>有限个闭集的并集是闭集。</p></li>
</ul>
<p>娱乐问题：素数是无限多的拓扑证明（Furstenberg，1955）</p>
<p>考虑 <span class="math inline">\(X=\mathbb{Z}\)</span>
为全体整数的集合，对于 <span class="math inline">\(a,b \in
\mathbb{Z}\)</span>，其中 <span class="math inline">\(a\geqslant
1\)</span>，我们定义 <span class="math inline">\(U_{a,b}=\{ka+b\mid k
\in \mathbb{Z}\}\)</span>（就是以 <span class="math inline">\(b\)</span>
为某一项的双边的等差数列）。我们定义 <span class="math inline">\(X\)</span> 的子集的集合 <span class="math inline">\(\mathcal{T}\)</span>：如果 <span class="math inline">\(U\in \mathcal{T}\)</span>，要么 <span class="math inline">\(U=\emptyset\)</span>，要么 <span class="math inline">\(U\)</span> 是某些 <span class="math inline">\(U_{a,b}\)</span> 的并集。</p>
<ul>
<li><p><span class="math inline">\(U\in
\mathcal{T}\)</span>。证明，<span class="math inline">\(x\in U\)</span>
当且仅当存在 <span class="math inline">\(a\geqslant 1\)</span>，使得
<span class="math inline">\(U_{a,x}\in \mathcal{T}\)</span>。</p>
<p>对于 <span class="math inline">\(x\in U\)</span>，一定有 <span class="math inline">\(x \in U_{s,t}\)</span>，于是 <span class="math inline">\(x=ks+t\)</span>，那么 <span class="math inline">\(U_{s,x}=U_{s,t} \in \mathcal T\)</span>。</p></li>
<li><p>证明，<span class="math inline">\(\mathbb{Z}\in
\mathcal{T}\)</span>。</p>
<p><span class="math inline">\(\mathbb Z = U_{1,0} \in \mathcal
T\)</span>。</p></li>
<li><p>证明，对于任意的 <span class="math inline">\(\{U_i\}_{i \in
I}\subset \mathcal{T}\)</span>，那么 <span class="math inline">\(\bigcup
U_i\in \mathcal{T}\)</span>。</p>
<p>Trivial.</p></li>
<li><p>证明， 如果 <span class="math inline">\(U,V\in
\mathcal{T}\)</span>，那么 <span class="math inline">\(U\cap V\in
\mathcal{T}\)</span>。</p>
<p>Trivial.</p></li>
<li><p>证明，任何有限集合都不是开集；任何补集是有限的集合都不是闭集。</p>
<p>Trivial.</p></li>
<li><p>证明，<span class="math inline">\(U_{a,b}\)</span>
即时开集也是闭集。</p>
<p>它是开集，它的补集是 <span class="math inline">\(\cup_{c\in [1,a],c
\neq b} U_{a,c}\)</span>，也是开集，所以它自己也是闭集。</p></li>
<li><p>证明，<span class="math inline">\(\displaystyle\mathbb{Z}-\{-1,1\}=\bigcup_{p~\text{是素数}}U_{p,0}\)</span>。</p>
<p>因为整数环去掉 <span class="math inline">\(0\)</span> 之后是一个
UFD。（草</p></li>
<li><p>用反证法证明，有无限多个素数.</p>
<p>如果只有有限个素数。<span class="math inline">\(U_{p,0}\)</span>
是闭集，<span class="math inline">\(\bigcup_{p~\text{是素数}}U_{p,0}\)</span>
是有限个闭集的并，还是闭集。那么 <span class="math inline">\(\lbrace
-1,1 \rbrace\)</span> 在 <span class="math inline">\(\mathbb Z\)</span>
上的补集是一个闭集，它是开集，而且是有限集，矛盾。</p>
<p>我超，好强。</p></li>
</ul>
<h1 id="期中考试">期中考试</h1>
<p>考试时间为 2 小时 25
分钟。两道大题之间是相互独立的。考试中后面的问题可以使用前面问题的结论（无论答题人是否已经得到正确的证明或者答案）。</p>
<h2 id="基本概念和技巧的考察">基本概念和技巧的考察</h2>
<ul>
<li><p>试用 <span class="math inline">\(\varepsilon-N\)</span>
语言证明：<span class="math inline">\(\displaystyle \lim_{n\rightarrow
\infty}\dfrac{n}{n^2+1}=0\)</span>。</p>
<p>Trivial.</p></li>
<li><p>试用 <span class="math inline">\(\varepsilon-\delta\)</span>
语言说明函数 <span class="math inline">\(\mathbb R\)</span> 上的函数
<span class="math inline">\(f(x)=\begin{cases} \sin(\frac{1}{x}), &amp;\
\ x\neq 0;\\0,&amp;\ \ x=0\end{cases}\)</span> 在 <span class="math inline">\(x=0\)</span> 处不连续。</p>
<p>Trivial.</p></li>
<li><p>计算极限：<span class="math inline">\(\displaystyle
\lim_{n\rightarrow
\infty}\left(1^2+2^2+3^2+\cdots+n^2\right)^\frac{1}{n}\)</span>。</p>
<p><span class="math inline">\(1\)</span>。</p></li>
<li><p>证明，级数 <span class="math inline">\(\displaystyle
\sum_{n=1}^\infty \frac{2n+1}{n^2(n+100)^2}\)</span> 收敛。</p>
<p>小于二阶调和级数，trivial.</p></li>
<li><p>给定实数的序列 <span class="math inline">\(\{a_n\}_{n\geqslant
1}\)</span>，假设级数 <span class="math inline">\(\displaystyle
\sum_{n=1}^\infty a_n\)</span> 收敛。证明，对任意的实数 <span class="math inline">\(x\in (-1,1)\)</span>，级数 <span class="math inline">\(\displaystyle \sum_{n=1}^\infty a_n x^n\)</span>
也收敛。（提示：利用Abel判别法）</p>
<p>PIN 真的，我哭死，他期中考试还在基础题上给提示（</p>
<p>Trivial.</p></li>
<li><p>假设 <span class="math inline">\(f\)</span> 是非空开区间 <span class="math inline">\((a,b)\)</span> 上的连续函数，证明，对任意的 <span class="math inline">\(x_1,x_2\in (a,b)\)</span>，存在 <span class="math inline">\(x_0 \in (a,b)\)</span>，使得</p>
<p><span class="math inline">\(f(x_0)=\frac{1}{2}\bigl(f(x_1)+f(x_2)\bigr)\)</span></p>
<p>介值定理，trivial.</p></li>
<li><p>假设函数 <span class="math inline">\(f:\mathbb R\rightarrow
\mathbb R\)</span> 是以 <span class="math inline">\(1\)</span>
为周期的连续函数，即对任意的 <span class="math inline">\(x\in \mathbb
R\)</span>，我们有 <span class="math inline">\(f(x+1)=f(x)\)</span>。证明，<span class="math inline">\(f\)</span> 有界并且能取到其最大值，即存在 <span class="math inline">\(x_0\in \mathbb R\)</span>，使得 <span class="math inline">\(f(x_0)=\displaystyle \sup_{x\in \mathbb
R}f(x)\)</span>。</p>
<p>Trivial.</p></li>
<li><p>证明，<span class="math inline">\(f(x)=\sqrt{x+1}\)</span> 作为
<span class="math inline">\(\mathbb R_{\geqslant 0}\)</span>
上的函数是一致连续的。</p>
<p>因为满足 Lipschitz 条件，<span class="math inline">\(L=\frac 1
2\)</span>。</p></li>
</ul>
<h2 id="级数">级数</h2>
<p>首先回忆一下二项式展开：<span class="math inline">\(\displaystyle
(1+z)^n=\sum_{k=0}^n {n \choose k} z^k\)</span>。特别地， 当 <span class="math inline">\(z=1\)</span> 时，我们有 <span class="math inline">\(\displaystyle 2^n=\sum_{k=0}^n {n \choose
k}\)</span>。</p>
<p>给定一个复数的数列 <span class="math inline">\(\{a_k\}_{k\geqslant
0}\)</span>，我们定义新的数列 <span class="math inline">\(\{a_n^*\}_{n\geqslant 0}\)</span>，其中 <span class="math inline">\(a_n^*=\frac{1}{2^n}\sum_{k=0}^n {n \choose
k}a_k\)</span></p>
<h3 id="等比数列">等比数列</h3>
<p>这一部分中，我们假设对任意的 <span class="math inline">\(k\geqslant
0\)</span>，<span class="math inline">\(a_k=z^k\)</span>，其中 <span class="math inline">\(z\)</span> 为复数。</p>
<ul>
<li><p>证明，如果 <span class="math inline">\(|z|&lt;1\)</span>，那么级数 <span class="math inline">\(\displaystyle \sum_{k=0}^\infty a_k\)</span>
收敛。我们用 <span class="math inline">\(A(z)\)</span>
表示这个极限。</p>
<p>Trivial，<span class="math inline">\(A(z) =
\frac{1}{1-z}\)</span>。</p></li>
<li><p>证明，如果 <span class="math inline">\(|z|&lt;1\)</span>，那么级数 <span class="math inline">\(\displaystyle \sum_{k=0}^\infty a^*_k\)</span>
收敛。我们用 <span class="math inline">\(A^*(z)\)</span>
表示这个极限。</p>
<p>Trivial 但差点被骗了，总之 <span class="math inline">\(a_k ^* =
\frac{z+1}{2}\)</span>，<span class="math inline">\(A^*(z) =
\frac{2}{1-z}\)</span>。</p></li>
<li><p>证明，如果 <span class="math inline">\(|z|\geqslant
1\)</span>，那么级数 <span class="math inline">\(\displaystyle
\sum_{k=0}^\infty a_k\)</span> 不收敛。</p>
<p>Trivial.</p></li>
<li><p>试找出一个 <span class="math inline">\(z\in
\mathbb{C}\)</span>，<span class="math inline">\(|z|&gt;1\)</span>，级数
<span class="math inline">\(\displaystyle \sum_{k=0}^\infty
a^*_k\)</span> 收敛。</p>
<p>级数部分和是 <span class="math inline">\(\frac{2}{1-z}
(1-(\frac{z+1}{2})^{k+1})\)</span>，取 <span class="math inline">\(z =
-2\)</span> 即可。</p></li>
<li><p>证明，如果 <span class="math inline">\(|z|=1\)</span> 并且 <span class="math inline">\(z\neq\pm 1\)</span>，那么级数 <span class="math inline">\(\displaystyle \sum_{k=0}^\infty a^*_k\)</span>
收敛。</p>
<p>Trivial.</p></li>
</ul>
<h3 id="收敛性比较">收敛性比较</h3>
<p>这一部分中，我们假设 <span class="math inline">\(\{a_k\}_{k\geqslant
0}\)</span> 为实数的序列。</p>
<ul>
<li><p>证明，当 <span class="math inline">\(k\in \mathbb{Z}_{\geqslant
0}\)</span> 固定的时候，我们有：</p>
<ul>
<li><span class="math inline">\(\lim_{n\rightarrow \infty} {n \choose
k}/{\frac{n^k}{k!}}=1\)</span></li>
<li><span class="math inline">\(\lim_{n\rightarrow \infty} {n \choose
k}/{2^n}=0\)</span></li>
</ul>
<p>Trivial.</p></li>
<li><p>任意给定非负整数 <span class="math inline">\(n&gt;q\)</span>，我们定义 <span class="math inline">\(a_{n,q}^*=\frac{1}{2^n}\sum_{k=0}^q {n \choose
k}a_k\)</span>，对每个固定的 <span class="math inline">\(q\)</span>，计算 <span class="math inline">\(\displaystyle \lim_{n\rightarrow \infty}
a_{n,q}^*\)</span>。</p>
<p><span class="math inline">\(0\)</span>。</p></li>
<li><p>如果 <span class="math inline">\(\displaystyle \lim_{n\rightarrow
\infty} a_{n}=0\)</span>，证明，<span class="math inline">\(\displaystyle \lim_{n\rightarrow \infty}
a_{n}^*=0\)</span>。</p>
<p>定义证明。</p></li>
<li><p>如果 <span class="math inline">\(\displaystyle \lim_{n\rightarrow
\infty} a_{n}\)</span> 存在，证明，<span class="math inline">\(\displaystyle \lim_{n\rightarrow \infty}
a_{n}^*\)</span> 存在并且恰好等于 <span class="math inline">\(\displaystyle \lim_{n\rightarrow \infty}
a_{n}\)</span>。</p>
<p>定义证明。</p></li>
<li><p>如果 <span class="math inline">\(\displaystyle \lim_{n\rightarrow
\infty} a^*_{n}\)</span> 存在，<span class="math inline">\(\displaystyle
\lim_{n\rightarrow \infty} a_{n}\)</span> 是否一定存在？</p>
<p>不一定，取 <span class="math inline">\(a_n =
(-1)^n\)</span>。</p></li>
</ul>
<p>在后面的问题中，对任意的 <span class="math inline">\(n\geqslant
0\)</span>，我们定义部分和 <span class="math inline">\(S_n=\sum_{k=0}^n
a_k, \ \ S^*_n=\sum_{k=0}^n a^*_k, \ \ U_n=2^n S_n^*\)</span></p>
<ul>
<li><p>证明，对任意的 <span class="math inline">\(n\geqslant
0\)</span>，<span class="math inline">\(U_n\)</span> 都可以写成 <span class="math inline">\(S_0,S_1,\cdots,S_n\)</span>
的整系数线性组合：<span class="math inline">\(U_n=\sum_{k=0}^n {n+1
\choose k+1} S_k\)</span></p>
<p>Trivial.</p></li>
<li><p>证明，如果级数 <span class="math inline">\(\displaystyle
\sum_{k=0}^\infty a_k\)</span> 收敛，那么 <span class="math inline">\(\displaystyle \sum_{k=0}^\infty a^*_k\)</span>
也收敛。</p>
<p>Trivial.</p></li>
</ul>
<h2 id="连续函数环的极大理想">连续函数环的极大理想</h2>
<p>假设 <span class="math inline">\(a&lt;b\)</span>
是实数，我们研究有界闭区间上的实数值连续函数的空间 <span class="math inline">\(C\bigl([a,b]\bigr)\)</span>。对于子集 <span class="math inline">\(I\subset
C\bigl([a,b]\bigr)\)</span>，如果它满足如下三个条件：</p>
<ul>
<li><p><span class="math inline">\(I\neq \emptyset\)</span>，<span class="math inline">\(I \neq C\bigl([a,b]\bigr)\)</span>；</p></li>
<li><p>对任意的 <span class="math inline">\(\varphi \in
I\)</span>，<span class="math inline">\(\psi \in I\)</span>，我们有
<span class="math inline">\(\varphi+\psi \in I\)</span>；</p></li>
<li><p>对任意的 <span class="math inline">\(\varphi \in
I\)</span>，<span class="math inline">\(f \in
C\bigl([a,b]\bigr)\)</span>，我们有 <span class="math inline">\(\varphi\cdot f \in I\)</span>.</p></li>
</ul>
<p>我们就称 <span class="math inline">\(I\)</span> 是 <span class="math inline">\(C\bigl([a,b]\bigr)\)</span> 的一个理想。假设 <span class="math inline">\(\mathfrak{m}\)</span> 是 <span class="math inline">\(C\bigl([a,b]\bigr)\)</span>
的理想并且不存在其它的包含 <span class="math inline">\(\mathfrak{m}\)</span> 的理想，我们就称 <span class="math inline">\(\mathfrak{m}\)</span> 是 <span class="math inline">\(C\bigl([a,b]\bigr)\)</span>
的一个极大理想（即若理想 <span class="math inline">\(I\supset
\mathfrak{m}\)</span>，那么 <span class="math inline">\(I
=\mathfrak{m}\)</span>）。</p>
<ul>
<li><p>对任意的子集 <span class="math inline">\(A\subset
[a,b]\)</span>，令 <span class="math inline">\(I(A)=\left\{f\in
C\bigl([a,b]\bigr)\big| \text{对任意的 $x\in
A$，$f(x)=0$}\right\}\)</span>。证明，<span class="math inline">\(I(A)\)</span> 是 <span class="math inline">\(C\bigl([a,b]\bigr)\)</span> 的理想。<span class="math inline">\(I([a,b])\)</span> 是什么？证明，如果有两个子集
<span class="math inline">\(A\subset B\subset [a,b]\)</span>，那么 <span class="math inline">\(I(A)\supset I(B)\)</span>。是否存在 <span class="math inline">\(A\subset [a,b]\)</span> 为真子集，使得 <span class="math inline">\(I(A)=\{0\}\)</span>?</p>
<p>前几问都是有手就行。最后一问取 <span class="math inline">\(A =
(a,b)\)</span>。</p></li>
<li><p>证明，如果 <span class="math inline">\(I \subset
C\bigl([a,b]\bigr)\)</span> 是理想，那么常值函数 <span class="math inline">\(1\notin I\)</span>。进一步证明，如果 <span class="math inline">\(I \subset C\bigl([a,b]\bigr)\)</span>
是理想，那么对任意的 <span class="math inline">\(f\in I\)</span>，<span class="math inline">\(f\)</span> 在 <span class="math inline">\([a,b]\)</span> 上一定有零点（即 <span class="math inline">\(f(x)=0\)</span> 在 <span class="math inline">\([a,b]\)</span> 上有解）。</p>
<p>如果是理想且恒等元在理想中，那么所有元素都在理想中，矛盾。</p>
<p>如果 <span class="math inline">\(f \in I\)</span> 且在 <span class="math inline">\([a,b]\)</span> 上没有零点，那么它是可逆的，<span class="math inline">\(f^{-1} \in C([a,b])\)</span>，于是 <span class="math inline">\(1 = f \cdot f^{-1} \in I\)</span>，矛盾。</p></li>
<li><p>对于 <span class="math inline">\(f \in
C\bigl([a,b]\bigr)\)</span>，证明，集合 <span class="math inline">\(V(f)=\bigl\{x\in [a,b]\big| f(x)=0\bigr\}\)</span>
是闭集。进一步证明，对于理想 <span class="math inline">\(I \subset
C\bigl([a,b]\bigr)\)</span>，集合 <span class="math inline">\(V(I)=\bigl\{x\in [a,b]\big| \text{对任意的 $f\in
I$},~ f(x)=0\bigr\}\)</span> 是闭集。如果理想 <span class="math inline">\(I \subset C\bigl([a,b]\bigr)\)</span> 使得 <span class="math inline">\(V(I)\)</span> 为全空间 <span class="math inline">\([a,b]\)</span>，你是否能够确定 <span class="math inline">\(I\)</span>？</p>
<p>记 <span class="math inline">\(T = \lbrace 0 \rbrace\)</span>，而
<span class="math inline">\(f^{-1} (T) = V(f)\)</span>
保持闭集性质。</p>
<p><span class="math inline">\(V(I) = \cap _{f\in I}
V(f)\)</span>，闭集的交集还是闭集。</p>
<p>如果 <span class="math inline">\(V(I) = [a,b]\)</span>，那么对任意的
<span class="math inline">\(f \in I\)</span> 都有 <span class="math inline">\(V(f) = [a,b]\)</span>，也就是说 <span class="math inline">\(f=0\)</span>，<span class="math inline">\(I\)</span> 是平凡理想。</p></li>
<li><p>对任意的点 <span class="math inline">\(x\in
[a,b]\)</span>，我们令 <span class="math inline">\(A=\{x\}\)</span> 并记
<span class="math inline">\(\mathfrak{m}_x
=I(A)=I\bigl(\{x\}\bigr)\)</span>，即 <span class="math inline">\(\mathfrak{m}_x=\left\{f\in C\bigl([a,b]\bigr)\big|
f(x)=0\right\}\)</span>。</p>
<p>证明，<span class="math inline">\(\mathfrak{m}_x\)</span>
是极大理想。</p>
<p>我差点想直接证明 <span class="math inline">\(C([a,b])\)</span> 是一个
PID，仔细一想里面的不可逆元全是零因子，根本不是整环。</p>
<p>不介意我用点抽代知识吧？</p>
<p>作环同态 <span class="math inline">\(t: C([a,b]) \to \mathbb
R\)</span>，<span class="math inline">\(f \to
f(x)\)</span>。如果存在极大理想 <span class="math inline">\(\mathfrak{m}
\supset \mathfrak{m}_x\)</span>，且使得存在 <span class="math inline">\(g\in \mathfrak m\)</span>，<span class="math inline">\(g(x) \neq 0\)</span>。</p>
<p>于是 <span class="math inline">\(\ker t = \mathfrak
m_x\)</span>，<span class="math inline">\(C([a,b]) / \mathfrak m _x
\cong \mathbb R\)</span> 是一个域，也即 <span class="math inline">\(\mathfrak m _x\)</span> 是一个极大理想。</p></li>
<li><p>证明，如果 <span class="math inline">\(\mathfrak{m}\)</span> 是
<span class="math inline">\(C\bigl([a,b]\bigr)\)</span>
的极大理想，那么存在 <span class="math inline">\(x\in [a,b]\)</span>
使得 <span class="math inline">\(\mathfrak{m}=\mathfrak{m}_x\)</span>。（提示：利用
<span class="math inline">\([a,b]\)</span> 是紧的）</p>
<p>如果 <span class="math inline">\(\mathfrak m\)</span>
是一个极大理想，而且不存在一个使得 <span class="math inline">\(\mathfrak
m = \mathfrak m _x\)</span> 的 <span class="math inline">\(x\in
[a,b]\)</span>。</p>
<p>于是对任意 <span class="math inline">\(x \in [a,b]\)</span>，存在
<span class="math inline">\(f_x\)</span> 使得 <span class="math inline">\(f_x(x) \neq 0\)</span>。由 <span class="math inline">\([a,b]\)</span> 是紧的可知存在一列函数 <span class="math inline">\(f_1,f_2,...,f_n\)</span>，满足对任意 <span class="math inline">\(x \in [a,b]\)</span>，存在 <span class="math inline">\(i \in \lbrace 1,2,...,n \rbrace\)</span>，使得
<span class="math inline">\(f_i (x) \neq 0\)</span>。于是 <span class="math inline">\(F=f_1 ^2 + ... + f_n ^2 \in \mathfrak m\)</span>
且是单位，矛盾。</p></li>
<li><p>是否存在理想 <span class="math inline">\(I \subset
C\bigl([a,b]\bigr)\)</span> 使得 <span class="math inline">\(V(I)=\emptyset\)</span>？</p>
<p>任意一个理想都被包含在某个极大理想中，<span class="math inline">\(V(I) \neq \emptyset\)</span>。</p></li>
<li><p>假设 <span class="math inline">\(A\)</span> 是闭集，证明，<span class="math inline">\(V(I(A))=A\)</span>。</p>
<p><span class="math inline">\(I(A)=\left\{f\in C\bigl([a,b]\bigr)\big|
\text{对任意的 $x\in A$，$f(x)=0$}\right\}\)</span>，</p>
<p><span class="math inline">\(V(f)=\bigl\{x\in [a,b]\big|
f(x)=0\bigr\}\)</span>。</p>
<p>在努力回忆 Galois
对应（？）是什么东西，但是忘了（，不知道有没有关系。</p>
<p>胡说八道：首先 <span class="math inline">\(A \in
V(I(A))\)</span>，然后证明对任意的 <span class="math inline">\(x \in
V(I(A))\)</span> 有 <span class="math inline">\(x \in
A\)</span>。否则存在 <span class="math inline">\(s \notin
A\)</span>，且对任意的 <span class="math inline">\(f \in I(A)\)</span>
都有 <span class="math inline">\(f(s)=0\)</span>。我们只要构造出一个不符合此条件的
<span class="math inline">\(g \in I(A)\)</span> 即可，而 <span class="math inline">\(g\in I(A)\)</span> 在 <span class="math inline">\([a,b]\)</span> 上有可数个零点，且 <span class="math inline">\(g(s)\neq 0\)</span>，逐段构造使其连续，且在 <span class="math inline">\(A\)</span> 上取值均为 <span class="math inline">\(0\)</span> 即可。</p></li>
</ul>
<blockquote>
<p>Remark：</p>
<p>上面的结论可以推广到紧的距离空间的情形：假设 <span class="math inline">\((X,d)\)</span> 是紧的距离空间，<span class="math inline">\(C(X)\)</span> 是 <span class="math inline">\(X\)</span>
上复数值的连续函数的全体，那么我们有如下的一一对应：<span class="math inline">\(X \longrightarrow \bigl\{\text{$C(X)$
的极大理想}\bigr\}, \ \  x\mapsto \mathfrak{m}_x\)</span></p>
<p>其中 <span class="math inline">\(\mathfrak{m}_x=\left\{f\in
C\bigl(X\bigr)\big| f(x)=0\right\}\)</span>。据此，我们把可以把环 <span class="math inline">\(C(X)\)</span> 中的极大理想想象成空间的点，从而通过
<span class="math inline">\(C(X)\)</span> 中的代数对象来研究 <span class="math inline">\(X\)</span> 上的几何，这是代数几何的开端。</p>
</blockquote>
<h1 id="休整">休整</h1>
<p>导数异常地轻松，半摸半写一天就写得差不多了，作为一个休息，之后会随第二篇直接发上来，作为二月的开端。</p>
<p>我觉得可能还是学不完，2.13
就要回北京了，后面要复习一下缓考的一门（水）课，大概还有两周时间给数分。学到这里也花了差不多两周，第一周一边学一边摆，第二周其他任务几乎全部停滞，就一直在读这本书。其实大多数精力都放在做习题上面了，原来的计划是习题跳着看一看就好，但还是改变了主意，想扎实一点。</p>
<p>说到底我也在怀疑选这本书到底对不对了，感觉 PIN
在讲一种很新的数分（，很怀疑和正常的版本是不是有差别，但应该是闭包才对吧（。实际上在我开始速通的后几天，转数环里就发了光叔的前两学期讲义，但是当时也没有换，就一直到这里了。PIN
确实讲得深，但是似乎还是缺少技巧的训练。算了，我又不是现在要考丘赛，那些之后再说吧。</p>
<p>还是在害怕。要用四周积累来的知识和已经学了一年半分析的同学一起上新学期的课程，我觉得真的好难。虽然微不足道的成功经验告诉我最重要的是不要害怕，但是果然，连做到不害怕都好难（</p>
<p><img src="https://s2.loli.net/2022/12/21/6IoqJymjuntP9b2.jpg" alt="QED.jpg"></p>
]]></content>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>Proof of Carathéodory’s Extension Theorem</title>
    <url>/2023/03/13/Proof-of-Caratheodory-Extension-Theorem/</url>
    <content><![CDATA[<p>《概率论 (1)》课程第一次
bonus。一个略长的证明，我使用的证明框架来自<a href="http://www.probability.net/WEBcaratheodory.pdf">这里</a>。感觉挺有意思，发出来<del>水一篇</del>留作纪念（，<del>毕竟博客的数学
tag 下面几乎全是统计，成何体统</del>。</p>
<p>本文发布时已过本次加分作业设定的截止时间。</p>
<p>证完了才知道 Kai Lai Chung 附录和 lzx
的课程笔记里都有提示是正常的吗（，有的人上课是真的一点都不听啊（</p>
<span id="more"></span>
<p>证明使用英文完成，我的英语全盛期水平高考才考了
135<del>（虽然是地狱难度的上海英语）</del>，可想而知有多烂。</p>
<p>Get started!</p>
<p>In the following, <span class="math inline">\(\Omega\)</span> is a
set. Whenever a union of sets is denoted <span class="math inline">\(\uplus\)</span> as opposed to <span class="math inline">\(\cup\)</span>, it indicates that the sets involved
are pairwise disjoint.</p>
<h1 id="definition-1-semi-ring">Definition 1 (semi-ring)</h1>
<p><strong>Definition 1 (semi-ring)</strong>:</p>
<p>A semi-ring on <span class="math inline">\(\Omega\)</span> is a
subset <span class="math inline">\(\mathcal S\)</span> of the power set
<span class="math inline">\(P(\Omega)\)</span> with the following
properties:</p>
<ul>
<li><span class="math inline">\(\emptyset \in \mathcal S\)</span></li>
<li><span class="math inline">\(A,B \in \mathcal S \Rightarrow A\cup B
\in \mathcal S\)</span></li>
<li><span class="math inline">\(A,B \in \mathcal S \Rightarrow \exists n
\geq 0, \exists A_i \in \mathcal S: A \setminus B = \uplus_{i=1} ^n
A_i\)</span></li>
</ul>
<h1 id="definition-2-ring">Definition 2 (ring)</h1>
<p><strong>Definition 2 (ring)</strong>:</p>
<p>A ring on <span class="math inline">\(\Omega\)</span> is a subset
<span class="math inline">\(\mathcal R\)</span> of the power set <span class="math inline">\(P(\Omega)\)</span> with the following
properties:</p>
<ul>
<li><span class="math inline">\(\emptyset \in \mathcal R\)</span></li>
<li><span class="math inline">\(A,B \in \mathcal R \Rightarrow A \cup B
\in \mathcal R\)</span></li>
<li><span class="math inline">\(A , B \in \mathcal R \Rightarrow A
\setminus B \in \mathcal R\)</span></li>
</ul>
<p><strong>Remark 1</strong>:</p>
<ul>
<li><p><span class="math inline">\(A \cup B = A\setminus (A \setminus
B)\)</span> and therefore that a ring is closed under pairwise
intersection.</p></li>
<li><p>A ring on <span class="math inline">\(\Omega\)</span> is also a
semi-ring on <span class="math inline">\(\Omega\)</span>.</p></li>
<li><p>Let <span class="math inline">\((\mathcal R_i ) _{i \in
I}\)</span> be an arbitrary family of rings on <span class="math inline">\(\Omega\)</span>, with <span class="math inline">\(I \neq \emptyset\)</span>. Then <span class="math inline">\(\mathcal R \triangleq \cap_{i \in I} \mathcal
R_i\)</span> is also a ring on <span class="math inline">\(\Omega\)</span>.</p></li>
</ul>
<p>These properties are trivial.</p>
<h1 id="definition-3-ring-generated-by-set">Definition 3 (ring generated
by set)</h1>
<p><strong>Definition 3 (ring generated by set)</strong>:</p>
<p>Let <span class="math inline">\(\mathcal A\)</span> be a subset of
the power set <span class="math inline">\(P(\Omega)\)</span>. Define $ R
(A) { R$ is ring on <span class="math inline">\(\Omega : \mathcal A
\subset \mathcal R\}\)</span>.</p>
<p>It's easy to show that <span class="math inline">\(P(\Omega)\)</span>
is a ring on <span class="math inline">\(\Omega\)</span>, and that <span class="math inline">\(R(\mathcal A)\)</span> is not empty. Define <span class="math inline">\(\mathcal R(\mathcal A) \triangleq \cap _{\mathcal
R \in R(\mathcal A)} \mathcal R\)</span> as the ring generated by <span class="math inline">\(\mathcal A\)</span>.</p>
<p><strong>Remark 2</strong>:</p>
<ul>
<li>In the definition above, we should show that <span class="math inline">\(\mathcal R(\mathcal A)\)</span> is a ring on <span class="math inline">\(\Omega\)</span> cause it's defined as the
intersections of all rings in <span class="math inline">\(R(\mathcal
A)\)</span>.</li>
<li><span class="math inline">\(\mathcal A \subseteq \mathcal R(\mathcal
A)\)</span>.</li>
</ul>
<h1 id="proposition-1-the-way-to-generate-a-ring-by-a-semi-ring">Proposition
1 (the way to generate a ring by a semi-ring)</h1>
<p><strong>Proposition 1 (the way to generate a ring by a
semi-ring)</strong>:</p>
<p>Let <span class="math inline">\(S\)</span> be a semi-ring on <span class="math inline">\(\Omega\)</span>. Define the set <span class="math inline">\(\mathcal R\)</span> of all finite unions of
pairwise disjoint elements of <span class="math inline">\(\mathcal
S\)</span>, i.e.</p>
<p><span class="math display">\[\mathcal R \triangleq \lbrace A:A =
\uplus_{i=1} ^n A_i ,A_i \in \mathcal S,n\in \mathbb Z+
\rbrace\]</span></p>
<p>(where if <span class="math inline">\(n=0\)</span>, the corresponding
union is empty, i.e. <span class="math inline">\(\emptyset \in \mathcal
R\)</span>). Then <span class="math inline">\(\mathcal R = \mathcal
R(\mathcal S)\)</span>.</p>
<p><strong>Proof</strong>:</p>
<p>First to prove that <span class="math inline">\(R\)</span> is a ring.
Let <span class="math inline">\(A = \uplus _{i=1} ^n A_i\)</span> and
<span class="math inline">\(B= \uplus _{j=1} ^p B_j \in \mathcal
R\)</span>:</p>
<ul>
<li><span class="math inline">\(A \cap B = \uplus _{i,j} (A_i \cap
B_j)\)</span> and that <span class="math inline">\(\mathcal R\)</span>
is closed under pairwise intersection.</li>
<li>If <span class="math inline">\(p \geq 1\)</span>, then <span class="math inline">\(A\setminus B = \cap_{j=1} ^p (\uplus _{i=1} ^n
(A_i \setminus B_j))\)</span>, and that <span class="math inline">\(\mathcal R\)</span> is closed under set
difference.</li>
<li><span class="math inline">\(A \cup B = (A\setminus B) \uplus
B\)</span>, and that <span class="math inline">\(\mathcal R\)</span> is
a ring on <span class="math inline">\(\Omega\)</span>.</li>
</ul>
<p>Then to prove that <span class="math inline">\(\mathcal R\)</span> is
the minimal ring that contains <span class="math inline">\(\mathcal
S\)</span>, which is trivial.</p>
<p>So <span class="math inline">\(\mathcal R(\mathcal S)\)</span> is
indeed the ring generated by the semi-ring <span class="math inline">\(\mathcal S\)</span>, now we have the way to
generate a ring from a semi-ring.</p>
<p><strong>Remark 3 (Another way to generate a ring by a
semi-ring)</strong>:</p>
<p>Everything being as before, define: <span class="math inline">\(\mathcal R &#39; \triangleq \lbrace A:A =
\cup_{i=1} ^n A_i,A_i \in S,n\in \mathbb Z+ \rbrace\)</span>. We don't
require the sets involved in the union to be pairwise disjoint. Using
the fact that the ring <span class="math inline">\(\mathcal R\)</span>
is closed under finite unoin, then <span class="math inline">\(\mathcal
R&#39; \subseteq \mathcal R\)</span> while <span class="math inline">\(\mathcal R\)</span> is the minimal ring that
contains <span class="math inline">\(\mathcal S\)</span>, thus <span class="math inline">\(\mathcal R&#39; = \mathcal R = \mathcal R
(\mathcal S)\)</span>.</p>
<h1 id="definition-4-measure-on-set">Definition 4 (measure on set)</h1>
<p><strong>Definition 4 (measure on set)</strong>:</p>
<p>Let <span class="math inline">\(\mathcal A \subseteq
P(\Omega)\)</span> with <span class="math inline">\(\emptyset \in
\mathcal A\)</span>. We call measure on <span class="math inline">\(\mathcal A\)</span>, any map <span class="math inline">\(\mu: \mathcal A \to [0,+\infty]\)</span> with the
following properties:</p>
<ul>
<li><span class="math inline">\(\mu(\emptyset) = 0\)</span></li>
<li><span class="math inline">\(A \in \mathcal A,A_n \in \mathcal
A\)</span> and <span class="math inline">\(A = \uplus _{n=1} ^{+\infty}
A_n \Rightarrow \mu(A) = \Sigma_{i=1} ^{+\infty} \mu (A_n)\)</span>
(which is called countable additivity)</li>
</ul>
<p>While $A $ is a <span class="math inline">\(\sigma-\)</span>algebra
on <span class="math inline">\(\Omega\)</span>, the second property can
be replaced by:</p>
<ul>
<li><span class="math inline">\(A_n \in \mathcal A\)</span> and <span class="math inline">\(A = \uplus _{n=1} ^{+\infty} A_n \Rightarrow
\mu(A) = \Sigma_{i=1} ^{+\infty} \mu (A_n)\)</span></li>
</ul>
<p><strong>Remark 4</strong>:</p>
<p>We don't require the set $A $ is a <span class="math inline">\(\sigma
-\)</span>algebra on <span class="math inline">\(\Omega\)</span>. If
<span class="math inline">\(A,B \in \mathcal A\)</span>, <span class="math inline">\(A \subseteq B\)</span> and <span class="math inline">\(B \setminus A \in \mathcal A\)</span>, then <span class="math inline">\(\mu(A) \leq \mu(B)\)</span>. The proof is
trivial.</p>
<h1 id="proposition-2-measure-extended-from-semi-ring-to-ring">Proposition 2
(measure extended from semi-ring to ring)</h1>
<p><strong>Proposition 2 (measure extended from semi-ring to
ring)</strong>:</p>
<p>Let <span class="math inline">\(\mathcal S\)</span> be a semi-ring on
<span class="math inline">\(\Omega\)</span>, and <span class="math inline">\(\mu : \mathcal S \to [0,+\infty]\)</span> be a
measure on <span class="math inline">\(\mathcal S\)</span>. There exists
an extension of <span class="math inline">\(\mu\)</span> on <span class="math inline">\(\mathcal R(\mathcal S)\)</span>, i.e. a measure
<span class="math inline">\(\bar{\mu}: \mathcal R (\mathcal S) \to
[0,+\infty]\)</span> such that <span class="math inline">\(\bar{\mu}|_{\mathcal S } = \mu\)</span>.</p>
<p><strong>Proof</strong>:</p>
<p>Let <span class="math inline">\(A\)</span> be an element of <span class="math inline">\(\mathcal R =\mathcal R(\mathcal S)\)</span> with
representation <span class="math inline">\(A = \uplus _{i=1} ^n
A_i\)</span> as a finite union of pairwise disjoint elements of <span class="math inline">\(\mathcal S\)</span>. Define <span class="math inline">\(\bar{\mu} (A) = \Sigma_{i=1} ^n \mu(A_i)\)</span>
as the extended measure on ring <span class="math inline">\(\mathcal
R\)</span>. Then check it's well-defined, derived from <span class="math inline">\(\mathcal S\)</span>, and is a measure.</p>
<ul>
<li><p>Let <span class="math inline">\(A \in \mathcal R(\mathcal
S)\)</span>, <span class="math inline">\(A = \uplus _{i=1} ^n A_i =
\uplus _{j=1} ^p B_j\)</span>, show that <span class="math inline">\(\bar{\mu} (A) = \Sigma_{i=1} ^n
\mu(A_i)=\Sigma_{j=1} ^m \mu(B_j)\)</span>.</p>
<p>For <span class="math inline">\(i=1,2,...,n\)</span>, <span class="math inline">\(\mu (A_i) = \Sigma_{j=1} ^p \mu(A_i \cap
B_j)\)</span>, for <span class="math inline">\(j=1,2,...,p\)</span>,
<span class="math inline">\(\mu(B_j) = \Sigma_{i=1} ^n \mu(A_i \cap
B_j)\)</span>.</p>
<p>Then <span class="math inline">\(\Sigma_{i=1} ^n \mu(A_i)=
\Sigma_{i=1} ^n \Sigma_{j=1} ^p \mu(A_i \cap B_j)= \Sigma_{j=1} ^p
\Sigma_{i=1} ^n \mu(A_i \cap B_j)= \Sigma_{j=1} ^m \mu(B_j)\)</span>, so
the map <span class="math inline">\(\bar{\mu} :\mathcal R (\mathcal S)
\to [0,+\infty]\)</span> is well-defined.</p></li>
<li><p>Easy to show that <span class="math inline">\(\bar{\mu}|_{\mathcal S } = \mu\)</span>.</p></li>
<li><p>Suppose that <span class="math inline">\((A_n)_{n \geq
1}\)</span> is a sequence of pairwise disjoint elements of <span class="math inline">\(\mathcal R (\mathcal S)\)</span>, each <span class="math inline">\(A_n\)</span> have the representation <span class="math inline">\(A_n = \uplus _{k=1} ^{p_n} A_n ^k , n \geq
1\)</span> as a finite union of disjoint elements of <span class="math inline">\(\mathcal S\)</span>.</p>
<p>Suppose moreover $A = _{n=1} ^{+} A_n $ is an element of <span class="math inline">\(\mathcal R(\mathcal S)\)</span> with
representation <span class="math inline">\(A = \uplus_{j=1} ^p
B_j\)</span>, as a finite union of pairwise disjoint elements of <span class="math inline">\(\mathcal S\)</span>.</p>
<p>We want to show that <span class="math inline">\(\bar{\mu} (A) =
\Sigma_{n=1} ^{\infty} \bar{\mu} (A_n)\)</span>, then <span class="math inline">\(\bar{\mu}\)</span> meets the property of countable
additivity, thus it's a measure on <span class="math inline">\(\mathcal
R(\mathcal S)\)</span>.According to the definition of <span class="math inline">\(\bar{\mu}\)</span>, <span class="math inline">\(\bar{\mu}(A) = \Sigma_{j=1}^p \mu(
B_j)\)</span>.</p>
<p>For each <span class="math inline">\(j=1,2,...,p\)</span>, <span class="math inline">\(B_j = \cup_{n=1} ^{+\infty} \cup_{k=1}^{p_n} (A_n
^k \cap B_j) = \uplus_{m=1} ^{+\infty} C_m\)</span>, while for <span class="math inline">\(m=1,2,...,+\infty\)</span>, <span class="math inline">\(C_m = \uplus _{k=1}^{p_n} (A_n ^k \cap
B_j)\)</span> is a union of disjoint pairwise elements in <span class="math inline">\(\mathcal S\)</span>, then <span class="math inline">\(C_m \in \mathcal S\)</span>.</p>
<p>According to the definition of <span class="math inline">\(\bar{\mu}\)</span>, <span class="math inline">\(\mu(C_m) = \Sigma_{k=1} ^{p_n} \mu(A_n ^k \cap
B_j)\)</span>, thus <span class="math inline">\(\mu(B_j) = \Sigma_{m=1}
^{+\infty} \mu(C_m) = \Sigma_{n=1} ^{+\infty}\Sigma_{k=1} ^{p_n} \mu(A_n
^k \cap B_j)\)</span>.</p>
<p>On the other hand, <span class="math inline">\(A_n ^k = A_n ^k \cap A
= \uplus_{j=1} ^p (A_n ^k \cap B_j)\)</span>, thus <span class="math inline">\(\bar{\mu}(A_n ^k) = \mu(A_n ^k) = \Sigma_{j=1} ^p
\mu(A_n ^k \cap B_j)\)</span>. While $A_n = _{k=1} ^{p_n} A_n ^k $, we
know that <span class="math inline">\(\bar{\mu} (A_n)= \Sigma_{k=1}^
{p_n} \bar{\mu}(A_n ^k) = \Sigma_{k=1}^ {p_n} \Sigma_{j=1} ^p \mu(A_n ^k
\cap B_j)\)</span>.</p>
<p>After all, ${}(A) = <em>{j=1} ^p (B_j) = </em>{j=1} ^p <em>{n=1}
^{+}</em>{k=1} ^{p_n} (A_n ^k B_j) = <em>{n=1} ^{+} </em>{k=1}^ {p_n}
<em>{j=1} ^p (A_n ^k B_j) = </em>{n=1} ^{+}{}(A_n) $, which indicates
that <span class="math inline">\(\bar{\mu}\)</span> is a measure on
<span class="math inline">\(\mathcal R(\mathcal S)\)</span>.</p></li>
</ul>
<p>Thus <span class="math inline">\(\bar{\mu}\)</span> is a extended
measure on the ring <span class="math inline">\(\mathcal R (\mathcal
S)\)</span>, and is extended from the semi-ring <span class="math inline">\(\mathcal S\)</span>.</p>
<h1 id="proposition-3-uniqueness-of-the-extension-barmu">Proposition 3
(Uniqueness of the extension <span class="math inline">\(\bar{\mu}\)</span>)</h1>
<p><strong>Proposition 3 (Uniqueness of the extension <span class="math inline">\(\bar{\mu}\)</span>)</strong></p>
<p>Let <span class="math inline">\(\mathcal S\)</span> be a semi-ring on
<span class="math inline">\(\Omega\)</span>, and <span class="math inline">\(\mu : \mathcal S \to [0,+\infty]\)</span> be a
measure on <span class="math inline">\(\mathcal S\)</span>. There exists
an <strong>unique</strong> extension of <span class="math inline">\(\mu\)</span> on <span class="math inline">\(\mathcal R(\mathcal S)\)</span>, i.e. a measure
<span class="math inline">\(\bar{\mu}: \mathcal R (\mathcal S) \to
[0,+\infty]\)</span> such that <span class="math inline">\(\bar{\mu}|_{\mathcal S } = \mu\)</span>.</p>
<p><strong>Proof</strong>:</p>
<p>We just prove the uniqueness of the structure of <span class="math inline">\(\bar{\mu}\)</span> in proposition 2.</p>
<p>Take <span class="math inline">\(\bar{\mu} : \mathcal R (\mathcal S)
\to [0,+\infty]\)</span> as defined in proposition 2, we proved that
<span class="math inline">\(\bar{\mu}\)</span> is indeed a measure on
the ring <span class="math inline">\(\mathcal R (\mathcal S)\)</span>.
Let <span class="math inline">\(\mu &#39;\)</span> be another measure
extended from <span class="math inline">\(\mathcal S\)</span>.</p>
<p>For each <span class="math inline">\(A \in \mathcal R(\mathcal
S)\)</span>, <span class="math inline">\(A\)</span> has a representation
<span class="math inline">\(A = \uplus_{i=1} ^n A_i\)</span> as a finite
union of pairwise disjoint elements in <span class="math inline">\(\mathcal S\)</span>. According to the definition,
<span class="math inline">\(\mu&#39;(A) = \Sigma_{i=1} ^n \mu &#39;(A_i)
= \mu(A_i) = \Sigma_{i=1}^n \bar{\mu}(A_i) = \bar{\mu}(A)\)</span>. This
being true for each <span class="math inline">\(A \in \mathcal
R(\mathcal S)\)</span>, then the extension is unique.</p>
<h1 id="definition-5-outer-measure">Definition 5 (outer-measure)</h1>
<p><strong>Definition 5 (outer-measure)</strong>:</p>
<p>We define an outer-measure on <span class="math inline">\(\Omega\)</span> as being any map <span class="math inline">\(\mu^*: P(\Omega) \to [0,+\infty]\)</span> with the
following properties:</p>
<ul>
<li><span class="math inline">\(\mu ^*(\emptyset) = 0\)</span></li>
<li><span class="math inline">\(A \subseteq B \Rightarrow \mu^*(A)\leq
\mu^*(B)\)</span></li>
<li><span class="math inline">\(\mu^*(\cup_{i=1} ^{+\infty} A_n) \leq
\Sigma_{i=1}^{+\infty} \mu^*(A_n)\)</span></li>
</ul>
<p><strong>Remark 5</strong>:</p>
<p>According to the third property of outer-measure, <span class="math inline">\(\mu^*(A \cup B) \leq \mu^*(A) +\mu^*(B)\)</span>
where <span class="math inline">\(\mu ^*\)</span> is an outer-measure on
<span class="math inline">\(\Omega\)</span> and <span class="math inline">\(A,B \subseteq \Omega\)</span>.</p>
<h1 id="definition-6-the-sigma-algebra-associated-with-outer-measure">Definition
6 (the <span class="math inline">\(\sigma-\)</span>algebra associated
with outer-measure)</h1>
<p><strong>Definition 6 (the <span class="math inline">\(\sigma-\)</span>algebra associated with
outer-measure)</strong>:</p>
<p>Let <span class="math inline">\(\mu^*\)</span> be an outer-measure on
<span class="math inline">\(\Omega\)</span>. We define:</p>
<p><span class="math display">\[\Sigma(\mu ^*) \triangleq \lbrace A
\subseteq \Omega: \mu^*(T) = \mu^*(T \cap A) + \mu^*(T \cap A^C),
\forall T \subseteq \Omega \rbrace\]</span></p>
<p>We call <span class="math inline">\(\Sigma(\mu^*)\)</span> the <span class="math inline">\(\sigma-\)</span>algebra associated with the
outer-measure <span class="math inline">\(\mu^*\)</span>. (The fact
<span class="math inline">\(\Sigma(\mu^*)\)</span> is a <span class="math inline">\(\sigma-\)</span>algebra remains to be proved)</p>
<h1 id="proposition-4-the-sigma-algebra-associated-with-outer-measure">Proposition
4 (the <span class="math inline">\(\sigma-\)</span>algebra associated
with outer-measure)</h1>
<p><strong>Proposition 4 (the <span class="math inline">\(\sigma-\)</span>algebra associated with
outer-measure)</strong>:</p>
<p>Let <span class="math inline">\(\mu^*\)</span> be an outer-measure on
<span class="math inline">\(\Omega\)</span>. Let <span class="math inline">\(\Sigma = \Sigma(\mu^*)\)</span> be the <span class="math inline">\(\sigma-\)</span>algebra associated with <span class="math inline">\(\mu^*\)</span>. <span class="math inline">\(\Sigma\)</span> is indeed a <span class="math inline">\(\sigma-\)</span>algebra.</p>
<p><strong>Proof</strong>:</p>
<p>Let <span class="math inline">\(A,B \in \Sigma\)</span> and <span class="math inline">\(T\subseteq \Omega\)</span>. First of all, <span class="math inline">\(\Omega,\emptyset \in \Sigma(\mu^*)\)</span> thus
<span class="math inline">\(\Sigma(\mu^*)\)</span> is non-empty.</p>
<ul>
<li><p>For <span class="math inline">\(A \in \Sigma\)</span>, there is
$^<em>(T) = ^</em>(T A) + ^<em>(T A^C)= ^</em>(T A^C)+ ^*(T A) $ thus
<span class="math inline">\(A^C \in \Omega\)</span>.</p></li>
<li><p>Note that <span class="math inline">\(T\cap A^C = T \cap (A\cap
B)^C \cap A^C\)</span>, <span class="math inline">\(T\cap A\cap B^C =
T\cap (A\cap B)^C \cap A\)</span>, then</p>
<p><span class="math display">\[\mu^*(T\cap A^C) +\mu^*(T\cap A\cap B^C)
= \mu^*(T \cap (A\cap B)^C \cap A^C) + \mu^*(T\cap (A\cap B)^C \cap A) =
\mu^*(T\cap(A\cap B)^C)\]</span></p>
<p>Addint <span class="math inline">\(\mu^*(T\cap (A\cap B))\)</span> on
both sides of the equation above, there is</p>
<p><span class="math display">\[\mu^*(T) = \mu^*(T \cap(A\cap
B))+\mu^*(T\cap (A\cap B)^C)\]</span></p>
<p>which suggests that <span class="math inline">\(A\cap B \in
\Sigma\)</span> when <span class="math inline">\(A ,B \in
\Sigma\)</span>, we proved that intersection is closed in <span class="math inline">\(\Sigma\)</span>.</p></li>
<li><p>With the two properties above, it's trivial to prove that <span class="math inline">\(A\cup B\)</span> and <span class="math inline">\(A\setminus B \in \Sigma\)</span>.</p></li>
</ul>
<p>Let <span class="math inline">\((B_n)_{n \geq 1}\)</span> be a
sequence of pairwise disjoint elements of <span class="math inline">\(\Sigma\)</span>, and let <span class="math inline">\(B\triangleq \uplus_{i=1}^{+\infty} B_i\)</span>.
Let <span class="math inline">\(N \geq 1\)</span>.</p>
<ul>
<li><p>For each <span class="math inline">\(N \in \mathbb Z+\)</span>,
there is <span class="math inline">\(\uplus_{i=1}^N B_i \in
\Sigma\)</span>. Thus <span class="math inline">\(\mu^*(T\cap
(\uplus_{i=1} ^N B_i)) = \Sigma_{i=1}^N \mu^*(T\cap B_n)\)</span>.
According to the definition of <span class="math inline">\(B\)</span>,
there is <span class="math inline">\(\uplus_{i=1} ^N B_i \subseteq
B\)</span>, then <span class="math inline">\(B^C \subseteq
(\uplus_{i=1}^N B_i)^C\)</span>. Thus <span class="math inline">\(T \cap
B^C \subseteq T \cap (\uplus_{i=1}^N B_i)^C\)</span>.</p>
<p>Due to the second property of outer-measure, <span class="math inline">\(\mu^*( T \cap B^C) \leq \mu^*(T\cap
(\uplus_{i=1}^N B_i)^C)\)</span>, thus there is:</p>
<p><span class="math display">\[\mu^*(T \cap B^C)
+\Sigma_{i=1}^{+\infty} \mu^*(T\cap B_i) \leq \mu^*(T \cap
(\uplus_{i=1}^N B_n)^C)+\Sigma_{i=1}^{+\infty} \mu^*(T\cap B_i) =
\mu^*(T \cap (\uplus_{i=1}^N B_n)^C)+\mu^*(T\cap (\uplus_{i=1} ^N B_i))
= \mu^*(T)\]</span></p>
<p>cause <span class="math inline">\((\uplus_{i=1}^N B_n) \in
\Sigma(\mu^*)\)</span>.</p>
<p>While <span class="math inline">\(\mu^*(T) \leq \mu^*(T\cap B^C) +
\mu^*(T\cap B) \leq \Sigma_{i=1}^{+\infty} \mu^*(T\cap B_i) +
\mu^*(T\cap B^C)\)</span>, thus <span class="math inline">\(\mu^*(T) =
\mu^*(T\cap B)+ \mu(T\cap B^C)\)</span> meets, <span class="math inline">\(B\triangleq \uplus_{i=1}^{+\infty} B_i \in
\Sigma\)</span>.</p></li>
</ul>
<p>All the statements above show that <span class="math inline">\(\Sigma(\mu^*)\)</span> is a <span class="math inline">\(\sigma-\)</span>algebra.</p>
<h1 id="proposition-5-the-measure-on-the-sigma-algebra-sigmamu">Proposition
5 (the measure on the <span class="math inline">\(\sigma-\)</span>algebra <span class="math inline">\(\Sigma(\mu^*)\)</span>)</h1>
<p><strong>Proposition 5 (the measure on the <span class="math inline">\(\sigma-\)</span>algebra <span class="math inline">\(\Sigma(\mu^*)\)</span>)</strong>:</p>
<p>Let <span class="math inline">\(\mu^*\)</span> be an outer-measure on
<span class="math inline">\(\Omega\)</span>. Let <span class="math inline">\(\Sigma = \Sigma(\mu^*)\)</span> be the <span class="math inline">\(\sigma-\)</span>algebra associated with <span class="math inline">\(\mu^*\)</span>. Then <span class="math inline">\(\mu^* |_{\Sigma}\)</span> is a measure on <span class="math inline">\(\Sigma\)</span>.</p>
<p><strong>Proof</strong>:</p>
<p><span class="math inline">\(\mu^*\)</span> is an outer-measure on
<span class="math inline">\(\Omega\)</span> (of course on <span class="math inline">\(\Sigma\)</span>), then we only need to prove the
countable additivity of <span class="math inline">\(\mu^*\)</span> on
<span class="math inline">\(\Sigma\)</span>.</p>
<p>According to the equation <span class="math inline">\(\mu^*(T \cup B)
= \Sigma_{i=1}^{+\infty} \mu^*(T\cap B_i)\)</span> in the proof of
proposition 4, take <span class="math inline">\(T=B\)</span> (cause
<span class="math inline">\(\Sigma\)</span> is a <span class="math inline">\(\sigma-\)</span>algebra on <span class="math inline">\(\Omega\)</span>,<span class="math inline">\(B \in
\Sigma\)</span>). Thus <span class="math inline">\(\mu^*(B) =
\Sigma_{i=1}^{+\infty} \mu^*( B_i)\)</span>, <span class="math inline">\(\mu^*|_{\Sigma}\)</span> is the measure on <span class="math inline">\(\Sigma\)</span>.</p>
<h1 id="proposition-6-the-outer-measure-on-the-set-derived-from-a-measure-on-the-ring">Proposition
6 (the outer-measure on the set derived from a measure on the ring)</h1>
<p><strong>Proposition 6 (the outer-measure on the set derived from a
measure on the ring)</strong>:</p>
<p>Let <span class="math inline">\(\mathcal R\)</span> be a ring on
<span class="math inline">\(\Omega\)</span> and <span class="math inline">\(\mu : \mathcal R \to [0,+\infty]\)</span> be a
measure on <span class="math inline">\(\mathcal R\)</span>. For all
<span class="math inline">\(T \subseteq \Omega\)</span>,define:</p>
<p><span class="math display">\[\mu^*(T) \triangleq \inf \lbrace
\Sigma_{n=1} ^{+\infty} \mu(A_n) , A_n \in \mathcal R , T \subseteq
\cup_{n=1}^{+\infty} A_n \rbrace\]</span></p>
<p>which also means <span class="math inline">\((A_n)\)</span> is an
<span class="math inline">\(\mathcal R-\)</span>cover of <span class="math inline">\(T\)</span>. Then <span class="math inline">\(\mu^*\)</span> is an outer-measure on <span class="math inline">\(\Omega\)</span>, derived from the measure <span class="math inline">\(\mu\)</span> on <span class="math inline">\(\mathcal R\)</span>, and <span class="math inline">\(\mu^* | _{\mathcal R} = \mu\)</span>.</p>
<p><strong>Proof</strong>:</p>
<ul>
<li><p>Take <span class="math inline">\(T=\emptyset\)</span>, <span class="math inline">\(A_n = \emptyset\)</span> for each <span class="math inline">\(n \in \mathbb Z+\)</span>, then <span class="math inline">\((A_n)_{n\geq 1}\)</span> is an <span class="math inline">\(\mathcal R -\)</span>cover of <span class="math inline">\(T\)</span>. It follows that <span class="math inline">\(0 \leq \mu^*(T) \leq 0\)</span>, then <span class="math inline">\(\mu^*(T)=0\)</span>.</p></li>
<li><p>Let <span class="math inline">\(A \subseteq B \subseteq
\Omega\)</span>. Let <span class="math inline">\((B_n)_{n\geq
1}\)</span> be an <span class="math inline">\(\mathcal R-\)</span>cover
of <span class="math inline">\(B\)</span>, then it's also an <span class="math inline">\(\mathcal R-\)</span>cover of <span class="math inline">\(A\)</span>.</p>
<p><span class="math inline">\(\mu^*(A) \leq \Sigma_{i=1}^{+\infty}
\mu(B_n)\)</span> for each <span class="math inline">\(\mathcal R
-\)</span>cover of <span class="math inline">\(B\)</span>, then <span class="math inline">\(\mu^*(A) \leq \inf( \Sigma_{i=1}^{+\infty}
\mu(B_n)) = \mu^*(B)\)</span>.</p></li>
<li><p>Let <span class="math inline">\((A_n)_{n \geq 1}\)</span> be a
sequence of subsets of <span class="math inline">\(\Omega\)</span>, with
<span class="math inline">\(\mu^*(A_n) &lt;+\infty\)</span> for all
<span class="math inline">\(n \geq 1\)</span>. According to the
definition of <span class="math inline">\(\mu^*\)</span>, given <span class="math inline">\(\varepsilon &gt;0\)</span>, then for all <span class="math inline">\(n \geq 1\)</span>, there exists an <span class="math inline">\(\mathcal R-\)</span>cover <span class="math inline">\((A_n ^p)_{p\geq 1}\)</span> of <span class="math inline">\(A_n\)</span> such that <span class="math inline">\(\Sigma_{p=1} ^{+\infty} \mu(A_n^p) &lt; \mu^*(A_n)
+\frac{\varepsilon}{2^n}\)</span>.</p>
<p>For the <span class="math inline">\(\mathcal R-\)</span>covers <span class="math inline">\(\cup_{p=1}^{+\infty} A_n^p\)</span>, <span class="math inline">\(\cup_{n=1}^{+\infty} \cup_{p=1}^{+\infty}
A_n^p\)</span> is a countable set and can be reorganized as <span class="math inline">\(\cup_{k=1} ^{+\infty} R_k = \cup_{n=1}^{+\infty}
\cup_{p=1}^{+\infty} A_n^p\)</span>, while <span class="math inline">\(R_k \in \mathcal R\)</span> for each <span class="math inline">\(k \in \mathbb Z+\)</span>. Then $<em>{k=1} ^{+}
R_k = </em>{n=1}^{+} _{p=1}^{+} A_n^p $ is an <span class="math inline">\(\mathcal R -\)</span>cover for <span class="math inline">\(\cup_{n=1}^{+\infty} A_n\)</span>.</p>
<p>According to the countable additivity of <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\mu^*(\cup_{n=1}^{+\infty} A_n)\leq
\mu(\cup_{n=1}^{+\infty} A_n) \leq \Sigma_{n=1}^{+\infty} \Sigma_{p=1}
^{+\infty} \mu(A_n^p)&lt;\Sigma_{n=1} ^{+\infty} \mu^*(A_n)
+\varepsilon\)</span> holds for each <span class="math inline">\(\varepsilon &gt;0\)</span>. Thus <span class="math inline">\(\mu^*(\cup_{i=1} ^{+\infty} A_n) \leq
\Sigma_{i=1}^{+\infty} \mu^*(A_n)\)</span> holds.</p></li>
</ul>
<p>According to all the properties shown above, <span class="math inline">\(\mu^*\)</span> is an outer-measure on <span class="math inline">\(\Omega\)</span>.</p>
<p>We show that $^* $ 's restriction on <span class="math inline">\(\mathcal R\)</span> is <span class="math inline">\(\mu\)</span> below.</p>
<ul>
<li><p>Let <span class="math inline">\(A \in \mathcal R\)</span>, <span class="math inline">\((A_n)_{n \geq 1}\)</span> be an <span class="math inline">\(\mathcal R-\)</span>cover of <span class="math inline">\(A\)</span> and put <span class="math inline">\(B_1
= A_1 \cap A\)</span>, and <span class="math inline">\(B_{n+1}
\triangleq (A_{n+1}\cap A) \setminus ((A_1 \cap A) \cup ...\cup (A_n
\cap A) )\)</span>. Thus, <span class="math inline">\((B_n)_{n \geq
1}\)</span> is a sequence of pairwise disjoint elements in <span class="math inline">\(\mathcal R\)</span>, and <span class="math inline">\(A = \uplus_{n=1} ^{+\infty} B_n\)</span>.</p>
<p>It's trivial that <span class="math inline">\(\mu^*(A) \leq
\mu(A)\)</span> cause <span class="math inline">\(A\)</span> is an <span class="math inline">\(\mathcal R-\)</span>cover of itself.On the other
hand, $(A) = <em>{i=1} ^{+} (B_i ) </em>{i=1} ^{+} (A_i) $ holds for
each <span class="math inline">\(\mathcal R-\)</span>cover <span class="math inline">\((A_n)_{n\geq 1}\)</span> for <span class="math inline">\(A\)</span>. Thus <span class="math inline">\(\mu(A) \leq \inf(\Sigma_{i=1} ^{+\infty} \mu(A_i))
= \mu ^*(A)\)</span>, the equality <span class="math inline">\(\mu^*(A)
= \mu(A)\)</span> holds.</p></li>
</ul>
<p>This being true for all <span class="math inline">\(A \in \mathcal
R\)</span>, we have proved that <span class="math inline">\(\mu ^*|
_{\mathcal R} = \mu\)</span>.</p>
<h1 id="proposition-7-the-sigma-extension-of-a-ring-and-its-measure">Proposition
7 (the <span class="math inline">\(\sigma-\)</span>extension of a ring
and its measure)</h1>
<p><strong>Proposition 7 (the <span class="math inline">\(\sigma-\)</span>extension of a ring and its
measure)</strong>:</p>
<p>Let <span class="math inline">\(\mathcal R\)</span> be a ring on
<span class="math inline">\(\Omega\)</span> and <span class="math inline">\(\mu : \mathcal R \to [0,+\infty]\)</span> be a
measure on <span class="math inline">\(\mathcal R\)</span>. Define <span class="math inline">\(\mu^*\)</span> as the outer-measure derived from
<span class="math inline">\(\mu\)</span> in proposition 6. Then the
<span class="math inline">\(\sigma-\)</span>extension <span class="math inline">\(\sigma(\mathcal R)\)</span> of <span class="math inline">\(\mathcal R\)</span> is a subset of <span class="math inline">\(\Sigma(\mu^*)\)</span>, thus <span class="math inline">\(\mu^* |_{\sigma(\mathcal R)}\)</span> is a measure
on <span class="math inline">\(\sigma(\mathcal R)\)</span>.</p>
<p><strong>Proof</strong>:</p>
<p>We want to show that <span class="math inline">\(\sigma(\mathcal R)
\subseteq \Sigma(\mu^*)\)</span>. According to proposition 4, we know
that <span class="math inline">\(\Sigma(\mu^*)\)</span> is a <span class="math inline">\(\sigma-\)</span>algebra, so we just need to show
that <span class="math inline">\(\mathcal R \subseteq
\Sigma(\mu^*)\)</span>.</p>
<p>Let <span class="math inline">\(A \in \mathcal R\)</span> and <span class="math inline">\(T\subseteq \Omega\)</span>. According to the third
property of outer measure <span class="math inline">\(\mu^*\)</span>,
there is <span class="math inline">\(\mu^*(T) \leq \mu^* (T\cap A)+\mu^*
(T\cap A^C)\)</span>.</p>
<p>Let <span class="math inline">\((T_n)_{n \geq 1}\)</span> be an <span class="math inline">\(\mathcal R-\)</span>cover of <span class="math inline">\(T\)</span>, then <span class="math inline">\((T_n
\cap A)_{n \geq 1}\)</span> and <span class="math inline">\((T_n \cap
A^C)\)</span> are <span class="math inline">\(\mathcal R-\)</span>covers
of <span class="math inline">\(T\cap A\)</span> and <span class="math inline">\(T \cap A^C\)</span> respectively. There is</p>
<p><span class="math display">\[\mu^*(T\cap A) +\mu^*(T\cap A^C)\leq
\Sigma_{n=1} ^{+\infty} \mu(T_n \cap A)+ \Sigma_{n=1} ^{+\infty} \mu(T_n
\cap A^C) = \Sigma_{n=1}^{+\infty}\mu(T_n)\]</span></p>
<p>holds for each <span class="math inline">\(\mathcal R-\)</span>cover
<span class="math inline">\((T_n)_{n \geq 1}\)</span>, thus <span class="math inline">\(\mu^*(T)=\inf(\Sigma_{n=1}^{+\infty}\mu(T_n)) \leq
\mu^*(T\cap A) +\mu^*(T\cap A^C)\leq \mu^*(T)\)</span>, the equalty
meets.Then it leads to <span class="math inline">\(\mu^*(T) =
\mu^*(T\cap A)+\mu^*(T\cap A^C)\)</span> holds for any <span class="math inline">\(T \subseteq \Omega\)</span>, thus <span class="math inline">\(A \in \Sigma(\mu^*)\)</span>.</p>
<p>This being true for all <span class="math inline">\(A \in \mathcal
R\)</span>, thus <span class="math inline">\(\mathcal R \subseteq
\Sigma(\mu^*)\)</span>.</p>
<h1 id="proposition-8-the-structure-of-the-sigma-extension-of-a-semi-ring">Proposition
8 (the structure of the <span class="math inline">\(\sigma-\)</span>extension of a semi-ring)</h1>
<p><strong>Proposition 8 (the structure of the <span class="math inline">\(\sigma-\)</span>extension of a
semi-ring)</strong>:</p>
<p>Assume that <span class="math inline">\(\mathcal S\)</span> is a
semi-ring, its <span class="math inline">\(\sigma-\)</span>extension is
<span class="math inline">\(\sigma(\mathcal S)\)</span>. Then <span class="math inline">\(\sigma(\mathcal S) = \sigma(\mathcal R(\mathcal
S))\)</span>.</p>
<p><strong>Proof</strong>:</p>
<p>According to definition 3, we have <span class="math inline">\(\mathcal S \subseteq \mathcal R(\mathcal S)
\subseteq \sigma(\mathcal R(\mathcal S))\)</span>, thus <span class="math inline">\(\sigma(\mathcal S) \subseteq \sigma(\mathcal
R(\mathcal S))\)</span>.</p>
<p>Moreover, <span class="math inline">\(\mathcal R(S)\)</span> is the
set of all finite unions of elements of <span class="math inline">\(\mathcal S\)</span>, then <span class="math inline">\(\mathcal R(\mathcal S) \subseteq \sigma(\mathcal
S)\)</span>. Consequently <span class="math inline">\(\sigma(\mathcal
R(\mathcal S)) \subseteq \sigma(\mathcal S)\)</span>.</p>
<p>Finally, we have proved that <span class="math inline">\(\sigma(\mathcal S) = \sigma(\mathcal R(\mathcal
S))\)</span>.</p>
<h1 id="theorem-1-carathéodorys-extension-theorem">Theorem 1
(Carathéodory’s Extension Theorem)</h1>
<p><strong>Theorem 1 (Carathéodory’s Extension Theorem)</strong>:</p>
<p>Assume that <span class="math inline">\(\mathcal S\)</span> is a
semi-ring, <span class="math inline">\(\mu : \mathcal S \to
[0,+\infty]\)</span> is a <span class="math inline">\(\sigma-\)</span>additive function on <span class="math inline">\(\mathcal S\)</span>. Then:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> has an extension measure
<span class="math inline">\(\mu^*\)</span> on <span class="math inline">\(\sigma(\mathcal S)\)</span>.</li>
<li>If the <span class="math inline">\(\mu\)</span> is <span class="math inline">\(\sigma-\)</span>finite, then the extension measure
is unique.</li>
</ul>
<p><strong>Proof</strong>:</p>
<ol type="1">
<li></li>
</ol>
<ul>
<li><p>First to show that <span class="math inline">\(\mu\)</span> is a
measure on semi-ring <span class="math inline">\(\mathcal
S\)</span>.</p>
<p>The <span class="math inline">\(\sigma-\)</span>additivity meets the
second property of measure, so we just need to prove that <span class="math inline">\(\mu(\emptyset)=0\)</span>. Take <span class="math inline">\(A_1 \in \mathcal S\)</span> as a non-empty set,
and <span class="math inline">\(A_2 =A_3 =...=\emptyset\)</span>.</p>
<p>According to the <span class="math inline">\(\sigma-\)</span>additivity of <span class="math inline">\(\mu\)</span>, there is <span class="math inline">\(\mu(\cup_{i=1}^{+\infty} A_i) = \mu(A_1) =
\Sigma_{i=1} ^{+\infty} \mu(A_i)\)</span>, thus <span class="math inline">\(\mu(\emptyset) = 0\)</span>.</p></li>
<li><p>According to proposition 1 and 2, we can extend semi-ring <span class="math inline">\(\mathcal S\)</span> to ring <span class="math inline">\(\mathcal R(\mathcal S)\)</span> and extend measure
<span class="math inline">\(\mu\)</span> on <span class="math inline">\(\mathcal S\)</span> to measure <span class="math inline">\(\bar{\mu}\)</span> on ring <span class="math inline">\(\mathcal R(\mathcal S)\)</span>, which can keep
<span class="math inline">\(\bar{\mu} | _{\mathcal S} =
\mu\)</span>.</p>
<p>From proposition 6, we can extend the measure <span class="math inline">\(\bar{\mu}\)</span> on ring <span class="math inline">\(\mathcal R(\mathcal S)\)</span> to the
outer-measure <span class="math inline">\(\mu^*\)</span> on set <span class="math inline">\(\Omega\)</span>, which keeps <span class="math inline">\(\mu^*|_{\mathcal R(\mathcal S)} =
\bar{\mu}\)</span>.</p>
<p>From proposition 4 and 5, we can find the <span class="math inline">\(\sigma-\)</span>algebra <span class="math inline">\(\Sigma(\mu^*)\)</span> associated with the
outer-measure <span class="math inline">\(\mu^*\)</span> on <span class="math inline">\(\Omega\)</span>. Also, the outer-measure <span class="math inline">\(\mu^*\)</span> on <span class="math inline">\(\Omega\)</span> is the measure on the <span class="math inline">\(\sigma-\)</span>algebra <span class="math inline">\(\Sigma(\mu^*)\)</span>, which means $^*| _{(^*)} $
is a measure.</p>
<p>According to proposition 7 and 8, the <span class="math inline">\(\sigma-\)</span>extension of the semi-ring <span class="math inline">\(\sigma(\mathcal S)=\sigma(\mathcal R(\mathcal S)
)\subseteq \Sigma(\mu^*)\)</span>, and $^*| _{(S)}=^*| _{(R(S) )} $ is
the measure on <span class="math inline">\(\sigma(\mathcal R(\mathcal S)
)\)</span>. At the same time, <span class="math inline">\(\mu^*|
_{\mathcal S} = \bar{\mu} |_{\mathcal S} = \mu\)</span>.</p></li>
</ul>
<p>We have extended the semi-ring <span class="math inline">\(\mathcal
S\)</span> to the <span class="math inline">\(\sigma-\)</span>algebra
<span class="math inline">\(\sigma(\mathcal S)\)</span>, and the <span class="math inline">\(\sigma-\)</span>additive function <span class="math inline">\(\mu\)</span> to the measure <span class="math inline">\(\mu^*| _{\sigma(\mathcal S)}\)</span>.</p>
<ol start="2" type="1">
<li></li>
</ol>
<p>As <span class="math inline">\(\mu\)</span> is <span class="math inline">\(\sigma-\)</span>finite and <span class="math inline">\(\mathcal S\)</span> is a semi-ring, we have <span class="math inline">\(\Omega = \uplus_{n=1}^{+\infty} A_n\)</span>,
<span class="math inline">\(A_n \in \mathcal S\)</span> and <span class="math inline">\(\mu(A_n) &lt;+\infty\)</span>. We want to prove
that <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\mu_2\)</span> are two measures on <span class="math inline">\(\sigma(\mathcal S)\)</span> and <span class="math inline">\(\mu_1 |_{\mathcal S} = \mu_2 |_{\mathcal S} =
\mu\)</span>, then <span class="math inline">\(\mu_1=\mu_2\)</span>.</p>
<p>Define <span class="math inline">\(\mathcal G = \lbrace A \in
\sigma(\mathcal S) : \mu_1(A_n \cap A) = \mu_2(A_n \cap A),\forall n \in
\mathbb Z+ \rbrace\)</span>, it's easy to show that <span class="math inline">\(\mathcal S \subseteq \mathcal G\)</span>. We'd
like to show that <span class="math inline">\(\mathcal G\)</span> is a
<span class="math inline">\(\sigma-\)</span>algebra, thus <span class="math inline">\(\sigma(\mathcal S) \subseteq \mathcal G\)</span>,
then there will be <span class="math inline">\(\mu_1 | _{\sigma(\mathcal
S)} = \mu_2 | _{\sigma(\mathcal S)}\)</span>, which means <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\mu_2\)</span> are the same on <span class="math inline">\(\sigma(\mathcal S)\)</span>.</p>
<p>Suppose <span class="math inline">\(B_k \in \mathcal G\)</span>, for
any <span class="math inline">\(k \in \mathbb N\)</span> there is <span class="math inline">\(B_k \subset B_{k+1}\)</span> and <span class="math inline">\(B_k \uparrow B\)</span>, then for each <span class="math inline">\(n\)</span>,</p>
<p><span class="math display">\[ \mu_1(B \cap A_n) = \lim _{k} \uparrow
\mu_1(B_k \cap A_n) =\lim_{k} \uparrow \mu_2(B_k \cap A_n) = \mu_2(B
\cap A_n)\]</span></p>
<p>thus <span class="math inline">\(B \in \mathcal G\)</span>. Similarly
for <span class="math inline">\(C_k \downarrow C\)</span>,<span class="math inline">\(C_k \in \mathcal G\)</span>, there is <span class="math inline">\(C \in \mathcal G\)</span>. Then <span class="math inline">\(\mathcal G\)</span> is closed for increasing and
decreasing limits, $G $ is a monotone class.</p>
<p>Moreover, for <span class="math inline">\(K \in \mathcal G\)</span>,
there is <span class="math inline">\(K^C \in \mathcal G\)</span>; for
<span class="math inline">\(A,B \in \mathcal G\)</span> and <span class="math inline">\(A \subset B\)</span>, there is <span class="math inline">\(B-A \in \mathcal G\)</span>; <span class="math inline">\(\Omega \in \mathcal G\)</span>. These properties
indicates <span class="math inline">\(\mathcal G\)</span> is a <span class="math inline">\(\lambda-\)</span>system, while <span class="math inline">\(\mathcal S\)</span> is a <span class="math inline">\(\pi-\)</span>system and <span class="math inline">\(\mathcal S \subset \mathcal G\)</span>, thus <span class="math inline">\(\sigma(\mathcal S) \subseteq \mathcal G\)</span>.
Then we've proved that <span class="math inline">\(\mu_1 |
_{\sigma(\mathcal S)} = \mu_2 | _{\sigma(\mathcal S)}\)</span>, the
extended measure on <span class="math inline">\(\sigma(\mathcal
S)\)</span> is unique.</p>
<h1 id="summary-of-the-whole-story">Summary of the whole story</h1>
<p>太抽象了，但我还是想把这个图发出来：</p>
<p><img src="https://s2.loli.net/2023/03/16/JmU19EyKPkchDqg.jpg" alt="roadmap.jpg"></p>
<p>Q.E.D.!</p>
]]></content>
      <tags>
        <tag>这里面看起来很好玩</tag>
        <tag>数学</tag>
        <tag>概率</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论 (1) 期末考点啥</title>
    <url>/2023/05/12/Probability-Theory-I-Final-2023-Spring/</url>
    <content><![CDATA[<p>不想存一堆照片复习还要靠翻相册，只是写在纸上的话又总是弄丢，<del>为什么不写到摸鱼学导论上呢</del>，<del>水一篇吧</del></p>
<p>被这学期突然增加的期中整怕了，lzx
的题不背一下的话还真不是每个都好做。</p>
<span id="more"></span>
<p>不知道为什么但是免责声明一下：仅供参考，记了但是没考 /
考了但是没记到的话跟我没关系，我期中后连早八都一节不漏的在上，属于是真的尽力了（</p>
<p>另外我的常用记号有一些和 lzx 不一样但其实应该更标准 /
普遍，比如我认为分布函数是右连续的，<span class="math inline">\(F_X(x) =
\mathbb P( X \leq x)\)</span>，<span class="math inline">\(n\)</span>
元正态分布的符号写作 <span class="math inline">\(N_n(\mu,
\Sigma)\)</span> 而非 <span class="math inline">\(N(\vec{a},B)\)</span>，等等。</p>
<!--顺便用这一篇捞一下一位天天咕咕不来和我贴贴的哥们儿（x，不过在班级同学面前贴可能还是羞耻了一点（，虽然我谁都不认识所以倒是完全不介意（-->
<h1 id="多元正态分布">多元正态分布</h1>
<p><del>我认为以下三个问题都很 trivial</del></p>
<h2 id="统计推断经典问题">统计推断经典问题</h2>
<p>据说有 <span class="math inline">\(\frac 2 3\)</span>
的可能性期末会考，这很概率论（</p>
<p>对于 $X_1, X_2, ..., X_n $ i.i.d. <span class="math inline">\(\sim
N(a,\sigma^2)\)</span>，记 <span class="math inline">\(\bar X =
\frac{1}{n} \Sigma_{i=1} ^n X_i\)</span>，<span class="math inline">\(S_n ^2 =\frac{1}{n-1} \Sigma_{i=1} ^n (X_i - \bar
X)^2\)</span>，证明：</p>
<ul>
<li><p><span class="math inline">\(\bar X\)</span> 和 $S_n ^2 $
独立；</p></li>
<li><p><span class="math inline">\(\bar X \sim N(a,
\frac{\sigma^2}{n})\)</span>；</p></li>
<li><p><span class="math inline">\(\frac{(n-1)S_n ^2}{\sigma ^2} \sim
\chi^2 (n-1)\)</span>。</p></li>
</ul>
<p><strong>Proof:</strong></p>
<ul>
<li><p>取多元正态分布 <span class="math inline">\(X = (X_1 , X_2 ,...,
X_n) ^T \sim N_n(\mu, \Sigma)\)</span>，其中 <span class="math inline">\(\mu = (a,a,...,a)^T,\Sigma = \sigma ^2 I_{n \times
n}\)</span>。</p>
<p>记 <span class="math inline">\(C = \begin{bmatrix} \frac{1}{\sqrt n}
&amp; \frac{1}{\sqrt n} &amp; ... &amp; \frac{1}{\sqrt n} \\ * &amp; *
&amp;... &amp; * \\ ... &amp; ... &amp; ... &amp; ... \\ * &amp; * &amp;
... &amp; * \end{bmatrix}\)</span>，适当取其余元素使得 <span class="math inline">\(C\)</span> 是一个正交阵，满足 <span class="math inline">\(C^TC = CC^T = I_{n \times n}\)</span>，</p>
<p>取 <span class="math inline">\(Y = (Y_1, Y_2,...,Y_n)^T = C X \sim
N_n (C \mu , C \Sigma C^T)\)</span>，注意到 <span class="math inline">\(C \mu = (\sqrt n a ,0,0,...,0)^T, C\Sigma C^T =
\sigma^2 I_{n \times n}\)</span>，因此有 <span class="math inline">\(Y_1
, Y_2, ..., Y_n\)</span> 相互独立，<span class="math inline">\(Y_1 \sim
N(\sqrt n a,\sigma^2)\)</span>，<span class="math inline">\(Y_2,Y_3,...,Y_n\)</span> i.i.d. <span class="math inline">\(\sim N(0,\sigma^2)\)</span>。</p>
<p>将 <span class="math inline">\(\bar X\)</span> 和 <span class="math inline">\(S_n\)</span> 表示为 <span class="math inline">\(\{Y_i \}\)</span> 的组合：</p>
<p><span class="math display">\[\bar X = \frac 1 n \Sigma_{i=1}^n X_i
=\frac{1}{ \sqrt n} Y_1\]</span></p>
<p><span class="math display">\[(n-1)S_n = \Sigma_{i=1} ^n X_i^2 - n
\bar X ^2 = X^TX - n \bar X^2 = X^TC^TCX - n \bar X^2 =Y^TY - Y_1 ^2 =
\Sigma_{i=1}^n Y_i^2 - Y_1 ^2 = \Sigma_{i=2}^n Y_i ^2 \]</span></p>
<p>由 <span class="math inline">\(Y_1 , Y_2, ..., Y_n\)</span>
相互独立可知 <span class="math inline">\(\frac{1}{\sqrt n} Y_1\)</span>
和 <span class="math inline">\(\Sigma_{i=2} ^n Y_i ^2\)</span>
相互独立，因此有 <span class="math inline">\(\bar X\)</span> 和 <span class="math inline">\(S_n\)</span> 独立。</p></li>
<li><p><span class="math inline">\(\bar X = \frac 1 n \Sigma_{i=1} ^n
X_i = \begin{bmatrix} \frac 1 n &amp; \frac 1 n &amp; ... &amp; \frac 1
n \end{bmatrix} \begin{bmatrix} X_1 \\ X_2 \\ ... \\ X_n \end{bmatrix} =
\frac 1 n \mathbb 1_n^T X \sim N(\frac 1 n \mathbb 1_n^T \mu, \frac 1 n
\mathbb 1^T_n \Sigma \frac 1 n \mathbb 1_n ) =
N(a,\frac{\sigma^2}{n})\)</span></p></li>
<li><p>在第一问的证明中已经得到<span class="math inline">\((n-1)S_n =
\Sigma_{i=2}^n Y_i ^2\)</span>，且 <span class="math inline">\(Y_2,Y_3,...,Y_n\)</span> i.i.d. <span class="math inline">\(\sim N(0,\sigma^2)\)</span>，因此有：</p>
<p><span class="math display">\[\frac{Y_2}{\sigma},\frac{Y_3}{\sigma},...,\frac{Y_n}{\sigma}
\text{i.i.d.} \sim N(0,1)\]</span></p>
<p><span class="math display">\[\frac{(n-1)S_n}{\sigma^2} =
\Sigma_{i=2}^n (\frac{Y_i}{\sigma})^2 \sim \chi^2(n-1)\]</span></p></li>
</ul>
<p><strong>Remark:</strong> 实际上就是中文教材上的定理
3.5.11，书上那个做法和我在统计推断课上学到的是一样的，但是写起来不如这个漂亮。<del>另外
lzx 在课上用的也是这个方法，或许考试也是写这个最好</del></p>
<h2 id="多元正态分布的计算问题">多元正态分布的计算问题</h2>
<p><span class="math inline">\(X = (X_1,X_2,X_3)^T \sim N_3(\mu,
\Sigma)\)</span> 服从 <span class="math inline">\(3\)</span>
元正态分布，其中 <span class="math inline">\(\mu = \begin{bmatrix} 1 \\
2 \\ 3 \end{bmatrix}\)</span>，<span class="math inline">\(\Sigma =
\begin{bmatrix} 4 &amp; 2 &amp; -2 \\ 2 &amp; 10 &amp;2 \\ -2 &amp;2
&amp;5 \end{bmatrix}\)</span>，求：</p>
<ul>
<li><span class="math inline">\(\mathbb E(X_1 - 2X_2 + X_3 | X_1 + X_2 +
X_3)\)</span></li>
<li><span class="math inline">\(Var(X_1 - 2X_2 +X_3 | X_1 + X_2 +
X_3)\)</span></li>
</ul>
<p><strong>Solution:</strong></p>
<p>记</p>
<p><span class="math display">\[\begin{bmatrix} U  \\ V \end{bmatrix}=
\begin{bmatrix}X_1 - 2X_2 +X_3 \\ X_1 +X_2+X_3 \end{bmatrix} =
\begin{bmatrix} 1 &amp; -2 &amp; 1 \\ 1 &amp; 1 &amp;1 \end{bmatrix}
\begin{bmatrix} X_1 \\ X_2 \\ X_3 \end{bmatrix}  = CX \sim N_2(C\mu,
C\Sigma C^T)\]</span></p>
<p>其中</p>
<p><span class="math display">\[C\mu = \begin{bmatrix} 1 &amp; -2 &amp;
1 \\ 1 &amp; 1 &amp;1 \end{bmatrix} \begin{bmatrix} 1 \\ 2\\ 3
\end{bmatrix} = \begin{bmatrix} 0 \\6 \end{bmatrix}\]</span></p>
<p><span class="math display">\[C\Sigma C^T = \begin{bmatrix} 1 &amp; -2
&amp; 1 \\ 1 &amp; 1 &amp;1 \end{bmatrix} \begin{bmatrix} 4 &amp; 2
&amp; -2  \\ 2 &amp; 10 &amp;2 \\ -2 &amp;2 &amp;5 \end{bmatrix}
\begin{bmatrix} 1 &amp; 1 \\ -2 &amp; 1 \\ 1 &amp; 1 \end{bmatrix}
=\begin{bmatrix}  29 &amp; -19 \\ -19 &amp; 23\end{bmatrix}\]</span></p>
<p>对于二元正态分布 <span class="math inline">\(\begin{bmatrix} U \\ V
\end{bmatrix} \sim N_2(\begin{bmatrix} \mu_1 \\ \mu_2 \end{bmatrix},
\begin{bmatrix} \sigma_1 ^2 &amp; r\sigma_1 \sigma_2 \\ r\sigma_1
\sigma_2 &amp; \sigma_2 ^2 \end{bmatrix})\)</span> 有结论</p>
<p><span class="math display">\[\mathbb E(U|V=v) = \mu_1 + r
\frac{\sigma_1}{\sigma_2} (v-\mu_2)\]</span></p>
<p><span class="math display">\[Var(U|V) = \sigma_1 ^2
(1-r^2)\]</span></p>
<p>代入可知 <span class="math inline">\(\mathbb E(U|V) =
-\frac{19}{23}(X_1 + X_2 + X_3 -6)\)</span>，<span class="math inline">\(Var(U|V) = \frac{306}{23}\)</span>。</p>
<p><strong>Remark 1:</strong>
我也不知道我算对了没有，反正考试也会改数字的，不管了（</p>
<p><strong>Remark 2:</strong>
事实上我不喜欢这个做法，用二元正态分布的性质这个操作并不够本质，我还以为
lzx 会在课上讲下面这个定理，但他也没讲，<del>好失望</del>。写一个对
<span class="math inline">\(p_1 + p_2\)</span>
维正态分布来说都正确的定理在这里好了。<del>展现底力的时候到了</del></p>
<p><strong>Lemma:</strong> 对于 <span class="math inline">\(p_1 +
p_2\)</span> 元正态分布 <span class="math inline">\(\begin{bmatrix}X_1
\\ X_2 \end{bmatrix} \sim N_{p_1 + p_2}(\begin{bmatrix}\mu_1 \\ \mu_2
\end{bmatrix}, \begin{bmatrix} \Sigma_{11} &amp; \Sigma_{12} \\
\Sigma_{21} &amp; \Sigma_{22} \end{bmatrix}) = N_p(\mu,
\Sigma)\)</span>，注意此处 <span class="math inline">\(X_1,X_2\)</span>
分别是 <span class="math inline">\(p_1,p_2\)</span> 元正态分布，则有
<span class="math inline">\(X_1\)</span> 的条件分布为：</p>
<p><span class="math display">\[X_1|_{X_2 = x_2} \sim N(\mu_1
+\Sigma_{21} \Sigma_{22}^{-1} (x_2 - \mu_2),\Sigma_{11} - \Sigma_{12 }
\Sigma_{22}^{-1} \Sigma_{21})\]</span></p>
<p><strong>Proof:</strong></p>
<p>取 <span class="math inline">\(C = \begin{bmatrix} I_{p_1 \times p_1}
&amp; -\Sigma_{12} \Sigma_{22}^{-1} \\ 0_{p_2 \times p_1} &amp; I_{p_2
\times p_2}\end{bmatrix}\)</span>，记 <span class="math inline">\(\begin{bmatrix}Y_1 \\ Y_2 \end{bmatrix} = C
\begin{bmatrix} X_1 - \mu_1 \\ X_2 - \mu_2 \end{bmatrix} \sim N_{p_1 +
p_2}(0,C\Sigma C^T)\)</span>，注意到：</p>
<p><span class="math display">\[C\Sigma C^T = \begin{bmatrix} I_{p_1
\times p_1} &amp; -\Sigma_{12} \Sigma_{22}^{-1} \\ 0_{p_2 \times
p_1}  &amp; I_{p_2 \times p_2}\end{bmatrix} \begin{bmatrix} \Sigma_{11}
&amp; \Sigma_{12} \\ \Sigma_{21} &amp; \Sigma_{22} \end{bmatrix}
\begin{bmatrix} I_{p_1 \times p_1} &amp; 0_{p_1 \times p_2} \\
-\Sigma_{22}^{-1} \Sigma_{21}  &amp; I_{p_2 \times p_2}\end{bmatrix} =
\begin{bmatrix} \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}
&amp; 0 \\ 0 &amp; \Sigma_{22} \end{bmatrix}\]</span></p>
<p>因此有：</p>
<p><span class="math display">\[Y_1 = (X_1 - \mu_1) - \Sigma_{12}
\Sigma_{22}^{-1} (X_2 - \mu_2) \sim N_{p_1} (0,\Sigma_{11}-\Sigma_{12}
\Sigma_{22}^{-1} \Sigma_{21})\]</span></p>
<p>于是 <span class="math inline">\(X_1\)</span> 的条件分布为 <span class="math inline">\(X_1|_{X_2 = x_2} \sim N(\mu_1 +\Sigma_{21}
\Sigma_{22}^{-1} (x_2 - \mu_2),\Sigma_{11} - \Sigma_{12 }
\Sigma_{22}^{-1} \Sigma_{21})\)</span>，得证。</p>
<p><strong>Remark 3</strong>: 据说这个题占 10
分，大概是说会作为半个题出现？</p>
<h2 id="多元正态分布的反例">多元正态分布的反例</h2>
<p>我们知道 <span class="math inline">\(X = (X_1 , X_2,...,X_n) ^T \sim
N_n(\mu, \Sigma) \iff \forall a \in \mathbb R ^n, Y= a^TX \sim N(a^T
\mu, a^T \Sigma a)\)</span>。</p>
<p>那么是否有对于任意的一元正态分布 <span class="math inline">\(X_k \sim
N(\mu_k , \sigma_k ^2)\)</span>，均可推出 <span class="math inline">\(X
= (X_1, X_2,...,X_n)^T \sim N_n(\mu, \Sigma)\)</span>？换言之，任意
<span class="math inline">\(n\)</span>
个服从一元正态分布的随机变量组合成的随机向量是否一定服从 <span class="math inline">\(n\)</span> 元正态分布？</p>
<p><strong>Solution:</strong> 答案是否定的，以下构造反例：</p>
<p>对于 <span class="math inline">\(X,Y\)</span> i.i.d.<span class="math inline">\(\sim N(0,1)\)</span>，记 <span class="math inline">\(Z = \begin{cases} |Y| , \quad X \geq 0 \\ -|Y|
\quad X &lt;0\end{cases}\)</span>，于是有 <span class="math inline">\(Z
\sim N(0,1)\)</span>。这是因为：</p>
<p><span class="math display">\[\begin{aligned} \forall x &gt;0 , F_Z(x)
= \mathbb P(Z \leq x )&amp; =\mathbb P(Z \leq x, X &lt;0) + \mathbb P(Z
\leq x , X \geq 0) \\ &amp;=\mathbb P(X &lt; 0)\mathbb P(Z\leq x |
X&lt;0) +\mathbb P(X \geq 0 )\mathbb P(Z\leq x | X \geq 0) \\&amp;=
\frac 1 2 +\frac 1 2 \mathbb P(Z\leq x|X\geq 0) \\&amp;= \frac 1 2 +
\frac 1 2 \mathbb P(-x \leq Y \leq x) \\ &amp;=\frac 1 2 + \frac 1 2
\mathbb P(0 &lt; Y \leq x) \\ &amp;= \mathbb P(Y \leq x) = \Phi(x)
\end{aligned}\]</span></p>
<p>其中 <span class="math inline">\(\Phi(x)\)</span>
指标准正态分布的分布函数。同理 <span class="math inline">\(\forall x
\leq 0\)</span> 也有 <span class="math inline">\(F_Z(x) =
\Phi(x)\)</span>，因此 <span class="math inline">\(Z \sim
N(0,1)\)</span>。</p>
<p>以下证明即使有 <span class="math inline">\(Z,Y \sim
N(0,1)\)</span>，但 <span class="math inline">\(\begin{bmatrix}Z \\ Y
\end{bmatrix}\)</span> 不服从二元正态分布。否则若有 <span class="math inline">\(\begin{bmatrix}Z \\ Y \end{bmatrix}\)</span>
服从二元正态分布，则 <span class="math inline">\(Z+Y\)</span>
服从正态分布，从而是一个连续型分布，<span class="math inline">\(\mathbb
P(Z+Y=0)=0\)</span>。事实上，</p>
<p><span class="math display">\[\begin{aligned} \mathbb P(Z+Y=0)&amp;
=\mathbb P(Z+Y=0,X\geq 0)+\mathbb P(Z+Y=0 ,X&lt;0)\\ &amp;=\mathbb
P(Z+Y=0|X\geq 0)\mathbb P(X \geq 0)+ \mathbb P(Z+Y=0 |X&lt;0) \mathbb
P(X&lt;0) \\&amp;=\frac 1 2 \mathbb P(|Y|+Y=0|X\geq 0)+\frac 1 2 \mathbb
P(-|Y|+Y=0 |X&lt;0) \\&amp;=\frac 1 2 \mathbb P(Y \leq 0)+ \frac 1
2  \mathbb P(Y&gt;0) \\&amp;= \frac 1 2 \end{aligned}\]</span></p>
<p>矛盾。因此虽然有 <span class="math inline">\(Z,Y \sim N(0,1)\)</span>
但 <span class="math inline">\(\begin{bmatrix}Z \\ Y
\end{bmatrix}\)</span> 不服从二元正态分布，反例已举出。</p>
<p><strong>Remark:</strong> 据说这个题也是 10
分，不知道是不是要和上面那个合起来出一道题。</p>
<h1 id="收敛定理">收敛定理</h1>
<h2 id="四种收敛之间的关系">四种收敛之间的关系</h2>
<p>实际上是六个小问题。（注：依分布收敛 lzx 一般都写成 <span class="math inline">\(X_n \stackrel{d}{\rightarrow}
X\)</span>，但我一般都叫它弱收敛，写作 <span class="math inline">\(X_n
\stackrel{w}{\rightarrow} X\)</span> 或者按照 Durrett 上的记号是 <span class="math inline">\(X_n \Rightarrow X\)</span>。）</p>
<ul>
<li><p><span class="math inline">\(X_n \stackrel{a.s.}{\rightarrow}
X\)</span> 可以推出 <span class="math inline">\(X_n
\stackrel{P}{\rightarrow} X\)</span></p>
<p><strong>Proof:</strong></p>
<p>这里需要用到一个引理: <span class="math inline">\(X_n
\stackrel{P}{\rightarrow} X \iff\)</span> 对 <span class="math inline">\(\{X_n \}\)</span> 的任意子序列 <span class="math inline">\(\{X_{nk} \}\)</span>，存在一个 <span class="math inline">\(\{X_{nk}\}\)</span> 的子序列 <span class="math inline">\(\{X_{nkj} \}\)</span> 满足 <span class="math inline">\(X_{nkj} \stackrel{a.s.}{\rightarrow}
X\)</span>。</p>
<p>如果 <span class="math inline">\(X_n \stackrel{a.s.}{\rightarrow}
X\)</span> 成立，则显然对 <span class="math inline">\(\{X_n \}\)</span>
的任意子序列 <span class="math inline">\(\{X_{nk}
\}\)</span>，它的任意一个子序列 <span class="math inline">\(\{X_{nkj}
\}\)</span> 也满足 <span class="math inline">\(X_{nkj}
\stackrel{a.s.}{\rightarrow} X\)</span>，因此有 <span class="math inline">\(X_n \stackrel{P}{\rightarrow}
X\)</span>。以下来证明上述的引理。</p>
<ul>
<li><p>固定一列 <span class="math inline">\(\{\varepsilon_{k}\}
\downarrow 0\)</span>，对 <span class="math inline">\(\{X_n \}\)</span>
的任意子序列 <span class="math inline">\(\{X_{nk} \}\)</span>，存在
<span class="math inline">\(n(m_k) &gt; n(m_{k-1})\)</span> 使得 <span class="math inline">\(\mathbb P(|X_{n(m_k) }-X| &gt; \varepsilon_k) &lt;
\frac{1}{2^k}\)</span> 对任意 <span class="math inline">\(k \in \mathbb
Z_+\)</span> 成立。于是有 <span class="math inline">\(\sum_{k=1}^{+\infty} \mathbb P(|X_{n(m_k)}-X| &gt;
\varepsilon_k)=1 &lt; +\infty\)</span>，由 Borel-Cantelli lemma 可知
<span class="math inline">\(\mathbb P(|X_{n(m_k)}-X| &gt; \varepsilon_k
\quad i.o.)=0\)</span>，也即 <span class="math inline">\(\{X_{n(m_k)}\}\stackrel{a.s.}{\rightarrow}
X\)</span> 是符合条件的子列，由 <span class="math inline">\(\{X_{nk}
\}\)</span> 的任意性可知充分性成立。</p></li>
<li><p>如果对 <span class="math inline">\(\{X_n\}\)</span> 的子序列
<span class="math inline">\(\{X_{nk} \}\)</span> 总存在它的子序列 <span class="math inline">\(\{X_{nkj}\} \stackrel{a.s.}{\rightarrow}
X\)</span>，固定 <span class="math inline">\(\delta
&gt;0\)</span>，考虑数列 <span class="math inline">\(y_n = \mathbb
P(|X_n-X| &gt; \delta)\)</span>。也就是说，对 <span class="math inline">\(\{y_n \}\)</span> 的任意子序列 <span class="math inline">\(\{y_{nk}\}\)</span> 总存在它的子序列满足 <span class="math inline">\(\{y_{nkj}\} \to 0\)</span>，因此有 <span class="math inline">\(\{y_n\} \to 0\)</span>，也即 <span class="math inline">\(\lim_{n \to \infty} \mathbb P(|X_n - X| &gt;
\delta) =0\)</span>，<span class="math inline">\(X_n
\stackrel{P}{\rightarrow} X\)</span>。</p>
<p>（注：否则有 <span class="math inline">\(\{y_n \}\)</span> 不收敛到
<span class="math inline">\(0\)</span>，存在它的一个子序列 <span class="math inline">\(\{y_{ns}\}\)</span> 收敛到 <span class="math inline">\(c \neq 0\)</span>，因此 <span class="math inline">\(\{y_{ns}\}\)</span> 的任意子序列也都收敛到 <span class="math inline">\(c \neq 0\)</span>，这与题设矛盾。）</p></li>
</ul>
<p>引理得证，随即有 <span class="math inline">\(X_n
\stackrel{a.s.}{\rightarrow} X\)</span> 可以推出 <span class="math inline">\(X_n \stackrel{P}{\rightarrow}
X\)</span>。</p></li>
<li><p><span class="math inline">\(X_n \stackrel{P}{\rightarrow}
X\)</span> 不能推出 <span class="math inline">\(X_n
\stackrel{a.s.}{\rightarrow}X\)</span></p>
<p><strong>Counterexample</strong>: 取 <span class="math inline">\(\Omega=[0,1), \mathcal F = \mathcal B
(\Omega)\)</span>，概率测度 <span class="math inline">\(\mathbb
P\)</span> 即为 <span class="math inline">\(\Omega\)</span> 上的
Lebesgue 测度。</p>
<p>取 <span class="math inline">\(X_{11}(\omega) = 1\)</span>, <span class="math inline">\(X_{21}(\omega) = \begin{cases}1 \quad \omega \in
[0,\frac 1 2) \\ 0 \quad \omega \in [\frac 1 2 , 1) \end{cases},
X_{22}(\omega) = \begin{cases}0 \quad \omega \in [0,\frac 1 2) \\ 1
\quad \omega \in [\frac 1 2 , 1) \end{cases}\)</span>, 以此类推。</p>
<p>也即，对 <span class="math inline">\(\forall k \in \mathbb
Z^+\)</span>，取 <span class="math inline">\(X_{ki} (\omega) =
\begin{cases}1 \quad \omega \in [\frac{i-1}{k} ,\frac i k) \\ 0 \quad
\text{otherwise} \end{cases} , i = 1,2,...,k\)</span></p>
<p>于是有 <span class="math inline">\(\{ X_{ki}\}\)</span>
是一族可数随机变量列，将其重新排列为 <span class="math inline">\(\{ Y_i
\}_{i=1} ^{+\infty}\)</span> 使得 <span class="math inline">\(Y_1 =
X_{11}, Y_2 = X_{21}, Y_{3} = X_{22},...\)</span> ,以下说明 <span class="math inline">\(Y_n \stackrel{P}{\rightarrow} 0\)</span> 但 <span class="math inline">\(Y_n \stackrel{a.s.}{\rightarrow} 0\)</span>
不成立。</p>
<p>事实上对 <span class="math inline">\(\forall \varepsilon
&gt;0\)</span>，<span class="math inline">\(\mathbb P(|X_{ki} - 0| &gt;
\varepsilon) = \mathbb P(X_{ki} =1) = \frac 1 k\)</span>, <span class="math inline">\(\lim _{n \to \infty} \mathbb P(|Y_n - 0 | &gt;
\varepsilon) =0\)</span>，因此有 <span class="math inline">\(Y_n
\stackrel{P}{\rightarrow} 0\)</span>；</p>
<p>然而对于 <span class="math inline">\(\forall k \in \mathbb
Z^+\)</span>，总存在 <span class="math inline">\(n_1, n_2 &gt;
k\)</span> 使得对 <span class="math inline">\(\forall \omega \in
[0,1)\)</span>，有 <span class="math inline">\(Y_{n_1} (\omega) =1,
Y_{n_2} (\omega) = 0\)</span>。因此 <span class="math inline">\(\mathbb
P(\lim_{n \to \infty} |Y_n(\omega) -0 | =0 )=0\)</span> 对任意的 <span class="math inline">\(\omega \in [0,1)\)</span> 成立，即 <span class="math inline">\(\{Y_n \}_{n=1} ^{+\infty}\)</span>
在任意点处都不收敛到 <span class="math inline">\(0\)</span>，<span class="math inline">\(Y_n \stackrel{a.s.}{\rightarrow} 0\)</span>
不成立。</p></li>
<li><p><span class="math inline">\(X_n \stackrel{L^p}{\rightarrow}
X\)</span> 可以推出 <span class="math inline">\(X_n
\stackrel{P}{\rightarrow} X\)</span></p>
<p><strong>Proof</strong>: 由 Markov 不等式，<span class="math inline">\(\mathbb P(\omega : |X_n(\omega) - X(\omega)| &gt;
\varepsilon) \leq \frac{\mathbb E |X_n(\omega) -
X(\omega)|^p}{\varepsilon ^p}\)</span> 对 <span class="math inline">\(\forall \varepsilon &gt;0\)</span> 成立。</p>
<p>当 <span class="math inline">\(X_n \stackrel{L^p}{\rightarrow}
X\)</span> 时有 <span class="math inline">\(\lim _{n \to \infty} \mathbb
E|X_n(\omega) - X(\omega)|^p =0\)</span>，也即对任意的 <span class="math inline">\(\delta &gt;0 , \varepsilon &gt;0\)</span>，存在
<span class="math inline">\(N \in \mathbb Z^+\)</span> 使得 <span class="math inline">\(n&gt;N\)</span> 时有 <span class="math inline">\(\mathbb E|X_n (\omega) - X(\omega)|^p \leq \delta
\varepsilon ^p\)</span>，于是 <span class="math inline">\(n &gt;
N\)</span> 时有 <span class="math inline">\(\mathbb P(\omega :
|X_n(\omega) - X(\omega)| &gt; \varepsilon)\leq \frac{\mathbb E
|X_n(\omega) - X(\omega)|^p}{\varepsilon ^p} \leq \frac{\delta
\varepsilon ^p}{\varepsilon ^p} = \delta\)</span>。</p>
<p>由 <span class="math inline">\(\delta &gt;0\)</span>
的任意性可知，<span class="math inline">\(\lim_{n \to \infty}\mathbb
P(|X_n(\omega) - X(\omega)| &gt; \varepsilon) =0\)</span>，也即 <span class="math inline">\(X_n \stackrel{P}{\rightarrow}
X\)</span>，得证。</p></li>
<li><p><span class="math inline">\(X_n \stackrel{P}{\rightarrow}
X\)</span> 不能推出 <span class="math inline">\(X_n \stackrel{L^p
}{\rightarrow} X\)</span></p>
<p><strong>Counterexample</strong>: 取 <span class="math inline">\(\Omega=[0,1), \mathcal F = \mathcal B
(\Omega)\)</span>，概率测度 <span class="math inline">\(\mathbb
P\)</span> 即为 <span class="math inline">\(\Omega\)</span> 上的
Lebesgue 测度。</p>
<p>记 <span class="math inline">\(X_n( \omega) = \begin{cases}2^n \quad
\omega \in (0,\frac 1 n) \\ 0 \qquad \text{otherwise}
\end{cases}\)</span>，则有 <span class="math inline">\(\mathbb P(|X_n
(\omega) - 0|) = \mathbb P(X_n = 2^n ) = \frac 1 n\)</span>，因此 <span class="math inline">\(X_n \stackrel{P}{\rightarrow} 0\)</span>；</p>
<p>然而 <span class="math inline">\(\mathbb E|X_n -0|^p = \mathbb E
|X_n|^p = \frac{2^{np}}{n} \to \infty\)</span>，因此 <span class="math inline">\(X_n \stackrel{L ^p }{\rightarrow}0\)</span>
不成立。</p></li>
<li><p><span class="math inline">\(X_n \stackrel{P}{\rightarrow}
X\)</span> 可以推出 <span class="math inline">\(X_n
\stackrel{w}{\rightarrow} X\)</span></p>
<p><strong>Proof</strong>: 记 <span class="math inline">\(X_n\)</span>
的分布函数是 <span class="math inline">\(F_n\)</span>，<span class="math inline">\(X\)</span> 的分布函数是 <span class="math inline">\(F\)</span>。考虑对于 <span class="math inline">\(F\)</span> 的任意连续点 <span class="math inline">\(x \in C(F)\)</span>，取 <span class="math inline">\(\forall y &lt;x&lt;z\)</span>，有：</p>
<p><span class="math display">\[\begin{aligned} \{\omega : X(\omega)
\leq y \} &amp; = \{\omega : X(\omega) \leq y , X_n (\omega) \leq x\}
\cup \{\omega: X(\omega) \leq y , X_n(\omega) &gt; x \} \\ &amp;
\subseteq \{\omega : X_n (\omega) \leq x\} \cup \{\omega: |X(\omega)-
X_n(\omega)| &gt; x-y \} \end{aligned}\]</span></p>
<p><span class="math display">\[\begin{aligned} \{\omega : X_n(\omega)
\leq x \} &amp; = \{\omega : X_n(\omega) \leq x , X (\omega) \leq z\}
\cup \{\omega: X_n(\omega) \leq x , X(\omega) &gt; z \} \\ &amp;
\subseteq \{\omega : X (\omega) \leq z\} \cup \{\omega: |X(\omega)-
X_n(\omega)| &gt; z-x \} \end{aligned}\]</span></p>
<p>反映到事件的概率测度，则有：</p>
<p><span class="math display">\[F(y) = \mathbb P(X \leq y)  \leq \mathbb
P(X_n \leq x) + \mathbb P(|X_n - X | &gt; x-y) = F_n(x)+\mathbb P(|X_n -
X | &gt; x-y)\]</span></p>
<p><span class="math display">\[F_n(x) = \mathbb P(X_n \leq x) \leq
\mathbb P(X \leq z)+ \mathbb P(|X_n - X | &gt; z-x)=F(z)+\mathbb P(|X_n
- X| &gt; z-x)\]</span></p>
<p>在上两式中分别取 <span class="math inline">\(n \to
\infty\)</span>，则有：</p>
<p><span class="math display">\[F(y) \leq \lim \inf F_n(x) \leq \lim
\sup F_n(x) \leq F(z)\]</span></p>
<p>再分别取 <span class="math inline">\(y \uparrow x, z \downarrow
x\)</span> 则有 <span class="math inline">\(\lim _{n\to \infty} F_n(x) =
F(x)\)</span> 在任意 <span class="math inline">\(x \in C(F)\)</span>
处成立，因此 <span class="math inline">\(X_n \stackrel{w}{\rightarrow}
X\)</span>。</p></li>
<li><p><span class="math inline">\(X_n \stackrel{w}{\rightarrow}
X\)</span> 不能推出 <span class="math inline">\(X_n
\stackrel{P}{\rightarrow} X\)</span></p>
<p><strong>Counterexample</strong>: 取 <span class="math inline">\(\{X_n
\}\)</span> 和 <span class="math inline">\(X\)</span> 独立同分布于 <span class="math inline">\(\begin{pmatrix}-1 &amp; 1 \\ \frac 1 2 &amp; \frac
1 2 \end{pmatrix}\)</span>，显然有 <span class="math inline">\(X_n
\stackrel{w}{\rightarrow} X\)</span>。</p>
<p>对 <span class="math inline">\(\varepsilon_0 = 1\)</span>，<span class="math inline">\(\mathbb P(\omega \colon |X_n(\omega) - X(\omega)|
&gt; \varepsilon_0) = \mathbb P(X(\omega)=1,X_n(\omega) = -1) + \mathbb
P(X(\omega)=- 1 ,X_n(\omega) = 1) = \frac 1 4 + \frac 1 4 = \frac 1
2\)</span> 对任意的 <span class="math inline">\(n \in \mathbb
Z^+\)</span> 都成立，因此 <span class="math inline">\(\lim _{n \to
\infty} \mathbb P(\omega : |X(\omega) - X_n(\omega)| &gt; \varepsilon_0)
= \frac 1 2 \neq 0\)</span>，<span class="math inline">\(X_n
\stackrel{P}{\rightarrow} X\)</span> 不成立。</p></li>
</ul>
<p><strong>Remark:</strong> 累死了，不会这几问一下子全考了吧（</p>
<h2 id="弱收敛的特征函数条件">弱收敛的特征函数条件</h2>
<p>证明 <span class="math inline">\(X_n \stackrel{w}{\rightarrow} X \iff
f_n(t) \triangleq \mathbb E(e^{itX_n}) \to f(t) \triangleq \mathbb
E(e^{itX}), \forall t \in \mathbb
R\)</span>，也即，弱收敛等价于特征函数逐点收敛。</p>
<p><strong>Proof:</strong> 充分性是显然的，由于 <span class="math inline">\(X_n \stackrel{w}{\rightarrow} X \iff\)</span>
对任意的有界连续函数 <span class="math inline">\(g(x)\)</span> 有 <span class="math inline">\(\mathbb Eg(X_n) = \mathbb Eg(X)\)</span>，而 <span class="math inline">\(|e^{itx}| \leq 1\)</span>
保证了结论成立。必要性的证明分为两步进行：</p>
<ul>
<li><p>记 <span class="math inline">\(X_n\)</span> 的分布函数为 <span class="math inline">\(F_n\)</span>，<span class="math inline">\(X\)</span> 的分布函数为 <span class="math inline">\(F\)</span>。</p>
<p>由 Helly's first theorem 可知，<span class="math inline">\(\{X_n
\}\)</span> 存在子序列 <span class="math inline">\(\{X_{nk} \}\)</span>
满足 <span class="math inline">\(F_{nk} \stackrel{w}{\rightarrow} \hat
F, k \to +\infty\)</span>，下证 <span class="math inline">\(\hat
F\)</span> 是一个分布函数。由收敛性知 <span class="math inline">\(\hat
F\)</span> 满足右连续、单调递增条件，只需证明 <span class="math inline">\(\hat F(-\infty)=0, \hat
F(+\infty)=1\)</span>。</p>
<p>否则存在 <span class="math inline">\(a = \hat F(+\infty) - \hat
F(-\infty) \in (0,1)\)</span>，由于 <span class="math inline">\(f(0)=1,f\)</span> 一致连续，则对任意 <span class="math inline">\(\varepsilon &gt;0\)</span> ，存在 <span class="math inline">\(r=r(\varepsilon)\)</span> 使得 <span class="math inline">\(\frac{1}{2r} \int_{-r}^r f(t) dt &gt;
1-\frac{1}{2} \varepsilon&gt; a+ \frac{1}{2} \varepsilon\)</span>。</p>
<p>取 <span class="math inline">\(b\)</span> 满足 <span class="math inline">\(F_{nk} (b) - F_{nk} (-b) &lt; a+ \frac 1 4
\varepsilon\)</span> 且 <span class="math inline">\(\frac{1}{br} &lt;
\frac 1 4 \varepsilon\)</span>，则有：</p>
<p><span class="math display">\[\begin{aligned} \frac{1}{2r} \int_{-r}^r
f_{nk}(t) dt &amp;= \frac{1}{2r} \int_{-r}^r dt \int_{\mathbb R} e^{itx}
F_{nk}(dx) =  \frac{1}{2r} (\int_{|x| \leq b}  F_{nk}(dx)
\int_{-r}^r   e^{itx}dt +\int_{|x| &gt; b}  F_{nk}(dx)
\int_{-r}^r   e^{itx}dt )\\&amp; \leq  \int_{|x| \leq
b}  F_{nk}(dx)+  \frac{1}{2r} \int_{|x| &gt; b} |\frac 2 x \sin
rx|  F_{nk}(dx)  &lt;  \int_{|x| \leq b}  F_{nk}(dx)+  \frac{1}{br} \leq
a + \frac 1 2 \varepsilon \end{aligned}\]</span></p>
<p>由控制收敛定理，取 <span class="math inline">\(k \to \infty\)</span>
则有 <span class="math inline">\(\frac{1}{2r} \int_{-r}^r f(t) dt \leq a
+ \frac 1 2 \varepsilon\)</span>，这与 <span class="math inline">\(r\)</span> 的取值相矛盾。因此 <span class="math inline">\(\hat F\)</span> 是一个分布函数。由 Helly's second
theorem 可知 <span class="math inline">\(F_{nk}\)</span>
对应的特征函数在 <span class="math inline">\(k \to +\infty\)</span>
时收敛到 <span class="math inline">\(\int e^{itx} \hat
F(dx)\)</span>。又因为 <span class="math inline">\(f_{nk}(t)\)</span>
逐点收敛到 <span class="math inline">\(f(t)\)</span> 且 <span class="math inline">\(f(t) = \int e^{itx}
F(dx)\)</span>，由特征函数的唯一性可知 <span class="math inline">\(F =
\hat F\)</span>。</p></li>
<li><p>下面证明 <span class="math inline">\(F_n
\stackrel{w}{\rightarrow} F\)</span>，否则存在 <span class="math inline">\(F\)</span> 的某一连续点 <span class="math inline">\(x_0\)</span> 满足 <span class="math inline">\(F_n(x_0)\)</span> 不收敛到 <span class="math inline">\(F(x_0)\)</span>。取其收敛子列 <span class="math inline">\(F_{mk}\)</span> 使得 <span class="math inline">\(\lim_{n \to +\infty} F_{mk}(x_0) =
F^*(x_0)\)</span>，由 Helly's first theorem 和上一步的结论可知，<span class="math inline">\(\{F_{mk} \}\)</span> 存在子序列 <span class="math inline">\(\{F_{mkj} \}\)</span> 满足 <span class="math inline">\(F_{mkj} \stackrel{w}{\rightarrow} F, j \to
+\infty\)</span>。于是 <span class="math inline">\(F(x_0) = \lim_{j\to
+\infty} F_{mkj} = \lim_{k\to +\infty} F_{mk} =
F^*(x_0)\)</span>，矛盾。</p></li>
</ul>
<p>综上可知 <span class="math inline">\(X_n \stackrel{w}{\rightarrow} X
\iff f_n(t) \to f(t)\)</span> 逐点成立。</p>
<h1 id="大数定律">大数定律</h1>
<h2 id="kronecker-lemma">Kronecker Lemma</h2>
<p>有以下三个<del>数分</del>定理成立：考虑实数列 <span class="math inline">\(\{c_n \}\)</span> 和部分和 <span class="math inline">\(S_n = \sum_{i=1}^n c_i\)</span> 所组成的数列 <span class="math inline">\(\{S_n\}\)</span>：</p>
<ul>
<li>若 <span class="math inline">\(c_n \to c\)</span>，则 <span class="math inline">\(\frac{S_n}{n} \to c\)</span></li>
<li>记 <span class="math inline">\(b_m=\sup \{|S_{m+k} - S_m| : k \geq 1
\}, b = \inf \{b_m:m \geq 1\}\)</span>，则 <span class="math inline">\(\sum_{n=1} ^\infty c_n\)</span> 收敛 <span class="math inline">\(\iff b=0\)</span></li>
<li>若 <span class="math inline">\(\sum_{n=1} ^\infty
\frac{c_n}{n}\)</span> 收敛，则 <span class="math inline">\(\frac{S_n}{n} \to 0\)</span></li>
<li>若数列 <span class="math inline">\(\{a_n \} \uparrow
+\infty\)</span> 且 <span class="math inline">\(a_n &gt;0\)</span>
恒成立，由 <span class="math inline">\(\sum_{n=1} ^\infty
\frac{c_n}{a_n}\)</span> 收敛可以得到 <span class="math inline">\(\frac{S_n}{a_n} \to 0\)</span></li>
</ul>
<p><strong>Proof:</strong></p>
<ul>
<li><p>对任意 <span class="math inline">\(\varepsilon
&gt;0\)</span>，存在 <span class="math inline">\(N \in \mathbb
Z_+\)</span> 使得对任意 <span class="math inline">\(n &gt; N\)</span> 有
<span class="math inline">\(|c_n - c| &lt; \varepsilon\)</span>，也即
<span class="math inline">\(c-\varepsilon &lt; c_n &lt; c +
\varepsilon\)</span>。</p>
<p>对 <span class="math inline">\(\forall n &gt;N\)</span> 有 <span class="math inline">\(\frac 1 n S_n = \frac 1 n (\sum_{i=1}^N c_i +
\sum_{i=N+1}^n c_i)\)</span>，其中 <span class="math inline">\((n-N)(c-\varepsilon)&lt;\sum_{i=N+1}^n c_i
&lt;(n-N)(c+\varepsilon)\)</span>，并记 <span class="math inline">\(M =
\sum_{i=1}^N c_i\)</span> 是一个常数。</p>
<p>取 <span class="math inline">\(N&#39; \in \mathbb Z_+\)</span>
使得对任意 <span class="math inline">\(n &gt;N&#39;\)</span>，有 <span class="math inline">\(\max
\{\frac{M-N(c-\varepsilon)}{n},\frac{M-N(c+\varepsilon)}{n} \} \leq
\varepsilon\)</span>，则对 <span class="math inline">\(\forall n &gt;
\max \{N,N&#39; \}\)</span> 有 <span class="math inline">\(|\frac 1 n
S_n - c| &lt; \varepsilon\)</span> 成立，于是由 <span class="math inline">\(\varepsilon\)</span> 的任意性可知 <span class="math inline">\(\frac 1 n S_n \to c\)</span>，得证。</p></li>
<li><p>若 <span class="math inline">\(b=0\)</span>，则对任意的 <span class="math inline">\(\varepsilon &gt;0\)</span>，存在 <span class="math inline">\(n_1\)</span> 使得 <span class="math inline">\(b_{n_1} &lt; \varepsilon\)</span>。从而对任意
<span class="math inline">\(k \geq 1\)</span> 有 <span class="math inline">\(|S_{n_1 + k} - S_{n_1}| &lt;
\varepsilon\)</span>，这说明 <span class="math inline">\(S_n =
\sum_{i=1}^n c_i\)</span> 是一个柯西列，则 <span class="math inline">\(\sum_{n=1} ^\infty c_n\)</span> 收敛；</p>
<p>反之，如果数列 <span class="math inline">\(\{S_n \}\)</span>
收敛，则它是一个柯西列，对任意 <span class="math inline">\(\varepsilon
&gt;0\)</span>，存在 <span class="math inline">\(N\in \mathbb
Z_+\)</span> 使得对任意的 <span class="math inline">\(n
&gt;N\)</span>，对任意 <span class="math inline">\(k \in \mathbb
Z_+\)</span> 都有 <span class="math inline">\(|S_{n+k} - S_n | &lt;
\varepsilon\)</span>，也即 <span class="math inline">\(b_n &lt;
\varepsilon\)</span> 对任意 <span class="math inline">\(n \in \mathbb
Z_+\)</span> 成立。因此也有 <span class="math inline">\(0\leq b = \inf
\{b_m : m\geq 1\} &lt; \varepsilon\)</span>，由 <span class="math inline">\(\varepsilon&gt;0\)</span> 的任意性可知此时 <span class="math inline">\(b=0\)</span>。</p></li>
<li><p>第三问实际上就是第四问的一个例子，我们直接证明最一般的情况。</p>
<p>记 <span class="math inline">\(t_n = \sum_{i=1}^n
\frac{c_n}{a_n}\)</span>，则有 <span class="math inline">\(\{t_n\} \to
t\)</span> 是一个收敛数列，此时有 <span class="math inline">\(c_n = a_n
(t_n - t_{n-1})\)</span>。</p>
<p>于是 <span class="math inline">\(S_n = \sum_{i=1}^n a_n(t_n -
t_{n-1}) = a_n t_n - \sum_{i=1}^{n-1} (a_{i+1} -
a_{i})t_{i}\)</span>，考虑 <span class="math inline">\(\frac{S_n}{a_n} =
t_n - \sum_{i=1}^{n-1} \frac{(a_{i+1} - a_{i})}{a_n}t_{i}\)</span>
则有每个 <span class="math inline">\(\frac{a_{i+1} -a_i}{a_n}
&gt;0\)</span>，此时有 <span class="math inline">\(t- \sum_{i=1}^{n-1}
\frac{a_{i+1} - a_i}{a_n} t_i \to t-\sum_{i=1}^{n-1} \frac{a_{i+1} -
a_i}{a_n} t \to 0\)</span>，也就是说 <span class="math inline">\(\frac{S_n}{a_n} \to 0\)</span> 在 <span class="math inline">\(n \to \infty\)</span> 时成立。</p>
<p>（这里其实在口胡了，但是注意到 <span class="math inline">\(t_n \to
t,a_n \to \infty\)</span> 然后用极限那一套 <span class="math inline">\(\varepsilon \sim N\)</span>
写一下也很简单）</p></li>
</ul>
<h2 id="独立同分布情况的强大数定律">独立同分布情况的强大数定律</h2>
<p>记 <span class="math inline">\(X_1,X_2,...,X_n,...
\text{i.i.d.}\)</span> 满足 <span class="math inline">\(\mathbb E|X_i|
&lt; \infty\)</span>，记 <span class="math inline">\(\mathbb E X_i =
\mu\)</span>，取 <span class="math inline">\(S_n = \sum_{i=1}^n
X_i\)</span>，则有<span class="math inline">\(n \to \infty\)</span> 时
<span class="math inline">\(\frac{S_n}{n} \stackrel{a.s.}{\rightarrow}
\mu\)</span>。</p>
<p><strong>Proof:</strong> 取 <span class="math inline">\(Y_n \triangleq
X_n \mathbb 1_{\{|X_n | \leq n\}}\)</span>，记 <span class="math inline">\(T_n = \sum_{i=1}^n Y_i\)</span>，注意到 <span class="math inline">\(\frac 1 n S_n - \mu = \frac 1 n (S_n - T_n)+\frac
1 n (T_n - \mathbb ET_n) + (\frac 1 n \mathbb ET_n -
\mu)\)</span>，因此想要证明 <span class="math inline">\(\frac{S_n}{n}
\stackrel{a.s.}{\rightarrow} \mu\)</span>
只需要证明上述三个括号内的部分几乎处处收敛。</p>
<ul>
<li><p>考虑：</p>
<p><span class="math display">\[\begin{aligned}\sum_{n=1}^\infty \mathbb
P(\omega: X_n \neq Y_n) &amp;= \sum_{n=1}^\infty \mathbb P(\omega: |X_n|
&gt;n) \leq \int_{0} ^\infty \mathbb P(|X_1| \geq x) dx = \mathbb E|X_1|
\leq  +\infty  \end{aligned}\]</span></p>
<p>于是有 <span class="math inline">\(\{X_n \},\{Y_n\}\)</span>
是等价随机变量列，<span class="math inline">\(X_n - Y_n
\stackrel{a.s.}{\rightarrow} 0\)</span>，由 Kronecker's lemma 的结论 1
可知 <span class="math inline">\(\frac{1}{n} \sum_{i=1}^n (X_i - Y_i)
\stackrel{a.s.}{\rightarrow} 0\)</span>，也就是 <span class="math inline">\(\frac 1 n (S_n - T_n) = \frac 1 n \sum_{i=1} ^n
(X_i - Y_i) \stackrel{a.s.}{\rightarrow} 0\)</span>。</p></li>
<li><p>考虑：</p>
<p><span class="math inline">\(\begin{aligned} \sum_{n=1}^\infty
\frac{Var Y_n}{n^2} &amp; \leq \sum_{n=1} ^\infty \frac{\mathbb
EY_n^2}{n^2} = \sum_{n=1}^\infty \frac{1}{n^2} \int_{-n}^n x^2
dF_{X_1}(x) = \sum_{n=1}^\infty \frac{1}{n^2} (\sum_{j=1} ^n \int_{j-1
\leq |x| \leq j} x^2 dF_{X_1}(x))\\&amp; = \sum_{n=1}^\infty (\int_{j-1
\leq |x| \leq j} x^2 dF_{X_1} (x) \cdot \sum_{n=j} ^\infty
\frac{1}{n^2}) \leq \sum_{n=1} ^\infty (\int_{j-1 \leq |x| \leq j} x^2
dF_{X_1}(x) \cdot \frac{C}{j} ) \\ &amp; = C \sum_{n=1}^\infty \frac 1 j
\int_{j-1 \leq |x| \leq j} |x|^2 dF_{X_1}(x) \leq C \sum_{n=1}^\infty
\int_{j-1 \leq |x| \leq j} |x| dF_{X_1}(x) = C\mathbb E|X_1| \leq +
\infty\end{aligned}\)</span></p>
<p>由 SLLN 的其中一个定理有 <span class="math inline">\(n \to
\infty\)</span> 时 <span class="math inline">\(\frac 1 n (T_n - \mathbb
ET_n)\stackrel{a.s.}{\rightarrow} 0\)</span> 成立。</p></li>
<li><p>由于 <span class="math inline">\(\mathbb E Y_n = \int_{\mathbb R}
x \mathbb 1_{[-n,n]} (x) dF_{X_1} (x)\)</span>，且 <span class="math inline">\(|x \mathbb 1_{[-n,n]}(x) | \leq
|x|\)</span>，<span class="math inline">\(\lim_{n \to \infty} x \mathbb
1_{[-n,n]}(x) = x\)</span>，将 <span class="math inline">\(\mathbb
EY_n\)</span> 作为一个可积函数列的积分来考虑。</p>
<p>且 <span class="math inline">\(\int_{\mathbb R} |x| dF_{X_1}(x) =
\mathbb E|X_1| \leq +\infty\)</span>，则由控制收敛定理，</p>
<p><span class="math display">\[\lim_{n \to \infty} \mathbb EY_n =
\int_{\mathbb R} \lim_{n \to \infty} x \mathbb 1_{[-n,n]} dF_{X_1}(x) =
\int_{\mathbb R} x dF_{X_1}(x) = \mathbb E X_1 = \mu\]</span></p>
<p>于是由 Kronecker's lemma 有 <span class="math inline">\(\frac 1 n
\sum_{i=1} ^n \mathbb E Y_n = \frac 1 n \mathbb E T_n \to \mu\)</span>
成立。</p></li>
</ul>
<p>综合上述三点可知 <span class="math inline">\(\frac 1 n S_n - \mu =
\frac 1 n (S_n - T_n)+\frac 1 n (T_n - \mathbb ET_n) + (\frac 1 n
\mathbb ET_n - \mu) \stackrel{a.s.}{\rightarrow}0\)</span>，也即 <span class="math inline">\(\frac{S_n}{n} \stackrel{a.s.}{\rightarrow}
\mu\)</span> 成立，得证。</p>
<p><strong>Remark 1:</strong> 实际上如果期望不存在，把 <span class="math inline">\(\mathbb E |X_1| &lt; +\infty\)</span> 这个条件改成
<span class="math inline">\(\mathbb E |X_1| = +\infty\)</span>，则有
<span class="math inline">\(\lim \sup_{n\to \infty} \frac{|S_n|}{n}
\stackrel{a.s.}{\rightarrow} +\infty\)</span>。</p>
<p>也就是说，对任意的 <span class="math inline">\(A &gt; 0\)</span> 有
<span class="math inline">\(\mathbb E(|X_1| /A) = \infty\)</span>
成立，则有：</p>
<p><span class="math display">\[+\infty = \mathbb E(|X_1|/A) =
\int_{\mathbb R} \mathbb P(|X_1|/A &gt; x)dx \leq \sum_{n=1}^\infty
\mathbb P(|X_1|/A &gt; n)\]</span></p>
<p>又因为 <span class="math inline">\(\{X_i \}\)</span> 同分布，因此
<span class="math inline">\(\sum_{i=1}^n \mathbb P(|X_n| &gt; An) =
+\infty\)</span>，使用各随机变量独立情形下的 Borel-Cantelli lemma，则有
<span class="math inline">\(\mathbb P(|X_n| &gt; An\quad \text{i.o.}) =
1\)</span>。事实上 <span class="math inline">\(\{\omega : |S_n -
S_{n-1}| = |X_n|&gt;An \} \subseteq \{\omega : |S_n| &gt;A n/2 \}\cup
\{\omega :|S_{n-1}|&gt;An/2 \}\)</span>，由此可知 <span class="math inline">\(\mathbb P(|S_n| &gt; \frac {An}{2} \quad
\text{i.o.})=1\)</span> 对任意的 <span class="math inline">\(A&gt;0\)</span> 恒成立。</p>
<p>这也就是说，对任意的 <span class="math inline">\(A&gt;0\)</span>，存在一个零测集 <span class="math inline">\(Z(A)\)</span> 使得对于任意的 <span class="math inline">\(\omega \in \Omega \setminus Z(A)\)</span>，有
<span class="math inline">\(\lim \sup_{n \to \infty}
\frac{S_n(\omega)}{n} \geq \frac{A}{2}\)</span> 成立；取 <span class="math inline">\(Z =\cup_{m=1}^\infty Z(m)\)</span>
仍为零测集，于是对任意的 <span class="math inline">\(\omega \in \Omega
\setminus Z\)</span> 都有 <span class="math inline">\(\lim \sup_{n \to
\infty} \frac{S_n(\omega)}{n} = + \infty\)</span>。</p>
<p>因此 <span class="math inline">\(\lim \sup_{n\to \infty}
\frac{S_n}{n} \stackrel{a.s.}{\rightarrow} +\infty\)</span>
成立，得证。</p>
<p><strong>Remark 2:</strong> 一个来自 Kai Lai Chung 的例子：<span class="math inline">\(\{X_n \}\)</span> 独立同分布，<span class="math inline">\(\mathbb P(X_1 = n) = \mathbb P(X_1 = -n) =
\frac{c}{n^2 \log n}, n =3,4,...\)</span>，<span class="math inline">\(c\)</span> 是归一化系数使得所有的概率加起来为
<span class="math inline">\(1\)</span>。</p>
<p>因此有 <span class="math inline">\(\mathbb E(X_1) = 0, \mathbb E|X_1|
= 2 \sum_{n=1}^\infty \frac{c}{n\log n} = +\infty\)</span>，可以推知
<span class="math inline">\(\lim \sup_{n \to \infty} \frac{S_n}{n} =
+\infty\)</span>；事实上由于 <span class="math inline">\(X\)</span>
的分布是关于原点对称的，也可以推知 <span class="math inline">\(\lim
\inf_{n \to \infty} \frac{S_n}{n} = -\infty\)</span>。与此同时由
Kolmogorov &amp; Feller's WLLN method 有 <span class="math inline">\(\frac{S_n}{n} \stackrel{p}{\rightarrow}
0\)</span>，二者是并不矛盾的。</p>
<h1 id="中心极限定理">中心极限定理</h1>
<h2 id="feller-clt-iff-lindeberg">Feller + CLT <span class="math inline">\(\iff\)</span> Lindeberg</h2>
<p>lzx: 必要性太复杂了，可以考虑考个充分性（看讲义应该是 Lindeberg <span class="math inline">\(\to\)</span> Feller + CLT，<del>Lindeberg
你好强大</del></p>
<p>对于三角随机变量列 <span class="math inline">\(\{X_{nj}\}, 1\leq j
\leq n,n \in \mathbb Z_+\)</span>，有 <span class="math inline">\(\mathbb EX_{nj} = 0\)</span> 和 <span class="math inline">\(\sum_{j=1}^n Var(X_{nj}) = \sum_{j=1}^n
\sigma_{nj}^2 = 1\)</span> 对任意 <span class="math inline">\(n \in
\mathbb Z_+\)</span> 成立。记其部分和为 <span class="math inline">\(S_n
= \sum_{j=1}^n X_{nj}\)</span>，则有以下三个条件：</p>
<ul>
<li><p>CLT: <span class="math inline">\(S_n \stackrel{w}{\rightarrow} S
\sim N(0,1)\)</span></p></li>
<li><p>Feller: <span class="math inline">\(\lim_{n \to \infty} \max_{1
\leq j \leq n} \sigma_{nj}^2 =0\)</span></p>
<p>另一个等价形式是 <span class="math inline">\(\lim_{n \to \infty}
\max_{1 \leq j \leq n} \mathbb P(|X_{nj} | \geq \varepsilon) =
0\)</span> 对任意 <span class="math inline">\(\varepsilon &gt;0\)</span>
成立</p></li>
<li><p>Lindeberg: <span class="math inline">\(\lim_{n\to \infty}
\sum_{j=1}^n \int_{|x| \geq \varepsilon} x^2 dF_{nj}(x) = 0\)</span>
对任意 <span class="math inline">\(\varepsilon &gt;0\)</span>
成立</p></li>
</ul>
<p>其中可以由 Lindeberg 条件成立推出 Feller 条件和 CLT 条件都成立。</p>
<p><strong>Proof</strong>:</p>
<ul>
<li><p>首先考虑使用 Lindeberg 条件推出 Feller 条件。由 Chebyshev
不等式可知，</p>
<p><span class="math display">\[\begin{aligned} \mathbb P(|X_{nj}|
\geq  \varepsilon) &amp; \leq \frac{\sigma^2_{nj}}{\varepsilon ^2}  =
\frac{1}{\varepsilon^2}( \int_{|x| \leq \tau} x^2 dF_{nj}(x) + \int_{|x|
&gt; \tau} x^2 dF_{nj}(x) ) \leq \frac{\tau ^2}{\varepsilon^2} +
\frac{1}{\varepsilon^2} \int_{|x| &gt; \tau} x^2 dF_{nj}(x)
\end{aligned}\]</span></p>
<p>由此可知 <span class="math inline">\(\max_{1 \leq j \leq n} \mathbb
P(|X_{nj}| \geq \varepsilon) \leq \frac{\tau ^2}{\varepsilon^2} +
\frac{1}{\varepsilon^2} \sum_{j=1}^n \int_{|x| &gt; \tau} x^2 dF_{nj}(x)
\to 0, n \to +\infty\)</span> 且取 <span class="math inline">\(\tau \to
0\)</span> 时成立，</p>
<p>同理 <span class="math inline">\(\max_{1 \leq j \leq n} \mathbb
P(|X_{nj}| \leq \varepsilon) \leq \tau ^2 + \sum_{j=1}^n \int_{|x| &gt;
\tau} x^2 dF_{nj}(x) \to 0, n \to +\infty\)</span> 且取 <span class="math inline">\(\tau \to 0\)</span> 时成立。</p></li>
<li><p>再考虑用 Lindeberg 条件推出 CLT 条件。记 <span class="math inline">\(S_n\)</span> 的特征函数是 <span class="math inline">\(f_{S_n}(t)\)</span>，<span class="math inline">\(X_{nj}\)</span> 的特征函数是 <span class="math inline">\(f_{X_{nj}}(t)\)</span>，且某一服从标准正态分布的随机变量
<span class="math inline">\(S\)</span> 的特征函数是 <span class="math inline">\(f_S (t) = e^{-\frac 1 2 t^2}\)</span>。</p>
<p>由 <span class="math inline">\(\mathbb EX_{nj}=0, VarX_{nj} =
\sigma^2_{nj}\)</span> 可知，<span class="math inline">\(f_{X_{nj}} = 1-
\frac 1 2 t^2 \sigma_{nj}^2 + o(\frac 1 2 \sigma_{nj}^2
t^2)\)</span>，于是有：</p>
<p><span class="math display">\[\begin{aligned} |f_{S_n}(t) - f_S(t)|
&amp;= |f_{S_n}(t) - \prod_{j=1} ^n (1- \frac 1 2 t^2 \sigma_{nj}^2) +
\prod_{j=1} ^n (1- \frac 1 2 t^2 \sigma_{nj}^2) - e^{-\frac 1 2 t^2
\sum_{j=1}^n \sigma_{nj}^2} | \\  &amp;\leq |\prod_{j=1} ^n
f_{X_{nj}}(t) - \prod_{j=1} ^n (1- \frac 1 2 t^2 \sigma_{nj}^2)| +
|\prod_{j=1} ^n (1- \frac 1 2 t^2 \sigma_{nj}^2) - \prod_{j=1}^n
e^{-\frac 1 2 t^2 \sigma_{nj}^2} |  \\ &amp; \triangleq \Delta_1 +
\Delta_2 \end{aligned}\]</span></p>
<p>以下对 <span class="math inline">\(\Delta_1 , \Delta_2\)</span>
分别进行估计：</p>
<p><span class="math display">\[\begin{aligned} \Delta_1 &amp; \leq
\sum_{j=1}^n |f_{X_{nj}} (t) - (1- \frac 1 2 t^2 \sigma_{nj}^2)| =
\sum_{j=1}^n |\mathbb E(e^{itX_{nj}} - 1-itX_{nj} + \frac 1 2 t ^2
X_{nj} ^2)| \leq \sum_{j=1}^n \mathbb E(\min\{|tX_{nj}|^2 , |tX_{nj}|^3
\}) \\ &amp; \leq \sum_{j=1}^n  (\mathbb E(|tX_{nj}|^3 , |X_{nj}| \leq
\tau) + \mathbb E(|tX_{nj}|^2 , |X_{nj}| &gt; \tau)) \leq \sum_{j=1}^n
(\tau |t|^3 \int_{|x| \leq \tau} x^2 dF_{nj}(x) +  t^2 \int_{|x| &gt;
\tau} x^2 dF_{nj}(x) )\\ &amp; \leq \tau |t|^3 \sum_{j=1}^n
\sigma_{nj}^2  + t^2 \sum_{j=1}^n \int_{|x| &gt; \tau} x^2
dF_{nj}(x)  =  \tau |t|^3 + t^2 \sum_{j=1}^n \int_{|x| &gt; \tau} x^2
dF_{nj}(x) \to 0\quad (n \to +\infty, \tau \to
0)  \end{aligned}\]</span></p>
<p><span class="math display">\[\begin{aligned} \Delta_2  &amp; \leq
\sum_{j=1}^n |e^{-\frac 1 2 t^2 \sigma_{nj}^2} - 1 + \frac 1 2 t^2
\sigma_{nj}^2| \leq \sum_{j=1}^n |\frac 1 2 t^2 \sigma_{nj}^2|^2   \leq
\frac 1 4 t^4 \max_{1\leq j \leq n} |\sigma_{nj}^2| \sum_{j=1}^n
\sigma_{nj}^2 = \frac 1 4 t^4 \max_{1\leq j \leq n} |\sigma_{nj}^2| \to
0 ,n \to +\infty  \end{aligned}\]</span></p>
<p>于是有 <span class="math inline">\(f_{S_n}(t) \to f_S(t)\)</span>
逐点收敛，也即 <span class="math inline">\(S_n \stackrel{w}{\rightarrow}
S \sim N(0,1)\)</span>，CLT 成立。</p></li>
</ul>
<p><strong>Remark 1</strong>: 实际上条件里面的 <span class="math inline">\(\mathbb EX_{nj}=0\)</span> 和 <span class="math inline">\(\sum_{j=1}^n Var(X_{nj}) = \sum_{j=1}^n
\sigma_{nj}^2 = 1\)</span>
并不需要成立，对于一般的三角随机变量列，只需要取 <span class="math inline">\(Y_{nj} = \frac{X_{nj} - \mathbb
EX_{nj}}{\sqrt{B_n^2}}, B_n ^2 = \sum_{j=1}^n \sigma_{nj}^2\)</span>
则可以满足上述两个标准化条件。这两个条件的加入使得计算和书写更加简便。</p>
<p><strong>Remark 2</strong>:
所以说充分性难道比必要性简单很多吗（挠头（<del>Lindeberg，你好强大</del></p>
<h1 id="鞅论">鞅论</h1>
<h2 id="doobs-stopping-time-theorem">Doob's Stopping Time Theorem</h2>
<p>英语稀碎，但是试图把这段话翻译成中文的时候觉得浑身不得劲，就这样吧（</p>
<p>说实话这道题真的水，但是涉及一些概念（discrete time martingale,
stopping time, etc.），不知道是记下来还是放弃比较合适（</p>
<p><span class="math inline">\(S,T\)</span> are bounded stopping times
w.r.t. <span class="math inline">\(\{\mathcal F_n
\}_{n=1}^{+\infty}\)</span>, while <span class="math inline">\(X =
\{X_n, \mathcal F_n \}\)</span> is a martingale (or supermartingale) on
<span class="math inline">\((\Omega, \mathcal F, \mathbb P)\)</span>.
<span class="math inline">\(S \leq T\)</span>.</p>
<ul>
<li><span class="math inline">\(\mathcal F_T\)</span> and <span class="math inline">\(\mathcal F_S\)</span> are <span class="math inline">\(\sigma -\)</span>fields of <span class="math inline">\(\Omega\)</span> ;</li>
<li><span class="math inline">\(X_T\)</span> is <span class="math inline">\(\mathcal F_T -\)</span>measurable, <span class="math inline">\(X_S\)</span> is <span class="math inline">\(\mathcal F_S-\)</span>measurable ;</li>
<li><span class="math inline">\(\mathbb E|X_S| &lt; +\infty\)</span>,
<span class="math inline">\(\mathbb E|X_T| &lt; +\infty\)</span> ;</li>
<li>For martingale, there is <span class="math inline">\(\mathbb E(X_T
|\mathcal F_S) = X_S \quad a.s.\)</span> and for supermartingale, there
is <span class="math inline">\(\mathbb E(X_T|\mathcal F_S) \leq X_S
\quad a.s.\)</span> .</li>
</ul>
<p><strong>Proof</strong>:</p>
<ul>
<li><p><span class="math inline">\(\mathcal F_T \triangleq \{A|A \cap
\{T=n\} \in \mathcal F_n , \forall n \geq 0\}\)</span>, we have the
following:</p>
<ul>
<li><span class="math inline">\(\Omega \cap\{T=n\} = \{T= n\} \in
\mathcal F_n\)</span>, <span class="math inline">\(\varnothing \cap
\{T=n\} = \varnothing \in \mathcal F_n\)</span>, thus <span class="math inline">\(\Omega, \varnothing \in \mathcal
F_T\)</span>.</li>
<li><span class="math inline">\(\forall A \in \mathcal F_T\)</span>,
there is <span class="math inline">\(A^C \cap \{T=n\} = \{T=n\} - A \cap
\{T=n\} \in \mathcal F_n\)</span>, thus <span class="math inline">\(A^C
\in \mathcal F_T\)</span>.</li>
<li>For pairwise disjoint <span class="math inline">\(\{A_k
\}_{k=1}^{+\infty} \in \mathcal F_T\)</span>, there is <span class="math inline">\((\uplus_{k=1}^{+\infty} A_k)\cap \{T=n\} =
\uplus_{k=1} ^{+\infty}(A_k \cap \{T=n \}) \in \mathcal F_n\)</span>.
Thus <span class="math inline">\(\uplus _{k=1}^{+\infty} A_k \in
\mathcal F_T\)</span>.</li>
</ul>
<p>We can conclude that <span class="math inline">\(\mathcal
F_T\)</span> is a <span class="math inline">\(\sigma-\)</span>field of
<span class="math inline">\(\Omega\)</span>, similarly <span class="math inline">\(\mathcal F_S\)</span> is a <span class="math inline">\(\sigma-\)</span>field of <span class="math inline">\(\Omega\)</span>.</p></li>
<li><p>To prove that <span class="math inline">\(X_T\)</span> is <span class="math inline">\(\mathcal F_T-\)</span>measurable, it suffices to
show <span class="math inline">\(\forall B \in \mathcal B^1\)</span>,
<span class="math inline">\(\{X_T \in B \} \in \mathcal
F_T\)</span>.</p>
<p>According to the definition, <span class="math inline">\(\{X_T \in
B\} \cap \{T=n \} = \{X_n \in B \} \cap \{T=n \} \in \mathcal
F_n\)</span>, thus <span class="math inline">\(\{X_T \in B \}\in
\mathcal F_T\)</span>.</p>
<p>Similarly, <span class="math inline">\(X_S\)</span> is <span class="math inline">\(\mathcal F_S -\)</span>measurable.</p></li>
<li><p><span class="math inline">\(S \leq T\)</span> are bounded
stopping time, take <span class="math inline">\(n_0\)</span> as their
upper bound, then <span class="math inline">\(T=\{0,1,2,...,n_0\}\)</span>. According to the
definition, <span class="math inline">\(X_T = \sum_{i=0}^{n_0} X_i
\mathbb 1_{\{T(\omega) =i\}}\)</span>.</p>
<p>Thus <span class="math inline">\(\mathbb E|X_T| \leq \sum_{i=0}^{n_0}
\mathbb E (|X_i| \mathbb 1_{\{T(\omega)=i \}}) \leq \sum_{i=0}^{n_0}
\mathbb E|X_i| &lt; +\infty\)</span>, cause <span class="math inline">\(X = \{X_n, \mathcal F_n \}\)</span> is a
martingale (or supermartingale).</p>
<p>Similarly <span class="math inline">\(\mathbb E|X_S| &lt;
+\infty\)</span>.</p></li>
<li><p>To treat the supermartingale case, we'd like to discuss the
special case first.</p>
<ul>
<li><p>If <span class="math inline">\(0 \leq T-S \leq 1\)</span>, for
<span class="math inline">\(\forall A \in \mathcal F_S\)</span>, take
<span class="math inline">\(A_j = A \cap \{S= j \} \cap \{T \geq j
\}\)</span> for <span class="math inline">\(j = 0,1,2,...,n_0\)</span>,
thus <span class="math inline">\(A = \uplus_{j=0}^{+\infty}
A_j\)</span>.</p>
<p>If <span class="math inline">\(T-S =1\)</span>, there is <span class="math inline">\(\int_A (X_S-X_T) d\mathbb P = \sum_{j=0}^{n_0}
\int_{A_j} (X_j - X_{j+1}) d \mathbb P \geq 0\)</span>, then we can
conclude that <span class="math inline">\(\mathbb E(X_T|\mathcal F_S)
\leq X_S\)</span>.</p>
<p>Else if <span class="math inline">\(T-S =0\)</span>, it's trivial to
conclude that <span class="math inline">\(\mathbb E(X_T|\mathcal F_S) =
\mathbb E(X_S|\mathcal F_S) = X_S\)</span>.</p></li>
<li><p>For the general case, denote <span class="math inline">\(R_j = T
\wedge (S+j)\)</span> as a series of stopping time and <span class="math inline">\(S = R_0 \leq R_1 \leq ... \leq R_{n_0} =
T\)</span> holds. Moreover, <span class="math inline">\(0 \leq R_{j+1} -
R_j \leq 1\)</span>, so the conclusion above can be utilized here.</p>
<p>For <span class="math inline">\(\forall A \in \mathcal F_S\)</span>,
there is <span class="math inline">\(\int_A X_S d\mathbb P = \int_A
X_{R_0} d \mathbb P \geq \int_A X_{R_1} d \mathbb P \geq ... \geq \int_A
X_{R_{n_0}} d \mathbb P = \int_A X_T d \mathbb P\)</span>, then we can
conclude that <span class="math inline">\(\mathbb E(X_T|\mathcal F_S)
\leq X_S\)</span>.</p></li>
</ul>
<p>The proof is almost the same for the case of martingale.</p></li>
</ul>
<h1 id="附录分布函数表">附录：分布函数表</h1>
<p>从 V1ncent19
那里抄来的表，学了半年多概统了我还没能完全背出来，实在是很蚌埠住。</p>
<p>From <a href="https://v1ncent19.github.io/SummaryNotes/">Statistic
Note</a> P10, by V1ncent19</p>
<table>
<colgroup>
<col style="width: 10%">
<col style="width: 26%">
<col style="width: 13%">
<col style="width: 24%">
<col style="width: 8%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(X\)</span></th>
<th><span class="math inline">\(p_X(k)\big/f_X(x)\)</span></th>
<th><span class="math inline">\(\mathbb{E}\)</span></th>
<th><span class="math inline">\(Var\)</span></th>
<th>PGF</th>
<th>MGF</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\mathrm{Bern} (p)\)</span></td>
<td></td>
<td><span class="math inline">\(p\)</span></td>
<td><span class="math inline">\(pq\)</span></td>
<td></td>
<td><span class="math inline">\(q+pe^s\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(B (n,p)\)</span></td>
<td><span class="math inline">\(C_n^k p^k(1-p)^{n-k}\)</span></td>
<td><span class="math inline">\(np\)</span></td>
<td><span class="math inline">\(npq\)</span></td>
<td><span class="math inline">\((q+ps)^n\)</span></td>
<td><span class="math inline">\((q+pe^s)^n\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mathrm{Geo} (p)\)</span></td>
<td><span class="math inline">\((1-p)^{k-1}p\)</span></td>
<td><span class="math inline">\(\dfrac{1}{p}\)</span></td>
<td><span class="math inline">\(\dfrac{q}{p^2}\)</span></td>
<td><span class="math inline">\(\dfrac{ps}{1-qs}\)</span></td>
<td><span class="math inline">\(\dfrac{pe^s}{1-qe^s}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(H(n,M,N)\)</span></td>
<td><span class="math inline">\(\dfrac{C_M^kC_{N-M}^{n-k}}{C_N^n}\)</span></td>
<td><span class="math inline">\(n\dfrac{M}{N}\)</span></td>
<td><span class="math inline">\(\dfrac{nM(N-n)(N-M)}{N^2(n-1)}\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(P(\lambda)\)</span></td>
<td><span class="math inline">\(\dfrac{\lambda^k}{k!}e^{-\lambda}\)</span></td>
<td><span class="math inline">\(\lambda\)</span></td>
<td><span class="math inline">\(\lambda\)</span></td>
<td><span class="math inline">\(e^{\lambda(s-1)}\)</span></td>
<td><span class="math inline">\(e^{\lambda(e^s-1)}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(U(a,b)\)</span></td>
<td><span class="math inline">\(\dfrac{1}{b-a}\)</span></td>
<td><span class="math inline">\(\dfrac{a+b}{2}\)</span></td>
<td><span class="math inline">\(\dfrac{(b-a)^2}{12}\)</span></td>
<td></td>
<td><span class="math inline">\(\dfrac{e^{sb}-e^{sa}}{(b-a)^s}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(N(\mu,\sigma^2)\)</span></td>
<td><span class="math inline">\(\dfrac{1}{\sigma
\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\)</span></td>
<td><span class="math inline">\(\mu\)</span></td>
<td><span class="math inline">\(\sigma^2\)</span></td>
<td></td>
<td><span class="math inline">\(e^{\frac{\sigma^2s^2}{2}+\mu
s}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\varepsilon(\lambda)\)</span></td>
<td><span class="math inline">\(\lambda e^{-\lambda x}\)</span></td>
<td><span class="math inline">\(\dfrac{1}{\lambda}\)</span></td>
<td><span class="math inline">\(\dfrac{1}{\lambda^2}\)</span></td>
<td></td>
<td><span class="math inline">\(\frac{\lambda}{\lambda-s}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\Gamma(\alpha,\lambda)\)</span></td>
<td><span class="math inline">\(\dfrac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda
x}\)</span></td>
<td><span class="math inline">\(\dfrac{\alpha}{\lambda}\)</span></td>
<td><span class="math inline">\(\dfrac{\alpha}{\lambda^2}\)</span></td>
<td></td>
<td><span class="math inline">\((\frac{\lambda}{\lambda-s})^\alpha\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(B(\alpha,\beta)\)</span></td>
<td><span class="math inline">\(\dfrac{1}{B(\alpha,\beta)}x^{\alpha-1}(1-x)^{\beta-1}\)</span></td>
<td><span class="math inline">\(\dfrac{\alpha}{\alpha+\beta}\)</span></td>
<td><span class="math inline">\(\dfrac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\chi^2_n\)</span></td>
<td><span class="math inline">\(\dfrac{1}{2^{\frac{n}{2}}\Gamma(\frac{n}{2})}x^{\frac{n}{2}-1}e^{-\frac{x}{2}}\)</span></td>
<td><span class="math inline">\(n\)</span></td>
<td><span class="math inline">\(2n\)</span></td>
<td></td>
<td>$ (1-2s)^{-n/2} $</td>
</tr>
<tr class="even">
<td><span class="math inline">\(t_\nu\)</span></td>
<td><span class="math inline">\(\dfrac{\Gamma(\frac{\nu+1}{2})}{\sqrt{\nu\pi}\Gamma(\frac{\nu}{2})}(1+\frac{x^2}{\nu})^{-\frac{\nu+1}{2}}\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(\dfrac{\nu}{\nu-2}\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(F_{m,n}\)</span></td>
<td><span class="math inline">\(\dfrac{\Gamma(\frac{m+n}{2})}{\Gamma(\frac{m}{2})\Gamma(\frac{n}{2})}\dfrac{m^\frac{m}{2}n^\frac{n}{2}x^{\frac{m}{2}-1}}{(mx+n)^{\frac{m+n}{2}}}\)</span></td>
<td><span class="math inline">\(\dfrac{n}{n-2}\)</span></td>
<td><span class="math inline">\(\dfrac{2n^2(m+n-2)}{m(n-2)^2(n-4)}\)</span></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Consider <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>
i.i.d. <span class="math inline">\(\sim N(0,1)\)</span>; <span class="math inline">\(Y,Y_1,Y_2,\ldots,Y_m\)</span> i.i.d. <span class="math inline">\(\sim N(0,1)\)</span></p>
<ul>
<li><p><span class="math inline">\(\chi^2\)</span> Distribution：</p>
<p><span class="math inline">\(\chi^2\)</span> distribution with degree
of freedom <span class="math inline">\(n\)</span>: <span class="math inline">\(\xi =\sum_{i=1}^n X_i^2\sim \chi^2_n\)</span>。
For independent <span class="math inline">\(\xi_i\sim\chi^2_{n_i},\,
i=1,2,\ldots,k\)</span>: <span class="math inline">\(x_{i_0}=\sum_{i=1}^k\xi_i\sim\chi^2_{n_1+\ldots+n_k}\)</span></p></li>
<li><p><span class="math inline">\(t\)</span> Distribution：</p>
<p><span class="math inline">\(t\)</span> distribution with degree of
freedom <span class="math inline">\(n\)</span>: <span class="math inline">\(T=\frac{Y}{\sqrt{\frac{\sum_{i=1}^nX_i^2}{n}}}=\frac{Y}{\sqrt{\xi
/ n}}\sim t_n\)</span></p></li>
<li><p><span class="math inline">\(F\)</span> Distribution：</p>
<p><span class="math inline">\(F\)</span> distribution with degree of
freedom <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span>: $ F=F_{m,n}$</p>
<ul>
<li>If <span class="math inline">\(Z\sim F_{m,n}\)</span>, then <span class="math inline">\(\dfrac{1}{Z}\sim F_{n,m}\)</span>；</li>
<li>If <span class="math inline">\(T\sim t_n\)</span>, then <span class="math inline">\(T^2\sim F_{1,n}\)</span>。</li>
</ul></li>
</ul>
<h1 id="后记">后记</h1>
<p>统推经典问题考了，计算和 SLLN 的 Remark
合出了一道题，反例没考；四种收敛里面我背的最痛苦的是几乎处处收敛但是没考，好似，特征函数条件考的是
Durrett 上那个变式，我觉得可能写不好就没写。Kronecker lemma 没考，SLLN
经典题，Lindeberg
把方差和条件轻微修改了一下，鞅论是原题。背定理总比真在考场上做题的紧张感弱一点。</p>
<p>我还挺喜欢概率的，概统是选定了，具体的之后再说，暑假争取多读点
Durrett。</p>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>概率</tag>
      </tags>
  </entry>
  <entry>
    <title>2022 Sharygin Geometry Olympic 题解小记</title>
    <url>/2022/08/14/Sharygin-Geometry-Olympic/</url>
    <content><![CDATA[<p>今年是第三次写 Sharygin Geometry Olympic
题解，可能是最后一次。<del>所以我又来水字数了</del></p>
<p>退役两年人员写几何题快裂开了，从来没觉得做题这么难过。但是蛮好玩的，什么叫思维体操啊（</p>
<p>只做了一点微小的贡献，谢谢大家。</p>
<span id="more"></span>
<p><img src="https://s2.loli.net/2022/08/14/1Uc97zNGbL3mwDF.png" alt="_B68C16QRPWR_OTA_22DPC2.png"></p>
<p><img src="https://s2.loli.net/2022/08/14/mKqN7Euwn5oxD3h.png" alt="img"></p>
<p><img src="https://s2.loli.net/2022/08/14/yxTUP4rwhBmMbaA.png" alt="image-20220814144153170"></p>
<p>显然，本人不善几何。尤其是自己的通讯地址变成华子之后水平骤降，每次都是替大家扫水题，然后排最后一个。其实这次论数量论质量都应该是排第四的，但是为了给新成员让路所以还是排最后了...啊就这样吧
XD，也不重要。<del>还是看看远处的 SRT 吧家人们</del></p>
<p>在新星发文章的最高记录是二作，大概是 2020 Vietnam Mathmatics
Olympic。成员们来来去去，最年轻的也马上高三了，或许是最后一次合作，起码我应该不会再参加了。</p>
<p>第一次在电脑上用 Geogebra，之前都是在手机上用，电脑上用
Sketchpad。Geogebra 上手莫名很快，手感也很熟悉，再一想发现快捷键和
AutoCAD 一模一样，这下职业病了。然后也是第一次尝试用 tikz 在 LaTeX
文档里插图，感觉还挺好用，赞美。</p>
<p>另外，谁能想到我五个几何题做了一天呢（思维体操，思维体操.jpg</p>
<h1 id="section">8-1</h1>
<p>非常水，我甚至能 15 分钟解决（</p>
<p>Sharygin2022.pdf（策划不给源代码，可恶（？</p>
<p><img src="https://s2.loli.net/2022/08/15/PNSgcDOoFwTaYU4.png" alt="image-20220815015024256"></p>
<p>Sharygin-by-Chiyuru.tex</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\textbf</span>&#123;8-1 证明:&#125;取<span class="built_in">$</span><span class="keyword">\triangle</span> BCD<span class="built_in">$</span>的外心为<span class="built_in">$</span>O<span class="built_in">$</span>.于是有<span class="built_in">$</span>OB=OD,AB=AD<span class="built_in">$</span>,由于</span><br><span class="line">	</span><br><span class="line"><span class="built_in">$</span><span class="keyword">\angle</span> DBO=90<span class="built_in">^</span><span class="keyword">\circ</span> -<span class="keyword">\angle</span> BCD=90<span class="built_in">^</span><span class="keyword">\circ</span> -<span class="keyword">\frac</span>&#123;1&#125;&#123;2&#125;<span class="keyword">\angle</span> BAD=<span class="keyword">\angle</span> ABD<span class="built_in">$</span>,</span><br><span class="line">	</span><br><span class="line">可知四边形<span class="built_in">$</span>ABOD<span class="built_in">$</span>为菱形.故有<span class="built_in">$</span>CP=AB=OD<span class="built_in">$</span>,且</span><br><span class="line">	</span><br><span class="line"><span class="built_in">$</span><span class="keyword">\angle</span> DCP=180<span class="built_in">^</span><span class="keyword">\circ</span> -<span class="keyword">\angle</span> ABC-<span class="keyword">\angle</span> BCD=180<span class="built_in">^</span><span class="keyword">\circ</span> -(<span class="keyword">\angle</span> ABD+<span class="keyword">\angle</span> BCD)-<span class="keyword">\angle</span> DBC=90<span class="built_in">^</span><span class="keyword">\circ</span> -<span class="keyword">\angle</span> DBC=<span class="keyword">\angle</span> ODC<span class="built_in">$</span></span><br><span class="line">	</span><br><span class="line">于是<span class="built_in">$</span>OD,CP<span class="built_in">$</span>互相平行且相等,则四边形<span class="built_in">$</span>OCPD<span class="built_in">$</span>为平行四边形,有<span class="built_in">$</span>CP=OD=OC=DP<span class="built_in">$</span>,得证.<span class="keyword">\qed</span></span><br><span class="line">	</span><br><span class="line"><span class="keyword">\textbf</span>&#123;评注:&#125;题目中的二倍角条件几乎明示了作圆心，连出辅助线后即得解。</span><br></pre></td></tr></table></figure>
<p>8-1.ggb（tikz 看起来丑丑的？</p>
<p><img src="https://s2.loli.net/2022/08/15/lnuBYpK5otj8ChA.png" alt="image-20220815014846845"></p>
<h1 id="section-1">8-2</h1>
<p>稍微有点痛，但是也还好，还是水题。</p>
<p>Sharygin2022.pdf</p>
<p><img src="https://s2.loli.net/2022/08/15/ysTVvjFzuHOapWi.png" alt="image-20220815015121064"></p>
<p>Sharygin-by-Chiyuru.tex</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\textbf</span>&#123;8-2 证明:&#125;取<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">_</span>1<span class="built_in">$</span>与<span class="built_in">$</span>AB<span class="built_in">$</span>的交点为<span class="built_in">$</span>E&#x27;<span class="built_in">$</span>.</span><br><span class="line">    </span><br><span class="line">有<span class="built_in">$</span><span class="keyword">\angle</span> CME&#x27;=<span class="keyword">\angle</span> CBE&#x27;=<span class="keyword">\angle</span> ME&#x27;A=90<span class="built_in">^</span><span class="keyword">\circ</span><span class="built_in">$</span>.可知<span class="built_in">$</span>M,E&#x27;A,D<span class="built_in">$</span>四点共圆,<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">_</span>1<span class="built_in">$</span>与<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">_</span>2<span class="built_in">$</span>的交点<span class="built_in">$</span>E<span class="built_in">$</span>与<span class="built_in">$</span>E&#x27;<span class="built_in">$</span>重合,在<span class="built_in">$</span>AB<span class="built_in">$</span>上.</span><br><span class="line">    </span><br><span class="line">故<span class="built_in">$</span><span class="keyword">\angle</span> CFD=<span class="keyword">\angle</span> CBE=90<span class="built_in">^</span><span class="keyword">\circ</span><span class="built_in">$</span>,<span class="built_in">$</span>M<span class="built_in">$</span>为斜边<span class="built_in">$</span>CD<span class="built_in">$</span>中点,即<span class="built_in">$</span>MF=MD=CM<span class="built_in">$</span>.</span><br><span class="line">    </span><br><span class="line">又注意到<span class="built_in">$</span><span class="keyword">\angle</span> AGB=<span class="keyword">\angle</span> CBF=<span class="keyword">\angle</span> FMD<span class="built_in">$</span>,即得<span class="built_in">$</span>M,F,G,D<span class="built_in">$</span>四点共圆,则<span class="built_in">$</span><span class="keyword">\angle</span> BGM=<span class="keyword">\angle</span> MDF=<span class="keyword">\angle</span> MFD=<span class="keyword">\angle</span> MGD<span class="built_in">$</span>,得证.<span class="keyword">\qed</span></span><br><span class="line">	</span><br><span class="line"><span class="keyword">\textbf</span>&#123;评注:&#125;作图准确的话可以很快得到<span class="built_in">$</span>E<span class="built_in">$</span>在线段<span class="built_in">$</span>AB<span class="built_in">$</span>上的结论，倒角即得解。</span><br></pre></td></tr></table></figure>
<p>8-2.ggb</p>
<p><img src="https://s2.loli.net/2022/08/15/Lpy3aAKCNsTvkcU.png" alt="image-20220815015442452"></p>
<p>策划说他写了个脚本批量修改 tikz 的格式，我们只要交个 .ggb
就好了。所以我前两张图的线粗细都不一样，测试一下（</p>
<h1 id="section-2">8-4</h1>
<p>这个题太痛了，我想了有一个多小时，然后发现自己好傻。</p>
<p>Sharygin2022.pdf</p>
<p><img src="https://s2.loli.net/2022/08/15/TFeBSaLlR3U7rxZ.png" alt="image-20220815015833700"></p>
<p>Sharygin-by-Chiyuru.tex</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\textbf</span>&#123;8-4 证明:&#125;取<span class="built_in">$</span><span class="keyword">\astrosun</span> (OPN)<span class="built_in">$</span> 和<span class="built_in">$</span>CD<span class="built_in">$</span>的另一交点为<span class="built_in">$</span>S<span class="built_in">$</span>,<span class="built_in">$</span><span class="keyword">\astrosun</span> (OPM)<span class="built_in">$</span>和<span class="built_in">$</span>AB<span class="built_in">$</span>的另一交点为<span class="built_in">$</span>T<span class="built_in">$</span>.</span><br><span class="line">联结<span class="built_in">$</span>SC<span class="built_in">_</span>1,SD<span class="built_in">_</span>1,B<span class="built_in">_</span>1T,A<span class="built_in">_</span>1T,SP,PT,ON,OM<span class="built_in">$</span>.</span><br><span class="line">    </span><br><span class="line">由<span class="built_in">$</span><span class="keyword">\angle</span> SPO=<span class="keyword">\angle</span> OND=<span class="keyword">\angle</span> OMA=<span class="keyword">\angle</span> OPT=90<span class="built_in">^</span><span class="keyword">\circ</span><span class="built_in">$</span>,知<span class="built_in">$</span>S,P,T<span class="built_in">$</span>三点共线.</span><br><span class="line">    </span><br><span class="line">考虑到<span class="built_in">$</span><span class="keyword">\triangle</span> PDC<span class="built_in">$</span>和<span class="built_in">$</span><span class="keyword">\triangle</span> PAB<span class="built_in">$</span>为相似三角形,其顶点与中点连线<span class="built_in">$</span>PN,PM<span class="built_in">$</span>、对应边的中垂线<span class="built_in">$</span>ON,OM<span class="built_in">$</span>的夹角对应地相等.即<span class="built_in">$</span><span class="keyword">\angle</span> OSP=<span class="keyword">\angle</span> ONP=<span class="keyword">\angle</span> OMP=<span class="keyword">\angle</span> OTP<span class="built_in">$</span>.也即<span class="built_in">$</span><span class="keyword">\astrosun</span> (OPN)<span class="built_in">$</span> 和<span class="built_in">$</span><span class="keyword">\astrosun</span> (OPM)<span class="built_in">$</span>的半径相等.</span><br><span class="line">    </span><br><span class="line">由此可知<span class="built_in">$</span>SP=PT,SD<span class="built_in">_</span>1=B<span class="built_in">_</span>1T,SC<span class="built_in">_</span>1=A<span class="built_in">_</span>1T,A<span class="built_in">_</span>1B<span class="built_in">_</span>1=C<span class="built_in">_</span>1D<span class="built_in">_</span>1<span class="built_in">$</span>.故<span class="built_in">$</span><span class="keyword">\triangle</span> SD<span class="built_in">_</span>1C<span class="built_in">_</span>1 <span class="keyword">\cong</span> <span class="keyword">\triangle</span> TB<span class="built_in">_</span>1A<span class="built_in">_</span>1<span class="built_in">$</span>.</span><br><span class="line">    </span><br><span class="line">考虑到<span class="built_in">$</span><span class="keyword">\angle</span> OC<span class="built_in">_</span>1P=<span class="keyword">\angle</span> OA<span class="built_in">_</span>1P<span class="built_in">$</span>,从而有<span class="built_in">$</span>OC<span class="built_in">_</span>1=OA<span class="built_in">_</span>1<span class="built_in">$</span>.同时<span class="built_in">$</span>OC=OA<span class="built_in">$</span>,得到<span class="built_in">$</span>C<span class="built_in">_</span>1C=A<span class="built_in">_</span>1A<span class="built_in">$</span>.同理也有<span class="built_in">$</span>B<span class="built_in">_</span>1B=D<span class="built_in">_</span>1D<span class="built_in">$</span>.</span><br><span class="line">过<span class="built_in">$</span>T<span class="built_in">$</span>作<span class="built_in">$</span>TF <span class="keyword">\bot</span> CA<span class="built_in">$</span>,过<span class="built_in">$</span>S<span class="built_in">$</span>作<span class="built_in">$</span>SE <span class="keyword">\bot</span> CA<span class="built_in">$</span>.由<span class="built_in">$</span>SP=PT<span class="built_in">$</span>可知<span class="built_in">$</span>TF=SE<span class="built_in">$</span>,结合<span class="built_in">$</span>C<span class="built_in">_</span>1C=A<span class="built_in">_</span>1A<span class="built_in">$</span> 可知<span class="built_in">$</span><span class="keyword">\triangle</span> AA<span class="built_in">_</span>1T<span class="built_in">$</span>和<span class="built_in">$</span><span class="keyword">\triangle</span> CC<span class="built_in">_</span>1S<span class="built_in">$</span>面积相等,同理<span class="built_in">$</span><span class="keyword">\triangle</span> BB<span class="built_in">_</span>1T<span class="built_in">$</span>和<span class="built_in">$</span><span class="keyword">\triangle</span> DD<span class="built_in">_</span>1S<span class="built_in">$</span>面积相等.</span><br><span class="line">    </span><br><span class="line">结合<span class="built_in">$</span><span class="keyword">\triangle</span> SD<span class="built_in">_</span>1C<span class="built_in">_</span>1 <span class="keyword">\cong</span> <span class="keyword">\triangle</span> TB<span class="built_in">_</span>1A<span class="built_in">_</span>1<span class="built_in">$</span>可知,四边形<span class="built_in">$</span>AA<span class="built_in">_</span>1B<span class="built_in">_</span>1B<span class="built_in">$</span>与<span class="built_in">$</span>CC<span class="built_in">_</span>1D<span class="built_in">_</span>1D<span class="built_in">$</span>面积相等,得证.<span class="keyword">\qed</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">\textbf</span>&#123;评注:&#125;本题大量运用了对称性，需要一定的几何直觉。作图准确的话不难发现两圆半径相等，从而迎刃而解。</span><br></pre></td></tr></table></figure>
<p>《迎 刃 而 解》</p>
<p>8-4.ggb</p>
<p><img src="https://s2.loli.net/2022/08/15/oQWZ4YFVtvAgMpc.png" alt="image-20220815020020232"></p>
<h1 id="section-3">8-7</h1>
<p>这个最痛。组合几何，尤其是答案都出乎意料的组合几何，太痛了（</p>
<p>Sharygin2022.pdf</p>
<p><img src="https://s2.loli.net/2022/08/15/RmnEHUKYSu9zgO5.png" alt="image-20220815020103145"></p>
<p>Sharygin-by-Chiyuru.tex</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\textbf</span>&#123;8-7 解:&#125;否。证明如下：</span><br><span class="line">	</span><br><span class="line">首先证明一个引理:对于共圆的四个点,它们一定位于某个正方形上.</span><br><span class="line">	</span><br><span class="line">不妨设共圆的四点为<span class="built_in">$</span>A,B,C,D<span class="built_in">$</span>,其中,四边形<span class="built_in">$</span>ABCD<span class="built_in">$</span>有至少两个角不是锐角，记为<span class="built_in">$</span><span class="keyword">\angle</span> B,<span class="keyword">\angle</span> C<span class="built_in">$</span>.</span><br><span class="line">两边延长<span class="built_in">$</span>BC<span class="built_in">$</span>,过<span class="built_in">$</span>A,D<span class="built_in">$</span>分别作<span class="built_in">$</span>BC<span class="built_in">$</span>的垂线<span class="built_in">$</span>AH,DF<span class="built_in">$</span>.不妨设<span class="built_in">$</span>AH≥DF<span class="built_in">$</span>,过<span class="built_in">$</span>A<span class="built_in">$</span>在<span class="built_in">$</span>FD<span class="built_in">$</span>的延长线上作垂线<span class="built_in">$</span>AG<span class="built_in">$</span>.从而四点<span class="built_in">$</span>A,B,C,D<span class="built_in">$</span>位于长方形<span class="built_in">$</span>HFGA<span class="built_in">$</span>上.若<span class="built_in">$</span>HFGA<span class="built_in">$</span>为正方形则引理已得证.</span><br><span class="line">	</span><br><span class="line">当<span class="built_in">$</span>HF&gt;FG<span class="built_in">$</span>时,分别延长<span class="built_in">$</span>HA,FG<span class="built_in">$</span>至<span class="built_in">$</span>A&#x27;,G&#x27;<span class="built_in">$</span>,使得<span class="built_in">$</span>HA&#x27;G&#x27;F<span class="built_in">$</span>为正方形,<span class="built_in">$</span>A,B,C,D<span class="built_in">$</span>在其上;当<span class="built_in">$</span>HF&lt;FG<span class="built_in">$</span>时,同理分别延长<span class="built_in">$</span>HF,GA<span class="built_in">$</span>至<span class="built_in">$</span>H&#x27;,A&#x27;<span class="built_in">$</span>即可.引理得证.</span><br><span class="line">	</span><br><span class="line">下面举出原命题的反例.取一个圆内接十边形的顶点,则它们不可能在同一个正方形上,这是因为一个正方形和圆最多有<span class="built_in">$</span>8<span class="built_in">$</span>个交点;同时,这<span class="built_in">$</span>10<span class="built_in">$</span>个点中的任意<span class="built_in">$</span>4<span class="built_in">$</span>个共圆,由引理知也即位于某一个正方形上.故原命题不一定成立,得证.</span><br><span class="line">	</span><br><span class="line"><span class="keyword">\textbf</span>&#123;评注:&#125;本题的举例非常巧妙，笔者写作过程中的最大困难在于判断命题的对错，因此走了一段弯路。</span><br></pre></td></tr></table></figure>
<p>8-7.ggb</p>
<p><img src="https://s2.loli.net/2022/08/15/USGKwlcHkMpFr9x.png" alt="image-20220815020229724"></p>
<h1 id="section-4">9-1</h1>
<p>这不比前面的都简单太多了？.jpg</p>
<p>Sharygin2022.pdf</p>
<p><img src="https://s2.loli.net/2022/08/15/XrtWVJ1iHUsNwEy.png" alt="image-20220815020307265"></p>
<p>Sharygin-by-Chiyuru.tex</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\textbf</span>&#123;9-1 证明:&#125;</span><br><span class="line">显然,<span class="built_in">$</span>BC<span class="built_in">_</span>1=<span class="keyword">\frac</span>&#123;1&#125;&#123;2&#125; (BH+HC+CB),BA<span class="built_in">_</span>1=<span class="keyword">\frac</span>&#123;1&#125;&#123;2&#125; (BA+AH+BH)<span class="built_in">$</span>.</span><br><span class="line">	</span><br><span class="line">于是<span class="built_in">$</span><span class="keyword">\frac</span>&#123;BC<span class="built_in">_</span>1&#125;&#123;BA<span class="built_in">_</span>1&#125;=<span class="keyword">\frac</span>&#123;BH+HC+CB&#125;&#123;BA+AH+BH&#125;=<span class="keyword">\frac</span>&#123;BC&#125;&#123;BA&#125;<span class="built_in">$</span>,从而<span class="built_in">$</span>AC<span class="keyword">\parallel</span> A<span class="built_in">_</span>1C<span class="built_in">_</span>1 <span class="built_in">$</span>,得证.<span class="keyword">\qed</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">\textbf</span>&#123;评注:&#125;非常基础的题目，熟知切点关于长度的结论即可。</span><br></pre></td></tr></table></figure>
<p>9-1.ggb</p>
<p><img src="https://s2.loli.net/2022/08/15/kN4LX1HRio6YB9h.png" alt="image-20220815020412523"></p>
<h1 id="后记与碎碎念">后记与碎碎念</h1>
<p>等到发表了（可能会拖到十月、十一月？）再来补个后记。其实就是丢个链接和文档，权当记录了。</p>
<p>看到行在清华公众号发的推文，才知道北京已经凉快些了，是初秋。上海还是每天都
40°C 左右，热得好难受。</p>
<p>这么说来，快要回去了。</p>
<h1 id="后后记update-8-6">后后记：Update 8-6</h1>
<p>这个锅甩来甩去又回到了我手上，不会做，晚上把它翻译好了。</p>
<p>摸到了倒数第二作x。</p>
<p>Sharygin2022.pdf</p>
<p><img src="https://s2.loli.net/2022/08/20/aemiT9nd35gKrtG.png" alt="image-20220820231640822"></p>
<p>Sharygin-8-6-by-Chiyuru.tex</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\textbf</span>&#123;8-6 解:&#125;我们首先给出作图方式：</span><br><span class="line">	</span><br><span class="line">联结两圆<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">_</span>1、<span class="keyword">\omega</span><span class="built_in">_</span>2<span class="built_in">$</span>的圆心<span class="built_in">$</span>O<span class="built_in">_</span>1、O<span class="built_in">_</span>2<span class="built_in">$</span>,任取<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">_</span>1<span class="built_in">$</span>上的点<span class="built_in">$</span>T<span class="built_in">$</span>并联结<span class="built_in">$</span>O<span class="built_in">_</span>2T<span class="built_in">$</span>,作直线<span class="built_in">$</span>O<span class="built_in">_</span>1S<span class="keyword">\parallel</span> O<span class="built_in">_</span>2T<span class="built_in">$</span>交<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">_</span>2<span class="built_in">$</span>于<span class="built_in">$</span>S<span class="built_in">$</span>.取<span class="built_in">$</span>ST<span class="built_in">$</span>与<span class="built_in">$</span>O<span class="built_in">_</span>1O<span class="built_in">_</span>2<span class="built_in">$</span>的交点为<span class="built_in">$</span>I<span class="built_in">$</span>.</span><br><span class="line">作射线<span class="built_in">$</span>OI<span class="built_in">$</span>分别交<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">_</span>1、<span class="keyword">\omega</span><span class="built_in">_</span>2<span class="built_in">$</span>于<span class="built_in">$</span>D,C<span class="built_in">$</span>,此即为<span class="built_in">$</span>OC:OD<span class="built_in">$</span>取最大值的情形.</span><br><span class="line">	</span><br><span class="line">证明:过<span class="built_in">$</span>O<span class="built_in">$</span>点以<span class="built_in">$</span>OC:OD<span class="built_in">$</span>为比例作<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">_</span>1<span class="built_in">$</span>的外位似圆<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">$</span>,</span><br><span class="line">易知<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">$</span>过点<span class="built_in">$</span>C<span class="built_in">$</span>.当<span class="built_in">$</span>OC:OD<span class="built_in">$</span>取最大值时,过<span class="built_in">$</span>O<span class="built_in">$</span>点以系数<span class="built_in">$</span>k&gt;OC:OD<span class="built_in">$</span>为比例作<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">_</span>1<span class="built_in">$</span>的外位似圆<span class="built_in">$</span><span class="keyword">\omega</span>&#x27;<span class="built_in">$</span>与<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">_</span>2<span class="built_in">$</span>无交点.</span><br><span class="line">	</span><br><span class="line">因此<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">$</span>和<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">_</span>1<span class="built_in">$</span>相切于<span class="built_in">$</span>C<span class="built_in">$</span>点.取<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">$</span>圆心为<span class="built_in">$</span>O<span class="built_in">_</span>3<span class="built_in">$</span>,有<span class="built_in">$</span>O<span class="built_in">_</span>2,C,O<span class="built_in">_</span>3<span class="built_in">$</span>共线,且<span class="built_in">$</span>O<span class="built_in">_</span>2O<span class="built_in">_</span>3<span class="keyword">\parallel</span> O<span class="built_in">_</span>1D<span class="built_in">$</span>.故射线<span class="built_in">$</span>ODC<span class="built_in">$</span>与线段<span class="built_in">$</span>O<span class="built_in">_</span>1O<span class="built_in">_</span>2<span class="built_in">$</span>交于<span class="built_in">$</span><span class="keyword">\omega</span><span class="built_in">_</span>1、<span class="keyword">\omega</span><span class="built_in">_</span>2<span class="built_in">$</span>的内位似中心，即为上述作出的<span class="built_in">$</span>I<span class="built_in">$</span>,得证.<span class="keyword">\qed</span></span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line"><span class="keyword">\textbf</span>&#123;评注:&#125;尺规作图题中常见的利用位似性质的题目，非常精妙。</span><br></pre></td></tr></table></figure>
<p>8-6.ggb</p>
<p><img src="https://s2.loli.net/2022/08/20/feokWsvVIGJ6m3T.png" alt="b.png"></p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
        <tag>这里面看起来很好玩</tag>
      </tags>
  </entry>
  <entry>
    <title>刷 Python Crash Course 然后还有酒井暑培 AI Track</title>
    <url>/2022/08/01/Python-Crash-Course/</url>
    <content><![CDATA[<p>简单的自救以及#每日这里面看起来很好玩。</p>
<p>其实就是写了点刷书习题，然后暑培写了 AI Track
的大作业。水个字数。</p>
<span id="more"></span>
<h1 id="前一半前言">前一半前言</h1>
<p>实际上，先前我在清华上过的每一门 CS
课程都或者痛苦不堪，或者毫无收获。</p>
<p>第一学期上了郑莉老师的 C++
程序设计基础选修课，从指针之后就开始加速冲，一节课链表一节课栈队列一节课模板一节课
IO
流一节课异常处理然后讲了些七零八碎的东西就上完了。我太菜了，指针之后就没跟上过，每周爆哭着写
OJ
题，写完就忘，摆烂到学期结束交了一个大作业，“优点是能跑，缺点是能跑的补集”。</p>
<p>老师表面反卷战士，不要求图形界面不要求炫酷功能，实际上助教评分把这些全评上了。拿
4.0
的都是来水绩点的佬，大作业答辩的时候我在众人中就像个垃圾桶，最后靠助教捞了一把才摸到一个
3.6。从此对所谓的“零基础”课程过敏，也对贵系课有了巨大恐惧，开始考虑转数而不是转码的事情。</p>
<p>第二学期为了完成培养方案，又重选了乔林老师的计程设，<del>这培养方案什么都替代不了，烦死啦。</del>也想重学一下
C（因为看到电子系室友就是这么学的，只是顺序反过来）。然后他又是讲到指针就结束了，我都会也就没听过课。花了半天了解了一下二者的语法差别和集中写完了七次随堂作业，又花了半天写了一个全是循环的
2048
大作业，再花一天（其实是在回家的高铁上）写完了大作业文档，最后莫名其妙就拿到了我的第一个
A+<del>，普通工科的计算机课可真水啊</del>。</p>
<p>还有一门假装自己是数据库，实际上是会计技能速成的课，也是培养方案所迫。前半部分老师讲怎么用
Excel 和写 SQL，还算可以；后半部分助教讲的 Python
七零八碎，上课讲的和作业竟没有半点关系，每次写作业都又要爆哭到深夜，绷不住了还求助过社友。其实也没学会，但是完成作业就摸到了一个
A，莫名其妙。<del>欺负文科生很有趣是吗</del></p>
<p>本来打算完整参加酒井暑培，结果被拔智齿、实习和随之而生的摸鱼之魂拖住了脚步。想着退而求其次，自己刷一遍蛇书，再听一下
AI
Track。然后发现蛇书其实讲得相当不错，迅速解除了上学期在破数据库课上留下的心理阴影，理顺了很多历史遗留问题，学到许多。</p>
<h1 id="后一半前言">后一半前言</h1>
<p>上次学长问我为什么非要上抽代，我想了半天也只说出来万能理由“这里面看起来很有趣”，还有“假如之后转统计的话好像还是看起来有点数学背景比较好”。然后他问我多付出那么多时间学这个可能未来就没用了的东西值不值得，我说我不知道。他问我为什么要同时学基础拓扑学，我的理由还是上述两个，思来想去打算退掉了，想换一门稍微简单点的课（比如面向工科的
ODE）缓一缓，或许还能配合数值分析。<del>任选一志愿白给了</del>。数据结构即使是雷系的，一想起自己
C/C++
的水平就很退缩，想给它退了换一门离散来上，等春季重选。还有一个多月就要回学校了，我连秋季上什么课都还没定好，有点麻。</p>
<p>（中间本来还有一大段，但发出来的版本里删掉了。）</p>
<p>书院最早的一批学生都还没到读研的时候，完全无从参考。院系里零字班的强者还相对多些，一字班见到的才过了一年基本就都在转出的路上半途而废了。<strong>（以偏概全警告）</strong></p>
<p>搞不清楚。一想到这些，还有我本人的自闭性格，我就想把头塞进抽屉里先逃避一下，最多拿出初概的
PPT 先看一会，假装自己还是先去学了。</p>
<p>扯远了，这篇是在说看蛇书和暑培的事情。</p>
<h1 id="先简单写亿个蛇书习题">先简单写亿个蛇书习题</h1>
<p><strong>取名鬼才警告，随手捏的信息不合实际警告，水字数警告。</strong></p>
<h2 id="基础">基础</h2>
<h3 id="切片">4-10 切片</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#4-10 切片</span></span><br><span class="line">list1 = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">8</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;first three:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> number <span class="keyword">in</span> list1[<span class="number">0</span>:<span class="number">3</span>]:</span><br><span class="line">    <span class="built_in">print</span>(number)</span><br><span class="line">    </span><br><span class="line">length=<span class="built_in">len</span>(list1)</span><br><span class="line">location=length//<span class="number">2</span>+<span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;middle three:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> number <span class="keyword">in</span> list1[location-<span class="number">2</span>:location+<span class="number">1</span>]:</span><br><span class="line">    <span class="built_in">print</span>(number)</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;last three:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> number <span class="keyword">in</span> list1[-<span class="number">3</span>:]:</span><br><span class="line">    <span class="built_in">print</span>(number)</span><br></pre></td></tr></table></figure>
<h3 id="检查用户名">5-10 检查用户名</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#5-10 检查用户名</span></span><br><span class="line">current_users = [<span class="string">&#x27;neruko&#x27;</span>,<span class="string">&#x27;Chiyuru&#x27;</span>,<span class="string">&#x27;chiyuruuu&#x27;</span>,<span class="string">&#x27;ouuan&#x27;</span>,<span class="string">&#x27;pieris05&#x27;</span>]</span><br><span class="line">new_users = [<span class="string">&#x27;Neruko&#x27;</span>,<span class="string">&#x27;aliceZ&#x27;</span>,<span class="string">&#x27;chiyuruuu&#x27;</span>,<span class="string">&#x27;chiyuruu&#x27;</span>,<span class="string">&#x27;TA&#x27;</span>]</span><br><span class="line"><span class="comment">#取名鬼才真的编不出来名字，谢谢社友们</span></span><br><span class="line">current_users2=[user.lower() <span class="keyword">for</span> user <span class="keyword">in</span> current_users]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> users <span class="keyword">in</span> new_users:</span><br><span class="line">    <span class="keyword">if</span> users.lower() <span class="keyword">in</span> current_users2:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;The name <span class="subst">&#123;users&#125;</span> has been used!&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;You can use the name <span class="subst">&#123;users&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Programme ended.&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="宠物">6-8 宠物</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#6-8 宠物</span></span><br><span class="line">pet_01 = &#123;<span class="string">&#x27;pet_type&#x27;</span>:<span class="string">&#x27;cat&#x27;</span>,<span class="string">&#x27;owner&#x27;</span>:<span class="string">&#x27;Chiyuru&#x27;</span>&#125;</span><br><span class="line">pet_02 = &#123;<span class="string">&#x27;pet_type&#x27;</span>:<span class="string">&#x27;dog&#x27;</span>,<span class="string">&#x27;owner&#x27;</span>:<span class="string">&#x27;ouuan&#x27;</span>&#125;</span><br><span class="line">pet_03 = &#123;<span class="string">&#x27;pet_type&#x27;</span>:<span class="string">&#x27;cat&#x27;</span>,<span class="string">&#x27;owner&#x27;</span>:<span class="string">&#x27;Neruko&#x27;</span>&#125;</span><br><span class="line">pets = [pet_01,pet_02,pet_03]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> pet <span class="keyword">in</span> pets:</span><br><span class="line">    pettype = pet[<span class="string">&#x27;pet_type&#x27;</span>]</span><br><span class="line">    ownername = pet[<span class="string">&#x27;owner&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;The <span class="subst">&#123;pettype&#125;</span>&#x27;s owner is <span class="subst">&#123;ownername&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;These are all the pets.&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="喜欢的地方">6-9 喜欢的地方</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#6-9 喜欢的地方</span></span><br><span class="line">favorite_places = &#123;<span class="string">&#x27;chiyuru&#x27;</span>:[<span class="string">&#x27;Shanghai&#x27;</span>,<span class="string">&#x27;London&#x27;</span>,<span class="string">&#x27;Tokyo&#x27;</span>],</span><br><span class="line">                   <span class="string">&#x27;Neruko&#x27;</span>:[<span class="string">&#x27;Beijing&#x27;</span>],</span><br><span class="line">                   <span class="string">&#x27;ouuan&#x27;</span>:[<span class="string">&#x27;Beijing&#x27;</span>]&#125;</span><br><span class="line"><span class="comment">#谢谢社友，其实只是写了北京（</span></span><br><span class="line"><span class="keyword">for</span> people <span class="keyword">in</span> favorite_places.keys():</span><br><span class="line">    <span class="keyword">for</span> city <span class="keyword">in</span> favorite_places[people]:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;people&#125;</span> loves <span class="subst">&#123;city&#125;</span>.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Programme ended.&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="城市">6-11 城市</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#6-11 城市</span></span><br><span class="line">cities = &#123;<span class="string">&#x27;Shanghai&#x27;</span>:&#123;</span><br><span class="line">    <span class="string">&#x27;country&#x27;</span>:<span class="string">&#x27;China&#x27;</span>,<span class="string">&#x27;pop&#x27;</span>:<span class="string">&quot;2kw&quot;</span>,<span class="string">&#x27;fact&#x27;</span>:<span class="string">&#x27;Best city in China&#x27;</span>&#125;,</span><br><span class="line">          <span class="string">&#x27;London&#x27;</span>:&#123;</span><br><span class="line">    <span class="string">&#x27;country&#x27;</span>:<span class="string">&#x27;Britain&#x27;</span>,<span class="string">&#x27;pop&#x27;</span>:<span class="string">&#x27;1kw&#x27;</span>,<span class="string">&#x27;fact&#x27;</span>:<span class="string">&#x27;Capital of Britain&#x27;</span>&#125;,</span><br><span class="line">          <span class="string">&#x27;Tokyo&#x27;</span>:&#123;</span><br><span class="line">    <span class="string">&#x27;country&#x27;</span>:<span class="string">&#x27;Japan&#x27;</span>,<span class="string">&#x27;pop&#x27;</span>:<span class="string">&#x27;2kw&#x27;</span>,<span class="string">&#x27;fact&#x27;</span>:<span class="string">&#x27;Heaven of ACGN&#x27;</span>&#125;&#125;  <span class="comment">#这都是什么暴论</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> city <span class="keyword">in</span> cities.keys():</span><br><span class="line">    info = cities[city]</span><br><span class="line">    place = info[<span class="string">&#x27;country&#x27;</span>]</span><br><span class="line">    people = info[<span class="string">&#x27;pop&#x27;</span>]</span><br><span class="line">    description = info[<span class="string">&#x27;fact&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;city&#125;</span> is in <span class="subst">&#123;place&#125;</span>. There&#x27;re <span class="subst">&#123;people&#125;</span> people live here. Chiyuru describe it as <span class="subst">&#123;description&#125;</span>. &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;These are the cities.&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="披萨配料">7-4 披萨配料</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#7-4 披萨配料</span></span><br><span class="line">toppings = [<span class="string">&#x27;pepper&#x27;</span>,<span class="string">&#x27;chicken&#x27;</span>,<span class="string">&#x27;ketchup&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> topping <span class="keyword">in</span> toppings:</span><br><span class="line">    get = <span class="built_in">input</span>(<span class="string">f&quot;Please enter the addictive:<span class="subst">&#123;topping&#125;</span>\n&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> get == <span class="string">&#x27;quit&#x27;</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Thank you!&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">elif</span> get <span class="keyword">in</span> toppings:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;You&#x27;ve added <span class="subst">&#123;get&#125;</span>.&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;You&#x27;ve got the wrong recipe!&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="电影票">7-5 电影票</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#7-5 电影票</span></span><br><span class="line">count = <span class="number">1</span></span><br><span class="line"><span class="keyword">while</span> count &lt;= <span class="number">1</span>:</span><br><span class="line">    age = <span class="built_in">input</span>(<span class="string">&quot;Please tell me your age:\n&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">int</span>(age) &lt; <span class="number">3</span>:</span><br><span class="line">        ticket = <span class="number">0</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Your ticket is <span class="subst">&#123;ticket&#125;</span> dollar.&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">int</span>(age) &lt; <span class="number">12</span>:</span><br><span class="line">        ticket = <span class="number">10</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Your ticket is <span class="subst">&#123;ticket&#125;</span> dollars.&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">int</span>(age) &gt; <span class="number">12</span>:</span><br><span class="line">        ticket = <span class="number">15</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Your ticket is <span class="subst">&#123;ticket&#125;</span> dollars.&quot;</span>)</span><br><span class="line">    count = count + <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3 id="熟食店">7-8 熟食店</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#7-8 熟食店</span></span><br><span class="line">sandwich_orders = [<span class="string">&#x27;tuna&#x27;</span>, <span class="string">&#x27;vegetable&#x27;</span>, <span class="string">&#x27;ham&#x27;</span>, <span class="string">&#x27;pastrami&#x27;</span>]</span><br><span class="line">finished_sandwiches = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> sandwich_orders:</span><br><span class="line">    order = sandwich_orders.pop()</span><br><span class="line">    finished_sandwiches.append(order)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;I made your <span class="subst">&#123;order&#125;</span> sandwich.&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The finished sandwiches are:&quot;</span>)    </span><br><span class="line"><span class="keyword">for</span> order <span class="keyword">in</span> finished_sandwiches:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;order&#125;</span> sandwich&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="五香牛肉">7-9 五香牛肉</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#7-9 五香牛肉</span></span><br><span class="line">sandwich_orders = [<span class="string">&#x27;pastrami&#x27;</span>,<span class="string">&#x27;tuna&#x27;</span>,<span class="string">&#x27;pastrami&#x27;</span>, <span class="string">&#x27;vegetable&#x27;</span>, <span class="string">&#x27;ham&#x27;</span>, <span class="string">&#x27;pastrami&#x27;</span>]</span><br><span class="line">finished_sandwiches = []</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The pastrami has been sold out.&quot;</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="string">&#x27;pastrami&#x27;</span> <span class="keyword">in</span> sandwich_orders:</span><br><span class="line">    sandwich_orders.remove(<span class="string">&#x27;pastrami&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> sandwich_orders:</span><br><span class="line">    order = sandwich_orders.pop()</span><br><span class="line">    finished_sandwiches.append(order)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;I made your <span class="subst">&#123;order&#125;</span> sandwich.&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="大号t恤">8-5 大号T恤</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#8-5 大号T恤</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_shirt</span>(<span class="params">size=<span class="string">&#x27;L&#x27;</span>,word=<span class="string">&#x27;I love Python&#x27;</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;The T-shirt is <span class="subst">&#123;size&#125;</span> size with the sentence &#x27;<span class="subst">&#123;word&#125;</span>&#x27;.&quot;</span>)</span><br><span class="line">make_shirt()</span><br><span class="line">make_shirt(<span class="string">&#x27;M&#x27;</span>,)</span><br><span class="line">make_shirt(word=<span class="string">&#x27;I love C&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="专辑">8-8 专辑</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#8-8 专辑</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_album</span>(<span class="params">singer,album</span>):</span><br><span class="line">    infos = &#123;<span class="string">&#x27;singer&#x27;</span>:singer,<span class="string">&#x27;album&#x27;</span>:album&#125;</span><br><span class="line">    <span class="keyword">return</span> infos</span><br><span class="line"><span class="built_in">print</span>(make_album(<span class="string">&#x27;Hoshino Gen&#x27;</span>,<span class="string">&#x27;Sun&#x27;</span>))</span><br><span class="line"></span><br><span class="line">flag = <span class="literal">True</span></span><br><span class="line"><span class="keyword">while</span> flag:</span><br><span class="line">    singer = <span class="built_in">input</span>(<span class="string">&quot;Please enter the name of the singer:&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> singer==<span class="string">&#x27;q&#x27;</span>:</span><br><span class="line">        flag = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    album = <span class="built_in">input</span>(<span class="string">&quot;Please enter the name of the album:&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> album == <span class="string">&#x27;q&#x27;</span>:</span><br><span class="line">        flag = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="built_in">print</span>(make_album(singer,album))</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The programme ended.&quot;</span>)        </span><br></pre></td></tr></table></figure>
<h3 id="发送消息">8-11 发送消息</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#8-11 发送消息</span></span><br><span class="line">msg = [<span class="string">&#x27;Hello!&#x27;</span>,<span class="string">&#x27;Nice day!&#x27;</span>,<span class="string">&#x27;Goodbye!&#x27;</span>]</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_messages</span>(<span class="params">messages</span>):</span><br><span class="line">    <span class="keyword">for</span> message <span class="keyword">in</span> messages:</span><br><span class="line">        <span class="built_in">print</span>(message)</span><br><span class="line">show_messages(msg)</span><br><span class="line"></span><br><span class="line">sent_msg = []</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_messages</span>(<span class="params">messages</span>):</span><br><span class="line">    msg2 = messages[:]</span><br><span class="line">    <span class="keyword">while</span> msg2:</span><br><span class="line">        message = msg2.pop()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Message &#x27;<span class="subst">&#123;message&#125;</span>&#x27; is sent.&quot;</span>)</span><br><span class="line">        sent_msg.append(message)</span><br><span class="line">    </span><br><span class="line">send_messages(msg)</span><br><span class="line">show_messages(msg)</span><br><span class="line">show_messages(sent_msg)</span><br></pre></td></tr></table></figure>
<h3 id="汽车">8-14 汽车</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#8-14 汽车</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_car</span>(<span class="params">builder,version,**carinfo</span>):</span><br><span class="line">    carinfo[<span class="string">&#x27;builder&#x27;</span>]=builder</span><br><span class="line">    carinfo[<span class="string">&#x27;version&#x27;</span>]=version</span><br><span class="line">    <span class="keyword">return</span> carinfo</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(save_car(<span class="string">&#x27;Toyota&#x27;</span>,<span class="string">&#x27;3&#x27;</span>,color=<span class="string">&#x27;red&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(save_car(<span class="string">&#x27;subaru&#x27;</span>,<span class="string">&#x27;outback&#x27;</span>,color=<span class="string">&#x27;blue&#x27;</span>,tow_package=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>
<h3 id="用户">9-5 用户</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#9-5 用户</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">User</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,firstName,lastName,notes,signature,login_attempts</span>):</span><br><span class="line">        self.firstName=firstName</span><br><span class="line">        self.lastName=lastName</span><br><span class="line">        self.notes=notes</span><br><span class="line">        self.signature=signature</span><br><span class="line">        self.login_attempts=login_attempts</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">describe_user</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;The user&#x27;s name is <span class="subst">&#123;self.firstName.title()&#125;</span> <span class="subst">&#123;self.lastName.title()&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;The user list the notes:<span class="subst">&#123;self.notes&#125;</span>.&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;The user list the signature:<span class="subst">&#123;self.signature&#125;</span>.&quot;</span>)</span><br><span class="line">       </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">greet_user</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Hello, <span class="subst">&#123;self.firstName.title()&#125;</span> <span class="subst">&#123;self.lastName.title()&#125;</span>!&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">increment_attempts</span>(<span class="params">self</span>):</span><br><span class="line">        self.login_attempts = self.login_attempts + <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Your login attempts are <span class="subst">&#123;self.login_attempts&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset_login_attempts</span>(<span class="params">self</span>):</span><br><span class="line">        self.login_attempts=<span class="number">0</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Your login attempts is <span class="subst">&#123;self.login_attempts&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">Chiyuruu = User(<span class="string">&quot;Feiyan&quot;</span>,<span class="string">&quot;Ma&quot;</span>,<span class="string">&quot;QWQ&quot;</span>,<span class="string">&quot;QWQWQ&quot;</span>,<span class="number">12</span>)</span><br><span class="line">Chiyuruu.describe_user()</span><br><span class="line">Chiyuruu.greet_user()</span><br><span class="line">Chiyuruu.increment_attempts()      </span><br><span class="line">Chiyuruu.increment_attempts() </span><br><span class="line">Chiyuruu.increment_attempts() </span><br><span class="line">Chiyuruu.increment_attempts() </span><br><span class="line">Chiyuruu.reset_login_attempts()</span><br></pre></td></tr></table></figure>
<h3 id="管理员">9-7 管理员</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#9-7 管理员</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">User</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,firstName,lastName,notes,signature,login_attempts</span>):</span><br><span class="line">        self.firstName=firstName</span><br><span class="line">        self.lastName=lastName</span><br><span class="line">        self.notes=notes</span><br><span class="line">        self.signature=signature</span><br><span class="line">        self.login_attempts=login_attempts</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">describe_user</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;The user&#x27;s name is <span class="subst">&#123;self.firstName.title()&#125;</span> <span class="subst">&#123;self.lastName.title()&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;The user list the notes:<span class="subst">&#123;self.notes&#125;</span>.&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;The user list the signature:<span class="subst">&#123;self.signature&#125;</span>.&quot;</span>)</span><br><span class="line">       </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">greet_user</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Hello, <span class="subst">&#123;self.firstName.title()&#125;</span> <span class="subst">&#123;self.lastName.title()&#125;</span>!&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">increment_attempts</span>(<span class="params">self</span>):</span><br><span class="line">        self.login_attempts = self.login_attempts + <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Your login attempts are <span class="subst">&#123;self.login_attempts&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset_login_attempts</span>(<span class="params">self</span>):</span><br><span class="line">        self.login_attempts=<span class="number">0</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Your login attempts is <span class="subst">&#123;self.login_attempts&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Admin</span>(<span class="title class_ inherited__">User</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,firstName,lastName,notes,signature,login_attempts,privileges = [<span class="string">&#x27;can add post&#x27;</span>,<span class="string">&#x27;can delete post&#x27;</span>,<span class="string">&#x27;can ban user&#x27;</span>]</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(firstName, lastName, notes, signature, login_attempts)</span><br><span class="line">        self.privileges = privileges</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_privileges</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> privilege <span class="keyword">in</span> self.privileges:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;The user is an Admin.He/She <span class="subst">&#123;privilege&#125;</span>.&quot;</span>)</span><br><span class="line"></span><br><span class="line">Chiyuru = Admin(<span class="string">&#x27;Feiyan&#x27;</span>,<span class="string">&#x27;Ma&#x27;</span>,<span class="string">&#x27;QWQ&#x27;</span>,<span class="string">&#x27;QWQWQ&#x27;</span>,<span class="number">114514</span>,)</span><br><span class="line"><span class="comment">#非常巧，今天8.1，正好是我在闭社成为监察员的第一天。</span></span><br><span class="line">Chiyuru.show_privileges()</span><br><span class="line">Chiyuru.greet_user()</span><br><span class="line">Chiyuru.describe_user()</span><br><span class="line">Chiyuru.increment_attempts()</span><br><span class="line">Chiyuru.reset_login_attempts()</span><br></pre></td></tr></table></figure>
<h3 id="权限换一种方式写9-7">9-8 权限（换一种方式写9-7）</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#9-8 权限（换一种方式写9-7）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Privileges</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,privileges = [<span class="string">&#x27;can add post&#x27;</span>,<span class="string">&#x27;can delete post&#x27;</span>,<span class="string">&#x27;can ban user&#x27;</span>]</span>):</span><br><span class="line">        self.privileges = privileges</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_privileges</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> privilege <span class="keyword">in</span> self.privileges:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;The user <span class="subst">&#123;privilege&#125;</span>.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">User</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,firstName,lastName,notes,signature,login_attempts</span>):</span><br><span class="line">        self.firstName=firstName</span><br><span class="line">        self.lastName=lastName</span><br><span class="line">        self.notes=notes</span><br><span class="line">        self.signature=signature</span><br><span class="line">        self.login_attempts=login_attempts</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">describe_user</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;The user&#x27;s name is <span class="subst">&#123;self.firstName.title()&#125;</span> <span class="subst">&#123;self.lastName.title()&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;The user list the notes:<span class="subst">&#123;self.notes&#125;</span>.&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;The user list the signature:<span class="subst">&#123;self.signature&#125;</span>.&quot;</span>)</span><br><span class="line">       </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">greet_user</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Hello, <span class="subst">&#123;self.firstName.title()&#125;</span> <span class="subst">&#123;self.lastName.title()&#125;</span>!&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">increment_attempts</span>(<span class="params">self</span>):</span><br><span class="line">        self.login_attempts = self.login_attempts + <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Your login attempts are <span class="subst">&#123;self.login_attempts&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset_login_attempts</span>(<span class="params">self</span>):</span><br><span class="line">        self.login_attempts=<span class="number">0</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Your login attempts is <span class="subst">&#123;self.login_attempts&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Admin</span>(<span class="title class_ inherited__">User</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,firstName,lastName,notes,signature,login_attempts</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(firstName, lastName, notes, signature, login_attempts)</span><br><span class="line">        self.privileges = Privileges()</span><br><span class="line">    </span><br><span class="line">Chiyuru = Admin(<span class="string">&#x27;Feiyan&#x27;</span>,<span class="string">&#x27;Ma&#x27;</span>,<span class="string">&#x27;QWQ&#x27;</span>,<span class="string">&#x27;QWQWQ&#x27;</span>,<span class="number">114514</span>)</span><br><span class="line">Chiyuru.privileges.show_privileges()</span><br></pre></td></tr></table></figure>
<h3 id="彩票">9-14 彩票</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#9-14 彩票</span></span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> choice</span><br><span class="line">ticket = (<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;3&#x27;</span>,<span class="string">&#x27;4&#x27;</span>,<span class="string">&#x27;5&#x27;</span>,<span class="string">&#x27;6&#x27;</span>,<span class="string">&#x27;7&#x27;</span>,<span class="string">&#x27;8&#x27;</span>,<span class="string">&#x27;9&#x27;</span>,<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;B&#x27;</span>,<span class="string">&#x27;C&#x27;</span>,<span class="string">&#x27;D&#x27;</span>,<span class="string">&#x27;E&#x27;</span>)</span><br><span class="line"></span><br><span class="line">my_ticket = [<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;4&#x27;</span>,<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;8&#x27;</span>]</span><br><span class="line">time = <span class="number">0</span></span><br><span class="line">flag = <span class="literal">False</span></span><br><span class="line"><span class="keyword">while</span> <span class="number">1</span>-flag:</span><br><span class="line">    time = time + <span class="number">1</span></span><br><span class="line">    letter1 = choice(ticket)</span><br><span class="line">    letter2 = choice(ticket)</span><br><span class="line">    letter3 = choice(ticket)</span><br><span class="line">    letter4 = choice(ticket)</span><br><span class="line">    letters = [letter1,letter2,letter3,letter4]</span><br><span class="line">    flag = (my_ticket == letters)</span><br><span class="line">    <span class="built_in">print</span>(letters)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;We have guessed <span class="subst">&#123;time&#125;</span> times.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The answer is correct!&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="python学习笔记">10-1 Python学习笔记</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#10-1 Python学习笔记</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;pi.txt&#x27;</span>) <span class="keyword">as</span> python_notes:</span><br><span class="line">    content = python_notes.read()</span><br><span class="line"><span class="built_in">print</span>(content)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;pi.txt&#x27;</span>) <span class="keyword">as</span> python_notes:</span><br><span class="line">    content_lines = python_notes.readlines()</span><br><span class="line"></span><br><span class="line">notes = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> content_lines:</span><br><span class="line">    <span class="built_in">print</span>(line.strip())</span><br><span class="line">    notes = notes + line.strip()</span><br><span class="line"><span class="built_in">print</span>(notes)</span><br></pre></td></tr></table></figure>
<h3 id="c语言学习笔记">10-2 C语言学习笔记</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#10-2 C语言学习笔记</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;pi.txt&#x27;</span>) <span class="keyword">as</span> python_notes:</span><br><span class="line">    content = python_notes.read()</span><br><span class="line"><span class="built_in">print</span>(content.replace(<span class="string">&#x27;Python&#x27;</span>,<span class="string">&#x27;C&#x27;</span>))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;pi.txt&#x27;</span>) <span class="keyword">as</span> python_notes:</span><br><span class="line">    content_lines = python_notes.readlines()</span><br><span class="line"></span><br><span class="line">notes = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> content_lines:</span><br><span class="line">    <span class="built_in">print</span>(line.strip().replace(<span class="string">&#x27;Python&#x27;</span>,<span class="string">&#x27;C&#x27;</span>))</span><br><span class="line">    notes = notes + line.strip()</span><br><span class="line"><span class="built_in">print</span>(notes.replace(<span class="string">&#x27;Python&#x27;</span>,<span class="string">&#x27;C&#x27;</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="访客名单">10-4 访客名单</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#10-4 访客名单</span></span><br><span class="line">guest = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">5</span>):</span><br><span class="line">    guest.append(<span class="built_in">input</span>(<span class="string">&quot;Please enter the name of your guest:&quot;</span>))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;guest.txt&#x27;</span>,<span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> guest_write:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">5</span>):</span><br><span class="line">        guest_write.write(<span class="string">f&#x27;<span class="subst">&#123;guest[i]&#125;</span>\n&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="调查">10-5 调查</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#10-5 调查</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;reasons.txt&#x27;</span>,<span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> reasons:</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        reason = <span class="built_in">input</span>(<span class="string">&quot;Enter a reason why you love programming:&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> reason ==<span class="string">&#x27;quit&#x27;</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        reasons.write(<span class="string">f&quot;<span class="subst">&#123;reason&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="加法计算器">10-7 加法计算器</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#10-7 加法计算器</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        a = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;The first number:&quot;</span>))</span><br><span class="line">        b = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;The second number:&quot;</span>))</span><br><span class="line">        a+b</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;You should try to enter a number&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;The answer is <span class="subst">&#123;a+b&#125;</span>.&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<h3 id="常见单词">10-10 常见单词</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#10-10 常见单词</span></span><br><span class="line">count1 = <span class="number">0</span></span><br><span class="line">count2 = <span class="number">0</span></span><br><span class="line">count3 = <span class="number">0</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;alice.txt&#x27;</span>,encoding = <span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> alice:</span><br><span class="line">    content = alice.readlines()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> content:</span><br><span class="line">    count1 = count1 + line.lower().count(<span class="string">&#x27;the&#x27;</span>)</span><br><span class="line">    count2 = count2 + line.lower().count(<span class="string">&#x27; the &#x27;</span>)</span><br><span class="line">    count3 = count3 + line.lower().count(<span class="string">&#x27;the &#x27;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;The results are <span class="subst">&#123;count1&#125;</span>, <span class="subst">&#123;count2&#125;</span> and <span class="subst">&#123;count3&#125;</span>.&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="记住喜欢的数">10-12 记住喜欢的数</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#10-12 记住喜欢的数</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">filename = <span class="string">&#x27;lucky_number.json&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename) <span class="keyword">as</span> l_n:</span><br><span class="line">        lucky_number = json.load(l_n)</span><br><span class="line"><span class="keyword">except</span> FileNotFoundError:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;You haven&#x27;t told us your lucky number!&quot;</span>)</span><br><span class="line">    number = <span class="built_in">input</span>(<span class="string">&quot;Please enter your lucky number:&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> l_n:</span><br><span class="line">        json.dump(number,l_n)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;You have saved your lucky number!&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Your lucky number is <span class="subst">&#123;lucky_number&#125;</span>.&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="验证用户">10-13 验证用户</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#10-13 验证用户</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_stored_username</span>():</span><br><span class="line"></span><br><span class="line">    filename = <span class="string">&#x27;username.json&#x27;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename) <span class="keyword">as</span> f:</span><br><span class="line">            username = json.load(f)</span><br><span class="line">    <span class="keyword">except</span> FileNotFoundError:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> username</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_new_username</span>():</span><br><span class="line"></span><br><span class="line">    username = <span class="built_in">input</span>(<span class="string">&quot;What is your name? &quot;</span>)</span><br><span class="line">    filename = <span class="string">&#x27;username.json&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        json.dump(username, f)</span><br><span class="line">        <span class="keyword">return</span> username</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">greet_user</span>():</span><br><span class="line"></span><br><span class="line">    username = get_stored_username()</span><br><span class="line">    <span class="keyword">if</span> username:</span><br><span class="line">        judge = <span class="built_in">input</span>(<span class="string">f&quot;Is <span class="subst">&#123;username&#125;</span> your username?Please enter yes/no.&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> judge == <span class="string">&#x27;yes&#x27;</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Nice to see you,<span class="subst">&#123;username&#125;</span>!&quot;</span>)</span><br><span class="line">        <span class="keyword">elif</span> judge == <span class="string">&#x27;no&#x27;</span>:</span><br><span class="line">            username = get_new_username()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;We&#x27;ll remember you when you come back, <span class="subst">&#123;username&#125;</span>!&quot;</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        username = get_new_username()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;We&#x27;ll remember you when you come back, <span class="subst">&#123;username&#125;</span>!&quot;</span>)</span><br><span class="line"></span><br><span class="line">greet_user()</span><br></pre></td></tr></table></figure>
<h2 id="数据可视化">数据可视化</h2>
<h3 id="插播物理实验三件套">插播：物理实验三件套</h3>
<p>想起来确实有物理实验报告三件套：Python 画图，R 计算<del>上位替代
Excel</del>，LaTeX 水字数。</p>
<p>用来画表格记数据的 Excel：那我呢那我呢（</p>
<h4 id="r-script.r">R-Script.R</h4>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">#不确定度。用的时候填充 data，修改其中的实验次数 “6”，根据情况修改已定系差和 B 类不确定度即可。</span></span><br><span class="line">data <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">,</span><span class="number">4</span><span class="punctuation">,</span><span class="number">5</span><span class="punctuation">,</span><span class="number">6</span><span class="punctuation">)</span></span><br><span class="line">d <span class="operator">=</span> mean<span class="punctuation">(</span>data<span class="punctuation">)</span> <span class="operator">-</span> <span class="number">0.03</span>  <span class="comment">#均值减去已定系差</span></span><br><span class="line">sd<span class="punctuation">(</span>d<span class="punctuation">)</span>  <span class="comment">#标准偏差</span></span><br><span class="line">tinv <span class="operator">=</span> qt<span class="punctuation">(</span><span class="number">0.975</span><span class="punctuation">,</span><span class="number">6</span><span class="operator">-</span><span class="number">1</span><span class="punctuation">)</span>  <span class="comment">#前者常数，后者自由度</span></span><br><span class="line">U_A <span class="operator">=</span> tinv<span class="operator">*</span>sd<span class="punctuation">(</span>d<span class="punctuation">)</span><span class="operator">/</span><span class="built_in">sqrt</span><span class="punctuation">(</span><span class="number">6</span><span class="punctuation">)</span></span><br><span class="line">U_B <span class="operator">=</span> <span class="number">0.004</span>  <span class="comment">#B类不确定度，一般就是0</span></span><br><span class="line"><span class="built_in">sqrt</span><span class="punctuation">(</span>U_A<span class="operator">^</span><span class="number">2</span><span class="operator">+</span>U_B<span class="operator">^</span><span class="number">2</span><span class="punctuation">)</span>  <span class="comment">#不确定度,一般就是U_A</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#线性回归。用的时候修改 y 和 x 的值即可。</span></span><br><span class="line">x <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">,</span><span class="number">4</span><span class="punctuation">,</span><span class="number">5</span><span class="punctuation">,</span><span class="number">6</span><span class="punctuation">)</span></span><br><span class="line">y <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">3</span><span class="punctuation">,</span><span class="number">4</span><span class="punctuation">,</span><span class="number">5</span><span class="punctuation">,</span><span class="number">6</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">,</span><span class="number">9</span><span class="punctuation">)</span></span><br><span class="line">ans_1 <span class="operator">=</span> lm<span class="punctuation">(</span>y<span class="operator">~</span>x<span class="punctuation">)</span>   <span class="comment">#斜率不为零的拟合值</span></span><br><span class="line">summary<span class="punctuation">(</span>ans_1<span class="punctuation">)</span>  <span class="comment">#显示具体值。其中Std.Error代表斜率截距A类不确定度</span></span><br><span class="line">ans_2 <span class="operator">=</span> lm<span class="punctuation">(</span>y<span class="operator">~</span>x<span class="operator">+</span><span class="number">0</span><span class="punctuation">)</span>   <span class="comment">#斜率为零的拟合值</span></span><br><span class="line">summary<span class="punctuation">(</span>ans_2<span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<h4 id="template.tex">Template.tex</h4>
<p>科协逼我写的 LaTeX 模板<del>还没人
star</del>：https://github.com/Chiyuru/THU-Fundamental-Physics-Report</p>
<p>然后甲方说你院会用 GitHub 的是少数，被逼在 Overleaf 上
Submit，竟然还过审了，人生污点喜加一：https://www.overleaf.com/latex/templates/qing-hua-da-xue-ji-chu-wu-li-shi-yan-bao-gao-mo-ban/bhmwsbdwnwwx</p>
<h4 id="python_script.py">Python_Script.py</h4>
<p>普通画个图用的，先不贴了（</p>
<h3 id="随机漫步">15-5 随机漫步</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> choice</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RandomWalk</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_points = <span class="number">50000</span></span>):</span><br><span class="line">        self.num_points = num_points</span><br><span class="line">        self.x_values = [<span class="number">0</span>]</span><br><span class="line">        self.y_values = [<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fill_walk</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(self.x_values) &lt; self.num_points:</span><br><span class="line">            x_direction = choice([-<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">            x_distance = choice([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">            x_length = x_direction * x_distance</span><br><span class="line">            </span><br><span class="line">            y_direction = choice([-<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">            y_distance = choice([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">0</span>])</span><br><span class="line">            y_length = y_direction * y_distance</span><br><span class="line">            </span><br><span class="line">            x_location = self.x_values[-<span class="number">1</span>] + x_length</span><br><span class="line">            self.x_values.append(x_location)</span><br><span class="line">            </span><br><span class="line">            y_location = self.y_values[-<span class="number">1</span>] + y_length</span><br><span class="line">            self.y_values.append(y_location)</span><br><span class="line"></span><br><span class="line">Ant = RandomWalk()</span><br><span class="line">Ant.fill_walk()</span><br><span class="line">point_number = <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">50000</span>)</span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots()</span><br><span class="line">ax.scatter(Ant.x_values,Ant.y_values,c=point_number,cmap=plt.cm.Blues,edgecolors=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">ax.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>这个好有趣哦，希望做云朵的胶带厂商学一下，<del>多按几次随机漫步都比你们画的好看</del></p>
<p><img src="https://s2.loli.net/2022/08/05/4j8rKmFDhU25pTi.png" alt="image-20220803160953455"></p>
<h3 id="插曲install-plotly">插曲：install plotly</h3>
<p>是的没错，前面那个是插播，这个是插曲。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conda install plotly</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Collecting package metadata (current_repodata.json): failed</p>
</blockquote>
<p>愣了一下才反应过来又是被梯子背刺了，下次记得关（</p>
<h3 id="交互式掷骰子">15-6 交互式（？）掷骰子</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> plotly <span class="keyword">import</span> offline</span><br><span class="line"><span class="keyword">from</span> plotly.graph_objs <span class="keyword">import</span> Bar,Layout</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Dice</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, faces = <span class="number">6</span></span>):</span><br><span class="line">        self.faces = faces</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">roll_dice</span>(<span class="params">self</span>):</span><br><span class="line">        result = random.randint(<span class="number">1</span>,self.faces)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    </span><br><span class="line">dice = Dice()</span><br><span class="line">results = []</span><br><span class="line">frequency = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">1001</span>):</span><br><span class="line">    result = dice.roll_dice()</span><br><span class="line">    results.append(result)</span><br><span class="line"><span class="built_in">print</span>(results)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">    frequency[result-<span class="number">1</span>] = frequency[result-<span class="number">1</span>] + <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(frequency)</span><br><span class="line"></span><br><span class="line">x_values = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>,dice.faces+<span class="number">1</span>))</span><br><span class="line">data = [Bar(x=x_values,y=frequency)]</span><br><span class="line">x_axis_config = &#123;<span class="string">&#x27;title&#x27;</span>:<span class="string">&#x27;result&#x27;</span>,<span class="string">&#x27;dtick&#x27;</span>:<span class="number">1</span>&#125;</span><br><span class="line">y_axis_config = &#123;<span class="string">&#x27;title&#x27;</span>:<span class="string">&#x27;frequency of the result&#x27;</span>&#125;</span><br><span class="line">my_layout = Layout(xaxis = x_axis_config,yaxis = y_axis_config)</span><br><span class="line">offline.plot(&#123;<span class="string">&#x27;data&#x27;</span>:data,<span class="string">&#x27;layout&#x27;</span>:my_layout&#125;,filename = <span class="string">&#x27;Dice.html&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="点数相乘">15-8 点数相乘</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> plotly <span class="keyword">import</span> offline</span><br><span class="line"><span class="keyword">from</span> plotly.graph_objs <span class="keyword">import</span> Bar,Layout</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Dice</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, faces</span>):</span><br><span class="line">        self.faces = faces</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">roll_dice</span>(<span class="params">self</span>):</span><br><span class="line">        result = random.randint(<span class="number">1</span>,self.faces)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    </span><br><span class="line">dice1 = Dice(<span class="number">6</span>)</span><br><span class="line">dice2 = Dice(<span class="number">6</span>)</span><br><span class="line">results1 = [dice1.roll_dice() <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">1001</span>)]</span><br><span class="line">results2 = [dice2.roll_dice() <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">1001</span>)]</span><br><span class="line">results = [results1[i]*results2[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">1000</span>)]</span><br><span class="line"></span><br><span class="line">frequencies = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">37</span>):</span><br><span class="line">    frequency = results.count(value)</span><br><span class="line">    frequencies.append(frequency)</span><br><span class="line"><span class="built_in">print</span>(frequencies)</span><br><span class="line"></span><br><span class="line">x_values = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">37</span>))</span><br><span class="line">data = [Bar(x=x_values,y=frequencies)]</span><br><span class="line">x_axis_config = &#123;<span class="string">&#x27;title&#x27;</span>:<span class="string">&#x27;result&#x27;</span>,<span class="string">&#x27;dtick&#x27;</span>:<span class="number">1</span>&#125;</span><br><span class="line">y_axis_config = &#123;<span class="string">&#x27;title&#x27;</span>:<span class="string">&#x27;frequency of the result&#x27;</span>&#125;</span><br><span class="line">my_layout = Layout(xaxis = x_axis_config,yaxis = y_axis_config)</span><br><span class="line">offline.plot(&#123;<span class="string">&#x27;data&#x27;</span>:data,<span class="string">&#x27;layout&#x27;</span>:my_layout&#125;,filename = <span class="string">&#x27;2Dice6.html&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="希特卡的降雨量梦回高考地理">16-1
希特卡的降雨量（梦回高考地理</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">filename = <span class="string">&#x27;sitka_weather_2018_simple.csv&#x27;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(filename) <span class="keyword">as</span> f:</span><br><span class="line">    content = csv.reader(f)</span><br><span class="line">    header_row = <span class="built_in">next</span>(content)</span><br><span class="line">    </span><br><span class="line">    rains = []</span><br><span class="line">    dates = []</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> content:</span><br><span class="line">        rain = <span class="built_in">float</span>(row[<span class="number">3</span>])</span><br><span class="line">        date = datetime.strptime(row[<span class="number">2</span>],<span class="string">&#x27;%Y-%m-%d&#x27;</span>)</span><br><span class="line">        rains.append(rain)</span><br><span class="line">        dates.append(date)</span><br><span class="line">    </span><br><span class="line">fig,ax = plt.subplots()</span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">ax.plot(dates,rains,c=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;daily rain&#x27;</span>,fontsize=<span class="number">12</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;Daily Rain in Sitka&#x27;</span>)</span><br><span class="line">fig.autofmt_xdate()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>为什么要画单日降雨量呀，季度性的才有点用吧（？</p>
<p><img src="https://s2.loli.net/2022/08/05/RsVhMAjPyTU9dNH.png" alt="image-20220803234204659"></p>
<h3 id="希特卡的日温差">16-2 希特卡的日温差</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">filename = <span class="string">&#x27;sitka_weather_2018_simple.csv&#x27;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(filename) <span class="keyword">as</span> f:</span><br><span class="line">    content = csv.reader(f)</span><br><span class="line">    header_row = <span class="built_in">next</span>(content)</span><br><span class="line">    </span><br><span class="line">    highs = []</span><br><span class="line">    lows = []</span><br><span class="line">    dates = []</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> content:</span><br><span class="line">        high = <span class="built_in">int</span>(row[<span class="number">5</span>])</span><br><span class="line">        low = <span class="built_in">int</span>(row[<span class="number">6</span>])</span><br><span class="line">        date = datetime.strptime(row[<span class="number">2</span>],<span class="string">&#x27;%Y-%m-%d&#x27;</span>)</span><br><span class="line">        highs.append(high)</span><br><span class="line">        lows.append(low)</span><br><span class="line">        dates.append(date)</span><br><span class="line">    </span><br><span class="line">fig,ax = plt.subplots()</span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">ax.plot(dates,highs,c=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">ax.plot(dates,lows,c=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Temperature&#x27;</span>,fontsize=<span class="number">12</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;Sitka Weather&#x27;</span>)</span><br><span class="line">fig.autofmt_xdate()</span><br><span class="line">ax.fill_between(dates,highs,lows,facecolor=<span class="string">&#x27;blue&#x27;</span>,alpha=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/08/05/fquirjDh5FHAskK.png" alt="image-20220803234934349"></p>
<p>我的评价是，不如屑北京（x</p>
<h3 id="咕咕咕">16-6 咕咕咕</h3>
<p>画地图结果地图的图层显示不出来，只有散点。血压高了，暂时没看出来哪里有问题。</p>
<p>太晚了，起来再研究。（咕咕咕</p>
<h2 id="使用-api">使用 API</h2>
<p>记得关梯子记得关梯子记得关梯子（</p>
<h3 id="其他语言">17-1 其他语言</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> plotly <span class="keyword">import</span> offline</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://api.github.com/search/repositories?q=language:c&amp;sort=stars&#x27;</span></span><br><span class="line">headers = &#123;<span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;application/vnd.github.v3+json&#x27;</span>&#125;</span><br><span class="line">r = requests.get(url, headers=headers)</span><br><span class="line">response_dict = r.json()</span><br><span class="line"></span><br><span class="line">repo_list = response_dict[<span class="string">&#x27;items&#x27;</span>]</span><br><span class="line">repo_names,stars,labels,repo_links =[],[],[],[]</span><br><span class="line"><span class="keyword">for</span> repo <span class="keyword">in</span> repo_list:</span><br><span class="line">    name = repo[<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">    star = repo[<span class="string">&#x27;stargazers_count&#x27;</span>]</span><br><span class="line">    owner = repo[<span class="string">&#x27;owner&#x27;</span>][<span class="string">&#x27;login&#x27;</span>]</span><br><span class="line">    description = repo[<span class="string">&#x27;description&#x27;</span>]</span><br><span class="line">    label = <span class="string">f&quot;<span class="subst">&#123;owner&#125;</span>&lt;br /&gt;<span class="subst">&#123;description&#125;</span>&quot;</span></span><br><span class="line">    repo_url = repo[<span class="string">&#x27;html_url&#x27;</span>]</span><br><span class="line">    repo_link = <span class="string">f&quot;&lt;a href=&#x27;<span class="subst">&#123;repo_url&#125;</span>&#x27;&gt;<span class="subst">&#123;name&#125;</span>&lt;/a&gt;&quot;</span></span><br><span class="line">    </span><br><span class="line">    repo_links.append(repo_link)</span><br><span class="line">    labels.append(label)</span><br><span class="line">    repo_names.append(name)</span><br><span class="line">    stars.append(star)</span><br><span class="line"></span><br><span class="line">data = [&#123;<span class="string">&#x27;type&#x27;</span>:<span class="string">&#x27;bar&#x27;</span>,<span class="string">&#x27;x&#x27;</span>:repo_links,<span class="string">&#x27;y&#x27;</span>:stars,<span class="string">&#x27;hovertext&#x27;</span>: labels,</span><br><span class="line">         <span class="string">&#x27;marker&#x27;</span>: &#123;<span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;rgb(60, 100, 150)&#x27;</span>,<span class="string">&#x27;line&#x27;</span>: &#123;<span class="string">&#x27;width&#x27;</span>: <span class="number">1.5</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;rgb(25, 25, 25)&#x27;</span>&#125;</span><br><span class="line">&#125;,<span class="string">&#x27;opacity&#x27;</span>: <span class="number">0.6</span>,&#125;]</span><br><span class="line">my_layout = &#123;<span class="string">&#x27;title&#x27;</span>:<span class="string">&#x27;Most Popular C Repos on Github&#x27;</span>,</span><br><span class="line">             <span class="string">&#x27;xaxis&#x27;</span>:&#123;<span class="string">&#x27;title&#x27;</span>:<span class="string">&#x27;Repos&#x27;</span>&#125;,<span class="string">&#x27;yaxis&#x27;</span>:&#123;<span class="string">&#x27;title&#x27;</span>:<span class="string">&#x27;Stars&#x27;</span>&#125;,&#125;</span><br><span class="line">fig = &#123;<span class="string">&#x27;data&#x27;</span>:data,<span class="string">&#x27;layout&#x27;</span>:my_layout&#125;</span><br><span class="line">offline.plot(fig,filename = <span class="string">&#x27;c_repos.html&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="django-与-web-应用程序">Django 与 Web 应用程序</h2>
<p>这个书上就给了个实例，我就跟着操作了一遍所以也并没有学会。不过也不是刚需，酒井暑培那边也没去听这个部分，<del>虽然看起来很炫酷很适合给我这种业余玩家炫技</del>。</p>
<h1 id="酒井暑培-ai-track-大作业">酒井暑培 AI Track 大作业</h1>
<p>大作业 Repo：https://github.com/c7w/sast2022-pytorch-training</p>
<p>近一个月后才开始做这份作业，多少是因为一开始基础和时间安排都没能跟上进度。完成之后这个暑假就没什么
coding 的任务了，安心<del>摸鱼</del>看数学去。</p>
<h2 id="subtask-0-环境配置与安装">Subtask 0 环境配置与安装</h2>
<blockquote>
<h3 id="准备-python-环境10-p.t.s">准备 <code>Python</code> 环境（10
p.t.s）</h3>
<p>我们在前面的课程已经学习过 <code>conda</code>
环境管理器的使用，你应该可以理解下面指令的作用。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n ai python=3.8</span><br><span class="line">conda activate ai</span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>
<p>如果你是 NVIDIA 显卡的受害者，那么恭喜你可以使用 CUDA
加速的相关库。你可以理解成充分利用你的显卡的算力来做并行计算。如果你有一张显存大于
4 GB 的显卡就非常符合本次任务的要求：请删除
<code>requirements.txt</code> 中 <code>torch==1.12.0</code>
这一行，然后安装带有 CUDA 加速版本的 <code>torch</code>：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Windows / Linux</span></span><br><span class="line">pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113</span><br><span class="line"><span class="comment"># macOS is not supported yet for CUDA :(</span></span><br><span class="line"><span class="comment"># Link copied from https://pytorch.org/</span></span><br></pre></td></tr></table></figure>
<h3 id="准备数据集5-p.t.s">准备数据集（5 p.t.s）</h3>
<p>请从上面清华云盘的链接中下载数据集，然后解压到 <code>data</code>
目录下，保证 <code>data</code> 目录下直接存在
<code>train</code>、<code>val</code>、<code>test</code> 文件夹与
<code>LICENSE</code> 文件。</p>
<p>请阅读 LICENSE 文件，继续进行本作业代表你已知晓并同意 LICENSE
文件中的所有内容。</p>
</blockquote>
<p><strong>其实这一步我就 fail 了</strong>，因为电脑显卡是 A 卡，不是 N
卡，用不了 CUDA。</p>
<p>所以还出门请亲友吃了个饭然后抢电脑跑数据（</p>
<p>另外不知道为什么装 CPUonly 的 PyTorch
也装不上，换了无数个源了也不行。然后随便试了一下装 icecream
都可以。我迟早要把这个破 Anaconda 卸了然后重装一遍 VScode 实在不行重装 C
盘也行（暴言</p>
<h2 id="subtask-1-数据预处理">Subtask 1 数据预处理</h2>
<blockquote>
<p>在这一部分我们需要撰写数据预处理的相关函数，你可能会用到
<code>Pillow</code>、<code>NumPy</code> 等库。</p>
<p>具体来说，我们需要统计 <code>train</code> 中 <code>imgs</code>
下图片对应的分类标签。<code>imgs</code>
中图片的<strong>逐像素</strong>标注位于 <code>train/labels</code>
下，你可以将每张图片认为是一张灰度图，存储了 <code>0-255</code> 这 256
个数的其中之一。标签 ID 与标签的对应关系如下：</p>
<table>
<thead>
<tr class="header">
<th>标签 ID</th>
<th>标签类别</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0, 7</td>
<td>Mountain</td>
</tr>
<tr class="even">
<td>1</td>
<td>Sky</td>
</tr>
<tr class="odd">
<td>2, 3, 8, 16, 20</td>
<td>Water</td>
</tr>
</tbody>
</table>
<p>也就是说，对于一张图片，我们要判断其中有没有山、有没有天空、有没有水，以此来实现对图片打“标签”的效果。接下来我们便要对这些图片及其标签进行预处理，其步骤为：</p>
<p>对于一张图片，如果其中标记为 “Mountain”
像素的个数<strong>超过</strong>了总像素的 20%，我们就认为这张图片中含有
“Mountain”。同理，如果一张图片中标记为 “Sky”、“Water”、“Human Factor”
的像素个数超过了总像素个数的 20%，我们就认为这张图片中含有
“Sky”、“Water”、“Human Factor”。</p>
<h3 id="数据预处理45-p.t.s">数据预处理（45 p.t.s）</h3>
<p>接下来请阅读并补全
<code>datasets/dataset_landscape_generator.py</code>
中的代码，以达到可以产生与 <code>data/val/file.txt</code> 相类似的
<code>data/train/file.txt</code> 的效果。为达成目标，你只需要修改
<code># TODO Start #</code> 与 <code># TODO End #</code>
之间的内容。</p>
<p>在你完成这部分后，你应该在 <code>./data/train</code> 下生成了一个
<code>file.txt</code> 文件。你可以与<a href="https://github.com/c7w/sast2022-pytorch-training/releases/download/hw/file.txt">这个文件</a>作对比以查看中间结果是否正确。</p>
<p><strong>【任务清单】</strong></p>
<ul>
<li>阅读
<code>data/val/file.txt</code>，了解我们要处理成的目标数据格式（5
p.t.s）</li>
<li>在 <code>process_data</code> 函数中：（20 p.t.s）
<ul>
<li>构建 <code>image_dir</code> 与
<code>label_dir</code>（<code>pathlib.Path</code>）</li>
<li>构建
<code>filename_list</code>（<code>os.listdir</code>，对字符串切片取消后缀名）</li>
<li>将处理后的字符串写入 <code>&#123;working_dir&#125;/file.txt</code>
（写入文件）</li>
</ul></li>
<li>在 <code>calc_label</code> 函数中：（20 p.t.s）
<ul>
<li>按照函数注释中的内容完成函数</li>
<li>正确的做法预处理 <code>train</code> 数据集中的数据应该在 10 min
以内完成</li>
<li>提示：将 <code>label</code> 视为传统的二维数组进行遍历需要至少 1024
<span class="math inline">\(\times\)</span> 768 次计算，而这在 8000
张图片上运行会导致处理效率的降低</li>
<li>提示：能否借助 NumPy 中的工具进行高效并行计算？</li>
<li>提示：<code>np.isin</code>，<code>np.sum</code></li>
</ul></li>
</ul>
</blockquote>
<p>打开 <code>train/labels</code>，<del>哇塞都好黑啊</del>。</p>
<p>打开 <code>datasets/dataset_landscape_generator.py</code>
研究了亿下，总之就是填四个函数，注释给得已经很清楚了。一个是利用 NumPy
打标签，写了半天循环才想起来可以直接使用表达式的值。然后没理解错的话就是写个路径，存所有图片的文件名，然后把标签结果的
<code>.txt</code> 输出到 <code>data/imgs</code>里去。</p>
<p>大概看懂了思路是什么，不需要自己写的地方的具体实现有的还是不太明白。不过程序跑出来的时候还是有点又惊讶又激动的，原来我也可以做到的吗XD。（站在巨人的肩膀上XD（这还只是个开始</p>
<p><img src="https://s2.loli.net/2022/08/08/tqsTPni1r9Y5dXk.png" alt="wowow"></p>
<h2 id="subtask-2-及以后">Subtask 2 及以后</h2>
<p>Repo
上的最新代码是已经填好大部分的版本，部分地方微调了一下。然后就是疯狂读文档试图理解他在干什么，虽然也没全懂...。</p>
<p>但是因为显卡的问题，所以都是在友人的电脑上完成的，也不写啥了。</p>
<h2 id="提交结果">提交结果</h2>
<p><img src="https://s2.loli.net/2022/08/09/RZkcSDdvMx4ojgT.png" alt="image-20220809161338510"></p>
<p>唔...因为很怂所以甚至没有用自己的学号提交...本来想用 2021114514
的，但是怎么偏偏 ban 了这个啊！</p>
<p><img src="https://s2.loli.net/2022/08/09/FNv13Hb49lDzfJ5.png" alt="image-20220809161456569"></p>
<p>交上去之后一想，好像确实也有用这个学号的人，再一查正好是同一个院系里的，啊这。<del>那就让你赚点暑培奖励吧</del></p>
<p>虽然是满分（因为平均过 0.80 了），但因为 Mountain 实在偏低所以没过
Strong
Baseline。自己的设备不合适也没什么机会再调了，要么下次再把友人骗出来一次
= =。</p>
<h2 id="后记">后记</h2>
<p>在考虑再试一次，然后用自己的学号提交...为什么总是在这些事情上这么自卑呢
= =</p>
<p>虽然理论水平不行，但是能跑出个结果倒是还挺好玩。</p>
<p><del>显卡要熟了</del></p>
<p><del>反正不是我自己的</del></p>
<h2 id="后记再后记">后记再后记</h2>
<p>又修了一天电脑，然后把 Anaconda 卸了，皈依 VSCode
神教。怀疑之前怎么换源都装不上 PyTorch 是因为 Anaconda
污染路径，其实类似问题还蛮多的，感觉很难解决，没必要。</p>
<p>大概就是拎包入住的公寓和需要自己装修的房子的区别吧。</p>
<p>今天又试着调了参，分数怎么比原来更低了（乐</p>
<p>还是没能以自己的名义交上去，做不到。</p>
<h2 id="最后的后记">最后的后记</h2>
<p>仓促之中调整的还是不够，所以想试着在自己的电脑上用 A 卡跑出来。</p>
<p>所以巧合之下发现原来的 <code>main.py</code>
还写错了一个地方，<del>是不是觉得没有人会真的用 A 卡或者 Mac
跑这个x</del>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># main.py</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    --snip--</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">int</span>,default=<span class="number">0</span> \</span><br><span class="line">                        <span class="keyword">if</span> torch.cuda.is_available() \</span><br><span class="line">                        <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>,<span class="built_in">help</span>=<span class="string">&#x27;Device number.&#x27;</span>)</span><br><span class="line">             <span class="comment"># correct: else torch.device(&quot;cpu&quot;)</span></span><br></pre></td></tr></table></figure>
<p>然后真的是结结实实地跑了十轮，十个小时。从早晨跑到晚上。这一天就当做给自己放假了，坐在电脑旁边读了一直想读的两本书，一本是毛姆的《面纱》，一本是钱穆的《中国历代政治得失》。</p>
<p>不插电源的话一张图跑 5~6s，插电只要 3.5s
左右。一开始没插电源，电量下去之后一度飙到了 6.5s，有点吓到。</p>
<p>最后还是没能过 Strong
Baseline，数据其实也没有之前那一次的好，但是用自己的学号提交了。<del>人类是有极限的</del>
A 卡是有极限的，一轮一小时的话实在是跑不动，所以就先这样了。</p>
<p>一些奇怪的散热方式：</p>
<p><img src="https://s2.loli.net/2022/08/12/2UQF14hTMNdLebG.png" alt="image-20220812234902021"></p>
<p>下面垫的是数值分析和抽代的书（</p>
<p><img src="https://s2.loli.net/2022/08/12/vXHJ45ySdztOhDr.png" alt="image-20220812234916346"></p>
<p>鸠占鹊巢，于是我坐在了地上（</p>
<p>刚在原仓库下提交了
Issue，总感觉对方好像没意识到问题其实只是在于，这个值应该是
<code>int</code> 而不是<code>str</code>而已（。不过也不太会有人用 CPU
硬跑了，就这样吧。</p>
<p><img src="https://s2.loli.net/2022/08/12/DrHWNjPntxoIOcy.png" alt="image-20220812234512664"></p>
<p>总之完结撒花！</p>
]]></content>
      <tags>
        <tag>这里面看起来很好玩</tag>
        <tag>刷书</tag>
      </tags>
  </entry>
  <entry>
    <title>请为 max cut problem 找一个 polynomial time solution</title>
    <url>/2023/11/11/The-Max-Cut-Problem/</url>
    <content><![CDATA[<p>就是说我这学期为什么会学到这么个东西呢（挠头</p>
<p>这什么破标题（</p>
<p>包含一些当初做 Intro to Optimization Theory Lecture 5 的 scribing
的时候想加又没加的私货，主要参考这份 <a href="https://www.iitgoa.ac.in/~sreejithav/misc/maxcut.pdf">note</a>
和另一份
slide，但我好像找不到了。虽然也很粗浅但超出了课堂讲授的和期中涉及的范围，之前本来就有一份草稿，整理出来图一乐。</p>
<span id="more"></span>
<h1 id="construction">Construction</h1>
<h2 id="max-cut-problem">Max Cut Problem</h2>
<p>Max Cut problem 关心的是 weighted undirected graph <span class="math inline">\(G = (V,E)\)</span>，也就是对于图上的每一条边 <span class="math inline">\((i.j)\)</span> 都有一个对应的 weight <span class="math inline">\(w_{ij} =
w_{ji}\)</span>，来回的权重相等是无向图的设定，如果两点之间没有边相连则
<span class="math inline">\(w_{ij}=0\)</span>，且有 <span class="math inline">\(w_{ii}=1\)</span>（实际上没有意义，计算中也不会涉及，但在矩阵中总要写出来）。</p>
<p>注：很草的是，zjz 所有的 weight 都是 <span class="math inline">\(1\)</span>，但的确不影响问题本质的理解，有 weight
的话还要多写一个参数，好累的。</p>
<p>在 <span class="math inline">\(G=(V,E)\)</span> 中 <span class="math inline">\(V\)</span> 代表点集，<span class="math inline">\(E\)</span> 代表连边和其上权重，用 weight
构成的一个 symmetric matrix 表示。</p>
<p>这种图上的一个 cut 指的是点集 <span class="math inline">\(V\)</span>
的一个子集 <span class="math inline">\(S \subseteq
V\)</span>，它实际上把点集划分为了 <span class="math inline">\(S\)</span> 和 <span class="math inline">\(T =
V\setminus S\)</span> 两部分，而 max cut problem
所研究的就是这两部分之间所连接的边的权重和</p>
<p><span class="math display">\[W(S) \triangleq \sum_{(i,j) \in S \times
T} w_{ij}\]</span></p>
<p>的最大值。</p>
<p>于是这个优化问题被形式化地定义为：</p>
<p><span class="math display">\[\begin{aligned}\textbf{maximize} \quad
&amp; W(S) \\ \textbf{given} \quad &amp; G =
(V,E)  \end{aligned}\]</span></p>
<h2 id="notations">Notations</h2>
<ul>
<li><p>For an input graph <span class="math inline">\(G\)</span>, we
denote by <span class="math inline">\(\mathrm{OPT} (G)\)</span> the
weight associated with the maxcut, i.e.</p>
<p><span class="math display">\[\mathrm{OPT} (G) = \max\{W(S) \mid S \
\text{is a subset of }V\}.\]</span></p></li>
<li><p>An <span class="math inline">\(\alpha\)</span>-approximate max
cut is a cut <span class="math inline">\(S\)</span> s.t. <span class="math inline">\(W(S) \geq \alpha \
\mathrm{OPT}(G)\)</span>.</p></li>
</ul>
<h2 id="approximate-algorithm">1/2-approximate Algorithm</h2>
<p>一个简单的 randomized algorithm 是对图上的每一个点，以 <span class="math inline">\(1/2\)</span> 的概率随机决定要不要把它们放进 cut
中，这样所得到的 sum of weight <span class="math inline">\(W(S)\)</span>
的期望是：</p>
<p><span class="math display">\[\begin{aligned} E(W(S)) &amp; =
E\sum_{(i,j)\in E} w_{ij}( \textbf{1}_{i \in S,j \in T}+\textbf1_{i \in
T ,j \in S}) = \sum_{(i,j)\in E} P(i\in S, j \in T) w_{ij} +P(i \in T ,j
\in S)w_{ij} \\ &amp; =  \sum_{(i,j)\in E} \frac 1 2 \times \frac 1 2
\times 2w_{ij}  = \frac 1 2 \sum_{(i,j) \in E} w_{ij}
\end{aligned}\]</span></p>
<p>所以这至少是一个 <span class="math inline">\(1/2\)</span>-approximate
algorithm，因为 <span class="math inline">\(\sum_{(i,j) \in E}
w_{ij}\)</span> 显著大于等于 <span class="math inline">\(\mathrm{OPT}(G)\)</span>。</p>
<h1 id="transformation-into-a-convex-problem">Transformation into a
Convex Problem</h1>
<p>从方法的角度来说，把一个 non-convex problem 转化为 convex problem
和求解过程中需要遵循的大的原则是：</p>
<ul>
<li>Transform the non-convex problem into convex ones through
relaxation</li>
<li>Recover a solution from the convex problem to the non-convex one
through random rounding</li>
</ul>
<p>在这里介绍一下把 max cut problem 转化为 convex problem
和求近似解的方法。</p>
<h2 id="step-1">Step 1</h2>
<p>一个最简单的可量化的转化是：</p>
<p><span class="math display">\[\begin{aligned} \textbf{maximize} \quad
&amp; \frac 1 4 \sum_{i \in V} \sum_{j \in V}w_{ij} (1-x_ix_j) \\
\textbf{subject to} \quad &amp; x_i \in \{+1,-1\}
\end{aligned}\]</span></p>
<p>这等价于考虑</p>
<p><span class="math display">\[\begin{aligned} \textbf{maximize} \quad
&amp; \frac 1 2\sum_{(i,j) \in E} w_{ij}(1-x_ix_j) \\
\textbf{subject  to} \quad &amp; x_i \in \{+1,-1\}
\end{aligned}\]</span></p>
<p>zjz
上课的时候没有解释为什么可以这样转换，哥们一边困着一边抄笔记的时候就差点在这里掉线了。意思就是说在
<span class="math inline">\(i \in S\)</span> 的时候取 <span class="math inline">\(x_i=1\)</span> 否则为 <span class="math inline">\(-1\)</span>，这样的话只有在不同集合中的 pair <span class="math inline">\((i,j)\)</span> 会被计入。注意上下两个形式所考虑的
<span class="math inline">\((i.j)\)</span>
不同，因此有系数上的轻微差别。</p>
<h2 id="step-2">Step 2</h2>
<p>自然地会想到取一个 <span class="math inline">\(n\)</span> 维向量
<span class="math inline">\(\textbf x = \begin{bmatrix} x_1 \\ x_2 \\
\vdots \\ x_n\end{bmatrix}\)</span> 使得 <span class="math inline">\(x_ix_j=X_{ij}\)</span>，其中 <span class="math inline">\(X=\textbf x \textbf x^T =
(X_{ij})\)</span>。因此可以转换为：</p>
<p><span class="math display">\[\begin{aligned} \textbf{maximize} \quad
&amp; \frac 1 4 \sum_{i \in V} \sum_{j \in V}w_{ij} (1-X_{ij}) \\
\textbf{subject to} \quad &amp; X=\textbf x \textbf x^T \text{ and
}X_{ii}=1 \end{aligned}\]</span></p>
<p>其中有这就变成了一个纯正的 symmetric &amp; semi-positive definite
matrix，看起来已经脱离了 maxcut 问题中的设定。更进一步的话舍弃掉 <span class="math inline">\(X=\textbf x \textbf x^T\)</span>
这一条件，直接替换为 <span class="math inline">\(X\)</span>
对称半正定，也即：</p>
<p><span class="math display">\[\begin{aligned} \textbf{maximize} \quad
&amp; \frac 1 4 \sum_{i \in V} \sum_{j \in V}w_{ij} (1-X_{ij}) \\
\textbf{subject to} \quad &amp; X \text{ is symmetric and semi-positive
definite, with }X_{ii}=1 \end{aligned}\]</span></p>
<p>就是理想的转换了。</p>
<p>zjz 在课上不是这样直接一步出结果，稍有不同的是他把 <span class="math inline">\(x_i\)</span> 又进行了一步变换达到 <span class="math inline">\(\textbf x _i \in \mathbb R^n\)</span>。</p>
<h2 id="step-3">Step 3</h2>
<p>一个自然的往 LP 转换的想法是把 <span class="math inline">\(x_ix_j\)</span> 替换为 <span class="math inline">\(z_e\)</span>，其中 <span class="math inline">\(e =
(i,j) \in E\)</span>，<span class="math inline">\(z_e=-1\)</span> 表示
<span class="math inline">\((i,j) \in S \times T\cup T \times
S\)</span>，否则 <span class="math inline">\(z_e=1\)</span>。然后用一些简化将 <span class="math inline">\(z_e\)</span> 加入 constraints。</p>
<p><span class="math display">\[\begin{aligned} \textbf{maximize} \quad
&amp; \frac 1 2 \sum_{e \in E} w_{ij}(1-z_e) \\ \textbf{subject to}
\quad &amp; z_{(u,v)} \geq -x_u -x_v -1 \\ &amp;z_{(u,v)} \geq x_u +
x_v-1 \\ &amp; x_v \in [-1,1] \end{aligned}\]</span></p>
<p>实际上 this attempt fails，因为取个 <span class="math inline">\(x_u=0,x_v=0,z_{(u,v)}=-1\)</span> 也能够满足
constraints，但这没有意义。</p>
<h2 id="step-4">Step 4</h2>
<p>另一种方法是考虑将每个顶点用一个 <span class="math inline">\(n\)</span> 维向量表示出来，将 <span class="math inline">\(x_ix_j\)</span> 替换为 <span class="math inline">\(\textbf x _i ^T \textbf
x_j\)</span>。这样转换的优点在于可以把所有的 <span class="math inline">\(n\)</span> 维向量放在 <span class="math inline">\(\mathbb R^n\)</span> 的单位球 <span class="math inline">\(\mathbb S^{n-1}\)</span>
上，这既出于归一化的考虑，也是因为</p>
<p><span class="math display">\[\frac 1 4 \|\textbf x_u - \textbf
x_v\|^2 = \frac 1 2(1-\textbf x_u^T\textbf x_v)\]</span></p>
<p>这样问题就转换为了</p>
<p><span class="math display">\[\begin{aligned} \textbf{maximize} \quad
&amp; \frac 1 2 \sum_{(i,j)\in E}w_{ij} (1-\textbf x_i ^T\textbf x_j) \\
\textbf{subject to} \quad &amp; \textbf x_i \in \mathbb S^{n-1} \text{
for any } i =1,2,\cdots,n \end{aligned}\]</span></p>
<p>事实上这不是一个等价的转换，某种程度上来说只是单向的。在 maxcut
问题中我们可以对所有 <span class="math inline">\(i \in S\)</span> 取
<span class="math inline">\(\textbf x_i =e_1\)</span>，对所有 <span class="math inline">\(j \in T\)</span> 取 <span class="math inline">\(\textbf x_j
=-e_1\)</span>。但并非上述问题的所有解都可以在 maxcut problem
中找到一个合适的解。我们也把 <span class="math inline">\(x_i \in
\{+1,-1\}\)</span> 这一整数规划的条件舍弃了，改为 <span class="math inline">\(\textbf x_i \in \mathbb S^{n-1}\)</span>。</p>
<p>称这一问题是 maxcut 问题的 relaxation，顾名思义放松了一些条件。</p>
<p>因此，记 step 4 中问题的 optimal cost 是 <span class="math inline">\(\mathrm{Maxcut}^0(S)\)</span>，原 maxcut problem
的 optimal cost 记为 <span class="math inline">\(\mathrm{OPT}(G)\)</span>，于是有</p>
<p><span class="math display">\[\mathrm{Maxcut^0(S)} \geq
\mathrm{OPT}(G),\]</span></p>
<p>也就是说如果找到一个上述问题的 <span class="math inline">\(\alpha\)</span>-approximation <span class="math inline">\(W^0(S)\)</span>也就有了原问题的 <span class="math inline">\(\alpha\)</span>-approximation，这是因为</p>
<p><span class="math display">\[W^0(S) \geq \alpha \
\mathrm{Maxcut^0(S)} \geq \alpha \ \mathrm{OPT}(G).\]</span></p>
<h2 id="step-5">Step 5</h2>
<p>通过在上述问题中取 <span class="math inline">\(X_{ij} = \textbf x_i
^T \textbf x_j\)</span> 可以得到一个新的更抽象化的优化问题：</p>
<p><span class="math display">\[\begin{aligned} \textbf{minimize} \quad
&amp; X \cdot A = \sum_{i,j \in V} X_{ij} A_{ij} \\ \textbf{subject
to}\quad &amp; X \succeq 0 \\ &amp; X_{ii}=1 \end{aligned}\]</span></p>
<p>看起来是做了一点 relaxation，我们舍弃了 <span class="math inline">\(\textbf x_i\)</span> 这些表达，直接用一个模糊的
<span class="math inline">\(X \succeq 0\)</span> 代替了，实际上它是和
step 4 转化出的问题</p>
<p><span class="math display">\[\begin{aligned} \textbf{maximize} \quad
&amp; \frac 1 2 \sum_{(i,j)\in E}w_{ij} (1-\textbf x_i ^T\textbf x_j) \\
\textbf{subject to} \quad &amp; \textbf x_i \in \mathbb S^{n-1} \text{
for any } i =1,2,\cdots,n \end{aligned}\]</span></p>
<p>相互等价。这是因为：</p>
<p><span class="math display">\[\begin{aligned} X \in \mathbb S_+^n
\text{ is feasilble} &amp; \iff  X_{ii}=1 \text{ for any }i \in V \\
&amp; \iff \|x_i\|=1 \text{ for any }i \in V \\ &amp; \iff x_i \in
\mathbb S^{n-1} \text{ for any }i \in V  \end{aligned}\]</span></p>
<p>至此得到了一个简洁的 symmetric semi-positive definite matrix
问题，这和 step 2 是一致的。</p>
<h2 id="remark">Remark</h2>
<p>在 step 2 中已经提到，zjz
在课上不是这样直接一步出结果，稍有不同的是他把 <span class="math inline">\(x_i\)</span> 又进行了一步变换达到 <span class="math inline">\(\textbf x _i \in \mathbb R^n\)</span>。</p>
<p>Step 2 和 step 5
转化出的问题在形式上相同是表面上的，实际上他的做法很合理很本质，因为
step 2 中的 symmetric positive definite matrix <span class="math inline">\(X\)</span> with <span class="math inline">\(X_{ii}=1\)</span> 可以通过 Cholesky 分解为 <span class="math inline">\(X =L^TL\)</span>，且有 <span class="math inline">\(L=\begin{bmatrix} l_1 &amp; l_2 &amp; \cdots &amp;
l_n \end{bmatrix}\)</span>，事实上把 <span class="math inline">\(l_i\)</span> 替换成 <span class="math inline">\(\textbf x_i\)</span> 就是 step 5
转换出的问题。</p>
<p>（注意到 <span class="math inline">\(X_{ij} =\textbf x_i ^T \textbf
x_j\)</span>，因此 <span class="math inline">\(X =
\begin{bmatrix}\textbf x_1 &amp; \cdots &amp; \textbf x_n
\end{bmatrix}^T \begin{bmatrix}\textbf x_1 &amp; \cdots &amp; \textbf
x_n\end{bmatrix}\)</span>）</p>
<p>而这一分解是后面得到 <span class="math inline">\(0.878\)</span>-approximation 的 geometrical
foundation，因为这个结论是在 <span class="math inline">\(\mathbb
R^n\)</span> 上通过估算内积得到的。</p>
<h1 id="approximation">0.878-approximation</h1>
<p>在 maxcut problem 中有一个著名的 <span class="math inline">\(0.878\)</span>-approximation，也即已经证明了</p>
<p><span class="math display">\[E(W(S)) \geq 0.878 \mathrm \
\mathrm{OPT}(G)\]</span></p>
<p><del>不详述证明了因为我也不是很会（</del>，也不是不会因为写出来其实很简洁，下面给出了证明，但这个东西是我一边写
cheatsheet 一边肝到五点多写完的所以当时是实在没心情了（x</p>
<p>然后讨论一下为什么这个看起来有点怪的 approximation
参数值是重要的，以及回收标题。</p>
<h2 id="proof">Proof</h2>
<p>前面已经说明了所有的 <span class="math inline">\(\textbf x_i\)</span>
都在单位球上，当它们都已知时以下给出一个构造 cut
的手段并计算其期望。</p>
<p>任过单位球作一个割平面 <span class="math inline">\(\{\textbf u^T
\textbf x =0 \mid \textbf x \in \mathbb S^{n-1}\}\)</span>，对于所有
<span class="math inline">\(\textbf x_i \in \{\textbf u ^Tx &gt;0\} \cap
\mathbb S^{n-1}\)</span> 取 <span class="math inline">\(i\in
S\)</span>，其余放入 <span class="math inline">\(T\)</span>。于是一对
<span class="math inline">\((i,j) \in S \times T\)</span>
当且仅当割平面穿过 <span class="math inline">\(\textbf x_i,\textbf
x_j\)</span> 的夹角。这一分割得到的 sum of weight 的期望是：</p>
<p><span class="math display">\[E(W(S)) = \sum_{i,j \in V}
w_{ij}P((i,j)\in S\times T) = \sum_{i,j \in V}w_{ij} \left(\frac{\arccos
\textbf x_i^T \textbf x_j}{\pi}\right)\]</span></p>
<p>和 symmetric semi-definite matrix 的结果 <span class="math inline">\(\mathrm{Maxcut} ^0(S) = \frac 1 2 \sum_{i,j \in V}
w_{ij}(1-\textbf x_i^T\textbf x_j)\)</span> 相比，考虑函数 <span class="math inline">\(\arccos x\)</span> 和 <span class="math inline">\(\frac 1 2(1-x)\)</span> 的最小比值是 <span class="math inline">\(0.878\)</span>，则有</p>
<p><span class="math display">\[E(W(S)) \geq 0.878 \
\mathrm{Maxcut}^0(S) \geq 0.878 \ \mathrm{OPT}(G).\]</span></p>
<h2 id="why-is-0.878-important">Why is 0.878 important?</h2>
<p>首先考虑一个 maxcut problem 的 decision version：对于给定的图 <span class="math inline">\(G=(V,E)\)</span> 和给定的 <span class="math inline">\(k&gt;0\)</span>，能否找到一个 sum of weight <span class="math inline">\(W(S) \geq k\)</span> 的 cut <span class="math inline">\(S\)</span>？这个问题 NP-complete，只要把所有的 cut
枚举出来然后逐个验证 sum of weight 是否大于等于 <span class="math inline">\(k\)</span> 即可。</p>
<p>事实上除非 NP = P，否则不可能找出一个 polynomial time solution to
maxcut problem，标题回收。</p>
<p>另外除非 NP = P，否则也不可能对任意的 <span class="math inline">\(\varepsilon &lt;1\)</span> 都可以找到一个 <span class="math inline">\(\varepsilon\)</span>-approximation
algorithm。比较强的结果是 <span class="math inline">\(\varepsilon &gt;
16/17\)</span> 时 <span class="math inline">\(\varepsilon\)</span>-approximation algorithm
不存在，而如果 the unique games conjecture is true 则 <span class="math inline">\(0.878\)</span>-approximation
已经是最佳估计了。</p>
<p>题外话是对于 integer programming 里提到过的 Knapsack problem
是可以找到任意的 <span class="math inline">\(\varepsilon\)</span>-approximation algorithm
的，这样的问题被称为 admit a PTAS。</p>
<h1 id="sdp-dual">SDP Dual</h1>
<h2 id="lagrangian-duality">Lagrangian Duality</h2>
<p>今天在摸 Lagrangian duality，又回来摸了一下 max
cut，玩出来一个好玩的东西然后一查什么嘛果然是早就有的答案（</p>
<p>先把 step 5 得到的 SDP 问题重写一下。原来长这样：</p>
<p><span class="math display">\[\begin{aligned}\textbf{minimize} \quad
&amp; X \cdot A = \sum_{i,j \in V} X_{ij} A_{ij} \\
\textbf{subject  to}\quad &amp; X \succeq 0 \\ &amp; X_{ii}=1
\end{aligned}\]</span></p>
<p>主要就是把 <span class="math inline">\(X_{ii}=1\)</span>
修改成和正定对称阵的内积形式：</p>
<p><span class="math display">\[\begin{aligned}\textbf{minimize} \quad
&amp; X \cdot A = \sum_{i,j \in V} X_{ij} A_{ij} \\ \textbf{subject
to}\quad &amp; X \succeq 0 \\ &amp; X \cdot (e_ie_i^T)=1 \quad \text{for
}\ i=1,2,\cdots, n \end{aligned}\]</span></p>
<p>写成 Lagrangian 得到 <span class="math inline">\(L(X,\lambda) = X
\cdot A + \sum_{i}^n \lambda_i (X\cdot(e_ie_i^T)-1) =
X\cdot(A+\mathrm{diag}(\lambda _1,\cdots,\lambda _n)) -\sum_{i=1}^n
\lambda _i\)</span>，其 dual problem 为</p>
<p><span class="math display">\[\begin{aligned} \textbf{minimize} \quad
&amp; \sum_{i=1}^n \lambda _i \\ \textbf{subject to} \quad
&amp;  \mathrm{diag}(\lambda_1,\cdots,\lambda_n) \succeq A \\ &amp;
\lambda \succeq 0  \end{aligned}\]</span></p>
<p>取 <span class="math inline">\(t =\frac 1 n \sum_{i=1}^n \lambda
_i\)</span> 于是有 <span class="math inline">\(\lambda = t \textbf 1 -
u\)</span> 且 <span class="math inline">\(\textbf 1^T
u=0\)</span>。于是问题转化为：</p>
<p><span class="math display">\[\begin{aligned} \textbf{minimize} \quad
&amp; nt \\ \textbf{subject to} \quad &amp;  tI \succeq
A+\mathrm{diag}(u_1,\cdots,u_n)  \\ &amp; u^T \textbf
1=0  \end{aligned}\]</span></p>
<h2 id="maximum-eigenvalue-programming">Maximum Eigenvalue
Programming</h2>
<p>考虑一对 primal problem 和 dual problem：</p>
<p><span class="math display">\[\begin{aligned} \textbf{maximum} \quad
&amp; A \cdot X \\ \textbf{subject to} \quad &amp; X \cdot I =1 \\&amp;
X \succeq 1 \end{aligned} \quad \quad \quad
\begin{aligned}\textbf{minimize} \quad &amp; v \\ \textbf{subject to
}\quad &amp; vI -A\succeq 0 \\ \\ \end{aligned}\]</span></p>
<p>右边的显然是特征值问题，optimal solution 和 optimal cost 即为 <span class="math inline">\(v = \lambda_{max}
(A)\)</span>。左边的则与上述问题类似。</p>
<h2 id="back-to-max-cut">Back to Max Cut</h2>
<p>因此 max cut problem 可以转化为：</p>
<p><span class="math display">\[\begin{aligned} \textbf{minimize} \quad
&amp; n \lambda_{max}(L+\mathrm{diag} (u_1,\cdots,u_n)) \\
\textbf{subject to} \quad  &amp; u^T \textbf
1=0  \end{aligned},\]</span></p>
<p>最终的结论是：</p>
<p><span class="math display">\[\frac n 4 \lambda_{max} (L(G)) \geq
\mathrm{Maxcut}^0(S) \geq \mathrm{OPT}(G).\]</span></p>
<p>其中 <span class="math inline">\(L(G)\)</span> 是 <span class="math inline">\(G\)</span> 的 Laplacian
matrix。<del>这个真不会证</del></p>
]]></content>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>Tsinghua Logic Summer School</title>
    <url>/2022/06/27/The-Second-Tsinghua-Logic-Summer-School/</url>
    <content><![CDATA[<p>第一次上前沿研究类的讲座课，本来是想像竞赛的时候按日写赛题评析一样，按照
DAY1~DAY5
的顺序每天上完课梳理一下思路，简单提一提觉得有趣的点。<del>结果到 DAY2
就被复杂度和计算理论知识直接干碎了。</del></p>
<p>后面的课虽然很有意思但一涉及到相关问题就不太能完全理解，硬要写的话没太大意义，遂放弃，变成了日常吐槽（又在水
blog 了是吗</p>
<span id="more"></span>
<h1 id="day-1">DAY 1</h1>
<p><strong>注：第一天结束之后随手记的东西，这一天完全理解了是因为之前就学过一点，遂保留。</strong></p>
<p>第一节课还是比较熟悉的内容。上学期刚在数据库课上学过 Relational
Algebra，开课前一晚找了本离散补了一下 First Order Logic。上课的时候 wiki
查了一下什么是 Relational Calculus 之后对照着 PPT
看了一遍，就去摸鱼了。</p>
<p>查作业题熬到半夜，关于证明 Relational Algebra 中 difference
的独立性。Google 出来<a href="https://moodle2.cs.huji.ac.il/nu15/pluginfile.php/167868/mod_resource/content/3/relalgLect1.pdf">一个看起来像是泰国人写的课件</a>，细讲了一下怎么证明乘积、并、投影和选择的独立性，偏偏没有取差。然后给了一个
Monotonic Query 的定义，看了一大圈回来才意识到这好像是证明 difference
独立性的提示。想了亿会之后意识到的确是提示，用单调性举个反例就好了，<del>我好蠢！</del>太优雅啦！</p>
<p>证明吸取过往教训没有口胡，而是<del>口胡加上</del>举了个反例。第一天没打
LaTeX，作业直接手写了个塑料英语交掉。句子丑到高三英语春考前的我自己都要跳出来骂人的程度。</p>
<h1 id="phokion-的塑料英语">Phokion 的塑料英语</h1>
<p>DAY1
我还在怀疑自己是不是因为秋季学期法语二外的荼毒，已经不能辨别正常的英文读音了，但
Chrome 的字幕显示确实和老爷子的读音差别好大。于是下午又去听了一下 Hybrid
Logic 主题，不用字幕的话也能听懂。得出结论不是我的问题（</p>
<p>这几天啃 PPT 之余好奇的就是：Phokion
的母语真的是英语吗？还是法语或者某个与法语相近的语言，比如西班牙语？（不是很懂语言学的知识，关于语系什么的ww）</p>
<p>听到了无数个法语读音的 -an，不发音的 h，只有 Chrome 字幕能明白的
“Query”， PPT 上关于 naive chase procedure 的描述中用的是有分音符的
naïve（也有可能是出于正式），读音也接近法语耶。感觉母语不是英语的可能性增加了！（x</p>
<h1 id="google-救大命">Google 救大命</h1>
<p>我的数据结构选的是下学期自动化系的课，相比计算机系的课来说是3学分阉割版<del>（主要是为了保命）</del>，秋季学期才开课。于是此前关于时间复杂度问题的认识还只停留在符号层面，计算理论更是一窍不通。从
DAY2 开始类似的问题就没太懂，常见问题的规约全靠 Google
救命，最后作业做了个七七八八，还行吧。</p>
<p>DAY3 的 Problem2 直接查出来一篇 Phokion 的
paper，在里面找某个结论的时候发现证明标了个引用符号，往前找文献又是给引理标了引用，最后找到了
Repair of Inconsistent Database
理论初建的论文。其他很多问题查文献往往也只有若干篇 Phokion 团队的
paper，只有您的实验室在做这个方向是吗.jpg</p>
<p>什么叫逻辑学专题与<strong>前沿</strong>啊。我还是第一次上前沿专题讨论课形式的课程呢。想到春季学期的时候差点选了数学系的《现代数学前沿概览》，后来学长说目前本来就比数学系基础差一点，不如再学一年再去<del>挨打</del>上课，<del>而且这课是
647 开的，可能要慎重，</del>遂暂时放弃。</p>
<h1 id="奇妙的作息时间">奇妙的作息时间</h1>
<p>回家之后不用去教室，早十可以九点半起床了。形成了很怪的作息：</p>
<ul>
<li>早晨九点半起床洗漱恰饭。对着字幕和 PPT 听 Phokion
的塑料英语，一直到十二点一刻。</li>
<li>早午饭间距有点近，可以先睡个午觉，一点半（甚至更晚）再起来吃午饭。</li>
<li>睡醒，恰饭，写作业。有可能还要听一遍回放，我太菜了QAQ</li>
<li>一边查文献一边摸鱼到深夜，两点半睡觉是基本操作<del>，甚至可以睡够七个小时，多好</del>。</li>
</ul>
<p>要是说没休息好，好像也不至于，加上午觉一天至少睡八个小时；要说没干活好像也没有，该做的都做了，起码不至于非常摸鱼。要说哪里很怪，可能就是午觉有点长，而且时区不太对了（</p>
<p>在学校无论晚上睡多久，似乎也很少睡午觉。从早晨出门开始就漂泊在外一整天，中途回寝室睡感觉挺麻烦的；即使多骑几段路回寝室，说不定上床睡觉也不方便；在教室或者图书馆趴着睡觉醒来都会头晕好一阵，体验也不是很好，干脆撑住就不睡了；第二节和第三节都有课的话吃个饭就不错了，这哪有觉给你睡啊，你睡不睡吧（</p>
<p>回家真好，松软的床就在两步之外，还不用爬梯子，累了就倒头睡觉qwq</p>
<h1 id="到底学到了什么">到底学到了什么</h1>
<p>真要说学到了多少 Database 理论知识，我自己都觉得愧疚：证明还要靠
Google，对着各种文献 Ctrl+F 然后剪刀手，DAY2
作业里不理解的题直接上手糊了<del>但是还拿了9/10是为什么呢</del>，之类的摸鱼行为真挺多的。<del>当然也不能指望我五天迅速精通老爷子研究了二十年的东西对吧</del>，哪怕讲座上的只是一点皮毛。</p>
<p>所以如果真的说学到了什么，大概之后回忆起来的还是 Phokion 在 PPT
上讲过的 target tgds&amp;egds
以电影数据为例的描述、总统选举不同规则下的结果等等，很有趣。</p>
<blockquote>
<p>举例是理解的试金石。</p>
</blockquote>
<p>学抽代和高代（选）的时候也是一样，正是因为有各式各样的例子和动手操作的空间，我才觉得初学数学相比初学其他很多东西来说更有趣。当然，哪怕很多时候最终目的还是回归抽象，“用做游戏的方式理解规则”的这个过程还是很乐在其中。</p>
<p>另外就是很开心坚持到了最后，没有自闭退课跑路。DAY2
的计算理论看麻了的时候想过无非几种可能：后面的内容变轻松一点，顺利上完
or
后面还是侧重于计算理论，越来越不懂，退课跑路明年多学点计算机知识之后再来
or 头铁把课上完，1
学分绩点拉胯的话就当多上了一门体育课<del>，反正怎么样也卷不过院系里那群卷王</del>。</p>
<p>还好后三天的内容很成体系也很有意思，也不是太需要基础，作业和
take-home exam
已经顺利搞定了。可能还有个原因就是有朋友（唔赛博朋友可以这样说吗，起码我认为是朋友的ww）也在上这门课，虽然也没鼓起勇气问
dalao 各种 trivial
的问题，但不知道为什么有很踏实的感觉，单人行动的话可能中途受不了跑路的概率也会增加一点吧（</p>
<p>系里之前还有几个也选了课的同学<del>（但我其实并不认识，惭愧）</del>问我打不打算退课跑路，尤其是第二天的时候虽然很犹豫，但回答至少会把课跟完，认真看看作业。你院每个学期为了
GPA 3.9+ 退课退到 20
学分的人真的好多，第一学期的时候我的心态其实也一样，为了 GPA
而没有手选数分高代，而是去微 A
和线代<del>爆杀</del>了。当然我目前的考虑还是不保研直接留学，<del>就算保研也没什么地方可以去，</del>可能也没有资格居高临下一般议论他人为了维持
GPA 的努力。</p>
<p>但我自己还是觉得学有趣的、有用的、对自己来说更有价值的东西，比保持一个毕业后就迅速贬值的数值更有意义；与此同时，培养方案只是顺便完成的东西而已<del>（其实是自己专业的培养方案太烂了）</del>。选一条更困难的道路，也是相当幸福的事情。（别中二了啊，以后再看到这句话肯定会尴尬的啊啊啊（</p>
<h1 id="结课合影">结课合影</h1>
<p>结课合影的时候发现没给 zoom
开摄像头权限，网页版打开权限后要刷新重进，重进之后大家都打开了摄像头于是直接卡爆，啥也显示不出来。好不容易把自己的摄像头打开，听到助教说已经截完图了，呜呜（</p>
<p>事后去看了课程回放，想自己截一个合影，发现因为电脑卡住而看不到界面的我完全失去了表情管理，还给所有人表演了一个展示浓密的头发（在镜头前理了半天乱糟糟的头发（应该没人看我吧应该没人看我吧x</p>
<p>是时候认真配一下另一台电脑的设置，然后把主力机换掉了。surface
中看不中用啊（但是真的很轻便呜呜</p>
]]></content>
      <tags>
        <tag>这里面看起来很好玩</tag>
        <tag>课程实录</tag>
      </tags>
  </entry>
  <entry>
    <title>统辅课程测评搬运</title>
    <url>/2022/11/10/Statistic-Minor-Repo/</url>
    <content><![CDATA[<p>一月余之前树洞上看到的统计辅修课程测评，来自物理系 9 字班的学长 <a href="https://v1ncent19.github.io">V1ncent19</a>，已得到授权转载。希望在选课期间
cover
到一些阅读我博客的、对统计学感兴趣的同学，也是一个重新排版后给我自己参考的方式。</p>
<p>本文同样遵守文末提到的 CC BY-NC-SA 4.0 协议，版权归原作者所有。</p>
<span id="more"></span>
<h1 id="统辅老师们的测评">统辅老师们的测评</h1>
<p>首先大概说一下几个我上过课的老师：（按 dz 第一次上他们课的顺序）</p>
<h2 id="邓婉璐">邓婉璐</h2>
<p>是大家都非常喜欢的，洞里已经有很多课友称赞过了我就不多谈了：讲课细致
+ 关心同学们 + 给分好，在你清可能都很少找到比 wljj 好的老师了。当然 dz
私下感觉有时候进度不够快 /
花在推导上的时间有点长，当然这属于个人偏好，小事。</p>
<h2 id="王江典">王江典</h2>
<p>dz 的统推和生存分析是 wjd 老师的，wjd
老师的课程会有很多推导（即使是在生存分析课这种理论部分没有那么多的课上），不过一个小问题就是她讲课的时候会细致地把公式都进行推导但是
dz 觉得缺乏对整体思路的鸟瞰，也不经常提供一些
intuition，导致可能会有知其然而不知其所以然的问题，所以建议上她的课的小伙伴课下多思考一下推导是怎么来的。wjd
老师应该是在业界待过，她的作业 &amp;
讲课中会有一定的代码成分，不过大多数可以通过调包查文档解决。王老师私下答疑这块非常热情，人很好，经常给
dz 各种方面的建议</p>
<h2 id="周在莹">周在莹</h2>
<p>这学期周老师休假了，不上课，不然本来应该也会有很多人问她的统计计算，dz
上过她的线性回归和统计计算。周老师在教学工作上投入了相当多的热情，上过周老师课的人应该能从课程设计、课下交流中感受到不少。周老师的课感觉讲得东西相当多
/
深，主要体现在她会通过紧凑的课程设计来讲更多的东西，同时提供一些进阶内容的
intro。周老师会喜欢给大家一些
intuition，帮助大家找到一些统计直觉，我觉得这个是很好的。周老师的作业布置地比较频繁，码量较多（当然能学到东西的课当然是会有相当的练习的，这是dz的观点）。因为统辅
9 的统计计算助教有点不当人&amp;周老师的课确实 workload
就较大，导致旧洞里曾有帖子怒喷 zzy 及其课，dz
觉得是不公允的，如果是确实想认真学好统辅的同学希望认真上一上周老师的课，跟起来会有难度但是可以学到很多东西，并且有助于你在其他课上意识到：这个东西周老师讲到过</p>
<h2 id="李东">李东</h2>
<p>或者称之为
mld（上过他课的人应该知道这个梗）。dz上他的多元统计（前半学期）和时间序列。马老师的课比较混沌，并且数学的部分非常多
&amp; tough，我觉得数理基础比较好的同学可能比较容易
survive，码量较小。但是说回来：马老师的考试比较简单，大概是讲3练1考2的水平，所以课上听不懂的同学也不用太担心
hhhhh。</p>
<h2 id="王天颖">王天颖</h2>
<p>另一位神中神老师，在 dz 这里与 dwl &amp; zzy
并称统辅课前三甲。dz上她的多元统计（后半学期）和生统概论，wty
老师是做生桶的，似乎是 biogenetic
方向，所以在她的课里会有一些生桶背景的内容。讲课也很细致，生桶课是英文授课但
dz 完全没有不适的感觉，作业内容不难，属于讲 2 练 2 考
2，非常均一的难度，给分也很好，dz 在 tyjj 这里拿到了在你清的第二门
A+，感谢 tyjj。</p>
<h2 id="俞声">俞声</h2>
<p>dz 上他的数科导和统计学习导论，俞老师是做 NLP
方面工作的所以他的作业也会代码成分相当多，听说在远古时期俞老师教统计计算的时候甚至会在课上讲
java。但是另一方面来说俞老师本科 &amp;
博士又是数学/运筹这种方向所以他课上的内容又会有很多数学。当然因为他的课是
ML 这种所以也不会有太多很讨厌的数学理论，具体课程考评可以看下面（如果 dz
更的话 hhhh）。俞老师的要求是比较严格的，作业 &amp;
考试是助教改，不会为难你，但是课堂习题的点评 &amp; 大作业 pre
就应该好好搞了，印象比较深的是俞老师的 pre
要求严格限制时间，并且会当场对每个 pre
进行点评并指出不足。另外俞老师常会抽出一节课时间来讲他本组的项目。</p>
<h2 id="杨朋昆">杨朋昆</h2>
<p>dz 正在上他的随机过程，杨老师的课详略布置很好，他的 slides
上会有所有主要结果 &amp;
例子，课上的推导会很细致，也很照顾基础没那么好的同学。作业难度不是特别高，如果概率论学得不错应该可以轻松（指在不太卡壳的意义上）完成。考试和给分等
dz 上完再更 hhhhh。</p>
<h1 id="统辅课程知识关联">统辅课程知识关联</h1>
<p><img src="https://s2.loli.net/2023/02/25/cy45jhtmwLuDr6P.png" alt="workflow-by-v1ncent19.png"></p>
<p>Via
V1ncent19，原地址见：https://www.mathcha.io/editor/GzrM8tE5SOVh7p92LDHj90rlLTkewZZ1t5mPrlv</p>
<p>dz
对统辅课先修关系的大致规划已经在链接中的图里大概画了一下，由于是网络图，dz
不希望弄得太凌乱(e.g.
严格来说初概应该是所有课的先修，但是把每门课都和初概连起来是否有点……)，所以里面的先修关系只标注了
dz 觉得共同点 &amp;
知识运用很多的先修关系，并用实线和虚线稍微进行了一下强度区分。所以这幅图里：</p>
<ul>
<li>没有线不代表没有知识先修关系，有时候是它可以默认包含在你上过一门其他课里，e.g.
初概→→统推→→因果推断这条线</li>
<li>虚线的含义可以理解为：如果你上过上级课对你修下级课有不少帮助，e.g.
指向统计学习导论的都是虚线，因为如果你完全把它当成一门机器学习课来听感觉也基本
ok，但是如果你有一些统计知识的话可以更多得把握统计机器学习的模型内涵。</li>
<li>实线的含义可以理解为：强烈建议先修/不修听不懂，e.g.应随→→时间序列，dz是先上的时间序列导致课程的前半段还是比较痛苦，这也是建议大家在秋季学期把应随上了再接下半学期时间序列的原因=
=</li>
</ul>
<p>省流：这个流程图大家图一乐就好，具体关于课程关系说明大家可以阅读下面的相关板块，关于先修情况的阐述会更详细一些，里面每门课大体会从统计课、数学课、coding
能力上给出一些先修建议。</p>
<h1 id="统辅课程测评">统辅课程测评</h1>
<h2 id="初等概率论-邓婉璐">初等概率论-邓婉璐</h2>
<p>从课程难度和课程进度综合比对上 wljj
的把握是很好的，而且考前也会有课程大纲的复习帮助大家找到课程主线。课程中未来会用到较多的主要是一些分布（尤其是正态分布及其衍生分布）、概率/期望/方差（及其
conditional
版本）的一些性质、收敛性在统辅课中要求的不多但是大数定律和中心极限定理就是很重要的内容了，希望以上三个部分大家不要太敷衍
hhhhhh。我们当时额外有一讲是多元正态分布的性质，大家也可以认真听一听，虽然多元里会讲但是这个内容蛮实用的。</p>
<p>前面也提到了 wljj
课堂讲授在数学推导和统计直觉上都做得很不错，这对学统辅进阶课是很好的；初概和统推都是每周
6
个课时，可能时间比较紧，虽然这两门课都不太难，不过还是建议大家尽量做一做预习和复习的工作这样课上能跟上思路，尤其是如果一些同学觉得自己数学不是很好的话，可能一段没跟上就已经讲到很后面不好补了；另外课上可以多给老师一些反馈，接接茬之类的，（dz
听另一位老师提到 wljj 偶尔会在办公室吐槽大家不是很活跃 hhhh）。总体来说
wljj 的初概在大致是讲 2 练 2 考 2
的水平，给分很可观，但考虑到课程本身不是完全的水课，所以希望大家不要完全抱着水学分拿
4.0 的心态来，还是需要付出一定努力的（anyway
这门课几乎能保证努力了一定有好的绩点体现，这感觉已经不知比一些课高到哪里去了）。</p>
<p>收获方面的话作为一门基础课主要作用当然是给后续课程提供支撑，大家可能注意到了
wljj 没有讲一些很糟糕的严谨数学（数学系的同学
sry，数学不糟糕，但是严谨的数学证明真的很折磨 =
=），我觉得这让初概作为一门基础课能够更好地让来自不同院系背景的同学接受，当然大家的知识基础不同，要付出的努力可能也会稍有差异，但是
dz 估计只要能上课基本跟上 wljj 的思路 +
作业好好做，那你的收获就足够为接下来的统辅提供良好的支持。</p>
<p>补充：课程教材外另一个 dz 用地较多的是北大 ldf 老师的盖桶讲义：</p>
<p>https://www.math.pku.edu.cn/teachers/lidf/course/probstathsy/probstathsy.pdf</p>
<p>这个系列还有统计计算和时间序列，大家可以去看看。</p>
<h2 id="统计推断-王江典">统计推断-王江典</h2>
<p>王老师的一些特点前面的教师篇已经提到一些了。这门课本身是统计的基石课程（dz
私下觉得它可能是最重要的），课程大致就是三个版块：统计量、估计、假设检验，会介绍统计推断中最
general
的那部分理论，包括如何描述估计量的性质、如何构造估计量、如何设计假设检验等。dz
觉得在整个统辅的角度来说里面地一些概念会反复用到，包括但不限于 sampling
dist / 无偏性 / MSE / MLE / OLS / 枢轴变量（pivot variable）/ 渐进性质 /
几种重要的假设检验思路（e.g. wald, score, LRT）/ hypothesis / p-value /
power function
等，另一些知识以后用到的没那么多，比如比较讨厌的充分完备统计量、UMVUE
之类的，但是如果有同学以后有计划转统的话这些内容还是都很重要的。dz
那个学期最后一小段王老师介绍了一些
non-parametric，讲得不多，至多算是提供了一个引子吧，主要的内容还是 dz
上面说的那些</p>
<p>wjd 老师课上会有很多推导，前面的帖子<a href="https://thuhollow.github.io/##107328">#107328</a>
里提到了王老师有时候容易把自己绕进去的情况，dz
深以为然，所以非常建议大家课前预习的时候把整体的证明思路都大致看一遍，不需要看计算细节因为王老师会带你做，但你需要知道你处在整个证明的哪个阶段，不然你可能会跟着迷失
hhhh；dz
当时统推是晚课，到课程最后课堂中二氧化碳浓度升高头已经很晕了，跟上进度更是不容易，如果今年还有晚课的话希望大家能
survive.</p>
<p>难度上大体是讲 2 练 1 考 2，考试不难，但有一定计算量，所以我打了 2
分。希望大家在符号计算和 C991 使用上都有一定造诣，dz
期末考试上打计算器打得非常疯狂，最后差不多是勉强提前 15
分钟完成的样子（对比之下同样是王老师的生存分析课考试就可以提前一个小时 =
= 也可能是 dz
统推学得不好）。给分方面王老师很慷慨，统计推断的给分分布没有详细调研但总之
dz 没有翻车，上学期的生存分析似乎几乎是全
4.0，所以大家不用担心给分（似乎统辅课几乎都不需要担心给分 hhhhhh）</p>
<p>收获方面客观地说就是完全够用，如果你想学更多可能就要寻求数学系的概统了，王老师的统推支持你学习后面的专业课是问题不大的，但是
dz 会建议大家在学习的时候多整理一下思路，从更抽象 /
更直觉地角度思考一下学习的内容，以免你迷失在推公式和求统计量中，因为里面的概念在后面的课程中会以不同的面貌出现，如果大家只记得它在课程中出现得样子而没有思考过它的内涵的话可能会影响对后续课程的理解。</p>
<h2 id="多元统计分析-李东-王天颖">多元统计分析-李东 &amp; 王天颖</h2>
<p>dz 那学期是 wljj 休假了，所以由马老师和 tyjj
来代课，应该说这两位老师的风格和 dwl 都不是很像，所以 dz
先把这块搁置了，先更后面的。</p>
<h2 id="线性回归分析-周在莹">线性回归分析-周在莹</h2>
<p>dz 觉得线性回归是统辅的核心课程，大家可能注意到了 dz
给统计推断的描述是基石课程而给回归课的描述是核心课，因为 dz
觉得统计推断是很多子版块背后的基础知识，而线性回归作为很基础的模型，它的概念、思想可以为迁移到其他版块的模型提供接口，所以
dz 作了这样的描述，不知道大家能不能 get 到 dz
的意指。不知道下学期的回归课还是不是周老师上，dz
觉得她把这门课教的很好，因为这门课的内容就是需要稍微充实一些才能覆盖一些稍微琐碎一些的知识点（而这些琐碎的点恰恰是大家以后会用到的）。这门课
dz
上的时候架构是这样的：前几周是单变量回归，就是大家高考的时候都学过的那个版本，会介绍相关的估计及性质，以及相应的
ANOVA。在这部分结束后会介绍一些诊断，比如齐方差、正态性、独立性等，以及对
outlier/leverage/influential
的诊断初步，以及通过变量变换进行修复。之后是多元版本，这个部分需要用到一些矩阵的语言，希望大家线性代数学得不错，有一个好处是讲这个部分之前大家应该已经在多元回归分析课中学过一些矩阵
/
多元随机变量的知识了，会好一些。这个部分同样是讲估计、ANOVA，之后会有一些多变量回归会遇到的共线性诊断、变量选择的问题。最后会有一部分向大家介绍离散分组变量的因子模型。</p>
<p>上课方面，周老师在每堂课开场会向大家以大纲的形式介绍一下这节课的内容，并提及这些部分和前后学习的知识的联系，这个非常实用，大家上课时可以注意一下这部分。周老师的另一个特点就是有很多雨课堂习题/投稿来让大家
keep focus
并让她了解大家的学习进度，她在看到自己觉得说的好的课堂投稿的时候会在教室里寻找这位同学予以表扬，所以如果你恰好在宿舍上课而又投稿了被点到就会比较尴尬
hhhh。其实周老师在课上给大家发的问题都是很好的思考题，并不是像其他一些课上的习题。如果大家课上能跟上周老师的思路思考这些问题的话会有非常多收获。当然说回来，周老师的课堂内容也是很多的，节奏也比较紧凑，但并不是说你要有很好的基础，周老师的课属于你认真听就基本能跟上，所以大家课上不要摸鱼
hhhh。课下作业这一块公式推导和代码都会有一些，所以非常推荐大家使用
rmarkdown 完成（其实 dz 觉得统计推断开始就可以用 rmd
了）作业题主要来自于教材 KNNL. 线性回归的 workload
感觉不是统辅课中最大的（最大的可能是同样由周老师教的统计计算
hhhh，但今年换成另一个老师教了），但也需要一些时间就是了，特别如果你在推导
/ 代码上不太熟的话可能一开始会 struggle 一下。</p>
<p>总体来说有些同学可能上回归课会觉得这门课的内容很“碎”，尤其是上到诊断那一块的时候，大家会觉得不像是一门“系统”的学科，因为有很多很多子版块。dz
和周老师交流过这个问题，周老师对这门课的定位是“应用统计课”，所以在其中讲述了很多大家在用统计学处理实际问题的时候会遇到的问题，dz
在后面做大作业/其他项目的时候深以为然，很多时候大家真正面临的任务并不是
well-defined with excellent data.
这些诊断、变换、数据清洗等脏活累活确实是占了很多部分的，所以希望大家在这些部分也多听一听，不一定要完全学会，但是以后在遇到实际问题的时候能想起来“周老师讲过这个方法”就很好了。</p>
<p>考评这一块，周老师的考评比较多元化，课堂表现、期中、期末、capstone、给老师发课程建议等等。但是并不意味着这是一门卷课，dz
那学期因为时间关系取消了期中，期末可以在考试和 capstone
中选一个做，所以压力并没有那么大。dz
当时选的是课程论文，但因为dz非常不擅长做比较社会科学的课题，而且精力分配的也不是很多，最后论文应该只有
85 分左右（sry 周老师，但是我真的不会写 =
=），但是其他东西加起来最后竟然还是拿到 A-
了；考试这块我听参加了考试的同学说&amp;我后来参加统计计算的考试能看出来周老师的考试并不会为难大家，大概是讲
3 练 1.5 考 2 的水平。</p>
<p>周老师十分喜欢和同学们交流，很多次习题课都主动留下来和同学们交流（dz
当时是习题课紧随在下课后），发邮件提问也都会得到热情的回应，所以建议大家有什么疑惑
/ 对课程有什么意见都多和老师沟通。
关于课程收获前面已经谈了一些了，主要就是帮助你 handle 实际问题 &amp;
为以后的学科提供接口，大家在以后的很多课上应该都会见到线性回归课上一些概念的影子，dz
觉得周老师的线性回归相当好，不知道下学期是不是还由她来教。</p>
<h2 id="统计计算与软件-周在莹">统计计算与软件-周在莹</h2>
<p>今年周老师休假去了，所以换成了张老师开，这个老师 dz
完全不了解，而且统计计算这门课内容会比较杂，课程内容会有很多老师的个人色彩，所以
dz
只向大家介绍周老师版本的课程大纲。最开始是一些关于计算机的基础知识，包括储存、运算等，以及
R 的一些知识，既有程序语言特点如向量化操作的介绍，也有一些实用的 R
命令；之后的算法部分首先是关于算法的基本前置知识，然后依次是线性代数中的算法、优化算法、EM
算法、随机模拟相关算法如 Bootstrap、MCMC。就目前 dz
上过的课来说暂时没有看出这门课多数内容在后续课程中的实用之处（逃），不过
R 语言简介、bootstrap、EM
倒是经常出现的，前面的线性代数算法大家可以当成是线性代数复习，里面也有一些有趣的线代结论；优化算法部分，大家就当是对那些算法有个脸熟吧。但是说回来虽然这门课的知识在统辅中好像用的不多，但是在你实际解决问题的时候/科研中是会用到的，你会需要去考虑你怎么设计程序才能避免长时间的等待
hhhhh，所以 dz 觉得这门课介于重要和不重要之间，取决于你的需求。</p>
<p>关于这门课的其他信息，如果明年换回周老师开了 dz
可以补上测评，目前大家可以先看看课程大纲图一乐。</p>
<h2 id="数据科学导论-俞声">数据科学导论-俞声</h2>
<p>这门课其实 dz
觉得完全可以大二上就选，这课不考试，感觉课下也几乎不用花时间，可能只有期末
project 的时候会比较忙一些，总体来说作为一门 3 分课 workload
相当小。课程内容包括对 R 的介绍、基本语法元素和逻辑语句、R
的一些特性比如向量化、数据处理、正则表达式与文字处理（因为俞 sir
是做文本处理相关工作的）、非常初等的机器学习、R
的作图和交互式文档等。从课程内容来说大家就能看出来这门课的内容非常应用了，课后作业基本就是让大家用课上学到的技术实现一些小任务，纯代码作业，最难的任务也就是在文本处理那块需要实现一个简单地
Baysian
分类器这样了，只要大家不是在代码方面完全陌生，稍微查查文档应该都能轻松
handle，而且 RStudio 是自带 Rdocumentation
的，甚至不需要你自己上网找，rmd/shiny 等进阶工具也都内置在 RStudio
里了，是一门新手友好的编程课。里面介绍的工具 /
技术都是非常实用的，这也是 dz
建议大家可以在大二上就选它的原因，可以方便大家在其他课程中用 R
完成作业。</p>
<p>课程中最有挑战性的部分是
capstone，要求组三人小组，自定一个任务并用课上学到的数据处理方法 +
一些机器学习做一个有趣的项目，就 dz 课上的观察很多人都用了 DeepLearning
相关的东西，但是其实也看到有很多小组没有用 DL
也有很有趣的结果，所以大家不用担心不会 DL 框架会吃亏（当然现在很多 DL
框架已经几乎能做到开箱即用了，学起来也并不难，大家不必有畏难心理）。前面说过俞
sir 是比较严格的，pre 的时候严格控制时间、要求每个同学有 equal
contribution、当场发表点评和建议都是俞老师的特点。顺带提一句，dz
私下觉得俞sir很帅，仅凭这一点也建议大家去上俞 sir 的课 hhhhhh。</p>
<p>另外俞老师似乎是不接受手选的，所以大家选课的时候优先级可能要放高一些，据他说主要原因是大作业中需要控制规模保证质量，不知道今年是不是还是如此。</p>
<p>春季学期的统计学习导论也是由俞 sir
教，但是这两门课之间没有什么联系，这也是 dz
建议大家可以早点上的另一个原因 &amp;
大家可以放心直接选统计学习导论。</p>
<h2 id="统计学习导论-俞声">统计学习导论-俞声</h2>
<p>与数科导的码课风格不同，俞老师的统计学习导论 dz
觉得更像是一门数学课，这门课建议大家先修线性回归和多元统计，因为俞 sir
虽然课上会带大家复习一些重要结论，但是毕竟是走马观花地过一遍，dz
听的时候觉得在学过一遍的情况下跟着复习效果不错。一个吐槽就是 dz
其实觉得从统辅设计的角度来说可能应该数科导放春季学期，统计学习放秋季
hhhhh，这样课程衔接会比较好一些。</p>
<p>课程内容主要基于 Springer 的 The Elements of Statistical Learning
这本书（顺便推荐一下 Springer Series in Statistics 这个系列的书，dz
觉得写得都很好，非常适合想要学习更深入统计学理论的同学），在这门课上你会学到很多机器学习模型的具体数学理论和性质（虽然讲得也没有很深，但是总之可能和大家想象中的机器学习课不是那么一样），比如回归讲变量选择的相关理论、分类模型讲
Baysian 分类准则、SVM 从约束优化讲起，搭配后面 RKHS
理论、聚类模型的谱方法、决策树的一些理论和后面的网络模型。据 dz
搜集到的课程反馈来说大家还是觉得这门课需要一些数学推导能力。课程作业数学代码均有，难度适中；有期中期末考试以及
capstone：考试就是有很多数学的东西了，题型包括判断简答和大题，据说不是那么容易（虽然
dz 考得不错），印象比较深的是期中考了一个 Kernel
Logistic，因为才刚讲完优化和 Kernel
相关的理论可能一些人没有复习，所以据助教说总体表现不是很理想。大作业的风格和数科导差不多，也是小组作业自选题目跑模型的样子，上学期由于疫情关系线上
pre 了，很遗憾（庆幸）没有线下感受俞 sir 的威压 hhhh。难度上 dz 觉得是讲
1.5 练 1.5 考 2 的水平。</p>
<p>收获这一块 dz 觉得比较重要的还是你会对一些重要的模型的基本架构 /
参数来源有一些了解，比如你会知道 cSVM 的 c
是什么之类的……当然这门课对神经网络涉及不深，毕竟不是专门的 DL
课，神经网络部分只是课程的其中一个版块；dz
觉得讲得比较出彩的还是前面的“传统模型”，或者说是前深度学习时代的模型。当然说回来大家在处理一些规模不算大，深度学习不好使的任务的时候这些经典模型还是很实用的，所以还是值得大家一学的，俞
sir
也会向大家介绍模型的适用特点、调参哲学等，作业的代码部分也有一些实现，算是兼顾了实用性的教学吧。</p>
<p>上次忘了补充一个点：俞 sir
上课十分渴望与同学们互动，但是大家好像都不是很喜欢和俞 sir
接茬的样子，希望以后再选俞 sir 课的同学们多多互动，capstone
选题的时候也可以多去讨论自己的想法，俞 sir 会给出很实用的建议。俞 sir
只是看起来 &amp; 对待学术问题的时候很严肃，在放松一些的场合俞 sir
人是很好的，而且好像还是深度二刺猿（未确证）/ 游戏宅（确证）。</p>
<h2 id="时间序列分析-李东">时间序列分析-李东</h2>
<p>马老师的课基本上 ppt 难度都比较大，讲课会给人一种比较混沌的感觉，dz
感觉这门课可能会是数学系同学喜欢的课（不是说数学都很混沌的意思
hhhh，指的是数学很难）。这门课的主要内容是
ARIMAmodel，一些其他的时间序列方法则涉猎不多。主线剧情是随机过程相关的一些简短介绍、对时间序列的描述、AR、MA、ARMA、SARIMA、诊断
&amp; 变点检测、多维版本、（其他都是 dz 基本没怎么听懂的内容
TuT，就当它们不存在吧）。马老师的课中会有比较多数学理论，课上会带大家过一遍但是不会讲深，大家如果感兴趣可以寻找
ppt
中感兴趣的内容自己探索，如果只以完成课程主线、拿到学分为目的的话这门课是讲
1 练 1 考 2，如果以认真学习掌握内容为目的的话就是讲 3 练 1 考
2，大家可以选择适合自己的学习模式。马老师答疑这块还是很认真的，dz
偶尔课后旁听了一些讨论，会针对课上的一些点介绍更详细 /
具体的理解。作业不多而且难度较低，期末有大作业和考试，大作业是做一个和中国有关的时间序列任务，不需要特别复杂，考试稍微有一些数学推导的内容，但是远用不上
ppt 里 /
课上讲的内容那么多，大家把握主线、熟悉基本概念和记号、学习一些比较基础的结论应该就够了（最后有一道思考题会比较难，需要有一定的数学理解才能答得出来），另外考试会有根据
R 输出写分析的半开放题，所以非常建议大家平时课后 / 做作业时多进行一些
coding
实践。这门课的给分总之应该不差，不知道是不是大家都学得比较混沌的关系，dz
感觉大多数内容都没有听懂也拿了 A-hhhhhhh。</p>
<p>收获这一块方差较大，取决于你有没有认真课后花一些时间，如果只是学到了考试要求的内容的话可能这门课收获就不会很大了，你可能至多知道
ARIMA 模型的框架和基本概念 = =，不过相关实现已经良好封装在 R
里了，实践起来倒也不会有太大问题。</p>
<p>补充一个点就是 dz 现在回忆起来，上这门课非常建议大家先修随机过程，dz
因为是物理系没有随机过程这门课，直接去修时间序列感觉还是吃了一些苦头的。</p>
<p>在实际使用中如果大家想了解 R 代码实现 /
熟悉一些其他的模型，dz参考过前面说过的北大 ldf
老师的教材https://www.math.pku.edu.cn/teachers/lidf/course/atsa/atsanotes/html/_atsanotes/atsanotes.pdf
以及另一本非常好的在线参考书https://otexts.com/fppcn/
大家可以去看一看</p>
<h2 id="生物统计导论-王天颖">生物统计导论-王天颖</h2>
<p>这门课确实是一门导论课，除了有因子模型稍微讲得深一些其他都基本上是让大家留个印象的级别。内容包括：统计推断的基本哲学回顾、因子模型、列联表、生存分析、临床试验、基因组学中的关联性分析（dz
随便翻的 = =，原称为
GWAS）。这门课是统辅中较为少见的2分课，内容确实也没有很深入 / 难，dz
觉得上过初概、统推、回归应该就足以 handle 的。课程是全英文授课，不过
tyjj 的口语很好，dz
觉得理解起来还挺轻松。任务量方面：作业量不算大，没有期中，期末考评是最后的期末考
+ 倒数第二节课的一个口头 pre，不用交书面报告；期末考允许 Cheatsheet
加上课程中没有特别艰深的数学，所以考试难度不算大，报告是做一个与
Covid-19
有关的问题，使用课上讲过的分析方法，因为课上对因子模型、生存分析、clinical
trial 等 topic都做了介绍，所以选题内容还是很广的，tyjj
也细心地提供了一些好的数据源，pre
打分是多方（同学、老师）交叉打分的方式。总体来说任务量不大，dz
觉得是很好的 2 分课的范本（真 · 两分：课上 1.5h + 课下 1.5h
绝对足够），难度上考虑到英文授课，可能可以给到讲 1.5 练 1 考
1，给分也很好，是一门较快乐的课程。tyjj
很关心同学们，答疑也很认真，大家如果上 tyjj 的课可以多去和老师交流。</p>
<p>收获这一块因为是导论课，所以 dz
觉得主要的意义在于提供一个生统的窗口，因为里面确实也介绍了很多生桶的进阶方向，比如生存分析、临床试验和基因组分析等，便于大家对生统这个学科的框架、研究的问题有一定的了解。</p>
<h2 id="可靠性数据与生存分析-王江典">可靠性数据与生存分析-王江典</h2>
<p>前面提到了生存分析是生统的一个分支版块，生统概论课上也有一个 section
是讲生存分析初步的，所以大家可以像 dz
一样把这两门课一块选，都在春季学期。如果对生存分析不太熟悉的同学可以先笼统地理解为研究“某件事情什么时候发生”（这个时候就不得不提起某蒙古上单的评论“*
* 什么时候 * 啊”，大概就是研究这种事情）。课上会先介绍生存函数 &amp;
相关概念及一些常用的参数化模型；之后在简单回顾一些统计推断知识后，讲非参数的估计
/ 检验方法，包括 life table 的检验、分组生存情况的 CMH log-rank
test、Wilcoxon rank sum test 等；之后是参数 / 半参数模型，包括 PH model
和 AFT model；其它还会有一些临床试验设计的 topic.
课程覆盖面这块还是比较充实的，也会有比较深入的话题。关于王老师的讲课风格方面在前面的<em>老师测评帖</em>和<em>统计推断帖</em>已经有所介绍了，这门课类似。作业的理论部分会有一定的难度，因为算一些具体的例子的时候还是有一些计算量的，其余大多数都是要使用
R 的，不过相关函数都已经良好封装了，大家要善于查文档解决问题
hhhhh。课程包含期中考和期末
pre，期中考不难但也不算简单，基本就跟统计推断是一个风格：一些概念理解 +
少量理论 + 较多的例子计算，dz
当时忘了带计算器了导致是在教学楼管理处借了一个那种会计计算器，搁那人肉泰勒展开算指数函数值，有点疯狂，导致在计算量比较大的背景下虽然做完但是答案几乎都错了
= = 期中成绩较为惨淡。期末的 pre
是大家组队读论文作口头报告，王老师提供了几个 options，dz
都查了一下，应该都是生存分析领域比较经典的论文，也和课程内容有紧密的联系，好好读下来是会有所收获的大作业。这门课给分良好，dz
如此惨淡的期中考背景下还是拿到了
A-，可能也是课堂规模小的缘故(这门课我们当时报的人比较少，可能是因为这个课是比较分支的分支领域，大家了解的不多)，总之大家如果报这门课不需要担心给分。难度上是讲
2 练 2 考 1.5 的样子。</p>
<p>课程收获这一块 dz
觉得是不错的，因为课程的理论部分不少，作业中的码题也保证了一定的实践量，所以大家如果以后有意走生统方向的可以来上一上这门课。</p>
<h2 id="因果推断导论-邓婉璐">因果推断导论-邓婉璐</h2>
<p>（V1ncent 更新了，我这里也更新一下）</p>
<p>wljj
的课程讲授还是这么稳健。这门课还真是导论课，主要介绍了两种主要的因果推断框架，主要内容分别依据两本课程参考书
Causal Inference for Statistics, Social, and Biomedical Sciences 和
Causal Inference in Statistics: A Primer
大家如果想预先了解一下/课上具体查询详细解释用可以翻翻这两本书。课程导向还是比较应用的，课后材料也提供了足量
coding 让同学们鉴赏。因果推断本身也是正在蓬勃发展的分支领域，
所以课程的整体思路是介绍一些基本的理论 &amp;
相应的哲学，有一些具体的算例让同学们熟悉应用方法，然后在中间穿插提供一些进阶内容的接口，有
reference 供同学们查找。课程讲述这块就是比较 wljj
的风格，不过和初概不太一样的可能是因果的内容更应用更琐碎一些，所以本身没有初概那么好讲，另外
dz
感觉有些地方的定义阐述不是很详细/周到，课下需要自己多查查书，特别是因果图那块的定义还蛮多的，大家除了查书还可以看看最后提供的一个引用链，里面提供了更多
intuitive 的解释和算例。课程考评包括 6-7 次的作业、自选题的 capstone
以及期末。作业不难，基本就是自己完成课程推导补充/一些简单的算例；大作业提供了往年优秀样本供大家参考，对着依葫芦画瓢应该也能取得不错的完成度；期末考试提供往年样题，且从最后出卷情况来看和作业重合度也较高，不知道有没有照顾大家普遍在阳的成分在，dz
就是最难受的时候撑着考完了试，光速做完就难受得交卷去睡觉了
hhhh，如果不出意外的话期末考应该是炸了，但是最后还是捞了个
A-，让我们说谢谢 wljj，当然 dz 大作业确实还是做的挺认真的，anyway
大概这门课稍微用点心思混个 4.0 还是不难的，大家不用担心。</p>
<p>关于给分：看来是大作业发力了，wljj
给了个优秀大作业，当然期末考大约是炸了，一加一减吃个
A-，大四老狗心满意足地走了；综合来看是比较 wljj 式的给分（你要问我什么是
wljj 式的给分，我只能说不知道 lol</p>
<p>最后给大家提供一些实用链：</p>
<p>Rubin
现在在丘中心任职，他在数学中心每学期有公开课，大家如果对因果推断领域感兴趣可以去听一听，指路
https://ymsc.tsinghua.edu.cn/xshd/zxgkk/jqgkk.htm；</p>
<p>因果图部分看过比较实用的是这个博客
https://rpatrik96.github.io/posts/2021/10/poc1-dags-d-sep/</p>
<h2 id="应用随机过程-杨朋昆">应用随机过程-杨朋昆</h2>
<p>这门课是真·应用·随机过程，课程中严格详尽的理论推导不多，我觉得可能更多是让大家多熟悉一些随机过程的基本模型、对随机过程的描述、相关处理方法、一些具体应用，这门课的教材是
Hajek 的 Random Processes for
Engineers，从这个书名大家应该也能猜到内容不会特别数学。杨老师并没有完全按照教材内容讲，顺序也是自定的，不过课程讲述顺序还不错，会有很多对基础前置知识的讲解，每一节集中处理一个
topic。这门课的难度不算高，杨老师的说法是上过概率论即可
handle，实际处理起来 dz
发现因为涉及一些连续型序列的问题，有一些泛函/应用 ode
的基础会更容易做题（少量基础即可）。授课方面是课前上传
ppt，课上板书讲解；slides
中包含所有重要结果，课程时间线也安排的很好，都是下课正好讲完，看得出老师在时间安排这块有
bear
来（doge）。这门课知识内容不难（如果你不去细扣课上略去的严谨推导的话），不过作业是一课一布置，所以还是有一些任务量的，作业难度比讲课难度略高略深，很多是对课堂内容的补充。考评方式是作业期中期末，无大作业。作业无
coding，助教的作业批改反馈挺详细，考试前习题课助教也会帮大家划重点。由于这门课开课历史不算悠久，所以考试难度控制比较成谜，从
dz 的经验来说可以给到讲 1.5 练 2 考
2。收获这块如果是瞅着“应用”俩字来的同学应该会比较有收获，比如课上讲了不少滤波/新息预测/决策过程之类的东西（也许是因为杨老师是你清
ee 系出身的罢
hhhhhh）；但如果是想学很多数学的同学的话可能不会很喜欢这门课的知识模式。</p>
<p>另外这门课在秋季开课，推荐大家 e.g.
大三秋季上应随，可以接春季的时间序列。</p>
<p>关于给分：给分也太好了，dz
期中拿了个烂分，期末阳着考了估计也是依托，结果还是 A-，好大力度的 curve
啊，杨老师我的超人。</p>
<h2 id="逻辑回归导论-王江典">逻辑回归导论-王江典</h2>
<p>（注：V1ncent
没上这门课所以没有测评，这个测评是来自这个树洞里其他层主的回复</p>
<p>这门课写作“逻辑回归”可能一时让人摸不着头脑，其实对标国外统计系的培养方案，这门课还有个名字叫
“Categorical Data Analysis（CDA）”（wjd
老师似乎说是申报课程的时候的一些遗留问题？）。CDA
其实是统计学中比较重要的一个分支，想在 biostatistics 或者 social science
之类的方向继续研究的话可能是需要掌握一些想关的知识的。由于王老师有说过这门课是以应用为主，所以涉及的理论部分不是很多，课程内容主要以老师的
ppt 为主，但感兴趣的话也可以参考一下 Agresti 的《Categorical Data
Analysis》（CDA的经典教材，内容非常全面）。课程的考核方式是期中 + 大作业
+
作业（40%+40%+20%），没有期末考试。平时作业大概两周一次，内容不算少，但部分题目就是上面
Agresti 那本书上的习题（顺带一提本书有 solution manual
）。期中考试以概念理解为主，题目很多都有应用背景，会考 R
代码的阅读，总体来说比较简单，但是题量比较大，很多人做不完，不过老师最后也调了分。期末的大作业是
3-4
人一组，自选题目，可发挥空间很大，而且老师会发往年的优秀报告（甚至最后很多组就是参考的优秀报告做的x），还有小组互评环节，只要不是太划水最后得分应该都不错（？）</p>
<p>如果套用 dz 的评价方式，这门课大概是讲 2 练 2 考
1.5（？）感觉这门课在统辅所有选修课中算相对轻松容易的（毕竟只有两学分），课程的内容也是比较有用的，给分也不错，还是比较推荐的～</p>
<h2 id="非参数统计导论-周在莹">非参数统计导论-周在莹</h2>
<p>（注：V1ncent
没上这门课所以没有测评，这个测评是来自这个树洞里其他层主的回复</p>
<p>cz 上过 2021 秋季学期的非参数统计导论，是 zzy
老师的，简单介绍一下印象。</p>
<p>2
学分课程，任务量比其他统辅课程会小一些，大概和逻辑回归相当吧。非参主要是讲如何在不假定分布的情况下做检验（比如平常的许多检验假设正态性，这在非参里面是不行的）。比如有
permutation test，binomial test，rank statistic，sign test，signed rank
test，对中位数的统计，分布检验（KS 检验），runs test
等，讲的内容不算太多。</p>
<p>成绩是 10% 课堂，40% 周常作业，50% 大作业。课堂上和 zzy
老师的其他课程（线性回归、统计计算）差不多，会有不少雨课堂题目，所以大概还是要听课的。教材是
Applied Nonparametric Statistical Methods, Fourth Edition, by Peter
Sprent and Nigel C . Smeeton，作业题会从里面出（出作业的时候直接简称
ANSM），也可能是课件里的证明。小作业总共 11
次，每次的任务量不算太大（相比于统计计算来说（</p>
<p>大作业是个人的，所以不用小组分锅（），要求适合用非参方法，但其实非参能做的事情也没那么多，可能比较好做的就是两个总体的比较，感觉还是
EDA、做些检验啥的，结合点别的方法。最后给分感觉还算慷慨，由于当年上的时候课友不多，没有足够的数据点。zzy
老师的课给分感觉还算不错，非参也挺符合老师总结说的“快乐成长、负担不重、收获满满”，cz
体验不错。</p>
<h1 id="资料索引">资料索引</h1>
<ul>
<li><p>工工 8 的一份统计计算总结材料：
https://mp.weixin.qq.com/s/LsQTh1_g93GJ5eGpaCh22Q</p></li>
<li><p>原作者 V1ncent19 的笔记整理，大家快去
star（x）：https://v1ncent19.github.io/SummaryNotes/</p></li>
<li><p>北大李东风老师的统计计算讲义：</p>
<p>https://www.math.pku.edu.cn/teachers/lidf/docs/statcomp/html/_statcompbook/statcomp2ndv.pdf</p>
<p>应用时间序列分析讲义：</p>
<p>https://www.math.pku.edu.cn/teachers/lidf/course/atsa/atsanotes/html/_atsanotes/atsanotes.pdf</p>
<p>概率统计讲义：https://www.math.pku.edu.cn/teachers/lidf/course/probstathsy/probstathsy.pdf</p></li>
<li><p>时间序列的在线参考书：https://otexts.com/fppcn/</p></li>
<li><p>因果推断导论-因果图：https://rpatrik96.github.io/posts/2021/10/poc1-dags-d-sep/</p></li>
<li><p>YMSC Rubin 的公开课：
https://ymsc.tsinghua.edu.cn/xshd/zxgkk/jqgkk.htm</p></li>
</ul>
]]></content>
      <tags>
        <tag>这里面看起来很好玩</tag>
        <tag>数学</tag>
        <tag>统计</tag>
      </tags>
  </entry>
  <entry>
    <title>数理统计初探——统计推断</title>
    <url>/2022/11/09/Statistical-Inference/</url>
    <content><![CDATA[<p>据说统计推断是统辅基础五大件里最难的，这门课也可以直接称为数理统计（基础）。我初概的体验并不是很好，甩锅给了不匹配的教材，还记了
PF。但统计推断要洗心革面好好上，也打算做预习。不仅是因为不打算再去数学系回炉重造，也是担心留下一种隐隐怀疑自己并不是很适合学统计的感觉，本科过半又换方向的试错成本就略高了。</p>
<p>不过，我确实也很好奇到底适不适合、有多感兴趣呢？真不行的话，该换还得换呀。</p>
<span id="more"></span>
<p>这课的 PPT
是英文，老师讲课用中文，教材英文中译都有，图书馆借来的是中文版，据说考试卷子是英文的。</p>
<p>妈呀.jpg，所以以下遇到名词的话会中英都写。一些懒得打的东西就直接通过截图
PPT 或者手写拍照给出，主要我也怕我把写的东西弄丢了（。</p>
<h1 id="lecture-1">Lecture 1</h1>
<p>先吹了会水，尽管课时紧张，还是要骗骗大家统计学前景非常广阔 x</p>
<p>本节介绍统计推断中的一些基本概念，对应教材第五章《随机样本的性质》。</p>
<h2 id="研究范围约定及基本定义">研究范围约定及基本定义</h2>
<ul>
<li><p>研究范围的约定：在研究大量数据、确定其行为时，因为难以全部分析，我们会对其进行多次随机抽样（Sampling），研究多次得到的样本的性质，以及“多次”中蕴含的性质，来推断总体数据的性质。这是统计推断的核心思想之一。以下约定一些术语。</p>
<ul>
<li><p>Population（总体）：总的研究范围，用一个随机变量 <span class="math inline">\(X\)</span> 来概括，<span class="math inline">\(X\)</span> 服从有某些参数 <span class="math inline">\(\theta\)</span> 的分布 <span class="math inline">\(F\)</span>。我们的目标正是通过抽样来找到这个分布
<span class="math inline">\(F\)</span>，从而刻画 Population
的性质。</p></li>
<li><p>Population parameters：用于表征 Population
的性质，比如期望，方差，矩，也就是上述的 <span class="math inline">\(\theta\)</span>。例如，对于一个服从正态分布的
Population，它的 Population parameters 记为 <span class="math inline">\(\theta=(\mu, \sigma^2)\)</span>。</p></li>
<li><p>Sample（样本）：多次抽样得到的随机变量 <span class="math inline">\(X_1,X_2,...,X_n\)</span>
独立同分布，有相同的（边缘）概率密度函数（PMF） <span class="math inline">\(f(x)\)</span>，则称其为 Population
中的（随机）样本。</p></li>
<li><p>Sample size（样本量）：显然上述的那个 <span class="math inline">\(n\)</span>
就是样本量，表征样本大小，trivial。</p></li>
</ul>
<p>举个例子。现在有 10000
个产品，其中有一部分废品。我们想知道大约有多少废品又不希望检测所有的产品，于是每次抽样
100 个进行检测。此处的 Population 就是指 10000 个产品，每次的 Sample
是抽到的 100 个样品，Sample size 是100。可以在 Population 上定义随机变量
<span class="math inline">\(X\)</span>，如果产品是废品则 <span class="math inline">\(X=1\)</span>，合格则 <span class="math inline">\(X=0\)</span>，则每个样本可以表征为 <span class="math inline">\(X=\lbrace X_1,X_2,...,X_n\rbrace\)</span>。</p>
<p>在我们抽样之前，<span class="math inline">\(X_i\)</span>
都还是未知的随机变量，和 Population 同分布。然而抽样之后，<span class="math inline">\(X=\lbrace X_1,X_2,...,X_n\rbrace\)</span>
就成为了一个确切的，由实数组成的数组，比如在上述例子中，某次抽样得到的结果是一个由
<span class="math inline">\(0,1\)</span> 表示的数组。</p>
<ul>
<li><p>Sample
space（样本空间）：和概率论中的样本空间不太一样的是，这里的样本空间表示所有抽样可以得到的数组，用
<span class="math inline">\(\chi\)</span> 表示，这个符号和 Chi-Square
分布的符号是相同的。在上述例子中，就是：<span class="math inline">\(\chi
= \lbrace (x_1,x_2,...,x_{100}) | x_i \in \lbrace 0,1
\rbrace,i=1,2,...,100\rbrace\)</span>。</p></li>
<li><p>Simple random sampling：怎么定义随机抽样？如果能使得到的 <span class="math inline">\(X_1,X_2,...,X_n\)</span> 独立同分布（<span class="math inline">\(i.i.d. \sim
F\)</span>），那么这种抽样方式就是简单随机抽样，也称为随机抽样。</p>
<p>需要注意的是，简单随机抽样是有放回的，否则抽到某一元素的概率会不断变化，并不是独立的。</p></li>
<li><p>Joint distribution function：<span class="math inline">\(F(x_1,x_2,...,x_n)=F(x_1)F(x_2)...F(x_n)\)</span></p></li>
<li><p>Joint density function (if exists)：<span class="math inline">\(f(x_1,x_2,...,x_n)=f(x_1)f(x_2)...f(x_n)\)</span></p></li>
</ul></li>
</ul>
<h2 id="统计量">统计量</h2>
<ul>
<li><p>定义了这么多东西之后，我们可以研究抽取出来的随机样本 <span class="math inline">\(X_1,X_2,...,X_n\)</span>，研究方式是定义一些关于这些随机样本的函数，研究函数的性质。</p>
<ul>
<li><p>Statistic（统计量）：记抽取得到的随机样本 / 数据为 <span class="math inline">\(X_1,X_2,...,X_n\)</span>，函数 <span class="math inline">\(T(X_1,...,X_n)\)</span>
称为一个统计量。显然，在抽取之前它是一个随机变量的函数，也即一个随机向量；但在抽取之后，<span class="math inline">\(T\)</span> 可以计算为一个实数。</p>
<p>作为随机变量，<span class="math inline">\(T\)</span> 的概率分布称为
Sampling Distribution，抽样分布。</p></li>
<li><p>亿些常用的 Statistic：</p>
<p>Sample mean：<span class="math inline">\(X = \frac{1}{n}
\Sigma_{i=1}^n X_i\)</span></p>
<p>Sample variance：<span class="math inline">\(S^2 = \frac{1}{n-1}
\Sigma_{i=1}^{n} (X_i-X) ^2\)</span></p>
<p>Sample standard deviation：<span class="math inline">\(S\)</span></p>
<p>K-th origin moment（k 阶矩）：<span class="math inline">\(a_{n,k} =
\frac{1}{n} \Sigma _{i=1} ^{n} X_i ^k, k =1,2,...\)</span></p>
<p>K-th center moment（k 阶中心矩）：<span class="math inline">\(m_{n,k}
= \frac{1}{n} \Sigma _{i=1} ^{n} (X_i-X) ^k, k =2,3,...\)</span></p>
<p>Order statistic（次序统计量）：排列所有的样本为 <span class="math inline">\(X_ {(1)} \leq X_ {(2)} \leq ... \leq
X_{(n)}\)</span>，则 <span class="math inline">\((X _{(1)}, X
_{(2)},...,X _{(n)})\)</span> 是次序统计量。</p>
<p>Sample medium（中位数）：<span class="math inline">\(m_{\frac{1}{2}}=X_{n/2}\)</span> 或者 <span class="math inline">\(\frac{1}{2} (X _{n/2}+X _{n/2+1})\)</span></p>
<p>Extremum of sample：<span class="math inline">\(X _{(1)},X
_{(n)}\)</span></p>
<p>Sample p-fractile（<span class="math inline">\(0&lt;p&lt;1\)</span>）：<span class="math inline">\(m_p = X_{(m)}\)</span>，其中 <span class="math inline">\(m=[(n+1)p]\)</span></p>
<p>Sample range（极差）：<span class="math inline">\(R=X _{(n)}-X
_{(1)}\)</span></p>
<p>Sample coefficient of variation（样本变异系数）：<span class="math inline">\(v=\frac{S}{X}\)</span></p>
<p>Sample skewness（样本偏度），Sample kurtosis（样本峰度）自查：</p>
<p><img src="https://s2.loli.net/2022/11/10/KgwxjsHpdqVCP8Q.png" alt="uwu"></p>
<p>Empirical distribution function（经验分布函数）：</p>
<p><span class="math inline">\(I_A(x)=1 \\; for \\; x \in A, otherwise
\\;0\)</span></p>
<p><span class="math inline">\(F_n(x)=\frac{1}{n}[number\\; of\\;
X_1,X_2,...,X_n \leq x]\)</span></p>
<p>对于二阶随机向量：</p>
<p><span class="math inline">\(S_{XY}=\frac{1}{n} \Sigma _{i=1} ^{n}
(X_i-X)(Y_i-Y)\)</span></p>
<p><span class="math inline">\(S_X,S_Y,X,Y\)</span>
各自同上定义。</p></li>
</ul></li>
</ul>
<h2 id="经典分布查阅">经典分布查阅</h2>
<h3 id="卡方分布">卡方分布</h3>
<p><img src="https://s2.loli.net/2022/11/10/96cXDZjMATdz1ns.png" alt="1.png"></p>
<p><img src="https://s2.loli.net/2022/11/10/kUnosgDvltpVGCx.png" alt="2.png"></p>
<p><img src="https://s2.loli.net/2022/11/10/XlfzMd3LVN6xBvn.png" alt="3.png"></p>
<h3 id="t-分布"><span class="math inline">\(t-\)</span>分布</h3>
<p><img src="https://s2.loli.net/2022/11/10/5C1DIs7VA8rRpvG.png" alt="4.png"></p>
<p><img src="https://s2.loli.net/2022/11/10/isu5VE8UmqGRDQc.png" alt="5.png"></p>
<p><img src="https://s2.loli.net/2022/11/10/WrPwDSbvtNxVTO7.png" alt="6.png"></p>
<h3 id="f-分布"><span class="math inline">\(F\)</span> 分布</h3>
<p><img src="https://s2.loli.net/2022/11/10/39KfRQ1cnBpDbM4.png" alt="7.png"></p>
<p><img src="https://s2.loli.net/2022/11/10/ipCfAIzGNYbrREK.png" alt="8.png"></p>
<p><img src="https://s2.loli.net/2022/11/10/XuYVFkrIE14ZpO8.png" alt="9.png"></p>
<h1 id="lecture-2">Lecture 2</h1>
<p>本节仍然是介绍统计学的基础内容，讨论了一些 Statistic
的性质，并介绍了分布族。</p>
<p>我偷懒，定理和证明就直接拍手写了，自认为自己的字还没那么不堪入目。另外每个学期都会有找不到的笔记，还是存电子版吧（</p>
<h2 id="统计量及其性质">统计量及其性质</h2>
<p>Lecture 1 中介绍了 114514 个常用的
Statistic，我们对其中一些讨论它们的 sample distribution 的性质。</p>
<h3 id="特殊统计量">特殊统计量</h3>
<ul>
<li><p>Sample mean：因为它的形式是 <span class="math inline">\(nX =
X_1+X_2+...+X_n\)</span>，且 <span class="math inline">\(X_i\)</span>
互相之间 i.i.d.，我们可以用概率母函数 / 矩母函数来处理得到 <span class="math inline">\(nX\)</span> 的分布。</p>
<p>如果只是求近似而不是准确的分布，可以使用 Central Limit Theorem
进行估计，但要注意，只有 <span class="math inline">\(X_i\)</span>
的方差有限的情况才能使用 CLT。</p></li>
<li><p>Linear transformation：形为 <span class="math inline">\(Y=\frac{X}{n}\)</span>，于是我们可以用 <span class="math inline">\(CDF\)</span> 转 <span class="math inline">\(PDF/PMF\)</span> 的方式计算它的 <span class="math inline">\(PDF/PMF\)</span>，直接给出结论：<span class="math inline">\(f_Y(y)=nf_X(ny)\)</span>。</p></li>
</ul>
<h3 id="经典结论">经典结论</h3>
<ul>
<li><p>Theorem 1：</p>
<p><img src="https://s2.loli.net/2022/11/14/XEcfOiPsK397zq6.png" alt="1.png"></p></li>
<li><p>Theorem 2：</p>
<p><img src="https://s2.loli.net/2022/11/14/48m1hsC5ozDNXyf.png" alt="2.png"></p>
<p>这个第二问的证明，要用一下 <span class="math inline">\(cov(X_1,X_2)=0\)</span>，权当留个提示。因为我第一遍没证出来。</p></li>
<li><p>Theorem 3：</p>
<p><img src="https://s2.loli.net/2022/11/14/R3xeGq69dJlwfoh.png" alt="3.png"></p>
<p>因为 <span class="math inline">\(\bar{X}\)</span> 的期望和 <span class="math inline">\(X_1\)</span> 的期望相同，<span class="math inline">\(S\)</span> 的期望和 <span class="math inline">\(X_1\)</span> 的方差相同，因此二者是 unbiased
statistic（无偏统计量）</p></li>
</ul>
<h3 id="正态分布的随机抽样">正态分布的随机抽样</h3>
<ul>
<li><p>Theorem
1：考虑独立不同分布的正态分布的线性组合，它的方差和期望也是一个线性组合。一般这种类似于
<span class="math inline">\(X_1+X_2+...+X_n\)</span>
的都可以用矩母函数证明。</p>
<p><img src="https://s2.loli.net/2022/11/14/2Hiut73Ns8YZE9x.png" alt="4.png"></p></li>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/11/14/EtzhJnWQaGgdk58.png" alt="5.png"></p>
<p><span class="math inline">\(X,Y\)</span>
是两个方差和期望都已知的正态分布，要求 <span class="math inline">\(P(X&gt;Y)=P(X-Y&gt;0)\)</span>，而 <span class="math inline">\(X-Y\)</span>
是正态分布的线性组合，也是参数已知的正态分布，将其标准化即可。</p></li>
<li><p>Theorem 2：考虑一组由正态分布随机抽样生成的
statistics，用矩阵形式表示：</p>
<p><img src="https://s2.loli.net/2022/11/14/Iti1jAKc74QRWbz.jpg" alt="2.jpg"></p>
<p>可以看到矩阵是正交矩阵时有很好的性质。固定正交矩阵的第一行之后，我们可以对此时的
<span class="math inline">\(\bar{X}\)</span> 和 <span class="math inline">\(S^2\)</span> 进行讨论：</p>
<p>Theorem 3：<span class="math inline">\(\bar{X}\)</span> 和 <span class="math inline">\(S^2\)</span> 是独立的，且由 <span class="math inline">\(S^2\)</span> 可以生成一个 Chi-Square 分布。</p>
<p><img src="https://s2.loli.net/2022/11/14/9sgt8DElTq4rPHA.jpg" alt="1.jpg"></p></li>
</ul>
<h2 id="指数分布族">指数分布族</h2>
<h3 id="概念">概念</h3>
<ul>
<li><p>简单来说，一个分布的 PDF / PMF 可以表示为 <span class="math inline">\(f(x; \theta) = c(\theta)h(x) exp[\Sigma_{j=1} ^{n}
w_j(\theta) t_j(x)]\)</span> 的形式，则无论随机取多少个独立同分布的
sample，它们的联合分布也可以保持这个形式，则称该 population
属于指数分布族。</p>
<p>其中的 <span class="math inline">\(\theta\)</span>
表示该分布的参数，可以表示为 <span class="math inline">\(\theta =
(\theta_1,\theta_2,...,\theta_k)\)</span></p>
<p>比如正态分布，Poisson 分布都属于指数分布族：</p>
<p><span class="math inline">\(f(x_1,x_2,...,x_n;\theta) = (\sqrt{2\pi}
\sigma)^{-n} exp(-\frac{1}{2\sigma ^2} \Sigma_{i=1} ^{n}
(x_i-\mu)^2)\)</span> 为正态分布的 Joint PDF；</p>
<p><span class="math inline">\(f(x_1,x_2,...,x_n;\theta) = e^{-n\theta}
(\Pi_{i=1} ^{n} \frac{1}{x_i !}) exp(ln\theta (x_1 + x_2 +...+
x_n))\)</span> 为泊松分布的 Joint PMF。</p>
<p>实际上，连续的指数分布族还有 Gamma，Beta
分布族，离散的指数分布族还有二项和负二项分布族。</p></li>
</ul>
<h3 id="自然指数分布族">自然指数分布族</h3>
<ul>
<li><p>自然指数分布族和举例：</p>
<p><img src="https://s2.loli.net/2022/11/15/rPZ4zcwh1BmeDsK.jpg" alt="E37A9170F0484981CC47B22C9F88227F.jpg"></p></li>
</ul>
<h3 id="位置与尺度族">位置与尺度族</h3>
<ul>
<li><p>位置与尺度族：直观来说，位置族的形状完全一样，但位置上有偏移，例如若干个期望不同而方差相同的正态分布；尺度族的位置相同，形状上有伸缩变化，例如若干个期望相同但方差不同的正态分布。</p></li>
<li><p>位置族：取一个标准概率密度函数（standard PDF）<span class="math inline">\(f(x)\)</span>，位置族中的其他函数 <span class="math inline">\(f(x-\mu)\)</span> 相对于这个标准函数的偏差记为
<span class="math inline">\(\mu\)</span>，称为 location
parameter（位置参数）.</p>
<p><img src="https://s2.loli.net/2022/11/15/Svc39OEw5YKbatr.png" alt="1 2.png"></p></li>
<li><p>尺度族：取一个标准概率密度函数（standard PDF）<span class="math inline">\(f(x)\)</span>，尺度族中的其他函数 <span class="math inline">\(\frac{1}{\sigma} f(\frac{x}{\sigma})\)</span>
相对于这个标准函数的偏差记为 <span class="math inline">\(\sigma\)</span>，称为 scale
parameter（尺度参数）.</p>
<p><img src="https://s2.loli.net/2022/11/15/CEtRPFrbusQZOlL.png" alt="2.png"></p></li>
<li><p>位置-尺度族：取一个标准概率密度函数（standard PDF）<span class="math inline">\(f(x)\)</span>，位置-尺度族中的其他随机变量 <span class="math inline">\(X\)</span> 有 PDF 为 <span class="math inline">\(\frac{1}{\sigma} f(\frac{x-\mu}{\sigma})\)</span>
，当且仅当存在以 <span class="math inline">\(f(z)\)</span> 为 PDF
的随机变量 <span class="math inline">\(Z\)</span>，从而有 <span class="math inline">\(X=\sigma Z+\mu\)</span>。</p>
<p>这一定理可以用 CDF 法证明。</p></li>
<li><p>例子：<span class="math inline">\(Z\sim N(\mu,\sigma
^2)\)</span>，且 $X=aZ+b $，于是 <span class="math inline">\(X\sim
N(a\mu +b,a^2 \sigma ^2 )\)</span>，相对于 standard distribution <span class="math inline">\(Y\sim N(0,1)\)</span>，location parameter 为 <span class="math inline">\(a\mu +b\)</span>，scale parameter 为 <span class="math inline">\(a\sigma\)</span>。</p></li>
</ul>
<h2 id="delta-method-application-only">Delta Method (Application
Only)</h2>
<p>就两个定理，也没证明。用于已知参数的分布 <span class="math inline">\(X\)</span> 的函数 <span class="math inline">\(g(X)\)</span>，对其进行近似。第一个定理针对 <span class="math inline">\(g&#39;(\mu) \neq 0\)</span>，第二个定理针对 <span class="math inline">\(g&#39;(\mu)=0\)</span> 的情况进行进一步近似。</p>
<p><img src="https://s2.loli.net/2022/11/15/DjVouFIUKhBtzk5.png" alt="d.png"></p>
<h2 id="其他定理查阅">其他定理查阅</h2>
<h3 id="大数定律">大数定律</h3>
<p><img src="https://s2.loli.net/2022/11/15/Vl6NgIHcZrKoFQ9.png" alt="w.png"></p>
<p><img src="https://s2.loli.net/2022/11/15/wJh6iVCW73djxNm.png" alt="x.png"></p>
<h3 id="中心极限定理">中心极限定理</h3>
<p><img src="https://s2.loli.net/2022/11/15/boNDnERSgxV5Cim.png" alt="y.png"></p>
<h3 id="slutskys-theorem">Slutsky's Theorem</h3>
<p><img src="https://s2.loli.net/2022/11/15/YQFvCIO8Wptlbig.png" alt="z.png"></p>
<h1 id="homework-1">Homework 1</h1>
<p><img src="https://s2.loli.net/2022/11/29/jIyFs5JalDzrpVP.png" alt="41.png"></p>
<p><img src="https://s2.loli.net/2022/11/29/ax2whdeIVbl58Cz.jpg" alt="42.jpg"></p>
<h1 id="lecture-3">Lecture 3</h1>
<p>本节介绍数据简化原理，仍然围绕 Statistic 的选取展开。</p>
<blockquote>
<p>Data don't make any sense, we will have to resort to statistics.</p>
</blockquote>
<p>然而，每一个 statistic
的使用都不可避免地会遗失数据的细节。这些细节有时是没有用的，statistic
反而保留了最有用的部分（例如
parameter）；有的时候是有用的，根据数据处理的目的，有可能需要重新选择
statistic。</p>
<h2 id="充分统计量">充分统计量</h2>
<h3 id="定义和应用">定义和应用</h3>
<ul>
<li><p>Sufficient statistics：<span class="math inline">\(T(x)\)</span>
是一个充分统计量当且仅当样本 <span class="math inline">\(X\)</span> 在
<span class="math inline">\(T(X)\)</span> 条件下的分布与 <span class="math inline">\(\theta\)</span> 无关。</p>
<p>写作数学语言：<span class="math inline">\(P_\theta(X=x | T(X)=T(x)) =
\frac{P_\theta (X=x)}{P_\theta(T(X)=T(x))} =
\frac{p(x;\theta)}{q(T(x);\theta)}\)</span> 与参数 <span class="math inline">\(\theta\)</span> 无关。于是，验证一个 statistic
<span class="math inline">\(T(x)\)</span> 最直接的方法就是计算 <span class="math inline">\(x\)</span> 的联合分布的概率密度，以及 <span class="math inline">\(T(x)\)</span> 的概率密度，对二者求比值。</p></li>
<li><p>对一些特殊的分布，我们来寻找它们的充分统计量。</p>
<ul>
<li><p>Bernoulli sufficient statistic：<span class="math inline">\(X_1,X_2,...,X_n i.i.d\sim B(1,\theta)\)</span>，则
<span class="math inline">\(T(X)=X_1+...+X_n\)</span> 是 <span class="math inline">\(\theta\)</span> 的充分统计量，可以通过 <span class="math inline">\(T(X)\sim B(n,\theta)\)</span> 来验算。</p></li>
<li><p>Normal sufficient statistic：<span class="math inline">\(X_1,X_2,...,X_n i.i.d\sim
N(\mu,\sigma^2)\)</span>，则 <span class="math inline">\(T(X)=\bar{X}\)</span> 是 <span class="math inline">\(\mu\)</span> 的充分统计量（注意不是 <span class="math inline">\(\sigma\)</span> 的充分统计量），可以通过 <span class="math inline">\(T(X)\sim N(\mu,\frac{\sigma^2}{n})\)</span>
验算。</p></li>
<li><p>Sufficient order statistic：<span class="math inline">\(X_1,X_2,...,X_n i.i.d\)</span>，population 的 PDF
是 <span class="math inline">\(f(x)\)</span>，于是全体次序统计量 <span class="math inline">\(X_{(1)},...,X_{(n)}\)</span> 是充分统计量，因为
<span class="math inline">\(P(X_1=x_1,...,X_n=x_n |
X_{(1)}=x_{(1)},...,X_{(n)}=x_{(n)}) = \frac{1}{n!}\)</span></p>
<p>Remark：这提示我们，次序统计量可以是多维的。</p></li>
</ul></li>
<li><p>显然，这样寻找充分统计量是不现实的。以下有因子分解定理帮助我们寻找合适的
<span class="math inline">\(T(x)\)</span>：</p>
<p>Factorization theorem：设 $f(x;) $ 是 sample X
的联合概率密度函数，统计量 <span class="math inline">\(T(x)\)</span> 是
sufficient statistic 当且仅当存在函数 <span class="math inline">\(g(t;\theta)\)</span> 和 <span class="math inline">\(h(x)\)</span>，满足 <span class="math inline">\(f(x;\theta)=g(T(x);\theta)h(x)\)</span>。</p>
<p>对离散条件的 Factorization theorem 进行证明：</p>
<p>左推右，trivial。右推左：</p>
<p><img src="https://s2.loli.net/2022/11/20/C49PtevUWc5jHVw.jpg" alt="3.jpg"></p></li>
<li><p>因此，由 Factorization theorem 可以知道，把 Joint PDF 里面 <span class="math inline">\(\theta,\bar{x}\)</span> 不可分离的部分，以及 <span class="math inline">\(\theta\)</span>
单独的部分取出放在一起，就可以从中找出 sufficient statistic。</p></li>
<li><p>应用数理统计的概率写法，求充分统计量</p>
<ul>
<li><p>Uniform sufficient statistic：<span class="math inline">\(X_1,X_2,...,X_n i.i.d\sim
Unif(\theta_1,\theta_2)\)</span>，寻找关于 <span class="math inline">\(\theta_1,\theta_2\)</span> 的充分统计量。</p>
<p>事实上，Joint PDF 可以写成 <span class="math inline">\(f(x_1,x_2,...,x_n)=(\frac{1}{\theta_2-\theta_1})^nI_{\lbrace\theta_1
\leq x_1,x_2,...,x_n \leq \theta_2\rbrace}\)</span>，也即</p>
<p><span class="math inline">\(f(x_1,x_2,...,x_n)=(\frac{1}{\theta_2-\theta_1})^nI_{\theta_1
\leq x_{(1)}}I_{x_{(n)} \leq \theta_2}\)</span>，于是 sufficient
statistic 是 <span class="math inline">\(x_{(1)},x_{(2)}\)</span>。</p></li>
<li><p>Exponential sufficient statistic：<span class="math inline">\(X_1,X_2,...,X_n i.i.d\sim
exp(\lambda)\)</span>，寻找关于 <span class="math inline">\(\lambda\)</span> 的充分统计量。</p>
<p>事实上，Joint PDF 是 <span class="math inline">\(f(\bar{x};\lambda)=\lambda^n
e^{-\lambda(x_1+...+x_n)}=\lambda^ne^{-\lambda t}
h(\bar{x})=g(t;\lambda)h(\bar{x})\)</span>，于是有 <span class="math inline">\(T(\bar{X})=X_1+X_2+...+X_n\)</span> 是 sufficient
statistic，而 <span class="math inline">\(h(\bar{x})=I_{x_i&gt;0,i=1,2,...,n}\)</span>。</p></li>
<li><p>还有很多例子，懒得举了</p></li>
</ul></li>
<li><p>Exponential family 的 PDF 有比较好的性质： <span class="math inline">\(f(x; \theta) = c(\theta)h(x) exp[\Sigma_{j=1} ^{n}
w_j(\theta) t_j(x)]\)</span></p>
<p>于是 Joint PDF 可以写为 <span class="math inline">\(f(\bar{x};
\theta) = c(\theta)^m \Pi_{i=1}^m h(x_i) exp[\Sigma_{j=1} ^{n}
\Sigma_{i=1} ^m w_j(\theta)
t_j(x_i)]\)</span>，因此这一样本的充分统计量是 <span class="math inline">\((\Sigma_{j=1}^m t_1(X_j),...,\Sigma_{j=1}^m
t_n(X_j))\)</span>。</p></li>
</ul>
<h3 id="充分统计量的性质">充分统计量的性质</h3>
<ul>
<li><span class="math inline">\(T\)</span> 是参数 <span class="math inline">\(\theta\)</span> 的充分统计量，且 <span class="math inline">\(T=\phi(S)\)</span>，则 <span class="math inline">\(S\)</span> 也是充分统计量。
<ul>
<li>如果 <span class="math inline">\(\phi\)</span>
是一一对应，二者的信息量相同。</li>
<li>如果 <span class="math inline">\(\phi\)</span> 不是一一对应，则
<span class="math inline">\(T\)</span> 是 <span class="math inline">\(S\)</span>
的一个精简而且还是充分统计量，是更有用的。</li>
</ul>
<img src="https://s2.loli.net/2022/11/20/obLXT61Kcunx5Mi.png" alt="1.png"></li>
<li>Examples（懒得抄了）：</li>
</ul>
<p><img src="https://s2.loli.net/2022/11/20/sitSDJEMO2VupG5.png" alt="2.png"></p>
<h3 id="极小充分统计量">极小充分统计量</h3>
<ul>
<li><p>sufficient statistic <span class="math inline">\(T^*(X)\)</span>
被称为 minimal sufficient statistic 当且仅当：对任意充分统计量 <span class="math inline">\(T(X)\)</span>，存在函数 <span class="math inline">\(\psi\)</span> 使得 <span class="math inline">\(T^*(X)=\psi(T(X))\)</span>。也就是说，<span class="math inline">\(T^*(X)\)</span> 实现了数据的最大简化。minimal
sufficient statistic 的维度是最小的，它不一定唯一。</p>
<ul>
<li>判定定理：<span class="math inline">\(f(x;\theta)\)</span> 是 <span class="math inline">\(X\)</span> 的 PDF，则对两个样本点 <span class="math inline">\(x\)</span> 和 <span class="math inline">\(y\)</span>，<span class="math inline">\(f(x;\theta)/f(y;\theta)\)</span> 是 <span class="math inline">\(\theta\)</span> 的常函数当且仅当 <span class="math inline">\(T(x)=T(y)\)</span>，那么 <span class="math inline">\(T(X)\)</span> 是 <span class="math inline">\(\theta\)</span> 的 minimal sufficient
statistic。证明如下：</li>
</ul>
<p><img src="https://s2.loli.net/2022/11/20/r24pTEG7dnRPHIw.jpg" alt="4.jpg"></p></li>
<li><p>举一些例子。</p>
<ul>
<li><p>Normal minimal sufficient statistic：<span class="math inline">\(X_1,X_2,...,X_n i.i.d\sim
N(\mu,\sigma^2)\)</span>，则 <span class="math inline">\((\bar{X},S^2)\)</span> 是 <span class="math inline">\((\mu,\sigma^2)\)</span>
的极小充分统计量。</p></li>
<li><p>Uniform minimal sufficient statistic：<span class="math inline">\(X_1,X_2,...,X_n i.i.d\sim Unif(\theta,\theta
+1)\)</span>，则 <span class="math inline">\((X_{(1)},X_{(2)})\)</span>
是 $$ 的极小充分统计量。</p></li>
<li><p>分别验证如下：</p>
<p><img src="https://s2.loli.net/2022/11/20/xUtclLFqdfzhI3E.jpg" alt="5.jpg"></p></li>
</ul></li>
</ul>
<h2 id="辅助统计量">辅助统计量</h2>
<h3 id="定义">定义</h3>
<ul>
<li><p><span class="math inline">\(S(X)\)</span> 是 ancillary statistic
当且仅当它的分布是 <span class="math inline">\(\theta\)</span>
的常函数。比如说，常数就是一个 trivial ancillary statistic。</p></li>
<li><p><span class="math inline">\(S(X)\)</span> 是一阶 ancillary
statistic，当 <span class="math inline">\(E(S(X))\)</span> 也是 <span class="math inline">\(\theta\)</span> 的常函数时。</p></li>
<li><p>举一些例子：</p>
<ul>
<li><p>Uniform ancillary statistic：<span class="math inline">\(X_1,X_2,...,X_n i.i.d\sim
Unif(\theta,\theta+1)\)</span>，则 <span class="math inline">\(X_{(n)}-X_{(1)}\)</span>
是辅助统计量。验证如下：</p></li>
<li><p>Location ancillary statistic：<span class="math inline">\(Z_1,Z_2,...,Z_n\)</span> 是服从 <span class="math inline">\(F(x)\)</span> 的 Population 中的样本，位置参数为
<span class="math inline">\(\theta\)</span>，于是 <span class="math inline">\(X_1=Z_1+\theta,...,X_n=Z_n+\theta\)</span>，故
<span class="math inline">\(r=X_{(n)}-X_{(1)}\)</span> 是 ancillary
statistic，因为</p>
<p>$F(r;)=P(Rr;)=P(maxX_i-minX_i r)=P(max Z_i-minZ_i
r)=P(Z_{(n)}-Z_{(1)}r) $</p>
<p>这是和 <span class="math inline">\(\theta\)</span>
无关的量。所以，location ancillary statistic 还可以是 <span class="math inline">\(X_{(n-1)}-X_{(3)}\)</span>，等等。</p></li>
<li><p>Scale ancillary statistic：同理，<span class="math inline">\(X_i/X_j\)</span> 都是 ancillary
statistic，因为可以归一为 <span class="math inline">\(Z_i/Z_j\)</span>。由统计量的函数性质可知，<span class="math inline">\(\frac{X_1+...+X_n}{X_i}\)</span> 是形式比较好的
ancillary statistic。</p></li>
</ul></li>
</ul>
<h3 id="辅助统计量的性质">辅助统计量的性质</h3>
<ul>
<li><span class="math inline">\(V(X)\)</span> 是 nontrivial ancillary
statistic，于是 <span class="math inline">\(\lbrace
x:V(x)=v\rbrace\)</span> 不包含任何 <span class="math inline">\(\theta\)</span> 的信息。</li>
<li><span class="math inline">\(T(X)\)</span> 是 statistic，如果 <span class="math inline">\(V(T(X))\)</span> 是 nontrivial ancillary
statistic，那么 <span class="math inline">\(T\)</span>
的简化中仍然不含有 <span class="math inline">\(\theta\)</span>，需要进一步进行简化。</li>
<li>如果一个 sufficient statistic <span class="math inline">\(T(X)\)</span> 没有非常值函数是 ancillary
statistic，那么它在简化数据中是最优的。</li>
</ul>
<h2 id="完全统计量">完全统计量</h2>
<h3 id="定义-1">定义</h3>
<ul>
<li><p><span class="math inline">\(X\sim F=\lbrace f(x;\theta),\theta
\in \Theta \rbrace\)</span> 是一个分布族，<span class="math inline">\(\Theta\)</span> 是参数空间。记 <span class="math inline">\(T=T(X)\)</span>，如果对于任意函数 <span class="math inline">\(\psi\)</span>，如果 <span class="math inline">\(E_\theta \psi(T(X))=0,\forall \theta \in
\Theta\)</span>，那么一定有 <span class="math inline">\(P_\theta(\psi(T(X))=0)=1,\forall \theta \in
\Theta\)</span>。</p></li>
<li><p>听起来很抽象，举几个例子：</p>
<ul>
<li><p><span class="math inline">\(X=(X_1,X_2,...,X_n)\)</span> 是来自于
<span class="math inline">\(B(1,\theta)\)</span> 的随机样本，那么 <span class="math inline">\(T(X)=\Sigma_{i=1} ^n X_i\)</span> 对于参数 <span class="math inline">\(\theta\)</span> 是一个 complete
statistic。验证如下：</p>
<p><img src="https://s2.loli.net/2022/11/20/4aC1ihZlAcNI2kR.jpg" alt="6.jpg"></p></li>
<li><p><span class="math inline">\(X=(X_1,X_2,...,X_n)\)</span> 是来自于
<span class="math inline">\(Unif(0,\theta)\)</span> 的随机样本，那么
<span class="math inline">\(T(X)=X_{(n)}\)</span> 对于参数 <span class="math inline">\(\theta\)</span> 是一个 complete
statistic。验证如下：</p>
<p><img src="https://s2.loli.net/2022/11/20/vuzCQqMW6fTLbxg.jpg" alt="7.jpg"></p></li>
</ul></li>
<li><p>complete statistic 不一定存在。</p></li>
</ul>
<h3 id="指数族中的完全统计量">指数族中的完全统计量</h3>
<ul>
<li><p>指数分布族的 PDF 有形式： <span class="math inline">\(f(x;
\theta) = c(\theta)h(x) exp[\Sigma_{j=1} ^{n} w_j(\theta)
t_j(x)]\)</span></p>
<p>于是如果参数空间 <span class="math inline">\(\Theta\)</span> 包括
<span class="math inline">\(R^k\)</span> 的开集，则统计量 <span class="math inline">\(T(X)=(\Sigma_{i=1} ^m t_1(X_i),...,\Sigma_{i=1} ^m
t_n(X_i))\)</span> 是一个 complete statistic。</p></li>
<li><p>Remark：定理中要求开集是为了防止一些特殊情况，比如：</p></li>
</ul>
<h3 id="完全统计量的性质">完全统计量的性质</h3>
<ul>
<li><p>如果 minimal sufficient statistic 存在，那么任何 complete
statistic 都是 minimal sufficient 的。</p></li>
<li><p>Basu Theorem：如果 <span class="math inline">\(T(X)\)</span> 是
(minimal) complete &amp; sufficient statistic，那么它和任何 ancillary
statistic 独立。这是一个很好的性质，因为直观上来看 ancillary statistic
是和任何 sufficient statistic
独立的而现实并非如此，而这个定理可以给出一个补充条件。</p></li>
<li><p>Basu Theorem 的应用：</p>
<ul>
<li><p>设 <span class="math inline">\(X_1,...,X_n i.i.d\sim
U(\theta_1,\theta_2)\)</span>，证明 <span class="math inline">\(\frac{X_{(i)} - X_{(1)}}{X_{(n)}-X_{(1)}}\)</span>
与 <span class="math inline">\((X_{(n)},X_{(1)})\)</span> 独立。</p>
<p><span class="math inline">\(X_{(n)}\)</span> 是 complete
statistic，<span class="math inline">\((X_{(n)},X_{(1)})\)</span> 是
minimal sufficient statistic，于是也是 minimal complete &amp; sufficient
statistic，只要证明 <span class="math inline">\(\frac{X_{(i)} -
X_{(1)}}{X_{(n)}-X_{(1)}}\)</span> 是 ancillary statistic 即可。</p>
<p>而这是一个位置-尺度分布族，需要先正规化为 <span class="math inline">\(Y_i =
\frac{X_i-\theta_1}{\theta_2-\theta_1}\)</span>，则有 <span class="math inline">\(Y_1,Y_2,...,Y_n i.i.d.\sim U(0,1)\)</span>，于是
<span class="math inline">\(\frac{X_{(i)} -
X_{(1)}}{X_{(n)}-X_{(1)}}=\frac{Y_{(i)}-Y_{(1)}}{Y_{(n)}-Y_{(1)}}\)</span>，从而是
<span class="math inline">\(\theta\)</span> 的常函数，为 ancillary
statistic。</p></li>
<li><p>设 <span class="math inline">\(X_1,...,X_n i.i.d\sim
N(\mu,\sigma^2)\)</span>，证明 <span class="math inline">\(\bar{X}\)</span> 和 <span class="math inline">\(S^2\)</span> 是独立的。</p>
<p>实际上，这个问题在 Lecture 2 中我们使用正交矩阵证明过，此处再给出一个
Basu Theorem 下的证明。事实上，我们已经知道对于已知的 <span class="math inline">\(\sigma^2\)</span>，有 <span class="math inline">\(\bar{X}\)</span> 是 complete &amp; sufficient，而
<span class="math inline">\(S^2\)</span> 是
ancillary，所以二者独立。</p></li>
</ul></li>
</ul>
<h2 id="似然原理">似然原理</h2>
<ul>
<li><p>如果 <span class="math inline">\(f(x;\theta)\)</span> 是样本
<span class="math inline">\(X=(X_1,X_2,...,X_n)\)</span> 的 Joint
PDF，则记 <span class="math inline">\(\theta\)</span> 的函数 <span class="math inline">\(L(\theta;x)=f(x;\theta)\)</span>
为似然函数（Likelihood Function），有时也写作 <span class="math inline">\(L(\theta)\)</span> 以突出变量。</p>
<p>Log Likelihood：<span class="math inline">\(l(\theta;x)=log
L(\theta;x)\)</span>。</p></li>
<li><p>Likelihood Principle：</p>
<ul>
<li>用参数族 <span class="math inline">\(\Theta\)</span> 中的不同参数
<span class="math inline">\(\theta_1,\theta_2\)</span> 进行比较 <span class="math inline">\(L(\theta_1;x)&gt;L(\theta_2;x)\)</span>，那么
<span class="math inline">\(\theta_1\)</span> 比起 <span class="math inline">\(\theta_2\)</span>
是一个更好的真实值的选择。从而可以在参数未知的情况下，对真实的 <span class="math inline">\(\theta\)</span> 进行推断。</li>
<li>样本点 <span class="math inline">\(x,y\)</span> 满足 <span class="math inline">\(L(\theta;x)\)</span> 和 <span class="math inline">\(L(\theta;y)\)</span> 之间成比例，即存在 <span class="math inline">\(L(\theta;x)=C(x,y)L(\theta;y)\)</span>，那么从
<span class="math inline">\(x,y\)</span> 出发对 <span class="math inline">\(\theta\)</span>
做如上推断，得到的结果是相同的。</li>
</ul></li>
<li><p>Equivalence Principe：如果 <span class="math inline">\(Y=g(X)\)</span> 是一个度量尺度变换，且 <span class="math inline">\(Y\)</span> 的模型和 <span class="math inline">\(X\)</span>
的模型具有相同的形式结构，则推断方法应同时满足度量同变和形式不变。</p></li>
</ul>
<h1 id="lecture-4">Lecture 4</h1>
<p>本节介绍 Fisher Information 和 Point Estimation。</p>
<h2 id="fisher-information">Fisher Information</h2>
<h3 id="定义-2">定义</h3>
<ul>
<li><p>取 <span class="math inline">\(f(x;\theta),\theta \in
\Theta\)</span> 作为一个分布族，则 score function 定义为 <span class="math inline">\(S(x;\theta)=\frac{\partial log L(\theta)}{\partial
\theta}=\frac{1}{f(x;\theta)} \frac{\partial f(x;\theta)}{\partial
\theta}\)</span>。</p>
<p>对于一个给定的 <span class="math inline">\(\theta\)</span>，可知
<span class="math inline">\(E[S(X,\theta)]=0,E[S(X,\theta)]^2=I(\theta)\)</span>，后者就是
Fisher Information。</p>
<p>因此，<span class="math inline">\(Var[S(X;\theta)]=E[S(X;\theta)]^2-
E^2[S((X;\theta))]=I(\theta)\)</span></p>
<p>对于一个 score function 有较大方差的分布，我们希望能够较为容易地估计
<span class="math inline">\(\theta\)</span>。</p></li>
<li><p><span class="math inline">\(I(\theta) = E[S(X;\theta)]^2 =
-E(\frac{\partial^2}{\partial \theta^2} logL(\theta))\)</span></p></li>
</ul>
<h3 id="与熵的关系">与熵的关系</h3>
<ul>
<li><p>relative entropy：<span class="math inline">\(KL(p:q)=\int
p(x)log \frac{p(x)}{q(x)} dx\)</span>，</p>
<p>定义：</p>
<p><span class="math inline">\(D(\theta,\theta + \Delta
\theta)=KL(f(x;\theta):f(x,\theta+\Delta \theta)) = -\int
f(x;\theta)[log f(x,\theta + \Delta \theta)-log f(x;\theta)]
dx\)</span></p>
<p>经过 Taylor 展开：</p>
<p><span class="math inline">\(log f(x,\theta + \Delta \theta)-log
f(x,\theta) = \frac{\partial log f(x,\theta)}{\partial \theta} \Delta
\theta + \frac{1}{2} \Delta \theta^\prime \frac{\partial^2 log
f(x,\theta)}{\partial \theta^\prime \partial \theta} \Delta \theta +
o(||\Delta \theta||^2)\)</span></p>
<p>于是：</p>
<p><span class="math inline">\(D(\theta,\theta+\Delta \theta) =
-E[\frac{\partial log f(x,\theta)}{\partial \theta}]\Delta \theta -
\frac{1}{2} \Delta \theta^\prime E[\frac{\partial^2 log
f(x,\theta)}{\partial \theta^\prime \partial \theta} ]\Delta \theta +
o(||\Delta \theta||^2) = -\frac{1}{2}\Delta \theta^\prime I(\theta)
\Delta \theta\)</span></p>
<p>Remark： Fisher Information 越大，越能够区分参数。</p></li>
</ul>
<h3 id="充分统计量和辅助统计量">充分统计量和辅助统计量</h3>
<p>不是很懂。贴个图吧。</p>
<p><img src="https://s2.loli.net/2022/11/20/bO8F4ynqUBN6ExL.png" alt="8.png"></p>
<h2 id="点估计">点估计</h2>
<h3 id="定义-3">定义</h3>
<ul>
<li>Example 1：<span class="math inline">\((X_1,X_2,...,X_n)i.i.d \sim
N(\mu,\sigma^2)\)</span>，我们想找到两个参数比较好的一个估计，可以考虑
<span class="math inline">\(\mu = \bar{X},\sigma^2 =
S^2\)</span>。这是非常典型的估计量，因为 <span class="math inline">\(E(\bar{X})=\mu,E(S^2) =\sigma^2\)</span>
，因此是无偏的。</li>
<li>Example 2：<span class="math inline">\((X_1,X_2,...,X_n)i.i.d \sim
P(\lambda)\)</span>，于是考虑 <span class="math inline">\(P(X_1=x_1,...,X_n=x_n)\)</span>可知 <span class="math inline">\(T(X)= X_1+...+X_n \sim P(n \lambda )\)</span>
是一个充分统计量，<span class="math inline">\(E(T(X))=\lambda\)</span>。</li>
<li>实际上，样本的任意一个 statistic 都是它的点估计量（point
estimator），实际观测值称为估计值，即 estimate，它是一个数值。</li>
</ul>
<h3 id="好的性质">好的性质</h3>
<ul>
<li><p>无偏性。对于 population <span class="math inline">\(\lbrace
f(x;\theta):\theta \in \Theta \rbrace\)</span> 中的随机抽样 <span class="math inline">\(X=(X_1,...,X_n)\)</span>，<span class="math inline">\(g(\theta)\)</span> 是定义在参数空间 <span class="math inline">\(\Theta\)</span> 上的函数，一个 <span class="math inline">\(g(\theta)\)</span> 的估计量，<span class="math inline">\(\hat{g}(X)=\hat{g}(X_1,...,X_n)\)</span> 是
unbiased 如果 <span class="math inline">\(E_\theta
[\hat{g}(X)]=g(\theta),\theta \in \Theta\)</span>。否则是有偏的。</p>
<p>定义 systematic error 为 <span class="math inline">\(E(\theta)-\theta\)</span>，则无偏即为 systematic
error 为 0.</p>
<p>说句人话，就是求某个 estimator 的期望是不是 <span class="math inline">\(\theta\)</span>，如果是的话就是无偏的。</p></li>
<li><p>有效性。对于两个 estimators <span class="math inline">\(\hat{g}_1(X),\hat{g}_2(X)\)</span>，如果 <span class="math inline">\(Var(\hat{g}_1(X))\leq Var(\hat{g}_2(X))\)</span>
对任意 <span class="math inline">\(\theta \in \Theta\)</span>
成立，并且参数空间中至少有一个 <span class="math inline">\(\theta\)</span> 使上述式子不取等号，那么称 <span class="math inline">\(\hat{g}_1 (X)\)</span> 相比 <span class="math inline">\(\hat{g}_2(X)\)</span> 更有效。</p></li>
<li><p>相合性。</p>
<ul>
<li><p>对任意样本量为 <span class="math inline">\(n\)</span> 的样本，记
<span class="math inline">\(\hat{g}_n(X) = \hat{g}_n
(X_1,...,X_n)\)</span> 是一个 estimator，如果 <span class="math inline">\(\hat{g}_n(X)\)</span> 依概率收敛到 <span class="math inline">\(g(\theta)\)</span>，也即，对任意的 <span class="math inline">\(\theta \in \Theta\)</span>，<span class="math inline">\(\varepsilon &gt;0\)</span>，有 <span class="math inline">\(\lim_{n\to \infty} P_\theta (|\hat{g}_n (X)
-g(\theta)| \geq \varepsilon)=0\)</span>，那么 <span class="math inline">\(\hat{g}_n(X)\)</span> 被称为一个 <span class="math inline">\(g(\theta)\)</span> 的 weakly consistent
estimator。</p></li>
<li><p>如果对任意 $$，有 <span class="math inline">\(P_\theta (lim _{n
\to \infty} \hat{g}_n (X)=g(\theta))=1\)</span>，则称其为 strongly
consistent estimator。</p></li>
<li><p>如果对任意 <span class="math inline">\(\theta \in \Theta
,r&gt;0\)</span>，有 $lim <em>{n } E</em>|_n(X)-g()|^r = 0 $，则称其为
<span class="math inline">\(g(\theta)\)</span> 的 <span class="math inline">\(r\)</span> 阶 consistent estimator。</p></li>
<li><p>Example
1：（这个对我来说还是一下子难以想到..归根结底是初概这一部分没学会，要补）</p>
<p><img src="https://s2.loli.net/2022/11/21/hI1jqgovw348xTl.png" alt="7.png"></p></li>
</ul></li>
</ul>
<h3 id="评价点估计的方式mse">评价点估计的方式——MSE</h3>
<ul>
<li><p>Mean Squared Error（MSE）：对于一个 estimator <span class="math inline">\(T\)</span> 和一个参数 <span class="math inline">\(\theta\)</span>，MSE 定义为：</p>
<p><span class="math inline">\(MSE(T)=MSE_\theta(T)=E_\theta((T-\theta)^2)=Var_\theta(T)+(Bias_\theta
(T))^2\)</span>，</p>
<p>其中，<span class="math inline">\(Bias_\theta
(T)=E_\theta(T)-\theta\)</span>。于是对于一个无偏的 <span class="math inline">\(T\)</span>，它的 MSE 就是方差。</p></li>
<li><p>如果有某个 <span class="math inline">\(\hat{g}^*(X)\)</span>
使得对任意的 estimator <span class="math inline">\(\hat{g}(X)\)</span>
都有 <span class="math inline">\(E_\theta(\hat{g}^* (X)-g(\theta))^2
\leq E_\theta(\hat{g} (X)-g(\theta))^2\)</span> 对任意的 <span class="math inline">\(\theta \in \Theta\)</span> 成立，则称其为
uniformly minimum MSE estimator，不一定存在。</p></li>
<li><p>往往需要在 bias 和 MSE
之间进行权衡，二者不一定同时最小。</p></li>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/11/21/KLW8I6ctOzSmqf2.png" alt="1.png"></p>
<p><img src="https://s2.loli.net/2022/11/21/RhG3MBuc5AyUjze.png" alt="3.png"></p>
<p><img src="https://s2.loli.net/2022/11/21/Io2l5Hzxhyb1OFW.jpg" alt="2.jpg"></p>
<p>Example 2：</p>
<p><img src="https://s2.loli.net/2022/11/21/rIVAXxnL7Gfyup4.png" alt="4.png"></p>
<p><img src="https://s2.loli.net/2022/11/21/loCKVpiHeg29GnB.png" alt="5.png"></p>
<p><img src="https://s2.loli.net/2022/11/21/3jhtxZyH9cKqPeT.jpg" alt="6.jpg"></p></li>
</ul>
<h3 id="求估计量的方法矩法">求估计量的方法——矩法</h3>
<ul>
<li><p><span class="math inline">\(X_1,X_2,...,X_n\)</span> 是来自于以
<span class="math inline">\(f_\theta(x)\)</span> 为 PDF 的有有限 <span class="math inline">\(k\)</span> 阶矩的随机样本，<span class="math inline">\(\theta=(\theta_1,...,\theta _k) \in R^k\)</span>
是未知的。定义：</p>
<ul>
<li>Sample moment：<span class="math inline">\(m_1 = \frac{1}{n}
\Sigma_{i=1} ^n X_i,m_2=\frac{1}{n}\Sigma_{i=1} ^n
X_i^2,...\)</span></li>
<li>Population moment：<span class="math inline">\(\mu_1 =
E(X_1)=h_1(\theta),\mu_2=E(X_1 ^2)=h_2(\theta),...\)</span></li>
</ul></li>
<li><p>Method of Moment（MOM）approach：对于未知的 <span class="math inline">\(\theta=(\theta_1,...,\theta_k)\)</span>，可以通过求解
<span class="math inline">\(k\)</span> 个方程 <span class="math inline">\(m_i=h_i(\theta)\)</span> 来确定它们每个的
estimator，<span class="math inline">\(k\)</span> 个方程确定 <span class="math inline">\(k\)</span> 个“未知数”，很合理。</p>
<p>事实上，这样解出来的 estimator 称为 moment
estimator，也有可能解不出来。</p></li>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/11/21/g5XFnsWCkaST3lH.png" alt="8.png"></p></li>
<li><p>矩法得到的 moment estimator 不一定唯一，比如取前 <span class="math inline">\(k\)</span> 个方程和取后 <span class="math inline">\(k\)</span>
个方程得到的结果可能是不一样的，有很多例子。为了计算方便，我们尽量会取低阶矩。为了
unbiasedness，往往会取中心矩。</p></li>
<li><p>MOM estimator 的性质：</p>
<ul>
<li><p>无偏性：样本原点矩一般都无偏，其余的没有一致的论断。</p>
<p><img src="https://s2.loli.net/2022/11/21/w4KPMSJuaA9DXmQ.png" alt="9.png"></p></li>
<li><p>相合性：</p>
<p><img src="https://s2.loli.net/2022/11/21/uDPOR9VXod4YMQj.png" alt="0.png"></p></li>
</ul></li>
<li><p>MOM 的优缺点：</p>
<ul>
<li>简单好算，不用知道分布。</li>
<li>样本较小时可能不精确，不一定完全反映样本的特征（漏参数）。</li>
</ul></li>
</ul>
<h1 id="homework-2">Homework 2</h1>
<p><img src="https://s2.loli.net/2022/11/29/Xx4dkfGNyOqcKnH.png" alt="51.png"></p>
<p><img src="https://s2.loli.net/2022/11/29/eO6nfItHCoqvJMr.jpg" alt="52.jpg"></p>
<h1 id="lecture-5">Lecture 5</h1>
<p>本节介绍另一种点估计方法——Maximum Likelihood
Estimator，这是最为流行的方法。</p>
<p>没想到的是这一讲还讲了一些数值方法，收敛到数值分析去了，我血赚（x</p>
<h2 id="极大似然估计量-mle">极大似然估计量 (MLE)</h2>
<h3 id="定义-4">定义</h3>
<ul>
<li><p>找一个使得似然函数的值最大的常数 <span class="math inline">\(\theta\)</span>，其函数作为一个 estimator，称为
maximum likelihood estimator。</p></li>
<li><p>MLE 的求法不一定是求导，先看看求导能不能做 &amp;&amp;
算出来的结果对了没有 &amp;&amp; 有没有更简单的方法</p></li>
<li><p>举个超几何分布的例子，这个问题的主要难度其实在于意识到，<span class="math inline">\(X\)</span>
单点就是一个观测值，以及用离散方法。</p>
<p><img src="https://s2.loli.net/2022/11/25/XiqgCueVUlanxLM.png" alt="AW1T5__2A4ZA_HG_64_2WRI.png"></p></li>
</ul>
<h3 id="性质">性质</h3>
<ul>
<li><p>Invariance Property：如果 <span class="math inline">\(\hat{\theta} _{MLE}\)</span> 是 <span class="math inline">\(\theta\)</span> 的 MLE，且 <span class="math inline">\(g\)</span> 是任意的函数，则 <span class="math inline">\(g(\hat{\theta} _{MLE})\)</span> 是 <span class="math inline">\(g(\theta)\)</span> 的 MLE。</p></li>
<li><p>Consistency：在某些条件下，MLE 序列依概率收敛到某个 <span class="math inline">\(\theta\)</span> 值。（非常模糊，看看就好</p></li>
<li><p>MLE &amp; sufficient statistic：<span class="math inline">\(X=(X_1,X_2,...,X_n)\)</span> 是 Population
中的一个随机抽样，Population 服从 <span class="math inline">\(\lbrace
f(x;\theta),\theta \in \Theta \rbrace\)</span> 的分布。如果 <span class="math inline">\(T=T(X_1,...,X_n)\)</span> 是一个充分统计量，且
<span class="math inline">\(\theta\)</span> 的 MLE 存在，那么 <span class="math inline">\(\hat{\theta}=\psi(T)\)</span> 是 <span class="math inline">\(T\)</span> 的一个函数。</p></li>
<li><p>Asymptotic normality：在某些情况下，MLE <span class="math inline">\(\hat{\theta}\)</span>
的序列（作为一个未赋值的随机变量）趋近于正态分布，准确来说，<span class="math inline">\(\sqrt{n} (\hat{\theta}_n - \theta) \to
N(0,\sigma_\theta ^2),n\to \infty\)</span>。其中，<span class="math inline">\(\sigma_\theta ^2 =
\frac{1}{I(\theta)}\)</span>，<span class="math inline">\(I(\theta)\)</span> 是 <span class="math inline">\(X\)</span> 的概率密度函数 <span class="math inline">\(f(x;\theta)\)</span> 导出的 Fisher
Information。</p>
<p>如果使用 Delta Method，可以导出 <span class="math inline">\(\sqrt{n}[g(\hat{\theta}_n)-g(\theta)] \to
N(0,(g&#39;^2(\theta)/I(\theta)))\)</span>。</p>
<p>以上均为依分布收敛。</p></li>
<li><p>相比于矩法，MLE
方法有求解更快的优点，但有时缺乏数值稳定性，且必须知道 Population
的分布。</p></li>
</ul>
<h3 id="mle-的数值解法">MLE 的数值解法</h3>
<ul>
<li>主要是使用牛顿法求解没有显式解的一阶微分方程。</li>
</ul>
<h2 id="mle-的应用">MLE 的应用</h2>
<ul>
<li><p>标记重捕法：标记重捕过程实际上可以视为超几何分布过程，使用关于
<span class="math inline">\(\theta\)</span> 的 MLE
估计即可。例如，第一次捉住了 10 只蜻蜓，全部做标记后放归。第二次捕捉 20
只蜻蜓后发现其中 4 只做了标记，希望求得种群数量 <span class="math inline">\(N\)</span>
的估计值。实际上，记第二次捕获的蜻蜓里有 <span class="math inline">\(r\)</span> 只做了标记，<span class="math inline">\(N\)</span> 可以被视为随机变量 <span class="math inline">\(r\)</span> 的分布中的参数，即 <span class="math inline">\(L(N;r)=f(r;N)=\frac{C_{10} ^r C_{N-10}^{20-r}}{C_N
^{20}}\)</span>，得到 <span class="math inline">\(N\)</span> 的 MLE 为
<span class="math inline">\(\hat{N}=[\frac{200}{r}]\)</span>，种群总数为
50 只的概率最大。</p></li>
<li><p>Hardy-Weinberg Law:
一个二倍体基因型包括两个基因，每个基因有两种表示，A 和
a。在人群中随机抽样得到 56 人中有 13 个为 AA 型，24 个为 Aa 型，19 个为
aa 型。求此基因显示为 A 的概率的 MLE。</p>
<p>实际上可以将以上抽样视作对一个服从 <span class="math inline">\(B(112,\theta)\)</span> 的 Population
进行抽样，得到一个容量为 112 的样本，其中抽取得到 50 个 A 和 62 个
a。考虑此样本的 Joint PDF 为 <span class="math inline">\(f(X)=C_{112}
^{50} \theta ^{50} (1-\theta) ^{62}\)</span> 取最大值时，<span class="math inline">\(\theta=\frac{25}{56}\)</span> 即为解。</p></li>
</ul>
<h1 id="lecture-6">Lecture 6</h1>
<p>本节重新介绍 Fisher
Information，并给出最后一种点估计方法——UMVUE。</p>
<h2 id="regular-condition">Regular Condition</h2>
<p>一共有五条，分别提示了开集，概率密度为正，对参数的导数存在，对参数的求导和对
x 的积分可交换，Fisher Information 有限。</p>
<p><img src="https://s2.loli.net/2022/11/27/jNVMn9zcTXJDWga.png" alt="I_FOWWR257NGS_3D57E.png"></p>
<h2 id="revisit-fisher-information">Revisit Fisher Information</h2>
<ul>
<li><p>Random Sample 的 Fisher Information</p>
<p><img src="https://s2.loli.net/2022/11/27/eHOVrwRymbkKZnz.jpg" alt="1.jpg"></p></li>
<li><p>Population 的 Fisher Infomation</p>
<p><img src="https://s2.loli.net/2022/11/27/ZhfiDLta5C1oklw.jpg" alt="2.jpg"></p></li>
<li><p>Example 1：对于<span class="math inline">\(X\sim N(\mu,\sigma
^2), \sigma^2\)</span> 已知，求 <span class="math inline">\(I(\mu)\)</span>。</p>
<p><img src="https://s2.loli.net/2022/11/27/fcCYRMNaik1ohTB.jpg" alt="3.jpg"></p></li>
<li><p>对于一个 estimator 序列 <span class="math inline">\(\lbrace
\hat{\theta}_n \rbrace\)</span>，有 <span class="math inline">\(\sqrt{n}
(\hat{\theta}_n -\theta _0) \to N(0,\frac{1}{I(\theta _0)})\)</span>
依分布收敛。考虑正态分布的性质可知，有 <span class="math inline">\(\hat{\theta}_n -\theta _0 \to
N(0,\frac{1}{nI(\theta _0)})\)</span>。其中 <span class="math inline">\(\theta_0\)</span> 表示参数的真值。</p></li>
</ul>
<h2 id="umvue">UMVUE</h2>
<h3 id="定义-5">定义</h3>
<ul>
<li><p>The best unbiased estimator 是方差最小的无偏估计量，因此其 MSE
也最小。也可以指 UMVUE，也即 uniformly minimum variance unbiased
estimator，一致最小方差无偏估计。其中的 uniformly
指的是对所有的参数都成立。</p></li>
<li><p>当然，一个样本可能不存在 unbiased estimator，也就没有
UMVUE，比如：</p>
<p><span class="math inline">\(X_1,X_2,...,X_n i.i.d. \sim
B(1,p)\)</span>，<span class="math inline">\(g(p)=\frac{1}{p}\)</span>
是要进行估计的量，它没有无偏估计量。</p>
<p><img src="https://s2.loli.net/2022/11/27/LKHB6VparIOimzP.jpg" alt="4.jpg"></p></li>
<li><p>每个无偏估计都是 sufficient estimator 的函数。</p></li>
</ul>
<h3 id="验证-umvue">验证 UMVUE</h3>
<ul>
<li><p>对于随机抽样 <span class="math inline">\(X_1,X_2,...,X_n\)</span>，样本对 <span class="math inline">\(\theta\)</span> 的充分统计量为 <span class="math inline">\(T(X)\)</span>，则 <span class="math inline">\(h(T(X))\)</span> 是 UMVUE 当且仅当对任意 <span class="math inline">\(0\)</span> 的无偏统计量 <span class="math inline">\(\psi(T(X))\)</span>，有 <span class="math inline">\(cov(\psi(T(X)),h(T(X)))=0\)</span>。其中有 <span class="math inline">\(E(\psi(T(X)))=0\)</span>。</p></li>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/11/29/ekTsyOlDz35i4mE.png" alt="OSWR18N__6IB39Z4H`1QVCV.png"></p></li>
</ul>
<h3 id="寻找-umvue">寻找 UMVUE</h3>
<p>寻找总比验证更困难。</p>
<ul>
<li><p>Cramer-Rao Inequality：<span class="math inline">\(X_1,X_2,...,X_n\)</span> 是服从 PDF <span class="math inline">\(f(x | \theta)\)</span> 的随机样本，<span class="math inline">\(W(X)=W(X_1,...,X_n)\)</span> 是 <span class="math inline">\(X\)</span> 的一个统计量，满足 <span class="math inline">\(\frac{d}{d\theta} E_\theta W(X) = \int
\frac{\partial}{\partial \theta} [W(x)f(x|\theta)] dx\)</span>，且 <span class="math inline">\(Var_\theta W(X) &lt; \infty\)</span>，于是 <span class="math inline">\(Var_\theta (W(X)) \geq \frac{(\frac{d}{d\theta}
E_\theta W(X))^2}{nI(\theta)}\)</span>。</p>
<p>如果一个 unbiased estimator 达到了 C-R lower bound，它就是
UMVUE。然而这不是充要条件，任意一个 UMVUE
未必满足取等条件。且需要注意只有在满足 Regularity Conditions
的时候才能保持 Cramer-Rao 成立。</p></li>
<li><p>多元形式的 Cramer-Rao Inequality：<span class="math inline">\(Cov_\theta(\hat{\theta}) \geq
(nI(\theta))^{-1}\)</span>。其中，<span class="math inline">\(A\geq
B\)</span> 表示 <span class="math inline">\(A-B\)</span>
是一个非负定矩阵。</p></li>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/11/29/WklE6cgO85VPaQF.png" alt="1.png"></p>
<p><img src="https://s2.loli.net/2022/11/29/k4IQJq2guEeOPft.png" alt="2.png"></p></li>
<li><p>Rao-Blackwell：<span class="math inline">\(T(X)\)</span> 是 <span class="math inline">\(g(\theta)\)</span> 的 sufficient statistic，<span class="math inline">\(\hat{g}(X)\)</span> 是 <span class="math inline">\(g(\theta)\)</span> 的 unbiased estimator，于是记
<span class="math inline">\(h(T)=E(\hat{g}(X)|T)\)</span> 也是一个
unbiased estimator，且 <span class="math inline">\(Var(h(T))\leq
Var(\hat{g}(X))\)</span>。</p>
<p>这是一个把 unbiased estimator 的方差降低的方法，启发出以下的
Lehmann-Scheffe Theorem。</p></li>
<li><p><span class="math inline">\(T(X)\)</span> 是 <span class="math inline">\(g(\theta)\)</span> 的 complete and sufficient
statistic，如果 <span class="math inline">\(\hat{g}(T(X))\)</span> 是
unbiased estimator，那么它就是唯一的 UMVUE。</p></li>
<li><p><span class="math inline">\(T(X)\)</span> 是 <span class="math inline">\(g(\theta)\)</span> 的 complete and sufficient
statistic，<span class="math inline">\(U\)</span> 是 <span class="math inline">\(g(\theta)\)</span> 的 unbiased estimator，那么
<span class="math inline">\(\hat{g}(T)=E_\theta (U|T)\)</span>
也是唯一的 UMVUE。</p>
<p>这给出了已知 complete and sufficient estimator
时的两种方法：要么直接寻找其函数使得它也是 unbiased
estimator，要么得到一个 unbiased estimator
然后二者结合做出解。显然，对于 Exponential Family
中的分布来说，这个方法比较容易操作，因为我们可以轻松地找到 complete and
sufficient estimator。</p>
<p>注意一个特例：Normal Distribution 的 UMVUE 就是对应的 <span class="math inline">\(\bar{X},S^2\)</span>
在系数和常数上的修正，这是易于证明的。</p></li>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/11/29/URSQ7feVcDzxbiI.png" alt="A.png"></p></li>
<li><p>Example 2：</p>
<p><img src="https://s2.loli.net/2022/11/29/MQK7iPAR4cZ2y9S.png" alt="B.png"></p>
<p><img src="https://s2.loli.net/2022/11/29/M1WTS7bhdzrKuOw.png" alt="B2.png"></p></li>
<li><p>Example 3：</p>
<p><img src="https://s2.loli.net/2022/11/29/dPZTSGnH5oic3Wq.png" alt="C.png"></p></li>
</ul>
<h2 id="判别无偏统计量的有效性">判别无偏统计量的有效性</h2>
<ul>
<li><p>Efficiency：</p>
<p><img src="https://s2.loli.net/2022/11/29/XMF42jQzGCEOWgm.png" alt="Z.png"></p></li>
</ul>
<h1 id="homework-3">Homework 3</h1>
<p><img src="https://s2.loli.net/2022/11/29/IOQVr1hGD6CHljs.png" alt="71.png"></p>
<p><img src="https://s2.loli.net/2022/11/29/xbO8HRDcuL7GgyC.jpg" alt="72.jpg"></p>
<p>后记：期中考试又考了一遍这个题，不过问的是 <span class="math inline">\(\theta ^2\)</span> 的
UMVUE。考场上自己写的时候才发现根本不用这么复杂，在第三行那一步的时候凑一个
<span class="math inline">\(\theta ^2\)</span>（此处是 <span class="math inline">\(\theta\)</span>）出来就行，搞不懂助教为什么凑的是
<span class="math inline">\(1-\theta\)</span>。结果是一样的，毕竟用
complete &amp; sufficient statistic 得出的 UMVUE 是唯一的。</p>
<p><span class="math inline">\(\theta ^2\)</span> 的 UMVUE 是 <span class="math inline">\(\frac{(n-1)(n-2)}{(T-1)(T-2)}\)</span>，可见与
<span class="math inline">\(\theta\)</span> 的 UMVUE 形式类似。</p>
<h1 id="mid-term">Mid-Term</h1>
<p><a href="https://in.closed.social:9443/ipfs/Qmc2T23eWee8879KWctzJn8Dfv843oNh8nbHx8KB7L4dY5">Click
Here</a></p>
<p>问就是，不是我写的，跟我没关系，请不要开盒.jpg</p>
<h1 id="lecture-7">Lecture 7</h1>
<p>本节介绍区间估计，它对于参数的估计就更模糊一些，注重于根据一系列数据来提供若干个区间，使得参数的函数值落在其中。听起来没那么完美，但是现实就是这样的嘛。</p>
<h2 id="interval-estimation">Interval Estimation</h2>
<h3 id="定义-6">定义</h3>
<ul>
<li><p>任意的 statistic <span class="math inline">\(\hat{g}_1(X),\hat{g}_2(X)\)</span> 满足 <span class="math inline">\(\hat{g}_1(X) \leq \hat{g} _2 (X)\)</span>，则区间
<span class="math inline">\([\hat{g}_1(X),\hat{g}_2(X)]\)</span> 是
<span class="math inline">\(g(\theta)\)</span> 的一个 interval
estimate（也可以叫做 confidence
interval）。这个定义很宽泛，因为一个区间估计未必需要 <span class="math inline">\(g(\theta)\)</span>
落在其中，它可以是无效的。需要注意的是，此处的用词是
estimate，意思是说，这里的 <span class="math inline">\(X\)</span>
指的是一个确切的样本。</p></li>
<li><p>coverage probability：区间 <span class="math inline">\([\hat{g}_1(X),\hat{g}_2(X)]\)</span> 的 coverage
probability 是随机区间 <span class="math inline">\([\hat{g}_1(X),\hat{g}_2(X)]\)</span> 包括真实值
<span class="math inline">\(g(X)\)</span> 的概率，也就是 <span class="math inline">\(P\lbrace g(\theta) \in [\hat{g}_1(X),\hat{g}_2(X)]
\rbrace &gt;0\)</span>。</p></li>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/12/05/RNYSJsKGExj4gWw.png" alt="1.png"></p>
<p><img src="https://s2.loli.net/2022/12/05/3PJrLzdAqt2ihon.png" alt="2.png"></p></li>
</ul>
<h3 id="measurement">Measurement</h3>
<p>然后就是要衡量一个 interval estimation 的有效度。</p>
<ul>
<li><p><span class="math inline">\(X_1,X_2,...,X_n\)</span> 是一个服从
<span class="math inline">\(f(x;\theta)\)</span> 的随机样本。Confidence
Level（置信度，也写作 reliability）被定义为 <span class="math inline">\(P(\theta \in
[\hat{\theta_1},\hat{\theta_2}])=P(\hat{\theta_1}\leq \theta \leq
\hat{\theta_2})\)</span>。</p></li>
<li><p>Confidence coefficient（置信系数）：<span class="math inline">\(inf_{\theta \in \Theta} P_\theta (\hat{\theta _1}
\leq \theta \leq \hat{\theta_2})\)</span></p></li>
<li><p>Precision（精确度）：有很多种估计方法，此处取最常用的方法：mean
interval length，即计算 <span class="math inline">\(E_{\theta}(\hat{\theta_2}-\hat{\theta
_1})\)</span>，这个值越大说明区间越长，因此估计的精确度越差。</p>
<p>一般来说，置信度和精确度是一对相反的要求，需要进行
trade-off。</p></li>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/12/05/I1emRiPvwFxkM4l.png" alt="3.png"></p></li>
<li><p>Revisit Confidence Interval：重新对于 confidence interval
进行定义，加上 confidence coefficient 的条件后如下：区间 <span class="math inline">\([\hat{\theta _1}(X),\hat{\theta _2}(X)]\)</span>
是 <span class="math inline">\(\theta\)</span> 的一个 interval
estimate，且对于一个给定的 <span class="math inline">\(\alpha\)</span>
有 <span class="math inline">\(0&lt;\alpha &lt;1\)</span>，如果 <span class="math inline">\(P(\hat{\theta_1}(X)\leq \theta \leq
\hat{\theta_2}(X)) \geq 1-\alpha\)</span>，那么称区间 <span class="math inline">\([\hat{\theta _1}(X),\hat{\theta _2}(X)]\)</span>
是一个有 confidence level 为 <span class="math inline">\(1-\alpha\)</span> 的， <span class="math inline">\(\theta\)</span> 的 confidence interval。</p>
<p>于是 confidence coefficient <span class="math inline">\(inf_{\theta
\in \Theta} P_\theta (\hat{\theta _1} (X)\leq \theta \leq
\hat{\theta_2}(X)) \leq \alpha\)</span>，是 confidence interval <span class="math inline">\([\hat{\theta _1}(X),\hat{\theta _2}(X)]\)</span>
的 confidence coefficient。</p></li>
<li><p>Remark 1：此处如果有 <span class="math inline">\(\alpha=0.05\)</span>，不代表 <span class="math inline">\(\theta\)</span> 有 <span class="math inline">\(0.95\)</span>
的概率落在得到的区间里，而是指的是我们有 <span class="math inline">\(0.95\)</span> 的信度能够确定 <span class="math inline">\(\theta\)</span> 在此区间里。更形象地，我们取 <span class="math inline">\(1000\)</span> 个样本，得到的 <span class="math inline">\(1000\)</span> 个区间里大约会有 <span class="math inline">\(950\)</span> 个覆盖住 <span class="math inline">\(\theta\)</span>。</p></li>
<li><p>Remark 2：在取样本之前，所有的区间 <span class="math inline">\([\hat{\theta _1}(X),\hat{\theta _2}(X)]\)</span>
都是 random interval，但取得样本之后区间的左右端都变为定值，称为
observed interval。</p></li>
<li><p>Confidence
Limit：有的时候我们只关心参数的上界或下界，即只考虑单边。对于给定的
statistic <span class="math inline">\(\hat{\theta}_U (X),\hat{\theta}_L
(X)\)</span>，对于给定的 <span class="math inline">\(0&lt;\alpha
&lt;1\)</span>，如果 <span class="math inline">\(P_\theta(\theta \leq
\hat{\theta}_U (X))\geq 1-\alpha,\theta \in \Theta\)</span>，或者 <span class="math inline">\(P_\theta(\theta \geq \hat{\theta}_L (X))\geq
1-\alpha,\theta \in \Theta\)</span>，则称 <span class="math inline">\(\hat{\theta}_U (X),\hat{\theta}_L (X)\)</span>
分别是 <span class="math inline">\(\theta\)</span> 的 upper confidence
limit 和 lower confidence limit，且有置信度 <span class="math inline">\(1-\alpha\)</span>。</p>
<p>针对 confidence limit 的 precision 估计：<span class="math inline">\(E(\hat{\theta}_U(X))\)</span> 越小或者 <span class="math inline">\(E(\hat{\theta}_L(X))\)</span> 越大，越精确。</p>
<p>此时，取 confidence interval 为 <span class="math inline">\([\hat{\theta _L}(X),\hat{\theta
_U}(X)]\)</span>，它的 confidence level 为 <span class="math inline">\(1-\alpha_1-\alpha_2\)</span>。</p></li>
</ul>
<h3 id="多维情形">多维情形</h3>
<p>略（</p>
<h2 id="构造合适的-interval-estimation">构造合适的 Interval
Estimation</h2>
<h3 id="pivot-quantity-method">Pivot quantity method</h3>
<p>如果要翻译的话，可以称为“枢轴量方法”。</p>
<ul>
<li><p>寻找 Pivot Quantity 的方法：找到一个包含参数 <span class="math inline">\(\theta\)</span> 的随机变量，它关于 <span class="math inline">\(X_1,X_2,...,X_n\)</span>
的部分最好是一个充分统计量的形式，且这个随机变量的分布已知。</p>
<p>观察此 pivot quantity 落在区间 <span class="math inline">\([a,b]\)</span> 上的概率，并适当选取让这个概率大于
<span class="math inline">\(1-\alpha\)</span>。</p>
<p>再把这个式子改成关于 <span class="math inline">\(\theta\)</span> 的
interval estimation 的形式。</p></li>
<li><p>总之，要找一个分布与 <span class="math inline">\(\theta\)</span>
无关，且形式上与 <span class="math inline">\(\theta\)</span>
有关的随机变量，它在形式上也不能和其他未知的参数有关。</p></li>
<li><p>位置-尺度族的常用 Pivot Quantity：</p>
<table>
<thead>
<tr class="header">
<th>Form of PDF</th>
<th>Type of PDF</th>
<th>Pivotal Quantity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(f(x-\mu)\)</span></td>
<td>Location</td>
<td><span class="math inline">\(\bar{X}-\mu\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\((1/\sigma)f(x/\sigma)\)</span></td>
<td>Scale</td>
<td><span class="math inline">\(\bar{X}/\sigma\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\((1/\sigma)f((x-\mu)/\sigma)\)</span></td>
<td>Location-Scale</td>
<td><span class="math inline">\((\bar{X}-\mu)/S\)</span></td>
</tr>
</tbody>
</table></li>
</ul>
<h3 id="approximate-ci">Approximate CI</h3>
<ul>
<li><p>顾名思义，在找不到合适的 pivot estimation
的时候，可以利用中心极限定理等方式取得一个依分布收敛的随机变量，把它作为
pivot estimation，然后进行考虑。</p></li>
<li><p>常用于不确定分布的 Population，或者无法求得合适的 pivot
estimation 的 Population。如果有精确的 pivot estimation
但是转化为参数中心的不等式时计算太复杂，也可以将其中的项进行改动，比如把某个
<span class="math inline">\(\mu\)</span> 改成 <span class="math inline">\(\bar{X}\)</span>，等等。</p></li>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/12/05/Tda2EkfYz8bBWP4.png" alt="4.png"></p></li>
<li><p>前提是样本量足够大。</p></li>
</ul>
<h2 id="关于正态分布的-ci">关于正态分布的 CI</h2>
<p>幸运的是，下面这张图上有你需要的一切：</p>
<p><img src="https://s2.loli.net/2022/12/05/p6dc2ZbUqeHmiBo.jpg" alt="5.jpg"></p>
<ul>
<li><p>1 和 2 指出的是对于某个随机样本 <span class="math inline">\(X_1,...,X_n i.i.d \sim N(\mu,
\sigma^2)\)</span>，在参数之一已知的时候，求出另一参数的 CI 的方法。在
Remark 里提出了不需要已知参数时的方法。</p></li>
<li><p>3 指出的是两个参数都不可知时，利用独立性得出 <span class="math inline">\(\mu,\sigma^2\)</span> 的 Confidence Region
的方式，虽然考试中并不会涉及，但是我觉得思路相当好。</p></li>
<li><p>4 指出的是两个不同的正态 Population 中分别取样，得出 <span class="math inline">\(\mu_1-\mu_2\)</span>，<span class="math inline">\(\frac{\sigma_1 ^2}{\sigma_2 ^2}\)</span> 的 CI
的方法。</p>
<p>分类讨论了几种：在方差相等时 <span class="math inline">\(\mu_1-\mu_2\)</span> 的 CI
可以准确求出（如果已知了 <span class="math inline">\(\sigma\)</span>
甚至更方便，用标准化到正态分布的 <span class="math inline">\(T\)</span>
就可以做了），方差不等时 <span class="math inline">\(\mu_1-\mu_2\)</span> 的 CI 是 approximate
的；此外，<span class="math inline">\(\frac{\sigma_1 ^2}{\sigma_2
^2}\)</span> 的 CI 求法在最后一种情况里给出。</p></li>
</ul>
<h1 id="homework-4">Homework 4</h1>
<p>略，基本就是以上内容的简单应用，不过计算量有点大（</p>
<h1 id="lecture-8">Lecture 8</h1>
<p>心情如图所示：orz orz orz orz orz orz</p>
<p><img src="https://s2.loli.net/2022/12/07/HhAGi4EruPK9cCM.png" alt="8__M_9R7H9G@JKC_T~7TYRM.png"></p>
<p>本节介绍假设检验的一些基本信息，这也是直到学期末为止的后半部分课程的主要内容。</p>
<p>突然想起 V1ncent19 学长说过的一段话：</p>
<blockquote>
<p>如果对生存分析不太熟悉的同学可以先笼统地理解为研究“某件事情什么时候发生”，这个时候就不得不提起某蒙古上单的评论“*
* 什么时候 * 啊”，大概就是研究这种事情。</p>
</blockquote>
<p>所以假设检验的通俗解释大概就是，对于某个样本，我们先验证它是否满足 A
条件，如果满足，我们就认为某个与参数相关的结论 B
是对的。否则，有一个和结论 B 矛盾的结论 C
成立。生活中其实处处都是假设检验，类似于通过“今天 ta
和我说话了”来判断出“ta
一定喜欢我吧！”这一假设成立，显然信度不是很高。</p>
<h2 id="基本定义">基本定义</h2>
<h3 id="检验的定义">检验的定义</h3>
<ul>
<li><p>Hypothesis Testing：我们有一个 distribution family 为 <span class="math inline">\(F=\lbrace f(x;\theta),\theta \in \Theta
\rbrace\)</span>，记 <span class="math inline">\(X=(X_1,X_2,...,X_n)\)</span>
是上述分布族中的一个随机样本。记 <span class="math inline">\(\Theta_0\)</span> 是 <span class="math inline">\(\Theta\)</span>
中不为空的一个子集，我们想检验是否有 <span class="math inline">\(\theta
\in \Theta_0\)</span>。记 <span class="math inline">\(\Theta_1=\Theta -
\Theta_0\)</span> 是 <span class="math inline">\(\Theta_0\)</span>
的补集。</p>
<ul>
<li>Null Hypothesis（原假设）：记为 <span class="math inline">\(H_0\)</span>：<span class="math inline">\(\theta
\in \Theta_0\)</span>，说明存在某个 <span class="math inline">\(\theta_0
\in \Theta_0\)</span>，使得 <span class="math inline">\(X_i \sim
f(x;\theta_0)\)</span>。</li>
<li>Alternative Hypothesis（备择假设）：<span class="math inline">\(H_0\)</span> 的 Alternative Hypothesis 记为 <span class="math inline">\(H_1\)</span>：<span class="math inline">\(\theta
\in \Theta_1\)</span>。</li>
<li>于是假设检验过程可以写为：<span class="math inline">\(H_o:\theta \in
\Theta_0 \leftrightarrow H_1 : \theta \in \Theta_1\)</span>。</li>
<li>Simple and composite hypothesis ：<span class="math inline">\(H_0 (/
H_1)\)</span> 是一个 simple hypothesis 等价于 <span class="math inline">\(\Theta_0(/ \Theta_1)\)</span> 是一个单点集，否则是
composite hypothesis。</li>
</ul>
<p>根据样本检验 <span class="math inline">\(H_0\)</span>
是否正确的过程，称作对于 <span class="math inline">\(H_1\)</span>
检验假设 <span class="math inline">\(H_0\)</span>。（我瞎翻译的，原文是
testing the hypothesis <span class="math inline">\(H_0\)</span> against
the alternative <span class="math inline">\(H_1\)</span>）</p>
<p>在 Hypothesis Testing 中，null hypothesis <span class="math inline">\(H_0\)</span> 称为 original
belief，是一个我们希望通过样本验证它是错的的精确条件。我们一般预设它是错的，预设
alternative hypothesis 是对的。</p></li>
<li><p>Rejection Region：在一个随机样本 <span class="math inline">\(X=(X_1,X_2,...,X_n)\)</span>
上我们要做出一个决定，即接受还是拒绝 null hypothesis <span class="math inline">\(H_0\)</span>。也就是说我们要定义出一个条件 <span class="math inline">\(A\)</span>，满足此条件则 accept null
hypothesis，否则 reject null hypothesis。</p>
<p>不满足条件 <span class="math inline">\(A\)</span> 的样本 <span class="math inline">\(X\)</span> 会使得 null hypothesis
被拒绝，符合我们的预设，这样的 <span class="math inline">\(X\)</span>
的集合称为 Rejection Region（或称 critical region），记为 <span class="math inline">\(D\)</span>，是一个样本子空间。于是 <span class="math inline">\(D^c\)</span> 就是 Acceptance Region，满足 <span class="math inline">\(\chi=D+D^c\)</span>，<span class="math inline">\(\chi\)</span> 是样本空间。</p></li>
<li><p>Two-side 和 One-side test：</p>
<ul>
<li><p>双边检验：<span class="math inline">\(H_0:\theta=\theta_0
\leftrightarrow H_1:\theta \neq \theta_0\)</span>，它的检验条件 <span class="math inline">\(A\)</span> 是 <span class="math inline">\(A: -c
\leq T(X)\leq c\)</span>，其中 <span class="math inline">\(T(X)\)</span>
是 <span class="math inline">\(\theta\)</span> 的一个估计量。于是
rejection region 就是 <span class="math inline">\(D=\lbrace |T(X)| &gt;c
\rbrace\)</span>。</p></li>
<li><p>单边检验：<span class="math inline">\(H_0:\theta \leq \theta_0
\leftrightarrow H_1 : \theta &gt; \theta_0\)</span>，它的检验条件 <span class="math inline">\(A\)</span> 是 <span class="math inline">\(A:
T(X)\leq c\)</span>，其中 <span class="math inline">\(T(X)\)</span> 是
<span class="math inline">\(\theta\)</span> 的一个估计量。于是 rejection
region 就是 <span class="math inline">\(D=\lbrace T(X) &gt;c
\rbrace\)</span>。</p>
<p>对称地，如果 <span class="math inline">\(H_0:\theta \geq \theta_0
\leftrightarrow H_1 : \theta &lt; \theta_0\)</span>，它的检验条件 <span class="math inline">\(A\)</span> 是 <span class="math inline">\(A:
T(X)\geq c\)</span>，其中 <span class="math inline">\(T(X)\)</span> 是
<span class="math inline">\(\theta\)</span> 的一个估计量。于是 rejection
region 就是 <span class="math inline">\(D=\lbrace T(X) &lt;c
\rbrace\)</span>。</p></li>
</ul></li>
</ul>
<h3 id="检验函数">检验函数</h3>
<ul>
<li><p>Test Function：在某些非黑即白的检验条件下，<span class="math inline">\(\psi(X)=I_{\lbrace reject H_0
\rbrace}\)</span>。也就是说 <span class="math inline">\(H_0\)</span> 被
reject、符合预设的时候 test function 取为 <span class="math inline">\(1\)</span>，否则取为 <span class="math inline">\(0\)</span>。</p>
<p>实际上，更标准的 test function 定义为 reject <span class="math inline">\(H_0\)</span> 的概率，如果是 non-randomized test 则
<span class="math inline">\(\psi(X)=0,1\)</span>，如果是 randomized test
则 <span class="math inline">\(\psi(X)\)</span> 可取 <span class="math inline">\([0,1]\)</span> 之间的值。</p></li>
<li><p>以下考虑一些 randomized test。</p>
<p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/12/08/567QUCzZwL1FvWa.png" alt="1.png"></p>
<p>由此定义 randomized test function：临界条件下定义 <span class="math inline">\(\psi (X)=r\)</span>，<span class="math inline">\(X\in D\)</span> 时 <span class="math inline">\(\psi(X)=1\)</span>，否则 <span class="math inline">\(X\in D^c\)</span> 时 <span class="math inline">\(\psi (X)=0\)</span>。</p></li>
</ul>
<h2 id="type-i-ii-errors">Type I &amp; II Errors</h2>
<p>实际上，我们在假设检验中进行随机抽样，总有可能取到偏误的样本，导致错误地
reject 或者 accept 了 <span class="math inline">\(H_0\)</span>。有两种错误，分别称为 Type I &amp; II
Error。</p>
<ul>
<li><p>通俗来说，Type I Error 是假阳性，也就是把实际正确的 <span class="math inline">\(H_0\)</span> 给 reject
了，就像给健康人判了感染一样。发生 Type I Error
是因为取到的样本恰好落在了 <span class="math inline">\(D\)</span>
里，这个概率是：</p>
<p><span class="math inline">\(\alpha(\theta)=P(I)=P[(X_1,X_2,...,X_n)
\in D | H_0]=P[(X_1,X_2,...,X_n) \in D | \theta \in
\Theta_0]\)</span></p>
<p>发生 Type I Error 的最大概率，也就是 <span class="math inline">\(\alpha=max_{\theta \in \Theta_0}
P(I)\)</span>，称为 the level of significance（显著性水平）。当 <span class="math inline">\(\alpha=0\)</span> 时说明 <span class="math inline">\(D=\emptyset\)</span>，也就是说 <span class="math inline">\(H_0\)</span> 永远被接受。</p></li>
<li><p>相对地，Type II Error 就是假阴性，<span class="math inline">\(P(II)=P[(X_1,X_2,...,X_n) \in D^c | \theta \notin
\Theta_0]\)</span>。</p>
<p>定义发生 Type II Error 的概率为 <span class="math inline">\(\beta(\theta)\)</span>，于是 <span class="math inline">\(\beta(\theta)=1\)</span> 时也有 <span class="math inline">\(D=\emptyset\)</span>，这是和预设不符的。</p></li>
<li><p>同时降低两种 Error 是不太可能的，以一个正态的估计量 <span class="math inline">\(T(X)\)</span>
为例，可以看到呈一个此消彼长的趋势。（课上这个图画了好久，不是很懂，摸鱼去了）</p>
<p><img src="https://s2.loli.net/2022/12/08/KZBEIO2hmdplVDW.png" alt="2.png"></p>
<p>但是在实际操作中我们会遵循 Neyman-Pearson Principle，去尽量降低发生
Type I Error 的概率，让 the level of significance 降低到一个预设的级别
<span class="math inline">\(\alpha\)</span>，再去考虑降低 Type II Error
的概率。</p>
<p>于是如果样本落进了 <span class="math inline">\(H_0\)</span> 的
acceptance
region，我们会保持自己的预设，优先考虑这个样本没有提供足够的证据来
reject <span class="math inline">\(H_0\)</span>，而不是我们应该 accept
<span class="math inline">\(H_0\)</span>。</p></li>
</ul>
<h2 id="power-function">Power Function</h2>
<ul>
<li><p>Power Function（功效函数，势函数）定义为一个假设检验中，样本落在
<span class="math inline">\(H_0\)</span> 的 rejection region <span class="math inline">\(D\)</span> 上的概率，即 <span class="math inline">\(\pi(\theta)=P_\theta (X \in D)\)</span>。当 accept
<span class="math inline">\(H_0\)</span> 时，<span class="math inline">\(\pi(\theta)=\alpha(\theta)\)</span>，否则 <span class="math inline">\(\pi(\theta)=1-\beta(\theta)\)</span>。</p></li>
<li><p>单次检验 <span class="math inline">\(\psi\)</span> 的 power
function 定义为 <span class="math inline">\(\pi_\psi(\theta)=E_\theta
[\psi(X)]\)</span>，其中 <span class="math inline">\(\psi(X)\)</span> 是
reject <span class="math inline">\(H_0\)</span> 的概率，也就是说 power
function 是整个检验中 reject <span class="math inline">\(H_0\)</span>
的概率总和。</p>
<p>对于一个 non-randomized test，<span class="math inline">\(\pi_\psi(\theta)=P_\theta (X=(X_1,...,X_n) \in
D)\)</span>，因为 <span class="math inline">\(\psi\)</span> 取值为 <span class="math inline">\(0,1\)</span>。</p>
<p>对于一个 randomized test，<span class="math inline">\(\pi_\psi(\theta)=P(T(X)&gt;c)+rP(T(X)=c)\)</span>，因为
<span class="math inline">\(\psi\)</span> 取值 <span class="math inline">\(0,1,r\)</span>。</p></li>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/12/08/qdEAG7vaSfxznMk.png" alt="3.png"></p>
<p>Remark：这个题给出了两个 power function 的曲线，可以看到 <span class="math inline">\(\pi_1(\theta)\)</span> 底部和 <span class="math inline">\(\theta\)</span> 轴贴得比较近，对于 Type I Error
的预防较好；在 <span class="math inline">\(\theta\)</span> 落在 <span class="math inline">\(\Theta_1\)</span> 中时 <span class="math inline">\(\pi(\theta)=1-\beta(\theta)\)</span>，因此 <span class="math inline">\(\pi_2(\theta)\)</span> 对 Type II Error
的预防较好。</p>
<p>实际上，这两个检验方式都不够好，没有同时预防两种 Error。最理想的
power function 应该在 <span class="math inline">\(\theta=0.5\)</span>
处陡然上升，这样 <span class="math inline">\(\alpha(\theta)\)</span> 和
<span class="math inline">\(\beta (\theta)\)</span>，也即发生 Type I
&amp; II Error 的概率都能得到控制。</p></li>
</ul>
<h2 id="p-value">P-value</h2>
<ul>
<li><p>感觉不是很好理解，先举个例子。我们已经知道在假设检验的时候一般都有一个范围，例如在
<span class="math inline">\(T(X)&gt;a\)</span> 时 reject <span class="math inline">\(H_0\)</span>，等等。当拿到一个样本计算出 <span class="math inline">\(T(X)\)</span> 后，它在大于 <span class="math inline">\(a\)</span> 时可能离 <span class="math inline">\(a\)</span> 很远，也可能离 <span class="math inline">\(a\)</span> 很近。离 <span class="math inline">\(a\)</span>
越远，我们越确信这个样本更好地反映了应该 reject <span class="math inline">\(H_0\)</span>。因此，我们希望找一个标准来衡量这种“确信”的程度，因此引入
P-value。</p></li>
<li><p>某一个样本 <span class="math inline">\(X\)</span> 的 P-value
反映出了在 reject or accept <span class="math inline">\(H_0\)</span>
这件事上有相同结果的时候，所能得到的其他样本比 <span class="math inline">\(X\)</span>
更加极端的概率。虽然听起来很奇怪，但就是这样的。反映到具体例子里，大概就是：</p>
<p><img src="https://s2.loli.net/2022/12/09/nGOdgRLDWl7yHYS.png"></p>
<p>P-value 是一个基于所得样本的条件概率，前提是 <span class="math inline">\(H_0\)</span> 成立。</p></li>
<li><p>Decision Rule：给出一个衡量标准 <span class="math inline">\(\alpha\)</span>，我们在 <span class="math inline">\(T(X)\)</span> 符合判断要求，且 <span class="math inline">\(P-value \leq \alpha\)</span> 时 reject <span class="math inline">\(H_0\)</span>。因此，P-value 能够衡量做出 rejection
of a hypothesis 这一决定的证据充分程度，P-value
越小，拒绝的理由越充分，这样的操作就可以称为一个 strong
rejection，称结果 highly statistically
significant（统计学上有高度的显著意义（我瞎翻译的</p></li>
<li><p>Example 1（HW）：</p>
<p><img src="https://s2.loli.net/2022/12/09/wnh3FPfROKgDjYG.png"></p>
<p>先建个模：试验得到的样本是 <span class="math inline">\((x_1,x_2)=(25.1,27.6)\)</span>，null hypothesis
指的是“药是无效的”，alternative hypothesis
指的是“药是有效的”（对此区分是因为我们预设 reject null
hypothesis）。如今得到了一个比较小的 P-value 是 <span class="math inline">\(0.015\)</span>，这说明了我们有比较大的把握通过这一个样本来确定药是有效的。</p>
<p>四个选项都不对。<span class="math inline">\(A\)</span> 选项计算的是
<span class="math inline">\(P(H_0)\)</span>，<span class="math inline">\(B\)</span> 选项计算的或许是 <span class="math inline">\(E(X_1-X_2)\)</span>，<span class="math inline">\(C\)</span> 选项计算的是 <span class="math inline">\(P(T(X_1)&lt;a |
H_0)\)</span>，虽然在形式上比较接近 P-value 的定义了但还是不对，<span class="math inline">\(D\)</span> 选项问题在于 <span class="math inline">\(p&gt;0.05\)</span> 时说明这一组样本对于 reject
<span class="math inline">\(H_0\)</span>
的可信度不够高，并不完全证明没有治疗效果。</p></li>
<li><p>The American Statistical Association's statement on p-values:
context, process, and purpose</p>
<p>因为 P-value 真的很容易被误用，所以 ASA 在 2016 年提出了使用和解释
P-value 的原则。摘录如下：</p>
<blockquote>
<ul>
<li><p>P-values can indicate how incompatible the data are with a
specified statistical model.</p>
<p>A p-value provides one approach to summarizing the
<strong>incompatibility</strong> between a particular set of data and a
proposed model for the data.</p>
<p>The smaller the p-value, the greater <strong>the statistical
incompatibility</strong> of the data with the null hypothesis, if the
underlying assumptions used to calculate the p-value hold.</p></li>
<li><p>P-values do not measure the probability that the studied
hypothesis is true, or the probability that the data were produced by
random chance alone.</p>
<p>Researchers often wish to turn a p-value into a statement about the
truth of a null hypothesis, or about the probability that random chance
produced the observed data. The p-value is neither.</p></li>
<li><p>Scientific conclusions and business or policy decisions should
not be based only on whether a p-value passes a specific
threshold.</p></li>
<li><p>Proper inference requires full reporting and
transparency.</p></li>
<li><p>A p-value, or statistical significance, does not measure the size
of an effect or the importance of a result.</p>
<p>Smaller p-values do not necessarily imply the presence of larger or
more important effects, and larger p-values do not imply a lack of
importance or even lack of effect.</p>
<p>Any effect, no matter how tiny, can produce a small p-value if the
sample size or measurement precision is high enough, and large effects
may produce unimpressive p-values if the sample size is small or
measurements are imprecise.</p>
<p>Similarly, identical estimated effects will have different p-values
if the precision of the estimates differs.</p>
<p>(讲了一些选取 estimator 会带来的区别，课程还没涉及到)</p></li>
<li><p>By itself, a p-value does not provide a good measure of evidence
regarding a model or hypothesis.</p>
<p>Researchers should recognize that a p-value without context or other
evidence provides limited information.</p>
<p>For example, a p-value near 0.05 taken by itself offers only weak
evidence against the null hypothesis.</p></li>
</ul>
</blockquote>
<p>总的来说，P-value 能够提供的信息是有限的。</p></li>
</ul>
<h1 id="lecture-9">Lecture 9</h1>
<p>本节继续介绍了以正态分布样本为主的假设检验。变得越来越像 Interval
Estimation 了。</p>
<p>首先回顾一下假设检验的过程：</p>
<ul>
<li>先设出一个 null hypothesis <span class="math inline">\(H_0\)</span>
和对应的 alternative hypothesis <span class="math inline">\(H_1\)</span>，二者不一定构成全集。</li>
<li>找到用于假设检验的 test statistic <span class="math inline">\(T(X)\)</span>，以及对应的 rejection region <span class="math inline">\(D\)</span>，例如 <span class="math inline">\(D=\lbrace X | T(X)&gt;a \rbrace\)</span>，<span class="math inline">\(a\)</span> 是待定的。</li>
<li>找到一个合适的 level of significance <span class="math inline">\(\alpha\)</span>，一般是 <span class="math inline">\(0.01,0.05\)</span>，通过控制 critical
value，也就是控制发生 Type I Error 的概率小于 <span class="math inline">\(\alpha\)</span>，来决定 <span class="math inline">\(D\)</span> 的具体形式。</li>
<li>取样本，计算 <span class="math inline">\(T(X)\)</span>，看它是否在
rejection region 里，判断是否要 reject null hypothesis。</li>
<li>计算 P-value
的大小，来判断通过这组样本作出决定的这一做法有多大的可信度。</li>
</ul>
<p>每一步都比较清楚了，目前落实到具体问题里需要处理的是找 test
statistic，以及控制 critical value 来得到 rejection region 两步。</p>
<h2 id="testing-in-various-populations">Testing in various
populations</h2>
<p>懒得翻译了，总之在正态分布的一些情况里、以及一些简单分布中进行分析。</p>
<h3 id="a-single-normal-population">A single normal population</h3>
<ul>
<li><p>检验 <span class="math inline">\(\mu\)</span> 的过程分为是否知道
<span class="math inline">\(\sigma\)</span>
具体值的两种情况，又分为三种典型的 Hypothesis
进行处理，一切都在图中：</p>
<p><img src="https://s2.loli.net/2022/12/11/k9AigbzHpQeyt6B.jpg" alt="a.jpg"></p>
<p>注意我们在进行检验的时候，往往把等于号的情况归到 null hypothesis
中去。</p>
<p>以上前半部分对 two-sided 进行了检验，remark 里指出了 <span class="math inline">\(\sigma\)</span> 未知的检验方法，这称为 <span class="math inline">\(U\)</span> 检验；后半部分对 one-sided
的一种情况进行了检验，同样在 remark 里指出了 <span class="math inline">\(\sigma\)</span> 未知的检验方法，这称为 <span class="math inline">\(t\)</span> 检验。</p></li>
<li><p>检验 <span class="math inline">\(\sigma\)</span>
的过程分为是否知道 <span class="math inline">\(\mu\)</span>
具体值的两种情况，又分为三种典型的 Hypothesis
进行处理，一切都在图中：</p>
<p><img src="https://s2.loli.net/2022/12/11/Me6BHyitGUdjaTR.jpg" alt="b.jpg"></p>
<p>此处都是利用 <span class="math inline">\(\chi^2\)</span>
分布进行检验，称为 <span class="math inline">\(\chi^2\)</span>
检验。</p></li>
</ul>
<h3 id="non-normal-population">Non-normal population</h3>
<ul>
<li><p>检验 <span class="math inline">\(B(1,\theta)\)</span> 分布的
population 的参数</p>
<p>以一个例子来说明：</p>
<p><img src="https://s2.loli.net/2022/12/11/Ofn4vm1bDRSzFoW.jpg" alt="d.jpg"></p>
<p>这带我们回顾了 test function <span class="math inline">\(\varphi(X)\)</span> 的定义，它代表了 <span class="math inline">\(T(X)\)</span> 取某个值的时候 reject <span class="math inline">\(H_0\)</span> 的信度。</p></li>
</ul>
<h3 id="two-normal-distributions">Two normal distributions</h3>
<ul>
<li><p>在 two normal distribution 的情况下，检验 <span class="math inline">\(\mu_1-\mu_2\)</span>，<span class="math inline">\(\sigma_1^2 / \sigma_2 ^2\)</span>，以及进行 paired
comparison。</p>
<p><img src="https://s2.loli.net/2022/12/11/hOlVTxcyKpUFo1t.jpg" alt="c.jpg"></p></li>
</ul>
<h3 id="summary">Summary</h3>
<p>本来想自己画个表格，结果摆了。</p>
<ul>
<li>One normal population</li>
</ul>
<p><img src="https://s2.loli.net/2022/12/11/KthOEMq1FsInJGe.png" alt="1.png"></p>
<p><img src="https://s2.loli.net/2022/12/11/jwuLg45MtpOP3Nf.png" alt="2.png"></p>
<ul>
<li>Two normal populations（不包括 paired comparison，paired comparison
的目标是考察一个正态分布的期望是否为 0）</li>
</ul>
<p><img src="https://s2.loli.net/2022/12/11/El63nDusdmoLqAP.png" alt="3.png"></p>
<p><img src="https://s2.loli.net/2022/12/11/LG6upPYa5c8v9QC.png" alt="4.png"></p>
<ul>
<li><p>Non-normal population</p>
<p><span class="math inline">\(B(1,\theta)\)</span> 见前。</p></li>
</ul>
<h2 id="bootstrapping-method">Bootstrapping Method</h2>
<p>本来觉得看起来很好玩，没想到居然直接不讲了，sigh。我自己补一个。</p>
<p>实际情况下样本不一定来自一个 Normal
Distribution，数据集也可能不够大。我们可以用 Bootstrap 的方法嗯造一个
Normal Distribution
的数据集，然后进行假设检验。方法是每次有放回地从数据集里抽取一组数据，注意不仅是样本之间可以有重叠，样本内部抽每个数据的时候也是有放回抽取的。</p>
<p>比如对于一个较小的、不确定是否为 Normal Distribution
的数据集做假设检验：<span class="math inline">\(H_0:\mu =
33.02\)</span>，<span class="math inline">\(H_1:\mu \neq
33.02\)</span>。</p>
<table>
<colgroup>
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
</colgroup>
<thead>
<tr class="header">
<th>No.</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Data</td>
<td>28</td>
<td>-44</td>
<td>29</td>
<td>30</td>
<td>26</td>
<td>27</td>
<td>22</td>
<td>23</td>
<td>33</td>
<td>16</td>
</tr>
<tr class="even">
<td>No.</td>
<td>11</td>
<td>12</td>
<td>13</td>
<td>14</td>
<td>15</td>
<td>16</td>
<td>17</td>
<td>18</td>
<td>19</td>
<td>20</td>
</tr>
<tr class="odd">
<td>Data</td>
<td>29</td>
<td>24</td>
<td>24</td>
<td>40</td>
<td>21</td>
<td>31</td>
<td>34</td>
<td>-2</td>
<td>25</td>
<td>19</td>
</tr>
</tbody>
</table>
<p>Bootstrap Method 代码实现如下：</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># To see whether datas are from a normal population</span></span><br><span class="line">speed <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">28</span><span class="punctuation">,</span> <span class="operator">-</span><span class="number">44</span><span class="punctuation">,</span> <span class="number">29</span><span class="punctuation">,</span> <span class="number">30</span><span class="punctuation">,</span> <span class="number">26</span><span class="punctuation">,</span> <span class="number">27</span><span class="punctuation">,</span> <span class="number">22</span><span class="punctuation">,</span> <span class="number">23</span><span class="punctuation">,</span> <span class="number">33</span><span class="punctuation">,</span> <span class="number">16</span><span class="punctuation">,</span> <span class="number">24</span><span class="punctuation">,</span> <span class="number">29</span><span class="punctuation">,</span> <span class="number">24</span><span class="punctuation">,</span> <span class="number">40</span><span class="punctuation">,</span> <span class="number">21</span><span class="punctuation">,</span> <span class="number">31</span><span class="punctuation">,</span> <span class="number">34</span><span class="punctuation">,</span> <span class="operator">-</span><span class="number">2</span><span class="punctuation">,</span> <span class="number">25</span><span class="punctuation">,</span> <span class="number">19</span><span class="punctuation">)</span></span><br><span class="line">hist<span class="punctuation">(</span>speed<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new population whose mean is 33.02</span></span><br><span class="line">newspeed <span class="operator">&lt;-</span> speed <span class="operator">-</span> mean<span class="punctuation">(</span>speed<span class="punctuation">)</span> <span class="operator">+</span> <span class="number">33.02</span></span><br><span class="line">mean<span class="punctuation">(</span>newspeed<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bootstrap Method : Take out 20 observations at random, do it for 1000 times</span></span><br><span class="line">bstrap <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="punctuation">)</span></span><br><span class="line"><span class="keyword">for</span> <span class="punctuation">(</span>i <span class="keyword">in</span> <span class="number">1</span><span class="operator">:</span><span class="number">1000</span><span class="punctuation">)</span><span class="punctuation">&#123;</span></span><br><span class="line">    newsample <span class="operator">&lt;-</span> sample<span class="punctuation">(</span>newspeed<span class="punctuation">,</span> <span class="number">20</span><span class="punctuation">,</span> replace <span class="operator">=</span> <span class="built_in">T</span><span class="punctuation">)</span></span><br><span class="line">    bstrap <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span>bstrap<span class="punctuation">,</span> mean<span class="punctuation">(</span>newsample<span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line">hist<span class="punctuation">(</span>bstrap<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate the p-value: P(stat &lt; 21.75) + P(stat &gt; 44.29)</span></span><br><span class="line"><span class="punctuation">(</span><span class="built_in">sum</span><span class="punctuation">(</span>bstrap <span class="operator">&lt;</span> <span class="number">21.75</span><span class="punctuation">)</span> <span class="operator">+</span> <span class="built_in">sum</span><span class="punctuation">(</span>bstrap <span class="operator">&gt;</span> <span class="number">44.29</span><span class="punctuation">)</span><span class="punctuation">)</span><span class="operator">/</span><span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The p-value is 0.004, which is less than 0.05. Reject H_0</span></span><br></pre></td></tr></table></figure>
<p>综上，这一组数据不足以支持 <span class="math inline">\(H_0\)</span>，我们选择 Reject <span class="math inline">\(H_0\)</span>。</p>
<h2 id="test-based-on-clt">Test based on CLT</h2>
<p>实际情况里不一定发生既不是 Normal
Distribution，数据集又很小这么背的事情。如果数据量很大的话，完全可以使用
CLT 方法，进行一个 asymptotic sampling distribution
的规约，然后对近似正态分布进行 Hypothesis Testing。</p>
<p>对于一组 <span class="math inline">\(X_1,X_2,...,X_n i.i.d. \sim
F\)</span>，有 mean <span class="math inline">\(\mu\)</span> 和 variance
<span class="math inline">\(\sigma^2\)</span>，取 <span class="math inline">\(\bar{X_n}=\Sigma_{i=1} ^n X_i/n\)</span> 为 sample
mean，<span class="math inline">\(S^2 = \Sigma _{i=1} ^n (X_i-\bar{X})^2
/(n-1)\)</span> 为 sample variance。利用 CLT 可知：</p>
<p><span class="math inline">\(F=N(\mu,\sigma^2)\)</span> 时，一定有
<span class="math inline">\(\sqrt{n}(\bar{X_n}-\mu)/\sigma \sim
N(0,1)\)</span>。否则 <span class="math inline">\(n\)</span>
足够大时，由 CLT 也有 <span class="math inline">\(\sqrt{n}(\bar{X_n}-\mu)/\sigma \to
N(0,1)\)</span>。</p>
<p><span class="math inline">\(F=N(\mu,\sigma^2)\)</span> 时，有 <span class="math inline">\(\sqrt{n}(\bar{X_n}-\mu)/S \sim
t_{n-1}\)</span>。否则 <span class="math inline">\(n\)</span>
足够大时，由 CLT 和 Slutsky Theorem，有 <span class="math inline">\(\sqrt{n}(\bar{X_n}-\mu)/S \to
N(0,1)\)</span>。这个形式是用在 <span class="math inline">\(\sigma\)</span> 未知的场合下进行假设检验的。</p>
<p>以上二者均依分布收敛。</p>
<ul>
<li><p>Test <span class="math inline">\(\mu_1 -\mu_2\)</span> when <span class="math inline">\(\sigma_1 ^2,\sigma_2 ^2\)</span> unknown, and m, n
are both large enough</p>
<p>由 CLT 和 Slutsky Theorem，可知在 <span class="math inline">\(H_0:\mu_1 -\mu_2 =\mu_0\)</span> 条件下，<span class="math inline">\(U=\frac{\bar{Y}-\bar{X}-\mu_0}{\sqrt{S_X ^2 /m+
S_Y ^2 /n}} \to N(0,1)\)</span>。对其假设检验，得到双尾检验的 Rejection
Region 是 <span class="math inline">\(D=\lbrace
(X_1,...,X_m,Y_1,...,Y_n) | |U|&gt;z_{\alpha /2}
\rbrace\)</span>。</p></li>
<li><p>Test the mean <span class="math inline">\(\theta\)</span> of
<span class="math inline">\(B(1,\theta)\)</span> when n is large
enough</p>
<p>由 CLT 可知在 <span class="math inline">\(H_0:\theta =
\theta_0\)</span> 条件下，<span class="math inline">\(U=\frac{\sqrt{n}(\bar{X}-\theta_0)}{\sqrt{\theta_0(1-\theta_0)}}
\to N(0,1)\)</span>，双尾检验的 Rejection Region 为 <span class="math inline">\(D=\lbrace (X_1,...,X_n) | |U| &gt; z_{\alpha /2}
\rbrace\)</span>。</p></li>
<li><p>Test the mean <span class="math inline">\(\theta\)</span> of
<span class="math inline">\(P(\theta)\)</span> when n is large
enough</p>
<p>由 CLT 可知在 <span class="math inline">\(H_0:\theta =
\theta_0\)</span> 条件下，<span class="math inline">\(U
=\frac{\sqrt{n}(\bar{X}-\theta_0)}{\sqrt{\theta_0}} \to
N(0,1)\)</span>，双尾检验的 Rejection Region 为 <span class="math inline">\(D=\lbrace (X_1,...,X_n) | |U| &gt; z_{\alpha /2}
\rbrace\)</span>。</p></li>
</ul>
<h1 id="homework-5">Homework 5</h1>
<p>略麻烦，我不是很懂那个 <span class="math inline">\(B(1,\theta)\)</span>
的自主检验方法，蹲一个标答。</p>
<h1 id="lecture-10">Lecture 10</h1>
<p>老师发着烧还坚持上课，辛苦了 qwq</p>
<p>本节继续介绍 Hypothesis Testing，但是使用 Likelihood Ratio 方法。</p>
<h2 id="likelihood-ratio-test-lrt">Likelihood Ratio Test (LRT)</h2>
<p>我们之前知道，解 MLE 方法的原理是 Likelihood Function 的值越大，说明
<span class="math inline">\(\theta\)</span> 作为参数的可能性越大。在
Hypothesis Test 中也可以通过 <span class="math inline">\(H_0,H_1\)</span> 的 maximum likelihood 得到最佳的
<span class="math inline">\(\theta\)</span>，从而对 <span class="math inline">\(H_0,H_1\)</span> 做判断。</p>
<p>为了方便后续的计算，我们先给出：对于一个 random sample <span class="math inline">\(X_1,...,X_n i.i.d. \sim N(\mu,\sigma
^2)\)</span>，在 MLE 那一讲已经求得，其 <span class="math inline">\(\hat{\mu}_{MLE} = \bar{X}\)</span> 是 sample
mean，但 <span class="math inline">\(\hat { \sigma } _{MLE} ^2\)</span>
不是 sample variance，而是 <span class="math inline">\(\frac {1} {n}
\Sigma _{ i=1 } ^n (x _i - \mu) ^2\)</span>。</p>
<h3 id="likelihood-ratio-method">Likelihood Ratio Method</h3>
<ul>
<li><p><span class="math inline">\(H_0:\theta =\theta_0 \leftrightarrow
H_1:\theta =\theta_1\)</span>，一个不是非常寻常的 hypothesis test。</p>
<p>考虑 <span class="math inline">\(\frac{L(\theta_0; x)}{L(\theta_1;
x)} &lt;c\)</span> 时 reject <span class="math inline">\(H_0\)</span>。显然，如果 accept <span class="math inline">\(H_1\)</span>，则说明全域 <span class="math inline">\(\Theta\)</span> 上的最佳参数是 <span class="math inline">\(\theta_1\)</span>，也即它是 MLE，使得 <span class="math inline">\(L(\theta_1;x)&gt;L(\theta_0;x)\)</span>
成立。于是在 hypothesis test 中放松些要求，考虑 <span class="math inline">\(\frac{L(\theta_0; x)}{L(\theta_1; x)}
&lt;c\)</span> 时 Reject <span class="math inline">\(H_0\)</span>。</p></li>
<li><p>推广到 <span class="math inline">\(H_0:\theta \in \Theta_0
\leftrightarrow H_1:\theta \in \Theta_1\)</span></p>
<p>考虑 <span class="math inline">\(\frac{sup_{\theta \in \Theta_0}
L(\theta;x)}{sup_{\theta \in \Theta_1} L(\theta;x)} &lt;c\)</span> 时
reject <span class="math inline">\(H_0\)</span>。这个想法也很自然，<span class="math inline">\(sup_{\theta \in \Theta} L(\theta;x)\)</span>
对应的 <span class="math inline">\(\theta\)</span> 就是 <span class="math inline">\(\Theta\)</span> 域中最佳的参数取值。</p>
<p>实际上，我们可以把 <span class="math inline">\(sup _{\theta \in
\Theta _0 } L(\theta ; x )\)</span> 记作 <span class="math inline">\(L(
\hat { \theta } _{MLE ; 0} )\)</span>。</p>
<p>同样地，把 <span class="math inline">\(sup _{\theta \in \Theta }
L(\theta;x)\)</span> 记作 $ L( _{MLE} )$。</p>
<p>于是当 <span class="math inline">\(L(\hat{\theta} _{MLE; 0}
)\)</span> / $ L( _{MLE} )$ 接近于 <span class="math inline">\(1\)</span> 时，<span class="math inline">\(H_0\)</span> 更有可能是对的；如果 <span class="math inline">\(L(\hat{\theta} _{MLE; 0} )\)</span> / <span class="math inline">\(L(\hat{\theta} _{MLE} )\)</span> 距离 <span class="math inline">\(1\)</span> 比较远，就更有可能是错的。</p></li>
<li><p>记 likelihood ratio 为 <span class="math inline">\(\lambda (x) =
L(\hat{\theta} _{MLE; 0} )\)</span> / <span class="math inline">\(L(\hat{\theta} _{MLE} )\)</span> ，于是当 <span class="math inline">\(\lambda(x)&lt;\lambda_0\)</span> 时 reject <span class="math inline">\(H_0\)</span>，其中 <span class="math inline">\(\lambda_0\)</span> 是一个等待被决定的常数。</p>
<p>决定这个常数的过程和上一讲的操作基本上是一样的。一般来说，我们会把
reject <span class="math inline">\(H_0\)</span> 的条件等价地写成：<span class="math inline">\(-2 log \lambda &gt; C(=-2log
\lambda_0)\)</span>，然后对于 continuous / discrete distribution
进行讨论。</p>
<p>对于 non-randomized test，<span class="math inline">\(\varphi (x) =
I_{\lbrace \lambda &lt; \lambda_0 \rbrace}\)</span>，考虑 <span class="math inline">\(\pi(x) = E_\theta \varphi(X) \leq
\alpha\)</span>。</p>
<p>对于 randomized test，在 <span class="math inline">\(\lambda=\lambda_0\)</span> 处插入 <span class="math inline">\(\varphi(x)=r\)</span>，<span class="math inline">\(r\)</span> 是一个 <span class="math inline">\((0,1)\)</span> 上的值即可。</p></li>
</ul>
<h2 id="单-population-上样本的-lrt">单 Population 上样本的 LRT</h2>
<p><img src="https://s2.loli.net/2022/12/15/MjSnHVXGrFRKC5e.jpg" alt="1.jpg"></p>
<h2 id="单-normal-distribution-上样本的-lrt">单 Normal Distribution
上样本的 LRT</h2>
<p><img src="https://s2.loli.net/2022/12/15/6dSaf9e4kvFW2OR.jpg" alt="2.jpg"></p>
<h2 id="双-normal-distribution-上样本的-lrt">双 Normal Distribution
上样本的 LRT</h2>
<p>饶了我罢。</p>
<p>PPT 第 27-36 页，自行查阅，此处略过。</p>
<h2 id="limiting-distribution-of-lr">Limiting Distribution of LR</h2>
<ul>
<li><p>如果 <span class="math inline">\(\Theta\)</span> 的维度为 <span class="math inline">\(k\)</span> 严格大于 <span class="math inline">\(\Theta_0\)</span> 的维度 <span class="math inline">\(s\)</span>，分布的 PDF
符合正则条件，则对于检验问题 <span class="math inline">\(H_o:\theta \in
\Theta_0 \leftrightarrow H_1 : \theta \in \Theta_1\)</span>，在 <span class="math inline">\(H_0\)</span> 条件下，当 <span class="math inline">\(n \to \infty\)</span> 时有 <span class="math inline">\(-2log \lambda(X) \to \chi _t ^2\)</span>
依分布收敛，<span class="math inline">\(t=n-s\)</span>。</p></li>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/12/15/fBSli5xwI4Kt2Jh.jpg" alt="3.jpg"></p></li>
<li><p>总的来说，对于一个大样本，我们对 <span class="math inline">\(H_0:\theta \in \Omega_0 \leftrightarrow H_1:\theta
\notin \Omega_0\)</span> 进行 LRT 时，LR 即为 <span class="math inline">\(\lambda=\frac{max_{\theta \in \Omega_0}
L(\theta)}{max_{\theta \in \Omega} L(\theta)}\)</span> 且使得 <span class="math inline">\(-2log\lambda \to \chi_t ^2\)</span>。于是 reject
<span class="math inline">\(H_0\)</span> 的条件即为 <span class="math inline">\(-2log \lambda&gt;-2log \lambda_0=\chi_{t,\alpha}
^2\)</span>，由此可以确定 <span class="math inline">\(\lambda_0\)</span>。</p></li>
<li><p>Application: (Hardy-Weinberg equilibrium) 一个基因可以表达为
<span class="math inline">\(A\)</span> 或者 <span class="math inline">\(a\)</span>，组合成为 <span class="math inline">\(AA,Aa,aa\)</span>
之一。对于观察到的基因样本，我们已知一个样本量为 <span class="math inline">\(n\)</span> 的样本中每种基因的个数，记为 <span class="math inline">\(N_{AA},N_{Aa},N_{aa}\)</span>。希望通过这一数据，推算出基因表达为
<span class="math inline">\(A\)</span> 的概率 <span class="math inline">\(\theta\)</span>。（以我高一上学期生物期中考试 42
分的水平勉强表达完了题面，真不懂这个东西）考虑如下：</p>
<ul>
<li><p>Hardy-Weinberg equilibrium 的 null hypothesis 为：<span class="math inline">\(H_0: p_{AA}=\theta^2\)</span>，<span class="math inline">\(p_{Aa}=2\theta (1-\theta)\)</span>，<span class="math inline">\(p_{aa}=(1-\theta)^2\)</span> 对某个 <span class="math inline">\(\theta \in (0,1)\)</span> 成立。对应的 alternative
hypothesis 即为 otherwise。用 LRT 进行检验：</p></li>
<li><p><span class="math inline">\(\Theta_0=\lbrace
(p_{AA},p_{Aa},p_{aa} )| p_{AA}=\theta^2\)</span>，<span class="math inline">\(p_{Aa}=2\theta (1-\theta)\)</span>，<span class="math inline">\(p_{aa}=(1-\theta)^2 \rbrace\)</span>
是一维的，因为变量实际上只有 <span class="math inline">\(\theta\)</span>。</p>
<p><span class="math inline">\(\Theta=\lbrace (p_{AA},p_{Aa},p_{aa} )|
p_{AA}+p_{Aa}+p_{aa}=1\rbrace\)</span>
是二维的，因为它由一个线性式决定。故 <span class="math inline">\(t=n-s=1\)</span>。</p></li>
<li><p>于是 $ =( { <em>{AA} })^{N </em>{AA} }$ <span class="math inline">\(( \frac{ \hat{p} _{0,Aa} } {\hat{p} _{Aa} }) ^{N
_{Aa} }\)</span> <span class="math inline">\((\frac{\hat{p} _{0,aa} }
{\hat{p} _{aa} } ) ^{N _{aa} }\)</span>。</p></li>
<li><p>Full-model MLE 是 <span class="math inline">\(\hat{p} _{AA}=N
_{AA} /n\)</span>，<span class="math inline">\(\hat{p} _{Aa}=N
_{Aa}/n\)</span>，<span class="math inline">\(\hat{p} _{aa}=N
_{aa}/n\)</span>。</p></li>
<li><p>而 sub-model 的 MLE 可以计算 Likelihood Function 得到，为 <span class="math inline">\(\hat{\theta} =
\frac{2N_{AA}+N_{Aa}}{2n}\)</span>。</p>
<p>对应可求得 <span class="math inline">\(\hat{p}
_{0,AA}\)</span>，<span class="math inline">\(\hat{p}
_{0,Aa}\)</span>，<span class="math inline">\(\hat{p}
_{0,aa}\)</span>，再代入 <span class="math inline">\(-2log\lambda \to
\chi_1 ^2\)</span> 就可以求出 rejection region，是一个 <span class="math inline">\(\chi^2\)</span> 检验的形式。</p></li>
</ul></li>
</ul>
<h2 id="summary-1">Summary</h2>
<p>没想到今天又熬了个通宵学统推，很酣畅淋漓的感觉。问就是生活在东四区。</p>
<p>沃日，修炸掉的 LaTeX 又修了半个小时， 这下快到东三区了。</p>
<p>LRT 的内容其实说白了和费尽心思找 test statistic 的 Hypothesis Test
求法没有区别，最后困难的点还是收敛到了找参数上面。LRT 是借助 level of
significance 以及视 <span class="math inline">\(\lambda(x)\)</span> 为
rejection region 的雏形来找 <span class="math inline">\(\lambda_0\)</span>，上一讲的检验找的是分位数，差不多的事。</p>
<h1 id="lecture-11">Lecture 11</h1>
<p>Hypothesis Test 的最后一讲，关于 Universal Most Powerful
Test，理解起来真的很折磨王。</p>
<h2 id="ump-test">UMP Test</h2>
<ul>
<li><p>Definition：对于某些特定的 hypothesis：<span class="math inline">\(H_0: \theta \in \Theta_0 \leftrightarrow H_1 :
\theta \in \Theta_1\)</span>，如果 power function 在 <span class="math inline">\(\Theta_0\)</span> 上的取值满足 <span class="math inline">\(\beta _{\varphi} (\theta)=E _\theta [\varphi (X)]
\leq \alpha, \forall \theta \in \Theta_0\)</span>，则记 test function
<span class="math inline">\(\varphi(x)\)</span> 是一个 level <span class="math inline">\(\alpha\)</span> test。</p>
<p>此时，记 <span class="math inline">\(\Phi _{\alpha} = \lbrace \forall
\varphi (x): \beta _{\varphi} (\theta) \leq \alpha , \theta \in \Theta_0
\rbrace\)</span> 是一系列满足 power function
的检验，如果其中存在某个检验 <span class="math inline">\(\varphi ^* (x)
\in \Phi _{\alpha}\)</span> 使得对任意的 <span class="math inline">\(\varphi (x)\)</span>，有 power function 在 <span class="math inline">\(\Theta_1\)</span> 上的任意取值也满足 <span class="math inline">\(\beta _{\varphi ^*} (\theta) \geq \beta _{\varphi
} (\theta)\)</span>，那么称检验 <span class="math inline">\(\varphi ^*
(x)\)</span> 是一个 uniformly most powerful level <span class="math inline">\(\alpha\)</span> test。</p>
<p>说人话：对于一些 Type I Error 发生概率不超过 <span class="math inline">\(\alpha\)</span> 的检验，其中 Type II Error
也最小（也就是说 <span class="math inline">\(\beta(\theta)\)</span> 在
<span class="math inline">\(\theta \in \Theta_1\)</span>
上取值总是最大）的那个就是 UMP test。</p></li>
<li><p>Neyman-Pearson Lemma 是一个在双单假设检验中寻找 UMP test
的充要条件。定理叙述为：</p>
<p>对于 Hypothesis <span class="math inline">\(H_0: \theta = \theta_0
\leftrightarrow H_1 : \theta = \theta _1\)</span>，分布对应 PDF 或 PMF
为 <span class="math inline">\(f(x | \theta_i)\)</span>，有某个 test
满足以下条件：</p>
<ul>
<li>如果 <span class="math inline">\(\frac{f(x|\theta _1)}{f(x|\theta
_2)} &gt; k\)</span>，则有 <span class="math inline">\(x \in
D\)</span>，样本在 <span class="math inline">\(H_0\)</span> 的 rejection
region 中。</li>
<li>如果 <span class="math inline">\(\frac{f(x|\theta _1)}{f(x|\theta
_2)} &lt; k\)</span>，则有 <span class="math inline">\(x \in
D^c\)</span>，样本不在 <span class="math inline">\(H_0\)</span> 的
rejection region 中。</li>
<li><span class="math inline">\(\alpha = P _{\theta _0} (X \in D |
H_0)\)</span>，即 Type I Error 发生的概率是 <span class="math inline">\(\alpha\)</span>。</li>
</ul>
<p>其中 <span class="math inline">\(k\)</span> 是某个非负数，<span class="math inline">\(\alpha\)</span> 是设定好的 level of
significance。</p>
<p>于是这个 test 是 UMP level <span class="math inline">\(\alpha\)</span> test。反过来对于一个 UMP
test，也一定满足上述条件，也就是说按照 Likelihood Ratio 的范围来确定
rejection region。</p></li>
<li><p>Neyman-Pearson Fundamental Lemma 是一个关于 discrete distribution
的更详细叙述。</p>
<p>对于 Hypothesis <span class="math inline">\(H_0: \theta = \theta_0
\leftrightarrow H_1 : \theta = \theta _1\)</span>，分布对应 PMF 为 <span class="math inline">\(f(x | \theta_i)\)</span>，样本为 <span class="math inline">\(X=(X_1,...,X_n)\)</span>，于是 test function
记为：<span class="math inline">\(\varphi(x)\)</span> 在 <span class="math inline">\(\frac{f(x|\theta _1)}{f(x|\theta _2)} &gt;
k\)</span> 时取 <span class="math inline">\(1\)</span>，在 <span class="math inline">\(\frac{f(x|\theta _1)}{f(x|\theta _2)} &lt;
k\)</span> 时取 <span class="math inline">\(0\)</span>，在 <span class="math inline">\(\frac{f(x|\theta _1)}{f(x|\theta _2)} = k\)</span>
时取 <span class="math inline">\(r\)</span>。</p>
<p>于是存在 <span class="math inline">\(k&gt;0,0&lt;r&lt;1\)</span>
，使得 <span class="math inline">\(E _{\theta _0} \varphi(X)= P _{\theta
_0} [\frac{f(x|\theta _1)}{f(x|\theta _2)} &gt; k] + r P _{\theta _0}
[\frac{f(x|\theta _1)}{f(x|\theta _2)} = k] = \alpha\)</span> ，这个
test 是所有 level of significance 小于 <span class="math inline">\(\alpha\)</span> 的 test 的 UMP。注意上式是一个在
<span class="math inline">\(H_0\)</span> 下的条件概率，表征 Type I Error
的概率。在具体例子里，我们可以通过这个式子确定 <span class="math inline">\(r\)</span> 的取值。</p>
<p>当然，如果是 continuous distribution，<span class="math inline">\(r=0\)</span>，同样做检验即可。</p></li>
<li><p>Corollary：有三条推论，但是懒得写了。</p>
<ul>
<li><p>对某个 Hypothesis 的 UMP level <span class="math inline">\(\alpha\)</span> test，它的 power function 在 <span class="math inline">\(\Theta_0\)</span> 上取值是 <span class="math inline">\(\alpha\)</span>，所以在 <span class="math inline">\(\Theta_1\)</span> 上大于等于 <span class="math inline">\(\alpha\)</span>。</p></li>
<li><p>关于充分统计量的两条。感觉不太会拿来考试就直接截个屏吧。证明也不难。</p>
<p><img src="https://s2.loli.net/2022/12/17/PBtvDJUlqOhGp3R.png" alt="1.png"></p></li>
</ul></li>
<li><p>Applications：</p>
<ul>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/12/17/RDNvXeBl5baAgzi.png" alt="2.png"></p>
<p>Discussions for Example 1：</p>
<p><img src="https://s2.loli.net/2022/12/17/b4Ffx9P1dA26yqv.png" alt="3.png"></p>
<p><img src="https://s2.loli.net/2022/12/17/FNAmipPtHXabL5S.jpg" alt="4.jpg"></p>
<p>Remark：这个很典型，从单点推广到单侧检验，但是双侧检验是行不通的。</p></li>
<li><p>Example 2：</p>
<p><img src="https://s2.loli.net/2022/12/17/EiyJw6PqGRHsKoC.png" alt="5.png"></p>
<p><img src="https://s2.loli.net/2022/12/17/nQjPt3hoWD7H189.png" alt="6.png"></p>
<p>Remark：因为会做所以就不手写了，截个图当存档。可以当做 UMP 系列中
randomized test 的范本。</p></li>
<li><p>Example 3：</p>
<p><img src="https://s2.loli.net/2022/12/17/86Ri75gPjQSnlfh.png" alt="7.png"></p>
<p><img src="https://s2.loli.net/2022/12/17/g9fpOdqFRrLPitW.jpg" alt="8.jpg"></p>
<p>Remark：最后一问下次再看看。</p></li>
</ul></li>
</ul>
<h2 id="ump-test-问题的常见规约">UMP Test 问题的常见规约</h2>
<p>在上面的 Application Examples 里面我们看到，UMP Test
问题有很多规约情况，可以通过两个单点 hypothesis
先归到一个单点，再推广到双区间情况。也有时候双侧检验不能规约。下面对于一般的情况进行讨论。</p>
<ul>
<li><p><span class="math inline">\(\varphi (x)\)</span> 是 hypothesis
<span class="math inline">\(H_0 : \theta = \theta _0 \leftrightarrow H_1
: \theta = \theta _1 (\theta _1 &gt; \theta _0)\)</span> 的一个 <span class="math inline">\(\alpha\)</span> level 检验。如果 <span class="math inline">\(\varphi(x)\)</span> 的取值不依靠 <span class="math inline">\(\theta _1\)</span> 而存在，则上述 hypothesis
可以推广到 <span class="math inline">\(H_0 : \theta = \theta _0
\leftrightarrow H_1 : \theta &gt; \theta _0\)</span> 形式。</p></li>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/12/17/ZF5RbupI9cnwrXe.png" alt="9.png"></p>
<p><img src="https://s2.loli.net/2022/12/17/bgRXpMVjwQltSus.jpg" alt="10.jpg"></p>
<p>Remark：第二问里面是一个双侧检验，但是 rejection region
仍然是单侧的。说明二者之间没有必然的关系。</p></li>
<li><p>Example 2：</p>
<p><img src="https://s2.loli.net/2022/12/17/S5qMUjbpfxisAvh.png" alt="11.png"></p>
<p><img src="https://s2.loli.net/2022/12/17/oKnPhzvRxJgL5Xp.jpg" alt="12.jpg"></p></li>
<li><p>Summary：做一般复合假设的 MP 的步骤，general hypothesis 记为
<span class="math inline">\(H_0: \theta \in \Theta _0 \leftrightarrow
H_1: \theta \in \Theta _1\)</span>。</p>
<ul>
<li>在 <span class="math inline">\(\Theta _0\)</span> 里寻找一个尽量靠近
<span class="math inline">\(\Theta _1\)</span> 的点 <span class="math inline">\(\theta _0\)</span>，在 <span class="math inline">\(\Theta _1\)</span> 里同样找一个 <span class="math inline">\(\theta _1\)</span>。</li>
<li>按照 NP lemma 来建立一个关于 <span class="math inline">\(H_0: \theta
= \theta _0 \leftrightarrow H_1: \theta =\theta _1\)</span> 的 MP，记为
<span class="math inline">\(\varphi _{\theta _1}\)</span>。</li>
<li>如果 <span class="math inline">\(\varphi _{\theta _1}\)</span> 关于
<span class="math inline">\(\theta _1\)</span> 独立，则它可以扩充到
<span class="math inline">\(H_0: \theta =\theta _0 \leftrightarrow H_1:
\theta \in \Theta _1\)</span> 的 UMP。</li>
<li>想要再扩充到 <span class="math inline">\(H_0: \theta \in \Theta _0
\leftrightarrow H_1: \theta \in \Theta _1\)</span> 的话，需要检验 power
function 在 <span class="math inline">\(\Theta_0\)</span>
里的取值，也即验证 <span class="math inline">\(E _\theta \varphi (X)
\leq \alpha,\theta \in \Theta_0\)</span>。一般来说，如果 power function
是单调的，这个条件比较容易满足，而这在单参数指数分布族中比较常见。</li>
<li>以上方法对单维度参数可行，且要求参数空间在 <span class="math inline">\(R\)</span> 上。分布属于单参数指数分布族。</li>
</ul></li>
<li><p>Fun Fact：实际上是先有了 N-P Lemma，人们才回头构造了 Likelihood
Ratio Test，最后才有最开始学习的 F-test，t-test 之类的东西。</p></li>
</ul>
<h2 id="hypothesis-testing-confidence-interval">Hypothesis Testing &amp;
Confidence Interval</h2>
<p>之前做题的时候一直感觉到这二者之间有关系，下面用定理和一个简单的一菜两吃（x）的例子详细说一下为什么其实是一回事，也作为
hypothesis testing 学习的尾声。</p>
<ul>
<li><p>Example：</p>
<p><img src="https://s2.loli.net/2022/12/17/vyAtcbTPdrGn6Zx.png" alt="13.png"></p>
<p><img src="https://s2.loli.net/2022/12/17/swD64V32gBTZG7t.jpg" alt="14.jpg"></p></li>
<li><p>Summary：实际上我们再看这个过程。以寻找 CI 为例。</p>
<ul>
<li><p>把目标转化为 Test the hypothesis： <span class="math inline">\(H_0: \theta = \theta _0 \leftrightarrow H_1:
\theta \neq \theta _0\)</span>，要求 level of significance 为 <span class="math inline">\(\alpha\)</span>。然后来计算 <span class="math inline">\(\theta\)</span> 的 confidence interval <span class="math inline">\([\hat{\theta} _1 (X),\hat{\theta} _2
(X)]\)</span>，有 confidence level 为 <span class="math inline">\(1-\alpha\)</span>。</p></li>
<li><p>在 <span class="math inline">\(H_0\)</span> 条件下，如果 <span class="math inline">\(\theta \notin [\hat{\theta} _1 (X),\hat{\theta} _2
(X)]\)</span>，我们就 reject <span class="math inline">\(H_0\)</span>。这一概率是 Type I Error 概率：</p>
<p><span class="math inline">\(P(reject | H_0)=P_{\theta _0}(\theta _0
\notin [\hat{ \theta } _1 (X), \hat { \theta } _2 (X) ]) = 1 - P _{
\theta _0} ( \theta _0 \in [\hat{ \theta} _1 (X),\hat{ \theta} _2 (X)])
= \alpha\)</span></p></li>
<li><p>所以 <span class="math inline">\([\hat{\theta} _1
(X),\hat{\theta} _2 (X)]\)</span> 是一个以 confidence level <span class="math inline">\(1-\alpha\)</span> 的 confidence interval</p></li>
</ul>
<p>寻找 upper confidence limit 则检验 hypothesis：<span class="math inline">\(H_0: \theta \geq \theta _0 \leftrightarrow H_1:
\theta &lt; \theta _0\)</span>；</p>
<p>寻找 lower confidence limit 则检验 hypothesis：<span class="math inline">\(H_0: \theta \leq \theta _0 \leftrightarrow H_1:
\theta &gt; \theta _0\)</span>。</p></li>
<li><p>Theorem 1：对任意的 <span class="math inline">\(\theta \in
\Theta\)</span>，有一个 hypothesis <span class="math inline">\(H_o:\theta = \theta _0\)</span> 的检验，它的 level
of significance 是 <span class="math inline">\(\alpha\)</span>，而 <span class="math inline">\(H_0\)</span> 的 acceptance region 是 <span class="math inline">\(A(\theta _0)\)</span>。于是集合 <span class="math inline">\(C(X)= \lbrace \theta : X \in A(\theta)
\rbrace\)</span> 是一个以 <span class="math inline">\(1-\alpha\)</span>
为 confidence level 的 confidence region for <span class="math inline">\(\theta\)</span>。</p></li>
<li><p>Theorem 2：<span class="math inline">\(C(X)\)</span> 是一个以
<span class="math inline">\(1-\alpha\)</span> 为 confidence level 的
confidence region for <span class="math inline">\(\theta\)</span>，也就是对任意 <span class="math inline">\(\theta _0 \in C(X)\)</span>，有 <span class="math inline">\(P[\theta _0 \in C(X) | \theta = \theta _0] = 1-
\alpha\)</span>。于是 hypothesis <span class="math inline">\(H_0 :
\theta = \theta _0\)</span> 的 acceptance region 是 <span class="math inline">\(A(\theta _0)=\lbrace X : \theta _0 \in C(X)
\rbrace\)</span>，这一 test 的 level of significance 是 <span class="math inline">\(\alpha\)</span>。</p></li>
</ul>
<h2 id="extended-content">Extended Content *</h2>
<p>总之就是好玩的东西。</p>
<h3 id="monotone-likelihood-ratio">Monotone Likelihood Ratio</h3>
<p>对于某个 sample 的充分统计量 <span class="math inline">\(T(X)\)</span>，考虑关于它的检验使得以 <span class="math inline">\(T(x)\)</span> 为 rejection region 的度量。</p>
<h3 id="ump-in-exponential-family">UMP in Exponential Family</h3>
<ul>
<li><p><span class="math inline">\(X_1,X_2,...,X_n\)</span> 是一组来自
exponential family 的 random sample，它们的 population 服从一个以 $f(x;)
= C() h(x) exp(Q() T(x)) $ 为 PDF 的 distribution。其中，<span class="math inline">\(Q(\theta)\)</span> 是严格单调的。由 exponential
family 的性质，我们记 <span class="math inline">\(V(x_1,...,x_n) =
\Sigma _{i=1} ^n T(x_i)\)</span> 为一个 sufficient statistic。</p>
<p>如果 <span class="math inline">\(Q(\theta)\)</span> 严格递增，考虑
hypothesis <span class="math inline">\(H_0: \theta \leq \theta _0
\leftrightarrow H_A : \theta &gt; \theta _0\)</span>，UMP test 的形式由
test function 给出： <span class="math inline">\(V(x_1,...,x_n)&gt;C\)</span> 时 <span class="math inline">\(\varphi (x_1,...,x_n) = 1\)</span>，<span class="math inline">\(V(x_1,...,x_n)&lt;C\)</span> 时 <span class="math inline">\(\varphi (x_1,...,x_n) = 0\)</span>， <span class="math inline">\(V(x_1,...,x_n) = C\)</span> 时 <span class="math inline">\(\varphi (x_1,...,x_n) = \gamma\)</span>。根据
level of significance 是 <span class="math inline">\(\alpha\)</span>，可以确定出 <span class="math inline">\(\gamma\)</span> 的取值。</p>
<p>hypothesis 的形式为 <span class="math inline">\(H_0: \theta \geq
\theta _0 \leftrightarrow H_A : \theta &lt; \theta _0\)</span>
的做法类似，<span class="math inline">\(Q(\theta)\)</span>
单调递减时的操作也类似。</p></li>
<li><p>可以这么做的原因是，这和使用 likelihood function
的结果是一样的。</p>
<p>先考虑单点 hypothesis <span class="math inline">\(H_0: \theta =
\theta _0 \leftrightarrow H_A : \theta = \theta _1(\theta _1 &gt; \theta
_0)\)</span>，此时有 <span class="math inline">\(\lambda (x)=\frac{f(x;
\theta _1)} {f(x; \theta _0)}\)</span> 是关于 <span class="math inline">\(V(x)\)</span> 严格单调的，由此可以给出单点处的 MP
Test，它不依赖于 <span class="math inline">\(\theta _1\)</span>，可以把
<span class="math inline">\(H _A\)</span> 延拓到 <span class="math inline">\(\theta &gt; \theta _0\)</span>。而 power function
在 <span class="math inline">\(\Theta _0\)</span> 上是关于 <span class="math inline">\(\theta\)</span> 单调的，可以再把 <span class="math inline">\(H_0\)</span> 延拓到 <span class="math inline">\(\theta \leq \theta _0\)</span>。</p></li>
<li><p>Example 1：The Binomial Case</p>
<p><img src="https://s2.loli.net/2022/12/17/ZO2Bn9E4PWrMdtc.png" alt="15.png"></p>
<p><img src="https://s2.loli.net/2022/12/17/2jpb3uU1qEtGl5L.png" alt="16.png"></p>
<p><img src="https://s2.loli.net/2022/12/17/rwAIq67U5Jl9FsK.png" alt="17.png"></p></li>
</ul>
<h1 id="homework-6">Homework 6</h1>
<p>破事挺多啊</p>
<p>助教在干啥助教为什么不批作业了（</p>
<h1 id="lecture-12">Lecture 12</h1>
<p>最后一课，介绍一些分布未知时的处理方法，称为非参数检验。</p>
<h2 id="sign-test">Sign Test</h2>
<ul>
<li><p>对于 paired data 的检验。</p>
<p>假定 <span class="math inline">\(X=(X_1,...,X_n),Y=(Y_1,...,Y_n)\)</span>
是已知的两组数据，希望知道二者之间有没有显著差异，即 hypothesis 为 <span class="math inline">\(H_0: \mu = 0 \leftrightarrow H_1 : \mu \neq
0\)</span>，其中记 <span class="math inline">\(Z_i = Y_i - X_i,\mu =
E(Z_i)\)</span>。</p>
<p>实际上我们也可以通过 two sample t test 进行操作，假设 <span class="math inline">\(X,Y\)</span>
是正态分布的。但是这样做精度不高，而且无法突出两组数据的特征，尤其是在有明显偏离的数据上，non-parametric
test 表现更好。</p>
<p>说回主题，在 sign test 中我们可以赋予每一个 data 一个 sign
值，以祈这一组 sign 值近似于某一分布。最简单的方式就是按照 data
的正负性来赋值，记 <span class="math inline">\(n_+\)</span> 为 sign
的正值数量，<span class="math inline">\(n_-\)</span> 为负值数量，舍弃
<span class="math inline">\(0\)</span> 值。于是有 <span class="math inline">\(n_0 = n_+ + n _-\)</span>，且 <span class="math inline">\(n_+ \sim B( n_0 , \theta)\)</span>，原假设即转化为
<span class="math inline">\(H_0 : \theta = 0.5 \leftrightarrow H_1 :
\theta \neq 0.5\)</span>，变成了熟悉的检验形式。</p></li>
<li><p>Example for paired test</p>
<p><img src="https://s2.loli.net/2022/12/22/FjSmXYCIPRvQHwD.png" alt="1.png"></p>
<p><img src="https://s2.loli.net/2022/12/22/vudYjS1GK7eBEq4.png" alt="2.png"></p></li>
<li><p>Test median of population</p>
<p>通过一个样本来找某一 population 的中位数，也可以通过 sign test
进行，放一个例子在这里，就不细说了。</p>
<p><img src="https://s2.loli.net/2022/12/22/b5DGMflA1I9SKti.png" alt="3.png"></p>
<p><img src="https://s2.loli.net/2022/12/22/sI5GdYKJR3P7Dbv.png" alt="4.png"></p>
<p>Remark：实际上在这个例子里，取 median 为 1.39 也不影响检验结果。sign
test 对具体数据的表现能力较弱，实际上是 low power 的。</p></li>
</ul>
<h2 id="wilcoxon-signed-rank-sum-test">Wilcoxon Signed Rank Sum
Test</h2>
<p>这个东西很好玩，但是考试暂时不考，码的成分又比较大，而且理论部分我想后面再研究研究再写，先跳过了。</p>
<h2 id="goodness-of-fit-test">Goodness of Fit Test</h2>
<p>难得遇到一个我早就考虑过的问题，大概是高一上生物课的时候，讲孟德尔种豌豆发现某些基因表达的比例大概是
<span class="math inline">\(9:3:3:1\)</span>。我就很好奇这个是怎么近似出来的，你总不能只告诉我“看着很像”吧。Goodness
of fit test 大概就是解决这一类问题。</p>
<ul>
<li><p>设 <span class="math inline">\(X=(X_1,...,X_n)\)</span>
是来自某一 population 的随机样本，<span class="math inline">\(F\)</span>
是一个给定的分布，也叫做 theoretical distribution，我们想要验证 <span class="math inline">\(H_o: X \sim F\)</span> 这一假设。</p>
<p>首先我们需要进行一些量化，来反映某个 statistic 什么情况下能代表 <span class="math inline">\(X \sim F\)</span>。也就是说，要定义一个 quantity
<span class="math inline">\(D=D(X_1,X_2,...,X_n,F)\)</span> 使得在 <span class="math inline">\(D \geq c\)</span> 时 reject <span class="math inline">\(H_0\)</span>。这时定义 goodness-of-fit 的程度为
<span class="math inline">\(p(d_0) = P(D \geq d_0 | H_0)\)</span>，<span class="math inline">\(d_0\)</span> 是确切样本下 <span class="math inline">\(D\)</span> 的观测值。</p></li>
<li><p>Pearson <span class="math inline">\(\chi ^2\)</span> test for
discrete F</p>
<p>令 <span class="math inline">\(X=(X_1,X_2,...,X_n)\)</span> 是
population <span class="math inline">\(X\)</span>
中的一个随机样本，theoretical distribution <span class="math inline">\(F\)</span> 为一个离散分布，其 PMF 为 <span class="math inline">\(f(a_i)=p_i,\Sigma _{i=1} ^r p_i =1\)</span>。于是
hypothesis 转化为 <span class="math inline">\(H_0: P(X=a_i) =
p_i,i=1,2,...,r\)</span>。</p>
<p>记 <span class="math inline">\(v_i\)</span> 是样本中观察到的 <span class="math inline">\(a_i\)</span> 的出现次数，于是 <span class="math inline">\(\Sigma _{i=1} ^r v_i= n\)</span>，<span class="math inline">\(v_i\)</span> 是自然数。在 <span class="math inline">\(H_0\)</span> 条件下，当 <span class="math inline">\(n\)</span> 足够大时，有频率 <span class="math inline">\(\frac { v_i }{n} \to p_i\)</span>。于是我们用
<span class="math inline">\(K_n = \Sigma _{i =1} ^r c_i (\frac {v_i}{n}
-p_i) = \Sigma _{i=1} ^r \frac{(v_i - np_i) ^2}{np_i }\)</span>
作为衡量的指标，其中的系数 <span class="math inline">\(c_i = \frac{n}
{p_i }\)</span>。</p>
<p>这一指标的好处在于，在 <span class="math inline">\(H_0\)</span>
条件下，当 $n $ 时有 <span class="math inline">\(K_n \to \Chi _{r-1}
^2\)</span>。所以称为 Pearson <span class="math inline">\(\chi
^2\)</span> test。</p></li>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/12/22/AVR9xkrwIlMyNhm.png" alt="5.png"></p></li>
<li><p>Pearson <span class="math inline">\(\chi ^2\)</span> test for
continuous F</p>
<p>这和数值分析里面那个差分技巧还挺像的，分割区间然后强行转成 discrete
distribution 就可以了。取 <span class="math inline">\(r-1\)</span>
个常数 <span class="math inline">\(a_0 = -\infty &lt; a_1 &lt; a _2
&lt;...&lt; a _{r-1} &lt; + \infty = a _r\)</span>，就把区间分割成了
<span class="math inline">\(r\)</span> 段（注意它们的起和止，除了 <span class="math inline">\(I_r\)</span> 之外都是左开右闭的）：<span class="math inline">\(I _1 = (- \infty , a _1], I_2 = (a_1, a_2],..., I
_r = (a _{r-1} , \infty)\)</span>。再记 <span class="math inline">\(p_j
= P _F(X \in I_j) = F(a_j) - F(a _{j-1})\)</span> 即可做出假设：<span class="math inline">\(H_0 : P(X \in I_j) =
p_j,j=1,2,...,r\)</span>。</p>
<p>类似地给出衡量指标 <span class="math inline">\(K_n = \Sigma _{i =1}
^r c_i (\frac {v_i}{n} -p_i) = \Sigma _{i=1} ^r \frac{(v_i - np_i)
^2}{np_i }\)</span>，在 <span class="math inline">\(H_0\)</span>
条件下，当 $n $ 时有 <span class="math inline">\(K_n \to \Chi _{r-1}
^2\)</span>。</p>
<p>Remark：可以看到这个操作的近似程度做得比较多，所以有几点注意事项。</p>
<ul>
<li>关于 <span class="math inline">\(r\)</span>
的选择。理论上和实际观测到的 frequency <span class="math inline">\(v_i\)</span> 不能小于 <span class="math inline">\(5\)</span>，否则应当合并相邻的区间。</li>
<li>不能根据得到的 sample 来划定 <span class="math inline">\(a_i\)</span>，这是没有普遍性的。</li>
<li>实际上因为左右端是取到无穷的，这一区间的选择方式可能带来一定问题。</li>
</ul></li>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/12/22/WgijzPlQUxEtbrm.png" alt="6.png"></p>
<p><img src="https://s2.loli.net/2022/12/22/4oz78PmgXJ3qxfn.png" alt="7.png"></p>
<p><img src="https://s2.loli.net/2022/12/22/waBlU8TnIVEYibs.png" alt="8.png"></p>
<p>Remark：可以看到这里 Pearson 指标的近似分布是 <span class="math inline">\(\chi ^2 _3\)</span> 而不是 <span class="math inline">\(\chi ^2 _5\)</span>，这是因为此处的 theoretical
distribution 参数也是未知的，是通过 MLE
方法估计出来的。在这种情况下，Pearson 指标将收敛到 <span class="math inline">\(\chi ^2 _{r-s-1}\)</span>，其中 <span class="math inline">\(s\)</span> 是未知参数的数目。</p></li>
</ul>
<h2 id="contingency-table-independence">Contingency Table
Independence</h2>
<p>另一种问题，种豌豆的时候每一次收获的结果必然有数值上的差异，（开始认真地编数据），比如说第一次是
<span class="math inline">\(213 : 76 : 69 : 25\)</span>，第二次是 <span class="math inline">\(254 : 85 : 89 :
32\)</span>，那么凭什么说它们都反映了同样的比例？</p>
<p>我们称 <span class="math inline">\(10\)</span>
次采集豌豆统计出来的表格为 contingency table，contingency
为偶然的意思，称这种检验为 homogeneity test，即为同质性检验。（词汇量
++！（</p>
<ul>
<li><p>实际上，我们用一个高维的 <span class="math inline">\(\chi
^2\)</span> 检验来解决问题。Contingency table 的形式如下：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Category 1</th>
<th>...</th>
<th>Category C</th>
<th><span class="math inline">\(\Sigma\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Group 1</td>
<td><span class="math inline">\(N_{11}\)</span></td>
<td>...</td>
<td><span class="math inline">\(N_{1C}\)</span></td>
<td><span class="math inline">\(N_{1+}\)</span></td>
</tr>
<tr class="even">
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td>Group R</td>
<td><span class="math inline">\(N_{R1}\)</span></td>
<td>...</td>
<td><span class="math inline">\(N_{RC}\)</span></td>
<td><span class="math inline">\(N_{R+}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\Sigma\)</span></td>
<td><span class="math inline">\(N_{+1}\)</span></td>
<td>...</td>
<td><span class="math inline">\(N_{+C}\)</span></td>
<td><span class="math inline">\(n\)</span></td>
</tr>
</tbody>
</table>
<p>记 <span class="math inline">\(p_{ij} = P(Category_j | Group _i) =
\frac{N _{ij} }{N _{i+} }\)</span>，于是有 <span class="math inline">\(\Sigma _{j=1} ^C p_{ij} = \Sigma _{i=1} ^R p_{ij}
= 1\)</span>。比较粗暴地来说，我们想要确定每一组 <span class="math inline">\(p_{ij}=p_j\)</span> 对任意的 <span class="math inline">\(i\)</span> 都是成立的，而 <span class="math inline">\(p_j = P(category _j)\)</span>。</p>
<p>所以假设可以写成：$H_0 : p_{ij} = p_j $ 对任意的 <span class="math inline">\(i \leq R\)</span> 都成立。此时 Pearson
指标可以写成：</p>
<p><span class="math inline">\(\Sigma _{i=1} ^R \Sigma _{ j=1 } ^C
\frac{(N _{ij} - N _{i+}N _{+j} /n) ^2} {N _{i+}N _{+j} /n} = n (\Sigma
_{i=1} ^R \Sigma _{ j=1 } ^C \frac{N_{ij} }{N_{i+} N_{+j}} - 1) \to \chi
_{(R-1)(C-1)} ^2\)</span>，这一近似在 <span class="math inline">\(R,S\)</span> 较大且符合 <span class="math inline">\(H_0\)</span> 假设的情况下是成立的。</p></li>
<li><p>Example 1：</p>
<p><img src="https://s2.loli.net/2022/12/22/Q9mAFDdYZUxPv6w.png" alt="9.png"></p></li>
</ul>
<h2 id="normality-test">Normality Test</h2>
<p>和 Wilcoxon Test 类似的原因，暂时先咕了</p>
<h2 id="summary-2">Summary</h2>
<p>Non-parametric Test
应用范围更广，毕竟一般都不知道是什么分布；在大样本情况下表现较好。</p>
<p>Parametric Test 的 model assumption
正确时精度很高，但是泛用性不够强。</p>
<h1 id="完结撒花">完结撒花</h1>
<p>证明和代码都还没有补齐，暂时称不上证明完毕。但是以考试为目标的应用部分完结了，目前称得上一个夜话团圆。</p>
<p><img src="https://s2.loli.net/2022/12/21/6TEM1vSosXLcwOg.jpg" alt="HEA.jpg"></p>
<h1 id="final">Final</h1>
<p>一些简单的提示。</p>
<ul>
<li><p>在正态分布 <span class="math inline">\(X_1,X_2,...,X_n i.i.d.
\sim N(\mu ,\sigma ^2)\)</span> 里，一些常用于检验的统计量及其分布：</p>
<ul>
<li><p><span class="math inline">\(\frac{\sqrt{n} (\bar{X} - \mu
)}{\sigma} \sim N(0,1)\)</span>，利用正态分布的线性性质即可。</p></li>
<li><p>记 sample mean 为 <span class="math inline">\(S^2 = \frac{1}{n-1}
\Sigma _{i=1} ^n (X_i - \bar{X})^2\)</span>，于是有 <span class="math inline">\(\frac{(n-1)S^2} {\sigma ^2} \sim \chi _{n-1}
^2\)</span>。</p>
<p>另一个 Chi-square 分布是 <span class="math inline">\(\frac{nS _{\mu}
} {\sigma ^2} = \Sigma _{i=1} ^n (\frac{X_i - \mu}{\sigma})^2 \sim \chi
^2 _{n}\)</span>。注意区分 <span class="math inline">\(S_\mu\)</span> 和
<span class="math inline">\(S\)</span> 的区别，前者实际上是 2-nd center
moment，后者是 sample variance。</p></li>
<li><p>以上计算都比较依赖 <span class="math inline">\(\sigma\)</span>，实际上 <span class="math inline">\(\frac{\sqrt{n} (\bar{X} - \mu)}{S} \sim
t_{n-1}\)</span>，由 <span class="math inline">\(t-\)</span>
分布的构造可以得出。</p></li>
<li><p>大数定律下，sample variance <span class="math inline">\(S \to
\sigma\)</span>。</p></li>
</ul></li>
<li><p>经典的 CI 估计</p>
<ul>
<li><p>单 population 下 <span class="math inline">\(X=(X_1,X_2,...,X_n)
i.i.d. \sim N(\mu ,\sigma ^2)\)</span>，四种估计：</p>
<p><span class="math inline">\(\mu\)</span> 已知，估计 <span class="math inline">\(\sigma\)</span>，pivot statistic 为 <span class="math inline">\(\frac{nS _{\mu} } {\sigma ^2} = \Sigma _{i=1} ^n
(\frac{X_i - \mu}{\sigma})^2 \sim \chi ^2 _{n}\)</span></p>
<p><span class="math inline">\(\mu\)</span> 未知，估计 <span class="math inline">\(\sigma\)</span>，pivot statistic 为 <span class="math inline">\(\frac{(n-1)S^2} {\sigma ^2} \sim \chi _{n-1}
^2\)</span></p>
<p><span class="math inline">\(\sigma\)</span> 已知，估计 <span class="math inline">\(\mu\)</span>，pivot statistic 为 <span class="math inline">\(\frac{\sqrt{n} (\bar{X} - \mu )}{\sigma} \sim
N(0,1)\)</span></p>
<p><span class="math inline">\(\sigma\)</span> 未知，估计 <span class="math inline">\(\mu\)</span>，pivot statistic 为 <span class="math inline">\(\frac{\sqrt{n} (\bar{X} - \mu)}{S} \sim
t_{n-1}\)</span></p></li>
<li><p>双 population 下 <span class="math inline">\(X=(X_1,...,X_m)
i.i.d. \sim N(\mu _1,\sigma _1 ^2)\)</span>，<span class="math inline">\(Y=(Y_1,...,Y_n)i.i.d. \sim N(\mu _2,\sigma _2
^2)\)</span>，四个参数都未知时的四种估计：</p>
<p><span class="math inline">\(\sigma _1 ^2 = \sigma _2 ^2 = \sigma
^2\)</span> 时估计 <span class="math inline">\(\mu_1 - \mu
_2\)</span></p>
<p><span class="math inline">\(\sigma _1 \neq \sigma _2\)</span>
时渐进估计 <span class="math inline">\(\mu_1 -\mu_2\)</span> 和 <span class="math inline">\(\sigma _1 ^2 / \sigma _2 ^2\)</span></p></li>
</ul></li>
<li><p>Precision（精确度）：有很多种估计方法，此处取最常用的方法：mean
interval length，即计算 <span class="math inline">\(E_{\theta}(\hat{\theta_2}-\hat{\theta
_1})\)</span>，这个值越大说明区间越长，因此估计的精确度越差。</p>
<p>还有 confidence coefficient 的定义。</p></li>
</ul>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>统计</tag>
        <tag>课程实录</tag>
        <tag>刷书</tag>
      </tags>
  </entry>
  <entry>
    <title>京京京京津津津津</title>
    <url>/2024/01/27/Tianjin/</url>
    <content><![CDATA[<p>京坏，津好；人坏，猫好（</p>
<p>咕了好久啊（（</p>
<span id="more"></span>
<p>我出门旅游一般都是随机进行一个街溜子啊不是 city
walk（，出发之前除了看看有没有想吃的东西之外基本不会有什么准备。不过冬天就是很适合到处随便吃吃逛逛走走，尤其是在北方，回了上海之后天天下雨都不是很想出门，所以就挺好的。</p>
<p>出发前一天晚上在和何老板以及他 npy
一起开美赛准备会，得出的结论是我们哪个题都不是很能做，急。我顺便提了一句后面两天要去天津玩可能不是很有时间准备，然后他问我为什么天津要玩两天，我当时还不明白这句话什么意思，事后证明他是对的（</p>
<h1 id="吃点啥">吃点啥</h1>
<p>省流：娜娜家便宜好吃，快去吃。</p>
<p>都是在商场里吃的，残念的是在天津待了两天日均睡到中午起床，没吃到早点。不过我来天津之前一位南开的热心网友曾经锐评过：</p>
<blockquote>
<p>哦对了突然想起来</p>
<p>天津三绝（十八街麻花，耳朵眼炸糕，狗不理包子）前俩都还好
狗不理包子千万别去（）</p>
<p>就是要是去尝尝炸糕 带点麻花回去 这都是支持的 但是这狗不理包子可绝对
nm——</p>
</blockquote>
<p>都没吃（挠头，<del>但也没踩雷，好好好</del>。</p>
<h2 id="梨花牛肉汤">梨花牛肉汤</h2>
<p>普通的还不错。但我有点怀疑是不是在京沪待久了被 PUA 惯了，两个人 90
左右吃一顿类似（实际上可能也是）预制菜和料理包的饭我竟感觉好便宜。拌饭酱是直接给了包装好的酱包而不是拌在饭里端上来，就当是它让我自己控制咸淡，我哭死（</p>
<p>金针菇肥牛好吃，有点偏甜口，感觉比熙春园做的好吃。题外话，大一的时候（学业）导师聚餐都是在熙春园，我每次都还挺期待的
<del>毕竟难得吃顿好的</del>，直到有一次她问我要不要点一道本帮菜试试，我点了个排骨年糕，就（（</p>
<p>招牌牛肉汤拌饭反正我是没吃出来哪里值得作为招牌了（，不过加的小菜都很便宜，好评。</p>
<p>到天津的第一天晚上吃了这家，实际上是打算去吃娜娜家，结果被高德地图骗到了东马路仁恒伊势丹之后才知道这里没有这家店（下详），总之就是走错了。</p>
<p>门口迎宾的小姐姐非常可爱，可以说是走进这家店的理由之一（</p>
<h2 id="娜娜家-nana-and-her-friends-restaurant">娜娜家 Nana and Her
Friends Restaurant</h2>
<p>听名字就很好吃（，是以前下饭的时候在神奇海挪的<a href="https://www.bilibili.com/video/BV1Nj411n7BN/">天津旅游 vlog</a>
知道的，这个 vlog
我来天津之前还复习了一遍，但还是只记住了娜娜家，所以就去吃了。</p>
<p>到天津的第一天晚上想吃这个，用高德导航了一下最近的一家店在东马路仁恒伊势丹
F7，去了发现这边最高是五层根本没有七楼，在百度地图和大众点评确认了一下发现是在和平区的仁恒伊势丹
C 座
F7，太坏了。我后来给高德上报了地点错误，然而它让我去现场拍照片补充内容，一来我是来旅游的不想同一个地方去两遍，二来我也有点想不通要怎么通过拍照证明这里没有这家店，就算了，如果有天津本地的朋友愿意帮忙的还请再想想办法（</p>
<p>听说这家的焦糖脆皮照烧柠檬鸡非常好吃就点了一份，菌菇汤自然哪里的都不会难喝，又加了一份薯条和两份饭，总价是
161，结果实实在在地吃撑了。我是前段时间突然想到我常去的几个华子的食堂都没有咖喱饭，也不知道哪里有，这次看到店里有就随手点了一份。然而不知道是不是因为你沪餐厅饭量全都是
omakase
式的，价格也是存在汇率的，总之我对正常的量和价位有严重的错估，这家店一份主食几乎是够两个人吃的。</p>
<p>柠檬鸡确实不错，但我感觉鸡肉本身除了贴着柠檬所以有淡淡的柠檬香气之外就没怎么入味（也确实很难，但焦糖脆皮做得很好吃，和柠檬香搭在一起味道很丰富。菌菇汤里本来就有切片的法棍，吃过之后我就对点餐量有隐隐的担忧了，直到我的咖喱饭上来之后发现担忧是完全正确的。薯条量很大但甚至只要
12
块钱一份，现炸的非常好吃但没吃完就打包了，肯○基麦○劳应该感到愧疚。</p>
<p>进店的时候是下午两点，这家是两点半闭餐，两点半到四点半是下午茶，不过两点钟人也还很多。很急地点餐的时候还在想可以到下午茶的时间再点甜品，结果吃撑了完全忘记了这回事，甚至都没看下午茶有啥。不过用小程序远程看了下感觉小贵，和星○克差不多或更贵，又变成了熟悉的价位（。</p>
<p>打包是免费的，纸袋和打包盒上都有插画，很精致。一开始以为湿巾的包装和纸巾上写的都是
have a good day，实际上是 have a food day，想起来初中的时候我还把 Luna
Lovegood 改成 Luna Lovefood 然后给自己起英文名叫 Luna 什么的（。</p>
<p>省流就是强推，好吃不贵。</p>
<h2 id="海底捞">海底捞</h2>
<p>为什么旅游要吃这个，是没东西吃了吗（<del>是的（</del></p>
<p>这边海底捞送的小零食是真的多，提了一大袋回去，粗粗一数有 15
包（（</p>
<p>在海底捞顺便把从娜娜家打包的薯条和柠檬鸡吃了，然而薯条软掉了，轻微伤心（</p>
<p>顺带一提这个海底捞在<a href="https://surl.amap.com/cOi0qo175JR">天津陆家嘴中心</a>，旁边的广场叫<a href="https://surl.amap.com/d1b7aAo3x3">陆家嘴金融广场</a>，导航看到的时候好疑惑，我是一键传送回家了吗（。走过去的时候从正门进去看到一家
4S
店，看着好大啊还在一楼好有钱——还在这么想的时候发现是华为，虽然合理但疑惑（二度</p>
<h2 id="好利来">好利来</h2>
<p>这算正餐吗，不算，但是当正餐吃了（</p>
<p>下单的时候还是芒果蛋糕，后来店员说只有草莓的了，送到有点图片和实物不符，在路上有点颠坏了，一些草莓掉到了盒子里，周围的白巧克力也碎了。它应该长下面这样但它确实不长这样，总之谢谢店员拍照，就当长这样了（。</p>
<p><img src="https://s2.loli.net/2024/01/30/s7teUYDA2acu5lk.jpg" alt="cake.jpg"></p>
<p>给欧老师唱了猫猫生日歌：</p>
<blockquote>
<p>喵喵 ~ 喵喵 ~ 喵喵，</p>
<p>喵喵 ~ 喵喵 ~ 喵喵，</p>
<p>喵喵喵 <span class="math inline">\(\uparrow\)</span> 喵喵 ~ 喵喵
~，</p>
<p>喵喵 ~ 喵喵 ~ 喵喵 ~</p>
</blockquote>
<p>得到了好评和贴贴，好哦。</p>
<p>事实上我以为布歌东京的四寸蛋糕会比这个大一些就没买，在大悦城实体店看的时候感觉也没大很多，而且这个也没说明尺寸，就下次一定了。</p>
<h2 id="奶茶">奶茶</h2>
<p>一天一杯！其实就喝了喜茶和霸王茶姬，为什么要恰连锁店。</p>
<p>之前听说天津的大媚奶茶店里章特别多，点饮料就可以免费盖，但是套色章是要收费的。然而很久没跑章了甚至忘记本子，既然不盖章了感觉也不是特别有必要去喝（。</p>
<p>回北京半夜又点了一杯茶话弄，为了凑起送还买了他家的魔芋和薯条小零食，第二天在高铁上看电影的时候吃了。然后还刮中了奖，奖品是下次在茶话弄点奶茶的话还可以获得二选一的小零食，所以是不是只要每次都刮中奖就能每次吃到一样的东西（做梦</p>
<p>回上海之后喝了茶百道，送了很好看的新年限定天华锦贴纸，活动链接在<a href="https://mp.weixin.qq.com/s/t9s6D0bKmjAbls6M_EPkFg">这里</a>，不知道现在还有没有但是快喝。我点的时候店员姐姐忘记给贴纸了，后来去问的时候她直接给了我两份，姐姐真好谢谢姐姐。</p>
<h2 id="鲜芋仙">鲜芋仙</h2>
<p>是暑假里我姐来北京的时候第一次带我吃的，最后一天午餐吃完蛋糕之后还是想吃甜品（为啥，又去大悦城吃了一次，随便转了转就回北京了。</p>
<p>因为太养胃（？）了所以点了热的，端上来一碗冒热气的红豆汤的时候我就愣住了（，不过吃起来也没啥至少不是烫的。其实所谓冰的也不过是常温，怕凉的话只要不选刨冰就
ok。</p>
<h1 id="去哪玩儿">去哪玩儿</h1>
<p>省流：走到哪算哪，好累，我想骑车，<del>但是有的人不会骑车，差评</del>（x</p>
<p>来这边玩住在天津站旁边就可以了，到哪里都不远，缺点也是到哪里都不远但很难有地铁能直达的地方，就那个每一趟都要走
2 公里左右。<del>所以说如果能骑车的话还是很方便的吧（鞭尸</del></p>
<h2 id="意式风情街">意式风情街</h2>
<p>步行街，蛮适合走路的。遇到一位天津猫猫，也是在天津看到的唯一一只实体猫，刚想问它会不会说相声就跑掉了。</p>
<p><img src="https://s2.loli.net/2024/01/30/m3pUMXqh56OzogK.jpg" alt="cat.jpg"></p>
<p>只拍到了猫尾巴，喵喵。</p>
<p>本来还想来天津跑章的，提前看小红书发现能免费盖印的地方并不多，也不知道为什么总之是没带本子，落地到酒店的时候才想起来，于是打算如果看到有好看的章子就买明信片盖。意式风情街这里有挺多纪念品小店，有一家说消费满
20
可以盖，明信片三块钱一张，<del>虽然景区章就那样</del>，不过被这个世纪钟戳中了还是勉强挑出
7
张盖了章，<del>感觉其实也没人管有没有消费，不过大多数人多的地方也都这样</del></p>
<p><img src="https://s2.loli.net/2024/01/30/R2i5AtBE9onqxCw.jpg" alt="postcard.jpg"></p>
<p>本来还想盖个天津之眼的章，不过小朋友太多了就没拿，最后随手摸了两个没去过的旧居的章。这个世纪钟的章在纪念品商店外面看到的时候就要
6
眼泪了，前两天刚看了一遍《恋爱的犀牛》，然而这才知道新世纪的大钟确有其事。</p>
<p>随便贴一段剧本：</p>
<blockquote>
<p>播音员：为了迎接新世纪的到来，我们要建造一座世界上独一无二的大钟，它巍然屹立，坚不可摧，体现着人类的智慧和力量。</p>
<p>市民
A：一百公斤，仅仅秒针就一百公斤，时间从没有这么像现在走得这么沉重。</p>
<p>市民 B：它经得起是非荣辱，沧海桑田 ，象征着我们的民族。</p>
<p>市民 C：一百位本世纪出生，本世纪死去的杰出诗人的诗句被刻上表盘。</p>
<p>市民 D：一位 67 岁的老诗人为了让自己的作品入选刚刚自杀。</p>
<p>市民
E：献给来临的新世纪，举世无双的世纪大钟，全部由我们设计，我们施工。</p>
<p>市民 F：应该写上这是人类智慧的结晶。</p>
<p>市民 A：我建议写成世界第九大奇迹，外星人的引路灯塔。</p>
<p>市民
B：为大钟发行的彩票，奖金已经累积到五百万元，还在继续上升！拿到这笔钱的将是新世纪的幸运儿！</p>
<p>市民
C：听说表盘上的数字是镀金的，就像这个世纪的人爱说的——时间就是金钱。</p>
<p>市民
D：我们家邻居答应给我五万块钱，如果我把他的字母缩写藏在表针后面。</p>
<p>市民 E：你敢！你们这是在破坏二百年后的文物！</p>
<p>市民 F：我要在 8
点钟的边上偷偷刻上自己的名字，这样就可以流芳百世。</p>
<p>市民
G：我要把我爱人的名字刻上大钟的基座，旁边再刻上一颗心，代表我们坚贞不渝的爱情。</p>
<p>【众人一起对他侧目而视。】</p>
<p>众人：爱情？</p>
</blockquote>
<p>单看开头其实看着怪莫名其妙的，但这个剧本真的好伟大（，<del>都给我看</del>。</p>
<h2 id="古文化街">古文化街</h2>
<p>走了一圈就出来了，有种在逛城隍庙的感觉（。两边的店铺大多是卖小吃的，我不是特别感兴趣就没买啥。</p>
<p>出来之后有个好玩的椅子（</p>
<h2 id="天津之眼">天津之眼</h2>
<p>省流：没去，太远了，附近没东西吃也没地铁，而且走到晚上已经好累了（</p>
<p>不过查了下票价，成人票应该是单人日间 80 夜间
100，坐半个小时，感觉也不是很值，再刷新了一下夜间票就卖完了，害怕。倒也想不起来静安大悦城顶楼那个摩天轮票价多少了，印象里是
140 左右，你沪确实存在汇率（</p>
<p><del>而且这个东西感觉不能乱坐，一般都有一些金克斯附魔（里见皇冠：？点我是吧</del></p>
<h2 id="其他">其他</h2>
<p>在路上看到了挺多有趣的东西。</p>
<p><img src="https://s2.loli.net/2024/01/30/YdRrq9xn71cSQ83.jpg" alt="miao_2 desserts.jpg"></p>
<p>但怎么没开门，急急急。在赤峰道，<del>不是赤峰路</del></p>
<p><img src="https://s2.loli.net/2024/01/30/1RXV76l2KTca9yD.jpg" alt="yogurt.jpg"></p>
<p>我也爱喝，但后来转了一圈发现这个瓷罐酸奶景区里到处都有卖的，无端联想了一些老上海雪花膏，就没买。说起来坐城际铁路来回的路上都有乘务员在推销上海雪花膏，脚趾抠地了（但京沪高铁上并没有（草</p>
<p><img src="https://s2.loli.net/2024/01/30/7Z4ktlMODCjbiSV.jpg" alt="ice.jpg"></p>
<p>我超，冰（</p>
<p>恁天津人太猛了，不过我后来想了想荷塘结冰的时候也是不能上的，但<a href="https://chiyuru.github.io/2022/08/17/2022-photos-and-fragments/">这篇</a>里面还有我在荷塘冰面上的影像（</p>
<p>在冰面上走路、坐冰车感觉都可以理解，放炮也勉强可以，骑自行车我就不明白了啊（（</p>
<p>于是在河边研究了一下旁边箱子里的救生物资有哪些，不过我也不会游泳也就是看看。但弄脏了裤子（</p>
<p>后来在天桥上看到有卖烟花的，当时连仙女棒都没买也没想到可以放，回上海之后猛然想起外环内禁鞭全市禁售，又开始为没在天津玩一下感到悲伤了（</p>
<h1 id="二周目">二周目？</h1>
<p>鼓楼没去，海博因为太远了所以两天都说要去但都没去（，天津之眼也没去，其实一直都在天津站附近转悠根本没走远，完全可以二周目。</p>
<p>好想骑车兜风啊！但共享单车体验有点地狱，自己的车旅游的时候也不方便带着，二周目的话能不能骑车走
G103 国道过去呢（肥宅幻想时刻.jpg</p>
<h1 id="一句话总结">一句话总结</h1>
<p><img src="https://s2.loli.net/2024/02/03/5tzhEmfCqkMHV9B.jpg" alt="吃猫.jpg"></p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>2024 年 3 月论文阅读笔记</title>
    <url>/2024/03/21/Work-Log-2024-03/</url>
    <content><![CDATA[<p>三周看了两篇 Biometrika，此前还没见过 spectral
clustering，写总结发现很多地方完全理解错误，真是令人感叹（</p>
<p>下次还是一边看一边写吧，感觉可以少花点时间，但好像又不保证能发现一开始理解错的地方（（</p>
<span id="more"></span>
<h1 id="background">Background</h1>
<h2 id="general-basic-settings">General Basic Settings</h2>
<p>In Network-Adjusted Covariates for Community Detection and Local
Linear Graphon Estimation Using Covariates we consider unweighted,
undirected network data with node-wise covariates.</p>
<p>Basic settings are represented as follows.</p>
<p>A network data is often represented as a graph <span class="math inline">\(\mathcal A = (\mathcal V, \mathcal E)\)</span>,
where <span class="math inline">\(\mathcal V\)</span> denotes the set of
<span class="math inline">\(n\)</span> nodes, and <span class="math inline">\(\mathcal E\)</span> denotes the set of edges
between nodes. The adjacency matrix <span class="math inline">\(A \in
\{0,1\} ^{n \times n}\)</span> shows the structure of the graph, where
<span class="math inline">\(A_{ij} = A_{ji} =1\)</span> if <span class="math inline">\((i,j) \in \mathcal E\)</span> and <span class="math inline">\(A_{ij} = A_{ji} =0\)</span> otherwise. Note that
self-loop is not allowed, then <span class="math inline">\(A_{ii} =
0\)</span> holds for any node <span class="math inline">\(i \in
[n]\)</span> (here <span class="math inline">\([n] = \{1,2, \cdots,
n\}\)</span> for simplexity). Let <span class="math inline">\(d_j =
\sum_{j=1}^n A_{ij}\)</span> denote the degree of node <span class="math inline">\(i\)</span> and <span class="math inline">\(\bar d
= \sum_{i=1}^n d_i/n\)</span> be the average degree of the graph.</p>
<p>For a statistical network with node-wise covariates, denote the
covariate vector of node <span class="math inline">\(i \in [n]\)</span>
as <span class="math inline">\(x_i \in \mathbb R^p\)</span>. Then the
covariate matrix <span class="math inline">\(X \in \mathbb R^{n \times
p}\)</span> is constructed with the <span class="math inline">\(i\)</span>-th row in <span class="math inline">\(X\)</span> as <span class="math inline">\(x_i\)</span>.</p>
<h2 id="community-classifying">Community Classifying</h2>
<p>In a community classifying process, let <span class="math inline">\(K\)</span> be the number of communities. Define a
<span class="math inline">\(n\)</span>-vector as the community label
vector <span class="math inline">\(l \in [K]^n\)</span> by denoting
<span class="math inline">\(l(i) = k\)</span>, if the node <span class="math inline">\(i\)</span> is in the <span class="math inline">\(k\)</span>-th community. This can also be
represented in the matrix form <span class="math inline">\(\Pi \in
\{0,1\}^{n \times K}\)</span> (which will be used to construct the
Laplacian matrix), where <span class="math inline">\(\Pi_{ij}
=1\)</span> if <span class="math inline">\(l(i) = j\)</span>, i.e. node
<span class="math inline">\(i\)</span> is a member of community <span class="math inline">\(j\)</span>. We aim to recover <span class="math inline">\(\Pi\)</span> in the classification problem.</p>
<h2 id="spectral-clustering-method-k-mean-clustering-method">Spectral
Clustering Method &amp; K-mean Clustering Method</h2>
<p>I hadn't learned these two methods before, so I took some notes.</p>
<h3 id="compactness-and-connectivity">Compactness and Connectivity</h3>
<p>Firstly, we need to distinguish between two concepts - compactness
and connectivity.</p>
<p>Compactness --- Points that lie close to each other fall in the same
cluster and are compact around the cluster center. The closeness can be
measured by the distance between the observations. E.g.: K-Means
Clustering</p>
<p>Connectivity --- Points that are connected or immediately next to
each other are put in the same cluster. Even if the distance between 2
points is less, if they are not connected, they are not clustered
together. Spectral Clustering is a technique that follows this
approach.</p>
<p><img src="https://s2.loli.net/2024/04/02/4pgL81zDtCYZ3Vv.png" alt="clustering.png"></p>
<h3 id="principle-of-k-means-clustering">Principle of K-means
Clustering</h3>
<p>K-means stores <span class="math inline">\(k\)</span> centroids that
it uses to define clusters. A point is considered to be in a particular
cluster if it is closer to that cluster's centroid than any other
centroid. K-Means finds the best centroids by alternating between (1)
assigning data points to clusters based on the current centroids and (2)
choosing centroids (points which are the center of a cluster) based on
the current assignment of data points to clusters.</p>
<p>The algorithm is shown below.</p>
<p><strong>Algorithm 1</strong> Repeat until convergence:{</p>
<ol type="1">
<li><p>For every <span class="math inline">\(i \in [n]\)</span>, set
<span class="math inline">\(c^{(i)} = \arg \min _j \| x^{(i)} -
\mu_j\|^2\)</span>;</p></li>
<li><p>For each <span class="math inline">\(j \in [k]\)</span>, set
<span class="math inline">\(\mu_j = \frac{\sum_{i=1}^n
\mathbf{1}_{c^{(i)} = j}x^{(i)}}{\sum_{i=1}^n \mathbf{1}_{c^{(i)} =
j}}\)</span>. }</p></li>
</ol>
<h3 id="principle-of-spectral-clustering">Principle of Spectral
Clustering</h3>
<p>Denote <span class="math inline">\(D = \text{diag} \{d_1,d_2,\cdots,
d_n\}\)</span> as the degree matrix, <span class="math inline">\(A\)</span> as the adjacency matrix. Then the
Laplacian of the graph is denoted as <span class="math inline">\(L =
D-A\)</span>.</p>
<p>Note that for any <span class="math inline">\(f \in \mathbb
R^n\)</span>, we have</p>
<p><span class="math display">\[\begin{aligned}
    \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n A_{ij} (f_i - f_j)^2  &amp;
=\frac{1}{2}( \sum_{i=1}^ n (\sum_{j=1}^n A_{ij})f_i ^2 + \sum_{j=1}^ n
(\sum_{i=1}^n A_{ij})f_j ^2 - 2\sum_{i=1} \sum _{j=1} A_{ij} f_i f_j )
\\ &amp;= \sum_{i=1} d_i f_i^2 - \sum_{i=1}^n \sum_{j=1}^n f_i f_j
A_{ij} = f^T Df - f^T Af =  f^T L f.
\end{aligned}\]</span></p>
<p>Consider minimizing <span class="math inline">\(\frac{1}{2}
\sum_{i=1}^n \sum_{j=1}^n A_{ij} (f_i - f_j)^2 = f^T L f\)</span> under
the embedding <span class="math inline">\(f^TDf =1\)</span>. (From the
perspective of solving the min-cut problem， it's equivalent to
minimizing <span class="math inline">\(\frac{f^T L
f}{f^TDf}\)</span>.)</p>
<p>The Lagrangian is <span class="math inline">\(L(\lambda ; f) = f^TLf
- \lambda f^T Df = f^T(L-\lambda D)f\)</span>. By differentiating w.r.t.
<span class="math inline">\(f\)</span>, it is equivalent to solve <span class="math inline">\((L-\lambda D)f =0\)</span>, i.e. to solve the
eigenvalues and eigenvectors of <span class="math inline">\(L^\prime =
D^{-1}L = I - D^{-1} A\)</span>.</p>
<p>The algorithm of spectral clustering is listed below.</p>
<p><strong>Algorithm 2</strong> 1. Compute <span class="math inline">\(D
= \text{diag}\{d_1, \cdots, d_n\}, L^\prime = I - D^{-1} A\)</span>.</p>
<ol start="2" type="1">
<li><p>Compute the first <span class="math inline">\(K\)</span>
eigenvectors <span class="math inline">\(v_1,v_2, \cdots , v_K\)</span>
of the matrix <span class="math inline">\(L^\prime\)</span>.</p></li>
<li><p>Build the matrix <span class="math inline">\(V \in \mathbb R^{n
\times K}\)</span> with the <span class="math inline">\(K\)</span>
eigenvectors as columns.</p></li>
<li><p>Interpret the rows of <span class="math inline">\(V\)</span> as
new data points <span class="math inline">\(Z_i \in \mathbb
R^K\)</span>.</p></li>
<li><p>Clustering the points <span class="math inline">\(Z_i\)</span>
with <span class="math inline">\(K\)</span>-means clustering in <span class="math inline">\(\mathbb R^K\)</span>.</p></li>
</ol>
<h2 id="graphon-function">Graphon Function</h2>
<p>In classical graphon theory, a graphon is a bivariate and symmetric
<span class="math inline">\([0,1]\)</span>-valued function <span class="math inline">\(f(u,v): [0,1] ^2 \to [0,1]\)</span> defined on a
probability space. In particular, the graphon model can be formulated as
a data-generating process through the following two successive
steps.</p>
<ol type="1">
<li><p>First, we draw the node-specific latent quantities <span class="math inline">\(\xi_1, \xi_2, \cdots , \xi_n\)</span> i.i.d. <span class="math inline">\(\sim\)</span> Uniform <span class="math inline">\([0,1]\)</span>.</p></li>
<li><p>Secondly, condition on the realizations of the latent quantities,
i.e. given <span class="math inline">\(\xi_1, \xi_2, \cdots,
\xi_n\)</span>, the adjacent matrix items follow certain conditional
distribution as</p>
<p><span class="math display">\[A_{ij} | \xi_i , \xi_j \sim
\text{Bernoulli} (f(\xi_1, \xi_j)),\]</span></p>
<p>where the graphon <span class="math inline">\(f\)</span> satisfies
<span class="math inline">\(f(u,v) = f(v,u)\)</span> for any <span class="math inline">\((u,v) \in [0,1]^2\)</span>.</p></li>
</ol>
<p>The Local Linear Graphon Estimation Using Covariates introduces some
adjustments to the graphon function, to make emphasis the effect of
<span class="math inline">\(n\)</span> and node heterogeneity.</p>
<h2 id="stochastic-block-model">Stochastic Block Model</h2>
<p>The stochastic block model is actually a construction of the graphon
estimation, i.e., the graphon <span class="math inline">\(f\)</span> is
formulated as a piecewise constant step function with a rectangular
pattern, i.e.</p>
<p><span class="math display">\[f(u,v) = \sum_{i=1}^K \sum_{j=1}^K
\mathbf{1}_{\{\zeta_{i-1} \leq u &lt; \zeta_i\}}
\mathbf{1}_{\{\zeta_{j-1} \leq v &lt; \zeta_j\}} P(i,j).\]</span></p>
<p>Specifically, for node pair <span class="math inline">\((i,j)\)</span> from community <span class="math inline">\((l(i),l(j))\)</span>, the distribution of <span class="math inline">\(A_{ij}\)</span> is</p>
<p><span class="math display">\[A_{ij} | l(i), l(j) \sim
\text{Bernoulli}( P(l(i),l(j))).\]</span></p>
<p>In Network-Adjusted Covariates for Community Detection, we utilize
the degree-corrected stochastic model concerning the popularity of each
node. The degree-corrected graphon is represented as:</p>
<p><span class="math display">\[f(u, \cdot) = a_k(u) w(\zeta_{k-1},
\cdot) \; \text{for all }u \in (\zeta_{k-1}, \zeta_k),\]</span></p>
<p>where <span class="math inline">\(a_k : [0,1] \to \mathbb
R_+\)</span> is a continuous non-decreasing function with <span class="math inline">\(a_k(\zeta_{k-1}) =1\)</span>. This setting entails
that two nodes from the same group will reveal the same basic
connectivity behavior (stochastically) but differ in the expected degree
by introducing <span class="math inline">\(a_k\)</span> for each
community <span class="math inline">\(k \in [K]\)</span>.</p>
<p>Specifically, for node pair <span class="math inline">\((i,j)\)</span> from community <span class="math inline">\((l(i),l(j))\)</span>, the distribution of <span class="math inline">\(A_{ij}\)</span> is</p>
<p><span class="math display">\[A_{ij} | l(i), l(j) \sim
\text{Bernoulli}( \theta _i \theta _j P(l(i),l(j))),\]</span></p>
<p>where the coefficient <span class="math inline">\(\theta_i\)</span>
represents the popularity of node <span class="math inline">\(i\)</span>
itself.</p>
<p>Denote <span class="math inline">\(\Theta = \text{diag} \{\theta_1,
\cdots, \theta_n\} \in \mathbb R^{n \times n}\)</span>, <span class="math inline">\(P = \{ P(i,j)\}_{n \times n} \in \mathbb R^{n
\times n}\)</span>, and the adjacency matrix <span class="math inline">\(A\)</span> can be identified by</p>
<p><span class="math display">\[E(A |\Pi) = \Omega_A - \text{diag}
(\Omega _A), \; \Omega_A = \Omega \Pi P \Pi^T \Theta.\]</span></p>
<p>Here the subtraction of <span class="math inline">\(\text{diag}(\Omega_A)\)</span> is to eliminate
self-loops in the network.</p>
<h2 id="covariates-modelling">Covariates Modelling</h2>
<p>To highlight the integrity of the network model, we always start from
a simple situation: the total model scale is large, and the mean degree
is dominated by dense communities. In the subsequent analysis, we have
drawn two intuitive conclusions from this.</p>
<p>The adjusted covariates of nodes in different communities are
affected by <span class="math inline">\(\sum_{j: A_{ij}=1} x_j\)</span>
and <span class="math inline">\(\alpha_i x_i\)</span>, respectively.
Furthermore, when <span class="math inline">\(x_i \sim ^{\text{approx}}
F_D, x_j \sim ^{\text{approx}} F_S, i \in D, j \in S\)</span> is true,
the results obtained using spectral clustering exhibit similar central
distributions.</p>
<p>Thus, we keep this setting and adjust it similarly to a
community-wise identity distribution setting, i.e. the covariates <span class="math inline">\(x_i\)</span> are generated by a standard
clustering model, and they are independently distributed as</p>
<p><span class="math display">\[x_i | \Pi \sim F_k, \; l(i) = k \in
[K].\]</span></p>
<p>Moreover, we assume that given the label vector <span class="math inline">\(l\)</span>, <span class="math inline">\(X\)</span>
is independent of <span class="math inline">\(A\)</span>.</p>
<h2 id="block-assignment-according-to-bandwidth">Block Assignment
According to Bandwidth</h2>
<p>Given a suitable bandwidth <span class="math inline">\(1 &lt; h \leq
n\)</span>, denote <span class="math inline">\(n = kh + r\)</span> where
<span class="math inline">\(r \equiv n \pmod h\)</span>. Then we assign
<span class="math inline">\(n\)</span> nodes into <span class="math inline">\(k\)</span> blocks, with the first <span class="math inline">\(k-1\)</span> blocks having <span class="math inline">\(h\)</span> nodes each, and the last block has
<span class="math inline">\(h+r\)</span>.</p>
<p>To represent this assignment, let <span class="math inline">\(\mathcal Z_{n,h} \subseteq [k]^n \subset \mathcal
R^n\)</span> contain all block assignment vectors <span class="math inline">\(z = (z_1, \cdots, z_n)^T\)</span>, where <span class="math inline">\(z_i = j\)</span> implies that node <span class="math inline">\(i\)</span> is in the <span class="math inline">\(j\)</span>-th block, <span class="math inline">\(1
\leq i \leq n, 1 \leq j \leq k\)</span>.</p>
<p>Actually, in Local Linear Graphon Estimation Using Covariates we
assign oracle into <span class="math inline">\(k\)</span> blocks with
order statistics.</p>
<h1 id="network-adjusted-covariates-for-community-detection">Network-Adjusted
Covariates for Community Detection</h1>
<p>This work introduces a network-adjusted covariate (based on the
community density) and applies the spectral clustering method to the
adjusted covariate matrix in two ways according to the different inputs.
Through orthogonal matrix transformation, the error between the two
outputs can be controlled. This indicates that this method has good
consistency.</p>
<h2 id="network-adjusted-covariates">Network-Adjusted Covariates</h2>
<p>This work introduces a network-adjusted covariate <span class="math inline">\(\{y_i\}\)</span> based on the effect of community
density and the node-wise covariates <span class="math inline">\(\{x_i\}\)</span>:</p>
<p><span class="math display">\[y_i = \alpha_i x_i + \sum_{j : A_{ij}
=1} x_j, \; \forall x \in [n],\]</span></p>
<p>and the weight</p>
<p><span class="math display">\[\alpha _i =\frac{\bar d /2}{d_i / \log n
+1}\]</span> is</p>
<p>chosen to balance the effect of neighbors (i.e., <span class="math inline">\(\sum_{j \neq i} x_j\)</span>.</p>
<p>This seems reasonable because neighbors are the most likely potential
members of the community that <span class="math inline">\(i\)</span> is
in), and the effect of the node itself (i.e. <span class="math inline">\(x_i\)</span>) according to the density of
community it is in.</p>
<p>To see how <span class="math inline">\(\alpha_i\)</span> balance two
parts, we need to define the sparsity and density of a certain
community.</p>
<p><strong>Definition 2.1</strong> (Sparse/Dense Community).
<em>Consider a network <span class="math inline">\(\mathcal A =
(\mathcal V, \mathcal E)\)</span> and constants <span class="math inline">\(c_d &gt; c_s &gt;0\)</span>. Consider community
<span class="math inline">\(k\)</span>, we call it a</em></p>
<ol type="1">
<li><p><em>(Relatively) dense community, if <span class="math inline">\(E(d_i) \geq c_d \log n\)</span> for any node <span class="math inline">\(i\)</span> s.t. <span class="math inline">\(l(i) =
k\)</span> (i.e. node <span class="math inline">\(i\)</span> is a member
of the community <span class="math inline">\(k\)</span>).</em></p></li>
<li><p><em>(Extremely) sparse community, if <span class="math inline">\(E(d_i) \leq c_s \log n\)</span> for any node <span class="math inline">\(i\)</span> s.t. <span class="math inline">\(l(i) =
k\)</span> (i.e. node <span class="math inline">\(i\)</span> is a member
of the community <span class="math inline">\(k\)</span>).</em></p></li>
</ol>
<p>This definition will be slightly adjusted later according to the
stochastic block model.</p>
<p><em>Question</em>: Why we can assume that the <span class="math inline">\(K\)</span> communities are either sparse or dense
ones (according to the setting in the paper)?</p>
<p>I think this assumption can be satisfied through proper selection of
<span class="math inline">\(c_D, c_S\)</span> (in extreme cases they are
almost the same), but this will somehow weaken the definition. Or this
is just an assumption on the network structure itself. (unimportant)</p>
<p>Intuitively, we consider the case where the community sizes are
comparable, then the average degree <span class="math inline">\(\bar
d\)</span> is dominated by dense communities. Then for node <span class="math inline">\(i\)</span> in dense communities we have <span class="math inline">\(\alpha _i \approx \log n /2 &lt; n\)</span>, then
the focus of weighting was on <span class="math inline">\(\sum_{j :
A_{ij}=1} x_j\)</span>, i.e. the potential community members of node
<span class="math inline">\(i\)</span>. Similarly, for node <span class="math inline">\(i\)</span> in sparse communities, we have <span class="math inline">\(\alpha _i \geq \frac{\bar d /2}{c_S +1} \approx
\frac{c_D}{2(c_S+1)} \log n\)</span>, which will let <span class="math inline">\(\alpha _i x\)</span> be considerably large with
respect to <span class="math inline">\(\sum_{j : A_{ij}=1}
x_j\)</span>.</p>
<p>Therefore, for nodes in dense communities, the adjusted covariates
focus on connections with potential community members to imply density.
And for sparse community members, the emphasis should be put on the node
itself because the network may not give much meaningful information.</p>
<p>Let <span class="math inline">\(Y = (y_1 ,\cdots , y_n)^T\)</span> be
the network-adjusted covariate matrix, then <span class="math display">\[Y = AX + D_\alpha X = (A+D_\alpha)X,\]</span>
where <span class="math inline">\(A\)</span> is the adjacency matrix,
<span class="math inline">\(X\)</span> is the covariate matrix, and
<span class="math inline">\(D_\alpha = \text{diag} \{\alpha_1, \cdots,
\alpha_n\}\)</span> as the matrix of weights.</p>
<h2 id="direct-spectral-clustering">Direct Spectral Clustering</h2>
<p>Here the graph <span class="math inline">\(\mathcal A = (\mathcal V,
\mathcal E)\)</span>, the adjacent matrix <span class="math inline">\(A\)</span> and the covariates <span class="math inline">\(X\)</span> are known. We operate the spectral
clustering method on the network-adjusted covariates <span class="math inline">\(Y\)</span> (also the generalized form) to give an
estimated community assignment <span class="math inline">\(\hat
l(i)\)</span>, <span class="math inline">\(i \in [n]\)</span>.</p>
<h3 id="spectral-clustering-on-network-adjusted-covariates">Spectral
Clustering on Network-Adjusted Covariates</h3>
<p>We can apply the spectral clustering method to the network-adjusted
covariate matrix <span class="math inline">\(Y\)</span> directly when
<span class="math inline">\((A,X)\)</span> are both known. The algorithm
is shown below.</p>
<p><strong>Algorithm 3</strong> 1. Compute <span class="math inline">\(Y
= AX + D_\alpha X\)</span>.</p>
<ol start="2" type="1">
<li><p>Compute the first <span class="math inline">\(K\)</span>
normalized left singular vectors <span class="math inline">\(\hat
\xi_1,\hat \xi_2, \cdots , \hat \xi_K\)</span> of the matrix <span class="math inline">\(Y\)</span>.</p></li>
<li><p>Build the matrix <span class="math inline">\(\hat \Xi \in \mathbb
R^{n \times K}\)</span> with the <span class="math inline">\(K\)</span>
eigenvectors as columns.</p></li>
<li><p>Interpret the rows of <span class="math inline">\(\hat
\Xi\)</span> as new data points <span class="math inline">\(\hat Z_i \in
\mathbb R^K\)</span>.</p></li>
<li><p>Clustering the points <span class="math inline">\(\hat
Z_i\)</span> with <span class="math inline">\(K\)</span>-means
clustering in <span class="math inline">\(\mathbb R^K\)</span>, and get
the community label vector <span class="math inline">\(\hat l\)</span>
according to the result.</p></li>
</ol>
<p>Note that the network-adjusted covariates are dominated by <span class="math inline">\(\sum_{j: A_{ij}=1} x_j\)</span> for node <span class="math inline">\(i\)</span> in dense communities, and by <span class="math inline">\(\alpha_i x_i\)</span> for <span class="math inline">\(i\)</span> in sparse communities. Then for the
large-scale community condition, we considered in the previous section,
for node <span class="math inline">\(i\)</span> in dense communities,
<span class="math inline">\(y_i \approx \sum_{j :A_{ij}=1} x_i \approx
d_i F_D\)</span> if <span class="math inline">\(\{x_i\}_{i \in
D}\)</span> follows similar distribution. Similarly, for node <span class="math inline">\(i\)</span> in sparse communities, <span class="math inline">\(y_i \approx \alpha_i x_i \approx
\frac{c_D}{2(c_S+1)} \log n F_S\)</span> if <span class="math inline">\(\{x_i\}_{i \in S}\)</span> follows similar
distribution.</p>
<p>Hence, the central distribution of adjusted covariates is
approximately the same up to degree heterogeneity factor <span class="math inline">\(d_i\)</span> in dense communities and constant
factor in sparse communities. This consistency will be inherited by the
left singular matrix <span class="math inline">\(\hat \Xi\)</span>, and
so are the rows of <span class="math inline">\(\hat \Xi\)</span>, which
is used as data in k-mean clustering.</p>
<h3 id="spectral-clustering-on-generalized-adjusted-covariates">Spectral
Clustering on Generalized Adjusted Covariates</h3>
<p>In the case the covariate matrix <span class="math inline">\(X\)</span> is uninformative, it should not be
included in the spectral clustering matrix <span class="math inline">\(Y
= (A+D_\alpha )X\)</span>. Then we leverage <span class="math inline">\(YY^T\)</span> with the adjacency matrix <span class="math inline">\(AA^T\)</span>, by denoting the "Laplacian matrix"
as <span class="math inline">\(L = YY^T + \beta n AA^T\)</span> and
performing the spectral clustering algorithm as follows.</p>
<p><strong>Algorithm 4</strong> 1. Compute <span class="math inline">\(Y
= AX + D_\alpha X\)</span>, <span class="math inline">\(L= YY^T + \beta
n AA^T\)</span>.</p>
<ol start="2" type="1">
<li><p>Compute the first <span class="math inline">\(K\)</span>
normalized left singular vectors <span class="math inline">\(\hat
\xi_1,\hat \xi_2, \cdots , \hat \xi_K\)</span> of the matrix <span class="math inline">\(L\)</span>.</p></li>
<li><p>Build the matrix <span class="math inline">\(\hat \Xi \in \mathbb
R^{n \times K}\)</span> with the <span class="math inline">\(K\)</span>
eigenvectors as columns.</p></li>
<li><p>Interpret the rows of <span class="math inline">\(\hat
\Xi\)</span> as new data points <span class="math inline">\(\hat Z_i \in
\mathbb R^K\)</span>.</p></li>
<li><p>Clustering the points <span class="math inline">\(\hat
Z_i\)</span> with <span class="math inline">\(K\)</span>-means
clustering in <span class="math inline">\(\mathbb R^K\)</span>, and get
the community label vector <span class="math inline">\(\hat l\)</span>
according to the result.</p></li>
</ol>
<p><span class="math inline">\(\beta\)</span> is selected as <span class="math inline">\(\| \hat x\|^2\)</span>. Actually larger <span class="math inline">\(\beta\)</span> is often preferred.</p>
<h2 id="degree-corrected-stochastic-blockmodel">Degree-Corrected
Stochastic Blockmodel</h2>
<p>According to the basic settings in the Background section, we apply
the degree-corrected stochastic block model with known parameters <span class="math inline">\((\Theta, K, P, \Pi, F_{[K]})\)</span> here as
follows. Note that <span class="math inline">\((A,X)\)</span> are
unknown and will be estimated by their mean. Also, <span class="math inline">\(\mathcal D, \mathcal S\)</span> are both unknown
as a basic setting.</p>
<p><em>Basic Ideas</em>: This is another way to perform the clustering,
but the adjacent matrix <span class="math inline">\(A\)</span> and the
covariate matrix <span class="math inline">\(X\)</span> are both
unknown. However, <span class="math inline">\((\Theta, K, P, \Pi,
F_{[K]})\)</span> are known parameters. We replace both of them with
their expectation to get the estimated network-adjusted covariate matrix
<span class="math inline">\(\hat Y\)</span> used for spectral
clustering, which can be calculated under the setting of a
degree-corrected stochastic block model.</p>
<p>Then we're going to compare the output with <span class="math inline">\(\hat l\)</span> estimated by <span class="math inline">\((A,X)\)</span> previously, and show that there
exists consistency even though the inputs are totally different (one
with <span class="math inline">\((\mathcal A,X, A)\)</span> and another
with <span class="math inline">\((\Theta, K, P, \Pi, F_{[K]})\)</span>).
This implies that the spectral clustering on network-adjusted covariates
is powerful.</p>
<p>Moreover, there may be mis-specified nodes in the given community
membership matrix <span class="math inline">\(\Pi\)</span>. We'll show
that the spectral clustering method on network-adjusted covariates will
correct some of them.</p>
<p>The process is shown as follows.</p>
<h3 id="model-establishment-and-spectral-clustering">Model Establishment
and Spectral Clustering</h3>
<p>For node pair <span class="math inline">\((i,j)\)</span> from
community <span class="math inline">\((l(i),l(j))\)</span>, the
distribution of <span class="math inline">\(A_{ij}\)</span> is</p>
<p><span class="math display">\[A_{ij} | l(i), l(j) \sim
\text{Bernoulli}( \theta _i \theta _j P(l(i),l(j))),\]</span></p>
<p>where the coefficient <span class="math inline">\(\theta_i\)</span>
represents the popularity of node <span class="math inline">\(i\)</span>
itself.</p>
<p>Denote <span class="math inline">\(\Theta = \text{diag} \{\theta_1,
\cdots, \theta_n\} \in \mathbb R^{n \times n}\)</span>, <span class="math inline">\(P = \{ P(i,j)\}_{n \times n} \in \mathbb R^{n
\times n}\)</span>, and the adjacency matrix <span class="math inline">\(A\)</span> can be identified by</p>
<p><span class="math display">\[E(A |\Pi) = \Omega_A - \text{diag}
(\Omega _A), \; \Omega_A = \Omega \Pi P \Pi^T \Theta.\]</span></p>
<p>Moreover, we suppose that <span class="math inline">\(X\)</span> is
independent of <span class="math inline">\(A\)</span> given the label
vector <span class="math inline">\(l\)</span> as a covariate modeling
assumption, i.e. they are independently distributed as</p>
<p><span class="math display">\[x_i | \Pi \sim F_k, \; l(i) = k \in
[K].\]</span></p>
<p>A standard stochastic block model generates the covariates <span class="math inline">\(x_i\)</span> according to the <span class="math inline">\(F_{[K]}\)</span>, and the estimation of <span class="math inline">\(X\)</span> we use later is</p>
<p><span class="math display">\[E(X) = [E(x_{i})]_{i \in [n]} =
[E(F_{l(i)})]_{i \in [n]}.\]</span></p>
<p>Under the above settings, note that</p>
<p><span class="math display">\[E(d_i) = E(\sum_{j=1}^n A_{ij}) = \theta
_i \sum_{j \neq i} \theta_j P(i,j) \leq n \theta_i \max_{i \in
[n]}\{\theta_i\},\]</span></p>
<p>we refine the definition of dense and sparse communities by
approximating the degree with the upper bound <span class="math inline">\(n \theta_i \theta_{\text{max}}\)</span> as
follows.</p>
<p><strong>Definition 2.2</strong> (Sparse/Dense Community Adjusted for
Stochastic Blockmodel). <em>Consider a network <span class="math inline">\(\mathcal A = (\mathcal V, \mathcal E)\)</span>
that follows the degree-corrected stochastic blockmodel with parameters
<span class="math inline">\((\Theta, K,P, \Pi, \theta)\)</span> and
<span class="math inline">\(\theta_{\text{max}} = \|\theta
\|_{\infty}\)</span>. Consider community <span class="math inline">\(k\)</span>, we call it a</em></p>
<ol type="1">
<li><p><em>(Relatively) dense community, if there exist constants <span class="math inline">\(c,c_d\)</span> s.t. <span class="math inline">\(\theta _i \geq c \theta_{\text{max}}\)</span>, and
<span class="math inline">\(n \theta _i \theta_{\text{max}} \geq c_d
\log n\)</span> for any node <span class="math inline">\(i\)</span> s.t.
<span class="math inline">\(l(i) = k\)</span> (i.e. node <span class="math inline">\(i\)</span> is a member of the community <span class="math inline">\(k\)</span>).</em></p></li>
<li><p><em>(Extremely) sparse community, if there exist constants <span class="math inline">\(0&lt;c_s &lt; c_d\)</span> <span class="math inline">\(n \theta_i \theta_{\text{max}} \leq c_s \log
n\)</span> for any node <span class="math inline">\(i\)</span> s.t.
<span class="math inline">\(l(i) = k\)</span> (i.e. node <span class="math inline">\(i\)</span> is a member of the community <span class="math inline">\(k\)</span>).</em></p></li>
</ol>
<p><em>Question</em>: Here <span class="math inline">\(E(d_i) = \theta
_i \sum_{j \neq i} \theta_j P(i,j)\)</span> is dominated by <span class="math inline">\(n \theta_i \| \theta \|_{\infty}\)</span>, however
this is a bit rough. We can replace this upper bound by <span class="math inline">\(\theta_i \sum_{i=1} ^n = \theta _i \| \theta
\|_1\)</span>. Will this make much difference? (I think not.)</p>
<p>To set up an oracle matrix for the network-adjusted covariate matrix,
we consider the dominated terms only. If <span class="math inline">\(i
\in \mathcal D\)</span>, the dominated term of <span class="math inline">\(y_i\)</span> is <span class="math inline">\(\sum_{j : A_{ij} =1} x_j\)</span>, which can be
estimated by the i-th row of <span class="math inline">\(E(A)
E(X)\)</span>. If <span class="math inline">\(i \in \mathcal S\)</span>,
the dominated term of <span class="math inline">\(y_i\)</span> is <span class="math inline">\(\alpha_i x_i\)</span>, which can be estimated by
the i-th row of <span class="math inline">\(\hat \alpha_i E(X)\)</span>.
Here the estimated weight is</p>
<p><span class="math display">\[\hat \alpha_i = \frac{E(\bar d) \log
n}{2(E(d_i) + \log n)}.\]</span></p>
<p>Denote <span class="math inline">\(I_{\mathcal D}\)</span> as the
identity matrix where only diagonals on <span class="math inline">\(\mathcal D\)</span> are preserved and others are
set as 0. This definition can be extended to other matrices. Hence</p>
<p><span class="math display">\[\Omega = \hat Y = (I_{\mathcal D} E(A)
I_{\mathcal D})E(X) + I_{\mathcal S} \hat D_\alpha E(X) = (I_{\mathcal
D} E(A) T_{\mathcal D} + I_{\mathcal S} \hat D_\alpha) E(X)\]</span></p>
<p>is the "network-adjusted covariate matrix" under population settings,
where <span class="math inline">\(\hat D_\alpha = \text{diag} \{\hat
\alpha _1, \cdots, \hat \alpha_n\}\)</span>.</p>
<h3 id="mis-specifying-of-nodes-and-recovery-methods">Mis-specifying of
Nodes and Recovery Methods</h3>
<p>Under the setting of the degree-corrected stochastic block model, we
define mis-specifying by the distribution of <span class="math inline">\(x_i\)</span>. Note that the conditional
distribution of <span class="math inline">\(x_i | \Pi\)</span> is
denoted as <span class="math inline">\(F_k\)</span> for <span class="math inline">\(l(i) = k\)</span>. However, the membership in
<span class="math inline">\(\Pi\)</span> may be wrong, which causes
mis-specifying and will result in:</p>
<p><span class="math display">\[x_i | \Pi \sim F_k, \; \; \text{but  }
x_i \sim G_i \neq F_k.\]</span></p>
<p>Such nodes <span class="math inline">\(x_i\)</span> are called
mis-specified nodes, and the corresponding row in <span class="math inline">\(E(X)\)</span> will be affected by such error. The
set of mis-specified nodes is denoted as <span class="math inline">\(\mathcal M\)</span>.</p>
<p><img src="https://s2.loli.net/2024/04/02/egNWnSoPxO7bmBG.png" alt="goodnodes.png"></p>
<p>Though the set <span class="math inline">\(\mathcal D, \mathcal
S\)</span> are unknown, we can classify the nodes into the three sets
above. Denote <span class="math inline">\(\mathcal G = D \cup (S \cap
M^c)\)</span> as the "good" nodes that can be recovered (this is
guaranteed by Theorem 2.2).</p>
<p>Similar to the process of directly applying spectral clustering to
<span class="math inline">\(Y\)</span>, we consider the adjusted
covariates and the generalized adjusted covariates as follows.</p>
<h3 id="oracle-based-network-adjusted-covariate-clustering">Oracle Based
Network-Adjusted Covariate Clustering</h3>
<p>Consider the spectral clustering on the oracle matrix <span class="math inline">\(\Omega _{\mathcal G} = I_{\mathcal G}
\Omega\)</span>, we have the following lemma.</p>
<p><strong>Lemma 1</strong> (Spectral Analysis on Oracle Matrix).
<em>Consider <span class="math inline">\(\Omega_{\mathcal G} =
I_{\mathcal G} \Omega\)</span> as the oracle matrix with rows restricted
on <span class="math inline">\(\mathcal G\)</span>. Denote the singular
value decomposition of <span class="math inline">\(\Omega _{\mathcal
G}\)</span> as <span class="math inline">\(\Omega_{\mathcal G} = \Xi
\Lambda U^T\)</span>, where <span class="math inline">\(\Xi \in \mathbb
R^{n \times K}, U \in \mathbb R^{p \times K}\)</span>, and <span class="math inline">\(\Lambda \in \mathbb R^{K \times K}\)</span>. Then
there is</em></p>
<p><span class="math display">\[\Xi_ i =   \begin{cases}
        \theta _i v_{l(i)}, \; &amp; i \in \mathcal D \\
        \hat \alpha_i u_{l(i)}, \; &amp; i \in \mathcal S \cap \mathcal
M^c \\
        0 , \; &amp; i \in S \cap M = \mathcal G^c,
    \end{cases}\]</span></p>
<p>where <span class="math inline">\(\{v_k\}\)</span>'s and <span class="math inline">\(\{u_k\}\)</span>'s are <span class="math inline">\(K\)</span>-dimensional vectors.</p>
<p><em>Question</em>: This is just an oracle analysis even based on
known <span class="math inline">\(\mathcal M\)</span>, how can we reach
the conclusion that "the label of nodes in <span class="math inline">\(\mathcal G\)</span> can be exactly recovered"?</p>
<p>I think by "recovery" the author means that, under the setting of the
stochastic block model, even if there are some mis-specified nodes in
<span class="math inline">\(\Pi\)</span> (i.e. the distribution of
covariates <span class="math inline">\(x_i\)</span> is wrongly assigned
as <span class="math inline">\(F_{l(i)}\)</span>), <span class="math inline">\(\hat l(i)\)</span> and <span class="math inline">\(\Pi_{i,j}\)</span> can correspond to each other
for nodes in <span class="math inline">\(\mathcal G\)</span>.</p>
<p>The lemma implies that by separating the centers (i.e. <span class="math inline">\(u_k\)</span> 's and <span class="math inline">\(v_k\)</span> 's), the label of nodes in <span class="math inline">\(\mathcal G\)</span> can be exactly recovered.
Actually, the central distribution can be identified through the
orthogonal transformation between <span class="math inline">\(\hat
\Xi\)</span> and <span class="math inline">\(\Xi\)</span> with high
probability and slight error. This can be guaranteed by the following
theorem.</p>
<p><strong>Theorem 2.1</strong> (Row-wise empirical and oracle singular
matrix distance). <em>Consider the degree-corrected stochastic block
model with covariates with parameters <span class="math inline">\((\Omega, K, P, \Pi , F_{[K]}, \mathcal
M)\)</span>, where <span class="math inline">\(p&gt;0\)</span> is
constant, <span class="math inline">\(\mathcal G\)</span> is the set of
good nodes and <span class="math inline">\(\varepsilon = |\mathcal G^c|
/n\)</span>. Let <span class="math inline">\(\Omega\)</span> be the
oracle matrix, <span class="math inline">\(\Xi\)</span> is the left
singular matrix of <span class="math inline">\(\Omega_{\mathcal G} =
I_{\mathcal G} \Omega\)</span>, and <span class="math inline">\(\hat
\Xi\)</span> consists of the top <span class="math inline">\(K\)</span>
left singular vectors of <span class="math inline">\(Y\)</span>.</em></p>
<p><em>Let <span class="math inline">\(c,C&gt;0\)</span> be constants
that vary case by case. We assume:</em></p>
<ol type="1">
<li><p><em>the sub-matrix of <span class="math inline">\(P\)</span> that
restricted to dense communities <span class="math inline">\(P_{\mathcal
D} = I_{\mathcal D} P\)</span> is full-rank;</em></p></li>
<li><p><em><span class="math inline">\(\| x _i \| \leq R\)</span> almost
surely, and for <span class="math inline">\(i \in \mathcal S \cap
\mathcal G\)</span>, with high probability <span class="math inline">\(\| x_i \ E(x_i)\| \leq \delta_X
R\)</span>;</em></p></li>
<li><p><em><span class="math inline">\(\lambda _K E(X) \geq c \sqrt n
R\)</span>;</em></p></li>
<li><p><em>the number of nodes in any community <span class="math inline">\(n_k / n \geq c &gt;0\)</span>.</em></p></li>
</ol>
<p><em>Then there are threshold constants <span class="math inline">\(C_\theta, \varepsilon _0, n_0\)</span>, and <span class="math inline">\(\delta_0\)</span>, s.t. if <span class="math inline">\(\delta_X \leq \delta _0\)</span>, <span class="math inline">\(\varepsilon \leq \varepsilon_0\)</span>, <span class="math inline">\(n \geq n_0\)</span>, <span class="math inline">\(n
\theta_{\text{max}}^2 \geq C_\theta \log n\)</span>, there exists an
orthogonal matrix <span class="math inline">\(O\)</span> and a constant
<span class="math inline">\(C&gt;0\)</span> with probability <span class="math inline">\(1 - O(1/n)\)</span> s.t.</em></p>
<p><span class="math display">\[\max _{i \in \mathcal G} \|\hat \Xi_i  -
O \xi_i\| \leq C(\delta_X + \sqrt \varepsilon + 1/ \sqrt{C_\theta}) /
\sqrt{n},\]</span></p>
<p>where <span class="math inline">\(\hat \Xi_i\)</span> and <span class="math inline">\(\Xi_i\)</span> are vectors formed by i-th row of
<span class="math inline">\(\hat \Xi\)</span> and <span class="math inline">\(\Xi\)</span>.</p>
<p>Hence, the algorithm of spectral clustering based on network-adjusted
covariates shows strong consistency. <span class="math inline">\(\hat
l(i)\)</span> and <span class="math inline">\(\Pi_{i,j}\)</span> can
correspond to each other for each node in the good set <span class="math inline">\(\mathcal G\)</span>. Note that the bound is
row-wise instead of the Frobenius norm bound using the Davis-Kahan
approach (haven't read yet).</p>
<p><strong>Theorem 2.2</strong> (Strong Consistency). <em>Suppose the
conditions 1 <span class="math inline">\(\sim\)</span> 4 in Theorem 2.1
hold. Let <span class="math inline">\(\hat l\)</span> be the estimated
labels by the spectral clustering method in <span class="math inline">\(Y\)</span>. Then there is a constant <span class="math inline">\(C_\theta\)</span> independent of <span class="math inline">\(n\)</span>, so that if <span class="math inline">\(n \theta_{\max} \geq C_\theta \log n\)</span>,
there exists a permutation <span class="math inline">\(\pi\)</span> s.t.
with probability <span class="math inline">\(1-
O(1/n)\)</span>,</em></p>
<p><span class="math display">\[\pi(\hat l(i)) = l(i), \; \; \text{all }
i \in \mathcal G.\]</span></p>
<p>Therefore the community detection error rate is bounded by <span class="math inline">\(|\mathcal G^c|/ n =\varepsilon\)</span>.</p>
<p>Hence we have <span class="math inline">\(E(\text{Err}_n) \leq
(1-O(1/n))\cdot \varepsilon + O(1/n) \cdot 1 = \varepsilon +
O(1/n)\)</span>. This will meet the statistical lower bound in the next
section.</p>
<h3 id="oracle-based-generalized-adjusted-covariate-clustering">Oracle
Based Generalized Adjusted Covariate Clustering</h3>
<p>In the direct application of spectral clustering method on the NAC,
we considered the case that <span class="math inline">\(X\)</span> is
uninformative, i.e. the covariate matrix <span class="math inline">\(X\)</span> is not of full-rank, and add <span class="math inline">\(AA^T\)</span> to <span class="math inline">\(YY^T\)</span> to achieve good clustering results.
This algorithm also shows consistency with the stochastic block model
settings.</p>
<p>In the previous section we assume that <span class="math inline">\(E(X)\)</span> is of full-rank. If <span class="math inline">\(\text{rank} (E(X)) &lt; K\)</span>, we should add
a weighted <span class="math inline">\(AA^T\)</span> to <span class="math inline">\(YY^T\)</span> as what we did in the direct
application of spectral clustering. Here we only add <span class="math inline">\(AA^T\)</span> restricted to rows in dense
communities, i.e.</p>
<p><span class="math display">\[\hat L = \Omega \Omega^T + \beta n
(I_{\mathcal D} E(A) I_{\mathcal D})^2.\]</span></p>
<p>Here, by extending the covariates to <span class="math inline">\(\mathbb R^{p+1}\)</span>, we still have the
Cholesky decomposition of <span class="math inline">\(\hat L = \tilde
\Omega \tilde \Omega ^T\)</span> as follows.</p>
<p>Define the extended covariates <span class="math inline">\(\{\tilde
x_i\}\)</span> as follows:</p>
<p><span class="math display">\[\tilde x_i = \begin{cases}
    (x_i , \sqrt \beta_i T_{l(i)}), \; &amp; i \in \mathcal D \\
    (x_i , 0) , \; &amp; i \notin \mathcal D
\end{cases} \in \mathbb R^{p+K_{\mathcal D}}.\]</span></p>
<p>where <span class="math inline">\(T_{l(i)}\)</span> is the row of
<span class="math inline">\(T = (\Pi^T \Theta \Pi)^{-1} (n \Pi^T \Theta
^2 \Pi)^{1/2} \in \mathbb R^{K_{\mathcal D} \times K_{\mathcal
D}}\)</span>. (Note that the rows and columns are restricted to dense
communities in <span class="math inline">\(T\)</span>, and <span class="math inline">\(T\)</span> is a diagonal matrix.)</p>
<p><strong>Question (not yet solved)</strong>: By computing <span class="math inline">\(T\)</span> and <span class="math inline">\(\hat
\Omega \hat \Omega^T\)</span> I find that the coefficient of <span class="math inline">\(T_{l(i)}\)</span> should change with the subscript
<span class="math inline">\(l(i)\)</span>. It seems that the calculation
results in the article may appear incorrect (or I misunderstand
something), but it does not affect the fact that <span class="math inline">\(\Omega \Omega^T + \beta n (I_{\mathcal{D}} E(A)
I_{\mathcal D})^2\)</span> can be represented as a Cholesky
decomposition <span class="math inline">\(\tilde \Omega \tilde \Omega
^T\)</span>.</p>
<p>Denote <span class="math inline">\(\tilde X \in \mathbb R^{n \times
(p+K_{\mathcal D})}\)</span> as the extended covariate matrix and <span class="math inline">\(E(\tilde X) \in \mathbb R^{n \times (p+K_{\mathcal
D})}\)</span> as its expectation. Denote <span class="math inline">\(\tilde \Omega = (I_{\mathcal D}E(A) I_{\mathcal D}
+ I_{\mathcal S} \hat D_\alpha) E(\tilde X) \in \mathbb R^{n \times
(p+K_{\mathcal D})}\)</span>, we have</p>
<p><span class="math display">\[\begin{aligned}
    \tilde \Omega \tilde \Omega ^T &amp; = (I_{\mathcal D}E(A)
I_{\mathcal D} + I_{\mathcal S} \hat D_\alpha) E(\tilde X) E(\tilde
X)^T  (I_{\mathcal D}E(A) I_{\mathcal D} + I_{\mathcal S} \hat D_\alpha)
    \\ &amp; =  (I_{\mathcal D}E(A) I_{\mathcal D} + I_{\mathcal S} \hat
D_\alpha) (E(X)E(X)^T + \tilde{TT^T}) (I_{\mathcal D}E(A) I_{\mathcal D}
+ I_{\mathcal S} \hat D_\alpha) \\
    &amp; = \Omega \Omega ^T + (I_{\mathcal D}E(A) I_{\mathcal D} +
I_{\mathcal S} \hat D_\alpha) (\tilde{TT^T}) (I_{\mathcal D}E(A)
I_{\mathcal D} + I_{\mathcal S} \hat D_\alpha) \\
    &amp; = \Omega \Omega ^T + \beta n (I_{\mathcal D}E(A) I_{\mathcal
D})^2.
\end{aligned}\]</span></p>
<p>Note that <span class="math inline">\(\tilde{TT^T}\)</span> is a
matrix in <span class="math inline">\(\mathbb R^{n \times n}\)</span>,
where the rows and columns in sparse communities are set as <span class="math inline">\(0\)</span>. For row <span class="math inline">\(i\)</span> where node <span class="math inline">\(i\)</span> is in a dense community, we have the
i-th row as <span class="math inline">\(TT^T_{i} = T_{l(i)} ^T \tilde
T\)</span>. Hence <span class="math inline">\(\tilde{TT^T}\)</span> is
composed of <span class="math inline">\(TT^T\)</span> and <span class="math inline">\(0\)</span>'s as other items.</p>
<p>Hence by relaxing the third condition in Theorem 2.1, we get the
consistency result on oracle-based spectral clustering on generalized
NAC as follows.</p>
<p><strong>Theorem 2.3</strong> (Consistency of Algorithm 4).
<em>Consider the degree-corrected stochastic block model with covariates
with parameters <span class="math inline">\((\Omega, K, P, \Pi ,
F_{[K]}, \mathcal M)\)</span>. Let <span class="math inline">\(\Omega\)</span> be the oracle matrix, <span class="math inline">\(\Xi\)</span> is the eigenvectors of <span class="math inline">\(\tilde \Omega \tilde \Omega ^T\)</span>, and <span class="math inline">\(\hat \Xi\)</span> consists of the top <span class="math inline">\(K\)</span> left singular vectors of <span class="math inline">\(L = YY^T + \beta n AA^T\)</span>.</em></p>
<p><em>Let <span class="math inline">\(c,C&gt;0\)</span> be constants
that vary case by case. We assume:</em></p>
<ol type="1">
<li><p><em>the sub-matrix of <span class="math inline">\(P\)</span> that
restricted to dense communities <span class="math inline">\(P_{\mathcal
D} = I_{\mathcal D} P\)</span> is full-rank;</em></p></li>
<li><p><em><span class="math inline">\(\| x _i \| \leq R\)</span> almost
surely, and for <span class="math inline">\(i \in \mathcal S \cap
\mathcal G\)</span>, with high probability <span class="math inline">\(\| x_i \ E(x_i)\| \leq \delta_X
R\)</span>;</em></p></li>
<li><p><em><span class="math inline">\(^\prime\)</span> Let <span class="math inline">\(K_{\mathcal S}\)</span> be the number of sparse
communities. There is a constant <span class="math inline">\(c&gt;0\)</span>, s.t. <span class="math inline">\(\lambda _{K_{\mathcal S}} (I_{\mathcal S} E(X))
\geq c \sqrt n R\)</span>;</em></p></li>
<li><p><em>the number of nodes in any community <span class="math inline">\(n_k / n \geq c &gt;0\)</span>.</em></p></li>
</ol>
<p>Then there are threshold constants <span class="math inline">\(C_\theta, \varepsilon _0, n_0\)</span>, and <span class="math inline">\(\delta_0\)</span>, s.t. if <span class="math inline">\(\delta_X \leq \delta _0\)</span>, <span class="math inline">\(\varepsilon \leq \varepsilon_0\)</span>, <span class="math inline">\(n \geq n_0\)</span>, <span class="math inline">\(n
\theta_{\text{max}}^2 \geq C_\theta \log n\)</span>, there are constants
<span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, so that when <span class="math inline">\(\beta_0 &lt; \beta &lt; \beta_1\)</span>, with
probability <span class="math inline">\(1- O(1/n)\)</span>, there exists
an orthogonal matrix <span class="math inline">\(O\)</span> and a
constant <span class="math inline">\(C &gt;0\)</span> that</p>
<p><span class="math display">\[\| \hat \Xi - O\Xi \| _F \leq C(\delta_X
+ \sqrt \varepsilon + 1/ \sqrt{C_\theta}).\]</span></p>
<p>Let <span class="math inline">\(\delta_{\text{net}} = \frac{\max _{i
\in \mathcal S} n \theta _i \theta_{\max}}{\min _{i \in \mathcal D} n
\theta _i \theta_{\max}}\)</span>. Let <span class="math inline">\(\text{Err}_n = \frac{1}{n} \min _{\pi : [K] \to
[K]} |\{i : \pi(\hat l(i)) \neq L(i)\}|\)</span> (i.e., the number of
nodes that are wrongly recovered). Then there exists a permutation <span class="math inline">\(\pi\)</span>, s.t. with probability <span class="math inline">\(1- O(1/n)\)</span>, the clustering error rate by
spectral clustering on generalized NAS (Algorithm 4) follows</p>
<p><span class="math display">\[\text{Err} _n \leq C(\delta_X + 1/
\sqrt{C_\theta} + \delta_{\text{net}} + \sqrt \varepsilon).\]</span></p>
<p>This is a weak consistency result because the noise caused by added
<span class="math inline">\(AA^T\)</span> is relatively large. Hence the
row-wise control is hardly available, and the error rate cannot be
controlled by a single constant <span class="math inline">\(\varepsilon\)</span>.</p>
<h2 id="statistical-lower-bound">Statistical Lower Bound</h2>
<p>Consider a simplified model <span class="math inline">\(SM(\theta_0,
\theta_{\max}, P, \mu_{[3]},\sigma)\)</span> .with <span class="math inline">\(K=3\)</span>. Nodes fall into each community
equally likely. Furthermore, nodes in community <span class="math inline">\(1,2\)</span> have <span class="math inline">\(\theta_1 = \theta_2 = \theta_0\)</span>, and nodes
in community 3 have <span class="math inline">\(\theta_3 =
\theta_{\max}\)</span>. Hence community 3 is dense, community 1,2 have
the flexibility to be either dense or sparse. The covariates are
generated by <span class="math inline">\(x_i \sim N(\mu_{l(i)}, \sigma^2
I_p) = F_{l(i)}\)</span>. Thus, we can derive a statistical lower bound
with such simplified model.</p>
<p><strong>Theorem 2.4</strong> (Statistical Lower Bound). <em>Consider
the <span class="math inline">\(SM(\theta_0, \theta_{\max}, P,
\mu_{[3]},\sigma)\)</span> with <span class="math inline">\(K=3\)</span>. There is a constant <span class="math inline">\(C&gt;0\)</span> and a constant <span class="math inline">\(c_p\)</span> on <span class="math inline">\(P\)</span>, s.t. if</em></p>
<ol type="1">
<li><p><em><span class="math inline">\(n \theta_0 \theta_{\max} &lt;
Cc_p\)</span>,</em></p></li>
<li><p><em><span class="math inline">\(\|\mu_2 - \mu_1 \| /\sigma_n &lt;
\sqrt{C \log n}\)</span>,</em></p></li>
</ol>
<p><em>then for any estimator <span class="math inline">\(\hat
l\)</span>, <span class="math inline">\(E(\text{Err}_n (\hat l, l)) \geq
1/n\)</span>, which implies that the exact recovery cannot be
achieved.</em></p>
<p>Note that the statistical lower bound meets the upper bound in
Theorem 2.2 up to a constant factor. Then the spectral clustering
approach on NAC is optimal.</p>
<h1 id="local-linear-graphon-estimation-using-covariates">Local Linear
Graphon Estimation Using Covariates</h1>
<h2 id="adjusted-conditional-distribution-of-the-adjacency-matrix-items">Adjusted
Conditional Distribution of the Adjacency Matrix Items</h2>
<p>The conditional distribution is slightly adjusted in a common
approach (the same as in Network histograms and universality of
blockmodel approximation) as</p>
<p><span class="math display">\[A_{ij} | \xi_i, \xi_j \sim
\text{Bernoulli} (p_{ij}) = \text{Bernoulli} (\rho_n f(\xi_i,
\xi_j)),\]</span></p>
<p>where the range of <span class="math inline">\(f\)</span> is extended
to <span class="math inline">\([0,+\infty)\)</span>, and <span class="math inline">\(\rho_n\)</span> is used to restrict the
conditional probability on <span class="math inline">\([0,1]\)</span>.</p>
<p>Moreover, we have <span class="math inline">\(n \to \rho_n\)</span>
as a non-increasing mapping, and <span class="math inline">\(\int \int
_{[0,1]^2 } f(x,y) dxdy =1\)</span> as a unity condition. Therefore,
noting that</p>
<p><span class="math display">\[\begin{aligned}
    E(A_{ij}) &amp; = E (E(A_{ij} | \xi _i , \xi _j) ) = E(P(A_{ij}=1 |
\xi _i , \xi _j)) = E(\rho_n f(\xi_i, \xi_j)) = \rho_n \int_{[0,1]^2}
f(u,v) dudv =\rho_n,
\end{aligned}\]</span></p>
<p>the coefficient <span class="math inline">\(\rho_n\)</span> which
also represents scale <span class="math inline">\(n\)</span> can be
estimated by the unbiased sample mean</p>
<p><span class="math display">\[\hat \rho_n = \frac{2}{n(n-1)} \sum_{1
\leq i &lt; j \leq n} A_{ij}.\]</span></p>
<p><em>Question</em>: Since unbiasedness seems weak (as I've learned
these days in a Bayesian lecture), is it necessary for us to make
another estimation of <span class="math inline">\(\rho_n\)</span>? This
estimation seems not to affect the graphon estimation and the bandwidth
selection. Also, this seems to be a common approach according to other
papers I've read. (unimportant)</p>
<p>The non-decreasing <span class="math inline">\(\{\rho_n\}\)</span>
seems to be reasonable, because when the scale of the network <span class="math inline">\(n\)</span> increases, the probability that two
nodes in the network are connected will decrease. Also, the graphon
function <span class="math inline">\(f(\xi_i , \xi_j)\)</span> focus on
the node heterogeneity by taking variables as node-specified latent
quantities <span class="math inline">\(\xi_1, \xi_2, \cdots,
\xi_n\)</span>. Thus the conditional distribution illustrates the
effects of both.</p>
<h2 id="local-linear-estimation">Local Linear Estimation</h2>
<h3 id="basic-ideas-and-representation">Basic Ideas and
Representation</h3>
<p>We do the local linear estimation with respect to fixed block pairs
<span class="math inline">\((a,b)\)</span> as:</p>
<p><span class="math display">\[p_{ij} = \rho_n f(\xi_i , \xi_j) =
\kappa_{ab, 0} + \kappa _{ab,1} \xi_i + \kappa _{ab,2}
\xi_j,\]</span></p>
<p>for any node <span class="math inline">\(i\)</span> in block <span class="math inline">\(a\)</span> and any node <span class="math inline">\(j\)</span> in block <span class="math inline">\(b\)</span>, i.e., for any <span class="math inline">\((i,j) \in [n]^2\)</span> s.t. <span class="math inline">\(z_i =a ,z_j = b\)</span>.</p>
<p>Also, the node-wise covariates <span class="math inline">\(\{x_i \in
\mathbb R\}\)</span> are applied to illustrate latent variables <span class="math inline">\(\{\xi_i\}\)</span>, i.e.</p>
<p><span class="math display">\[\xi_i = x_i + \varepsilon _i,\]</span>
where <span class="math inline">\(\{ \varepsilon _i \}\)</span> are
white noise <span class="math inline">\((0, \sigma^2)\)</span>, and
assume that <span class="math inline">\((\xi_i , \varepsilon_i)\)</span>
are mutually independent. Hence, the latent node variables <span class="math inline">\(\{\xi_i\}\)</span> in the local linear estimation
model can be replaced by <span class="math inline">\(\{x_i
\}\)</span>.</p>
<p>Question (not yet solved): Does this approach introduce additional
noise, i.e. <span class="math inline">\(\kappa _{ab, 1} \varepsilon_i +
\kappa_{ab,2} \varepsilon_j\)</span> into the regression model? Will
this cause heteroscedasticity? Or this is something that we just replace
the latent variables with covariates for simplexity without these
concerns. So we just treat observed covariares <span class="math inline">\(\{x_i\}\)</span> as an observation of the latent
variables <span class="math inline">\(\{\xi_i\}\)</span>?</p>
<p>In a word, what's the point of introducing a white noise sequence
<span class="math inline">\(\{\varepsilon _i \}\)</span> here? Maybe
only for completeness and rigorousness for the replacement, or we just
have no better approaches to estimated the linear coefficients under
such heteroscedasticity, so we just omitted it. In all, it did not
appear again in subsequent derivations.</p>
<p>The natural estimation approach based on data <span class="math inline">\((p_{ij}, x_i ,x_j)\)</span> is to apply squared
error. Note that <span class="math inline">\(p_{ij}\)</span> is unknown,
and it can approximately be replaced by <span class="math inline">\(A_{ij}\)</span> according to the conditional
Bernoulli distribution. Therefore, the loss function is defined as</p>
<p><span class="math display">\[l_{ab} =\sum_{(i,j) \in z^{-1}(a) \times
z^{-1}(b)} (A_{ij} - \kappa_{ab, 0} - \kappa_{ab,1} x_i - \kappa_{ab,2}
x_j)^2 = \sum_{(i,j) \in z^{-1}(a) \times z^{-1}(b)} (A_{ij} -
\kappa_{ab}^T X_{ij})^2,\]</span></p>
<p><span class="math display">\[L(\kappa, z; A,X) = \sum_{(a,b) \in
[k]^2 } l_{ab} = \sum_{(a,b) \in [k]^2 }\sum_{(i,j) \in z^{-1}(a) \times
z^{-1}(b)} (A_{ij} - \kappa_{ab}^T X_{ij})^2,\]</span></p>
<p>where <span class="math inline">\(\kappa_{ab} = (\kappa_{ab, 0},
\kappa_{ab,1}, \kappa_{ab,2})^T, X_{ij} = (1, x_i ,x_j)^T\)</span>,
<span class="math inline">\(\kappa = (\kappa_{ab}) \in \mathbb R^{3
\times k \times k}\)</span>, <span class="math inline">\(X =
(X_{ij})\)</span>.</p>
<p>The optimal solution is denoted as</p>
<p><span class="math display">\[(\hat \kappa, \hat z ) = \arg \min
_{\kappa \in \mathbb R^{3 \times k \times k}, z \in \mathcal Z_{n,h}}
L(\kappa, z ; A,X),\]</span></p>
<p>where the block pairwise coefficient <span class="math inline">\(\kappa\)</span> is uncorrelated with the block
assignment function <span class="math inline">\(z\)</span>.</p>
<p>Then by given the least square estimation <span class="math inline">\((\hat \kappa, \hat z )\)</span>, we can derive the
estimation of <span class="math inline">\(\{f(x_i ,x_j)\}_{(i,j) \in
[n]^2}\)</span> as:</p>
<p><span class="math display">\[\hat f(x_i , x_j ) = \hat \rho_n ^{-1}
\hat p_{ij} = \hat \rho_n ^{-1} \hat \kappa_{\hat z(i), \hat z(j)}^T
X_{ij},\]</span></p>
<p>which is actually a discrete estimation of the graphon function <span class="math inline">\(f\)</span> on <span class="math inline">\(n^2\)</span> points <span class="math inline">\(\{(i,j) : i, j \in [n]\}\)</span>.</p>
<p>However, we aim to estimate the graphon function <span class="math inline">\(f\)</span> on any point in <span class="math inline">\([0,1]^2\)</span>, so some approximation is
required.</p>
<p><em>Question</em>: Do we expect the estimation <span class="math inline">\(\hat f\)</span> to have some good properties, such
as continuity, differentiability, etc. ?</p>
<p>Actually not, the estimated graphon is organized with grids.</p>
<p>We can take the simplest approach by dividing the interval <span class="math inline">\([0,1]^2\)</span> into <span class="math inline">\(k^2\)</span> blocks, and assign each point <span class="math inline">\((u,v) \in [0,1]^2\)</span> to the nearest block
<span class="math inline">\((a,b) = (\min \{[nu/h]+1, k\} , \min
\{[nv/h]+1, k\})\)</span>. Then the natural estimation of <span class="math inline">\(f\)</span> at <span class="math inline">\((u,v)\)</span> is interpreted as <span class="math inline">\(\hat f(u,v) = \hat \rho_n ^{-1} (\hat
\kappa_{ab,0} + \hat \kappa_{ab, 1} u + \hat \kappa_{ab,2} v)\)</span>.
This approach is reasonable because <span class="math inline">\(x_i =
\xi_i + \varepsilon_i\)</span> is nearly a uniform distribution on <span class="math inline">\([0,1]\)</span>, then we can approximate <span class="math inline">\((u,v)\)</span> according to the nearby <span class="math inline">\((x_i , x_j)\)</span>.</p>
<p>Till then, there are two problems remain to solve:</p>
<ol type="1">
<li><p>How to select a proper bandwidth <span class="math inline">\(h\)</span> according to the network? This may
relate to some trade-off between the bias and the variance.</p></li>
<li><p>How to get the least square estimation <span class="math inline">\((\hat \kappa, \hat z )\)</span>? Note that the
<span class="math inline">\(z^{-1}\)</span> in the subscript of
summation is difficult to handle.</p></li>
</ol>
<p>The next section introduces some analysis based on oracle.</p>
<h3 id="oracle-based-local-linear-estimation">Oracle Based Local Linear
Estimation</h3>
<p>Given a network <span class="math inline">\(\mathcal A = (\mathcal V,
\mathcal E)\)</span> and its node-wise covariates <span class="math inline">\(\{x_i\}_{i=1}^n\)</span>, consider the oracle that
provides order statistics of the unobserved node positions <span class="math inline">\(\{\xi_i\}\)</span>, i.e. we are given <span class="math inline">\(\xi_{(1)} \leq \xi_{(2)} \leq \cdots \leq
\xi_{(n)}\)</span>.</p>
<p><em>Question</em>: Why this makes sense? This seems to be a common
approach in former papers And I think it makes sense according to the
trivial estimation in the previous section, i.e. we treat covariates
<span class="math inline">\(\{x_i\}\)</span> as an approximation of
<span class="math inline">\(\{\xi_i\}\)</span>, and assign any point
<span class="math inline">\((u,v)\)</span> to the nearest block in <span class="math inline">\([0,1]^2\)</span> because <span class="math inline">\(\{\xi_1,\xi_2, \cdots, \xi_n\}\)</span> are i.i.d.
Uniform[0,1]. Also, the order statistics are sufficient in nonparametric
models.</p>
<p>Similar to what we did in the previous section, we assign <span class="math inline">\(\{\xi_{(i)}\}\)</span> into <span class="math inline">\(k\)</span> blocks according to the order. To be
more precise, we take <span class="math inline">\(\{\xi_{(1)} ,
\xi_{(2)}, \cdots, \xi_{(h)}\}\)</span> as block <span class="math inline">\(1\)</span>, <span class="math inline">\(\{\xi_{(h+1)} , \xi_{(h+2)}, \cdots,
\xi_{(2h)}\}\)</span> as block <span class="math inline">\(2\)</span>,
<span class="math inline">\(\cdots\)</span> , <span class="math inline">\(\{\xi_{((k-2)h+1)} , \xi_{((k-2)h+2)}, \cdots,
\xi_{((k-1)h)}\}\)</span> as block <span class="math inline">\(k-1\)</span>, and <span class="math inline">\(\{\xi_{((k-1)h+1)} , \xi_{((k-1)h+2)}, \cdots,
\xi_{(n)}\}\)</span> as block <span class="math inline">\(k\)</span>.
This way we actually construct an oracle block assignment vector <span class="math inline">\(\hat z ^* = (\hat z_1 ^* \cdots, \hat z_n
^*)^T\)</span>, where node <span class="math inline">\(i\)</span> is
assigned according to <span class="math inline">\(\xi_i = \xi_{(j)}
\triangleq \xi_{((i)^{-1})}\)</span> to the <span class="math inline">\(\min\{[j/h], k\} = \min\{[(i)^{-1}/h],
k\}\)</span> -th block. Mathematically we construct <span class="math inline">\(\hat z ^* = (\hat z_i ^* )_{i \in [n]}=
(\min\{[(i)^{-1}/h], k\})_{ i \in [k]}\)</span> as the oracle lock
assignment vector.</p>
<p>To estimate the graphon <span class="math inline">\(f\)</span> at any
point <span class="math inline">\((u,v) \in [0,1]^2\)</span>, it's
natural to consider fitting the nodes nearby into the local linear model
specifically for point <span class="math inline">\((u,v)\)</span>.
Denote <span class="math inline">\(B^*(u) = [u - \frac{h}{2n}, u
+\frac{h}{2n}]\)</span> as a block generated by <span class="math inline">\(u \in (\frac{h}{2n}, 1- \frac{h}{2n})\)</span>.
Then the closed ball <span class="math inline">\(B^*(u)\)</span> is
approximately a block with width <span class="math inline">\(\frac{h}{n}
\approx \frac{1}{k}\)</span>, similar to the original division of
blocks. Nodes "in" this area are considered as points nearby, and they
can be used to fit the local linear model for <span class="math inline">\((u,v)\)</span>. To describe what kind of nodes are
next to <span class="math inline">\((u,v)\)</span>, use the oracle to
assign such points into the interval.</p>
<p>Note that <span class="math inline">\(E(\xi_{(i)}) =
\frac{i}{n+1}\)</span>, we replace <span class="math inline">\(\xi_{i} =
\xi_{(i)^{-1}}\)</span> with the expectation of its corresponding order
statistic, i.e. <span class="math inline">\(\frac{(i)^{-1}}{n+1} = \hat
\xi_{i}\)</span>, and assign it to the block generate by any <span class="math inline">\(u \in [0,1]\)</span>. That is, if <span class="math inline">\(\hat \xi_{i} = \frac{(i)^{-1}}{n+1} \in
B^*(u)\)</span>, then <span class="math inline">\(\xi_i\)</span>
(actually node <span class="math inline">\(i\)</span>) is assigned into
the block generated by <span class="math inline">\(u\)</span>, and we
take the "block assignment vector" (adjusted for any <span class="math inline">\(u \in [0,1]\)</span>) as <span class="math inline">\(z_i^*(u) =1\)</span>, otherwise <span class="math inline">\(0\)</span>. Hence the Oracle neighborhood
indicator vector (according to the bandwidth <span class="math inline">\(h\)</span> because the measure of the closed ball
<span class="math inline">\(B^*(u)\)</span> is <span class="math inline">\(\frac{h}{n}\)</span>) is defined as <span class="math inline">\(z^*(u;h) = \{z_1 ^*(u), \cdots,
z_n^*(u)\}^T\)</span>.</p>
<p>Hence, the local linear model of any <span class="math inline">\((u,v) \in [0,1]^2\)</span> is derived from</p>
<p><span class="math display">\[A_{ij} \approx \rho_n f(\xi_i, \xi_j) =
p_{ij} = \gamma_{uv, 0} + \gamma _{uv,1} \xi_i + \gamma_{uv, 2} \xi_j
\approx  \gamma_{uv, 0} + \gamma _{uv,1} x_i + \gamma_{uv, 2} x_j
.\]</span></p>
<p>for any node <span class="math inline">\(i\)</span> in block
generated by <span class="math inline">\(u\)</span>, node <span class="math inline">\(j\)</span> in block generated by <span class="math inline">\(v\)</span> correspondingly. Then the loss caused
by each pair of such <span class="math inline">\((i,j)\)</span> is
approximately interpreted as</p>
<p><span class="math display">\[l_{ij}(u,v) = (A_{ij} - \gamma_{uv,0} -
\gamma_{uv, 1} x_i -\gamma_{uv,2} x_j)^2.\]</span></p>
<p>To estimate the loss, it's natural to sum the loss caused by such
pairs of <span class="math inline">\((i,j)\)</span> together, i.e.</p>
<p><span class="math display">\[\begin{aligned}
    L(u,v) &amp; = \sum_{\frac{(i)^{-1}}{n+1} \in B^*(u),
\frac{(j)^{-1}}{n+1} \in B^*(v)} l_{ij} (u,v) = \sum_{1 \leq i &lt; j
\leq n} l_{ij} (u,v) z_i^*(u) z_j^*(v) \\ &amp; = \sum_{1 \leq i &lt; j
\leq n} (A_{ij} - \gamma_{uv,0} - \gamma_{uv, 1} x_i -\gamma_{uv,2}
x_j)^2 z_i^*(u) z_j^*(v).
\end{aligned}\]</span></p>
<p>The least-squares estimator</p>
<p><span class="math display">\[\hat \gamma_{uv} = (\hat \gamma_{uv,0} ,
\hat \gamma_{uv,1}, \hat \gamma_{uv,2}) = \arg \min _{\gamma_{uv}}
L(u,v),\]</span></p>
<p>and the according graphon estimation at point <span class="math inline">\((u,v) \ in [0,1]^2\)</span> is</p>
<p><span class="math display">\[\hat f(u,v) = (\hat \rho _n)^{-1} \hat
p(u,v) = (\hat \rho _n)^{-1} (\hat \gamma_{uv,0} + \hat \gamma_{uv,1} u
+ \hat \gamma_{uv,2} v).\]</span></p>
<p><em>Question</em>: During this process, what steps may introduce
error into the result?</p>
<p>Many approximations are made to make the estimation possible and
intuitive, the following are some of them:</p>
<ol type="1">
<li><p>According to the local linear regression, we estimated the
graphon by <span class="math inline">\(\hat f(u,v) = (\hat \rho _n)^{-1}
(\hat \gamma_{uv,0} + \hat \gamma_{uv,1} u + \hat \gamma_{uv,2}
v)\)</span> with the nearby nodes <span class="math inline">\((i,j)\)</span> according to the order statistics
oracle.</p>
<p>The model itself will introduce errors to the prediction as linear
models do.</p></li>
<li><p>Still the issue of replacing <span class="math inline">\(\xi_i\)</span> with observed covariates <span class="math inline">\(x_i\)</span> with error <span class="math inline">\(\xi_i = x_i +\varepsilon _i\)</span>, and
introduce it into the local linear model <span class="math inline">\(p_{ij} = \gamma_{uv, 0 } + \gamma_{uv,1} \xi_i +
\gamma _{uv, 2} \xi_j\)</span> without adding the noise as <span class="math inline">\(\gamma_{uv,1} \varepsilon _i + \gamma_{uv, j }
\varepsilon _j\)</span>. The error increases with the scale of estimated
<span class="math inline">\(\hat \gamma_{uv}\)</span>.</p></li>
<li><p>To simplify the estimation, we take <span class="math inline">\(A_{ij} \approx p_{ij} = \gamma_{uv, 0 } +
\gamma_{uv,1} \xi_i + \gamma _{uv, 2} \xi_j\)</span>, while <span class="math inline">\(E(A_{ij} | \xi_i , \xi_j ) = p_{ij}\)</span>.
Actually, <span class="math inline">\(A_{ij}\)</span> is even not an
unbiased estimator of <span class="math inline">\(p_{ij}\)</span>. But
how to do better?</p></li>
<li><p>To assign nearby nodes to the block generated by any <span class="math inline">\(u \in (0,1)\)</span>, we replace <span class="math inline">\(\xi_{i} = \xi_{(i)^{-1}}\)</span> with the
expectation of the order statistic <span class="math inline">\(\frac{(i)^{-1}}{n+1}\)</span>, i.e. for any <span class="math inline">\(u \in (0,1)\)</span>, the generated block contains
about <span class="math inline">\(k\)</span> nodes.</p>
<p>And, for example, for <span class="math inline">\(u_1, u_2 \in
[\frac{h}{2n}, \frac{h}{2n} + \frac{1}{n+1}]\)</span>, <span class="math inline">\(v_1 , v_2 \in [\frac{h}{2n}, \frac{h}{2n} +
\frac{1}{n+1}]\)</span>, the node pairs <span class="math inline">\((i,j)\)</span> contained in the blocks generated
by <span class="math inline">\((u_1, v_1), (u_2, v_2)\)</span> are
almost the same up to one single node in the right "boundary" (e.g.,
there may exist some <span class="math inline">\(\frac{i}{n+1} \in
[\frac{h}{n}, \frac{h}{n} + \frac{1}{n+1}]\)</span>, then the numbers of
nodes in block generated by <span class="math inline">\(u_1 =
\frac{h}{2n}, u_2 = \frac{h}{2n} + \frac{1}{n+1}\)</span> will even
differ), so the estimated coefficients <span class="math inline">\(\hat
\gamma_{u_1, v_1}, \hat \gamma_{u_2, v_2}\)</span> may have a certain
degree of consistency.</p>
<p>Ideally, <span class="math inline">\(\hat f(u,v)= (\hat \rho _n)^{-1}
(\hat \gamma_{uv,0} + \hat \gamma_{uv,1} u + \hat \gamma_{uv,2}
v)\)</span> is linear in the region taken for example. However, if there
exist some points, like, with high leverage, it will have a significant
impact on the estimated regression coefficients <span class="math inline">\(\hat \gamma_{uv}\)</span>. This may lead to abrupt
changes in the estimated graphon value <span class="math inline">\(\hat
f(u,v)\)</span> of adjacent regions, i.e. will result in discontinuous
points with large oscillation with respect to the true graphon <span class="math inline">\(f\)</span> (assumed continuous).</p>
<p>This may contribute to severe errors when we use MISE to measure the
difference between the real graphon <span class="math inline">\(f\)</span> and the estimated <span class="math inline">\(\hat f\)</span>.</p></li>
</ol>
<p>However, the upper bound of MISE, bias and variance given by this
work shows that all these errors are controlled.</p>
<h2 id="error-estimation-and-bandwidth-selection-conclusions">Error
Estimation and Bandwidth Selection Conclusions</h2>
<p>With the graphon function <span class="math inline">\(\hat f\)</span>
estimated at each point <span class="math inline">\((u,v)\)</span>, it
suffices to illustrate that the estimation is good, and give the
selection rule of bandwidth <span class="math inline">\(h\)</span> since
it is the only remaining variable in the oracle-based analysis.</p>
<p><strong>Theorem 3.1</strong> (Upper bound for the bias and variance
of the linear graphon estimation). Given a bandwidth <span class="math inline">\(h &gt; 1\)</span>, assume that <span class="math inline">\(\frac{h}{n} \to 0\)</span> as <span class="math inline">\(n \to \infty\)</span>, <span class="math inline">\(h = \omega (\sqrt n)\)</span>, and the graphon
<span class="math inline">\(f : [0,1]^2 \to [0,\infty )\)</span> is
twice differentiable with continuous second-order partial derivatives.
Let <span class="math inline">\(f_u\)</span> and <span class="math inline">\(f_v\)</span> denote the first-order partial
derivatives with respect to the first and second variables,
respectively. Then, as <span class="math inline">\(n \to
\infty\)</span>, for any interior point <span class="math inline">\((u,v) \in (0,1)^2\)</span>,</p>
<p><span class="math display">\[\text{bias} (\hat f(u,v;h))  =
\frac{1}{24} \frac{h^2}{n^2} (\frac{\partial ^2 f}{\partial u^2} (u,v) +
\frac{\partial ^2 f}{\partial v ^2} (u,v)) (1+ o(1)),\]</span></p>
<p>and</p>
<p><span class="math display">\[\text{Var} (\hat f(u,v;h)) = [\frac{\bar
f_\omega -\rho_n \bar f_\omega ^2}{\rho_n h^2} + 2 \bar f_{u;\omega}
\bar f_{v;\omega}\frac{u+v}{n+2}(\frac{2n}{n+1} - (u+v))](1+
o(1)).\]</span></p>
<p>We denote by</p>
<p><span class="math display">\[\bar f_\omega  = \frac{1}{|\omega_{uv}|}
\int \int _{\omega_{uv}} f(x,y) dxdy,\]</span></p>
<p><span class="math display">\[\bar f_\omega ^2 \frac{1}{|\omega_{uv}|}
\int \int _{\omega_{uv}} f^2(x,y) dxdy,\]</span></p>
<p><span class="math display">\[\bar f_{u;\omega} =
\frac{1}{|\omega_{uv}|} \int \int _{\omega_{uv}} f_u(x,y)
dxdy,\]</span></p>
<p><span class="math display">\[\bar f_{v;\omega} =
\frac{1}{|\omega_{uv}|} \int \int _{\omega_{uv}} f_v(x,y)
dxdy\]</span></p>
<p>the corresponding local averages over the size-<span class="math inline">\(h\)</span> oracle region <span class="math inline">\(\omega _{uv} = B^*(u) \times B^*(v)\)</span>.</p>
<p><em>Question</em>: The paper gives that " The variance given by the
first term in scales as the inverse of the effective degrees of freedom,
i.e., <span class="math inline">\((\rho _n h^2)^{-1}\)</span> in each
neighborhood.", but how to get such effective degrees of freedom? (It
seems to be an unimportant question)</p>
<p><strong>Theorem 3.2</strong>. Under the conditions of Theorem 3.1, as
<span class="math inline">\(n \to \infty\)</span>, the mean integrated
squared error <span class="math inline">\(\text{MISE}(\hat f)\)</span>
of the oracle local linear estimator satisfies</p>
<p><span class="math display">\[\text{MISE}(\hat f) \leq (\frac{1}{144}
\frac{h^4}{4n^4} \psi_{2,f} + (\rho_n h^2)^{-1}+ \frac{5n}{3 (n+1)(n+2)}
\max_{(u,v) \in [0,1]^2} \bar f_{u;\omega} \bar f_{v; \omega}) (1+
o(1)),\]</span></p>
<p>where <span class="math inline">\(\psi _{2,f} = \int \int _{[0,1]^2}
\Delta f(u,v)^2dudv\)</span>, with <span class="math inline">\(\Delta\)</span> denoting the Laplacian of <span class="math inline">\(f\)</span> at <span class="math inline">\((u,v)\)</span>. This leads to the mean integrated
squared error optimal bandwidth</p>
<p><span class="math display">\[h^* = (\frac{288}{\rho_n
\psi_{2,f}})^{1/6} n^{2/3}.\]</span></p>
<p>This bandwidth is a kind of trade-off between the sparsity of the
network and its structural variability as measured in <span class="math inline">\(\psi_{2,f}\)</span>. Under such bandwidth <span class="math inline">\(h = h^*\)</span>, it follows that</p>
<p><span class="math display">\[\text{MISE} (\hat f) \leq (C \frac{
\psi_{2,f} ^{1/3}}{\rho_n ^{2/3} n^{4/3} } +  \frac{5n}{3 (n+1)(n+2)}
\max_{(u,v) \in [0,1]^2} \bar f_{u;\omega} \bar f_{v; \omega}) (1+
o(1)),\]</span></p>
<p>i.e. the mean integrated squared error of the local linear estimator
decays at a rate of <span class="math inline">\((n^{4/3} \rho_n
^{2/3})^{-1}\)</span>.</p>
<p>However, <span class="math inline">\(\psi _{2,f}\)</span> of an
unknown function <span class="math inline">\(f\)</span> should be
estimated by given data. (I hadn't understand the principle of this
algorithm yet :(</p>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>统计</tag>
        <tag>概率</tag>
      </tags>
  </entry>
  <entry>
    <title>通衢漫记</title>
    <url>/2024/07/08/Wuhan-Trip-2024/</url>
    <content><![CDATA[<p>实为 7.4 - 7.7 日记超长废话补足版。</p>
<p>全文大约一万字，其实一天就写完了，但写得我腱鞘炎犯了还痛经，拖了两天又等了个快递才修改完。阅读需要十分钟左右，如果还有更重要的事情就先别看了（</p>
<span id="more"></span>
<p>期末周那段时间我就开始策划暑假期间的超长旅行，考完试先在天津休息几天平复一下期末的精神创伤，回北京收拾东西前往南昌找我姐汇合，待几天然后前往武汉长沙，再到南昌休整一下就回上海。事实上这趟旅程并不完全是为了休息，我几乎每天晚上回家或者回酒店都会打开平板读几个小时论文，也有一整天待在家里读论文的时候，并自认为这段时间科研效率远高于平时（也许是我的
workflow 出现了一些改变，我开始接受直接在平板上记笔记，Notability
的很多功能让读论文这件事能够轻松变成做手账）。我认为我的确在通过旅行逃避一些东西，但至少并不是科研或者学习，另外也有一定要奔赴的见面以及告别。</p>
<p>在天津的某天凌晨得知妈妈身体继去年夏秋之交后再次出现相同的问题，凌晨趴在床上对比仁济医院瑞金医院中山医院华山医院和红房子的专家号区别何在，腆着脸咨询高中阶段都没怎么说过话的如今人在二医大的同学，交医附属的这些个三甲医院出病理互相之间认不认啊，因为去年在中山医院（复医系）做的病理结果被仁济医院（交医系）的医生骂了，说病理哪能会写成这个样子的啦，单纯性增生和复杂性增生都不写出来，然后又蛐蛐一波中山医院。但中山医院很委屈：我们只报恶性的啊。</p>
<p>其实每次一遇到这样的情况都会很动摇出国的想法，我倒也已经没那么焦虑我并不存在的科研成果能否把我送去个看着还行的学校了，最担心的还是哪怕取得学位就回国，在这期间亲人（其实就我妈一个人）能否平安无恙，在除了我之外没有任何可能的照护者而正处在围绝经期的我妈妈身体本就不好的情况下，这样的家庭结构已经够脆弱了，所以说实话我早就觉得，我最初那个取得学位之后在国外留下来的愿望几乎就不可能实现，只不过强基的背景下也没法在国内有学上，还得走一遭。<!--（24.07.16 update: 不是哥们，我今天突然思考了一下，那我为什么不本科毕业直接找工作啊，我当初打算念 PhD 不是因为想出国吗？那还延毕个啥啊？我超，快大四了突然开始思考这个问题，这不对劲吧（）-->当然人可以既有远虑又有近忧，首先是这次我妈的病情有没有加重，而首先的首先就是我还能否成行了。人又可以有不止一个近忧，首先的首先的同时，南昌武汉长沙一个不漏地下暴雨，整个长江中下游都在防汛，不知道上海有没有再内涝了。</p>
<p>离开北京的前夜，我收拾东西的时候打碎了桌上的一个玻璃杯，2022
年暑假我妈带我去家附近商场的时候购入，她在名创优品挑了个腰间有三指宽的防烫橡胶圈的杯子，说冬天接热水的时候这样不会烫到手，玻璃杯传热好，等水稍微凉下来一点又可以拿来捂手，然后替我付了钱。实际上哪怕冬天我也至少会点少冰去冰的饮料，喝水只接小半杯热水兑冷水，倒是有段时间用它冲咖啡确实用到了橡胶圈防烫的功能，其余时间只是防滑，今年习惯喝瑞幸之后就闲置了下来。收拾行李的时候为了够到桌面上更远的物品，我把它拿出来放在桌沿旁，洗好挂在床边的裤子因为沾水太重掉了下来，正好砸中它。也许是我站得比较远，杯子摔下来的时候也被衣物覆盖着一部分，总之哪怕在寝室里穿着短裤也没有受伤，实属幸运。</p>
<p>蹲在地上用胶带粘玻璃碎片的时候，就想起大一暑假购入这个杯子的情景，因为对专业的迷茫而整日无所事事，在商场我有点漫不经心地听我妈讲买下这个杯子的理由，她可能是因为自己挑中了的原因并没有像平时一样要求我自行付钱，我虽然不怎么喜欢它粉色的盖子，也得过且过了，毕竟同一款式没有其他颜色可以供她再询问我的选择。我想起这段时间每天和她通一个多小时电话讨论后面应该去哪个手术条件好的医院做什么项目的检查，再把病理拿去哪个可以尽快挂到专家号的医院问诊，病理不同结果的不同选择支，某些药物只有个别医院有，一切精确到医生的职称、专长，医院是复医系还是交医系，某个医院只有远郊分院的科室可以做检查，但问诊要去另一个分院，这样的情况。故事进行到这里我也许应该立刻改签回家了，但思来想去十天应该还不够问诊检查和出病理的，刚到家的时候应该治疗方案都还没出，而八月更不可能有时间出行，后面大概率要忙于陪同我妈治疗，甚至手术陪床承包所有的杂事，我还得抽空拔一颗智齿，科研都不得不停摆，退一万步讲我姐那时肯定已经开始上班了，根本见不到。</p>
<p>后来翻二医大同学的朋友圈，发现我关闭朋友圈的这两年里错过了很多我可能会爱看的笑话，当然我还是会继续关下去。于是我截图打码其中若干条，并发语音大笑着用桑海矮乌（上海话）跟我妈朗读并评论，伊刚肿瘤医院多年前一台宫腔镜手术捅穿了病人的子宫，导致整个医院被完全禁止再做宫腔镜，搞笑伐，株连九族怎么不把复旦系医院全算进去，以后红房子（复旦附属妇产科医院）也不许再做宫腔镜。因为我没有心，医疗事故被我讲成嘲讽没有日间手术床位也无法提供其他全身性医疗保障的红房子的笑话，来开启劝她去中山或者我们高贵的交医系医院做检查的话题。</p>
<p>我这个人一直都这样，希望一切事情都能通过动用我毕生的幽默才能，讲个笑话就轻飘飘解决了，并不是因为我真的是傻逼，而是我很恐惧需要严肃谈谈、推心置腹才能解决的问题，从我二十一年浅薄的认知里可以知道，那种情况一定是痛的、会流眼泪的。我妈听了我的洋泾浜之后直乐，说那这个手术在别的医院做应该都没什么风险吧，毕竟就是个比较大的检查，虽然上全麻。我说是呢，那我就不回去陪你了，晚点来帮你取病理，你好好听医生的话哦。私心里我需要继续这趟旅行，另外如果我赶回去，她一定认为这确是一件值得紧张的大事，不再是个检查性质的小手术了。</p>
<p>又多了一份因为我的轻蔑而加在肩头的罪愆，从北京出发了。从第一天就很不顺利，飞往南昌的飞机一直延误。当然后面更不顺利，然后是湖南洪涝灾害严重导致不得不取消了长沙的行程，后来九江也洪水，7.3
开往武汉的高铁大面积取消，湖北省博的预约只能推迟到
7.7，在一串售罄中改签比原来慢半个多小时时间也不合适的车票，反复修改酒店，不得不在武汉待了四天。去到武汉的第二天我还在想长沙既然雨停了可能也还是能再去一下，哪怕看完湖南博物院就走，然而我姐突然接到半个月后去单位报到需要尽早准备材料的通知，海昏侯博物馆都无法再出行，晚上洞庭湖决堤，长沙彻底不可能了。</p>
<p>乘高铁到武汉是下午三点多，去酒店放下东西之后其实我觉得这旅行到这里就可以结束了，来都来了，一脚踩在武汉的地界上了，我也已经累了，好跑特了。个么来都来了，茶颜悦色总是要喝一下，江汉路也得走一圈，两个条件加起来就变成了颤颤巍巍端着一杯没盖子的茶颜悦色去逛了
X118，看了几十个谷子店。</p>
<p>我还是第一次线下认真观察谷子店，走着走着后知后觉地发现差不多也是第一次参与了线下的二次元集会，具体来说就是好多
coser，虽然我是看到自由之翼的披风还辨认了半天那个姐是韩吉还是莎夏啊的程度。但说实话没什么意思，本来应该是一件很开心的事情，在看了几十个几乎复制粘贴，IP
大半都不认识的谷店之后也会有点反胃，更反胃的是第二天去光谷又看了十几个。按我浅陋的观察和理解，买谷这件事情疑似已经从单纯的消费支持变成了带有很强社交属性的活动，不禁让我产生了现在的中学生（年级不太大也不太小那种）会不会因为不买谷被孤立啊难道二次元已经成主流文化了感觉还是别了吧这样莫名其妙的担忧和随之而来的神秘的悲伤以及正义感，当然我怀疑这个想法很傻逼，所以写在这里之前我没有说出来过。</p>
<p>前段时间被江西菜霸凌了，第一天晚上尝了下湖北菜，在江汉路随便选了个馆子，叫竹花醉，其实还可以，分量挺大，味道中规中矩，不过没吃出来有什么特色，感觉和做得好吃的江西菜甚至食堂大伙差不多。但有一道芙蓉豆腐印象还挺深的，油豆腐一样的外皮里面内容物是类似鸡蛋羹的口感，汤很鲜很增色，如果早上起来能吃到这样的汤煮的面条那人生还有什么解决不了的问题这样的感觉。当然我吃不到，所以晚饭中还在不断地回复我妈的消息，比较红房子和中山医院的优劣来选择去哪个做宫腔镜，还在术前检查中遇到了一系列问题。多年来我往往会被她要求在两个不完美的选项和不确定的未来之间选出一个完美的结果，不允许任何差池，也许这就是为什么看过进击的巨人第一季里利威尔在巨树之森教艾伦做无悔的选择那一段剧情之后，我下决心这辈子都永远赞美和感激谏山创（假的）。</p>
<p>晚上在酒店大堂，被两个冒着酒气的壮汉骚扰许久，先是搭讪，后来又要跟着我同乘电梯，我从电梯门前走开他们也跟着走开，我过去他们又跟上来。但我看到前台也是两个小姑娘在值班之后，突然悲哀地发现我已经失去了几天前半夜在昌北机场拒绝拼车时那份跳脚大骂的勇气，也许因为不涉及钱财，又不是我给两位大哥转十块钱他们就放过我了（万一呢？），也真的打不过。我早已很多次地想购入一个
Apple Watch
来督促健身，基本都因为最近基金跌了或者一整个月没有收入入账之类的缺钱理由放弃，但谁知道我觉得自己最需要肌肉的时候竟然会是在一个听起来比较安全的新一线城市（我勉强承认是新一线）较繁华地段华住会旗下汉庭酒店的大堂，电光石火间我已经看到悲哀的结局是在头发没擦干还穿着睡衣的情况下，就算我有肌肉会格斗，打起来大约也很难脱身。我思绪万千，然而经过长到几乎永恒的不冷静思考之后我才终于回答了两位大哥的问题：你是本地人吗？我艰难地把嘴边那句“是本地人”憋了回去，家人们谁懂啊，我以为是本地人就是上海人的意思呢，谁知道我桑海宁跑到武汉来居然变成阿迪宁（外地人）了啊？</p>
<p>从在大哥们的手下挂着笑脸脱身之后就没有什么好事，第二天是更崩溃的一天，给我的感觉就是光谷有啥可逛的，实在没办法不知道去哪里了只能闯进武大，然后去看东湖这样子。我单知道纬度差不多所以副高影响的往往就是武汉
-
上海一线，我哪里知道武汉比上海还热这么多。不，我其实知道，我妈早就反复问我到底为啥要来这个地方，后来进手术室之前还在问，我长这么大唯一一次中暑就是五年前在武汉比赛的时候，虽然带点心理原因导致的（下详）。在光谷吃了一顿非常难吃的牛排之后，我决定下面几顿要么吃本地的连锁店，要么干脆就选在上海吃过的店，所以山石榴什么时候开遍全国？下午走投无路去了武大，不用预约刷了身份证就能进，平时在学校里骂游客骂多了，自己变成别人学校里的游客的时候是万万不敢去教学楼和图书馆附近的，精心规划之后坐公交车从南门入校，绕着珞珈山在商业街和家属区走了一圈之后从凌波门出校了。一方面是我觉得凌波门旁边是类似于本初之海的水域（指东湖），总之听起来能遇到绫波丽，另一方面换位思考如果游客只逛照澜院和清华路以南，我还是很欢迎的，毕竟我的系馆只有伟清楼会被这个范围覆盖，而我和导师虽然人都在华子但一直
remote，所以不关我事。</p>
<p>本来我还以为能绕着东湖骑一圈，就像后一天我以为我能在这个季节徒步走过长江大桥一样，这个地方总是能证明我真的很不自量力（也即在春季学期自学了量子力学），首先
10
分钟一块五的共享单车就完全打败我，也完全打败上海的物价，其次这里骑一圈全长十个武汉长江大桥。没骑几步我姐就接到了单位打来的通知报到电话，这下更没心情了，我见缝插针去视奸了一个武大同学的朋友圈，找到了附近一家好吃的咖喱店，在居民区里，叫顶屋咖喱。店主的女儿看起来不到上小学的年纪，在店里跑来跑去，开门迎客，摇风铃，端茶倒水，跑过来和我们（在她的视角下也许是两位美丽大姐姐但其实在店里忍住不说傻逼话就只能假装端庄了）咿咿呀呀地搭话。可能有点
biased，但我体感不管是地铁上还是这家店里，武汉的小朋友还是比较有礼貌的，比南昌小朋友好多了，当然也可能是在江西看到了太多的姐弟、姐姐弟、姐姐姐弟组合或独生子，我单纯是疲惫了。</p>
<p>我姐在一边痛饮 80mL
梅酒一边改变她后续的行程，我在督促我妈第二天手术之前禁水禁食，办住院的时候用现金，把财物留在家里，以及向医生护士问清楚无数的问题，中间还查了个成绩发现合同法吃了
B+，实分析没给 A+ 但我导竟给了我
A+，想起考试周最后几天在中文模板上用英文（使得我和 GPT
都比较习惯）糊出来的那个金统大作业，感到无比的羞耻。走出来之后买了四个莲蓬头拿回去剥莲子吃，其实还是来南昌之后我才知道莲蓬头里面的莲子抠出来剥了壳就能吃，也第一次看到满大街都是卖这个的，我猜上海可能朱家角靠近淀山湖那边能见到类似的景象，市区是真的没有。武汉地铁口卖的茉莉花倒是很便宜，三元两串五元三串的量级，而且是那种可以当成手链的长长一串。我以前一直以为这个东西是上海特色，有一次在福州路的地铁站入口看到十元一串，实际上只是可以别在衣襟上的小小一簇，卖花的老奶奶好像人均宁波人，还会说用别针别在小孩子胸前意味着“别惊”。就，不说别的，至少价格挺上海特色的。其实现在那句很流行的“今生戴花来世漂亮”出处根本不是这两年火起来的蟳埔簪花围，多年前我在一篇讲上海卖茉莉花的文章里就见过。现在躺在南昌的床上，已经想不起来在咖喱店喝的波子汽水到底是什么味道了，脑袋里还是只有夏日橘子汽水少年日出蝉鸣的烂梗，其实点单时很期待的。</p>
<p>第三天。已经彻底不知道武汉还有什么地方可去，被高温折磨得不行，碰巧我妈这天手术，我心情实在不好，商量了一下和我姐分开行动，去运转武汉地铁了。说是运转，实际上对我来说约等于拿着公交卡随机游走，拍拍车拍拍
POV
辨认下涂装自娱自乐这样子。我一直不敢说自己是车迷，不敢去交协，完全没和人谈论过这方面的爱好，一方面比起深度爱好者我承认自己啥也不懂就是觉得好玩自己图一乐，另外这个圈子如同当年竞赛的圈子一样确实没有让我去社交的欲望（我尽力委婉了）。</p>
<p>第一站是去万松园吃
brunch，一段时间以前看到上海某某网红街推出了可以拿在手里边走边吃的饭，饭盒旁边还留了个插咖啡杯的空，可以一边吃
brunch 一边 city
walk，我当时还和我姐嘴这件事，说肯定是湖北人搞出来的，到底撒宁为得欢喜（谁会喜欢）在牡路高头（在大马路上）一边走一边切
ve（吃饭）啊？陈光记贵但确实还不错（我已经不知道很多东西难吃是因为它就是难吃还是我适应不了你们华中的口味呢），别的就算了，旁边茶颜悦色有插座，坐着充了一个小时的电和我妈在手术前继续沟通所有的问题，我和她如同
ChatGPT
和狡猾的用户，她什么都来问我，要求我给出答案，但基本不相信我的说法。这家店倒是生意不忙，店员姐姐打扫卫生之余见缝插针给我塞了好多试吃，还有明信片，怪不好意思的，就在这家买了点周边带回去，但主要都送人了/计划着送人/带给我妈吃，只有一个冻干茶礼盒是留给自己的。它比正常的七条冷萃茶组合装贵五块钱，包装设计成了票据收纳盒的形式，我之前就觉得很需要这种东西，因为思路繁杂的时候我还在坚持用手写便签解决问题，之前在我桌上充当票据收纳盒的是秋季学期开学时校学生会送的小饼干的包装盒，没有这个茶礼包装那种投进邮筒的感觉。思来想去还是支持了下他们的设计，确实很有意思而且我很需要，值得为这个没啥用的巧思付钱。</p>
<p>一直到把我妈送进手术室我才又进地铁，后来兜兜转转去了只有三四站路的江汉路，刚出门不久就实现了一个跨越若干天的二维随机（并不随机）游走常返，第一天晚上在路边看到盖纪念章的店但没带本子，去补了一下。另外心血来潮想晚上写信却没有笔，为了买支笔我在江汉路来回走了
1.2km
才找到文具店，幽默的是导航的那家晨光文具店早已倒闭，是在它隔壁的无名小店买到了笔，却没有信纸信封，晚上回去从盖章本上随意扯了几张用来写信。</p>
<p>等手术的时候想去别的地方走走，昨天兴冲冲地想点茶颜悦色子品牌古德墨柠，但暂且只有长沙有，这么一想可以去一下古德寺（谐音梗对不起）。实际上我是一个攻击性极强、毫无敬畏心、尖酸刻薄的傻逼，多年前我在浦电路上课，那时知乎方兴未艾，地铁站的灯箱里全都是蓝色的薛定谔抱猫广告图，我每次都站在他面前狼吞虎咽我的早餐。浦电路是上海目前唯一一个重名地铁站，当然如果以后某个地铁站想以沪太路命名，全上海直到太仓也就都是沪太路站了，我想浦电路也是一样的道理。我当时总是分不清该在四号线下车还是六号线下，也没有智能手机可以随身携带，如果坐了六号线就只能拎着一袋煎饺和巧克力奶飞奔在雨后泥泞的道路上。上课的燕乔大厦旁边有个基督教堂，有次路过的时候被门口的一位中年妇女递了一张传单：上海基督教浦东福音堂欢迎您。旁边的铁门半开着，三三两两有人走进去，白皮肤蓝眼睛西装革履带着家人的外国人，空荡着一边袖管的病人，后来常常路过黄浦区三甲医院附近的教堂，就觉得信教者无非这两类，让我想起拉美小说里总有的吉卜赛人集会和从其中侧身穿过的外乡人。</p>
<p>后来我拿着传单到拥挤的浦电路站面对着薛定谔仔细阅读，路人视角下可能是年纪尚小就被传了福音的中学生，我心里想的其实是他们的话术怎么多年都没有进步，永远在说历史上最有名的科学家们全信上帝，个么不信上帝的都被烧死了啊。还说张学良也信上帝，我要是学他人生岂不是完蛋了。再抬头看薛定谔，很想查一下他信什么教，但又没有手机，然后想起给我递传单的那个女人，她看着我的眼神虔诚、郑重，并没有因为我是小孩子而失去一丝一毫的恳切，但我那时就觉得自己没有心，她的眼睛和故事，对我来说什么都不算。</p>
<p>走在去循礼门站的路上一查古德寺的学生票比雍和宫还贵一块钱。我和这座城市昨天，又或许五年前就已相看两厌，所以我在路边堂堂正正地骂了出来。再一搜小红书发现衣着暴露不得入内，不过膝的短裤短裙都算暴露，又想起四年前夏天我妈带我去静安寺上香，门票一人
50，我穿了
jk，所以才惩罚我到未央书院念书吧。每年大年初五去城隍庙上香倒是很难穿得暴露，怎么我也还没发财，看来福气还在后头。</p>
<p>乘上地铁往郊区走，想了想还是去打卡了一下我高中时期做噩梦最经常梦到的地方，三角湖地铁站以及武汉外国语学校初中部，五年前
CGMO 的考点。最常做的一个梦是从马路对面的酒店出发穿过三角湖地铁站，从 B
口出来走进校门然后爬一个很长的坡去教学楼考试，另外一个也比较常见的是在教学楼里考试结束之后所有人起立收卷，只有我因为考得实在太糟糕了，站起来的时候腿都在软。</p>
<p>既然已经过去很久了且本质的问题已经解决，说出来也无所谓，高中前两年我一直处在一个抑郁的情况，实质上是以搞竞赛为借口啥也不干，任由高考成绩垫底。尤其是在高一暑假考那次
CGMO 以及暑假后的联赛这段时间状态最差，了解我黑历史的话应该知道那年 CGMO
是银牌倒数，联赛比前一年滑了几百名到省三垫底，教练都劝我考虑下回去学高考的程度。这样摆了两年之后感觉要露馅了，退役前的暑假把之前听过的课的讲义看了一遍，买了两本中等数学训练题集刷完，明日方舟日均游戏时长两小时，勉勉强强混了个
CGMO
金牌和省一就跑路了。其实我高中那段时间做什么都就只是希望不要搞得太难看，只要混个差不多的成绩赶紧跑路就好，不要太好也不要太差，要正好处在不会被人关注到又能给老师家长一个交代的程度，后面九个月速通高考也是差不多的情况。大一暑假思考转什么专业的时候想起来这件事情，突然就觉得自己虽然水平不怎么样但应该还是有一丁点天赋在数学上面的，至少相比于其他的东西，就比如说物理，我是一点天赋也没有。写代码嘛，因为是以前完全没接触过的领域所以多少有点抗拒，也得不到什么正反馈，学文科又不符合我的经济状况，学医来不及了，那就选个抽代玩一玩这样子。</p>
<p>高中毕业之后就没再做那两个梦了，高三的时候做完噩梦醒来就想起来要速通高考到一个可以交差的程度，就更怨恨这个地方，应该从来没想到还会再来一次。在鹰潭一中那次比赛考得最好，名次离省队最近，但我全然忘记那里是什么景象了，而这破地方的教学楼长啥样我都还印象深刻（也可能是太豪华了导致的，五年前我在教学楼里等什么东西的时候就一边补魔眼收集列车一边破口大骂，同样是郊区哪能华二环境还不如一个初中，上中的一个姐说哎呀再郊区也是张江高科，地方没这么大）。三角湖地铁站有个夏季允许纳凉的通知贴在某个出站口处，当年比赛的时候一天从地铁站穿行好几次，会遇到很多老人和流浪汉，也犹有印象。这次去看起来是在举办小升初活动，地铁站挤满了家长，在校门口拍了个照就逃跑了，希望以后别再梦到了。</p>
<p>后来继续乘地铁，露天站台一般都要下来观察一下附近的情况然后多等一班车，这样一天下来大概就能了解整个城市的交通情况，虽然了解了也没啥用我真不想再来了，但总比一天不知道干什么搁酒店闷头读论文好。这一天甚至是我在武汉玩的最开心的一天（。</p>
<p>晚饭之前我妈就办好出院了，医生的意思是手术过程中感觉应该没有严重，不出意外可以按照温和的方案继续治疗，但他的意见仅作参考，具体还得等病理结果，又用和我相同的话回答了一些问题。显然在我妈眼里哪怕是关于网上都能搜到的问题我也是个没什么用的
baseline，而医生是
sota。我叮嘱了几句之后就去昙华林和我姐汇合，才知道她一天逛了四五家武汉的独立书店，只能说高下立判了，我这种只会花一天时间坐地铁的人就注定度过一个失败的人生。之前我们说武汉真的是一座好没安全感的城市，一个是第一天晚上就遭遇了一些骚扰，另外这边走在街头真的太容易被搭话了，不是让帮忙扫二维码就是要送东西然后做什么活动，一天被叫十几次美女。但是这一天下来我一次都没有被叫住，所以我认为问题出在我姐身上。</p>
<p>最后跟着她去旁边最后一家书店转了转，转了就很难不买，买了一本美国少数族裔访谈录，截止现在还没拆封。我这两年很沉迷各类非虚构作品，主要是因为里面的故事，这些故事的发生，不一定是因为社会学理论或者历史总是呈螺旋式上升的，社会学家随便用什么理论解释，也未必有人包含什么态度，故事只是这么发生了而已，我很沉迷这种感觉。我说完这段话以后自我感觉良好得不得了，我姐问我，嗯，那么你对你的生活完全失去掌控感也是因为要让事情自然而然地发生吗？我有点情绪崩溃。</p>
<p>逛书店就会自然地对书籍甚至书架排布产生一些评价，看到福柯那本疯癫与文明之后我有点受不了，之前写东西的时候就觉得自己懂得太少，笔下故事的男主逃不开那种动辄会引用福柯的文艺男设定，我发现自己平时虽然也喜欢嘲笑声称自己懂福柯的男的，但真要假装自己懂福柯，还得去看点福柯。后来一直卡在看不进福柯的阶段，逐渐封笔了。</p>
<p>因为不敢在文艺男密度比外头高的书店里讲这些话，就在回去的地铁上说，然后和我姐一起哈哈大笑，我们在一起的时光大概就这个样子，讲一些傻逼话，又怕在路上被人打了。后来又有点伤感，我是从什么时候开始性格变得这么尖锐，感觉是上高中之后不知道要怎么样才能进入市区初中毕业彼此相互认识的小孩们的圈子，就只会通过开一些尖酸刻薄的玩笑，说一些自以为惊世骇俗的话让人注意到我，其实就是重复一些别的大人说过的话，也没有得到想要的效果，慢慢就换了战术，选择沉默下去，度过三年之后到新的地方假装不认识所有人来重新开始。于是我说，我也不是随时都会这么先锋，都能保持一个这样在冲锋的样子，可能在你面前装得比较多一点，还有就是在我的女酮朋友们面前，完全不敢露出任何不先锋的一面，怕跟她们说了我喜欢男的就会突然被绝交。真到对待自己的事情，实际上我经常还是会觉得，嗯，哈哈哈，的。我不知道她懂我的意思没有，我想应该没有，我决定现在在这篇文章里也不说。</p>
<p>想了想我还是又换了个话题，高中的时候有一次在食堂打饭，阿姨给我夹了一块明显小很多的鸡排，说女孩子少吃点油腻的，不然会胖，别的男的的鸡排都好大一个，你知道大鸡排在上海话里怎么讲吗？叫嘟鸡扒，之前有个乐队给豪大大鸡排写了一首宣传曲，用上海话唱出来，就是这个梗。那一次我和很多其他时刻一样开始狠狠感叹凭什么就我没有嘟鸡扒，挺生气的，但那块鸡排我真的没吃完，咽不下去，太干巴太难吃了，当时就觉得想一直坚持一个仿佛在进步但实际自己也不知道在干吗的形象实在太难了，何况我保持一个先锋的形态本身可能就只是表演型人格发作而已呢。她拍了拍我的肩膀说这有什么，先不先锋的，你哪天就算结婚了也还是我的朋友。我真受不了了。</p>
<p>后来就是回酒店，写信，整理要寄出去和自留的东西，没有读论文就睡觉了，截止我回上海都没再读过论文了，我有罪。用盖章本上撕下来的纸写了很久，但不是标准的信纸就不知道是不是真写了很多，写到手痛就放弃，草草收尾。</p>
<p>最后一天就是去看期待了三天的省博，还是第一次看到不按照时间顺序而是按专题布展的省博，很有意思，曾侯乙墓的出土看得我仇富，就不是海昏侯墓那种几百公斤金子带来的仇富心理，是在阶层身份上感觉到被霸凌。越王勾践剑那个展厅就一把剑，排队排了三圈，最后懒得去排了，买了个越王勾践剑的簪子，放在我的猫猫玩偶身边倒是大小正合适，但它掉色，大概是上面的黑色花纹的涂料不停往下掉。在文创店看到一个越王勾践剑的银手镯，是把剑弯曲成一个环在手脖子上绕一圈，还有又胖又短的毛绒剑，这家店还会把高挑的鹤做成圆形的书签，感觉这些东西失去了它原本的形态就变得毫无意义了。刚从曾侯乙和考证曾国的展厅出来之后就是梁庄王展厅，时代跨度大得有点反应不过来。离开后才知道这博物馆还有
B1
层，地面层却没给出任何醒目的指示，就错过了一个大概是声乐文物相关的展厅，算了。</p>
<p>走出省博之后感觉很轻松，因为吃个饭就能坐高铁回南昌了，高铁开出湖北开到江西之后感觉前所未有的轻松快乐，也不知道为什么这几天过得这么难受，可能是没吃到什么好的，另外平白遭受了骚扰，人也很烦躁，哪怕只是为了达到一个视觉上的效果也该健身了。也许省博按照原计划排前两天的话心情会好点，但那样可能两天就跑路了（。</p>
<p>在武大看茶颜悦色店里的留言本，有人写了一句“盛夏行上海，晚冬行武汉”，感觉按照这个指示的话我确实可以快点回家，也真的好想逃跑。但其实夏天去上海也很折磨，毕竟副高就是要么压在武汉
-
上海一线要么往北抬然后就一起下雨，而且晚冬去哪里本来就都很舒服，（对我来说）是可以穿一件卫衣在上海街头走一天的那种难得的自由闲适，何必来这儿呢（。思来想去，但愿写字的人只是在记录自己的行程，而不是作为一种普适的建议，也别真有人信了。</p>
<p>最后，人都到万松园了，还是拍了个偷感很重的照片，也许是想假装是女高，我自己也不明白。旁边清洁工大爷在扫地，我拍完连打了一串喷嚏，连滚带爬跑进中山公园地铁站，大骂为什么这个站和阿拉长宁区那个出站换乘站叫同一个名字，结果在里相打皮革城的广告，受不了了，哪怕我妈定居在这里我也不要再来。</p>
<p><img src="https://s2.loli.net/2024/07/08/YcUCwm8QPXnED6F.jpg" alt="WFLS.jpg"></p>
<p>后记：回南昌称体重发现瘦了一斤。</p>
<p>后后记：回南昌两天，看路上骑电动车的开车的过马路的还有地铁安检员都觉得眉清目秀。</p>
<p>在武汉打车差点坐吐了一次，被司机骂了好几次，江汉路步行街的红绿灯只要人凑齐了就能过，第三天在那里被电动车擦着过去哥们还回头骂了我（也许不是我）一句别挡路，定睛一看后备箱上贴着四个大字：骑士精神。</p>
<p>第一天晚上坐地铁我耐心对着安检员喝水，第二天早上我对着安检传送带前的安检员喝一口，传送带后的安检员说没看到我喝必须再喝一口，到下午我已经学会把水塞进包里扔传送带上，过完安检不管后面的人在喊什么拿了就跑进闸机。第三天出门的时候感觉得带个两瓶水才够，实际上还买了好几杯茶颜悦色，纯茶水和奶茶都有，也才堪堪够喝，出汗太多了。运转到人少的地铁站（三角湖（点名））不好意思过完安检直接跑，安检员让我把包里没拆封压在最底下的水拿出来，我掏了半天他还来扯我帆布袋的带子说这样能把口开大点，我不想让人碰，往后躲了一步又嫌我动作慢。等等等等。最后一天又是在武汉火车站那个一瓶水要喝两遍的站过安检，又在说只抿一下不行的谁看得出来你喝了没有，我大喊一声有完没完了，把人吓了一跳，放我过了。但其实我吼完之后自己也吓了一跳，感觉平时不至于这么焦躁，之前看到湖北省自杀率全国最高，虽然不是很了解也不是搞地域歧视（熟悉我的人应该会知道相比我私下口嗨到处歧视，这已经非常温和了，作者的私德和文字体现出来的不处在同一水平），但人呈现出的整体性的状态，不可能没有环境的因素，就像我只是来旅游三天半感觉自己素质已经直线下降。旁边一个背着包拉着行李的小哥因为充电宝两万五毫安被拦下，安检员问他你去哪里？如果是去学校的话我睁一只眼闭一只眼就让你过了，坐高铁的话要没收，小哥说自己坐地铁去学校，拿了充电宝也没往地铁口走。</p>
<p>记得到南昌的第一天过安检让我喝水我还有点困惑，个么你们安检小包都不用放传送带，怎么就非得让喝水。此前我也只在郑州和若干年前的北京遇到过查水的安检，郑州并不严格，放包里过传送带的就不检查，天津去了两次，每天从天津站坐地铁也没查过，甚至上海的传送带安检我都没放过几次包，我高中时就回家不怎么学习所以只背帆布袋不背书包，后来一直习惯帆布袋出行，给安检员开包看一眼就可以了。后来发现南昌这边小包不过传送带也只是比较忙的站才宽松，但严格检查的站安检员至少都还客气点，（有时）会说谢谢。等地铁的时候跟我姐吐槽安检，微博转头就给我俩推送六月份那个上海地铁持刀砍人案件进展，她哈哈大笑说所以你们那才会有人在地铁上砍人啊。这怎么不是一种非虚构文学：我私德败坏，也没什么态度，更不是非要表达什么比生活更加高大的概念，事情就这么发生了。</p>
<p>后后后记：回家了。在上海手机没电了看地铁电视，可以看到小猫咪追松鼠，本地生态环境介绍，展览和美食软广。在武汉坐地铁，每次在外面怕电量不够又没有充电宝，不敢用手机的时候，只能看：</p>
<p><img src="https://s2.loli.net/2024/07/10/qzrgkji8fLy3D5N.jpg" alt=".jpg"></p>
<p>南昌地铁好像没有电视，没事了（？</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title>躺平记——游戏篇</title>
    <url>/2022/07/11/lying-flat-in-games/</url>
    <content><![CDATA[<p>新鲜的 tag:
躺平。<del>甚至想把之前的科协躺平篇改个标题，然后变成一个系列</del></p>
<p>在 <a href="https://chiyuru.github.io/2022/06/16/Hello-World/#more">Hello
World！</a>和 <a href="https://chiyuru.github.io/about/">About</a>
里就提到过，我有很多游戏的坑。音游有
Lanota、Arcaea，<del>抽卡类</del>塔防有明日方舟，其实也玩过若干国产乙女游戏，若干
GalGame，棋牌类有雀魂，还有不知道该怎么分类的 Fate/Grand
Order（FGO）。每次玩着玩着就会回到 FGO
去，可能是别的游戏都有或挺大或不小的圈子，而<del>半死不活的</del> FGO
没有。即使有，想要无视也很容易，因为身边没有玩 FGO 的朋友了。</p>
<span id="more"></span>
<p>五月初的时候方舟周年庆，于是一年一度回了坑，兴趣高涨。体验了一下这一年来漏掉的活动，新的肉鸽系统和保全派驻，还毕业了尘影余音这个不大不小的活动。只不过因为同学在七月新活动更新的时候，发消息讲了几句他已经打完第一波关卡看完剧情了，我就突然感觉无趣，草草卸载开始冬眠。就是一瞬间，开始对这个“需要"每天上线刷材料、和友人互动讨论玩梗、肝新剧情的系统感到疲倦。下次再来，可能就是明年五月了，也可能更晚。</p>
<p>然后很快就是 Arcaea 4.0
更新，更新之后的早晨大家惊呼对立被光反杀，我才知道两年后的今天终于有新剧情和突破既有定数的新歌了。然后今天上推偶然知道刺球（<span class="citation" data-cites="SkisK刺球">@SkisK刺球</span>）抢到了
Testify BYD 全球首 PM（-33）和收到官方恭喜，更新后的几天内没有其他
PM，更是离理论值很远。看了一眼<a href="https://www.bilibili.com/video/BV1xV4y1n71z?spm_id_from=333.999.0.0&amp;vd_source=6ae5c31a80120436d23cf7b7c7ceb3ba">手元</a>，感觉真的非常科幻，我一辈子可能也不会碰到这张谱了吧。<del>另外，官方的意思是全球范围内有PM就复活对立吗</del></p>
<p>很久不玩 Arcaea
了主要是因为条件不允许。在学校的话不想日常在寝室里表演爆敲手机屏，感觉会很吵。只是假期玩的话水平也上不去，所以偶尔想打歌了的话下回来敲一敲就好。“身边”玩音游的大多是以前的高中同学，不过我已经主动在母校毕业生中隐藏自己了，屏蔽和退出了一些群，不太像以前一样和他们互动，也就渐渐被忘记了；还有你清的一些音游人，都比我强很多，一般就是偶尔聊起来，或者碰巧刷到他们的视频。尽管你清音游相关社团印象里在我高中时就听说和憧憬过，但现如今也没有加入的打算。事实上，到现在为止我没有加入过任何社团，可能以后也不会。</p>
<p>乙女游戏更容易厌倦，我也不是去体验恋爱的，单纯是欣赏一下美工；剧情也还算有点意思。不过国乙的通病还得是不氪金就当狗和任务繁琐，回坑很快就觉得像上班一样，没意思了。GalGame
因为太挑剔，很难遇到喜欢的作品，朋友的推荐大多数也不合胃口，试错试多了就麻了。</p>
<p>雀魂的话，
惭愧地说我不是很会打。寒假的时候三人场刷到雀士然后发现还会掉回去，觉得好累，就没再上线过了。身边打雀的朋友人均很强，也没人注意到本菜狗的悄悄跑路。</p>
<p>总之到最后就是会跑回 FGO。从前一起玩 FGO
的朋友现在无一例外都弃坑了，而且都再也没回去过，缺乏社交性反而很惬意；活动关卡打不打也很无所谓，许多活动都是复刻，四五年前就体验过了；老玩家的原因，材料资源很充足，不需要肝，一段时间不登录也不会天塌下来；型月世界的设定很复杂，游戏和不同线路的番剧会相互呼应，刷着番打游戏体验很好（指路型月我最喜欢的一条线《<a href="https://zh.moegirl.org.cn/Fate/EXTRA_Last_Encore">Fate/EXTRA Last
Encore</a>》）；另外，因为是手游的原因，很轻量。</p>
<p>其中最要紧的还是“缺乏社交性”这一项。本来就不是很擅长社交，也不太想为了跟上朋友们讨论的梗而去打活动，不想再听到“你怎么跳过剧情啊，方舟的精髓就是剧情”这种评论。有的时候很疲惫了来玩游戏，就是只想暴力打打关卡而已。为了维持社交而每日登录、互动、活动肝到毕业这样的烦恼更是没有了。关卡也没有特别难的，要么蓝卡队总能苟过去，不能的话就不打了，反正也没有什么很特别的奖励。感兴趣的话可以看看
B 站的花式打法，只是不知道这几年过去还有多少 up 在做这方面的视频。</p>
<p>还记得初三的暑假在地铁上打
FGO，有个上海大学的路人小哥激动地叫住我想看看我的
box，只可惜我是小米渠道服，没有加到他的好友。或许当时这个游戏就已经不是那么热门了。</p>
<p>说了这么多，一句话总结的话，就是：</p>
<blockquote>
<p>我又社恐自闭了。</p>
</blockquote>
<p>如果再要加一句，那就是：</p>
<blockquote>
<p>我觉得“连打游戏都在摆烂”其实是一件很正常的事情。</p>
</blockquote>
]]></content>
      <tags>
        <tag>碎碎念</tag>
        <tag>躺平</tag>
      </tags>
  </entry>
  <entry>
    <title>躺平记——暑假特别篇</title>
    <url>/2022/09/01/lying-flat-in-holiday/</url>
    <content><![CDATA[<h1 id="你不会摆烂了一个暑假吧">你不会摆烂了一个暑假吧？</h1>
<p>确实，不然我暑假回家干嘛？</p>
<span id="more"></span>
<h1 id="躺平">躺平</h1>
<p>六月五日学期没结束就乘车回家了。原本打算九月十二号返校，结果为了三天灰码提前到了九月九日，又因为临近喜提了一次弹窗再提前到了九月六日返校。没能在家过中秋节。</p>
<p>一共在家里躺平了三个月零一天，合计 93 天。按照每天平均 7
小时睡眠，在家躺平（物理）了差不多四周。</p>
<h1 id="出游">出游</h1>
<p>考虑到大概率要润出去读研，再往后的日子根本不知道人在哪里，现在就已经感觉到在家、在上海的时间越来越少。所以出去玩未尝不是一种未雨绸缪（啥啊</p>
<p>和友人出去一起吃饭，逛中华艺术宫<del>然后写了几句北京欢迎你塞进意见箱里</del>，debug，借电脑跑神经网络，学习一些北大开学才考的线性代数，以及单纯地逛街。今年夏天实在太热了，而我本来就怕热，所以出去的时间并不多。多数时间也是在商场里走走然后在咖啡厅坐坐，聊聊天。还有和老母亲一起出门逛街，陪她去看病或者她陪我拔牙什么的。</p>
<p>静安大悦城，长宁龙之梦，五角场，徐家汇&amp;天玥桥路，中华艺术宫，世博源，虹口龙之梦，七宝万科，第九人民医院。</p>
<p>在静安大悦城的星巴克陪友人写线代的时候，从 lib-pku 仓库的 PR
里找到了<a href="https://github.com/lib-pku/libpku/pull/70">北大的最新往年题</a>，感觉出的不错，比华子的人肉计算器考法不知道高到哪儿去了。印象里有个证明矩阵可以奇异值分解的题，想来他们没讲过这个，也不会像华子一样出在卷子里算半天。还有个介绍半天对偶空间然后写写基就行了的压轴题，蛮好玩的。往前翻翻零几年的卷子，怎么线代里还出张量，他们四学分的课这么能塞吗。</p>
<p>不过遗憾是今年秋季学期，交大和华子同时开学，没来得及去找同学玩。寒假还是错开的，到时候再去聚吧。</p>
<h1 id="读闲书">读闲书</h1>
<p>老母亲在家有个习惯，看到我总会问问我在做什么。我也不想一副天天在看手机摸鱼的样子，或者对着电脑眼睛瞎掉，也不想真的天天看数学书。所以把家里的闲书，看过的或者没看过的，挑一些轻薄的小册子拿出来读读，大概这样。</p>
<p>其实我喜欢在开学的时候，带一些富有启发性的小册子，或者非常喜爱的书回学校。一个学期可能都没什么时间或者心情去看它们，但是摆在书架上就让我安慰一些。如果很喜欢的话可能还会假期再带回家看看。</p>
<ul>
<li>大一入学的时候从家里寄了个顺丰大件去学校，带了几本比较厚的《枪炮、病菌与钢铁》，《一个陌生女人的来信》，《线》（维多利亚·希斯洛普），还有《万历十五年》。</li>
<li>寒假回去带了《面纱》（毛姆），《汴京残梦》，《文城》，《恋爱的犀牛》，《病毒来袭》。</li>
<li>这次带上了《中国历代政治得失》，《人类存在的意义》，《英语写作手册——风格的要素》，《日出酒店》（维多利亚·希斯洛普）。</li>
</ul>
<h1 id="看剧">看剧</h1>
<ul>
<li>为了看周迅，去看了剧版《红高粱》，日剧《母亲》的改编《不完美的她》（可惜是烂剧），还有电影《苏州河》。</li>
<li>五月的时候在北京没有看成话剧《恋爱的犀牛》，于是把当年<a href="https://www.bilibili.com/video/BV1ct411k7Vj?spm_id_from=333.337.search-card.all.click">在高中看的话剧社版</a>，还有<a href="https://www.bilibili.com/video/BV1Ku411f7Vy?spm_id_from=333.337.search-card.all.click">段奕宏郝蕾版</a>的都刷了几遍。</li>
<li>还有陪老母亲看的《康熙王朝》，童年回忆了，虽然现在看感觉剧本挺一般，但是演员演技都真不错。</li>
</ul>
<h1 id="码">码</h1>
<ul>
<li>带了软院程设教材回家，重刷 C/C++
的过程中感觉自己真的菜。其实那是一篇没有写完就弃坑了的博客来着...于是打算退了下学期的数据结构，仍然怀疑自己不适合、貌似也不是特别喜欢干这个。
<ul>
<li>那我应该干点什么呢？</li>
</ul></li>
<li>参加了 SAST 暑培的 AI
Track，了解了一点神经网络的知识，为此还重学了一下 Python，刷了《Python
Crash Course》，收获良多。之前的博客写到过。《DS
Tutorial》翻了一部分，没事就看两眼。所以，或许努努力还可以成为数据科学家？（x</li>
<li>有点担心下学期的统辅课和数值分析实验，浅看了一下 R
的文档，大概可能也许是会了。MATLAB
还没动，之前答应好同学说暑假去了解一下数学建模，寒假完打美赛，也咕了。</li>
<li>说到建模比赛，本来是<del>为了奖金</del>想参加九月的高教社建模比赛的。结果一查获奖名单，好几百个一等奖和好几百个二等奖里，每年就两三个华子的队伍。于是开始怀疑<del>参加了恐怕会成为人生污点</del>，在这方面也打不过专门准备这个比赛的学校，遂作罢。</li>
</ul>
<h1 id="数学">数学</h1>
<ul>
<li><p>初概要来了
PPT，看了一点感觉不难就没下文了。统推在后八周，需要前置，所以彻底没看。</p></li>
<li><p>数值分析看了两章，总感觉自学就有点人肉计算器，不知道上课会怎么讲，实验怎么搞，打算等开学。（对华子的教学水平抱有最后的信心</p></li>
<li><p>抽代看的最多，群看完了环开了头，不过看的是复旦姚慕生，习题很水，翻译翻得我怀疑人生，还没有索引。比如一上来的么元，懂了，断么九（这个“么”在
QQ 的聊天字体里还挺像“幺”的，笑死。</p></li>
<li><p>ODE
没选数学系的，两学分的课权当辅助数值分析了，问题不大。</p></li>
<li><p>本来想退了数据结构换成离散的，但又觉得冲不动了，于是打算换个通识课。离散正好有未央计划的网课，大不了之后去水个绩点。</p></li>
</ul>
<p>总结：基本没学，不负责任地把一切交给学期中的自己。</p>
<p>其实也一直在纠结，比如我毫无分析基础，微积分摆烂了，有没有必要补一下数分？然后又想茶园也就是上了微积分线代就开抽代了，想来问题不大。读抽代的时候感觉它在骂我之前学的竞赛和代数都是
trivial 情况，有被骂到。然后还去翻了翻以前的竞赛笔记，上 <a href="https://artofproblemsolving.com/">AOPS</a>
看了一眼，发现古早的时候我的用户名并没有那么整整齐齐地叫
“驰雨Chiyuru”，可惜改不了了。给自己的账号补了补个人简介，回了一封高二时候发出去的关于
VMO 题目私信的回复（</p>
<h1 id="发呆摸鱼和杂项">发呆摸鱼和杂项</h1>
<ul>
<li>反复调整选课策略，比如思考到最后决定退掉基础拓扑学（浪费了任选一志愿），灵机一动打算补退选加塞一门经管学院的社科通识《工程经济学》（我的必修是土木系的工程经济学，想来差别不会巨大，可以摸鱼），数据结构也想退掉了。还在犹豫离散、ODE
二选一的话要选谁。试了试选北大课，意料之中地失败了，下学期再来吧.jpg</li>
<li>听歌，打了几次音游和
FGO，歌单加了十几首歌。闭社个人页面里的“最近爱听”更新速度总是追不上我换歌的速度。</li>
<li>和朋友们一起写了 Sharygin
2022，在此之前还研究了一下下学期的物理实验。</li>
<li>在想怎么做
SRT，现有的院系里的几个朋友在这方面靠不太住，我自己也立不出项，坐等报名。另外就是进实验室打工的问题，打算上几节课之后约
OOH
和初概的老师聊聊，或者去找抽代老师聊聊？但我本人并不是学纯数的料就是了（</li>
<li>玩了玩 thuservice 里的东西，给自己开了个闭社校友站的号。发现了 <a href="https://rekcarc-tsc-uht.readthedocs.io/en/latest/index.html">THU-CST-Cracker</a>，才知道原来高代选讲是贵系必修，难怪上学期班里那么多贵系的，我还以为都是来凑热闹的。这样的话会不会其实有很多人和我一样，微积分
A2 拿 B+，但是高代选拿 A 的呢ww。</li>
</ul>
<h1 id="突然想起来还有个夏季小学期">突然想起来还有个夏季小学期</h1>
<ul>
<li>没报程设是我的失误，不过反正我也不是第一回失误了。</li>
<li>逻辑讲座上得很开心。</li>
<li>制图无疑要喜提 3.6，但是不 3.3 就是大好事。</li>
<li>毛概不至于 F。</li>
<li>认识实习在家/在高铁上/在寝室通过腾讯会议看别人上工地，爽死。虽然周末就要交两份报告了，但我还没开始也不知道怎么开始，摆烂。</li>
</ul>
<p>暑期学期绩点好像肯定会有点低，不过这只是 GPA
下行的开始，习惯就好。</p>
<h1 id="后记爬回学校">后记·爬回学校</h1>
<p>回学校收拾完寝室的第一件事，是验证 GitHub 学生身份（</p>
<p>前前后后被 Reject 了近十次，理由分别有：</p>
<ul>
<li>开了梯子所以 ip 地址不在学校所在地</li>
<li>人在上海所以 ip 地址不在学校所在地</li>
<li>校园卡上的学校英文名用前置摄像头拍出来太糊，识别不了</li>
<li>虽然有直接上传高清学生证照片而不是当场拍照的选项，但是传了也会被
reject，建议当场拍照（</li>
<li>虽然录取通知书上的 Tsinghua University
字够大，但是在校生不能用录取通知书认证（</li>
</ul>
<p>最后的解决方案是把录取通知书垫在校园卡后面拍了个照，秒过，什么人工智障（</p>
<p>然后到学校一天多了还没去注册，差点忘记这事了。</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
        <tag>躺平</tag>
      </tags>
  </entry>
  <entry>
    <title>你知道茴字的四种写法吗？</title>
    <url>/2022/09/19/huixiangdou/</url>
    <content><![CDATA[<p>看到“满同态”还可以被叫做“映上同态”，并且后面的习题确实这么问了的时候，我的第一反应就是：你知道茴字的四种写法吗？</p>
<p>以及，“映上同态”这个词听起来莫名很日式（</p>
<span id="more"></span>
<h1 id="群论">群论</h1>
<p>群论还没过半我就被名词绕进去了，写作业难点不在题，而在于看完题干疯狂翻“某些定义并不复杂但不知道叫什么的名词”（现实世界没有
Ctrl+F 真麻烦啊），所以开了个坑。</p>
<p>平时给自己检索用，然后考前复看一下？</p>
<h2 id="群的定义">群的定义</h2>
<ul>
<li><span class="math inline">\(GL_n(K)\)</span> 被称为域 <span class="math inline">\(K\)</span> 上的 <span class="math inline">\(n\)</span> 阶一般线性群。元素为 <span class="math inline">\(K\)</span> 上的 <span class="math inline">\(n\times n\)</span> 非异矩阵全体，运算为矩阵乘法。
<ul>
<li><span class="math inline">\(SL_n(K)\)</span> 称为域 <span class="math inline">\(K\)</span> 上的 <span class="math inline">\(n\)</span> 阶特殊线性群。相对 <span class="math inline">\(GL_n(K)\)</span> 来说，<span class="math inline">\(SL_n(K)\)</span> 对其元素多一个约束，即行列式值为
<span class="math inline">\(1\)</span>。</li>
</ul></li>
<li><span class="math inline">\(Hamilton\)</span> 四元数群：<span class="math inline">\(H=\lbrace \pm 1, \pm i, \pm j, \pm k
\rbrace\)</span>。</li>
</ul>
<h2 id="子群">子群</h2>
<ul>
<li>由 <span class="math inline">\(S\)</span> 生成的子群 $S $ ：<span class="math inline">\(S\)</span> 是群 <span class="math inline">\(G\)</span> 的子集，<span class="math inline">\(G\)</span> 中所有包含 <span class="math inline">\(S\)</span> 的子集的交称为 <span class="math inline">\(\langle S \rangle\)</span> ，其元素称为 <span class="math inline">\(\langle S \rangle\)</span> 的生成元。
<ul>
<li>如果 <span class="math inline">\(S\)</span> 是一个有限集，那么 <span class="math inline">\(\langle S \rangle\)</span>
称为有限生成的子群；</li>
<li>如果 <span class="math inline">\(G\)</span>
可以被一个有限集生成，那么 <span class="math inline">\(G\)</span>
被称为有限生成的群；</li>
<li>循环群。</li>
</ul></li>
</ul>
<h2 id="傍集正规群">傍集，正规群</h2>
<ul>
<li>右傍集也叫做右伴集。对于群 <span class="math inline">\(G\)</span>
及其子群 <span class="math inline">\(H\)</span>，右傍集的个数称为子群
<span class="math inline">\(H\)</span> 在 <span class="math inline">\(G\)</span> 中的<strong>指数</strong>，记为 <span class="math inline">\([G:H]\)</span>。</li>
<li>单群：群 <span class="math inline">\(G\)</span> 只有 <span class="math inline">\(G,\lbrace e\rbrace\)</span>
（此二者称为平凡正规子群）作为正规子群，则称 <span class="math inline">\(G\)</span> 为单群。</li>
<li>正规化子：对于群 <span class="math inline">\(G\)</span> 及其子群
<span class="math inline">\(H\)</span>，取 <span class="math inline">\(N(H)=\lbrace g\in G | gH=Hg \rbrace\)</span> 为
<span class="math inline">\(H\)</span> 在 <span class="math inline">\(G\)</span> 中的正规化子，<span class="math inline">\(H\)</span> 是它的正规子群。</li>
<li>换位子子群，换位子元：称 <span class="math inline">\([a,b]=a^{-1}
b^{-1} ab\)</span> 为 <span class="math inline">\(a\)</span> 和 <span class="math inline">\(b\)</span> 的换位子元，<span class="math inline">\(G\)</span> 上所有换位子元生成的子群称为 <span class="math inline">\(G\)</span>
的换位子子群，<strong>也叫做导群</strong>，记为 <span class="math inline">\([G,G]\)</span>。它是 <span class="math inline">\(G\)</span> 的正规子群。</li>
<li>极大正规子群是<strong>非平凡的</strong>阶数最大的正规子群。</li>
<li>注：虽然右傍集的等价关系耳熟能详，但是左傍集 <span class="math inline">\(aH=bH\)</span> 等价于 <span class="math inline">\(a^{-1}b \in H\)</span>。</li>
</ul>
<h2 id="同态">同态</h2>
<ul>
<li>对于 <span class="math inline">\(G_1\rightarrow G_2\)</span>
上的同态 <span class="math inline">\(f\)</span>，单映射称为单同态，满映射称为满同态或<strong>映上同态</strong>。双射称为同构。
<ul>
<li>如果 <span class="math inline">\(G_1=G_2\)</span>，<span class="math inline">\(f\)</span> 称为自同态；如果 <span class="math inline">\(f\)</span> 同时还为同构，称为自同构。<span class="math inline">\(G\)</span> 上自同构组成的群为 <span class="math inline">\(Aut(G)\)</span>。</li>
<li>平凡同态，就是把所有的 <span class="math inline">\(G_1\)</span>
元素映射到 <span class="math inline">\(G_2\)</span>
的幺元。（开始摆烂解释</li>
<li><span class="math inline">\(G\rightarrow G\)</span> 上的恒等自同构
<span class="math inline">\(Id_G\)</span>。</li>
<li>内自同构：<span class="math inline">\(a\)</span> 是群 <span class="math inline">\(G\)</span> 上的一个元素，<span class="math inline">\(G\rightarrow G\)</span>上的映射 <span class="math inline">\(\phi_a:\phi_a(x)=axa^{-1}\)</span>
称为内自同构。这样的同构组成的群为 <span class="math inline">\(Inn(G)\)</span>。</li>
<li><span class="math inline">\(H\)</span> 是群 <span class="math inline">\(G\)</span> 的正规子群，<span class="math inline">\(G\)</span> 到商集 <span class="math inline">\(G /
H\)</span> 上的自然映射称为<strong>自然同态</strong>。</li>
</ul></li>
<li>对于 <span class="math inline">\(G_1\rightarrow G_2\)</span>
上的同态 <span class="math inline">\(f\)</span>，<span class="math inline">\(Im f\)</span> 称为 <span class="math inline">\(G_1\)</span> 在 <span class="math inline">\(f\)</span> 下的同态像。</li>
<li>此处还有同态基本定理，对应定理，第一、二同构定理。<del>这里空间太小了写不下</del></li>
</ul>
<h2 id="循环群">循环群</h2>
<ul>
<li><span class="math inline">\(U_n\)</span> 由小于 <span class="math inline">\(n\)</span> 且与 <span class="math inline">\(n\)</span> 互素的正整数组成，<span class="math inline">\(G\)</span> 中元素的运算遵从 <span class="math inline">\(mk\equiv s(mod\; n)\)</span>。
<ul>
<li>这个定义可以用来证明欧拉公式，以及有结论 <span class="math inline">\(Aut(Z_n)\cong U_n\)</span>。</li>
</ul></li>
<li>插播一个吐槽：本节习题 <span class="math inline">\(6\)</span>
的“两个”是在修饰“无限循环群”，而不是修饰“映上同态”（悲</li>
</ul>
<h2 id="置换群">置换群</h2>
<ul>
<li><p>集合（注意不必为群） <span class="math inline">\(S\)</span>
上的变换群 <span class="math inline">\(A(S)\)</span>：<span class="math inline">\(S\)</span> 上所有一一对应组成 <span class="math inline">\(A(S)\)</span>。</p>
<ul>
<li><p>集合 <span class="math inline">\(S\)</span> 上的置换群：当 <span class="math inline">\(S\)</span> 是有限集时，<span class="math inline">\(A(S)\)</span> 的任一子群为 <span class="math inline">\(S\)</span> 上的置换群。</p></li>
<li><p><span class="math inline">\(Cayley\)</span> 定理叙述了任一群
<span class="math inline">\(G\)</span>
必同构于某一集合（证明中给出的正是 <span class="math inline">\(G\)</span>）上的变换群。</p>
<p>（碎碎念，总感觉 <span class="math inline">\(Cayley\)</span>
定理这个名字好像数竞的时候也见过，但是完全忘记是什么了。不知道是不是特定群下的简化情况然后拿给高中生玩了，或者单纯是重名？）</p></li>
<li><p>左平移：对于 <span class="math inline">\(g \in G\)</span>，定义
<span class="math inline">\(G \rightarrow G\)</span> 上的映射 <span class="math inline">\(\tau _g (x) = gx,x\in G\)</span> 为由 <span class="math inline">\(g\)</span> 决定的 <span class="math inline">\(G\)</span> 的左平移。</p></li>
<li><p>类似地可以定义右平移。</p></li>
</ul></li>
<li><p>任一置换可以表示为若干个对换的乘积，对换的个数决定了置换是奇置换还是偶置换。</p>
<ul>
<li><p>特殊的置换 <span class="math inline">\(k-\)</span>循环的奇偶性与
<span class="math inline">\(k+1\)</span> 相同。</p>
<p>（这是因为 <span class="math inline">\((i_1,i_2,...i_k) = (1, i_1)(1,
i_2)...(1,i_k)(1,i_1)\)</span>.</p></li>
<li><p>换一种观点，每一个置换群对应一个置换矩阵，其奇偶性和该矩阵的行列式的正负性统一。</p></li>
</ul></li>
<li><p><span class="math inline">\(n\)</span> 次对称群 <span class="math inline">\(S_n\)</span>：阶为 <span class="math inline">\(n\)</span> 的集合 <span class="math inline">\(X\)</span> 上的所有置换构成群 <span class="math inline">\(S(X)\)</span>，当我们把 <span class="math inline">\(X\)</span> 的所有元素抽象为带有下标的 <span class="math inline">\(x_1,...,x_n\)</span> 来研究置换时，就将 <span class="math inline">\(S(X)\)</span> 记为 <span class="math inline">\(S_n\)</span>。说人话的话，就是在集合 <span class="math inline">\(\lbrace 1,2,...,n \rbrace\)</span>
上的所有置换构成的群，称为 <span class="math inline">\(n\)</span>
次对称群 <span class="math inline">\(S_n\)</span>.</p>
<ul>
<li><span class="math inline">\(S_n\)</span> 上的全体偶置换构成的群
<span class="math inline">\(A_n\)</span> 称为 <span class="math inline">\(n\)</span> 次交换群，其阶数为 <span class="math inline">\(S_n\)</span> 的一半，即 <span class="math inline">\(\frac{1}{2} n!\)</span>.</li>
<li>一个特例：<span class="math inline">\(A_4\)</span> 上的特殊正规子群
<span class="math inline">\(K = \lbrace
(1),(1,2)(3,4),(1,3)(2,4),(1,4)(2,3) \rbrace\)</span> 称为 <span class="math inline">\(Klein\)</span> 四元群。<span class="math inline">\(Klein\)</span> 四元群还有正规子群 <span class="math inline">\(H=\lbrace (1),(1,2)(3,4)\rbrace\)</span>，但 <span class="math inline">\(H\)</span> 并不是 <span class="math inline">\(A_4\)</span>
的正规子群，呼应了前面章节提过的正规子群不具有传递性。同时，<span class="math inline">\(A_4\)</span> 上并无 <span class="math inline">\(6\)</span> 阶正规子群（见习题）。</li>
</ul></li>
<li><p>真的搞清楚什么是置换群，什么是变换群，什么是对称群了吗？</p>
<ul>
<li><p><span class="math inline">\(S\)</span> 上的变换群记为 <span class="math inline">\(A(S)\)</span>，表示所有 <span class="math inline">\(S\)</span> 上的一一对应（<span class="math inline">\(S\)</span>
未必是群，不能称自同构）。对称群的元素是 <span class="math inline">\(X\)</span> 上的所有置换，记为 <span class="math inline">\(S(X)\)</span> 也记作 <span class="math inline">\(S_n\)</span>。置换群是对称群的子群。</p>
<p>注：此处按照 hx
给出的讲义定义，目的是方便作业和考试。读者请在老师的说法或至少一本靠谱的教材（起码不是复旦绿皮）中得到定义。</p></li>
<li><p>hx
课上的讲法是为了不引起混淆，把置换群和对称群视作同一个东西。但是这让我更混淆了（</p></li>
<li><p>书上的区别在于把置换群当做变换群的子群了。本质上我觉得变换群和对称群是同一个东西，至少可以同构，无非一个更抽象。所以也问题不大。</p></li>
</ul></li>
</ul>
<h2 id="群作用">群作用</h2>
<ul>
<li><p>群对于集合的作用体现在元素和元素的层面，例如集合的置换群作用在该集合上的过程。</p></li>
<li><p>定义好 <span class="math inline">\(G\times S \to S\)</span>
的左作用后，我们可以称 <span class="math inline">\(G\)</span> 在 <span class="math inline">\(S\)</span> 上定义了一个左作用，集合 <span class="math inline">\(S\)</span> 称为一个 <span class="math inline">\(G-\)</span>集合。</p></li>
<li><p>共轭作用：定义 <span class="math inline">\(G\times G \to
G\)</span> 上的作用 <span class="math inline">\(a*x=a^{-1}xa,a\in G,x
\in G\)</span> 为 <span class="math inline">\(G\)</span>
对自身的共轭作用，<span class="math inline">\(a^{-1}xa\)</span> 称为
<span class="math inline">\(x\)</span> 的共轭元。</p></li>
<li><p>对于 <span class="math inline">\(G-\)</span>集合 <span class="math inline">\(S\)</span>，记 <span class="math inline">\(Stab\\;
x =\lbrace g \in G | g*x=x\rbrace,x \in S\)</span> 为 <span class="math inline">\(x\)</span> 在 <span class="math inline">\(G\)</span> 中的稳定化子，也称 <span class="math inline">\(x\)</span> 的迷向子群。（什么迷神x</p>
<ul>
<li><p>请不要和子群的正规化子 <span class="math inline">\(N(H)\)</span>
搞混了，尽管在某一个例子里我们得到了某群的稳定化子即为正规化子。</p></li>
<li><p>于是对任意 <span class="math inline">\(x\in S\)</span>，有 <span class="math inline">\(|Gx|=[G:Stab \\; x]\)</span> （证明时考虑 <span class="math inline">\(G/Stab \\; x\)</span> 与 <span class="math inline">\(Gx\)</span>
之间的群同构即可）。这得到了每个轨道中的元素个数。</p></li>
<li><p>反过来，我们用轨道的元素个数统计 <span class="math inline">\(S\)</span> 的大小，有 <span class="math inline">\(|S|=\Sigma_{x\in C} \lbrace G:Stab \\;
x\rbrace\)</span> ，<span class="math inline">\(C\)</span>
是各个轨道中的代表元集。</p></li>
</ul></li>
<li><p>对于有限集 <span class="math inline">\(G\)</span>，<span class="math inline">\(C\)</span> 是它的中心，于是 <span class="math inline">\(|G|=|C|+\Sigma [G:C(y_i)]\)</span>，其中 <span class="math inline">\(C(y_i)\)</span> 代表 <span class="math inline">\(y_i\)</span> 在群 <span class="math inline">\(G\)</span> 中的中心化子，<span class="math inline">\(y_i\)</span> 跑遍 <span class="math inline">\(G\)</span>
中含不止一个元素的共轭类的全体。（证明：利用 <span class="math inline">\(G\)</span> 在自身上的共轭作用）</p>
<ul>
<li>也不要把中心化子和稳定化子，正规化子搞混了。中心化子针对群的元素给出一些与其交换的元素，稳定化子针对
<span class="math inline">\(G-\)</span>群的元素给出一些能构成 <span class="math inline">\(G\)</span>
的子群的元素，而正规化子针对某个群的子群给出一些使其左右傍集相等的元素。（绕口令</li>
</ul></li>
<li><p>有限群的阶为 <span class="math inline">\(p^m\)</span>，其中 <span class="math inline">\(p\)</span> 为素数，则称该群为 <span class="math inline">\(p\)</span> 群。任意 <span class="math inline">\(p\)</span>
群的中心含有不止一个元素。（证明：利用上一条结论）</p></li>
<li><p><span class="math inline">\(p^2\)</span> 阶群是 <span class="math inline">\(Abel\)</span> 群。</p></li>
<li><p>如果 <span class="math inline">\(S\)</span> 是一个 <span class="math inline">\(G-\)</span>集合且 <span class="math inline">\(S\)</span> 在 <span class="math inline">\(G\)</span> 的作用下的轨道只有一个，也即对任意
<span class="math inline">\(x\in S\)</span> 有 <span class="math inline">\(Gx=S\)</span>，那么称 <span class="math inline">\(G\)</span> 在 <span class="math inline">\(S\)</span> 上的作用是可迁的，称 <span class="math inline">\(G\)</span> 是一个可迁群。</p>
<ul>
<li>举个例子：<span class="math inline">\(S_n\)</span> 是可迁群。</li>
</ul></li>
</ul>
<h2 id="sylow-定理">Sylow 定理</h2>
<p>其实这里也没什么好说的，做课后题就知道了（</p>
<ul>
<li>关于书后那一堆 <span class="math inline">\(k\)</span>
阶群有无单群的分析，引用一段 Math StackExchange 一个问题下的<a href="https://math.stackexchange.com/questions/843162/how-to-prove-a-group-g-of-order-72-cant-be-a-simple-group#comment1738903_843162">评论</a>：</li>
</ul>
<blockquote>
<p>Most questions of this type (when you first see them) can be solved
using one of the following three methods.</p>
<ol type="1">
<li>Show that, for some prime <span class="math inline">\(p\)</span>,
<span class="math inline">\(G\)</span> must have a unique Sylow-<span class="math inline">\(p\)</span> subgroup.</li>
<li>Show that if <span class="math inline">\(G\)</span> fails to have
any normal Sylow subgroups, you end up accounting for more elements of
Sylow subgroups then there are in your group.</li>
<li>Show that, if <span class="math inline">\(G\)</span> has a
Sylow-<span class="math inline">\(p\)</span> subgroup, then <span class="math inline">\(|G|\)</span> does not divide <span class="math inline">\(n_p(G)!\)</span>. This implies that <span class="math inline">\(G\)</span> is non-simple.</li>
</ol>
</blockquote>
<ul>
<li><p>还有一个证了 <span class="math inline">\(100\)</span>
以内阶群只有 <span class="math inline">\(60\)</span>
阶和素数阶可能是单群的问题，蛮有意思的：<a href="https://math.stackexchange.com/questions/480558/g-is-non-abelian-simple-group-of-order-100-then-g-cong-a-5">Click
Here</a></p>
<p>我自己动手试过一次，比较难的就是证明 <span class="math inline">\(90\)</span> 阶群有正规子群，这和书上那个 <span class="math inline">\(108\)</span> 阶的例题思路完全一样。</p></li>
<li><p>另一个有用的工具是书上那个证了 <span class="math inline">\(pq\)</span> 阶群最多有两种形态的例题。</p></li>
</ul>
<h2 id="群的直积">群的直积</h2>
<ul>
<li>内直积的三个判定法则，以及习题中（习题9）补充的一个。就，复习的时候记得证明一下。</li>
</ul>
<h2 id="有限生成-abel-群">有限生成 Abel 群</h2>
<ul>
<li><p><span class="math inline">\(G\)</span> 是有限生成 <span class="math inline">\(Abel\)</span> 群，可以分解为有限个循环群 <span class="math inline">\(C_i\)</span> 的直和：<span class="math inline">\(G=C_1\oplus C_2\oplus...\oplus
C_k\)</span>，其中存在某个 <span class="math inline">\(j\leq k\)</span>
使得 <span class="math inline">\(C_1,C_2,...,C_j\)</span>
是有限循环群，<span class="math inline">\(C_{j+1},...,C_k\)</span>
是无限循环群。称无限循环群的个数 <span class="math inline">\(k-j\)</span> 是 <span class="math inline">\(G\)</span> 的秩，称有限循环群的阶 <span class="math inline">\(m_1,m_2,...m_j\)</span> 是 <span class="math inline">\(G\)</span> 的不变因子组。</p>
<ul>
<li>由 <span class="math inline">\(G\)</span>
直和分解的唯一性，知不变因子组和秩都是不变量。</li>
<li>给定秩数和不变因子组，也唯一确定了有限生成 <span class="math inline">\(Abel\)</span> 群。</li>
</ul></li>
<li><p>如果有限生成 <span class="math inline">\(Abel\)</span> 群 <span class="math inline">\(G\)</span>
可以分解为有限个无限循环群的直和，称其为有限生成的自由 <span class="math inline">\(Abel\)</span> 群。</p>
<p>Dobby is a free <del>elf</del> abelian group!</p></li>
<li><p>称数组 <span class="math inline">\((e_1,e_2,...,e_k)\)</span>
是自然数 <span class="math inline">\(n\)</span> 的一个分划，如果 <span class="math inline">\(1\leq e_1\leq e_2\leq ...\leq
e_k\)</span>，且<span class="math inline">\(n=e_1+e_2+...+e_k\)</span>。<span class="math inline">\(P(n)\)</span> 表示 <span class="math inline">\(n\)</span> 的分划数。</p>
<ul>
<li><p>当 <span class="math inline">\(p\)</span> 是一个素数时，阶为
<span class="math inline">\(p^n\)</span> 的 <span class="math inline">\(Abel\)</span> 群同构类集与 <span class="math inline">\(n\)</span>
的分划集之间存在一个一一对应。（Trivial</p></li>
<li><p><span class="math inline">\(n=p_1^{f_1} p_2^{f_2}...
p_k^{f_k}\)</span> 为其素因子分解，互不同构的 <span class="math inline">\(n\)</span> 阶 <span class="math inline">\(Abel\)</span> 群的个数等于 <span class="math inline">\(P(f_1)P(f_2)...P(f_k)\)</span>。（考虑每个 Sylow
子群的再分解即可</p>
<p>这样作出的分解与 <span class="math inline">\(G\)</span>
的直和分解并不相同，需要再进行合并。</p></li>
<li><p>取 <span class="math inline">\(n=p_1^{f_1} p_2^{f_2}...
p_k^{f_k}\)</span> 的初等因子组（书上那个方阵），它和 <span class="math inline">\(n\)</span>
阶群的不变因子组之间一一对应。（Trivial</p></li>
</ul></li>
<li><p>分解的时候先注意一下它是不是个 <span class="math inline">\(Abel\)</span> 群，别 sb 了（</p></li>
</ul>
<h2 id="正规群列与可解群">正规群列与可解群</h2>
<ul>
<li>合成群列是保证群列中的商因子 <span class="math inline">\(G_{i+1}/G_i\)</span> 均为单群，也即 <span class="math inline">\(G_i\)</span> 是 <span class="math inline">\(G_{i+1}\)</span>
的极大正规子群的正规群列。不是所有的群都有合成群列，有限群一定有，无限群可能没有，例如整数加法群。</li>
<li>可解群：记群 <span class="math inline">\(G\)</span> 的合成群列为
<span class="math inline">\(\lbrace e\rbrace=G_0\triangleleft
G_1\triangleleft ... \triangleleft G_r=G\)</span>，其商因子 <span class="math inline">\(G_{i+1}/G_{i}\)</span> 均为 <span class="math inline">\(Abel\)</span> 群时称 <span class="math inline">\(G\)</span>
为可解群，否则称不可解（什么不可解，唱起来了（x
<ul>
<li>素数幂阶群是可解群。</li>
<li>有限 <span class="math inline">\(Abel\)</span> 群是可解群。</li>
<li>可解群的子群和同态像还是可解群；如果 <span class="math inline">\(G\)</span> 的正规子群 <span class="math inline">\(K\)</span> 满足 <span class="math inline">\(K\)</span> 和 <span class="math inline">\(G/K\)</span> 是可解群，则 <span class="math inline">\(G\)</span> 是可解群。</li>
<li><span class="math inline">\(G\)</span> 是可解群等价于其 <span class="math inline">\(n\)</span> 次导群（换位子子群）为 <span class="math inline">\(\lbrace e \rbrace\)</span>。</li>
<li><span class="math inline">\(G\)</span> 是可解群也等价于其商因子
<span class="math inline">\(G_{i+1}/G_{i}\)</span>
都是素数阶（循环）群。</li>
</ul></li>
<li>上中心列：<span class="math inline">\(G\)</span> 是一个群，其中心为
<span class="math inline">\(C\)</span>，记为 <span class="math inline">\(C_1\)</span>。作 <span class="math inline">\(G/C_1\)</span> 的中心 <span class="math inline">\(C_2/C_1\)</span>，于是得到 <span class="math inline">\(C_1\triangleleft C_2 \triangleleft G\)</span> 且
<span class="math inline">\(C_2\)</span> 唯一确定。依次得到 <span class="math inline">\(C_1,C_2,...,C_n\)</span>，它们形成一个 <span class="math inline">\(G\)</span> 的正规群列，称为上中心列。</li>
<li>当 <span class="math inline">\(G\)</span> 的 <span class="math inline">\(n\)</span> 次中心 <span class="math inline">\(C_n=G\)</span> 时，称 <span class="math inline">\(G\)</span> 为幂零群。满足此条件的最小的 <span class="math inline">\(n\)</span> 称为 <span class="math inline">\(G\)</span> 的幂指数。
<ul>
<li><span class="math inline">\(G\)</span> 是幂零群还等价于 <span class="math inline">\(G\)</span> 有一个正规群列 <span class="math inline">\(\lbrace e\rbrace=G_0\triangleleft G_1\triangleleft
... \triangleleft G_r=G\)</span>，使得 <span class="math inline">\(G_i/G_{i-1} \subseteq
C(G/G_{i-1})\)</span>。这里要求每个 <span class="math inline">\(G_i
\triangleleft G\)</span>，即使正规子群不存在传递性。</li>
</ul></li>
</ul>
<h1 id="环论">环论</h1>
<p>第六周第二节课，环论。（</p>
<h2 id="环的定义">环的定义</h2>
<ul>
<li><p>非空集合 <span class="math inline">\(R\)</span>
上定义了加法和乘法，且满足乘法分配率和结合律，<span class="math inline">\((R,+)\)</span> 是加法群时称 <span class="math inline">\(R\)</span> 为一个环，加法群的幺元 <span class="math inline">\(0\)</span> 称为零元素。如果 <span class="math inline">\(R\)</span> 上的乘法也有幺元，称其为恒等元，<span class="math inline">\(R\)</span> 称为带恒等元的环。</p></li>
<li><p>一些有特殊名称的环：</p>
<ul>
<li>对模 <span class="math inline">\(n\)</span> 下的整数加法群 <span class="math inline">\(Z_n\)</span>，定义其上的乘法为模 <span class="math inline">\(n\)</span> 同余的乘法，则扩充为一环，称为模 <span class="math inline">\(n\)</span> 的整数环。</li>
<li><span class="math inline">\(Hamilton\)</span> 四元数环：<span class="math inline">\(1,i,j,k\)</span>
的线性组合构成此环，加法为线性加法，乘法与四元数群相同，满足结合律。</li>
<li>用现有的环 <span class="math inline">\(R\)</span> 中元素构造出的
<span class="math inline">\(n\times n\)</span> 矩阵全体称为 <span class="math inline">\(R\)</span> 上的 <span class="math inline">\(n\)</span> 阶矩阵环。运算服从普通矩阵。</li>
<li>加法群 <span class="math inline">\(M\)</span>
上的自同态全体构成的集合 <span class="math inline">\(EndM\)</span>
称为加法群的自同态环，乘法即为同态的复合。</li>
<li>对于现有的环 <span class="math inline">\(R\)</span>，在集合 <span class="math inline">\(R\)</span>
上定义一个新的环结构，加法不变，乘法的结果改为 <span class="math inline">\(a*b=ba\)</span>，则称新的环为 <span class="math inline">\(R\)</span> 的反环，记为 <span class="math inline">\(R^o\)</span> 或者 <span class="math inline">\(R^{op}\)</span>。</li>
<li>环 <span class="math inline">\(R\)</span> 上的形式幂级数环 <span class="math inline">\(R[[x]]\)</span>（上次见到双层中括号还是求期望）（这个我不是非常确信，等
hx 讲了再写吧，但感觉就是作为两个多项式相乘 /
相加得到的系数？）（Update：的确如此）</li>
</ul></li>
<li><p>环的不同类型：</p>
<ul>
<li><p>交换环。</p></li>
<li><p>无零因子的环称为整环。通俗来说，整环上不存在两个不为零但乘积为零的元素。这样的元素称为零因子，按其在等式中的位置称为左零因子和右零因子。</p></li>
<li><p>对于 <span class="math inline">\(R^*=R / \lbrace 0
\rbrace\)</span>，若其中任意元素都是可逆元，则称 <span class="math inline">\(R\)</span>
是一个除环。通俗来说，一个环除去零元素后每个元素都能找到逆元，也即构成一个群，则称为除环。</p>
<p>环元素的逆元按位置称为左逆元和右逆元，有左逆元 /
右逆元不保证存在右逆元 /
左逆元。如果一个元素的左右逆元相等，则称其有唯一的逆元，此元素称为可逆元或单位。</p></li>
<li><p>交换的除环称为域。也就是说，一个域去掉零元素后构成一个 <span class="math inline">\(Abel\)</span> 群。</p>
<p>有理数环，实数环，复数环都是域。四元数环是除环，但不是域。（每个元素的逆元易求）</p>
<p>域也可以是有限元素构成的。</p></li>
</ul></li>
</ul>
<h2 id="子环理想与商环">子环，理想与商环</h2>
<p>主要关心一些东西的定义过程，以及它们为什么是合理的。</p>
<ul>
<li><p>商环的定义过程：</p>
<ul>
<li>首先，找到一个等价关系来定义商群。<span class="math inline">\(I\)</span> 为环 <span class="math inline">\(R\)</span> 的一个理想，对 <span class="math inline">\(R\)</span> 中的元素 <span class="math inline">\(a,b\)</span>，称 <span class="math inline">\(a\sim
b\)</span> 当且仅当 <span class="math inline">\(a-b \in
I\)</span>。（验证其满足等价关系三性质）定义 <span class="math inline">\(R/I\)</span> 是商群。因为 <span class="math inline">\(R\)</span> 和 <span class="math inline">\(I\)</span> 都是加法群，则 <span class="math inline">\(R/I\)</span> 也是加法群，它的元素可以写成加法形式
<span class="math inline">\(\overline{a}=a+I\)</span>。</li>
<li>对于加法群 <span class="math inline">\(R/I\)</span>，在其上定义乘法让它成为一个环。定义
<span class="math inline">\((a+I)(b+I)=ab+I\)</span>（验证乘法良定义），再证明乘法对结合律和分配律都成立，于是
<span class="math inline">\(R/I\)</span> 是一个环，称为 <span class="math inline">\(R\)</span> 关于理想 <span class="math inline">\(I\)</span> 的商环。（有时也称为差环）</li>
</ul>
<p>比较遗憾的是，习题中商环内容基本没有出现。我对商群掌握的就不大好，所谓破碎的群知识（</p></li>
<li><p>环理想的运算：</p>
<ul>
<li><p>定义加法。环 <span class="math inline">\(R\)</span> 上的理想
<span class="math inline">\(I,J\)</span> 之间的所谓加法定义为 <span class="math inline">\(I+J=\lbrace a+b|a\in I,b\in
J\rbrace\)</span>，容易验证 <span class="math inline">\(I+J\)</span>
也是 <span class="math inline">\(R\)</span> 的理想，且可证明 <span class="math inline">\(I+J=(I \cup
J)\)</span>。注意此处是对并集做了生成理想。</p>
<p>若干个理想的加法定义类似。</p></li>
<li><p>定义乘法。环 <span class="math inline">\(R\)</span> 上的理想
<span class="math inline">\(I,J\)</span> 之间的所谓乘法定义为 <span class="math inline">\(IJ=\lbrace \Sigma a_ib_i | a_i\in I,b_i \in
J\rbrace\)</span>，容易验证 <span class="math inline">\(IJ\)</span> 也是
<span class="math inline">\(R\)</span> 的理想。且 <span class="math inline">\(I+J=R\)</span> 时，有 <span class="math inline">\(IJ=I\cap J\)</span>。（习题 <span class="math inline">\(15\)</span>）</p></li>
<li><p>于是我们可以证明，环理想的乘法满足分配律和结合律（习题 <span class="math inline">\(4,5\)</span>）。因此环的理想构成的集合满足一切除了加法逆元外的环性质。（未经确认的个人观点，我觉得环理想不能定义减法吧）</p></li>
</ul></li>
<li><p>理想的一些定理：</p>
<ul>
<li><p>带恒等元的交换环 <span class="math inline">\(R\)</span>
是域等价于 <span class="math inline">\(R\)</span>
只有平凡理想。</p></li>
<li><p>如果一个非交换环只有平凡理想而又不是除环，则称之为单环。</p>
<p>设 <span class="math inline">\(R\)</span> 是除环，则 <span class="math inline">\(M_n(R)\)</span>
是单环。（证明略复杂，见书）</p></li>
<li><p>一个技巧：某个环只有平凡理想的时候，可以手搓出来一些理想（比如某个元素生成的主理想），利用它和环相等来推性质；对应地，如果要证明某个环只有平凡理想，可以证明任意搓出来的非零理想中有恒等元。上面两个定理分别应用了这两条技巧，习题中也有用到的。</p></li>
<li><p>同时有非平凡的左理想和右理想不代表有非平凡理想。比如说，单环
<span class="math inline">\(M_n(R)\)</span>
有非平凡的左右理想。</p></li>
</ul></li>
</ul>
<h2 id="环同态">环同态</h2>
<p>和群同态基本一样，略（</p>
<h2 id="整环分式域">整环，分式域</h2>
<ul>
<li><p><span class="math inline">\(R\)</span> 是一个整环， <span class="math inline">\(a\)</span>
是其中的非零元，如果存在某个最小的正整数 <span class="math inline">\(m\)</span> 满足 <span class="math inline">\(ma=0\)</span>，则称其为 <span class="math inline">\(a\)</span> 的周期，<span class="math inline">\(a\)</span> 是周期元。</p>
<ul>
<li><p>如果 <span class="math inline">\(R\)</span>
上至少有一个周期元，则存在素数 <span class="math inline">\(p\)</span>，使得对 <span class="math inline">\(R\)</span> 的一切非零元 <span class="math inline">\(r\)</span> 都有 <span class="math inline">\(pr=0\)</span>，称 <span class="math inline">\(p\)</span> 为 <span class="math inline">\(R\)</span> 的特征。</p></li>
<li><p>如果 <span class="math inline">\(R\)</span>
上没有周期元，称其特征为 <span class="math inline">\(0\)</span>。</p></li>
</ul>
<p>特征一般指的是整环的特征，如果不是整环的话可能有不同周期的元素。</p>
<ul>
<li>特征为 <span class="math inline">\(p\)</span>
的任意域有一个最小子域，它同构于 <span class="math inline">\(Z_p\)</span>。称这个最小子域为素域。</li>
<li>特征为 <span class="math inline">\(0\)</span>
的任意域上也有素域的概念，记为 <span class="math inline">\(F_0=(1)\)</span>，它和有理数域同构。</li>
</ul></li>
<li><p>一个含有恒等元的交换整环称为整区。（叠
buff：交换，有恒等元，没有零因子，相比域只差了逆元这一项）在整区上可以用等价关系定义分式域，过程如下。（这就回到了数分（1）的第一节课）</p>
<ul>
<li><p>记 <span class="math inline">\(R\times R^*\)</span>
上的等价关系为 <span class="math inline">\((a,b)\sim (c,d)\)</span>
当且仅当 <span class="math inline">\(ad=bc\)</span>，记 <span class="math inline">\((a,b)\)</span> 的等价类为 <span class="math inline">\(\frac{a}{b}\)</span>，<span class="math inline">\(F\)</span> 为所有等价类的集合，于是 <span class="math inline">\(F\)</span> 就是由整区 <span class="math inline">\(R\)</span> 定义出来的分式域。</p></li>
<li><p>再在 <span class="math inline">\(F\)</span>
上定义加法和乘法，分别验证它们是良好定义的。</p></li>
<li><p>找出 <span class="math inline">\(F\)</span> 上的零元素 <span class="math inline">\(\frac{0}{a}\)</span> 和恒等元 <span class="math inline">\(\frac{a}{a}\)</span>。再验证 <span class="math inline">\(F\)</span>
是一个环，满足每个元素有逆元、没有零因子、交换，于是 <span class="math inline">\(F\)</span> 是一个域，称其为分式域。</p></li>
</ul>
<p>还可以在整区 <span class="math inline">\(R\)</span>
及其定义出的分式域 <span class="math inline">\(F\)</span> 上定义同态
<span class="math inline">\(f(r)=\frac{r}{1}\)</span>，于是 <span class="math inline">\(f\)</span> 是一个单同态，也称为标准嵌入。在 <span class="math inline">\(F\)</span> 上定义的单同态都称为嵌入。</p></li>
<li><p>定义得到标准嵌入后，我们还可以继续定义整区 <span class="math inline">\(R\)</span>，<span class="math inline">\(R\)</span>
定义出的分式域 <span class="math inline">\(F\)</span> 和另一个域 <span class="math inline">\(F&#39;\)</span>之间的映射关系。由此证明第一点中提到的特征为
<span class="math inline">\(0\)</span>
的域的素域与有理数域同构。</p></li>
</ul>
<h2 id="唯一分解环">唯一分解环</h2>
<p>以下讨论默认在整区中进行。</p>
<ul>
<li>真因子：若 <span class="math inline">\(b\)</span> 可以整除 <span class="math inline">\(a\)</span>，但 <span class="math inline">\(a\)</span> 不整除 <span class="math inline">\(b\)</span>，则称 <span class="math inline">\(b\)</span> 是 <span class="math inline">\(a\)</span> 的真因子。</li>
<li>如果 <span class="math inline">\(a|b\)</span> 且 <span class="math inline">\(b|a\)</span> 则 <span class="math inline">\(a,b\)</span> 之间相差一个单位，记作 <span class="math inline">\(a\sim b\)</span>，称为 <span class="math inline">\(a\)</span> 和 <span class="math inline">\(b\)</span> 相伴。</li>
<li>不可约元：整区中的元素 <span class="math inline">\(a\)</span>
如果不是单位且不能分解成两个真因子的乘积，则称为不可约元（类比素数）。</li>
<li>Gauss 整区，唯一分解环（Unique Factorization Domian）：<span class="math inline">\(R\)</span>
中任意一个非零且不是单位的元素都可以分解为有限个不可约元的乘积，且这种分解在相伴条件下唯一。则称
<span class="math inline">\(R\)</span> 是唯一分解环。
<ul>
<li>整区 <span class="math inline">\(R\)</span> 是唯一分解环等价于 <span class="math inline">\(R\)</span> 适合因子链条件和素性条件。</li>
<li>整区 <span class="math inline">\(R\)</span> 是唯一分解环等价于 <span class="math inline">\(R\)</span> 适合因子链条件和最大公因子条件。</li>
</ul></li>
<li>素元：若 <span class="math inline">\(p\)</span> 不是 <span class="math inline">\(R\)</span> 的一个单位，对任意 <span class="math inline">\(ab\)</span>，从 <span class="math inline">\(p|ab\)</span> 可以推出 <span class="math inline">\(p|a\)</span> 或 <span class="math inline">\(p|b\)</span>，则 <span class="math inline">\(p\)</span> 称为素元。</li>
<li>因子链条件：<span class="math inline">\(R\)</span>
中不存在以下无限序列：<span class="math inline">\(a_1,a_2,...,a_i,a_{i+1},...\)</span> 使得 <span class="math inline">\(a_{i+1}\)</span> 是 <span class="math inline">\(a_i\)</span> 的真因子，则称 <span class="math inline">\(R\)</span> 适合因子链条件。</li>
<li>素性条件：若 <span class="math inline">\(R\)</span>
的任意不可约元都是素元，则称 <span class="math inline">\(R\)</span>
适合素性条件。</li>
<li>最大公因子条件：<span class="math inline">\(R\)</span>
上任意两个元素都有最大公因子。</li>
</ul>
<h2 id="pid-与欧氏整区">PID 与欧氏整区</h2>
<p>以下全部在整区中进行讨论。</p>
<p>何宝好像分不清欧式和欧氏（？），差别很大的啊！（脑补一个欧式装潢的整区</p>
<ul>
<li><p>从另一个角度看整除问题，如果有 <span class="math inline">\(b|a\)</span> 说明 <span class="math inline">\(b\)</span> 在 <span class="math inline">\(a\)</span> 生成的主理想中，从而有 <span class="math inline">\((b)\subseteq (a)\)</span>；如果有 <span class="math inline">\(b|a\)</span> 且 <span class="math inline">\(a|b\)</span>，则有 <span class="math inline">\((a)=(b)\)</span>。因此，因子链条件也可以写作：环
<span class="math inline">\(R\)</span> 中没有无限真升的主理想链
$(a_1)(a_2)... $。这被称为主理想升链条件。</p></li>
<li><p>设 <span class="math inline">\(R\)</span>
是一个整区，若它的每个理想都可以由一个元素生成，则称 <span class="math inline">\(R\)</span> 为主理想整区，记为 PID（Principe Ideal
Domain）。</p>
<ul>
<li>任一 PID 都是 UFD。</li>
</ul></li>
<li><p>欧氏整区：设 <span class="math inline">\(R\)</span>
是一个整区且存在从 <span class="math inline">\(R^*\)</span> 到 <span class="math inline">\(N\)</span> 的映射 <span class="math inline">\(\delta\)</span>，满足：</p>
<ul>
<li>若 <span class="math inline">\(a,b\in R\)</span> 且 <span class="math inline">\(b\neq 0\)</span>，则存在 <span class="math inline">\(q,r \in R\)</span> 满足 <span class="math inline">\(a=bq+r\)</span>，且或者 <span class="math inline">\(r=0\)</span>，或者 <span class="math inline">\(\delta(r)&lt; \delta(b)\)</span>。</li>
<li>对任意非零元 <span class="math inline">\(a\)</span>,<span class="math inline">\(b\)</span>，有 <span class="math inline">\(\delta(a)\leq \delta(ab)\)</span>。</li>
</ul>
<p>则称 <span class="math inline">\(R\)</span> 是一个欧氏整区。映射
<span class="math inline">\(\delta\)</span> 称为欧氏赋值。</p></li>
<li><p>欧氏整区都是 PID。</p></li>
</ul>
<h2 id="域上的一元多项式环">域上的一元多项式环</h2>
<p>多项式的 degree 非常好用。</p>
<ul>
<li><span class="math inline">\(F\)</span> 是一个域，<span class="math inline">\(F[x]\)</span>
是欧式整区，其上的欧氏赋值即为它的最高次项次数。
<ul>
<li>于是它也是 PID 和 UFD。</li>
</ul></li>
<li><span class="math inline">\(F[x]\)</span> 中多项式 <span class="math inline">\(f(x)\)</span> 不可约等价于 <span class="math inline">\(F[x]/(f(x))\)</span> 是一个域，也即 <span class="math inline">\((f(x))\)</span> 是 <span class="math inline">\(F[x]\)</span> 的极大理想。</li>
<li>（余数定理）若 <span class="math inline">\(f(x)\in
F[x]\)</span>，<span class="math inline">\(a\in F\)</span>，则存在唯一的
<span class="math inline">\(q(x)\)</span> 使得 <span class="math inline">\(f(x)=(x-a)q(x)+f(a)\)</span>。
<ul>
<li>由此可知，<span class="math inline">\((x-a)|f(x)\)</span> 等价于
<span class="math inline">\(a\)</span> 是 <span class="math inline">\(f(x)\)</span> 的根。</li>
<li><span class="math inline">\(F[x]\)</span> 上的 <span class="math inline">\(n\)</span> 次多项式在 <span class="math inline">\(F\)</span> 上有至多 <span class="math inline">\(n\)</span> 个不同的根。（归纳）</li>
</ul></li>
<li>任何一个域的乘法群的有限子群是循环群。因此，有限域的乘法子群都是循环群。</li>
</ul>
<h2 id="交换环上的多项式环">交换环上的多项式环</h2>
<p>说实话，总是代入 <span class="math inline">\(Z[x]\)</span>
是我学习多项式环的最大困难...</p>
<ul>
<li>视 <span class="math inline">\(R[x_1,x_2,...,x_n] =
R[x_1,x_2,...,x_{n-1}] [x_n]\)</span>
，从而多项式环可以归纳地讨论。</li>
<li>设 <span class="math inline">\(R\)</span> 是带恒等元的交换环，<span class="math inline">\(r\)</span> 是一个正整数，则 <span class="math inline">\(R[x_1,x_2,...,x_n]\)</span> 满足以下的泛性：<span class="math inline">\(S\)</span> 是任意一个带恒等元的交换环，<span class="math inline">\(\psi\)</span> 是 <span class="math inline">\(R\)</span> 到 <span class="math inline">\(S\)</span> 上的环同态，<span class="math inline">\(u_1,u_2,...,u_n\)</span> 是 <span class="math inline">\(S\)</span> 上 <span class="math inline">\(r\)</span> 个元素，则必存在从 <span class="math inline">\(R[x_1,x_2,...,x_r]\)</span> 到 <span class="math inline">\(S\)</span> 的唯一的环同态 <span class="math inline">\(\phi\)</span>，使得对一切 <span class="math inline">\(a\in R\)</span> 有 <span class="math inline">\(\phi(a)=\psi(a)\)</span>。且 <span class="math inline">\(\phi(x_i)=\psi(x_i)\)</span>，<span class="math inline">\(i=1,2,...,r\)</span>.
<ul>
<li>从而有 <span class="math inline">\(R\)</span> 上的任意两个 <span class="math inline">\(r\)</span> 元多项式环同构。</li>
<li><span class="math inline">\(R[x_1,x_2,...,x_n]\)</span>
中两个多项式相等的充要条件是每个单项式前的系数相等。（induction）</li>
</ul></li>
<li>代数无关元：<span class="math inline">\(R[x_1,x_2,...,x_n]
\rightarrow R[u_1,u_2,...,u_n]\)</span> 上的泛性映射是同构时，称 <span class="math inline">\(x_1.x_2,...,x_n\)</span>
是代数无关元，否则称为代数相关元。代数相关 / 无关元的性质类似于线性相关
/ 无关。</li>
<li><span class="math inline">\(F\)</span> 是有无数个元素的域，则对于
<span class="math inline">\(F[x_1,x_2,...,x_n]\)</span>
上的任意一个非零多项式 <span class="math inline">\(f(x_1,x_2,...,x_n)\)</span>，必存在一组元素 <span class="math inline">\(a_1,a_2,...,a_n \in F\)</span>，使得 <span class="math inline">\(F(a_1,a_2,...,a_n) \neq
0\)</span>。（induction）</li>
<li>本原多项式：<span class="math inline">\(R\)</span> 是 UFD，从而
<span class="math inline">\(R\)</span>
上任意多个元素都有最大公因数。对于<span class="math inline">\(R[x_1,x_2,...,x_n]\)</span> 上的元素 <span class="math inline">\(f(x)=a_nx^n+...+a_1x+a_0\)</span>，如果 <span class="math inline">\((a_n,a_{n-1},...,a_1,a_0)=1\)</span>，则称 <span class="math inline">\(f(x)\)</span> 是本原多项式。</li>
<li><span class="math inline">\(R\)</span> 是一个 UFD，<span class="math inline">\(F\)</span> 是 <span class="math inline">\(R\)</span> 的分式域，如果 <span class="math inline">\(f(x)\)</span> 是 <span class="math inline">\(F[x]\)</span> 中的本原多项式，则 <span class="math inline">\(f(x)=rf_1(x)\)</span>，<span class="math inline">\(r\in F\)</span> 且 <span class="math inline">\(f_1(x)\)</span> 是 <span class="math inline">\(R[x]\)</span> 中的本原多项式。此分解除了差一个
<span class="math inline">\(R\)</span> 的单位外是确定的。
<ul>
<li><span class="math inline">\(R\)</span> 是 UFD，若 <span class="math inline">\(f(x)\)</span> 和 <span class="math inline">\(g(x)\)</span> 是 <span class="math inline">\(F[x]\)</span> 中的本原多项式，且它们在 <span class="math inline">\(F[x]\)</span> 中是相伴元，则它们在 <span class="math inline">\(R[x]\)</span> 中也相伴。</li>
</ul></li>
<li>本原多项式的积还是本原多项式。</li>
<li>如果 <span class="math inline">\(R\)</span> 是 UFD，则 <span class="math inline">\(R[x]\)</span> 也是 UFD。从而 <span class="math inline">\(R[x_1,x_2,...,x_n]\)</span> 也是 UFD。</li>
</ul>
<h2 id="素理想">素理想</h2>
<p>本节在含恒等元的交换环上讨论。</p>
<ul>
<li><p>设 <span class="math inline">\(P\)</span> 是环 <span class="math inline">\(R\)</span> 的理想且 <span class="math inline">\(P\neq R\)</span>，若对 <span class="math inline">\(R\)</span> 中元素 <span class="math inline">\(a,b\)</span>，从 <span class="math inline">\(ab\in
P\)</span> 可以推出 <span class="math inline">\(a\in P\)</span> 或者
<span class="math inline">\(b\in P\)</span>，则称 <span class="math inline">\(P\)</span> 是环 <span class="math inline">\(R\)</span> 的素理想。</p>
<p>这等价于 <span class="math inline">\(P/R\)</span>
是整区。因此，环的极大理想一定是素理想。</p></li>
<li><p>设 <span class="math inline">\(R\)</span>
是含恒等元的交换环，<span class="math inline">\(I\)</span>
是它的一个理想且 <span class="math inline">\(I\neq R\)</span>，则 <span class="math inline">\(I\)</span> 一定含在 <span class="math inline">\(R\)</span> 的某个极大理想中。</p>
<p>任何一个含恒等元的环都有极大理想。</p></li>
<li><p><span class="math inline">\(R\)</span>
的任意不可逆元素都含在某个极大理想中。如果 <span class="math inline">\(R\)</span>
只有这样的唯一一个极大理想，则称为局部环。</p></li>
<li><p>交换环 <span class="math inline">\(R\)</span>
所有素理想的交称为小根，等于 <span class="math inline">\(R\)</span>
的所有幂零元和零元素组成的理想，称为诣零根。</p>
<p>所有极大理想的交称为大根，等于 <span class="math inline">\(R\)</span>
的全部满足 <span class="math inline">\(1-ar\)</span> 可逆对任意 <span class="math inline">\(r\)</span> 成立的 <span class="math inline">\(a\)</span> 的集合。</p></li>
</ul>
<h1 id="域与-galois-理论">域与 Galois 理论</h1>
<p>蛞蝓好难！</p>
<h2 id="域的扩张">域的扩张</h2>
<ul>
<li><p>假设 <span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的扩域，<span class="math inline">\(S\)</span> 是 <span class="math inline">\(E\)</span> 的子集，记 <span class="math inline">\(F(S)\)</span> 是 <span class="math inline">\(E\)</span> 上由 <span class="math inline">\(F\)</span> 和 <span class="math inline">\(S\)</span> 生成的子域，表示所有包含 <span class="math inline">\(F\)</span> 和 <span class="math inline">\(S\)</span> 的子域之交。显然，<span class="math inline">\(F(S)(T)=F(S\cup T)\)</span>。</p>
<p>如果 <span class="math inline">\(S\)</span> 是一个单点，则 <span class="math inline">\(F(u)\)</span> 称为 <span class="math inline">\(F\)</span> 的单扩张，元素 <span class="math inline">\(u\)</span>
称为本原元。单扩张的代数扩张和超越扩张比较容易研究，这是因为 <span class="math inline">\(F(u)=F[u]\)</span>。</p>
<p>若为代数扩张，<span class="math inline">\(F(u)\)</span>
的元素可以写作小于 <span class="math inline">\(u\)</span>
的极小多项式次数的多项式，如果是超越扩张则 $F(u)= | f(x),g(x) F[x],g
$。</p></li>
<li><p>另外一个角度的域扩张：<span class="math inline">\(E\)</span> 是
<span class="math inline">\(F\)</span> 的扩域，<span class="math inline">\(E\)</span> 可以看做 <span class="math inline">\(F\)</span> 上的线性空间（不一定有限维度）。如果
<span class="math inline">\([E:F]&lt;\infty\)</span>
则成为有限扩张，否则为无限扩张。</p></li>
<li><p><span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的扩域，<span class="math inline">\(K\)</span> 是 <span class="math inline">\(E\)</span> 的扩域，此时 <span class="math inline">\([K:F]\)</span> 有限的充要条件是 <span class="math inline">\([K:E],[E:F]\)</span> 都有限，有 <span class="math inline">\([K:F]=[K:E][E:F]\)</span>。</p>
<p>于是，当 <span class="math inline">\([K:F]\)</span>
是素数时，二者之间没有其他子域。</p></li>
<li><p>有限扩张一定是代数扩张，但代数扩张不一定有限。</p></li>
<li><p>(Steinitz Theorem)：<span class="math inline">\(E\)</span> 是
<span class="math inline">\(F\)</span> 的扩域且 <span class="math inline">\([E:F]\)</span> 有限，则 <span class="math inline">\(E=F[u]\)</span> 的充要条件是 <span class="math inline">\(E\)</span> 和 <span class="math inline">\(F\)</span> 之间只有有限个中间域。</p></li>
</ul>
<h2 id="代数扩域">代数扩域</h2>
<p>袋鼠蛞蝓x</p>
<ul>
<li><p><span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的扩域，<span class="math inline">\(K\)</span> 是 <span class="math inline">\(E\)</span> 上 <span class="math inline">\(F\)</span> 的代数元全体构成的集合，它也是一个
<span class="math inline">\(E\)</span> 的子域。</p>
<p>两个代数数的和、差、积、商都是代数数。</p></li>
<li><p>虽然代数扩张不一定是有限扩张，我们可以给出有限扩张的一些性质：</p>
<p><span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的扩域，则 <span class="math inline">\([E:F]&lt;\infty\)</span> 等价于存在 <span class="math inline">\(E\)</span> 中的有限个代数元 <span class="math inline">\(u_1,...,u_n\)</span> 使得 <span class="math inline">\(E=F(u_1,u_2,...,u_n)\)</span>。</p></li>
<li><p>代数扩张有传递性。如果 <span class="math inline">\(E\)</span> 是
<span class="math inline">\(F\)</span> 的代数扩域，<span class="math inline">\(K\)</span> 是 <span class="math inline">\(E\)</span> 的代数扩域，则 <span class="math inline">\(K\)</span> 是 <span class="math inline">\(F\)</span> 的代数扩域。</p>
<p><span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的扩域，<span class="math inline">\(K\)</span> 是 <span class="math inline">\(E\)</span> 上 <span class="math inline">\(F\)</span> 的代数元全体构成的集合，则任何 <span class="math inline">\(E\)</span> 上 <span class="math inline">\(K\)</span> 的代数元属于 <span class="math inline">\(K\)</span>。</p></li>
<li><p><span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的扩域，<span class="math inline">\(K\)</span> 是 <span class="math inline">\(E\)</span> 的子域且是 <span class="math inline">\(F\)</span> 的代数扩域，如果 <span class="math inline">\(K\)</span> 在 <span class="math inline">\(E\)</span> 中的任何代数扩域都和 <span class="math inline">\(K\)</span> 重合（无真代数扩张），那么 <span class="math inline">\(K\)</span> 是 <span class="math inline">\(F\)</span> 在 <span class="math inline">\(E\)</span> 中的代数闭包，<span class="math inline">\(K\)</span> 也称为在 <span class="math inline">\(E\)</span> 中是代数封闭的。</p>
<p>于是，<span class="math inline">\(F\)</span> 在 <span class="math inline">\(E\)</span> 中的代数闭包是全体 <span class="math inline">\(E\)</span> 中 <span class="math inline">\(F\)</span>
上的代数元集合。这是一个相对的概念。</p></li>
<li><p><span class="math inline">\(K\)</span> 是一个域，如果 <span class="math inline">\(K\)</span>
无真代数扩张，则称其为一个代数闭域。这等价于 <span class="math inline">\(K[x]\)</span>
上所有不可约多项式都为一阶。</p></li>
<li><p>如果 <span class="math inline">\(K\)</span> 是 <span class="math inline">\(F\)</span> 的代数扩域，且 <span class="math inline">\(K\)</span> 是一个代数闭域，则称 <span class="math inline">\(K\)</span> 是 <span class="math inline">\(F\)</span> 的代数闭包。</p>
<p>一个代数闭域 <span class="math inline">\(K\)</span> 的子域 <span class="math inline">\(F\)</span> 的代数闭包 <span class="math inline">\(E\)</span>
一定也是代数闭域。于是每个域都有一个代数闭域作为其代数扩张，即为其代数闭包。</p></li>
<li><p>一个域的代数闭包在同构的意义下是唯一的。也即，如果 <span class="math inline">\(K\)</span> 有两个代数闭包 <span class="math inline">\(E_1,E_2\)</span>，则存在同构映射 <span class="math inline">\(\psi:E_1 \to E_2\)</span> 满足 <span class="math inline">\(\psi(a)=a,\forall a \in K\)</span>。</p></li>
</ul>
<h2 id="分裂域">分裂域</h2>
<p>研究由 <span class="math inline">\(F[x]\)</span> 上的某个已知多项式
<span class="math inline">\(f(x)\)</span> 的根决定的扩域。</p>
<ul>
<li><p>对于 <span class="math inline">\(F\)</span> 上的不可约多项式
<span class="math inline">\(f(x)\)</span>，它在 <span class="math inline">\(F\)</span> 的扩域 <span class="math inline">\(F[x]/(f(x))\)</span> 上有根。</p></li>
<li><p><span class="math inline">\(f(x)\)</span> 是 <span class="math inline">\(F\)</span> 上的首一多项式，<span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的扩域且适合条件：</p>
<ul>
<li><p><span class="math inline">\(f(x)\)</span> 在 <span class="math inline">\(E[x]\)</span> 上可以分解为一次因式的乘积，即存在
<span class="math inline">\(r_1,r_2,...,r_n \in E\)</span> 满足 <span class="math inline">\(f(x)=(x-r_1)...(x-r_n)\)</span></p></li>
<li><p><span class="math inline">\(E=F[r_1,r_2,...,r_n]\)</span></p></li>
</ul>
<p>则称 <span class="math inline">\(E\)</span> 是多项式 <span class="math inline">\(f(x)\)</span> 的分裂域，可以把 <span class="math inline">\(E\)</span> 看做 <span class="math inline">\(F\)</span> 添加了 <span class="math inline">\(f(x)\)</span> 的根得到的扩域。</p></li>
<li><p><span class="math inline">\(F[x]\)</span> 任意首一多项式 <span class="math inline">\(f(x)\)</span>
的分裂域存在，以下考虑其是否唯一的问题。事实上，分裂域在同构的意义下是唯一的。</p>
<ul>
<li><p>设 <span class="math inline">\(\eta : a\to \bar{a}\)</span> 是域
<span class="math inline">\(F\to \bar{F}\)</span> 的同构，<span class="math inline">\(E\)</span> 和 <span class="math inline">\(\bar{E}\)</span> 分别是 <span class="math inline">\(F,\bar{F}\)</span> 的扩域，<span class="math inline">\(u\in E\)</span> 是 <span class="math inline">\(F\)</span> 上代数元且其极小多项式为 <span class="math inline">\(g(x)\)</span>，则 <span class="math inline">\(\eta\)</span> 可以扩张为 <span class="math inline">\(F(u)\to \bar{E}\)</span>
上的单同态，这种扩张的数目等于 <span class="math inline">\(\bar{g}(x)\)</span> 在 <span class="math inline">\(\bar{E}\)</span> 上不同根的个数。</p></li>
<li><p>设 <span class="math inline">\(\eta : a\to \bar{a}\)</span> 是域
<span class="math inline">\(F\to \bar{F}\)</span> 的同构，<span class="math inline">\(f(x)\)</span> 是 <span class="math inline">\(F[x]\)</span> 上的首一多项式，<span class="math inline">\(\bar{f}(x)\)</span> 是 <span class="math inline">\(\bar{F}[x]\)</span>
上相应的多项式（对多项式的每个系数做映射）。<span class="math inline">\(E\)</span> 和 <span class="math inline">\(\bar{E}\)</span> 分别是 <span class="math inline">\(f(x),\bar{f}(x)\)</span> 的分裂域，则 <span class="math inline">\(\eta\)</span> 可以扩张为 <span class="math inline">\(E\to \bar{E}\)</span>
上的同构，这种扩张的数目不超过 <span class="math inline">\([E:F]\)</span>。当 <span class="math inline">\(\bar{f}(x)\)</span> 在 <span class="math inline">\(\bar{E}\)</span> 上无重根时，正好等于 <span class="math inline">\([E:F]\)</span>。</p>
<p>因此，取特殊情况 <span class="math inline">\(F=\bar{F},\eta\)</span>
是恒等映射，则有 <span class="math inline">\(E\)</span> 和 <span class="math inline">\(\bar{E}\)</span>
都同构，也即分裂域在同构的意义下是唯一的。</p></li>
<li><p><span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 上多项式 <span class="math inline">\(f(x)\)</span> 的分裂域，则 <span class="math inline">\(E/F\)</span> 的自同构（保持 <span class="math inline">\(F\)</span> 中元素不动的自同构）数目不超过 <span class="math inline">\([E:F]\)</span>。当 <span class="math inline">\(f(x)\)</span> 在 <span class="math inline">\(E\)</span> 上无重根时，正好等于 <span class="math inline">\([E:F]\)</span>。</p></li>
</ul>
<p>说实话不是很懂上面两个东西怎么用的...可能是还没学 Galois
理论的原因，也可以预见学习的时候会很痛苦了。</p></li>
</ul>
<h2 id="可分扩域">可分扩域</h2>
<ul>
<li><p>设 <span class="math inline">\(F\)</span> 上的多项式 <span class="math inline">\(f(x)=f_1(x)^{k_1} f_2(x)^{k_2} ...
f_n(x)^{k_n}\)</span>，考虑 <span class="math inline">\(f_0(x)=f_1(x)f_2(x) ... f_n(x)\)</span>，它和
<span class="math inline">\(f(x)\)</span> 有相同的分裂域 <span class="math inline">\(E\)</span>。其中 <span class="math inline">\(f_i(x),f_j(x)\)</span>
互素且都是不可约因子，因此互相之间没有相同的根。</p>
<p>于是 <span class="math inline">\(f_0(x)\)</span>
有重根等价于它的某个因子 <span class="math inline">\(f_i(x)\)</span>
有重根。因此，我们讨论 <span class="math inline">\(f_0(x)\)</span>
的所有因子都没有重根的情形，此时称 <span class="math inline">\(f(x),f_0(x)\)</span> 为可分多项式。此时 <span class="math inline">\(E/F\)</span> 的自同构也有 <span class="math inline">\([E:F]\)</span> 个。</p></li>
<li><p><span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的扩域，如果一个 <span class="math inline">\(E\)</span> 上元素 <span class="math inline">\(u\)</span> 在 <span class="math inline">\(F\)</span> 上的极小多项式是可分多项式，称 <span class="math inline">\(u\)</span> 是 <span class="math inline">\(F\)</span> 上的可分元。</p>
<p>如果 <span class="math inline">\(E\)</span>
上的每个元都是可分元，则称 <span class="math inline">\(E\)</span> 是
<span class="math inline">\(F\)</span> 的可分扩张 / 可分扩域。</p></li>
<li><p>研究域 <span class="math inline">\(F\)</span>
上的多项式何时有重根，分为特征为 <span class="math inline">\(0\)</span>
或 <span class="math inline">\(k\)</span> 的情况讨论。首先，如果 <span class="math inline">\(f(x)\)</span> 是 <span class="math inline">\(F\)</span> 上的非零首一多项式，则 <span class="math inline">\(f(x)\)</span> 在分裂域中无重根等价于 <span class="math inline">\((f(x),f^\prime (x))=1\)</span>。</p>
<ul>
<li>如果 <span class="math inline">\(F\)</span> 的特征为 <span class="math inline">\(0\)</span>，则 <span class="math inline">\(F\)</span> 上的不可约多项式都是可分多项式。</li>
<li>如果 <span class="math inline">\(F\)</span> 的特征是 <span class="math inline">\(p \neq 0\)</span>，则 <span class="math inline">\(F\)</span> 上的不可约多项式可分的充要条件为 <span class="math inline">\(g^\prime (x)=0\)</span>，形状为 <span class="math inline">\(g(x)=a_o + a_1 x^p +...+a_k x^{kp}\)</span></li>
</ul>
<p>于是我们知道，只有特征不为 <span class="math inline">\(0\)</span>
的域上才有不可分多项式。</p></li>
<li><p>Frobenius 同态：特征为 <span class="math inline">\(p\)</span>
的域 <span class="math inline">\(F\)</span> 上的映射 <span class="math inline">\(\psi(a)=a^p\)</span> 是 <span class="math inline">\(F\)</span> 上的自同态，也是单同态。记 <span class="math inline">\(F^p =\lbrace a^p | a \in F \rbrace\)</span>，它是
<span class="math inline">\(F\)</span> 的子域</p></li>
<li><p>特征为 <span class="math inline">\(p\)</span> 的域上的多项式
<span class="math inline">\(x^p-b\)</span> 要么不可约，要么可以表示为
<span class="math inline">\((x-a)^p\)</span> 的形式。</p></li>
<li><p>如果某个域上的所有多项式都是可分多项式，则称其为完全域。</p>
<p>显然，完全域 <span class="math inline">\(F\)</span> 的代数扩域 <span class="math inline">\(E\)</span> 一定是可分扩域，<span class="math inline">\(E\)</span> 中元素 <span class="math inline">\(u\)</span> 在 <span class="math inline">\(F\)</span> 上的极小多项式一定是可分多项式，于是
<span class="math inline">\(u\)</span> 是可分元，<span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的可分扩域。特征为 <span class="math inline">\(0\)</span> 的域都是完全域，比如 <span class="math inline">\(Q,R,C\)</span> 等等。</p>
<p>特征为 <span class="math inline">\(p\)</span>
的域是完全域的等价条件是 <span class="math inline">\(F=F^p\)</span>。</p></li>
<li><p>有限域一定是完全域。因为其 Frobenius 同态一定是同构。</p></li>
</ul>
<h2 id="正规扩域">正规扩域</h2>
<ul>
<li><p>引理：<span class="math inline">\(f(x)\)</span> 是 <span class="math inline">\(F\)</span> 上的多项式，<span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 上关于多项式 <span class="math inline">\(f(x)\)</span> 的分裂域。对于某个 <span class="math inline">\(u\in E\)</span>，它的极小多项式为 <span class="math inline">\(g(x)\)</span>，则 <span class="math inline">\(g(x)\)</span> 的所有根都在 <span class="math inline">\(E\)</span> 中，也即在 <span class="math inline">\(E\)</span> 中可以分解为一次因式的积。</p>
<p>也就是说，对于某个 <span class="math inline">\(F\)</span> 的分裂域
<span class="math inline">\(E\)</span>，<span class="math inline">\(F\)</span> 上的任意不可约多项式 <span class="math inline">\(g(x)\)</span> 要么根全部在 <span class="math inline">\(E\)</span> 中，要么全都不在 <span class="math inline">\(E\)</span> 中。这符合正规扩域的要求。</p></li>
<li><p>正规扩域：<span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的代数扩域，<span class="math inline">\(F\)</span> 上的任意不可约多项式 <span class="math inline">\(g(x)\)</span> 要么根全部在 <span class="math inline">\(E\)</span> 中，要么全都不在 <span class="math inline">\(E\)</span> 中，则称 <span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的正规扩域（正规扩张）。</p></li>
<li><p>如果 <span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的有限扩张，则 <span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的正规扩张等价于 <span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 上某个多项式的分裂域。</p></li>
<li><p>域 <span class="math inline">\(F\)</span>
的任意有限扩张一定含在某个正规扩张中。</p></li>
<li><p>正规闭包：<span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的代数扩域，若 <span class="math inline">\(K\)</span> 是 <span class="math inline">\(F\)</span> 的正规扩域且包含 <span class="math inline">\(E\)</span>，<span class="math inline">\(M\)</span>
是 <span class="math inline">\(F\)</span> 的正规扩域且满足 <span class="math inline">\(F \subseteq E \subseteq M \subseteq
K\)</span>，则一定有 <span class="math inline">\(M=K\)</span> 时，称
<span class="math inline">\(K\)</span> 是 <span class="math inline">\(E/F\)</span> 的正规闭包。</p></li>
<li><p><span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的有限维正规扩张，<span class="math inline">\(K\)</span> 是 <span class="math inline">\(E\)</span> 与 <span class="math inline">\(F\)</span> 的中间域，<span class="math inline">\(F
\subseteq K \subseteq E\)</span>，以下结论互相等价：</p>
<ul>
<li><span class="math inline">\(K\)</span> 是 <span class="math inline">\(F\)</span> 的正规扩张</li>
<li>如果 <span class="math inline">\(\sigma\)</span> 是 <span class="math inline">\(E/F\)</span> 的自同构，则 <span class="math inline">\(\sigma(K) \subseteq K\)</span></li>
<li>如果 <span class="math inline">\(\sigma\)</span> 是 <span class="math inline">\(E/F\)</span> 的自同构，则 <span class="math inline">\(\sigma(K) = K\)</span></li>
</ul></li>
<li><p><span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 上可分多项式 <span class="math inline">\(f(x)\)</span> 的分裂域，则 <span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的可分扩张，也就是说 <span class="math inline">\(E\)</span> 上的每个元素都是 <span class="math inline">\(F\)</span> 的可分元。</p></li>
</ul>
<h2 id="galois-扩域与-galois-对应">Galois 扩域与 Galois 对应</h2>
<ul>
<li><p>Galois 扩域：对于一个域 <span class="math inline">\(F\)</span>
上的可分多项式 <span class="math inline">\(f(x)\)</span>，<span class="math inline">\(F\)</span> 关于 <span class="math inline">\(f(x)\)</span> 的分裂域即为 Galois 扩域。</p>
<p>这是因为 Galois 扩域的意义为 <span class="math inline">\(F\)</span>
上的有限维可分正规扩张，分裂域是有限维扩域，<span class="math inline">\(F\)</span> 关于可分多项式 <span class="math inline">\(f(x)\)</span>
的分裂域一定是一个可分扩张，且是正规扩张。（草，突然发现好像说反了</p></li>
<li><p>Galois 群：<span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的扩域，<span class="math inline">\(E/F\)</span>
上的自同构全体构成一个群（运算为映射的合成），称为 <span class="math inline">\(E/F\)</span> 的 Galois 群，记为 <span class="math inline">\(Gal E/F\)</span>。</p>
<p>因此 <span class="math inline">\(F\)</span> 的 Galois 扩域为 <span class="math inline">\(E\)</span>，使得 <span class="math inline">\(|Gal
E/F|=[E:F]\)</span>。</p></li>
<li><p>不变子域：<span class="math inline">\(E\)</span> 是一个域，<span class="math inline">\(AutE\)</span> 是 <span class="math inline">\(E\)</span> 上的自同构群，<span class="math inline">\(G\)</span> 是 <span class="math inline">\(AutE\)</span> 的一个子群。定义 <span class="math inline">\(InvG=\lbrace a \in E | \eta(a)=a,\forall \eta \in
G \rbrace\)</span>。可以证明 <span class="math inline">\(InvG\)</span>
满足有恒等元、无零因子、非零可逆和交换的性质，因此它是 <span class="math inline">\(E\)</span> 的一个子域，称为 <span class="math inline">\(E\)</span> 的 <span class="math inline">\(G\)</span> 不变子域。于是我们可以把 <span class="math inline">\(E\)</span> 当做 <span class="math inline">\(InvG\)</span> 的扩域，它们在维数上有以下关系：</p>
<ul>
<li>Artin 引理：<span class="math inline">\(G\)</span>
是有限子群时，<span class="math inline">\(|G| \geq
[E:InvG]\)</span></li>
</ul></li>
<li><p><span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的 Galois 扩域，等价于 <span class="math inline">\(F=InvG\)</span>，其中 <span class="math inline">\(G\)</span> 是 <span class="math inline">\(AutE\)</span> 的有限子群。也就是说，<span class="math inline">\(G\)</span> 是 <span class="math inline">\(E/F\)</span> 上的自同构全体，可以写作 <span class="math inline">\(Gal(E/InvG)=G,F=Inv (Gal E/F)\)</span>。</p></li>
<li><p>Galois 理论的基本定理：在定理叙述之前先做定义。</p>
<ul>
<li><p><span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的扩域，于是 <span class="math inline">\(G=Gal E/F\)</span>，作集合 <span class="math inline">\(\Sigma=\lbrace H|H\)</span> 是 <span class="math inline">\(G\)</span> 的子群 <span class="math inline">\(\rbrace\)</span>，<span class="math inline">\(\Omega=\lbrace K|K\)</span> 是 <span class="math inline">\(E,F\)</span> 的中间域 <span class="math inline">\(\rbrace\)</span>，定义 <span class="math inline">\(\varphi: H \to InvH\)</span>，<span class="math inline">\(\psi :K \to GalE/K\)</span>，二者是在 <span class="math inline">\(\Sigma,\Omega\)</span> 上方向相反的映射。</p></li>
<li><p>有一些结论：</p>
<p><span class="math inline">\(H_1 \subseteq H_2\)</span>，则 <span class="math inline">\(Inv H_2 \subseteq Inv H_1\)</span></p>
<p><span class="math inline">\(K_1 \subseteq K_2\)</span>，则 <span class="math inline">\(Gal E/K_1 \subseteq Gal E/K_2\)</span></p>
<p><span class="math inline">\(H \subseteq Gal(E/Inv H)\)</span></p>
<p><span class="math inline">\(K\subseteq Inv(Gal E/K)\)</span></p></li>
<li><p>如果 <span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的 Galois 扩域，则：</p>
<p><span class="math inline">\(\psi,\varphi\)</span>
是互逆的一一对应，称为 Galois 对应；</p>
<p><span class="math inline">\(H_1 \subseteq H_2 \iff Inv H_2 \subseteq
Inv H_1\)</span>；</p>
<p><span class="math inline">\(| H| = [E:Inv H]\)</span>，于是有 <span class="math inline">\([G:H]=[Inv H:F]\)</span>；</p>
<p><span class="math inline">\(H\)</span> 是 <span class="math inline">\(G\)</span> 的正规子群等价于 <span class="math inline">\(InvH\)</span> 是 <span class="math inline">\(F\)</span> 的正规扩域，此时还有 <span class="math inline">\(Gal(Inv H/F) \cong G/H\)</span>。</p></li>
</ul></li>
</ul>
<h2 id="有限域">有限域</h2>
<ul>
<li><p>有限域也称 Galois 域。特征为 <span class="math inline">\(p\)</span> 的有限域 <span class="math inline">\(F\)</span> 的元素个数为 <span class="math inline">\(p^n\)</span>，是素子域 <span class="math inline">\(Z_p\)</span> 的分裂域，对应多项式是 <span class="math inline">\(f(x)=x^{p^n}-x\)</span>。这是一个可分多项式，因此
<span class="math inline">\(F\)</span> 是 <span class="math inline">\(Z_p\)</span> 的 Galois
扩域。大小相同的这样的域在同构的意义下唯一。</p></li>
<li><p><span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的扩域，<span class="math inline">\(E,F\)</span> 都是有限域且 <span class="math inline">\([E:F]=m\)</span>，则 <span class="math inline">\(Gal E/F\)</span> 是一个阶为 <span class="math inline">\(m\)</span> 的循环群，生成元是 <span class="math inline">\(E\)</span> 上的自同构 <span class="math inline">\(\eta :a \to a^q\)</span>，<span class="math inline">\(q=|F|\)</span>。</p>
<p>考虑 <span class="math inline">\(Gal E/Z_p\)</span> 是循环群，<span class="math inline">\(GalE/F\)</span> 是它的子群，而 <span class="math inline">\(m\)</span> 阶子群有且仅有一个即可。</p></li>
<li><p><span class="math inline">\(E\)</span> 是元素个数等于 <span class="math inline">\(p^n\)</span> 的域，且 <span class="math inline">\(m|n\)</span>，于是 <span class="math inline">\(E\)</span> 的元素个数为 <span class="math inline">\(p^m\)</span> 的子域有且仅有一个。</p></li>
</ul>
<h2 id="分圆域">分圆域</h2>
<p>我的域论真的一塌糊涂，每天都在默念还好我以后接触到的域都是普通数域了（</p>
<ul>
<li><p>对于一个特征为 <span class="math inline">\(0\)</span> 的域，研究
<span class="math inline">\(F\)</span> 上多项式 <span class="math inline">\(x^n -1\)</span> 的分裂域 <span class="math inline">\(E\)</span>，称之为 <span class="math inline">\(F\)</span> 上的 <span class="math inline">\(n\)</span> 阶分圆域。</p>
<p>显然有 <span class="math inline">\((x^n -1 , nx^{n-1}
)=1\)</span>，于是 <span class="math inline">\(x^n -1\)</span>
在其分裂域上有 <span class="math inline">\(n\)</span> 个不同的根，这
<span class="math inline">\(n\)</span> 个根构成的循环群记为 <span class="math inline">\(R\)</span>。它作为循环群有生成元，称之为 <span class="math inline">\(1\)</span> 的 <span class="math inline">\(n\)</span> 次本原根，这样的本原根显然有 <span class="math inline">\(\varphi(n)\)</span> 个，与此同时 <span class="math inline">\(R\)</span> 的自同构也有 <span class="math inline">\(\varphi(n)\)</span>
个，构成了循环的自同构群。</p></li>
<li><p>如上定义后可以知道 <span class="math inline">\(Gal E/F\)</span>
是一个 Abel 群，它和 <span class="math inline">\(AutR\)</span>
的子群是同构的。</p></li>
<li><p><span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 关于元素 <span class="math inline">\(d\)</span> 的 <span class="math inline">\(Galois\)</span> 扩域，如果 <span class="math inline">\(Gal E/F\)</span> 是一个循环群，则称 <span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的循环扩域 / 循环扩张。如果 <span class="math inline">\(Gal E/F\)</span> 是一个 <span class="math inline">\(Abel\)</span> 群，则称 <span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的 <span class="math inline">\(Abel\)</span> 扩张。</p>
<p>由上一条可知分圆域是 <span class="math inline">\(F\)</span> 的 <span class="math inline">\(Abel\)</span> 扩张。</p></li>
<li><p>如果 <span class="math inline">\(E=F(d)\)</span>，其中 <span class="math inline">\(d \notin F\)</span> 且 <span class="math inline">\(d^n \in F\)</span>，<span class="math inline">\(n\)</span> 是满足 <span class="math inline">\(d^n
\in F\)</span> 的最小正整数，于是称 <span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 关于 <span class="math inline">\(d\)</span> 的 <span class="math inline">\(n\)</span> 次根扩张 / 扩域。</p></li>
<li><p>如果 <span class="math inline">\(F\)</span> 含有 <span class="math inline">\(1\)</span> 的 <span class="math inline">\(n\)</span> 次本原根，且 <span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的 <span class="math inline">\(n\)</span> 次根扩张，那么 <span class="math inline">\(E/F\)</span> 是一个循环扩张，<span class="math inline">\([E:F]=k\)</span> 是 <span class="math inline">\(n\)</span> 的一个因子。</p>
<p>反之，如果 <span class="math inline">\(E\)</span> 是 <span class="math inline">\(F\)</span> 的 <span class="math inline">\(n\)</span> 维循环扩域，那么一定存在某个 <span class="math inline">\(d \in E\)</span>，使得 <span class="math inline">\(E=F(d), d^n \in F\)</span>。</p></li>
<li><p>回到关于 <span class="math inline">\(Q\)</span> 上的 <span class="math inline">\(n\)</span> 阶分圆域的讨论。<span class="math inline">\(R\)</span> 是 <span class="math inline">\(1\)</span> 的 <span class="math inline">\(n\)</span> 次根集合，令 <span class="math inline">\(\varphi _{n} (x) = \Pi (x-z)\)</span>，其中 <span class="math inline">\(z\)</span> 跑遍 <span class="math inline">\(R\)</span> 中的本原根。这一多项式一定是 <span class="math inline">\(Q[x]\)</span> 上的多项式，称为 <span class="math inline">\(n\)</span> 阶分圆多项式。</p>
<p>实际上，<span class="math inline">\(x^n -1 = \Pi _{d | n ,d \leq n}
\varphi _{d} (x)\)</span>，例如 <span class="math inline">\(x^{12} -1 =
(x-1)(x+1)(x^2 +x +1)(x^2 +1 )(x^2 -x +1)(x^4 -x^2
+1)\)</span>，分别对应了 <span class="math inline">\(1,2,3,4,6,12\)</span> 阶的分圆多项式。</p>
<p><span class="math inline">\(\varphi _n (x)\)</span> 都是 <span class="math inline">\(Q[x]\)</span> 上的不可约多项式，因此也是 $x^n -1 $
的本原根的极小多项式。</p></li>
<li><p>有理数域上 <span class="math inline">\(n\)</span> 阶分圆域的
<span class="math inline">\(Galois\)</span> 群同构于 <span class="math inline">\(n\)</span> 阶循环群的自同构群，阶为 <span class="math inline">\(\varphi (n)\)</span>。</p>
<p>特殊地，有理数域上 <span class="math inline">\(p\)</span> 阶分圆域的
<span class="math inline">\(Galois\)</span> 群是 <span class="math inline">\(p-1\)</span> 阶的。</p></li>
</ul>
<h2 id="一元方程式的根式求解">一元方程式的根式求解</h2>
<p>都会了，也没什么能考的题，所以不想写了（摆烂</p>
<h1 id="期中提示">期中提示</h1>
<p>打星号的表示笔者到现在还不能很好地反应过来怎么证明，打井号的表示会证明但记不住（</p>
<p>越复习越绝望，真就是破碎的群知识。尤其 hx
是第一年，不确定性更强了（</p>
<h2 id="引理都会证了吗">引理都会证了吗？</h2>
<ul>
<li><p><span class="math inline">\(H,K\)</span> 是群 <span class="math inline">\(G\)</span> 的子群，<span class="math inline">\(HK=\lbrace hk | h\in H,k\in
K\rbrace\)</span>，于是 <span class="math inline">\(HK=KH
\Leftrightarrow HK\)</span> 是 <span class="math inline">\(G\)</span>
的子群。</p></li>
<li><p><span class="math inline">\(H,K\)</span> 是群 <span class="math inline">\(G\)</span> 的两个有限子群，有 <span class="math inline">\(|HK||H\cap K|=|H||K|\)</span>。</p>
<p>与此同时，如果 <span class="math inline">\(H\)</span> 是 <span class="math inline">\(G\)</span> 的正规子群，则有 <span class="math inline">\(KH/H \cong K/H\cap K\)</span>。</p>
<p>推广到环同态结论，如果 <span class="math inline">\(S\)</span> 是
<span class="math inline">\(R\)</span> 的环理想，<span class="math inline">\(I\)</span> 是 <span class="math inline">\(R\)</span> 的子环，则有 <span class="math inline">\((S+I)/I \cong S/S\cap I\)</span>。</p></li>
<li><p><span class="math inline">\(G\)</span> 的两个正规子群 <span class="math inline">\(H,K\)</span> 交集为 <span class="math inline">\(\lbrace e
\rbrace\)</span>，那么二者之间元素交换，也就是说，对 <span class="math inline">\(\forall h \in H,k\in K\)</span>，有 <span class="math inline">\(hk=kh\)</span>。</p>
<p>后续这个用来证明了直积的几个性质，非常好用。也很好证明。</p></li>
<li><p><span class="math inline">\(a,b\)</span> 是群 <span class="math inline">\(G\)</span> 中的两个元素，<span class="math inline">\(ab=ba\)</span>，若 <span class="math inline">\(o(a)=m,o(b)=n\)</span>，则存在 <span class="math inline">\(g\in G\)</span> 满足 <span class="math inline">\(o(g)=[m,n]\)</span>。</p></li>
<li><p><span class="math inline">\(G\)</span> 是一个有限群，<span class="math inline">\(H\)</span> 是 <span class="math inline">\(G\)</span> 的子群且 <span class="math inline">\([G:H]=n\)</span>，则 <span class="math inline">\(H\)</span> 含有 <span class="math inline">\(G\)</span> 的一个正规子群 <span class="math inline">\(K\)</span>，<span class="math inline">\([G:K]|n!\)</span>。如果 <span class="math inline">\(|G|\)</span> 不能整除 <span class="math inline">\(n!\)</span>，那么 <span class="math inline">\(K\)</span> 是 <span class="math inline">\(G\)</span> 的一个非平凡正规子群。（**）</p></li>
<li><p><span class="math inline">\(G\)</span> 是 <span class="math inline">\(p^m\)</span> 阶群。证明：</p>
<ul>
<li><span class="math inline">\(N\)</span> 是 <span class="math inline">\(G\)</span> 的正规子群且 <span class="math inline">\(N\neq \lbrace e \rbrace\)</span>，则 <span class="math inline">\(C\cap N\neq \lbrace e \rbrace\)</span>，<span class="math inline">\(C\)</span> 是 <span class="math inline">\(G\)</span> 的中心。（**）</li>
<li><span class="math inline">\(H\)</span> 是 <span class="math inline">\(G\)</span> 的真子群，则 <span class="math inline">\(H\)</span> 真包含于 <span class="math inline">\(N(H)\)</span>。（*）</li>
<li><span class="math inline">\(G\)</span> 的子群 <span class="math inline">\(H\)</span> 为 <span class="math inline">\(p^{m-1}\)</span> 阶，则 <span class="math inline">\(H\)</span> 是 <span class="math inline">\(G\)</span> 的正规子群。</li>
</ul></li>
<li><p><span class="math inline">\(G\)</span> 不含指数为 <span class="math inline">\(2\)</span> 的子群，则一定有指数为 <span class="math inline">\(3\)</span> 的正规子群。</p></li>
<li><p>(Cauchy 引理)一个有限 <span class="math inline">\(Abel\)</span>
群 <span class="math inline">\(G\)</span> 满足素数 <span class="math inline">\(p\)</span> 整除 <span class="math inline">\(|G|\)</span>，则 <span class="math inline">\(G\)</span> 中有一个元素的周期是 <span class="math inline">\(p\)</span>。（*）</p>
<p>更一般地，并不需要 <span class="math inline">\(Abel\)</span>
群这个条件也可以满足。</p></li>
<li><p>所有的 <span class="math inline">\(pq\)</span> 阶群（<span class="math inline">\(p,q\)</span> 为素数，<span class="math inline">\(q&gt;p\)</span>）都可以写成两种形式之一。</p>
<p>一个是普通的循环群，另一个是类似于二面体群的一个表述：</p>
<p><span class="math inline">\(\lbrace a^i b^j | i=0,1,...,p-1,
j=0,1,...,q-1, aba=b^r\rbrace\)</span>，且 <span class="math inline">\(r\)</span> 满足 <span class="math inline">\(r\not
\equiv 1(mod \\;q)\)</span>，以及 <span class="math inline">\(r^p \equiv
1(mod \\; q)\)</span>。</p>
<p>如果 <span class="math inline">\(p=2\)</span>
的话，这就是一个二面体群。</p></li>
</ul>
<h2 id="定理都会证-记得了吗">定理都会证 / 记得了吗？</h2>
<ul>
<li><p><span class="math inline">\(G\)</span> 是一个有限阶交换群，于是
<span class="math inline">\(G\)</span> 是循环群 <span class="math inline">\(\Leftrightarrow\)</span> <span class="math inline">\(|G|\)</span> 是满足式子 <span class="math inline">\(a^n=e,\forall a \in G\)</span>
的最小正整数。（*）</p>
<p>看到最小就应该知道，先找个最大的但比 <span class="math inline">\(|G|\)</span>
小的，再证明有比他更大的，矛盾。</p></li>
<li><p><span class="math inline">\(n\geq 5\)</span> 时，<span class="math inline">\(A_n\)</span> 是单群。</p>
<p>只要证明所有的三元组都在 <span class="math inline">\(A_n\)</span>
的正规子群里，也就是有一个在正规子群里即可。否则考虑正规子群中不动点最多的元素，可能有两类，分别证明可以更多。</p>
<p>真的很怀疑何宝会考一些定理的证明，不然这 <span class="math inline">\(1.5h\)</span> 时间究竟能做出点啥（挠头</p></li>
<li><p>轨道元素数的计数：<span class="math inline">\(|Gx|=[G:Stab \\;
x]\)</span>。（*）（怎么这个都不会啊（恼</p>
<p>作映射 <span class="math inline">\(Gx\rightarrow
G/S\)</span>，证明它同构。</p></li>
<li><p>带恒等元的交换环是域等价于它只有平凡理想。（#）</p>
<p>也就是说这里平凡理想代替了每个元素可逆的条件，在这个情况下也正是这么推出来的。</p></li>
<li><p>特征为 <span class="math inline">\(p\)</span>
的域有最小子域，它同构于 <span class="math inline">\(Z_p\)</span>。</p>
<p>特征为 <span class="math inline">\(0\)</span>
的域有最小子域，它同构于有理数域。</p>
<p>作一个恒等元的主理想，它和 <span class="math inline">\(Z\)</span>
同构，<span class="math inline">\(Z\)</span> 的分式域是 <span class="math inline">\(Q\)</span>，把它们放到分式域造出来的单同态三角里，推出
<span class="math inline">\(Q\)</span> 在 <span class="math inline">\(F\)</span> 中的像是最小子域。</p></li>
</ul>
<h2 id="难题会做了吗">难题会做了吗？</h2>
<ul>
<li><p><span class="math inline">\(G\)</span> 是有限群且有一个 <span class="math inline">\(p-Sylow\)</span> 子群 <span class="math inline">\(P\)</span>，令 <span class="math inline">\(N=N(P)\)</span> 是 <span class="math inline">\(P\)</span> 的正规化子群，证明：<span class="math inline">\(G\)</span> 的任意包含 <span class="math inline">\(N\)</span> 的子群等于它的正规化子群。（*）</p>
<p><span class="math inline">\(H\)</span> 是 <span class="math inline">\(G\)</span> 的包含 <span class="math inline">\(N\)</span> 的子群，对于 <span class="math inline">\(x\in N(H)\)</span>，<span class="math inline">\(x^{-1} Px\)</span> 是 <span class="math inline">\(p-Sylow\)</span> 子群且属于 <span class="math inline">\(N\)</span>，于是属于 <span class="math inline">\(H\)</span>。故存在 <span class="math inline">\(y
\in H\)</span> 满足 <span class="math inline">\(y^{-1}
x^{-1}Pxy=P\)</span>，于是 <span class="math inline">\(xy \in
N(P)=N\)</span>，有 <span class="math inline">\(N(H)\subseteq
H\)</span>，相等。</p></li>
<li><p><span class="math inline">\(G\)</span> 是有限群且有一个 <span class="math inline">\(p-Sylow\)</span> 子群 <span class="math inline">\(P\)</span>，<span class="math inline">\(H\)</span>
是 <span class="math inline">\(G\)</span> 的子群且 <span class="math inline">\(|H|=p^m\)</span>，证明 <span class="math inline">\(H \cap N(P)=H\cap N\)</span>。（*）</p>
<p>只要证明左边包含于右边。因为 <span class="math inline">\((H\cap
N(P))P\)</span> 是 <span class="math inline">\(G\)</span> 的子群，<span class="math inline">\(P\)</span> 是 <span class="math inline">\(H\)</span> 的 <span class="math inline">\(p-Sylow\)</span> 子群，则 <span class="math inline">\((H\cap N(P))P \subseteq P\)</span>。于是 <span class="math inline">\((H\cap N(P))P / P\cong (H\cap N(P)) / (H\cap
P)\)</span>，于是二者相等。</p></li>
<li><p>实数环上的自同构只有恒等变换一个。</p>
<p>这个证明思路其实很像柯西方程，先证有理数环，再夹出实数情况。</p></li>
<li><p><span class="math inline">\(F\)</span> 是一个数域，则在 <span class="math inline">\(m\neq n\)</span> 时，不存在从环 <span class="math inline">\(M_n(F)\)</span> 到 <span class="math inline">\(M_m(F)\)</span> 上的满同态。</p>
<p>如果存在的话，<span class="math inline">\(kerf\)</span> 是 <span class="math inline">\(M_n(F)\)</span> 的理想，只能是 <span class="math inline">\(\lbrace e \rbrace\)</span> 或者 <span class="math inline">\(M_n(F)\)</span> 自身。</p></li>
</ul>
<h2 id="概念记对了吗">概念记对了吗？</h2>
<ul>
<li><p>可解群，幂零群的东西真记不清楚。</p>
<ul>
<li>可解群的子群和同态像还是可解群；如果 <span class="math inline">\(G\)</span> 的正规子群 <span class="math inline">\(K\)</span> 满足 <span class="math inline">\(K\)</span> 和 <span class="math inline">\(G/K\)</span> 是可解群，则 <span class="math inline">\(G\)</span> 是可解群。</li>
<li><span class="math inline">\(G\)</span> 是可解群等价于其 <span class="math inline">\(n\)</span> 次导群（换位子子群）为 <span class="math inline">\(\lbrace e \rbrace\)</span>。</li>
<li>当 <span class="math inline">\(G\)</span> 的 <span class="math inline">\(n\)</span> 次中心 <span class="math inline">\(C_n=G\)</span> 时，称 <span class="math inline">\(G\)</span> 为幂零群。满足此条件的最小的 <span class="math inline">\(n\)</span> 称为 <span class="math inline">\(G\)</span> 的幂指数。</li>
<li><span class="math inline">\(G\)</span> 是幂零群还等价于 <span class="math inline">\(G\)</span> 有一个正规群列 <span class="math inline">\(\lbrace e\rbrace=G_0\triangleleft G_1\triangleleft
... \triangleleft G_r=G\)</span>，使得 <span class="math inline">\(G_i/G_{i-1} \subseteq
C(G/G_{i-1})\)</span>。这里要求每个 <span class="math inline">\(G_i
\triangleleft G\)</span>，即使正规子群不存在传递性。</li>
</ul></li>
<li><p>单环：不是除环的非交换环只有平凡理想，称为单环。</p>
<p>典型的单环是在除环 <span class="math inline">\(R\)</span>
上构造的矩阵环 <span class="math inline">\(M_n(R)\)</span>。</p></li>
<li><p>整区：交换的带恒等元的整环，只比域少一个逆元条件。</p></li>
<li><p>由分式域造出来的域和域之间的单同态：会画那个图就懂了，一个整区两个域，两个嵌入推一个单同态。</p></li>
</ul>
<h2 id="踩坑踩麻了吗">踩坑踩麻了吗？</h2>
<ul>
<li><p>正规子群不能传递，很多时候觉得灵光一闪做出来了都不靠谱。</p></li>
<li><blockquote>
<p>批证明题作业的感觉就像有一扇门，正确解法是拉动门把手进去，但有学生拿了把斧头把门劈开进去了，有人从门缝下钻进去，有人拆了通风管道爬进来，还有人挂在三层楼外拍窗。而我就是在门里等人的那个，一脸懵逼看着他们各显神通。——不知出处</p>
<p>而我进不去门，翻开答案知道可以拧门把手之后还是拧反方向了，有的时候答案就写了“把手”两个字，于是我把门把手扳了下来。——驰雨</p>
<p>做证明题的感觉就像面对着一扇玻璃门，有的玻璃看着太过透明以至于过于激动地直接冲了过去然后直接被撞晕；有的题在门前犹豫半天不敢靠近，结果走过去发现是自动门。——Retaliatory
Peddlers</p>
</blockquote></li>
</ul>
<h2 id="赛博猫猫敲键盘">赛博猫猫敲键盘</h2>
<p>以下内容和本人没有任何关系，是我博客右侧的赛博猫猫随便按出来的东西，如果可以阅读纯属巧合：</p>
<ul>
<li><p>求 <span class="math inline">\(100\)</span> 阶 <span class="math inline">\(Abel\)</span>
群的所有同构类，写出它们的不变因子组。</p>
<p>有手就行。</p></li>
<li><p>普通的置换计算题，具体数字忘了。</p>
<p>有手就行。</p></li>
<li><p>在 <span class="math inline">\(G=R \backslash
\lbrace-1\rbrace\)</span> 上自行定义一个运算使其称为群，并证明。</p>
<p>我靠，我考试的时候真的不会，明明都想到 <span class="math inline">\((-1,-1)\)</span> 映射到 <span class="math inline">\(-1\)</span>，还想到了 <span class="math inline">\((a+1)(b+1)\)</span>，结果还是开天窗了。无数数竞的悲伤回忆开始攻击我..</p>
<p>实际上就是定义 <span class="math inline">\(a\times
b=ab+a+b\)</span>.</p></li>
<li><p>作 <span class="math inline">\(Z_m\)</span> 到 <span class="math inline">\(Z_n\)</span>
上的同态，有多少个？单同态有多少个？满同态有多少个？</p>
<p>私以为是这张卷子最麻烦的题目，多分分类，我也不确定做对没有...（UPD：错了一点点细节。</p>
<p>感觉一看就是个结论，但我没见过，临场慌得要死。</p></li>
<li><p>证明 <span class="math inline">\(105\)</span> 阶群有一个 <span class="math inline">\(35\)</span> 阶子群。</p>
<p>一个 <span class="math inline">\(5\)</span> 阶正规子群和一个 <span class="math inline">\(7\)</span> 阶群的乘积，或者一个 <span class="math inline">\(7\)</span> 阶正规子群和一个 <span class="math inline">\(5\)</span> 阶群的乘积都是 <span class="math inline">\(35\)</span> 阶子群，所以只要用一下 <span class="math inline">\(Sylow\)</span> 定理就可以了。</p>
<p>临场慌得要死 ++，这个题写了好久，还把 <span class="math inline">\(HK=KH\)</span> 等价于 <span class="math inline">\(HK\)</span> 是 <span class="math inline">\(G\)</span>
的子群那个结论写上去了，完全没用。</p></li>
<li><p>证明 <span class="math inline">\(R[x]/(x^2+1)\)</span> 和复数环
<span class="math inline">\(C\)</span> 同构，其中 <span class="math inline">\((x^2+1)\)</span> 是 <span class="math inline">\(x^2+1\)</span> 生成的主理想。</p>
<p>作同态 <span class="math inline">\(f(g(x))=g(i)\)</span>，它是满同态，<span class="math inline">\(kerf=(x^2+1)\)</span>。</p></li>
<li><p>求 <span class="math inline">\(n\)</span> 阶二面体群 <span class="math inline">\((n\geq 2)\)</span> 的中心，什么样的 <span class="math inline">\(n\)</span> 能够使得 <span class="math inline">\(D_n\)</span> 是幂零群？</p>
<p>中心分奇偶讨论，奇数只有 <span class="math inline">\(\lbrace e
\rbrace\)</span>，偶数还有个 <span class="math inline">\(y^{n/2}\)</span>，再讨论 <span class="math inline">\(2\)</span> 的情况，中心就是自身；幂零群当且仅当
<span class="math inline">\(n\)</span> 是 <span class="math inline">\(2\)</span> 的幂次，用上中心列证明就行。</p>
<p>前者作业里做过，后者一看就是个结论但我没见过，我不是废物谁是废物？</p></li>
</ul>
<p>总结：废物一个，1.3 走起。</p>
<h1 id="期末提示">期末提示</h1>
<p>期末没有提示，复习的时候注意事项直接手写了，理了好几大张纸。结果期末考上来第一题：</p>
<blockquote>
<p>陈述你在这门课中印象最深的一个定理或者结论，并描述它的一个应用或者推论。</p>
</blockquote>
<p>给我整蒙了（</p>
<p>总之这一篇完结了！华子的代数还是劲不够大（至少比隔壁的代数学实验班差远了，hx
的劲也没 zmx
大），下学期的两门分析应该会比抽代更痛苦一些。代数的旅途也快到终点了，之后还有一门不是必须要上的拓扑学（因为是基础方向的专业课，但我应该会去上一下），就要说再见了。之后还会用到的基本上都是简单的抽代知识和线性代数了呢w</p>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>课程实录</tag>
        <tag>刷书</tag>
      </tags>
  </entry>
  <entry>
    <title>在科协躺平的第一学期</title>
    <url>/2022/06/25/lying-flat/</url>
    <content><![CDATA[<h1 id="偶然想起来的事">偶然想起来的事</h1>
<p>今天网络学堂把 Spring Term 归档进了 Past Terms
。打开微信把已经很久没人发言的春季学术部群撤掉了置顶，它立刻就消失了。但实际上春季学期我还有一个没完成的任务，就是本该在
11 周交上的学术图表绘制推送。</p>
<span id="more"></span>
<p><a href="https://imgtu.com/i/jFflHs"><img src="https://s1.ax1x.com/2022/06/25/jFflHs.jpg" alt="当初收到的任务描述"></a></p>
<p>高代选期中前一天，日常缺席集体活动的我咕掉了学术部的部会早早睡觉，所以远程被安排了这个选题。“学术图表绘制”不是
R 语言，不是 Python ，甚至不是 Matlab 或者 Excel ，而是 PPT 绘图和 Visio
绘图简介。<del>而且咕了会议的情况下还不知道它是哪个离谱的人选的。</del></p>
<p>出于糊弄精神，我确实还是选了 PPT
的部分浅学了一下然后写了一份稿子，但它始终是个没人肯去修改的初稿，堆满了不会有人细看的公众号文章该有的又生硬又生动的词句和插图。第十二周的时候组员问我要不要交给部长，我说算了吧，部长什么时候来要了我们再交。</p>
<p>不过还好，部长好像每天都在忙于学业，早就忘记了这件事；科协主席是理学院八字班的学长，毕业换届成九字班电子系的另一位学长之后，谁还会记得我们这个小推文的任务呢？</p>
<p>在科协的第一个学期是灰白色的，我什么令自己满意的东西都没有做。</p>
<h1 id="另外的想法">另外的想法</h1>
<p>三月初科协招新面试的时候，学术部的学长问我会不会写 LaTeX 和MarkDown
，用没用过 Git
，会写哪些编程语言。我能出现在科协，想来这些都没太大问题。最后一个问题是有没有运营过公众号，会不会用秀米。</p>
<p>我还真没用过，也不是很会排版。与此同时也有点诧异，在看过计算机系学生科协维护的
<a href="https://docs.net9.org/">SAST skill docs</a>
、于是很向往地来面试之前，我没想到未来的产出是先写在 word
文档里再发在公众号上，而不是至少采用写在 .md 里再同步到 .github.io
这种连我折腾一下都能会的粗粝形式。<del>（所以现在自己搞blog算不算一种单飞呢bushi</del></p>
<p>后来在社恐地狱的部会上，我还是没能提出这个问题。和一位学长聊过一些，他并不认为是一个好的
idea
。给的几个原因是假如学术部不发推文、赛事部一年复活一次，那“未央科协公众号”恐怕会变成“未央科协从游部公众号”；哪怕写成花里胡哨的公众号文章目前都不会有人看，那做成
blog
形式更没人想看；目的是普及，暂时不是专精；部员水平其实也参差不齐，甚至不是所有人都会写
.md，也不是所有人都想抽出时间来学。</p>
<p>但我始终以为我们本来应该做的是一个比 <a href="https://docs.net9.org/">SAST skill docs</a>
更入门级的东西，没有基础也能看，甚至可以精细到从一帧一帧教学配环境开始；或许没必要教
C++
<del>从</del>入门<del>到放弃</del>，但从普及和院系实际的角度来说教一教用
Excel
处理实验数据的技巧，而不是又没用又无聊的东西，不也很好吗；它本来可以有更漂亮的形式，而不该只能在微信里显示代码的截图、一行只显示几个字、还混杂着公众号推文的特色；目标是普及技能的话，一位不会写
LaTeX
的同学来找科协的文章看，究竟是被引导到一个简单大方的网页上看分类好的教程舒服，还是在科协公众号铺天盖地的从游信息里找学术部推文、然后对着图片和莫名其妙的宋体字敲代码更不容易令人放弃呢？</p>
<p>其实也经常会怀疑，我恐怕还是太傲慢了；不仅傲慢，实际上自己也是一个没多少本事的人，对很多事情都不通原理、掌握一些表面的应用技巧就耍开了。之前还想过两年后换届，假如我能够成为副部，是很希望把这件事做起来的。但我这样的性格，真的适合领导者的角色吗？我想利用领导者的身份来实现我的想法，但恐怕只想逃避日常管理的责任，最后只会因为各种原因半途而废、变得更糟。</p>
<p>不知道这些想法是出于一直以来的自卑，还是事实如此，唔...还是先多学习吧。</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
        <tag>科协</tag>
      </tags>
  </entry>
  <entry>
    <title>睡隙碎笔</title>
    <url>/2022/07/29/sleep(0)/</url>
    <content><![CDATA[<p>不知道给这些稀碎的话语叫什么好，就叫睡隙碎笔吧。</p>
<p>之前想叫摸（鱼）隙碎笔，想了想觉得一天还是睡觉的时间比摸鱼更多，单独一个“摸”字也很奇怪。</p>
<span id="more"></span>
<h1 id="朋友圈">朋友圈</h1>
<p>把朋友圈的入口关掉了。才发现看朋友圈并不是关心大家说了什么，只是习惯性去点掉红点，然后像给长长的计划表打满钩一样每一条都看一遍，获得属于强迫症的满足感。</p>
<p>清华的同学去全国各地实践，高中同学回母校招生，女孩子们拍照出图，九宫格里塞满了无尽的细节，我只感觉也并没有需要我细细查看的部分。</p>
<p>我没有多少朋友，我的朋友们也成不了圈，只能成放射图。</p>
<h1 id="音游最高成就">音游最高成就</h1>
<p>音游最高成就不应该是最难的谱面打了多少分数，而是收了最喜欢的曲子。</p>
<p>Enchanted Love，Vindication，Life is Piano，Particle Arts。</p>
<h1 id="并不成文的诗词">并不成文的诗/词</h1>
<p>袭文改墨不思醒，识巨材卓笑技佞。寒鸟妄过岭，硕鼠皆礼行。纵有四时千般景，未及璨月一点明。</p>
<h1 id="并不成文的诗词-2.0">并不成文的诗/词 2.0</h1>
<p>云中年少过天江。落花堂，酒茶香。不问经年，一抹剪梅裳。也曾看人间浩荡，孤月色，倚白墙。</p>
<p>小酌清宴绕梁香。醉回廊，聚无常。风起忽觉，拭袖泪千行。最可怜相思遍唱，难道尽，此情长。</p>
<p>很久以前按江城子填的，不知道当初是什么心情了。<del>可能和 ex
有关？</del></p>
<h1 id="发病警告">发病警告</h1>
<p>集体照：好丑</p>
<p>不慎被人拍到：好丑</p>
<p>北京健康宝：好丑</p>
<p>起床照镜子：好一个沉鱼落雁闭月羞花的美人</p>
<p>地铁玻璃门：好一个沉鱼落雁闭月羞花的美人</p>
<p>洗手间的超大镜子：好一个沉鱼落雁闭月羞花的美人</p>
<h1 id="新生寄语">新生寄语（？</h1>
<p>如果要认真寄语，那目前就是：</p>
<p>在你清做的第一件失败的事情，是入学英语分级考认真考出了四级；第二件是大一上学期就报了法语二外，虽然这很欧皇。少了
4 学分的必修 4.0
事小，但二者一起成功摧毁了我本就不高的英语水平，有点得不偿失。</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
        <tag>睡隙碎笔</tag>
      </tags>
  </entry>
  <entry>
    <title>感觉要长脑子了</title>
    <url>/2023/07/25/sparkle-or-cliche/</url>
    <content><![CDATA[<p>随便记录一下之前的一些零碎的非常 trivial
的想法<del>，简称正确的废话，经由我破碎的叙述之后正常人应该是理解不了</del>。翻翻书上的批注还是能感觉到每次想到这些的时候，都有一种要长脑子了的，喜悦感（</p>
<span id="more"></span>
<p>虽然我 tag 打的是概率和统计，但是我感觉这其实又是一篇实分析（挠头</p>
<h1 id="lebesgues-decomposition-theorem">Lebesgue's Decomposition
Theorem</h1>
<p>在读 Radon-Nikodym Theorem 的时候看到过 mutually singular
的定义：</p>
<blockquote>
<p>Two measures <span class="math inline">\(\mu_1,\mu_2\)</span> are
said to be mutually singular if there is a set <span class="math inline">\(A\)</span> with <span class="math inline">\(\mu_1
(A) = \mu_2 (A^c)=0\)</span>. In this case we also write <span class="math inline">\(\mu_1 \perp \mu_2\)</span>.</p>
</blockquote>
<p>在刚开始学概率论，只是学到概率测度的时候也接触过一个让我有点摸不着头脑的定义，叫做奇异连续：</p>
<blockquote>
<p>A function <span class="math inline">\(F\)</span> is called singular
continuous if it is continuous, not identically zero and <span class="math inline">\(F&#39;\)</span> (exists and) equals zero a.e.
.</p>
</blockquote>
<p>如果说得再粗暴一点的话，奇异连续分布函数就是一个增长点在 Lebesgue
零测集里的函数，我一般都会形象地记成“所有的重量落在一个零测集里”。它只在分布函数的
Lebesgue decomposition
里出现过一次，我还以为有什么大用处，但是后面就没再出现过。</p>
<p>哦对，它还在一个很有意思的计算题里出现过一次，是 lzx
布置的作业题，期中考前我和助教对线了一晚上最后发现大家都有点问题（，还在
2023.04.21 的日记里记过一笔。</p>
<blockquote>
<p><strong>跑题</strong>：虽然有些跑题，但是那个计算题长这样：</p>
<p>随机变量 <span class="math inline">\(X,Y\)</span> 分别服从 <span class="math inline">\([0,1]\)</span>
区间上的均匀分布，其联合分布函数为</p>
<p><span class="math display">\[F(x,y) = \begin{cases} x^{1-\alpha} y
&amp; x^\alpha \geq y ^\beta \\ xy^{1-\beta} &amp; x^\alpha &lt; y^\beta
\end{cases} \quad \forall (x,y) \in [0,1]^2\]</span></p>
<p>其中 <span class="math inline">\(\alpha,\beta \in (0,1)\)</span>
为参数，<span class="math inline">\(F\)</span> 的支撑为 <span class="math inline">\([0,1]^2\)</span>，但 <span class="math inline">\(F\)</span>
既不是纯绝对连续的也不是纯奇异连续的，这是因为；</p>
<p><span class="math display">\[\frac{\partial^2}{\partial x \partial y}
F(x,y) = \begin{cases} (1-\alpha)x^{-\alpha} &amp; x^\alpha &gt; y^\beta
\\ (1-\beta) y^{-\beta} &amp; x ^\alpha &lt; y^\beta  \end{cases} \quad
\forall (x,y) \in (0,1)^2\]</span></p>
<p>因此可以将 <span class="math inline">\(F\)</span>
分解为奇异连续部分和绝对连续部分之和，也即 <span class="math inline">\(F
= F_{ac} +F_s\)</span>。计算可知<del>读者自证</del>：</p>
<p><span class="math display">\[F_{ac}(x,y) = \begin{cases} xy^{1-\beta}
- \frac{\beta}{\alpha+\beta - \alpha \beta} x^{\frac{\alpha + \beta -
\alpha \beta}{\beta}} &amp; x^\alpha &lt; y^\beta  \\ x^{1-\alpha}y -
\frac{\alpha}{\alpha+\beta - \alpha \beta} y ^{\frac{\alpha + \beta -
\alpha \beta}{\alpha}} &amp; x^\alpha &gt; y^\beta \end{cases} \quad
\forall (x,y) \in (0,1)^2\]</span></p>
<p><span class="math display">\[F_s(x,y) =\begin{cases} \frac{\alpha
\beta}{\alpha+\beta - \alpha \beta} x^{\frac{\alpha+\beta - \alpha
\beta}{\beta}} &amp; x^\alpha = y^\beta \\ \frac{\beta}{\alpha+\beta -
\alpha \beta} x^{\frac{\alpha + \beta - \alpha \beta}{\beta}} &amp;
x^\alpha &lt; y^\beta \\ \frac{\alpha}{\alpha+\beta - \alpha \beta} y
^{\frac{\alpha + \beta - \alpha \beta}{\alpha}} &amp; x^\alpha &gt;
y^\beta \end{cases}  \quad \forall (x,y)\in [0,1]^2\]</span></p>
<p>另外可以注意到 <span class="math inline">\(P(X^\alpha = Y^\beta) =
F_s(1,1) = \frac{\alpha \beta}{\alpha+\beta - \alpha
\beta}\)</span>。</p>
<p>再注：中科大那本书上说这道题来自 Nelsen 老爷子 2006 年著作的第 45
页，我猜他想说的是那本 <a href="https://link.springer.com/book/10.1007/0-387-28678-0">An
Introduction to
Copulas</a>，虽然我并没有找到这道题，而且浅看了一下也没太明白单独定义一个
copulas 是干什么的（悲</p>
</blockquote>
<p>直到看到 mutually singular
的定义（<del>之后很久</del>）才想起来，singular continuous function
<span class="math inline">\(F_s\)</span> 定义了一个在 <span class="math inline">\(\mathbb R\)</span> 上的测度 <span class="math inline">\(\mu_s (-\infty , a] = F_s(a)\)</span>，相对于
<span class="math inline">\(\mathbb R\)</span> 上的 Lebesgue measure
<span class="math inline">\(m\)</span>，实际上有 <span class="math inline">\(\mu_s \perp m\)</span>。如果不介意舍弃 continuous
的条件，将其和 discrete function <span class="math inline">\(F_d\)</span> 合在一起定义测度 <span class="math inline">\(\mu&#39; (-\infty,a] =
F_s(a)+F_d(a)\)</span>，同样有 <span class="math inline">\(\mu&#39;
\perp m\)</span>。</p>
<p>对应最原始的 Lebesgue decomposition theorem（也就是在 Radon-Nikodym
theorem 证明里看到的版本）：</p>
<blockquote>
<p>Let <span class="math inline">\(\mu, \upsilon\)</span> be two <span class="math inline">\(\sigma-\)</span>finite measures on a measurable
space <span class="math inline">\((\Omega, \Sigma)\)</span>, there exist
two <span class="math inline">\(\sigma-\)</span>finite measures <span class="math inline">\(\upsilon_s,\upsilon_r\)</span> such that:</p>
<ul>
<li><span class="math inline">\(\upsilon = \upsilon_s +
\upsilon_r\)</span></li>
<li>There exists <span class="math inline">\(g \geq 0\)</span> such that
<span class="math inline">\(\upsilon_r (E) =\int_E g d\mu\)</span>
(actually means <span class="math inline">\(v_r \ll \mu\)</span>)</li>
<li><span class="math inline">\(v_s \perp \mu\)</span></li>
</ul>
</blockquote>
<p>进行一个 refinement：取 <span class="math inline">\(\mu\)</span> 为
<span class="math inline">\(\mathbb R\)</span> 上的 Lebesgue 测度，定义
<span class="math inline">\(F_c(a) = \upsilon_r (-\infty, a]\)</span>
即为一个 absolutely continuous function，再将 <span class="math inline">\(F&#39;(a) = \upsilon_s(-\infty, a]\)</span>
拆分为离散部分和连续部分则有 <span class="math inline">\(F&#39;(a) =
F_d(a) +F_s(a)\)</span>。所以，对于由 <span class="math inline">\(\upsilon\)</span> 定义的 <span class="math inline">\(F(a) = \upsilon(-\infty, a]\)</span>，有：</p>
<blockquote>
<p><span class="math inline">\(F = F_s + F_c + F_d\)</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(F_s\)</span> is the singular continuous
part</li>
<li><span class="math inline">\(F_c\)</span> is the absolutely
continuous part</li>
<li><span class="math inline">\(F_d\)</span> is the discrete part</li>
</ul>
</blockquote>
<p>这和分布函数仍然相差一个数值上的标准化。取 <span class="math inline">\(V(F) = F(+\infty) - F(-\infty)\)</span>
作为一个全变差，<span class="math inline">\(F&#39; = \frac{1}{V(F)}
F\)</span> 即为 <span class="math inline">\(F\)</span>
对应的分布函数。同样定义分布函数 <span class="math inline">\(F&#39;_s,F&#39;_d,F&#39;_c\)</span> 且显然有 <span class="math inline">\(V(F) = V(F_s) +V(F_c) +
V(F_d)\)</span>，于是：</p>
<p><span class="math display">\[F&#39; = \frac{V(F_s)}{V(F_s) + V(F_d) +
V(F_c)} F&#39;_s + \frac{V(F_d)}{V(F_s) + V(F_d) + V(F_c)} F&#39;_d+
\frac{V(F_c)}{V(F_s) + V(F_d) + V(F_c)}F&#39;_c\]</span></p>
<p>即为熟知的分布函数的 Lebesgue
decomposition，也给出了线性组合形式系数的来历。</p>
<p>查了下 wiki 发现的确是正确的废话，另外还有个<a href="https://en.wikipedia.org/wiki/Lebesgue%27s_decomposition_theorem#L%C3%A9vy%E2%80%93It%C5%8D_decomposition">随机过程的类似推广</a>但我现在看不懂，<del>前面的区域下次再来探索吧</del>（</p>
<h1 id="four-steps-procedure-in-integration">Four Steps Procedure in
Integration</h1>
<p>本质上来说，是一些我经常弄混的东西的换个角度的翻来覆去的梳理。</p>
<h2 id="for-nonnegative-function">For Nonnegative Function</h2>
<p>在实分析中熟知的是，对一般可测函数的积分有一个四步构造法，简单复习一个：</p>
<blockquote>
<ul>
<li>Simple functions</li>
<li>Bounded and finitely supported functions</li>
<li>Nonnegative functions</li>
<li>General functions</li>
</ul>
</blockquote>
<p>（<del>相信这四行字就足够了</del>）</p>
<p>第三步对于 nonnegative function <span class="math inline">\(f \geq
0\)</span>，定义 <span class="math inline">\(\int f d\mu = \sup \{\int h
\,\mathrm d \mu : 0 \leq h \leq f, h \text{ is bounded and finitely
supported} \}\)</span>，这显然 well-defined；与此同时还有一个
lemma：</p>
<blockquote>
<p>Let <span class="math inline">\(E_n \uparrow \Omega\)</span> have
<span class="math inline">\(\mu(E_n) &lt; +\infty\)</span>, then <span class="math inline">\(\int _{E_n} (f \wedge n) \,\mathrm d \mu \uparrow
\int f \,\mathrm d \mu\)</span> as <span class="math inline">\(n \to
+\infty\)</span>。</p>
</blockquote>
<p>某天想起这个 lemma 的时候突然想到，其实完全可以看成 <span class="math inline">\(\int f d\mu\)</span>
的另一个定义，即作为这一类序列的极限，轻微有别于 <span class="math inline">\(\sup \int h d\mu\)</span>
的定义。但这个看起来有比较大的操作空间，可测集序列 <span class="math inline">\(\{E_n \} \uparrow \Omega\)</span>
可以自取，就能用截断构造出各种趋于 <span class="math inline">\(f\)</span> 的可测函数列。</p>
<p>听起来很有用！但稍微试了下除了证明一些基本的性质（比如<span class="math inline">\(\int (f +g) d\mu= \int f d\mu + \int g
d\mu\)</span>
的半边不等式，以及法图引理）之外还没见过太多的用法（，只不过证出来这个之后我也一下子觉得自己要长脑子了（</p>
<h2 id="who-is-dense-on-l1-space">Who is Dense on <span class="math inline">\(L^1\)</span> Space</h2>
<p>首先复习一下什么叫做 <span class="math inline">\(A\)</span> is dense
on <span class="math inline">\(L^1\)</span>
space，我感觉这种东西真的是学了之后不用就会变成名词党。类比 <span class="math inline">\(\mathbb Q\)</span> 在 <span class="math inline">\(\mathbb R\)</span> 上稠密就是对任意的 <span class="math inline">\(g \in L^1\)</span> 存在 <span class="math inline">\(A\)</span> 中序列 <span class="math inline">\(\{\psi_n \} \stackrel{L^1}{\rightarrow}
g\)</span>，也就是 <span class="math inline">\(\| \psi_n - g
\|_{L^1}=\int |\psi_n -g | \,\mathrm d \mu \to
0\)</span>；或者说，对任意的 <span class="math inline">\(\varepsilon
&gt;0\)</span> 都存在 <span class="math inline">\(\varphi \in
A\)</span>，使得 <span class="math inline">\(\| \varphi - g \|_{L^1} =
\int |\varphi - g| \,\mathrm d\mu &lt; \varepsilon\)</span>。</p>
<p>Stein 告诉我们应该熟知以下三种 density：</p>
<blockquote>
<ul>
<li>simple function</li>
<li>step function</li>
<li>compactly supported continuous function</li>
</ul>
</blockquote>
<p>另外一个（一组）我会弄混的结论是这样的，实质上是一个 convergence
sequence，只有第一条是重要的：</p>
<blockquote>
<ul>
<li>For any nonnegative measurable function <span class="math inline">\(f\)</span>, there exists a sequence of increasing
nonnegative simple function <span class="math inline">\(\{\varphi_k
\}_{k=1}^{+\infty}\)</span> which converges to <span class="math inline">\(f\)</span> pointwise.</li>
<li>For any measurable function <span class="math inline">\(f\)</span>,
there exists a sequence of simple function <span class="math inline">\(\{\varphi_k \}_{k=1}^{+\infty}\)</span> which
converges to <span class="math inline">\(f\)</span> pointwise, and <span class="math inline">\(|\varphi_k (x) | \leq |\varphi_{k+1}
(x)|\)</span>.</li>
<li>For any measurable function <span class="math inline">\(f\)</span>,
there exists a sequence of step function <span class="math inline">\(\{\varphi_k \}_{k=1}^{+\infty}\)</span> which
converges to <span class="math inline">\(f\)</span> pointwise.</li>
</ul>
</blockquote>
<h2 id="how-to-apply-four-steps-procedure-elegently">How to Apply Four
Steps Procedure Elegently</h2>
<p>我写证明其实很口胡，这样不好。如果是遇到 four steps procedure
可以搞定的问题（指的是 simple function/step function 可以
work，然后直接能从 density/convergent sequence 推出 general function
works 或者至少是 nonnegative function works
的情况）会非常开心。然而这听起来就很口胡，也不可能是一个万能的方法，稍有不慎真的口胡了的话后果很严重。</p>
<p>举两个我比较喜欢用来复习和脑内提示的例子，分别代表了 density 和
convergent sequence
两种方法，对应上一个标题下的两组结论，我个人认为至少对我是稍微有点指导意义的（怎么这也要叠甲呢</p>
<h3 id="riemann-lebesgue-lemma">Riemann-Lebesgue lemma</h3>
<blockquote>
<p>If <span class="math inline">\(g\)</span> is integrable then <span class="math inline">\(\lim_{n \to \infty} \int g(x) \cos nx \,\mathrm d
x =0\)</span></p>
</blockquote>
<p><strong>Proof</strong>: It's easy to prove that the conclusion holds
for step functions. For any integrable function <span class="math inline">\(g\)</span> and any <span class="math inline">\(\varepsilon &gt;0\)</span>, there exists a step
function <span class="math inline">\(f\)</span> that <span class="math inline">\(\| f-g \|_{L^1} = \int |f-g| \,\mathrm dx &lt;
\varepsilon\)</span>.(density)</p>
<p>Note that:</p>
<p><span class="math display">\[|\int g(x) \cos nx \,\mathrm d x |
=|\int( g(x)-f(x))\cos nx \,\mathrm d x| \leq \int|( g(x)-f(x))||\cos nx
|\,\mathrm d x \leq \int|( g(x)-f(x))|\,\mathrm d x  &lt;
\varepsilon\]</span></p>
<h3 id="lemma-in-conditional-expectation">Lemma in Conditional
Expectation</h3>
<blockquote>
<p>If <span class="math inline">\(X \in \mathcal F\)</span> and <span class="math inline">\(\mathbb E|Y|, \mathbb E|XY| &lt; +\infty\)</span>
then <span class="math inline">\(\mathbb E(XY|\mathcal F) = X \mathbb
E(Y|\mathcal F)\)</span></p>
</blockquote>
<p><strong>Proof</strong>: It's easy to prove that the conclusion holds
for <span class="math inline">\(X = \mathbb 1_A\)</span>, where <span class="math inline">\(A \in \mathcal F\)</span>, thus it holds for
simple random variables.</p>
<p>Take <span class="math inline">\(X = X^+ - X^-\)</span>, there exist
two increasing simple random variable sequences <span class="math inline">\(\{X_k^+\}\uparrow X^+\)</span> and <span class="math inline">\(\{X_k^-\}\uparrow X^-\)</span>. According to the
monotone convergence theorem,</p>
<p><span class="math display">\[X^+\mathbb E(Y|\mathcal F)=\lim_{k \to
\infty} X_k^+ \mathbb E(Y|\mathcal F) =\lim_{k \to \infty} \mathbb
E(X_k^+ Y|\mathcal F) =  \mathbb E(X^+ Y|\mathcal F)\]</span></p>
<p><span class="math display">\[X^-\mathbb E(Y|\mathcal F)=\lim_{k \to
\infty} X_k^- \mathbb E(Y|\mathcal F) =\lim_{k \to \infty} \mathbb
E(X_k^- Y|\mathcal F) =  \mathbb E(X^- Y|\mathcal F)\]</span></p>
<h2 id="littlewoods-three-principles">Littlewood's Three Principles</h2>
<p>学的时候也不知道是因为 Stein
的翻译逆天还是因为什么，总之觉得这个本来应该很形象的东西是真的抽象。</p>
<blockquote>
<ul>
<li>Every measurable set is nearly a finite sum of intervals;</li>
<li>Every function (of class <span class="math inline">\(L^p\)</span>)
is nearly continuous;</li>
<li>Every convergent sequence of functions is nearly uniformly
convergent.</li>
</ul>
</blockquote>
<p>第一条代入外测度和开覆盖就挺好理解的，第三条到现在我其实也不是很能直观上理解，只知道一个
Egorov 定理，脑子长了一半还没完全长出来。</p>
<p>第二条当时也是嗯记了 Lusin 定理，其实也不是非常明白为什么要倒退一步取
bounded and finitely supported function 来做，或许就只是为了说明 <span class="math inline">\(m(E-F_\varepsilon) &lt; \varepsilon\)</span>
吗。看了 Durrett Ex.1.4.3 上对 <span class="math inline">\(q\)</span>
进行一些 linearly round 的操作得到 <span class="math inline">\(r\)</span> 的这道题才想起来其实就是一个关于 <span class="math inline">\(f\)</span> 的近似，直观上就所谓 <span class="math inline">\(f\)</span> is nearly
continuous。虽然很显然但还是要长脑子了（（</p>
<h1 id="miscellaneous-topics-in-convergence-theorems">Miscellaneous
Topics in Convergence Theorems</h1>
<p>关于实分析中一些收敛定理（有界收敛、单调收敛、法图引理和控制收敛）的杂谈，<del>大多数是解决
Stein 带来的困惑</del></p>
<h2 id="bounded-convergence-theorem">Bounded Convergence Theorem</h2>
<p>有一个因为不是很常用所以我都快忘记了的收敛定理叫做有界收敛，它是对于
bounded and finitely supported
function（事实上函数列的支撑比这更严格一些，要求全体函数的支撑的并集有限）特化的。</p>
<h3 id="convergence-type">Convergence Type</h3>
<p>在 Durrett 上这一定理的叙述是：</p>
<blockquote>
<p>Let <span class="math inline">\(E\)</span> be a set with <span class="math inline">\(\mu (E) &lt; \infty\)</span>. Suppose <span class="math inline">\(f_n\)</span> vanished on <span class="math inline">\(E^c\)</span>, <span class="math inline">\(|f_n|
\leq M\)</span> and <span class="math inline">\(f_n \to f\)</span> in
measure.</p>
<p>Then <span class="math inline">\(\int f \, \mathrm d \mu = \lim
\limits_{n \to \infty} \int f_n \, \mathrm d \mu\)</span>.</p>
</blockquote>
<p>我感觉到有点不对是因为知识太贫乏，Stein 并没有教过我什么叫做 converge
in measure，还是概率论学到 converge in probability
的时候当场补课的。如果在 bounded convergence theorem
的时候就学过那我就把 Stein 吃下去（</p>
<p>于是查了一下 Stein 的叙述，的确是 a.e. 收敛，幸免于吃书：</p>
<blockquote>
<p>Let <span class="math inline">\(E\)</span> be a set with <span class="math inline">\(\mu (E) &lt; \infty\)</span>. Suppose <span class="math inline">\(f_n\)</span> vanished on <span class="math inline">\(E^c\)</span>, <span class="math inline">\(|f_n|
\leq M\)</span> and <span class="math inline">\(f_n \to f\)</span> a.e.
.</p>
<p>Then <span class="math inline">\(\int f \, \mathrm d \mu = \lim
\limits_{n \to \infty} \int f_n \, \mathrm d \mu\)</span>.</p>
</blockquote>
<p>虽然 converge a.e. 比 converge in measure 更强，但是这个问题在
converge in measure 的时候其实更好证，不需要用到 Egorov Theorem
就可以完成。所以说其实 Durrett 又给出了一个更强的结论。</p>
<h3 id="refinement-in-probability">Refinement in Probability</h3>
<p>解决了 convergence type 的问题之后，因为 converge in measure
这件事情戳到了 DNA，所以我突然开始思考把 Durrett 上这个 bounded
convergence theorem 推广成随机变量列的形式的问题。它会变成：</p>
<blockquote>
<p>Let <span class="math inline">\(E\)</span> be a set with <span class="math inline">\(\mathbb P (E) &lt; \infty\)</span>. Suppose <span class="math inline">\(X_n\)</span> vanished on <span class="math inline">\(E^c\)</span>, <span class="math inline">\(|X_n|
\leq M\)</span> and <span class="math inline">\(X_n \to X\)</span> in
probability.</p>
<p>Then <span class="math inline">\(\mathbb E X = \lim \limits_{n \to
\infty} \mathbb EX_n\)</span>.</p>
</blockquote>
<p>事实上 <span class="math inline">\(\mathbb P (E) &lt; \infty\)</span>
这个条件完全没必要存在，也不需要再考虑所有随机变量的支撑之并可能测度无限这样的危险。</p>
<blockquote>
<p><span class="math inline">\(|X_n| \leq M\)</span> and <span class="math inline">\(X_n \to X\)</span> in probability, then <span class="math inline">\(\mathbb E X = \lim \limits_{n \to \infty} \mathbb
EX_n\)</span>.</p>
</blockquote>
<p>哦，这不就是弱化的 DCT 吗（</p>
<p>翻了下 Durrett 发现列举 four step 的时候说的是 bounded
function，我读的时候还煞有介事地补了个 with finite
support，如果是在概率测度下确实没必要<del>但他这里其实也不是</del>，凡是随机变量都
finitely supported。源头其实只是概率测度多出了一个 <span class="math inline">\(\mathbb P(\Omega) =1\)</span>
的条件，感觉要长脑子了。或许 free probability
也会带有类似的性质吗？<del>我第一次接触 free probability 这个概念是在
ypk
给我的论文里，看起来似乎除了不是归一化的测度之外没有太多区别。</del></p>
<p>还有个讨论映射的收敛定理，<del>因为稍微复杂所以</del>快忘了，随手记一下好了。<del>证明留作习题（什么东西（其实我也不会证</del></p>
<blockquote>
<p>Suppose <span class="math inline">\(X_n \to X\)</span> a.s.. Let
<span class="math inline">\(g,h\)</span> be continuous functions
with:</p>
<ul>
<li><span class="math inline">\(g \geq 0\)</span> and <span class="math inline">\(g(x) \to \infty\)</span> as <span class="math inline">\(|x| \to \infty\)</span></li>
<li><span class="math inline">\(|h(x)| / g(x) \to 0\)</span> as <span class="math inline">\(|x| \to \infty\)</span></li>
<li><span class="math inline">\(\mathbb Eg(X_n) \leq K &lt; +
\infty\)</span> for all <span class="math inline">\(n\)</span></li>
</ul>
<p>Then <span class="math inline">\(\mathbb Eh(X_n) \to \mathbb
Eh(X)\)</span>.</p>
</blockquote>
<h2 id="misunderstanding-of-fatous-lemma">Misunderstanding of Fatou's
Lemma</h2>
<p>在读 Stein 学法图引理的时候给出的形式是这样的：</p>
<blockquote>
<p>If <span class="math inline">\(f_n \geq 0\)</span> and <span class="math inline">\(f_n \to f\)</span> a.e., then <span class="math inline">\(\lim \limits_{n \to \infty} \inf \int f_n \,
\mathrm d x \geq \int f \, \mathrm d x\)</span>.</p>
</blockquote>
<p>我当时非常摸不着<del>头发</del>头脑，为什么会想出来这么一个形式，用一个
<span class="math inline">\(\lim \inf\)</span> 来控制 <span class="math inline">\(\int f \, \mathrm
dx\)</span>，是为了显示这个控制实际上已经很紧了吗？直到某次读 Durrett
Chapter 1 的时候才知道原始的结论是这样的：</p>
<blockquote>
<p>If <span class="math inline">\(f_n \geq 0\)</span>, then <span class="math inline">\(\lim \limits_{n \to \infty} \inf \int f_n \,
\mathrm d x \geq \int \lim \limits_{n \to \infty} \inf f_n \, \mathrm d
x\)</span>.</p>
</blockquote>
<p>这就非常好看以及非常能够理解了，实际上是处理了一个积分号和下极限的交换问题，而
Stein
上面的形式是一个自然的推广。在这一问题的证明里，非常有幸，又看到了一个当初让我觉得长脑子了的技巧（指路
Four Steps Procedure in Integration - For Nonnegative
Function），然后就觉得更长脑子了（</p>
<blockquote>
<p><strong>Proof</strong>:</p>
<p>Let <span class="math inline">\(g_n = \inf_{m \geq n} f_m(x) \leq
f_n(x)\)</span> and as <span class="math inline">\(n \uparrow
\infty\)</span>, <span class="math inline">\(g_n (x) \uparrow g(x) =
\lim \limits_{n \to \infty} \inf f_n(x)\)</span></p>
<p>Since <span class="math inline">\(\int f_n \, \mathrm d \mu \geq \int
g_n \, \mathrm d \mu\)</span>, there is <span class="math inline">\(\lim
\limits_{n \to \infty} \inf \int f_n \mathrm d \mu \geq \lim \limits_{n
\to \infty} \inf \int g_n \mathrm d \mu\)</span>.</p>
<p>It suffices then to show that <span class="math inline">\(\lim
\limits_{n \to \infty} \inf \int g_n \mathrm d \mu \geq \int g \,
\mathrm d \mu\)</span>.</p>
<p>Let <span class="math inline">\(E_m \uparrow \Omega\)</span> be sets
of finite measure. Since <span class="math inline">\(g_n \geq 0\)</span>
and for fixed <span class="math inline">\(m\)</span>, <span class="math inline">\((g_n \wedge m ) \cdot \mathbb 1_{E_m} \to (g
\wedge m ) \cdot \mathbb 1_{E_m} a.e.\)</span>.</p>
<p>The bounded convergence theorem implies <span class="math inline">\(\lim \limits_{n \to \infty} \inf \int g_n \,
\mathrm d \mu \geq \int_{E_m} (g_n \wedge m ) \, \mathrm d \mu \to
\int_{E_m} (g \wedge m ) \, \mathrm d \mu\)</span>,</p>
<p>and <strong>the second definition of the integration of nonnegative
function</strong> implies <span class="math inline">\(\int_{E_m} (g
\wedge m ) \, \mathrm d \mu \uparrow \int g \, \mathrm d
\mu\)</span>.</p>
<p>Take sup over <span class="math inline">\(m\)</span> and the desired
result follows.</p>
</blockquote>
<h1 id="random-variable">Random Variable</h1>
<p>遇到复杂的随机变量组合（尤其是下标里带 stopping time 的那种），其实把
<span class="math inline">\(X_n\)</span> 当成 <span class="math inline">\(X_n(\omega)\)</span> 来想的话就好很多。</p>
<p>举一个 Dubin's Inequality 的例子：啊没举呢，简单记一笔下次写（</p>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>统计</tag>
        <tag>概率</tag>
      </tags>
  </entry>
  <entry>
    <title>三点几了，饮茶先啦</title>
    <url>/2023/09/29/tea/</url>
    <content><![CDATA[<p>咖啡喝腻了，最近在尝试用茶饮料作为替代，猫超有两排货架卖的都是茶，闲的没事进行了一次超过一个月的测评。</p>
<p><del>写着写着就变成说相声了</del></p>
<span id="more"></span>
<h1 id="茶-pi-系列">茶 <span class="math inline">\(\pi\)</span>
系列</h1>
<p>爱糖水人士狂喜，但完全当不了咖啡的替代，<del>但是可以当果茶的替代，赚了</del>。</p>
<h2 id="西柚茉莉花茶">西柚茉莉花茶</h2>
<p>年轻人的第一款茶 <span class="math inline">\(\pi\)</span>，猫超卖四块五三教自动售货机卖五块五，高下立判。味道是有一点点茶味儿和西柚味的比较清甜的糖水，说人话就是三到五分糖加香精，尤其这个茶味儿就像北京菜里面放的辣椒一样是摆着看的，但我确实比较喜欢喝糖水，好评。</p>
<h2 id="青提乌龙茶">青提乌龙茶</h2>
<p>年轻人的第二款茶 <span class="math inline">\(\pi\)</span>（，才知道不同口味的茶 <span class="math inline">\(\pi\)</span>
价格也不同，这款四块七。青提的味道很重（在说废话），感觉糖加多了有点腻歪，不是西柚茉莉花茶那种清甜的三分糖的味道，另外也喝不出乌龙茶的味儿，不想再喝了。</p>
<h2 id="柠檬红茶">柠檬红茶</h2>
<p>这不就是冰红茶？没任何区别还卖我四块五，感觉被骗了。</p>
<h2 id="柑普柠檬茶">柑普柠檬茶</h2>
<p>农夫山泉你好会做生意啊！柑皮 +
普洱，这不就是东方树叶青柑普洱的搭配再加点糖和柠檬茶吗（</p>
<p>室友之前跟我说茶 <span class="math inline">\(\pi\)</span>
颜色最深的一款比较好喝，应该就是这个。但我尝了感觉其实是茶 <span class="math inline">\(\pi\)</span>
里最难喝的一款，像是青柑普洱混冰红茶，柑皮微微发苦的回甘不仅没能被齁甜的柠檬茶掩盖，反而混在了一起，又不像甜咸口那么融洽，总之一点都不搭。</p>
<h2 id="蜜桃乌龙茶">蜜桃乌龙茶</h2>
<p>另一个室友最喜欢的一款，其实确实不错，但我喝饮料一般都不喜欢蜜桃口味，感觉有点发腻，这个也不例外。能喝到乌龙茶的清爽感，但对蜜桃香精的耐受度实在太低，甚至会觉得糊嗓子。</p>
<h2 id="柚子绿茶">柚子绿茶</h2>
<p>上次去的时候还没有，还以为六种茶 <span class="math inline">\(\pi\)</span>
但猫超只卖五种，收集不齐了。好像是卖四块八，最贵的一款，口味和西柚茉莉类似，毕竟都有柚子的清香，感觉不相上下但我更喜欢绿茶茶底一点。</p>
<h2 id="总结">总结</h2>
<p>西柚茉莉 <span class="math inline">\(\approx\)</span> 柚子绿茶 &gt;
青提乌龙 &gt; 蜜桃乌龙 &gt; 柑普柠檬茶 &gt; 柠檬红茶</p>
<p>馋糖水的时候应该会选前三款喝，后三种不会再买了。这么一看就是在把果味和茶底排列组合嘛（</p>
<h1 id="东方树叶系列">东方树叶系列</h1>
<p>怎么又是农夫山泉？</p>
<h2 id="茉莉花茶">茉莉花茶</h2>
<p>你这白开水怎么没味儿啊？</p>
<h2 id="青柑普洱">青柑普洱</h2>
<p>听着就不好喝（，但本着测评要测全的职业精神还是买了，至少颜色很深看起来感觉很能醒。买回来一开寝室门室友（当然又是
wafarinliu
老师）就说之前喝过这个感觉有点苦，我说只要比咖啡好喝就好说。</p>
<p>结果真的很难喝，但是是最清醒的一集，莫非咖啡也是因为难喝所以能保持清醒，而不是咖啡因在起作用（</p>
<h2 id="红茶">红茶</h2>
<p>昏 睡 红 茶（指喝了还是困（</p>
<h2 id="绿茶">绿茶</h2>
<p>绿茶和乌龙茶不知道为什么学校的猫超不卖了，还是我去上地那次从那边的超市背回来的。说起来那边居然比猫超还贵一点，这俩都在四块五到五块这个范围里，具体忘记多少了。</p>
<p>后面这三款都非常的朴素，甚至给我一种我自己泡茶包也行的蜜汁自信，毕竟东方树叶的配料表都很干净。</p>
<h2 id="乌龙茶">乌龙茶</h2>
<p>味道挺淡的，口味没有三得利系列的乌龙茶那么重，没啥很深的印象。</p>
<h2 id="黑乌龙">黑乌龙</h2>
<p>某天猫超突然出现的，上次去上地那家超市倒是没有。然而这和乌龙茶有什么很大的区别吗（</p>
<h2 id="总结-1">总结</h2>
<p>整体味道都不浓，但回味的时候完全可以感觉到鼻腔里充斥着茶香，很清爽的感觉，不会像茶
<span class="math inline">\(\pi\)</span>
一样被甜味盖住，只是感觉兑水还是兑多了。想喝清淡口的时候会选东方树叶，只可惜绿茶和乌龙茶学校里暂时买不到。</p>
<p>六种口味没有特别雷的，每一款都挺不错，红茶在里面算是偏浓的了，青柑普洱味道最重也稍微有点一言难尽，不过还在我的接受范围里，也算是一种提神利器。</p>
<h1 id="元气森林系列">元气森林系列</h1>
<h2 id="燃茶-醇香乌龙">燃茶-醇香乌龙</h2>
<p>六块，我的财力只能支撑我喝这一次.jpg</p>
<p>还是那句话，虽然也不错，但所有的乌龙茶都比不上三得利那个无糖款。这个有加膳食纤维，<del>但是应该不缺这点罢</del>。</p>
<h2 id="燃茶-茉莉花茶">燃茶-茉莉花茶</h2>
<p>没什么特别的感觉，也多少有点你这白开水怎么没味儿啊，是不是茉莉花茶都这样呢。但茉莉花香确实挺浓的，每喝一口之后都努力呼吸一下
<del>感觉还活着真好，还能闻到花香</del>。</p>
<h2 id="纤茶-桑椹五黑茶">纤茶-桑椹五黑茶</h2>
<p>看到这个的时候我其实有那么点疑惑，但也还是皱着眉头买了（</p>
<p>其实挺好喝的，很喜欢茶里面这个谷物（主要是黑芝麻）的味道，没太喝出桑椹的味。但不怎么能醒（</p>
<h2 id="纤茶-玉米须茶">纤茶-玉米须茶</h2>
<p>比起上一个来说更困惑了，不是很想买，再说吧（</p>
<h2 id="总结-2">总结</h2>
<p>我之前看名字一直以为这个桑椹五黑茶是黑暗料理，但出乎我意料的好喝，很推荐。燃茶那两款没啥特别的印象，性价比不如东方树叶。</p>
<h1 id="三得利系列">三得利系列</h1>
<p>基本都是无糖/微糖，爱糖人士狂怒，但是确实能醒。</p>
<h2 id="无糖乌龙茶">无糖乌龙茶</h2>
<p>四块五一瓶，最便宜的一集。和我的人生一样苦（开玩笑的，它哪有那么苦）。</p>
<p>苦味给我的感觉类似于大麦茶，我还挺喜欢的，喝了感觉能看完 200 页 <a href="https://services.math.duke.edu/~rtd/PTE/PTE5_011119.pdf">PTE</a>
再睡觉。</p>
<h2 id="低糖乌龙茶">低糖乌龙茶</h2>
<p>不好喝，甜味完全把茶味盖过去了，喝起来就是真·糖水。</p>
<p>平时喝奶茶我都五分/三分糖，不知道这个低糖到底是多低，反正我觉得很腻。还不如每年秋季学期体测跑完
800
米之后终点处的那个补液盐水好喝呢，每次老师都是拿一包葡萄糖剪开口直接往水桶里倒，完全不关心（可能吧）浓度，也没这么难喝。</p>
<h2 id="无糖茉莉乌龙">无糖茉莉乌龙</h2>
<p>四教售货机买的，五块五一瓶，和猫超一个价。瓶子好看，瓶口要是大一点我就拿回去插花了。确实是无糖的茶（废话），味道比东方树叶的茉莉花茶茶味儿浓，想了想是乌龙的原因吧。而且总比咖啡好喝很多。</p>
<h2 id="零能量糖茉莉乌龙">零能量糖茉莉乌龙</h2>
<p>喝了低糖乌龙茶之后本来就有点抗拒这个同构的加糖款，不是很想买的，但是本着测评要测全的原则还是买了（</p>
<p>果然也不好喝，虽然没有低糖乌龙茶那么雷但是口味也很怪，可能茶饮料单独加糖就是不太行，至少要加果味/加奶。所以说奶茶店已经把这门生意做明白了，好喝的只有奶茶和果茶，如果单独想喝茶就什么都别加了。</p>
<h2 id="橘皮乌龙">橘皮乌龙</h2>
<p>？我很难评，人类怎么会做出来这么难喝的东西。</p>
<p>乌龙没问题，这几款反正都是一样的乌龙茶呗，但加的这个橘皮颇有一种在和面包饺子的时候加奥尔良粉上色的感觉，也不是不能吃，但反正就是很怪，没啥必要。</p>
<p>好神秘的比喻，看<a href="https://space.bilibili.com/1916474">神奇海挪</a>看的（</p>
<h2 id="总结-3">总结</h2>
<p>能让我愿意回购的就只有无糖乌龙茶和无糖茉莉乌龙，性价比最高的还得是无糖乌龙茶，便宜好喝不困（比起咖啡来说还是没那么不困，但已经蛮好了），好喜欢这个类似于大麦茶的苦味。别的都是屑。</p>
<h1 id="其他乱七八糟的">其他乱七八糟的</h1>
<h2 id="怡宝菊花茶">怡宝菊花茶</h2>
<p>到现在为止还没有测到过菊花茶，在猫超看到有就买了，最难喝的一集（之一），至少和三得利低糖乌龙不相上下。很乐的是这两款我是连着两天喝的，太折磨了。</p>
<p>菊花茶本身没什么问题，也能喝到黄冰糖的味道，但是这两个味道搭在一起就变得非常逆天，每一口都是大折磨。糖加太多了，齁甜，但是又完全没盖住菊花茶的苦味，嘴里喝的是糖水感觉嗓子都发粘，鼻子里闻到的是苦味和黄冰糖的焦香，实在受不了。</p>
<p>我本来都开始怀疑是不是苦的东西里就不适合加糖了，想想以前买的贝纳颂加糖也挺好喝的，只能说加糖也就算了，为什么非要加黄冰糖，<del>为了和白菊花对仗吗</del></p>
<h2 id="兰芳园冻柠茶">兰芳园冻柠茶</h2>
<p>五块五，标的是低糖但是感觉还是有点甜了，不如桂源铺现做的好喝
<del>毕竟便宜一半多呢</del>（</p>
<p>和港式茶餐厅的一个味，其实还不错但是不可能提神，也没什么茶的成分，纯当糖水喝。</p>
<h2 id="奈雪茉莉初雪">奈雪茉莉初雪</h2>
<p>比东方树叶茉莉花茶浓一些但其实也就那样（，配料表差不多都很干净，但是它卖六块五，不会再买了（</p>
<h2 id="淳茶舍消茶-普洱">淳茶舍消茶-普洱</h2>
<p>yue。</p>
<h2 id="喜茶瓶装-空茶">喜茶瓶装-空茶</h2>
<p><del>喝不起喜茶我还喝不起五块钱的喜茶瓶装吗</del></p>
<p>学名叫玄米大麦饮，玄米就是糙米，<del>糙米薏仁汤那个糙米</del>。看了下本质上不是茶，配料是水，大麦，玄米，维生素
C 和碳酸氢钠，纯喝一个谷物的味道，感觉不错。</p>
<h2 id="喜茶瓶装-一颗柠茶">喜茶瓶装-一颗柠茶</h2>
<p>买之前我就知道它肯定是一个冰红茶的味儿了，只是对瓶子上面写的“纯柠檬汁，一瓶含一颗柠檬的维
C”“真实茶叶萃取”“低糖零脂”抱有一丝丝期待，拧开喝了一口果然是冰红茶，只不过是没那么甜的冰红茶，急了。</p>
<p>喜茶瓶装都这样，下次真的别再买别的柠檬茶了，肯定都四舍五入冰红茶（</p>
<h1 id="偷偷喝咖啡是吧">偷偷喝咖啡是吧？</h1>
<p>其实最近也有尝一些之前没喝过的咖啡啦。</p>
<h2 id="永璞闪萃可可咖啡">永璞闪萃可可咖啡</h2>
<p>是咖啡液胶囊，本来想着如果是有瓶盖的牛奶可以先喝一口然后直接把咖啡倒进去
<del>然后就少洗一个杯子</del>，然而翻了下库存发现那种已经喝完了。</p>
<h2 id="nevertimescoffee-无糖美式咖啡">NEVER<span class="math inline">\(\times\)</span>COFFEE 无糖美式咖啡</h2>
<p>第一次喝盒装的咖啡，在猫超看到买一送一两盒五块五而且放在冰柜里才买的，周三有四节课，晚饭之后运筹学课上喝一口，<del>然后睡不着，第二天还早八</del></p>
<p><del>好苦，和我的命一样苦</del>
每喝一口我的胃和舌头都在痉挛（，毕竟是美式，可能还是要加点糖和牛奶才能喝。</p>
<h1 id="总总总结">总总总结</h1>
<p>想起来小学的时候在宝山少年宫的活动里尝过用话梅泡茶的做法，其实印象还挺深刻的，虽然后来再也没喝过。反正至少比上面被差评的这些怪东西好喝。</p>
<p>三得利乌龙茶、东方树叶和元气森林的五黑茶应该之后会不停地回购吧，喝了一圈还是返璞归真了，很喜欢乌龙茶类似大麦茶的香气，还有五黑茶里谷物的味道，至于东方树叶就是兑了水的纯茶味，我也都挺喜欢的。只可惜东方树叶猫超卖的种类也不全，没品位.jpg。别的就看眼缘了。</p>
<p>谢谢你看我说相声说到这里，毕竟也没啥意思（</p>
]]></content>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
</search>
